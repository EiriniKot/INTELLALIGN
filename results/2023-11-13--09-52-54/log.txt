{"Avg objective": 14.265625, "Games time in secs": 306.0673627369106, "Avg game time in secs": 86.12107822574035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.11, "agent_stopped_more": 0.45, "played_steps": 11.97, "reached_maximum_moves": 0.44}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1699869487409, "logtype": "played_game"}
{"Avg objective": 15.5859375, "Games time in secs": 261.48071420937777, "Avg game time in secs": 100.31640556866478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"reached_maximum_moves": 0.48, "played_steps": 13.72, "agent_stopped_more": 0.45, "agent_stopped_0": 0.07}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1699869748890, "logtype": "played_game"}
{"Ratio train steps to played games": 0.45229681978798586, "Avg loss": 50.31195209920406, "Avg value loss": 49.751228749752045, "Avg policy loss": 0.5607231901958585, "Total num played games": 283, "Total num trained steps": 128, "Timestamp in ms": 1699869827758, "logtype": "training_step"}
{"Ratio train steps to played games": 0.8121019108280255, "Avg loss": 8.889725644141436, "Avg value loss": 8.352913290262222, "Avg policy loss": 0.5368123261723667, "Total num played games": 314, "Total num trained steps": 256, "Timestamp in ms": 1699869908434, "logtype": "training_step"}
{"Ratio train steps to played games": 1.136094674556213, "Avg loss": 5.108206581324339, "Avg value loss": 4.585656082257628, "Avg policy loss": 0.5225505032576621, "Total num played games": 337, "Total num trained steps": 384, "Timestamp in ms": 1699869970445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3950953678474114, "Avg loss": 3.9598789252340794, "Avg value loss": 3.451779754832387, "Avg policy loss": 0.5080991918221116, "Total num played games": 367, "Total num trained steps": 512, "Timestamp in ms": 1699870031035, "logtype": "training_step"}
{"Avg objective": 14.8203125, "Games time in secs": 325.1125888675451, "Avg game time in secs": 117.97959614251158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"reached_maximum_moves": 0.67, "played_steps": 16.12, "agent_stopped_more": 0.26, "agent_stopped_0": 0.07}, "Total num played games": 384, "Total num trained steps": 601, "Timestamp in ms": 1699870074003, "logtype": "played_game"}
{"Total num played games": 428, "Total num trained steps": 601, "Timestamp in ms": 1699870458488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.86328125}
{"Ratio train steps to played games": 1.4678899082568808, "Avg loss": 3.634110866114497, "Avg value loss": 3.137380718253553, "Avg policy loss": 0.4967301464639604, "Total num played games": 436, "Total num trained steps": 640, "Timestamp in ms": 1699870475654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7258426966292135, "Avg loss": 2.805491229519248, "Avg value loss": 2.3397595146670938, "Avg policy loss": 0.4657317034434527, "Total num played games": 445, "Total num trained steps": 768, "Timestamp in ms": 1699870524482, "logtype": "training_step"}
{"Ratio train steps to played games": 2.0, "Avg loss": 2.070108665153384, "Avg value loss": 1.6068247882649302, "Avg policy loss": 0.463283872930333, "Total num played games": 448, "Total num trained steps": 896, "Timestamp in ms": 1699870573389, "logtype": "training_step"}
{"Ratio train steps to played games": 2.183368869936034, "Avg loss": 2.129379976540804, "Avg value loss": 1.6732582282274961, "Avg policy loss": 0.4561217452865094, "Total num played games": 469, "Total num trained steps": 1024, "Timestamp in ms": 1699870622409, "logtype": "training_step"}
{"Ratio train steps to played games": 2.279207920792079, "Avg loss": 2.182254111394286, "Avg value loss": 1.729321819730103, "Avg policy loss": 0.4529322877060622, "Total num played games": 505, "Total num trained steps": 1152, "Timestamp in ms": 1699870671048, "logtype": "training_step"}
{"Avg objective": 15.21875, "Games time in secs": 633.6551293265074, "Avg game time in secs": 118.34728806868952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3671875, "Avg reasons for ending game": {"reached_maximum_moves": 0.66, "played_steps": 15.79, "agent_stopped_more": 0.23, "agent_stopped_0": 0.12}, "Total num played games": 512, "Total num trained steps": 1205, "Timestamp in ms": 1699870707658, "logtype": "played_game"}
{"Total num played games": 556, "Total num trained steps": 1205, "Timestamp in ms": 1699871104057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.91796875}
{"Ratio train steps to played games": 2.249560632688928, "Avg loss": 2.445826416835189, "Avg value loss": 1.9970773234963417, "Avg policy loss": 0.4487491112668067, "Total num played games": 569, "Total num trained steps": 1280, "Timestamp in ms": 1699871135664, "logtype": "training_step"}
{"Ratio train steps to played games": 2.440207972270364, "Avg loss": 1.9871104573830962, "Avg value loss": 1.5364882089197636, "Avg policy loss": 0.4506222566124052, "Total num played games": 577, "Total num trained steps": 1408, "Timestamp in ms": 1699871184551, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6122448979591835, "Avg loss": 1.7829918004572392, "Avg value loss": 1.3375627808272839, "Avg policy loss": 0.44542902894318104, "Total num played games": 588, "Total num trained steps": 1536, "Timestamp in ms": 1699871232630, "logtype": "training_step"}
{"Ratio train steps to played games": 2.723404255319149, "Avg loss": 1.7382118497043848, "Avg value loss": 1.292024364694953, "Avg policy loss": 0.44618747546337545, "Total num played games": 611, "Total num trained steps": 1664, "Timestamp in ms": 1699871281692, "logtype": "training_step"}
{"Avg objective": 16.1171875, "Games time in secs": 614.8566852845252, "Avg game time in secs": 112.37111342244316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3046875, "Avg reasons for ending game": {"reached_maximum_moves": 0.62, "played_steps": 14.88, "agent_stopped_more": 0.21, "agent_stopped_0": 0.17}, "Total num played games": 640, "Total num trained steps": 1769, "Timestamp in ms": 1699871322516, "logtype": "played_game"}
{"Ratio train steps to played games": 2.781055900621118, "Avg loss": 1.977454012259841, "Avg value loss": 1.5269704521633685, "Avg policy loss": 0.45048356940969825, "Total num played games": 644, "Total num trained steps": 1792, "Timestamp in ms": 1699871331128, "logtype": "training_step"}
{"Total num played games": 694, "Total num trained steps": 1806, "Timestamp in ms": 1699871701036, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2421875}
{"Ratio train steps to played games": 2.689075630252101, "Avg loss": 2.5183262825012207, "Avg value loss": 2.07080680411309, "Avg policy loss": 0.4475194609258324, "Total num played games": 714, "Total num trained steps": 1920, "Timestamp in ms": 1699871750356, "logtype": "training_step"}
{"Ratio train steps to played games": 2.835180055401662, "Avg loss": 1.5024896962568164, "Avg value loss": 1.071816579438746, "Avg policy loss": 0.43067311425693333, "Total num played games": 722, "Total num trained steps": 2048, "Timestamp in ms": 1699871806693, "logtype": "training_step"}
{"Ratio train steps to played games": 2.882119205298013, "Avg loss": 1.5293486649170518, "Avg value loss": 1.0986123871989548, "Avg policy loss": 0.4307362714316696, "Total num played games": 755, "Total num trained steps": 2176, "Timestamp in ms": 1699871865633, "logtype": "training_step"}
{"Avg objective": 15.234375, "Games time in secs": 558.3330497182906, "Avg game time in secs": 99.32980741208303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 13.41, "agent_stopped_0": 0.2, "reached_maximum_moves": 0.53}, "Total num played games": 768, "Total num trained steps": 2216, "Timestamp in ms": 1699871880851, "logtype": "played_game"}
{"Ratio train steps to played games": 2.942528735632184, "Avg loss": 1.5307026775553823, "Avg value loss": 1.1125599006190896, "Avg policy loss": 0.41814277484081686, "Total num played games": 783, "Total num trained steps": 2304, "Timestamp in ms": 1699871914889, "logtype": "training_step"}
{"Total num played games": 853, "Total num trained steps": 2410, "Timestamp in ms": 1699872364845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9765625}
{"Ratio train steps to played games": 2.808314087759815, "Avg loss": 1.5816343133337796, "Avg value loss": 1.1602862770669162, "Avg policy loss": 0.4213480483740568, "Total num played games": 866, "Total num trained steps": 2432, "Timestamp in ms": 1699872374486, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8796400449943755, "Avg loss": 1.800489418208599, "Avg value loss": 1.3695374210365117, "Avg policy loss": 0.43095198832452297, "Total num played games": 889, "Total num trained steps": 2560, "Timestamp in ms": 1699872423528, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0033519553072625, "Avg loss": 1.2115498092025518, "Avg value loss": 0.7846417957916856, "Avg policy loss": 0.4269080173689872, "Total num played games": 895, "Total num trained steps": 2688, "Timestamp in ms": 1699872473875, "logtype": "training_step"}
{"Avg objective": 16.078125, "Games time in secs": 598.0347316469997, "Avg game time in secs": 90.67718156139017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "reached_maximum_moves": 0.47, "played_steps": 11.91, "agent_stopped_more": 0.26}, "Total num played games": 896, "Total num trained steps": 2700, "Timestamp in ms": 1699872478885, "logtype": "played_game"}
{"Ratio train steps to played games": 3.0509209100758397, "Avg loss": 1.2215380230918527, "Avg value loss": 0.8047237736172974, "Avg policy loss": 0.4168142599519342, "Total num played games": 923, "Total num trained steps": 2816, "Timestamp in ms": 1699872524934, "logtype": "training_step"}
{"Ratio train steps to played games": 3.063475546305931, "Avg loss": 1.4679171489551663, "Avg value loss": 1.0505281330551952, "Avg policy loss": 0.4173890061210841, "Total num played games": 961, "Total num trained steps": 2944, "Timestamp in ms": 1699872574898, "logtype": "training_step"}
{"Total num played games": 1016, "Total num trained steps": 3014, "Timestamp in ms": 1699872935552, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.82421875}
{"Avg objective": 14.9609375, "Games time in secs": 462.8409634716809, "Avg game time in secs": 109.79913984175073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.19, "played_steps": 14.73, "reached_maximum_moves": 0.62, "agent_stopped_0": 0.2}, "Total num played games": 1024, "Total num trained steps": 3028, "Timestamp in ms": 1699872941726, "logtype": "played_game"}
{"Ratio train steps to played games": 2.961427193828351, "Avg loss": 1.655084565281868, "Avg value loss": 1.2379491315223277, "Avg policy loss": 0.4171354379504919, "Total num played games": 1037, "Total num trained steps": 3072, "Timestamp in ms": 1699872958390, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0651340996168583, "Avg loss": 1.3253078432753682, "Avg value loss": 0.9164151102304459, "Avg policy loss": 0.40889273025095463, "Total num played games": 1044, "Total num trained steps": 3200, "Timestamp in ms": 1699873008179, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1161048689138577, "Avg loss": 1.1935710762627423, "Avg value loss": 0.7883149574045092, "Avg policy loss": 0.40525611652992666, "Total num played games": 1068, "Total num trained steps": 3328, "Timestamp in ms": 1699873061401, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1475409836065573, "Avg loss": 1.2949723158963025, "Avg value loss": 0.8885477273724973, "Avg policy loss": 0.40642458689399064, "Total num played games": 1098, "Total num trained steps": 3456, "Timestamp in ms": 1699873112371, "logtype": "training_step"}
{"Ratio train steps to played games": 3.138353765323993, "Avg loss": 1.488242810126394, "Avg value loss": 1.0868813190609217, "Avg policy loss": 0.401361484779045, "Total num played games": 1142, "Total num trained steps": 3584, "Timestamp in ms": 1699873162845, "logtype": "training_step"}
{"Avg objective": 17.390625, "Games time in secs": 262.5172102730721, "Avg game time in secs": 70.85084989706229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.24, "played_steps": 9.3, "reached_maximum_moves": 0.34}, "Total num played games": 1152, "Total num trained steps": 3614, "Timestamp in ms": 1699873204244, "logtype": "played_game"}
{"Total num played games": 1194, "Total num trained steps": 3614, "Timestamp in ms": 1699873491028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48828125}
{"Ratio train steps to played games": 3.0326797385620914, "Avg loss": 1.5857691182754934, "Avg value loss": 1.1910242028534412, "Avg policy loss": 0.3947449086699635, "Total num played games": 1224, "Total num trained steps": 3712, "Timestamp in ms": 1699873530704, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1093117408906883, "Avg loss": 1.187434006948024, "Avg value loss": 0.7963521354831755, "Avg policy loss": 0.3910818682052195, "Total num played games": 1235, "Total num trained steps": 3840, "Timestamp in ms": 1699873581342, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1342812006319116, "Avg loss": 1.12914076494053, "Avg value loss": 0.7404347225092351, "Avg policy loss": 0.38870603987015784, "Total num played games": 1266, "Total num trained steps": 3968, "Timestamp in ms": 1699873629783, "logtype": "training_step"}
{"Avg objective": 16.125, "Games time in secs": 449.00924199074507, "Avg game time in secs": 80.49307458758994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2421875, "Avg reasons for ending game": {"reached_maximum_moves": 0.41, "played_steps": 10.69, "agent_stopped_more": 0.2, "agent_stopped_0": 0.38}, "Total num played games": 1280, "Total num trained steps": 4029, "Timestamp in ms": 1699873653254, "logtype": "played_game"}
{"Ratio train steps to played games": 3.148347425057648, "Avg loss": 1.1818150728940964, "Avg value loss": 0.7966262658592314, "Avg policy loss": 0.3851888154167682, "Total num played games": 1301, "Total num trained steps": 4096, "Timestamp in ms": 1699873678392, "logtype": "training_step"}
{"Total num played games": 1387, "Total num trained steps": 4215, "Timestamp in ms": 1699874032250, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.40234375}
{"Ratio train steps to played games": 3.044700793078587, "Avg loss": 1.372703363187611, "Avg value loss": 0.9883750877343118, "Avg policy loss": 0.3843282775487751, "Total num played games": 1387, "Total num trained steps": 4224, "Timestamp in ms": 1699874036354, "logtype": "training_step"}
{"Avg objective": 17.578125, "Games time in secs": 385.8998000919819, "Avg game time in secs": 84.41305870180076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "reached_maximum_moves": 0.45, "played_steps": 11.18, "agent_stopped_more": 0.13}, "Total num played games": 1408, "Total num trained steps": 4231, "Timestamp in ms": 1699874039154, "logtype": "played_game"}
{"Ratio train steps to played games": 3.024322446143155, "Avg loss": 1.7882190216332674, "Avg value loss": 1.3989916960708797, "Avg policy loss": 0.38922733161598444, "Total num played games": 1439, "Total num trained steps": 4352, "Timestamp in ms": 1699874087481, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0853994490358128, "Avg loss": 1.285766527056694, "Avg value loss": 0.9056870215572417, "Avg policy loss": 0.38007951248437166, "Total num played games": 1452, "Total num trained steps": 4480, "Timestamp in ms": 1699874136901, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0884718498659516, "Avg loss": 1.153155855834484, "Avg value loss": 0.7682672911323607, "Avg policy loss": 0.3848885695915669, "Total num played games": 1492, "Total num trained steps": 4608, "Timestamp in ms": 1699874187825, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 187.82778510823846, "Avg game time in secs": 46.82137856884219, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.2, "played_steps": 5.88, "reached_maximum_moves": 0.21}, "Total num played games": 1536, "Total num trained steps": 4709, "Timestamp in ms": 1699874226982, "logtype": "played_game"}
{"Ratio train steps to played games": 3.032010243277849, "Avg loss": 1.6512658623978496, "Avg value loss": 1.2765998924151063, "Avg policy loss": 0.3746659478638321, "Total num played games": 1562, "Total num trained steps": 4736, "Timestamp in ms": 1699874238217, "logtype": "training_step"}
{"Total num played games": 1633, "Total num trained steps": 4814, "Timestamp in ms": 1699874572113, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.30078125}
{"Avg objective": 17.0078125, "Games time in secs": 356.87878058850765, "Avg game time in secs": 71.22641954064602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2890625, "Avg reasons for ending game": {"reached_maximum_moves": 0.43, "played_steps": 9.26, "agent_stopped_0": 0.52, "agent_stopped_more": 0.05}, "Total num played games": 1664, "Total num trained steps": 4841, "Timestamp in ms": 1699874583861, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8900772430184194, "Avg loss": 1.653841070830822, "Avg value loss": 1.2959520360454917, "Avg policy loss": 0.35788903781212866, "Total num played games": 1682, "Total num trained steps": 4864, "Timestamp in ms": 1699874593093, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9347442680776012, "Avg loss": 1.3528157649561763, "Avg value loss": 1.0002581849694252, "Avg policy loss": 0.35255758301354945, "Total num played games": 1701, "Total num trained steps": 4992, "Timestamp in ms": 1699874642790, "logtype": "training_step"}
{"Ratio train steps to played games": 2.998828353837141, "Avg loss": 1.0922052743844688, "Avg value loss": 0.7540548485703766, "Avg policy loss": 0.33815042837522924, "Total num played games": 1707, "Total num trained steps": 5120, "Timestamp in ms": 1699874691477, "logtype": "training_step"}
{"Ratio train steps to played games": 2.988610478359909, "Avg loss": 1.2085382863879204, "Avg value loss": 0.8737032623030245, "Avg policy loss": 0.33483502827584743, "Total num played games": 1756, "Total num trained steps": 5248, "Timestamp in ms": 1699874741058, "logtype": "training_step"}
{"Avg objective": 17.265625, "Games time in secs": 193.21443049423397, "Avg game time in secs": 55.902867443845025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.21, "played_steps": 7.38, "agent_stopped_0": 0.5, "reached_maximum_moves": 0.29}, "Total num played games": 1792, "Total num trained steps": 5337, "Timestamp in ms": 1699874777076, "logtype": "played_game"}
{"Ratio train steps to played games": 2.9767441860465116, "Avg loss": 1.1259765499271452, "Avg value loss": 0.8007710850797594, "Avg policy loss": 0.32520546461455524, "Total num played games": 1806, "Total num trained steps": 5376, "Timestamp in ms": 1699874792263, "logtype": "training_step"}
{"Total num played games": 1860, "Total num trained steps": 5418, "Timestamp in ms": 1699875097250, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48828125}
{"Ratio train steps to played games": 2.883184913567313, "Avg loss": 1.610295256599784, "Avg value loss": 1.2890480170026422, "Avg policy loss": 0.32124723750166595, "Total num played games": 1909, "Total num trained steps": 5504, "Timestamp in ms": 1699875137221, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9394572025052192, "Avg loss": 1.0746225910261273, "Avg value loss": 0.7528888257220387, "Avg policy loss": 0.32173375482670963, "Total num played games": 1916, "Total num trained steps": 5632, "Timestamp in ms": 1699875186430, "logtype": "training_step"}
{"Avg objective": 17.4453125, "Games time in secs": 428.76701384224, "Avg game time in secs": 62.44403478830645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.18, "played_steps": 8.09, "reached_maximum_moves": 0.3}, "Total num played games": 1920, "Total num trained steps": 5681, "Timestamp in ms": 1699875205843, "logtype": "played_game"}
{"Ratio train steps to played games": 2.962448559670782, "Avg loss": 1.0766434879042208, "Avg value loss": 0.7621526913717389, "Avg policy loss": 0.3144907949026674, "Total num played games": 1944, "Total num trained steps": 5760, "Timestamp in ms": 1699875235577, "logtype": "training_step"}
{"Ratio train steps to played games": 2.941058941058941, "Avg loss": 1.2996507678180933, "Avg value loss": 0.9828907016199082, "Avg policy loss": 0.3167600599117577, "Total num played games": 2002, "Total num trained steps": 5888, "Timestamp in ms": 1699875286296, "logtype": "training_step"}
{"Ratio train steps to played games": 2.950465914664051, "Avg loss": 1.2398036033846438, "Avg value loss": 0.9221974075771868, "Avg policy loss": 0.31760617927648127, "Total num played games": 2039, "Total num trained steps": 6016, "Timestamp in ms": 1699875337387, "logtype": "training_step"}
{"Avg objective": 18.7578125, "Games time in secs": 140.51397434808314, "Avg game time in secs": 65.47428474442859, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.16, "played_steps": 8.52, "reached_maximum_moves": 0.33}, "Total num played games": 2048, "Total num trained steps": 6018, "Timestamp in ms": 1699875346357, "logtype": "played_game"}
{"Total num played games": 2088, "Total num trained steps": 6018, "Timestamp in ms": 1699875637157, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.38671875}
{"Avg objective": 19.390625, "Games time in secs": 319.7741935905069, "Avg game time in secs": 47.360534185674624, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.09, "played_steps": 6.02, "reached_maximum_moves": 0.25, "agent_stopped_0": 0.66}, "Total num played games": 2176, "Total num trained steps": 6091, "Timestamp in ms": 1699875666131, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7889241942805265, "Avg loss": 1.836188217625022, "Avg value loss": 1.5257403790019453, "Avg policy loss": 0.31044783908873796, "Total num played games": 2203, "Total num trained steps": 6144, "Timestamp in ms": 1699875686925, "logtype": "training_step"}
{"Ratio train steps to played games": 2.832881662149955, "Avg loss": 1.152861719019711, "Avg value loss": 0.8501839879900217, "Avg policy loss": 0.3026777326595038, "Total num played games": 2214, "Total num trained steps": 6272, "Timestamp in ms": 1699875736757, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8314159292035397, "Avg loss": 1.2351120859384537, "Avg value loss": 0.9374684654176235, "Avg policy loss": 0.29764361516572535, "Total num played games": 2260, "Total num trained steps": 6400, "Timestamp in ms": 1699875785099, "logtype": "training_step"}
{"Avg objective": 19.1640625, "Games time in secs": 158.45417815074325, "Avg game time in secs": 45.73033322725678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.16, "played_steps": 6.0, "reached_maximum_moves": 0.24}, "Total num played games": 2304, "Total num trained steps": 6500, "Timestamp in ms": 1699875824586, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8137931034482757, "Avg loss": 1.1511472868733108, "Avg value loss": 0.8558551725000143, "Avg policy loss": 0.2952921132091433, "Total num played games": 2320, "Total num trained steps": 6528, "Timestamp in ms": 1699875835466, "logtype": "training_step"}
{"Total num played games": 2394, "Total num trained steps": 6622, "Timestamp in ms": 1699876230519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.09375}
{"Avg objective": 17.8671875, "Games time in secs": 416.6783941667527, "Avg game time in secs": 66.86273314514256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2265625, "Avg reasons for ending game": {"reached_maximum_moves": 0.38, "played_steps": 8.79, "agent_stopped_0": 0.52, "agent_stopped_more": 0.11}, "Total num played games": 2432, "Total num trained steps": 6647, "Timestamp in ms": 1699876241264, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7145187601957588, "Avg loss": 1.3809458618052304, "Avg value loss": 1.0923949088901281, "Avg policy loss": 0.28855094499886036, "Total num played games": 2452, "Total num trained steps": 6656, "Timestamp in ms": 1699876244628, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6888624653190645, "Avg loss": 1.674648185260594, "Avg value loss": 1.3847459573298693, "Avg policy loss": 0.2899022252531722, "Total num played games": 2523, "Total num trained steps": 6784, "Timestamp in ms": 1699876294717, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7159135559921412, "Avg loss": 1.04849266493693, "Avg value loss": 0.7640149402432144, "Avg policy loss": 0.2844777300488204, "Total num played games": 2545, "Total num trained steps": 6912, "Timestamp in ms": 1699876344863, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 118.76155044697225, "Avg game time in secs": 16.107966556810425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.14, "played_steps": 1.69, "reached_maximum_moves": 0.05}, "Total num played games": 2560, "Total num trained steps": 6951, "Timestamp in ms": 1699876360026, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6805026656511806, "Avg loss": 1.4867660598829389, "Avg value loss": 1.2003126561176032, "Avg policy loss": 0.2864534149412066, "Total num played games": 2626, "Total num trained steps": 7040, "Timestamp in ms": 1699876394987, "logtype": "training_step"}
{"Ratio train steps to played games": 2.67163622810287, "Avg loss": 1.0937115489505231, "Avg value loss": 0.82614934630692, "Avg policy loss": 0.2675622053211555, "Total num played games": 2683, "Total num trained steps": 7168, "Timestamp in ms": 1699876443828, "logtype": "training_step"}
{"Avg objective": 19.1484375, "Games time in secs": 90.71583484858274, "Avg game time in secs": 42.92615315243893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3671875, "Avg reasons for ending game": {"reached_maximum_moves": 0.23, "played_steps": 5.41, "agent_stopped_0": 0.7, "agent_stopped_more": 0.08}, "Total num played games": 2688, "Total num trained steps": 7186, "Timestamp in ms": 1699876450742, "logtype": "played_game"}
{"Total num played games": 2744, "Total num trained steps": 7224, "Timestamp in ms": 1699876816140, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8046875}
{"Avg objective": 17.375, "Games time in secs": 381.2822395619005, "Avg game time in secs": 52.360696463263594, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "reached_maximum_moves": 0.3, "played_steps": 6.88, "agent_stopped_more": 0.06}, "Total num played games": 2816, "Total num trained steps": 7262, "Timestamp in ms": 1699876832024, "logtype": "played_game"}
{"Ratio train steps to played games": 2.538622129436326, "Avg loss": 1.4534554942511022, "Avg value loss": 1.186772432178259, "Avg policy loss": 0.26668304798658937, "Total num played games": 2874, "Total num trained steps": 7296, "Timestamp in ms": 1699876846098, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 51.97621415555477, "Avg game time in secs": 7.204700026632054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.29}, "Total num played games": 2944, "Total num trained steps": 7390, "Timestamp in ms": 1699876884001, "logtype": "played_game"}
{"Ratio train steps to played games": 2.514053504910261, "Avg loss": 1.2573260581120849, "Avg value loss": 1.0008961586281657, "Avg policy loss": 0.25642989412881434, "Total num played games": 2953, "Total num trained steps": 7424, "Timestamp in ms": 1699876897062, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5291359678499665, "Avg loss": 0.8556308741681278, "Avg value loss": 0.602944963844493, "Avg policy loss": 0.25268591614440084, "Total num played games": 2986, "Total num trained steps": 7552, "Timestamp in ms": 1699876946672, "logtype": "training_step"}
{"Avg objective": 19.4765625, "Games time in secs": 105.60591157525778, "Avg game time in secs": 30.3171899876761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.375, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.11, "played_steps": 3.87, "reached_maximum_moves": 0.14}, "Total num played games": 3072, "Total num trained steps": 7667, "Timestamp in ms": 1699876989607, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4935064935064934, "Avg loss": 1.3678990695625544, "Avg value loss": 1.1172181852161884, "Avg policy loss": 0.25068088329862803, "Total num played games": 3080, "Total num trained steps": 7680, "Timestamp in ms": 1699876994576, "logtype": "training_step"}
{"Avg objective": 19.9296875, "Games time in secs": 49.711604909971356, "Avg game time in secs": 27.975548764516134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.07, "played_steps": 3.15, "reached_maximum_moves": 0.12}, "Total num played games": 3200, "Total num trained steps": 7796, "Timestamp in ms": 1699877039319, "logtype": "played_game"}
{"Ratio train steps to played games": 2.432398753894081, "Avg loss": 1.325576804112643, "Avg value loss": 1.077569406479597, "Avg policy loss": 0.24800739088095725, "Total num played games": 3210, "Total num trained steps": 7808, "Timestamp in ms": 1699877043789, "logtype": "training_step"}
{"Total num played games": 3270, "Total num trained steps": 7825, "Timestamp in ms": 1699877364304, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.6953125}
{"Avg objective": 17.84375, "Games time in secs": 336.3584689553827, "Avg game time in secs": 48.5926946579857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "reached_maximum_moves": 0.28, "played_steps": 6.41, "agent_stopped_more": 0.05}, "Total num played games": 3328, "Total num trained steps": 7852, "Timestamp in ms": 1699877375683, "logtype": "played_game"}
{"Avg objective": 21.4375, "Games time in secs": 31.29112910106778, "Avg game time in secs": 5.395309102808824, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.02}, "Total num played games": 3456, "Total num trained steps": 7933, "Timestamp in ms": 1699877406974, "logtype": "played_game"}
{"Ratio train steps to played games": 2.292978907830107, "Avg loss": 1.7093800487928092, "Avg value loss": 1.4772011525928974, "Avg policy loss": 0.23217890411615372, "Total num played games": 3460, "Total num trained steps": 7936, "Timestamp in ms": 1699877408049, "logtype": "training_step"}
{"Ratio train steps to played games": 2.260723296888141, "Avg loss": 1.3023737110197544, "Avg value loss": 1.0786292171105742, "Avg policy loss": 0.2237445026403293, "Total num played games": 3567, "Total num trained steps": 8064, "Timestamp in ms": 1699877456394, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 61.81825768388808, "Avg game time in secs": 8.557570819699322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.52}, "Total num played games": 3584, "Total num trained steps": 8098, "Timestamp in ms": 1699877468792, "logtype": "played_game"}
{"Ratio train steps to played games": 2.24718792866941, "Avg loss": 1.1460843705572188, "Avg value loss": 0.9303846778348088, "Avg policy loss": 0.21569967980030924, "Total num played games": 3645, "Total num trained steps": 8192, "Timestamp in ms": 1699877503713, "logtype": "training_step"}
{"Avg objective": 19.703125, "Games time in secs": 61.068178897723556, "Avg game time in secs": 16.92341299908003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.05, "played_steps": 1.85, "agent_stopped_0": 0.87, "reached_maximum_moves": 0.08}, "Total num played games": 3712, "Total num trained steps": 8264, "Timestamp in ms": 1699877529860, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2142667021559754, "Avg loss": 1.111218688543886, "Avg value loss": 0.9141346039250493, "Avg policy loss": 0.19708408729638904, "Total num played games": 3757, "Total num trained steps": 8320, "Timestamp in ms": 1699877551066, "logtype": "training_step"}
{"Avg objective": 19.515625, "Games time in secs": 48.807777646929026, "Avg game time in secs": 29.361855206501787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "reached_maximum_moves": 0.12, "played_steps": 3.2, "agent_stopped_more": 0.03}, "Total num played games": 3840, "Total num trained steps": 8393, "Timestamp in ms": 1699877578668, "logtype": "played_game"}
{"Total num played games": 3926, "Total num trained steps": 8425, "Timestamp in ms": 1699877919999, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4609375}
{"Avg objective": 19.296875, "Games time in secs": 348.0965279377997, "Avg game time in secs": 40.694375033373944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.12, "played_steps": 5.07, "reached_maximum_moves": 0.19}, "Total num played games": 3968, "Total num trained steps": 8441, "Timestamp in ms": 1699877926765, "logtype": "played_game"}
{"Ratio train steps to played games": 2.1279596977329973, "Avg loss": 1.3829680383205414, "Avg value loss": 1.1976036964915693, "Avg policy loss": 0.18536433996632695, "Total num played games": 3970, "Total num trained steps": 8448, "Timestamp in ms": 1699877929124, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 27.006003899499774, "Avg game time in secs": 5.345856239437126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.02}, "Total num played games": 4096, "Total num trained steps": 8513, "Timestamp in ms": 1699877953771, "logtype": "played_game"}
{"Ratio train steps to played games": 2.060052846504924, "Avg loss": 1.672372560016811, "Avg value loss": 1.4947302667424083, "Avg policy loss": 0.17764228384476155, "Total num played games": 4163, "Total num trained steps": 8576, "Timestamp in ms": 1699877976995, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 50.885393442586064, "Avg game time in secs": 7.178303974767914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.94, "agent_stopped_more": 0.06, "played_steps": 0.3}, "Total num played games": 4224, "Total num trained steps": 8653, "Timestamp in ms": 1699878004657, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0465553726781094, "Avg loss": 1.1650680592283607, "Avg value loss": 0.995679272338748, "Avg policy loss": 0.16938878619112074, "Total num played games": 4253, "Total num trained steps": 8704, "Timestamp in ms": 1699878023010, "logtype": "training_step"}
{"Ratio train steps to played games": 2.0390210113137845, "Avg loss": 0.9366937186568975, "Avg value loss": 0.7754023927263916, "Avg policy loss": 0.161291332449764, "Total num played games": 4331, "Total num trained steps": 8832, "Timestamp in ms": 1699878069368, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 73.80587828345597, "Avg game time in secs": 18.43121979033458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "agent_stopped_more": 0.09, "played_steps": 2.07, "reached_maximum_moves": 0.06}, "Total num played games": 4352, "Total num trained steps": 8855, "Timestamp in ms": 1699878078463, "logtype": "played_game"}
{"Ratio train steps to played games": 2.016201620162016, "Avg loss": 1.0577451661229134, "Avg value loss": 0.9004311370663345, "Avg policy loss": 0.15731401648372412, "Total num played games": 4444, "Total num trained steps": 8960, "Timestamp in ms": 1699878117089, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 51.41198956593871, "Avg game time in secs": 30.388555665384047, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "reached_maximum_moves": 0.16, "played_steps": 3.58, "agent_stopped_more": 0.03}, "Total num played games": 4480, "Total num trained steps": 8994, "Timestamp in ms": 1699878129875, "logtype": "played_game"}
{"Total num played games": 4564, "Total num trained steps": 9026, "Timestamp in ms": 1699878458779, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.08984375}
{"Avg objective": 18.1171875, "Games time in secs": 339.27388491667807, "Avg game time in secs": 47.328837246997864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.07, "played_steps": 5.98, "reached_maximum_moves": 0.23}, "Total num played games": 4608, "Total num trained steps": 9049, "Timestamp in ms": 1699878469149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.934227330779055, "Avg loss": 1.5318399257957935, "Avg value loss": 1.3806462101638317, "Avg policy loss": 0.15119372605113313, "Total num played games": 4698, "Total num trained steps": 9088, "Timestamp in ms": 1699878483547, "logtype": "training_step"}
{"Avg objective": 20.15625, "Games time in secs": 21.504079312086105, "Avg game time in secs": 5.631550593519933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.05, "played_steps": 0.11}, "Total num played games": 4736, "Total num trained steps": 9107, "Timestamp in ms": 1699878490653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8970769864141621, "Avg loss": 1.4383831745944917, "Avg value loss": 1.2796349748969078, "Avg policy loss": 0.15874819736927748, "Total num played games": 4858, "Total num trained steps": 9216, "Timestamp in ms": 1699878529685, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 43.46694778650999, "Avg game time in secs": 5.927100964981946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_0": 0.92, "agent_stopped_more": 0.08, "played_steps": 0.23}, "Total num played games": 4864, "Total num trained steps": 9228, "Timestamp in ms": 1699878534121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9028513238289206, "Avg loss": 0.9418003703467548, "Avg value loss": 0.7753533793147653, "Avg policy loss": 0.1664469859097153, "Total num played games": 4910, "Total num trained steps": 9344, "Timestamp in ms": 1699878577174, "logtype": "training_step"}
{"Avg objective": 18.84375, "Games time in secs": 84.60097607783973, "Avg game time in secs": 20.87734574613569, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.12, "played_steps": 2.73, "reached_maximum_moves": 0.1}, "Total num played games": 4992, "Total num trained steps": 9455, "Timestamp in ms": 1699878618722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8959167333867093, "Avg loss": 1.0139565290883183, "Avg value loss": 0.8465757353696972, "Avg policy loss": 0.16738078300841153, "Total num played games": 4996, "Total num trained steps": 9472, "Timestamp in ms": 1699878626218, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8977856860419138, "Avg loss": 0.8992474172264338, "Avg value loss": 0.7273348225280643, "Avg policy loss": 0.1719125939416699, "Total num played games": 5058, "Total num trained steps": 9600, "Timestamp in ms": 1699878682126, "logtype": "training_step"}
{"Total num played games": 5111, "Total num trained steps": 9627, "Timestamp in ms": 1699878810846, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.28515625}
{"Avg objective": 18.1953125, "Games time in secs": 196.81093233823776, "Avg game time in secs": 50.99713512502785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"reached_maximum_moves": 0.24, "played_steps": 7.01, "agent_stopped_more": 0.18, "agent_stopped_0": 0.58}, "Total num played games": 5120, "Total num trained steps": 9632, "Timestamp in ms": 1699878815533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8883711900601825, "Avg loss": 1.2513901726342738, "Avg value loss": 1.0669086766429245, "Avg policy loss": 0.1844814857468009, "Total num played games": 5151, "Total num trained steps": 9728, "Timestamp in ms": 1699878873973, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8981124807395995, "Avg loss": 0.9860182106494904, "Avg value loss": 0.7990680802613497, "Avg policy loss": 0.18695013306569308, "Total num played games": 5192, "Total num trained steps": 9856, "Timestamp in ms": 1699878953324, "logtype": "training_step"}
{"Avg objective": 19.828125, "Games time in secs": 202.16925494000316, "Avg game time in secs": 16.22625761956442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.82, "agent_stopped_more": 0.12, "played_steps": 1.99, "reached_maximum_moves": 0.06}, "Total num played games": 5248, "Total num trained steps": 9960, "Timestamp in ms": 1699879017702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8935887708649468, "Avg loss": 0.9597265059128404, "Avg value loss": 0.7688232348300517, "Avg policy loss": 0.1909032710827887, "Total num played games": 5272, "Total num trained steps": 9984, "Timestamp in ms": 1699879030374, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9009212257943222, "Avg loss": 0.8442937219515443, "Avg value loss": 0.643408955540508, "Avg policy loss": 0.20088476000819355, "Total num played games": 5319, "Total num trained steps": 10112, "Timestamp in ms": 1699879102979, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 151.16661048680544, "Avg game time in secs": 14.492878280507284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.78, "agent_stopped_more": 0.17, "played_steps": 1.82, "reached_maximum_moves": 0.05}, "Total num played games": 5376, "Total num trained steps": 10228, "Timestamp in ms": 1699879168869, "logtype": "played_game"}
{"Total num played games": 5417, "Total num trained steps": 10228, "Timestamp in ms": 1699879362194, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.7734375}
{"Ratio train steps to played games": 1.876993583868011, "Avg loss": 1.0872994284145534, "Avg value loss": 0.8767517281230539, "Avg policy loss": 0.21054770797491074, "Total num played games": 5455, "Total num trained steps": 10240, "Timestamp in ms": 1699879370159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8985533785021058, "Avg loss": 0.9303929731249809, "Avg value loss": 0.7166194249875844, "Avg policy loss": 0.21377354429569095, "Total num played games": 5461, "Total num trained steps": 10368, "Timestamp in ms": 1699879431909, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 293.6928506810218, "Avg game time in secs": 16.78383137070341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.18, "played_steps": 2.16, "reached_maximum_moves": 0.07}, "Total num played games": 5504, "Total num trained steps": 10436, "Timestamp in ms": 1699879462562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9055918663761802, "Avg loss": 0.8074499273207039, "Avg value loss": 0.58872798550874, "Avg policy loss": 0.21872194262687117, "Total num played games": 5508, "Total num trained steps": 10496, "Timestamp in ms": 1699879491508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8993384587877704, "Avg loss": 0.9612647062167525, "Avg value loss": 0.7328051435761154, "Avg policy loss": 0.22845956217497587, "Total num played games": 5593, "Total num trained steps": 10624, "Timestamp in ms": 1699879547499, "logtype": "training_step"}
{"Avg objective": 20.25, "Games time in secs": 117.88207828998566, "Avg game time in secs": 9.567821470089257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.18, "played_steps": 1.08, "reached_maximum_moves": 0.03, "agent_stopped_0": 0.79}, "Total num played games": 5632, "Total num trained steps": 10700, "Timestamp in ms": 1699879580444, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9073975518893027, "Avg loss": 0.9424202535301447, "Avg value loss": 0.6998407514765859, "Avg policy loss": 0.2425795025192201, "Total num played games": 5637, "Total num trained steps": 10752, "Timestamp in ms": 1699879603937, "logtype": "training_step"}
{"Total num played games": 5691, "Total num trained steps": 10832, "Timestamp in ms": 1699879804390, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1796875}
{"Ratio train steps to played games": 1.8982725527831095, "Avg loss": 1.0574337486177683, "Avg value loss": 0.8020174489356577, "Avg policy loss": 0.2554162966553122, "Total num played games": 5731, "Total num trained steps": 10880, "Timestamp in ms": 1699879826961, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 285.9145635012537, "Avg game time in secs": 20.44453705122578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.21, "played_steps": 2.88, "reached_maximum_moves": 0.1, "agent_stopped_0": 0.69}, "Total num played games": 5760, "Total num trained steps": 10963, "Timestamp in ms": 1699879866359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9066343322362722, "Avg loss": 0.9384299872908741, "Avg value loss": 0.6890926633495837, "Avg policy loss": 0.24933733243960887, "Total num played games": 5773, "Total num trained steps": 11008, "Timestamp in ms": 1699879887261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9039151991793468, "Avg loss": 0.9181626788340509, "Avg value loss": 0.6519768147263676, "Avg policy loss": 0.26618586492259055, "Total num played games": 5849, "Total num trained steps": 11136, "Timestamp in ms": 1699879943666, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 112.1649312209338, "Avg game time in secs": 13.005264682491543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.19, "played_steps": 1.66, "reached_maximum_moves": 0.05}, "Total num played games": 5888, "Total num trained steps": 11218, "Timestamp in ms": 1699879978524, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9086595492289442, "Avg loss": 0.9689546646550298, "Avg value loss": 0.6936464542523026, "Avg policy loss": 0.2753082064446062, "Total num played games": 5901, "Total num trained steps": 11264, "Timestamp in ms": 1699879999535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9082077051926298, "Avg loss": 0.862399650271982, "Avg value loss": 0.5758983984123915, "Avg policy loss": 0.28650124836713076, "Total num played games": 5970, "Total num trained steps": 11392, "Timestamp in ms": 1699880053336, "logtype": "training_step"}
{"Total num played games": 5993, "Total num trained steps": 11434, "Timestamp in ms": 1699880200802, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.43359375}
{"Avg objective": 20.4765625, "Games time in secs": 227.58878312632442, "Avg game time in secs": 22.83870606441633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.25, "played_steps": 3.16, "reached_maximum_moves": 0.11}, "Total num played games": 6016, "Total num trained steps": 11446, "Timestamp in ms": 1699880206113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9083830351225977, "Avg loss": 0.9025033167563379, "Avg value loss": 0.6011197394691408, "Avg policy loss": 0.30138358066324145, "Total num played games": 6036, "Total num trained steps": 11520, "Timestamp in ms": 1699880239219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9145299145299146, "Avg loss": 1.0205041039735079, "Avg value loss": 0.7186933709308505, "Avg policy loss": 0.3018107331590727, "Total num played games": 6084, "Total num trained steps": 11648, "Timestamp in ms": 1699880318315, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 179.2136469837278, "Avg game time in secs": 10.157298715392244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.23, "played_steps": 1.19, "reached_maximum_moves": 0.02}, "Total num played games": 6144, "Total num trained steps": 11751, "Timestamp in ms": 1699880385327, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9075004049894704, "Avg loss": 1.0448062075302005, "Avg value loss": 0.7367689036764205, "Avg policy loss": 0.30803730653133243, "Total num played games": 6173, "Total num trained steps": 11776, "Timestamp in ms": 1699880401254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9116749638670307, "Avg loss": 0.8874787129461765, "Avg value loss": 0.5795475847553462, "Avg policy loss": 0.30793112551327795, "Total num played games": 6227, "Total num trained steps": 11904, "Timestamp in ms": 1699880484858, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 135.24591124802828, "Avg game time in secs": 8.13529414110235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.2, "played_steps": 0.94, "reached_maximum_moves": 0.02}, "Total num played games": 6272, "Total num trained steps": 11960, "Timestamp in ms": 1699880520573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9174501992031872, "Avg loss": 0.8028854173608124, "Avg value loss": 0.4897689754143357, "Avg policy loss": 0.3131164447404444, "Total num played games": 6275, "Total num trained steps": 12032, "Timestamp in ms": 1699880566673, "logtype": "training_step"}
{"Total num played games": 6276, "Total num trained steps": 12036, "Timestamp in ms": 1699880730991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.75}
{"Ratio train steps to played games": 1.9104477611940298, "Avg loss": 1.1438000579364598, "Avg value loss": 0.8284404037985951, "Avg policy loss": 0.3153596497140825, "Total num played games": 6365, "Total num trained steps": 12160, "Timestamp in ms": 1699880805362, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 327.74608255177736, "Avg game time in secs": 6.890570281495457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 0.73, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.78}, "Total num played games": 6400, "Total num trained steps": 12233, "Timestamp in ms": 1699880848319, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9171477609611485, "Avg loss": 0.8666028054431081, "Avg value loss": 0.5548786816652864, "Avg policy loss": 0.31172412005253136, "Total num played games": 6409, "Total num trained steps": 12288, "Timestamp in ms": 1699880880550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9130970724191063, "Avg loss": 0.818231008015573, "Avg value loss": 0.500876925420016, "Avg policy loss": 0.3173540880670771, "Total num played games": 6490, "Total num trained steps": 12416, "Timestamp in ms": 1699880949251, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 144.7324438765645, "Avg game time in secs": 9.184039985193522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 1.11, "agent_stopped_0": 0.71, "reached_maximum_moves": 0.02}, "Total num played games": 6528, "Total num trained steps": 12496, "Timestamp in ms": 1699880993052, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9205328433624254, "Avg loss": 0.9887737995013595, "Avg value loss": 0.6676570809213445, "Avg policy loss": 0.321116725448519, "Total num played games": 6531, "Total num trained steps": 12544, "Timestamp in ms": 1699881016888, "logtype": "training_step"}
{"Total num played games": 6582, "Total num trained steps": 12637, "Timestamp in ms": 1699881231028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6328125}
{"Ratio train steps to played games": 1.9120265580202203, "Avg loss": 1.0703469272702932, "Avg value loss": 0.7519139007199556, "Avg policy loss": 0.3184330244548619, "Total num played games": 6627, "Total num trained steps": 12672, "Timestamp in ms": 1699881254583, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 307.90954376012087, "Avg game time in secs": 19.721952909691026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"reached_maximum_moves": 0.09, "played_steps": 2.59, "agent_stopped_more": 0.17, "agent_stopped_0": 0.74}, "Total num played games": 6656, "Total num trained steps": 12749, "Timestamp in ms": 1699881300962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9201920192019202, "Avg loss": 0.9475878742523491, "Avg value loss": 0.6330640437081456, "Avg policy loss": 0.31452383229043335, "Total num played games": 6666, "Total num trained steps": 12800, "Timestamp in ms": 1699881331070, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9162466646901868, "Avg loss": 0.9447606075555086, "Avg value loss": 0.614326199516654, "Avg policy loss": 0.3304344017524272, "Total num played games": 6746, "Total num trained steps": 12928, "Timestamp in ms": 1699881407633, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 153.71750246733427, "Avg game time in secs": 11.732831178538618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.3, "played_steps": 1.65, "reached_maximum_moves": 0.05}, "Total num played games": 6784, "Total num trained steps": 13007, "Timestamp in ms": 1699881454679, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9214128035320088, "Avg loss": 1.0459872288629413, "Avg value loss": 0.714110582601279, "Avg policy loss": 0.33187663927674294, "Total num played games": 6795, "Total num trained steps": 13056, "Timestamp in ms": 1699881482881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9161337209302325, "Avg loss": 0.8915736526250839, "Avg value loss": 0.5592869534157217, "Avg policy loss": 0.3322867010720074, "Total num played games": 6880, "Total num trained steps": 13184, "Timestamp in ms": 1699881557064, "logtype": "training_step"}
{"Total num played games": 6891, "Total num trained steps": 13237, "Timestamp in ms": 1699881684583, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.8828125}
{"Avg objective": 19.6953125, "Games time in secs": 234.3246635850519, "Avg game time in secs": 18.02560631102824, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 2.6, "agent_stopped_0": 0.62, "reached_maximum_moves": 0.09}, "Total num played games": 6912, "Total num trained steps": 13245, "Timestamp in ms": 1699881689004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9184320507277706, "Avg loss": 0.9716360843740404, "Avg value loss": 0.6306667553726584, "Avg policy loss": 0.340969325741753, "Total num played games": 6939, "Total num trained steps": 13312, "Timestamp in ms": 1699881732289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9248066456602693, "Avg loss": 0.8714552740566432, "Avg value loss": 0.5336020715767518, "Avg policy loss": 0.3378531960770488, "Total num played games": 6982, "Total num trained steps": 13440, "Timestamp in ms": 1699881810860, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 184.5969036128372, "Avg game time in secs": 6.649987998054712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.33, "played_steps": 0.84, "reached_maximum_moves": 0.01}, "Total num played games": 7040, "Total num trained steps": 13547, "Timestamp in ms": 1699881873601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.918953323903819, "Avg loss": 0.9423671504482627, "Avg value loss": 0.6008050458040088, "Avg policy loss": 0.3415621042950079, "Total num played games": 7070, "Total num trained steps": 13568, "Timestamp in ms": 1699881886829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.923865711476331, "Avg loss": 0.9557567373849452, "Avg value loss": 0.608574933372438, "Avg policy loss": 0.34718180960044265, "Total num played games": 7119, "Total num trained steps": 13696, "Timestamp in ms": 1699881965208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9288405190456257, "Avg loss": 0.8471145662479103, "Avg value loss": 0.4989836858585477, "Avg policy loss": 0.3481308778282255, "Total num played games": 7167, "Total num trained steps": 13824, "Timestamp in ms": 1699882028104, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 154.52380371280015, "Avg game time in secs": 11.544392027368303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "reached_maximum_moves": 0.05, "played_steps": 1.54, "agent_stopped_more": 0.31}, "Total num played games": 7168, "Total num trained steps": 13824, "Timestamp in ms": 1699882028125, "logtype": "played_game"}
{"Total num played games": 7216, "Total num trained steps": 13836, "Timestamp in ms": 1699882148570, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.29296875}
{"Ratio train steps to played games": 1.9220278275244524, "Avg loss": 0.9689949825406075, "Avg value loss": 0.6067400517640635, "Avg policy loss": 0.3622549279825762, "Total num played games": 7259, "Total num trained steps": 13952, "Timestamp in ms": 1699882203539, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 210.68783364631236, "Avg game time in secs": 14.38634599733632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.32, "played_steps": 2.09, "reached_maximum_moves": 0.06}, "Total num played games": 7296, "Total num trained steps": 14030, "Timestamp in ms": 1699882238813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9275739320920044, "Avg loss": 0.7294722101651132, "Avg value loss": 0.38522890862077475, "Avg policy loss": 0.3442433027084917, "Total num played games": 7304, "Total num trained steps": 14080, "Timestamp in ms": 1699882261504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9224627875507443, "Avg loss": 0.9288246347568929, "Avg value loss": 0.5750562311150134, "Avg policy loss": 0.3537684038747102, "Total num played games": 7390, "Total num trained steps": 14208, "Timestamp in ms": 1699882318329, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 114.60871803574264, "Avg game time in secs": 11.099833410655265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.24, "played_steps": 1.59, "reached_maximum_moves": 0.05, "agent_stopped_0": 0.7}, "Total num played games": 7424, "Total num trained steps": 14286, "Timestamp in ms": 1699882353422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.927659002285868, "Avg loss": 0.8132070964202285, "Avg value loss": 0.4610379902878776, "Avg policy loss": 0.3521691062487662, "Total num played games": 7437, "Total num trained steps": 14336, "Timestamp in ms": 1699882375712, "logtype": "training_step"}
{"Total num played games": 7487, "Total num trained steps": 14437, "Timestamp in ms": 1699882469407, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.0625}
{"Ratio train steps to played games": 1.919830103530661, "Avg loss": 0.8707160451449454, "Avg value loss": 0.5219590123742819, "Avg policy loss": 0.34875703300349414, "Total num played games": 7534, "Total num trained steps": 14464, "Timestamp in ms": 1699882482011, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 175.70598592795432, "Avg game time in secs": 10.10535981330031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.34, "played_steps": 1.42, "reached_maximum_moves": 0.03}, "Total num played games": 7552, "Total num trained steps": 14563, "Timestamp in ms": 1699882529128, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9241724910985099, "Avg loss": 0.8446801616810262, "Avg value loss": 0.49244215327780694, "Avg policy loss": 0.3522380057256669, "Total num played games": 7583, "Total num trained steps": 14592, "Timestamp in ms": 1699882541219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9279633267845449, "Avg loss": 0.800668265670538, "Avg value loss": 0.4578058092156425, "Avg policy loss": 0.3428624557564035, "Total num played games": 7635, "Total num trained steps": 14720, "Timestamp in ms": 1699882601134, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 98.17496754601598, "Avg game time in secs": 6.330149819972576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.32, "played_steps": 0.77, "reached_maximum_moves": 0.01}, "Total num played games": 7680, "Total num trained steps": 14777, "Timestamp in ms": 1699882627303, "logtype": "played_game"}
{"Ratio train steps to played games": 1.931572785221803, "Avg loss": 0.9300592439249158, "Avg value loss": 0.5832454671617597, "Avg policy loss": 0.34681377094238997, "Total num played games": 7687, "Total num trained steps": 14848, "Timestamp in ms": 1699882661485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9292708064931718, "Avg loss": 0.7094422823283821, "Avg value loss": 0.37509934918489307, "Avg policy loss": 0.3343429327942431, "Total num played games": 7762, "Total num trained steps": 14976, "Timestamp in ms": 1699882718622, "logtype": "training_step"}
{"Total num played games": 7790, "Total num trained steps": 15040, "Timestamp in ms": 1699882842408, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.421875}
{"Avg objective": 21.8671875, "Games time in secs": 219.37343250401318, "Avg game time in secs": 6.1159273061930435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.81, "agent_stopped_0": 0.64, "reached_maximum_moves": 0.01}, "Total num played games": 7808, "Total num trained steps": 15049, "Timestamp in ms": 1699882846677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9277600510529675, "Avg loss": 1.0761429169215262, "Avg value loss": 0.7166626886464655, "Avg policy loss": 0.35948022501543164, "Total num played games": 7835, "Total num trained steps": 15104, "Timestamp in ms": 1699882871531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.932377569144887, "Avg loss": 0.7629915634170175, "Avg value loss": 0.40753290755674243, "Avg policy loss": 0.3554586546961218, "Total num played games": 7882, "Total num trained steps": 15232, "Timestamp in ms": 1699882929401, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 134.50091323815286, "Avg game time in secs": 6.4737848207878415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.91, "reached_maximum_moves": 0.01}, "Total num played games": 7936, "Total num trained steps": 15348, "Timestamp in ms": 1699882981178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9295226130653267, "Avg loss": 0.7690599702764302, "Avg value loss": 0.41184761724434793, "Avg policy loss": 0.3572123572230339, "Total num played games": 7960, "Total num trained steps": 15360, "Timestamp in ms": 1699882985685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.932252027448534, "Avg loss": 0.8395488695241511, "Avg value loss": 0.48151960386894643, "Avg policy loss": 0.3580292572733015, "Total num played games": 8015, "Total num trained steps": 15488, "Timestamp in ms": 1699883042565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9365079365079365, "Avg loss": 0.7328055053949356, "Avg value loss": 0.37685593019705266, "Avg policy loss": 0.35594957042485476, "Total num played games": 8063, "Total num trained steps": 15616, "Timestamp in ms": 1699883099049, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 117.87176423706114, "Avg game time in secs": 13.343448309999076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.38, "played_steps": 1.96, "reached_maximum_moves": 0.05}, "Total num played games": 8064, "Total num trained steps": 15616, "Timestamp in ms": 1699883099050, "logtype": "played_game"}
{"Total num played games": 8114, "Total num trained steps": 15643, "Timestamp in ms": 1699883234135, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.36328125}
{"Ratio train steps to played games": 1.9289389855427592, "Avg loss": 1.2558742291294038, "Avg value loss": 0.8939318084158003, "Avg policy loss": 0.3619424272328615, "Total num played games": 8162, "Total num trained steps": 15744, "Timestamp in ms": 1699883281533, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 221.15399878285825, "Avg game time in secs": 11.581771979821497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.4, "played_steps": 1.7, "reached_maximum_moves": 0.04}, "Total num played games": 8192, "Total num trained steps": 15827, "Timestamp in ms": 1699883320204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.932659522649781, "Avg loss": 0.8103428385220468, "Avg value loss": 0.44066214840859175, "Avg policy loss": 0.3696806882508099, "Total num played games": 8212, "Total num trained steps": 15872, "Timestamp in ms": 1699883340437, "logtype": "training_step"}
{"Ratio train steps to played games": 1.936811524028568, "Avg loss": 0.7603776736650616, "Avg value loss": 0.3889025847893208, "Avg policy loss": 0.37147508445195854, "Total num played games": 8261, "Total num trained steps": 16000, "Timestamp in ms": 1699883399572, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 127.74612797237933, "Avg game time in secs": 5.930278678846662, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.81, "agent_stopped_0": 0.58}, "Total num played games": 8320, "Total num trained steps": 16109, "Timestamp in ms": 1699883447950, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9320714028992452, "Avg loss": 0.8049832191318274, "Avg value loss": 0.4424215166363865, "Avg policy loss": 0.3625616969075054, "Total num played games": 8347, "Total num trained steps": 16128, "Timestamp in ms": 1699883455505, "logtype": "training_step"}
{"Total num played games": 8404, "Total num trained steps": 16244, "Timestamp in ms": 1699883602375, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.55078125}
{"Ratio train steps to played games": 1.9283511269276394, "Avg loss": 0.8650493859313428, "Avg value loss": 0.490833860472776, "Avg policy loss": 0.37421552487649024, "Total num played games": 8429, "Total num trained steps": 16256, "Timestamp in ms": 1699883607536, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 173.20954412966967, "Avg game time in secs": 12.141332036568201, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.45, "played_steps": 1.83, "reached_maximum_moves": 0.04}, "Total num played games": 8448, "Total num trained steps": 16287, "Timestamp in ms": 1699883621160, "logtype": "played_game"}
{"Ratio train steps to played games": 1.939046040951592, "Avg loss": 0.9602956334128976, "Avg value loss": 0.5825812596594915, "Avg policy loss": 0.3777143689803779, "Total num played games": 8449, "Total num trained steps": 16384, "Timestamp in ms": 1699883665528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9331460016391524, "Avg loss": 0.9440595633350313, "Avg value loss": 0.5761867712717503, "Avg policy loss": 0.3678727855440229, "Total num played games": 8541, "Total num trained steps": 16512, "Timestamp in ms": 1699883720024, "logtype": "training_step"}
{"Avg objective": 19.9609375, "Games time in secs": 132.84536356292665, "Avg game time in secs": 7.830565442010993, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 1.09, "agent_stopped_0": 0.59, "reached_maximum_moves": 0.02}, "Total num played games": 8576, "Total num trained steps": 16589, "Timestamp in ms": 1699883754010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9370197904540163, "Avg loss": 0.8208072921261191, "Avg value loss": 0.44720442418474704, "Avg policy loss": 0.37360286712646484, "Total num played games": 8590, "Total num trained steps": 16640, "Timestamp in ms": 1699883776841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9396182764603818, "Avg loss": 0.8870043409988284, "Avg value loss": 0.5100970447529107, "Avg policy loss": 0.3769072969444096, "Total num played games": 8645, "Total num trained steps": 16768, "Timestamp in ms": 1699883834004, "logtype": "training_step"}
{"Total num played games": 8687, "Total num trained steps": 16845, "Timestamp in ms": 1699883962189, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.5703125}
{"Avg objective": 20.3046875, "Games time in secs": 212.45617114193738, "Avg game time in secs": 14.988894258087385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 2.41, "reached_maximum_moves": 0.05, "agent_stopped_0": 0.42}, "Total num played games": 8704, "Total num trained steps": 16854, "Timestamp in ms": 1699883966466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9341728677733256, "Avg loss": 0.8742063352838159, "Avg value loss": 0.49784299614839256, "Avg policy loss": 0.37636334355920553, "Total num played games": 8735, "Total num trained steps": 16896, "Timestamp in ms": 1699883985205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9376280446164353, "Avg loss": 0.7998601314611733, "Avg value loss": 0.42208685423247516, "Avg policy loss": 0.3777732802554965, "Total num played games": 8786, "Total num trained steps": 17024, "Timestamp in ms": 1699884043259, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 102.7747076433152, "Avg game time in secs": 5.314108941369341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.76}, "Total num played games": 8832, "Total num trained steps": 17084, "Timestamp in ms": 1699884069241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9411498415572657, "Avg loss": 0.8539092466235161, "Avg value loss": 0.46826482051983476, "Avg policy loss": 0.3856444265693426, "Total num played games": 8836, "Total num trained steps": 17152, "Timestamp in ms": 1699884100810, "logtype": "training_step"}
{"Ratio train steps to played games": 1.937002578186302, "Avg loss": 0.8274078937247396, "Avg value loss": 0.44793971348553896, "Avg policy loss": 0.3794681855943054, "Total num played games": 8921, "Total num trained steps": 17280, "Timestamp in ms": 1699884155828, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 124.64085769280791, "Avg game time in secs": 6.351942358887754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.84, "agent_stopped_0": 0.62, "reached_maximum_moves": 0.01}, "Total num played games": 8960, "Total num trained steps": 17368, "Timestamp in ms": 1699884193882, "logtype": "played_game"}
{"Ratio train steps to played games": 1.938098419060343, "Avg loss": 0.9236105140298605, "Avg value loss": 0.538669430068694, "Avg policy loss": 0.38494107546284795, "Total num played games": 8982, "Total num trained steps": 17408, "Timestamp in ms": 1699884211921, "logtype": "training_step"}
{"Total num played games": 8985, "Total num trained steps": 17448, "Timestamp in ms": 1699884339842, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.31640625}
{"Ratio train steps to played games": 1.9413262482010407, "Avg loss": 0.8131521758623421, "Avg value loss": 0.4344081486342475, "Avg policy loss": 0.3787440243177116, "Total num played games": 9033, "Total num trained steps": 17536, "Timestamp in ms": 1699884380686, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 241.09169607795775, "Avg game time in secs": 6.834486155450577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.45, "played_steps": 1.07, "reached_maximum_moves": 0.02}, "Total num played games": 9088, "Total num trained steps": 17659, "Timestamp in ms": 1699884434974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9393939393939394, "Avg loss": 0.8569661490619183, "Avg value loss": 0.4754956419346854, "Avg policy loss": 0.3814705016557127, "Total num played games": 9107, "Total num trained steps": 17664, "Timestamp in ms": 1699884437132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9378063391787388, "Avg loss": 0.9421135634183884, "Avg value loss": 0.5494923788355663, "Avg policy loss": 0.3926211812067777, "Total num played games": 9181, "Total num trained steps": 17792, "Timestamp in ms": 1699884492905, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 91.30102356895804, "Avg game time in secs": 4.731217642940464, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.57}, "Total num played games": 9216, "Total num trained steps": 17869, "Timestamp in ms": 1699884526275, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9410745233968805, "Avg loss": 0.7561421608552337, "Avg value loss": 0.3704433795064688, "Avg policy loss": 0.385698776692152, "Total num played games": 9232, "Total num trained steps": 17920, "Timestamp in ms": 1699884549325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9444085326438267, "Avg loss": 0.744395611807704, "Avg value loss": 0.3575838935794309, "Avg policy loss": 0.3868117167148739, "Total num played games": 9282, "Total num trained steps": 18048, "Timestamp in ms": 1699884610427, "logtype": "training_step"}
{"Total num played games": 9283, "Total num trained steps": 18050, "Timestamp in ms": 1699884705856, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.16015625}
{"Avg objective": 21.8515625, "Games time in secs": 231.8262733425945, "Avg game time in secs": 7.3975991058541695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 1.19, "agent_stopped_0": 0.45}, "Total num played games": 9344, "Total num trained steps": 18155, "Timestamp in ms": 1699884758101, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9386666666666668, "Avg loss": 0.8359303479082882, "Avg value loss": 0.44662784319370985, "Avg policy loss": 0.38930250285193324, "Total num played games": 9375, "Total num trained steps": 18176, "Timestamp in ms": 1699884767055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9419628647214855, "Avg loss": 0.8329579923301935, "Avg value loss": 0.45061410311609507, "Avg policy loss": 0.38234388129785657, "Total num played games": 9425, "Total num trained steps": 18304, "Timestamp in ms": 1699884822712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9461514095660437, "Avg loss": 0.7353033511899412, "Avg value loss": 0.3510581264272332, "Avg policy loss": 0.38424521847628057, "Total num played games": 9471, "Total num trained steps": 18432, "Timestamp in ms": 1699884877375, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 119.4646139703691, "Avg game time in secs": 6.741123693194822, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 1.09, "reached_maximum_moves": 0.01}, "Total num played games": 9472, "Total num trained steps": 18432, "Timestamp in ms": 1699884877566, "logtype": "played_game"}
{"Ratio train steps to played games": 1.940813552232563, "Avg loss": 0.9554336504079401, "Avg value loss": 0.5827787858434021, "Avg policy loss": 0.3726548620034009, "Total num played games": 9563, "Total num trained steps": 18560, "Timestamp in ms": 1699884931948, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 88.24670476838946, "Avg game time in secs": 8.687020430050325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.39, "played_steps": 1.25, "reached_maximum_moves": 0.02}, "Total num played games": 9600, "Total num trained steps": 18637, "Timestamp in ms": 1699884965813, "logtype": "played_game"}
{"Total num played games": 9618, "Total num trained steps": 18652, "Timestamp in ms": 1699885068968, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.45703125}
{"Ratio train steps to played games": 1.9341751190229766, "Avg loss": 1.0379396239295602, "Avg value loss": 0.6589683475904167, "Avg policy loss": 0.3789712751749903, "Total num played games": 9662, "Total num trained steps": 18688, "Timestamp in ms": 1699885083571, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9467149508535955, "Avg loss": 0.7508731791749597, "Avg value loss": 0.3802345503354445, "Avg policy loss": 0.3706386350095272, "Total num played games": 9665, "Total num trained steps": 18816, "Timestamp in ms": 1699885141365, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 219.62810247205198, "Avg game time in secs": 8.671780094126007, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.35, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.52}, "Total num played games": 9728, "Total num trained steps": 18921, "Timestamp in ms": 1699885185442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9422741720496257, "Avg loss": 0.8501795257907361, "Avg value loss": 0.4879672088427469, "Avg policy loss": 0.3622123161330819, "Total num played games": 9753, "Total num trained steps": 18944, "Timestamp in ms": 1699885194303, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9444331158238173, "Avg loss": 0.7523954741191119, "Avg value loss": 0.39907422778196633, "Avg policy loss": 0.3533212475012988, "Total num played games": 9808, "Total num trained steps": 19072, "Timestamp in ms": 1699885248843, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 113.69969948753715, "Avg game time in secs": 8.735498349837144, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.46, "played_steps": 1.27, "reached_maximum_moves": 0.02}, "Total num played games": 9856, "Total num trained steps": 19189, "Timestamp in ms": 1699885299141, "logtype": "played_game"}
{"Ratio train steps to played games": 1.947752865983565, "Avg loss": 0.7364131875801831, "Avg value loss": 0.3863713414175436, "Avg policy loss": 0.35004184930585325, "Total num played games": 9857, "Total num trained steps": 19200, "Timestamp in ms": 1699885303829, "logtype": "training_step"}
{"Total num played games": 9907, "Total num trained steps": 19255, "Timestamp in ms": 1699885421646, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.26171875}
{"Ratio train steps to played games": 1.9414364640883979, "Avg loss": 1.1535405102185905, "Avg value loss": 0.7910210280679166, "Avg policy loss": 0.3625194823835045, "Total num played games": 9955, "Total num trained steps": 19328, "Timestamp in ms": 1699885454540, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 190.10072483867407, "Avg game time in secs": 7.728283658783766, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 1.16, "agent_stopped_0": 0.61, "reached_maximum_moves": 0.02}, "Total num played games": 9984, "Total num trained steps": 19407, "Timestamp in ms": 1699885489242, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9448220711715314, "Avg loss": 0.8613438301254064, "Avg value loss": 0.5094867160078138, "Avg policy loss": 0.35185712412931025, "Total num played games": 10004, "Total num trained steps": 19456, "Timestamp in ms": 1699885510308, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9475882645450024, "Avg loss": 0.8823748771101236, "Avg value loss": 0.5323516310891137, "Avg policy loss": 0.35002324846573174, "Total num played games": 10055, "Total num trained steps": 19584, "Timestamp in ms": 1699885565761, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 130.51464774645865, "Avg game time in secs": 4.666940235547372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.68}, "Total num played games": 10112, "Total num trained steps": 19707, "Timestamp in ms": 1699885619757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9451351884744426, "Avg loss": 0.7486627080943435, "Avg value loss": 0.40096628840547055, "Avg policy loss": 0.3476964223664254, "Total num played games": 10133, "Total num trained steps": 19712, "Timestamp in ms": 1699885621179, "logtype": "training_step"}
{"Ratio train steps to played games": 1.943764083472127, "Avg loss": 0.9264346342533827, "Avg value loss": 0.5856059156358242, "Avg policy loss": 0.3408287102356553, "Total num played games": 10207, "Total num trained steps": 19840, "Timestamp in ms": 1699885675362, "logtype": "training_step"}
{"Total num played games": 10208, "Total num trained steps": 19859, "Timestamp in ms": 1699885862769, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.83984375}
{"Avg objective": 21.078125, "Games time in secs": 249.88398012891412, "Avg game time in secs": 5.1376455434947275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.79}, "Total num played games": 10240, "Total num trained steps": 19873, "Timestamp in ms": 1699885869641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9470502194051682, "Avg loss": 0.8436635159887373, "Avg value loss": 0.48469094024039805, "Avg policy loss": 0.3589725799392909, "Total num played games": 10255, "Total num trained steps": 19968, "Timestamp in ms": 1699885909904, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9504998544113366, "Avg loss": 0.6811114985030144, "Avg value loss": 0.33551912219263613, "Avg policy loss": 0.3455923767760396, "Total num played games": 10303, "Total num trained steps": 20096, "Timestamp in ms": 1699885964358, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 137.7041158657521, "Avg game time in secs": 6.282736695051426, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.89, "agent_stopped_0": 0.6}, "Total num played games": 10368, "Total num trained steps": 20199, "Timestamp in ms": 1699886007345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9458289233137689, "Avg loss": 0.8303016773425043, "Avg value loss": 0.4810439820867032, "Avg policy loss": 0.34925769502297044, "Total num played games": 10393, "Total num trained steps": 20224, "Timestamp in ms": 1699886017393, "logtype": "training_step"}
{"Ratio train steps to played games": 1.947650492870131, "Avg loss": 0.708772286074236, "Avg value loss": 0.36504511057864875, "Avg policy loss": 0.34372718213126063, "Total num played games": 10449, "Total num trained steps": 20352, "Timestamp in ms": 1699886072297, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 93.00935117155313, "Avg game time in secs": 7.266905577736907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 1.06, "reached_maximum_moves": 0.01}, "Total num played games": 10496, "Total num trained steps": 20411, "Timestamp in ms": 1699886100355, "logtype": "played_game"}
{"Total num played games": 10500, "Total num trained steps": 20461, "Timestamp in ms": 1699886222425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.46484375}
{"Ratio train steps to played games": 1.943532314700579, "Avg loss": 1.35619026562199, "Avg value loss": 1.0131063929293305, "Avg policy loss": 0.3430838726926595, "Total num played games": 10537, "Total num trained steps": 20480, "Timestamp in ms": 1699886230087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9453412630982725, "Avg loss": 0.9819561610929668, "Avg value loss": 0.6191343932878226, "Avg policy loss": 0.3628217636141926, "Total num played games": 10593, "Total num trained steps": 20608, "Timestamp in ms": 1699886284681, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 219.36893144063652, "Avg game time in secs": 5.539692862017546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.8, "agent_stopped_0": 0.59}, "Total num played games": 10624, "Total num trained steps": 20690, "Timestamp in ms": 1699886319724, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9480458474257798, "Avg loss": 0.8143776622600853, "Avg value loss": 0.4618289233185351, "Avg policy loss": 0.35254874802194536, "Total num played games": 10644, "Total num trained steps": 20736, "Timestamp in ms": 1699886339446, "logtype": "training_step"}
{"Ratio train steps to played games": 1.950818139317438, "Avg loss": 0.8424542010761797, "Avg value loss": 0.4839256072882563, "Avg policy loss": 0.3585285961162299, "Total num played games": 10695, "Total num trained steps": 20864, "Timestamp in ms": 1699886397165, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 129.64160323143005, "Avg game time in secs": 7.708036169540719, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 1.37}, "Total num played games": 10752, "Total num trained steps": 20990, "Timestamp in ms": 1699886449366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9518363551836355, "Avg loss": 0.7995756769087166, "Avg value loss": 0.4358800270128995, "Avg policy loss": 0.36369564780034125, "Total num played games": 10754, "Total num trained steps": 20992, "Timestamp in ms": 1699886449733, "logtype": "training_step"}
{"Total num played games": 10799, "Total num trained steps": 21064, "Timestamp in ms": 1699886574019, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.20703125}
{"Ratio train steps to played games": 1.9471694633966439, "Avg loss": 0.896293512545526, "Avg value loss": 0.5388889110181481, "Avg policy loss": 0.35740459407679737, "Total num played games": 10846, "Total num trained steps": 21120, "Timestamp in ms": 1699886597533, "logtype": "training_step"}
{"Avg objective": 20.46875, "Games time in secs": 179.61372471787035, "Avg game time in secs": 5.215050563696423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.75}, "Total num played games": 10880, "Total num trained steps": 21196, "Timestamp in ms": 1699886628980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9502524093620928, "Avg loss": 0.8025399781763554, "Avg value loss": 0.4431543837999925, "Avg policy loss": 0.35938559868372977, "Total num played games": 10895, "Total num trained steps": 21248, "Timestamp in ms": 1699886651151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9529465509365007, "Avg loss": 0.8325199980754405, "Avg value loss": 0.47756299027241766, "Avg policy loss": 0.3549570080358535, "Total num played games": 10945, "Total num trained steps": 21376, "Timestamp in ms": 1699886707548, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 121.80932637304068, "Avg game time in secs": 5.632603669728269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.95, "agent_stopped_0": 0.48}, "Total num played games": 11008, "Total num trained steps": 21481, "Timestamp in ms": 1699886750790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.948794634765271, "Avg loss": 0.795550666982308, "Avg value loss": 0.44112449418753386, "Avg policy loss": 0.3544261757051572, "Total num played games": 11034, "Total num trained steps": 21504, "Timestamp in ms": 1699886759369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.951023721475602, "Avg loss": 0.7296552937477827, "Avg value loss": 0.38132603745907545, "Avg policy loss": 0.3483292575692758, "Total num played games": 11087, "Total num trained steps": 21632, "Timestamp in ms": 1699886813374, "logtype": "training_step"}
{"Avg objective": 19.328125, "Games time in secs": 118.96465042419732, "Avg game time in secs": 8.063956939673517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 1.34, "reached_maximum_moves": 0.01}, "Total num played games": 11136, "Total num trained steps": 21666, "Timestamp in ms": 1699886869755, "logtype": "played_game"}
{"Total num played games": 11136, "Total num trained steps": 21666, "Timestamp in ms": 1699886928930, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.7578125}
{"Ratio train steps to played games": 1.945721183939909, "Avg loss": 0.8655359125696123, "Avg value loss": 0.5129169307183474, "Avg policy loss": 0.35261898185126483, "Total num played games": 11183, "Total num trained steps": 21760, "Timestamp in ms": 1699886969165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9488914611343602, "Avg loss": 0.7167652396019548, "Avg value loss": 0.3688531807856634, "Avg policy loss": 0.34791205229703337, "Total num played games": 11231, "Total num trained steps": 21888, "Timestamp in ms": 1699887026611, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 188.5750100016594, "Avg game time in secs": 4.659239686632645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.69}, "Total num played games": 11264, "Total num trained steps": 21963, "Timestamp in ms": 1699887058331, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9511654701763714, "Avg loss": 0.7771834705490619, "Avg value loss": 0.4367545014247298, "Avg policy loss": 0.3404289659811184, "Total num played games": 11283, "Total num trained steps": 22016, "Timestamp in ms": 1699887080852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.953767425445562, "Avg loss": 0.7094923038966954, "Avg value loss": 0.35434699535835534, "Avg policy loss": 0.35514531400986016, "Total num played games": 11334, "Total num trained steps": 22144, "Timestamp in ms": 1699887134323, "logtype": "training_step"}
{"Avg objective": 19.890625, "Games time in secs": 123.84260928072035, "Avg game time in secs": 5.777869362180354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.95}, "Total num played games": 11392, "Total num trained steps": 22260, "Timestamp in ms": 1699887182174, "logtype": "played_game"}
{"Total num played games": 11433, "Total num trained steps": 22267, "Timestamp in ms": 1699887295591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.1640625}
{"Ratio train steps to played games": 1.9476169654569304, "Avg loss": 0.713644667994231, "Avg value loss": 0.36810697440523654, "Avg policy loss": 0.34553770115599036, "Total num played games": 11435, "Total num trained steps": 22272, "Timestamp in ms": 1699887297995, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9510495601428448, "Avg loss": 0.8066642307676375, "Avg value loss": 0.4555719868512824, "Avg policy loss": 0.351092248223722, "Total num played games": 11481, "Total num trained steps": 22400, "Timestamp in ms": 1699887352537, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 198.31596507132053, "Avg game time in secs": 5.43387413873279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.45, "played_steps": 0.91, "reached_maximum_moves": 0.02}, "Total num played games": 11520, "Total num trained steps": 22466, "Timestamp in ms": 1699887380490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9537727666955766, "Avg loss": 0.6839756320696324, "Avg value loss": 0.3390335537260398, "Avg policy loss": 0.34494207869283855, "Total num played games": 11530, "Total num trained steps": 22528, "Timestamp in ms": 1699887405715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9536086919030784, "Avg loss": 0.8671520731877536, "Avg value loss": 0.5128797098295763, "Avg policy loss": 0.35427236277610064, "Total num played games": 11597, "Total num trained steps": 22656, "Timestamp in ms": 1699887457758, "logtype": "training_step"}
{"Avg objective": 23.2421875, "Games time in secs": 117.07531612738967, "Avg game time in secs": 5.2574268894823035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.91, "agent_stopped_0": 0.52}, "Total num played games": 11648, "Total num trained steps": 22754, "Timestamp in ms": 1699887497565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9516018502655474, "Avg loss": 1.1380018817726523, "Avg value loss": 0.7722904663532972, "Avg policy loss": 0.36571141704916954, "Total num played games": 11674, "Total num trained steps": 22784, "Timestamp in ms": 1699887509758, "logtype": "training_step"}
{"Total num played games": 11729, "Total num trained steps": 22870, "Timestamp in ms": 1699887633934, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.640625}
{"Ratio train steps to played games": 1.94589774078478, "Avg loss": 0.9496334057766944, "Avg value loss": 0.5789150015916675, "Avg policy loss": 0.37071839440613985, "Total num played games": 11774, "Total num trained steps": 22912, "Timestamp in ms": 1699887651412, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 162.4025939758867, "Avg game time in secs": 7.097815712957527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.49, "played_steps": 1.22, "reached_maximum_moves": 0.02}, "Total num played games": 11776, "Total num trained steps": 22932, "Timestamp in ms": 1699887659968, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9565217391304348, "Avg loss": 0.6460112051572651, "Avg value loss": 0.28468439483549446, "Avg policy loss": 0.3613268102053553, "Total num played games": 11776, "Total num trained steps": 23040, "Timestamp in ms": 1699887707840, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9509894736842106, "Avg loss": 0.7584832441061735, "Avg value loss": 0.39910894201602787, "Avg policy loss": 0.3593743029050529, "Total num played games": 11875, "Total num trained steps": 23168, "Timestamp in ms": 1699887759473, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 135.74867559596896, "Avg game time in secs": 5.423488825268578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.88, "reached_maximum_moves": 0.01}, "Total num played games": 11904, "Total num trained steps": 23256, "Timestamp in ms": 1699887795717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9531315502641067, "Avg loss": 0.9798497739247978, "Avg value loss": 0.6058409721590579, "Avg policy loss": 0.374008797807619, "Total num played games": 11927, "Total num trained steps": 23296, "Timestamp in ms": 1699887811892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9551752921535892, "Avg loss": 0.7627475578337908, "Avg value loss": 0.39136369701009244, "Avg policy loss": 0.3713838641997427, "Total num played games": 11980, "Total num trained steps": 23424, "Timestamp in ms": 1699887864164, "logtype": "training_step"}
{"Total num played games": 12030, "Total num trained steps": 23472, "Timestamp in ms": 1699887989829, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.390625}
{"Avg objective": 21.1953125, "Games time in secs": 195.7359785642475, "Avg game time in secs": 5.949583982132026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 1.05}, "Total num played games": 12032, "Total num trained steps": 23474, "Timestamp in ms": 1699887991453, "logtype": "played_game"}
{"Ratio train steps to played games": 1.950070381717314, "Avg loss": 0.9519376857206225, "Avg value loss": 0.5758924883557484, "Avg policy loss": 0.376045189332217, "Total num played games": 12077, "Total num trained steps": 23552, "Timestamp in ms": 1699888023979, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9529896907216495, "Avg loss": 0.6497009256854653, "Avg value loss": 0.2813667027512565, "Avg policy loss": 0.36833421722985804, "Total num played games": 12124, "Total num trained steps": 23680, "Timestamp in ms": 1699888079326, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 120.68231096677482, "Avg game time in secs": 4.976144275220577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.88}, "Total num played games": 12160, "Total num trained steps": 23759, "Timestamp in ms": 1699888112135, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9551613697955161, "Avg loss": 0.7903968379832804, "Avg value loss": 0.41161073150578886, "Avg policy loss": 0.3787861140444875, "Total num played games": 12177, "Total num trained steps": 23808, "Timestamp in ms": 1699888132059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9573928688256461, "Avg loss": 0.7287266249768436, "Avg value loss": 0.35914443305227906, "Avg policy loss": 0.36958219134248793, "Total num played games": 12228, "Total num trained steps": 23936, "Timestamp in ms": 1699888185221, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 124.73346333950758, "Avg game time in secs": 5.526094731307239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.97, "agent_stopped_0": 0.42}, "Total num played games": 12288, "Total num trained steps": 24057, "Timestamp in ms": 1699888236869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9561046984230206, "Avg loss": 0.8904635580256581, "Avg value loss": 0.5229077351978049, "Avg policy loss": 0.3675558229442686, "Total num played games": 12302, "Total num trained steps": 24064, "Timestamp in ms": 1699888239123, "logtype": "training_step"}
{"Total num played games": 12331, "Total num trained steps": 24076, "Timestamp in ms": 1699888335357, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.73046875}
{"Ratio train steps to played games": 1.9541966233136765, "Avg loss": 0.8806174455676228, "Avg value loss": 0.49622267961967736, "Avg policy loss": 0.3843947642017156, "Total num played games": 12379, "Total num trained steps": 24192, "Timestamp in ms": 1699888385896, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 178.72497990354896, "Avg game time in secs": 5.556593948684167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.54, "played_steps": 1.02, "reached_maximum_moves": 0.01}, "Total num played games": 12416, "Total num trained steps": 24265, "Timestamp in ms": 1699888415594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9570290496499558, "Avg loss": 0.8046931410208344, "Avg value loss": 0.4384597376920283, "Avg policy loss": 0.36623341497033834, "Total num played games": 12427, "Total num trained steps": 24320, "Timestamp in ms": 1699888438582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9570925392251042, "Avg loss": 0.7145601829979569, "Avg value loss": 0.350885963649489, "Avg policy loss": 0.3636742227245122, "Total num played games": 12491, "Total num trained steps": 24448, "Timestamp in ms": 1699888489219, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 112.79857276380062, "Avg game time in secs": 5.253753904253244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.86, "agent_stopped_0": 0.51}, "Total num played games": 12544, "Total num trained steps": 24545, "Timestamp in ms": 1699888528393, "logtype": "played_game"}
{"Ratio train steps to played games": 1.954429775727692, "Avg loss": 0.8147052521817386, "Avg value loss": 0.4509912747889757, "Avg policy loss": 0.3637139741331339, "Total num played games": 12574, "Total num trained steps": 24576, "Timestamp in ms": 1699888540618, "logtype": "training_step"}
{"Total num played games": 12624, "Total num trained steps": 24680, "Timestamp in ms": 1699888696024, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.04296875}
{"Ratio train steps to played games": 1.949877654116347, "Avg loss": 0.8301112190820277, "Avg value loss": 0.4660389480413869, "Avg policy loss": 0.36407226603478193, "Total num played games": 12669, "Total num trained steps": 24704, "Timestamp in ms": 1699888706104, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 192.45189854875207, "Avg game time in secs": 6.911054518175661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 1.2}, "Total num played games": 12672, "Total num trained steps": 24737, "Timestamp in ms": 1699888720845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9595170454545454, "Avg loss": 0.6528744550887495, "Avg value loss": 0.2994953681482002, "Avg policy loss": 0.35337908542715013, "Total num played games": 12672, "Total num trained steps": 24832, "Timestamp in ms": 1699888762157, "logtype": "training_step"}
{"Ratio train steps to played games": 1.955421497963021, "Avg loss": 0.8136570972856134, "Avg value loss": 0.4518185256747529, "Avg policy loss": 0.36183857754804194, "Total num played games": 12764, "Total num trained steps": 24960, "Timestamp in ms": 1699888813075, "logtype": "training_step"}
{"Avg objective": 23.671875, "Games time in secs": 125.6844303291291, "Avg game time in secs": 4.3696107247669715, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.79}, "Total num played games": 12800, "Total num trained steps": 25041, "Timestamp in ms": 1699888846529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9574003276897871, "Avg loss": 0.8606891008093953, "Avg value loss": 0.48284587578382343, "Avg policy loss": 0.37784322584047914, "Total num played games": 12817, "Total num trained steps": 25088, "Timestamp in ms": 1699888865181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9595119676717438, "Avg loss": 0.7693292952608317, "Avg value loss": 0.3903947251383215, "Avg policy loss": 0.37893456872552633, "Total num played games": 12868, "Total num trained steps": 25216, "Timestamp in ms": 1699888917897, "logtype": "training_step"}
{"Total num played games": 12917, "Total num trained steps": 25280, "Timestamp in ms": 1699889043947, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.86328125}
{"Avg objective": 21.6796875, "Games time in secs": 199.91948524303734, "Avg game time in secs": 5.5371032806287985, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 1.04, "agent_stopped_0": 0.43}, "Total num played games": 12928, "Total num trained steps": 25286, "Timestamp in ms": 1699889046449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9547242576166601, "Avg loss": 0.9783759356942028, "Avg value loss": 0.6024819000158459, "Avg policy loss": 0.37589403823949397, "Total num played games": 12965, "Total num trained steps": 25344, "Timestamp in ms": 1699889071589, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9576512181999846, "Avg loss": 0.7130630766041577, "Avg value loss": 0.3417377086589113, "Avg policy loss": 0.37132536876015365, "Total num played games": 13011, "Total num trained steps": 25472, "Timestamp in ms": 1699889123091, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 101.20446794480085, "Avg game time in secs": 3.8723094907036284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.66}, "Total num played games": 13056, "Total num trained steps": 25533, "Timestamp in ms": 1699889147654, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9601837672281777, "Avg loss": 0.7701996974647045, "Avg value loss": 0.40142201527487487, "Avg policy loss": 0.36877767532132566, "Total num played games": 13060, "Total num trained steps": 25600, "Timestamp in ms": 1699889174398, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9558309259540825, "Avg loss": 0.9505841904319823, "Avg value loss": 0.5761850705603138, "Avg policy loss": 0.37439911579713225, "Total num played games": 13154, "Total num trained steps": 25728, "Timestamp in ms": 1699889224515, "logtype": "training_step"}
{"Avg objective": 23.3125, "Games time in secs": 111.86236772872508, "Avg game time in secs": 4.550849949388066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.77, "agent_stopped_0": 0.55}, "Total num played games": 13184, "Total num trained steps": 25813, "Timestamp in ms": 1699889259516, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9575257419745609, "Avg loss": 0.8741001463495195, "Avg value loss": 0.4882957066874951, "Avg policy loss": 0.38580443733371794, "Total num played games": 13208, "Total num trained steps": 25856, "Timestamp in ms": 1699889276912, "logtype": "training_step"}
{"Total num played games": 13209, "Total num trained steps": 25883, "Timestamp in ms": 1699889376941, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.02734375}
{"Ratio train steps to played games": 1.9600935425467714, "Avg loss": 0.7866230974905193, "Avg value loss": 0.40456430916674435, "Avg policy loss": 0.3820587934460491, "Total num played games": 13256, "Total num trained steps": 25984, "Timestamp in ms": 1699889418651, "logtype": "training_step"}
{"Avg objective": 19.84375, "Games time in secs": 207.48535850271583, "Avg game time in secs": 7.574214821608621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.56, "played_steps": 1.43, "reached_maximum_moves": 0.01}, "Total num played games": 13312, "Total num trained steps": 26101, "Timestamp in ms": 1699889467002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9575680335857262, "Avg loss": 0.8565128000918776, "Avg value loss": 0.4780401788884774, "Avg policy loss": 0.37847261666320264, "Total num played games": 13339, "Total num trained steps": 26112, "Timestamp in ms": 1699889470842, "logtype": "training_step"}
{"Ratio train steps to played games": 1.957696038200403, "Avg loss": 0.6843580610584468, "Avg value loss": 0.30900286696851254, "Avg policy loss": 0.37535519374068826, "Total num played games": 13403, "Total num trained steps": 26240, "Timestamp in ms": 1699889522644, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 85.01230582036078, "Avg game time in secs": 4.343931560055353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.81}, "Total num played games": 13440, "Total num trained steps": 26314, "Timestamp in ms": 1699889552014, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9599345870809486, "Avg loss": 0.8170929071493447, "Avg value loss": 0.4498064157087356, "Avg policy loss": 0.3672864839900285, "Total num played games": 13453, "Total num trained steps": 26368, "Timestamp in ms": 1699889573121, "logtype": "training_step"}
{"Total num played games": 13503, "Total num trained steps": 26483, "Timestamp in ms": 1699889706258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.421875}
{"Ratio train steps to played games": 1.9571576303737628, "Avg loss": 0.8415317721664906, "Avg value loss": 0.47410456999205053, "Avg policy loss": 0.3674272058997303, "Total num played games": 13538, "Total num trained steps": 26496, "Timestamp in ms": 1699889711911, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 200.90108874812722, "Avg game time in secs": 4.045324004226131, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.69, "agent_stopped_0": 0.55}, "Total num played games": 13568, "Total num trained steps": 26597, "Timestamp in ms": 1699889752916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9582230067666961, "Avg loss": 0.8309966083616018, "Avg value loss": 0.46450007252860814, "Avg policy loss": 0.36649654037319124, "Total num played games": 13596, "Total num trained steps": 26624, "Timestamp in ms": 1699889763304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9599238039416806, "Avg loss": 0.7773366896435618, "Avg value loss": 0.41549170191865414, "Avg policy loss": 0.36184498737566173, "Total num played games": 13649, "Total num trained steps": 26752, "Timestamp in ms": 1699889815008, "logtype": "training_step"}
{"Avg objective": 20.984375, "Games time in secs": 83.03056777641177, "Avg game time in secs": 4.491158198652556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.84}, "Total num played games": 13696, "Total num trained steps": 26804, "Timestamp in ms": 1699889835948, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9621870209504344, "Avg loss": 0.7695358679629862, "Avg value loss": 0.4119505686685443, "Avg policy loss": 0.357585301855579, "Total num played games": 13699, "Total num trained steps": 26880, "Timestamp in ms": 1699889868791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.957880237784544, "Avg loss": 0.9121648774016649, "Avg value loss": 0.5608965591527522, "Avg policy loss": 0.35126832337118685, "Total num played games": 13794, "Total num trained steps": 27008, "Timestamp in ms": 1699889918082, "logtype": "training_step"}
{"Total num played games": 13798, "Total num trained steps": 27082, "Timestamp in ms": 1699890033012, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.2578125}
{"Avg objective": 21.140625, "Games time in secs": 201.0598727837205, "Avg game time in secs": 4.785289869192638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.86, "agent_stopped_0": 0.53}, "Total num played games": 13824, "Total num trained steps": 27092, "Timestamp in ms": 1699890037008, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9599855543517515, "Avg loss": 0.7789280584547669, "Avg value loss": 0.4234029573854059, "Avg policy loss": 0.35552510479465127, "Total num played games": 13845, "Total num trained steps": 27136, "Timestamp in ms": 1699890054689, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9619314910765688, "Avg loss": 0.6952444431371987, "Avg value loss": 0.3420076343463734, "Avg policy loss": 0.3532368103042245, "Total num played games": 13896, "Total num trained steps": 27264, "Timestamp in ms": 1699890105443, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 117.38116921857, "Avg game time in secs": 4.908739909733413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.98}, "Total num played games": 13952, "Total num trained steps": 27382, "Timestamp in ms": 1699890154389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9592303840926972, "Avg loss": 0.7462040670216084, "Avg value loss": 0.39012707269284874, "Avg policy loss": 0.35607698815874755, "Total num played games": 13981, "Total num trained steps": 27392, "Timestamp in ms": 1699890157940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9603219831884884, "Avg loss": 0.8496696611400694, "Avg value loss": 0.4915878578322008, "Avg policy loss": 0.35808180016465485, "Total num played games": 14038, "Total num trained steps": 27520, "Timestamp in ms": 1699890210730, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 88.52715750224888, "Avg game time in secs": 4.886982017298578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.96}, "Total num played games": 14080, "Total num trained steps": 27601, "Timestamp in ms": 1699890242917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.962450312322544, "Avg loss": 0.7021225576754659, "Avg value loss": 0.33945645741187036, "Avg policy loss": 0.36266609840095043, "Total num played games": 14088, "Total num trained steps": 27648, "Timestamp in ms": 1699890262054, "logtype": "training_step"}
{"Total num played games": 14137, "Total num trained steps": 27684, "Timestamp in ms": 1699890371825, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.6484375}
{"Ratio train steps to played games": 1.958262831359278, "Avg loss": 0.9088873930741102, "Avg value loss": 0.5427759812446311, "Avg policy loss": 0.36611140985041857, "Total num played games": 14184, "Total num trained steps": 27776, "Timestamp in ms": 1699890410086, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 204.79071322642267, "Avg game time in secs": 7.46651051963272, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 1.45, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.01}, "Total num played games": 14208, "Total num trained steps": 27866, "Timestamp in ms": 1699890447707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9604440385020727, "Avg loss": 0.7110697473399341, "Avg value loss": 0.34183935879264027, "Avg policy loss": 0.3692303888965398, "Total num played games": 14233, "Total num trained steps": 27904, "Timestamp in ms": 1699890462961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9626128964503256, "Avg loss": 0.7229935205541551, "Avg value loss": 0.36758775589987636, "Avg policy loss": 0.35540576558560133, "Total num played games": 14283, "Total num trained steps": 28032, "Timestamp in ms": 1699890515737, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 119.24181979522109, "Avg game time in secs": 5.199972430287744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 1.02}, "Total num played games": 14336, "Total num trained steps": 28157, "Timestamp in ms": 1699890566949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9619591722984742, "Avg loss": 0.6675468147732317, "Avg value loss": 0.3137633502483368, "Avg policy loss": 0.3537834601011127, "Total num played games": 14352, "Total num trained steps": 28160, "Timestamp in ms": 1699890568052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9601552213983784, "Avg loss": 0.8519873891491443, "Avg value loss": 0.4804816044634208, "Avg policy loss": 0.37150579295121133, "Total num played games": 14431, "Total num trained steps": 28288, "Timestamp in ms": 1699890631621, "logtype": "training_step"}
{"Total num played games": 14431, "Total num trained steps": 28288, "Timestamp in ms": 1699890729894, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.8203125}
{"Avg objective": 21.8046875, "Games time in secs": 166.78395523503423, "Avg game time in secs": 3.238103817027877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.6}, "Total num played games": 14464, "Total num trained steps": 28294, "Timestamp in ms": 1699890733734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96249741004213, "Avg loss": 0.832933634519577, "Avg value loss": 0.4556308697210625, "Avg policy loss": 0.3773027677088976, "Total num played games": 14479, "Total num trained steps": 28416, "Timestamp in ms": 1699890792810, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645536513180535, "Avg loss": 0.9613145440816879, "Avg value loss": 0.5788706291932613, "Avg policy loss": 0.38244391698390245, "Total num played games": 14529, "Total num trained steps": 28544, "Timestamp in ms": 1699890854749, "logtype": "training_step"}
{"Avg objective": 23.53125, "Games time in secs": 172.1995143238455, "Avg game time in secs": 4.3590440780244535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.96, "agent_stopped_0": 0.44}, "Total num played games": 14592, "Total num trained steps": 28648, "Timestamp in ms": 1699890905933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9602762204293724, "Avg loss": 0.9217805610969663, "Avg value loss": 0.5289779904996976, "Avg policy loss": 0.3928025742061436, "Total num played games": 14626, "Total num trained steps": 28672, "Timestamp in ms": 1699890917192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9625212947189097, "Avg loss": 0.9051553879398853, "Avg value loss": 0.525417062221095, "Avg policy loss": 0.3797383282799274, "Total num played games": 14675, "Total num trained steps": 28800, "Timestamp in ms": 1699890977198, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 100.79853991232812, "Avg game time in secs": 4.699206566569046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.98, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.01}, "Total num played games": 14720, "Total num trained steps": 28861, "Timestamp in ms": 1699891006732, "logtype": "played_game"}
{"Total num played games": 14723, "Total num trained steps": 28890, "Timestamp in ms": 1699891106037, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.7578125}
{"Ratio train steps to played games": 1.9583643626023965, "Avg loss": 0.9378814480733126, "Avg value loss": 0.5702883349731565, "Avg policy loss": 0.3675931126344949, "Total num played games": 14771, "Total num trained steps": 28928, "Timestamp in ms": 1699891124404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9607909299500608, "Avg loss": 0.6716838120482862, "Avg value loss": 0.3133515074150637, "Avg policy loss": 0.3583323087077588, "Total num played games": 14818, "Total num trained steps": 29056, "Timestamp in ms": 1699891187305, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 220.38278249278665, "Avg game time in secs": 3.529057949242997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.72, "agent_stopped_0": 0.54}, "Total num played games": 14848, "Total num trained steps": 29136, "Timestamp in ms": 1699891227115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9628732849071833, "Avg loss": 0.8189181396737695, "Avg value loss": 0.4539987165480852, "Avg policy loss": 0.3649194266181439, "Total num played games": 14868, "Total num trained steps": 29184, "Timestamp in ms": 1699891250456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9650063685727692, "Avg loss": 0.7377889496274292, "Avg value loss": 0.3862030004383996, "Avg policy loss": 0.35158594604581594, "Total num played games": 14917, "Total num trained steps": 29312, "Timestamp in ms": 1699891312797, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 138.08113144151866, "Avg game time in secs": 4.123137302303803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.89, "agent_stopped_0": 0.41}, "Total num played games": 14976, "Total num trained steps": 29420, "Timestamp in ms": 1699891365196, "logtype": "played_game"}
{"Ratio train steps to played games": 1.961031175059952, "Avg loss": 0.8236249221954495, "Avg value loss": 0.4691213675541803, "Avg policy loss": 0.35450355731882155, "Total num played games": 15012, "Total num trained steps": 29440, "Timestamp in ms": 1699891375402, "logtype": "training_step"}
{"Total num played games": 15013, "Total num trained steps": 29493, "Timestamp in ms": 1699891494200, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.0703125}
{"Ratio train steps to played games": 1.9632162539008033, "Avg loss": 0.9063461911864579, "Avg value loss": 0.5301688401959836, "Avg policy loss": 0.37617735867388546, "Total num played games": 15061, "Total num trained steps": 29568, "Timestamp in ms": 1699891531394, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 194.65606929548085, "Avg game time in secs": 3.851336810301291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.77}, "Total num played games": 15104, "Total num trained steps": 29628, "Timestamp in ms": 1699891559852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9652547981469226, "Avg loss": 0.7471452187746763, "Avg value loss": 0.38769982126541436, "Avg policy loss": 0.3594454014673829, "Total num played games": 15110, "Total num trained steps": 29696, "Timestamp in ms": 1699891593679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9621052631578948, "Avg loss": 0.7520168507471681, "Avg value loss": 0.3902962899301201, "Avg policy loss": 0.36172056500799954, "Total num played games": 15200, "Total num trained steps": 29824, "Timestamp in ms": 1699891656051, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 137.6091206688434, "Avg game time in secs": 4.0707016956293955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.84, "agent_stopped_0": 0.49}, "Total num played games": 15232, "Total num trained steps": 29909, "Timestamp in ms": 1699891697462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9629071367717412, "Avg loss": 0.8188931164331734, "Avg value loss": 0.4561618025181815, "Avg policy loss": 0.3627313149627298, "Total num played games": 15259, "Total num trained steps": 29952, "Timestamp in ms": 1699891718591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9644723092998955, "Avg loss": 0.6228079074062407, "Avg value loss": 0.2640304578235373, "Avg policy loss": 0.3587774446932599, "Total num played games": 15312, "Total num trained steps": 30080, "Timestamp in ms": 1699891783553, "logtype": "training_step"}
{"Total num played games": 15312, "Total num trained steps": 30096, "Timestamp in ms": 1699891900673, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.54296875}
{"Avg objective": 20.4140625, "Games time in secs": 216.2946853134781, "Avg game time in secs": 3.760479575357749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.78, "agent_stopped_0": 0.48}, "Total num played games": 15360, "Total num trained steps": 30123, "Timestamp in ms": 1699891913756, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666666666666666, "Avg loss": 0.7715476520825177, "Avg value loss": 0.41418660536874086, "Avg policy loss": 0.35736104543320835, "Total num played games": 15360, "Total num trained steps": 30208, "Timestamp in ms": 1699891954976, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9627329192546583, "Avg loss": 0.830853579333052, "Avg value loss": 0.4723570990609005, "Avg policy loss": 0.3584964813198894, "Total num played games": 15456, "Total num trained steps": 30336, "Timestamp in ms": 1699892014893, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 138.24768169410527, "Avg game time in secs": 2.9789315847010585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 15488, "Total num trained steps": 30411, "Timestamp in ms": 1699892052004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9645321467724253, "Avg loss": 0.768496255390346, "Avg value loss": 0.40952226205263287, "Avg policy loss": 0.358973995083943, "Total num played games": 15507, "Total num trained steps": 30464, "Timestamp in ms": 1699892077534, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9666345226615236, "Avg loss": 0.6949784737080336, "Avg value loss": 0.34583051421213895, "Avg policy loss": 0.349147965433076, "Total num played games": 15555, "Total num trained steps": 30592, "Timestamp in ms": 1699892138699, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 129.51359639689326, "Avg game time in secs": 3.8317879750975408, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.84}, "Total num played games": 15616, "Total num trained steps": 30698, "Timestamp in ms": 1699892181518, "logtype": "played_game"}
{"Total num played games": 15652, "Total num trained steps": 30698, "Timestamp in ms": 1699892259416, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2109375}
{"Ratio train steps to played games": 1.9570618589539401, "Avg loss": 0.9061988792382181, "Avg value loss": 0.5606600637547672, "Avg policy loss": 0.3455388230504468, "Total num played games": 15697, "Total num trained steps": 30720, "Timestamp in ms": 1699892268092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648407643312102, "Avg loss": 0.6586114440578967, "Avg value loss": 0.3048847974278033, "Avg policy loss": 0.35372664174064994, "Total num played games": 15700, "Total num trained steps": 30848, "Timestamp in ms": 1699892320293, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 164.9670402146876, "Avg game time in secs": 3.384610394248739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.7}, "Total num played games": 15744, "Total num trained steps": 30916, "Timestamp in ms": 1699892346485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666666666666666, "Avg loss": 0.8049176866188645, "Avg value loss": 0.4628171861404553, "Avg policy loss": 0.34210050059482455, "Total num played games": 15750, "Total num trained steps": 30976, "Timestamp in ms": 1699892371198, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962892843619841, "Avg loss": 0.7132300920784473, "Avg value loss": 0.35919117205776274, "Avg policy loss": 0.3540389162953943, "Total num played games": 15846, "Total num trained steps": 31104, "Timestamp in ms": 1699892422993, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 115.32864949293435, "Avg game time in secs": 4.405559962237021, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.98, "agent_stopped_0": 0.44}, "Total num played games": 15872, "Total num trained steps": 31197, "Timestamp in ms": 1699892461814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9642138364779875, "Avg loss": 0.7542251329869032, "Avg value loss": 0.3835265232482925, "Avg policy loss": 0.37069860799238086, "Total num played games": 15900, "Total num trained steps": 31232, "Timestamp in ms": 1699892475241, "logtype": "training_step"}
{"Total num played games": 15949, "Total num trained steps": 31299, "Timestamp in ms": 1699892591367, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.609375}
{"Ratio train steps to played games": 1.9603675689191724, "Avg loss": 0.9329657088965178, "Avg value loss": 0.5609311001608148, "Avg policy loss": 0.37203461048193276, "Total num played games": 15997, "Total num trained steps": 31360, "Timestamp in ms": 1699892617320, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 206.83892351947725, "Avg game time in secs": 3.2965212923882063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.68, "agent_stopped_0": 0.48}, "Total num played games": 16000, "Total num trained steps": 31485, "Timestamp in ms": 1699892668653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9654806491885144, "Avg loss": 0.5448487401008606, "Avg value loss": 0.1889453919720836, "Avg policy loss": 0.3559033456258476, "Total num played games": 16020, "Total num trained steps": 31488, "Timestamp in ms": 1699892669621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964518734853663, "Avg loss": 0.780718581750989, "Avg value loss": 0.42901261697988957, "Avg policy loss": 0.35170596360694617, "Total num played games": 16093, "Total num trained steps": 31616, "Timestamp in ms": 1699892720170, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 81.91990304552019, "Avg game time in secs": 3.0283960693341214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.66}, "Total num played games": 16128, "Total num trained steps": 31691, "Timestamp in ms": 1699892750573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966241328047572, "Avg loss": 0.7853155736811459, "Avg value loss": 0.42252049688249826, "Avg policy loss": 0.3627950861118734, "Total num played games": 16144, "Total num trained steps": 31744, "Timestamp in ms": 1699892772239, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9681961341320324, "Avg loss": 0.6904569882899523, "Avg value loss": 0.3326168350176886, "Avg policy loss": 0.3578401564154774, "Total num played games": 16193, "Total num trained steps": 31872, "Timestamp in ms": 1699892823795, "logtype": "training_step"}
{"Total num played games": 16245, "Total num trained steps": 31900, "Timestamp in ms": 1699892930218, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.54296875}
{"Avg objective": 21.4140625, "Games time in secs": 182.1311263591051, "Avg game time in secs": 3.470232778432546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.73, "agent_stopped_0": 0.48}, "Total num played games": 16256, "Total num trained steps": 31904, "Timestamp in ms": 1699892932705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9639722580249186, "Avg loss": 0.8897131357807666, "Avg value loss": 0.5159323173575103, "Avg policy loss": 0.3737808158621192, "Total num played games": 16293, "Total num trained steps": 32000, "Timestamp in ms": 1699892972676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965916044547791, "Avg loss": 0.7004594313912094, "Avg value loss": 0.34790056553902104, "Avg policy loss": 0.3525588682387024, "Total num played games": 16342, "Total num trained steps": 32128, "Timestamp in ms": 1699893023127, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 113.76886761374772, "Avg game time in secs": 3.464602905252832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.77}, "Total num played games": 16384, "Total num trained steps": 32188, "Timestamp in ms": 1699893046474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9676691270664308, "Avg loss": 0.6534529009368271, "Avg value loss": 0.30268244160106406, "Avg policy loss": 0.350770462770015, "Total num played games": 16393, "Total num trained steps": 32256, "Timestamp in ms": 1699893074889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9661222755145407, "Avg loss": 0.675197352655232, "Avg value loss": 0.33893341303337365, "Avg policy loss": 0.3362639374099672, "Total num played games": 16471, "Total num trained steps": 32384, "Timestamp in ms": 1699893126061, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 118.59012653492391, "Avg game time in secs": 3.7671591818798333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.77, "agent_stopped_0": 0.49}, "Total num played games": 16512, "Total num trained steps": 32479, "Timestamp in ms": 1699893165064, "logtype": "played_game"}
{"Total num played games": 16543, "Total num trained steps": 32499, "Timestamp in ms": 1699893276439, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.8828125}
{"Ratio train steps to played games": 1.9610350443331925, "Avg loss": 0.822408595122397, "Avg value loss": 0.4749374225502834, "Avg policy loss": 0.34747118514496833, "Total num played games": 16579, "Total num trained steps": 32512, "Timestamp in ms": 1699893281345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9673316858537762, "Avg loss": 0.6165305369067937, "Avg value loss": 0.2683519497513771, "Avg policy loss": 0.3481785840122029, "Total num played games": 16591, "Total num trained steps": 32640, "Timestamp in ms": 1699893334507, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 190.61687931232154, "Avg game time in secs": 3.6649613523477456, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.84}, "Total num played games": 16640, "Total num trained steps": 32695, "Timestamp in ms": 1699893355681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9689340223530825, "Avg loss": 0.6573710336815566, "Avg value loss": 0.3121879515820183, "Avg policy loss": 0.3451830835547298, "Total num played games": 16642, "Total num trained steps": 32768, "Timestamp in ms": 1699893386205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9652308979031006, "Avg loss": 0.7407260588370264, "Avg value loss": 0.4013566642533988, "Avg policy loss": 0.33936938736587763, "Total num played games": 16739, "Total num trained steps": 32896, "Timestamp in ms": 1699893437455, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 113.57983697205782, "Avg game time in secs": 3.4642093745205784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.73, "agent_stopped_0": 0.5}, "Total num played games": 16768, "Total num trained steps": 32976, "Timestamp in ms": 1699893469261, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967119370979271, "Avg loss": 0.6181873474270105, "Avg value loss": 0.2851850842125714, "Avg policy loss": 0.33300226170103997, "Total num played games": 16788, "Total num trained steps": 33024, "Timestamp in ms": 1699893488189, "logtype": "training_step"}
{"Total num played games": 16842, "Total num trained steps": 33102, "Timestamp in ms": 1699893603719, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.5625}
{"Ratio train steps to played games": 1.9627590290112493, "Avg loss": 0.9526796899735928, "Avg value loss": 0.5973891046596691, "Avg policy loss": 0.3552905935794115, "Total num played games": 16890, "Total num trained steps": 33152, "Timestamp in ms": 1699893624568, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 204.43789245560765, "Avg game time in secs": 3.511117809379357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.79}, "Total num played games": 16896, "Total num trained steps": 33271, "Timestamp in ms": 1699893673699, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9659144612476371, "Avg loss": 0.5730088260024786, "Avg value loss": 0.2257645009085536, "Avg policy loss": 0.34724432649090886, "Total num played games": 16928, "Total num trained steps": 33280, "Timestamp in ms": 1699893676816, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9666804026608582, "Avg loss": 0.909017312573269, "Avg value loss": 0.5493812822387554, "Avg policy loss": 0.35963604017160833, "Total num played games": 16987, "Total num trained steps": 33408, "Timestamp in ms": 1699893727636, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 82.00592706538737, "Avg game time in secs": 2.931895499030361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.63}, "Total num played games": 17024, "Total num trained steps": 33473, "Timestamp in ms": 1699893755705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9683061392182182, "Avg loss": 0.7070571894291788, "Avg value loss": 0.34140261413995177, "Avg policy loss": 0.3656545716803521, "Total num played games": 17038, "Total num trained steps": 33536, "Timestamp in ms": 1699893784310, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9701527477029321, "Avg loss": 1.0816090102307498, "Avg value loss": 0.7221820799168199, "Avg policy loss": 0.35942694591358304, "Total num played games": 17087, "Total num trained steps": 33664, "Timestamp in ms": 1699893835484, "logtype": "training_step"}
{"Total num played games": 17137, "Total num trained steps": 33703, "Timestamp in ms": 1699893933825, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.484375}
{"Avg objective": 22.546875, "Games time in secs": 180.85385946556926, "Avg game time in secs": 3.155284868524177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.73, "agent_stopped_0": 0.39}, "Total num played games": 17152, "Total num trained steps": 33709, "Timestamp in ms": 1699893936559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966307826592959, "Avg loss": 0.9947019144892693, "Avg value loss": 0.6101704781176522, "Avg policy loss": 0.3845314362552017, "Total num played games": 17185, "Total num trained steps": 33792, "Timestamp in ms": 1699893970197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9681443657885576, "Avg loss": 0.6553600528277457, "Avg value loss": 0.3084691297262907, "Avg policy loss": 0.34689092077314854, "Total num played games": 17234, "Total num trained steps": 33920, "Timestamp in ms": 1699894023065, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 109.16981457546353, "Avg game time in secs": 3.0409993804933038, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 17280, "Total num trained steps": 33978, "Timestamp in ms": 1699894045729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9699704912341607, "Avg loss": 0.8676238676998764, "Avg value loss": 0.5016570903826505, "Avg policy loss": 0.3659667654428631, "Total num played games": 17283, "Total num trained steps": 34048, "Timestamp in ms": 1699894073137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9665669236966279, "Avg loss": 0.6847171247936785, "Avg value loss": 0.325625320780091, "Avg policy loss": 0.35909181251190603, "Total num played games": 17378, "Total num trained steps": 34176, "Timestamp in ms": 1699894121288, "logtype": "training_step"}
{"Avg objective": 22.75, "Games time in secs": 110.82049017213285, "Avg game time in secs": 2.9425733647076413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.69, "agent_stopped_0": 0.51}, "Total num played games": 17408, "Total num trained steps": 34262, "Timestamp in ms": 1699894156550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9673663684331268, "Avg loss": 1.0452670769300312, "Avg value loss": 0.6832855780376121, "Avg policy loss": 0.361981502501294, "Total num played games": 17436, "Total num trained steps": 34304, "Timestamp in ms": 1699894174181, "logtype": "training_step"}
{"Total num played games": 17436, "Total num trained steps": 34307, "Timestamp in ms": 1699894277538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6015625}
{"Ratio train steps to played games": 1.9692862045298558, "Avg loss": 0.7646050732582808, "Avg value loss": 0.39209803368430585, "Avg policy loss": 0.3725070361979306, "Total num played games": 17484, "Total num trained steps": 34432, "Timestamp in ms": 1699894329042, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 221.96638997271657, "Avg game time in secs": 3.7268255892704474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.87}, "Total num played games": 17536, "Total num trained steps": 34556, "Timestamp in ms": 1699894378516, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684456342199692, "Avg loss": 0.6596813548821956, "Avg value loss": 0.29970823699841276, "Avg policy loss": 0.35997311607934535, "Total num played games": 17557, "Total num trained steps": 34560, "Timestamp in ms": 1699894380023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9677785341502156, "Avg loss": 0.9914553468115628, "Avg value loss": 0.6252936833770946, "Avg policy loss": 0.3661616654135287, "Total num played games": 17628, "Total num trained steps": 34688, "Timestamp in ms": 1699894431011, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 79.48267749138176, "Avg game time in secs": 3.916087682111538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.88}, "Total num played games": 17664, "Total num trained steps": 34755, "Timestamp in ms": 1699894457999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694535580948072, "Avg loss": 0.7670089036691934, "Avg value loss": 0.38447725342120975, "Avg policy loss": 0.38253165129572153, "Total num played games": 17678, "Total num trained steps": 34816, "Timestamp in ms": 1699894484273, "logtype": "training_step"}
{"Total num played games": 17727, "Total num trained steps": 34908, "Timestamp in ms": 1699894606495, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.99609375}
{"Ratio train steps to played games": 1.966182759396804, "Avg loss": 0.7869429634884, "Avg value loss": 0.3995355563238263, "Avg policy loss": 0.38740739901550114, "Total num played games": 17772, "Total num trained steps": 34944, "Timestamp in ms": 1699894620701, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 203.92178923264146, "Avg game time in secs": 3.7101847939484287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.83, "agent_stopped_0": 0.47}, "Total num played games": 17792, "Total num trained steps": 35043, "Timestamp in ms": 1699894661921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9676279174147218, "Avg loss": 0.8234122679568827, "Avg value loss": 0.44596528966212645, "Avg policy loss": 0.3774469681084156, "Total num played games": 17824, "Total num trained steps": 35072, "Timestamp in ms": 1699894673244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9693951770827505, "Avg loss": 0.8013467411510646, "Avg value loss": 0.41562091116793454, "Avg policy loss": 0.38572582975029945, "Total num played games": 17873, "Total num trained steps": 35200, "Timestamp in ms": 1699894724736, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 83.06660573557019, "Avg game time in secs": 3.1482164654153166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.63}, "Total num played games": 17920, "Total num trained steps": 35252, "Timestamp in ms": 1699894744988, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708228730822872, "Avg loss": 0.7638501778710634, "Avg value loss": 0.3964939331635833, "Avg policy loss": 0.36735624517314136, "Total num played games": 17925, "Total num trained steps": 35328, "Timestamp in ms": 1699894775761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674823816658342, "Avg loss": 0.8309149339329451, "Avg value loss": 0.4620911609963514, "Avg policy loss": 0.36882376461289823, "Total num played games": 18021, "Total num trained steps": 35456, "Timestamp in ms": 1699894826619, "logtype": "training_step"}
{"Total num played games": 18025, "Total num trained steps": 35512, "Timestamp in ms": 1699894937682, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.75}
{"Avg objective": 22.21875, "Games time in secs": 195.7785919420421, "Avg game time in secs": 3.429769174690591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.84, "agent_stopped_0": 0.51}, "Total num played games": 18048, "Total num trained steps": 35517, "Timestamp in ms": 1699894940766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688485586233608, "Avg loss": 1.122223534155637, "Avg value loss": 0.7346535850083455, "Avg policy loss": 0.3875699534546584, "Total num played games": 18073, "Total num trained steps": 35584, "Timestamp in ms": 1699894968845, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705346796887933, "Avg loss": 0.7664008571300656, "Avg value loss": 0.4021906512789428, "Avg policy loss": 0.3642102056182921, "Total num played games": 18123, "Total num trained steps": 35712, "Timestamp in ms": 1699895021074, "logtype": "training_step"}
{"Avg objective": 22.96875, "Games time in secs": 129.646237436682, "Avg game time in secs": 3.91327007432119, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 1.05}, "Total num played games": 18176, "Total num trained steps": 35835, "Timestamp in ms": 1699895070413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694471919991208, "Avg loss": 0.9797750003635883, "Avg value loss": 0.6005629331339151, "Avg policy loss": 0.3792120625730604, "Total num played games": 18197, "Total num trained steps": 35840, "Timestamp in ms": 1699895071949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9684216287215412, "Avg loss": 0.8340013497509062, "Avg value loss": 0.47129792266059667, "Avg policy loss": 0.362703422550112, "Total num played games": 18272, "Total num trained steps": 35968, "Timestamp in ms": 1699895122410, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 80.79872008413076, "Avg game time in secs": 2.76495647590491, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.64}, "Total num played games": 18304, "Total num trained steps": 36040, "Timestamp in ms": 1699895151212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969768076398363, "Avg loss": 0.8302297343034297, "Avg value loss": 0.4554293805267662, "Avg policy loss": 0.3748003523796797, "Total num played games": 18325, "Total num trained steps": 36096, "Timestamp in ms": 1699895174023, "logtype": "training_step"}
{"Total num played games": 18325, "Total num trained steps": 36115, "Timestamp in ms": 1699895313319, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2421875}
{"Ratio train steps to played games": 1.9715343166603168, "Avg loss": 0.6562090064398944, "Avg value loss": 0.29158097825711593, "Avg policy loss": 0.36462802975438535, "Total num played games": 18373, "Total num trained steps": 36224, "Timestamp in ms": 1699895357728, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 251.1726681459695, "Avg game time in secs": 3.4421862911549397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.8}, "Total num played games": 18432, "Total num trained steps": 36337, "Timestamp in ms": 1699895402385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9685367702805154, "Avg loss": 0.7390135086607188, "Avg value loss": 0.3827488036477007, "Avg policy loss": 0.3562647020444274, "Total num played games": 18466, "Total num trained steps": 36352, "Timestamp in ms": 1699895407999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9694957348018574, "Avg loss": 0.7313608212862164, "Avg value loss": 0.3868817189941183, "Avg policy loss": 0.34447909775190055, "Total num played games": 18522, "Total num trained steps": 36480, "Timestamp in ms": 1699895458176, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 80.4783015716821, "Avg game time in secs": 3.0432472710090224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 18560, "Total num trained steps": 36543, "Timestamp in ms": 1699895482863, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9711916428840666, "Avg loss": 0.7451379587873816, "Avg value loss": 0.40881447785068303, "Avg policy loss": 0.33632348058745265, "Total num played games": 18571, "Total num trained steps": 36608, "Timestamp in ms": 1699895508319, "logtype": "training_step"}
{"Total num played games": 18620, "Total num trained steps": 36718, "Timestamp in ms": 1699895632258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.91015625}
{"Ratio train steps to played games": 1.9684921230307577, "Avg loss": 0.7484050353523344, "Avg value loss": 0.41326575371203944, "Avg policy loss": 0.3351392785552889, "Total num played games": 18662, "Total num trained steps": 36736, "Timestamp in ms": 1699895639529, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 194.7877024617046, "Avg game time in secs": 3.199058711004909, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.67, "agent_stopped_0": 0.55}, "Total num played games": 18688, "Total num trained steps": 36831, "Timestamp in ms": 1699895677651, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969492974301437, "Avg loss": 0.8978746798820794, "Avg value loss": 0.5650586650008336, "Avg policy loss": 0.33281602419447154, "Total num played games": 18717, "Total num trained steps": 36864, "Timestamp in ms": 1699895690779, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9710662332818245, "Avg loss": 0.7685575007926673, "Avg value loss": 0.4296936379978433, "Avg policy loss": 0.3388638598844409, "Total num played games": 18767, "Total num trained steps": 36992, "Timestamp in ms": 1699895743919, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 88.57528637908399, "Avg game time in secs": 2.9515026577282697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.77, "agent_stopped_0": 0.45}, "Total num played games": 18816, "Total num trained steps": 37046, "Timestamp in ms": 1699895766227, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972579445212031, "Avg loss": 0.833076091716066, "Avg value loss": 0.4883702563820407, "Avg policy loss": 0.3447058437159285, "Total num played games": 18818, "Total num trained steps": 37120, "Timestamp in ms": 1699895797200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9687103594080337, "Avg loss": 0.9259611889719963, "Avg value loss": 0.5809304516296834, "Avg policy loss": 0.3450307440944016, "Total num played games": 18919, "Total num trained steps": 37248, "Timestamp in ms": 1699895847921, "logtype": "training_step"}
{"Total num played games": 18920, "Total num trained steps": 37319, "Timestamp in ms": 1699895966871, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.18359375}
{"Avg objective": 21.5625, "Games time in secs": 203.32668237946928, "Avg game time in secs": 2.772275307419477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.6, "agent_stopped_0": 0.56}, "Total num played games": 18944, "Total num trained steps": 37324, "Timestamp in ms": 1699895969553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9704238717840574, "Avg loss": 0.839985765516758, "Avg value loss": 0.47876201814506203, "Avg policy loss": 0.3612237391062081, "Total num played games": 18968, "Total num trained steps": 37376, "Timestamp in ms": 1699895990141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9719739194447365, "Avg loss": 0.6643829590175301, "Avg value loss": 0.31709851510822773, "Avg policy loss": 0.34728444879874587, "Total num played games": 19018, "Total num trained steps": 37504, "Timestamp in ms": 1699896042706, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 122.86531246267259, "Avg game time in secs": 3.206345474376576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.9, "agent_stopped_0": 0.36}, "Total num played games": 19072, "Total num trained steps": 37625, "Timestamp in ms": 1699896092419, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9698492462311559, "Avg loss": 0.7272509483154863, "Avg value loss": 0.3713998097809963, "Avg policy loss": 0.3558511403389275, "Total num played games": 19104, "Total num trained steps": 37632, "Timestamp in ms": 1699896094876, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9702061048786852, "Avg loss": 0.7941952482797205, "Avg value loss": 0.448291955399327, "Avg policy loss": 0.3459032920654863, "Total num played games": 19165, "Total num trained steps": 37760, "Timestamp in ms": 1699896146089, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 81.86996498145163, "Avg game time in secs": 2.9095006134884898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.72}, "Total num played games": 19200, "Total num trained steps": 37831, "Timestamp in ms": 1699896174289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9717408274785324, "Avg loss": 0.8340789680369198, "Avg value loss": 0.46851183474063873, "Avg policy loss": 0.36556712770834565, "Total num played games": 19215, "Total num trained steps": 37888, "Timestamp in ms": 1699896195847, "logtype": "training_step"}
{"Total num played games": 19264, "Total num trained steps": 37922, "Timestamp in ms": 1699896291156, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.75}
{"Ratio train steps to played games": 1.9684652029826015, "Avg loss": 0.9330984686966985, "Avg value loss": 0.5606959939468652, "Avg policy loss": 0.3724024712573737, "Total num played games": 19312, "Total num trained steps": 38016, "Timestamp in ms": 1699896330096, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 197.23379710316658, "Avg game time in secs": 3.4520303689787397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.77, "agent_stopped_0": 0.45}, "Total num played games": 19328, "Total num trained steps": 38118, "Timestamp in ms": 1699896371523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97014617013584, "Avg loss": 0.6027681524865329, "Avg value loss": 0.2548741806531325, "Avg policy loss": 0.3478939675260335, "Total num played games": 19361, "Total num trained steps": 38144, "Timestamp in ms": 1699896381687, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9717156105100464, "Avg loss": 0.8571499544195831, "Avg value loss": 0.5049760738620535, "Avg policy loss": 0.35217388067394495, "Total num played games": 19410, "Total num trained steps": 38272, "Timestamp in ms": 1699896434911, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 84.7863211389631, "Avg game time in secs": 3.096565556974383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.8}, "Total num played games": 19456, "Total num trained steps": 38326, "Timestamp in ms": 1699896456309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9733799270260548, "Avg loss": 0.6953540404792875, "Avg value loss": 0.3433380851056427, "Avg policy loss": 0.3520159579347819, "Total num played games": 19459, "Total num trained steps": 38400, "Timestamp in ms": 1699896486344, "logtype": "training_step"}
{"Total num played games": 19557, "Total num trained steps": 38526, "Timestamp in ms": 1699896630125, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.4453125}
{"Ratio train steps to played games": 1.9697341513292435, "Avg loss": 0.7574300898704678, "Avg value loss": 0.4056290654698387, "Avg policy loss": 0.3518010280095041, "Total num played games": 19560, "Total num trained steps": 38528, "Timestamp in ms": 1699896631739, "logtype": "training_step"}
{"Avg objective": 20.3203125, "Games time in secs": 177.4600616041571, "Avg game time in secs": 3.3324216150067514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.79, "agent_stopped_0": 0.48}, "Total num played games": 19584, "Total num trained steps": 38534, "Timestamp in ms": 1699896633770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9716908951798011, "Avg loss": 0.8483363813720644, "Avg value loss": 0.49124657118227333, "Avg policy loss": 0.3570898009929806, "Total num played games": 19605, "Total num trained steps": 38656, "Timestamp in ms": 1699896682987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9732878803297038, "Avg loss": 0.6592962108552456, "Avg value loss": 0.31878758675884455, "Avg policy loss": 0.3405086216516793, "Total num played games": 19654, "Total num trained steps": 38784, "Timestamp in ms": 1699896733119, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 145.24321316368878, "Avg game time in secs": 2.998627678869525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.74, "agent_stopped_0": 0.5}, "Total num played games": 19712, "Total num trained steps": 38898, "Timestamp in ms": 1699896779013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9704765280802148, "Avg loss": 0.7952824498061091, "Avg value loss": 0.4526091272709891, "Avg policy loss": 0.34267332684248686, "Total num played games": 19747, "Total num trained steps": 38912, "Timestamp in ms": 1699896784322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9715670925710822, "Avg loss": 0.8527287351898849, "Avg value loss": 0.5035068375291303, "Avg policy loss": 0.3492219018517062, "Total num played games": 19801, "Total num trained steps": 39040, "Timestamp in ms": 1699896834638, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 82.17642880603671, "Avg game time in secs": 2.914132981764851, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.84}, "Total num played games": 19840, "Total num trained steps": 39105, "Timestamp in ms": 1699896861196, "logtype": "played_game"}
{"Total num played games": 19851, "Total num trained steps": 39129, "Timestamp in ms": 1699896949838, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.375}
{"Ratio train steps to played games": 1.9683401175938489, "Avg loss": 0.8340435242280364, "Avg value loss": 0.4795503579080105, "Avg policy loss": 0.3544931716751307, "Total num played games": 19899, "Total num trained steps": 39168, "Timestamp in ms": 1699896965498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9714529399959864, "Avg loss": 0.6071255384013057, "Avg value loss": 0.24559753097128123, "Avg policy loss": 0.36152800521813333, "Total num played games": 19932, "Total num trained steps": 39296, "Timestamp in ms": 1699897016589, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 193.67734970152378, "Avg game time in secs": 3.369990005288855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.84, "agent_stopped_0": 0.44}, "Total num played games": 19968, "Total num trained steps": 39392, "Timestamp in ms": 1699897054874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9713971397139713, "Avg loss": 0.8547359162475914, "Avg value loss": 0.49277890531811863, "Avg policy loss": 0.36195701360702515, "Total num played games": 19998, "Total num trained steps": 39424, "Timestamp in ms": 1699897067011, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9729136529156481, "Avg loss": 0.6993675176054239, "Avg value loss": 0.3377968928543851, "Avg policy loss": 0.3615706239361316, "Total num played games": 20047, "Total num trained steps": 39552, "Timestamp in ms": 1699897119439, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 83.47467903979123, "Avg game time in secs": 2.879728484651423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.66}, "Total num played games": 20096, "Total num trained steps": 39600, "Timestamp in ms": 1699897138349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741778197920294, "Avg loss": 0.7921243603341281, "Avg value loss": 0.4252114623086527, "Avg policy loss": 0.3669129000045359, "Total num played games": 20099, "Total num trained steps": 39680, "Timestamp in ms": 1699897170840, "logtype": "training_step"}
{"Total num played games": 20149, "Total num trained steps": 39730, "Timestamp in ms": 1699897271489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.0390625}
{"Ratio train steps to played games": 1.9709362776649997, "Avg loss": 0.8164123988244683, "Avg value loss": 0.4441755551379174, "Avg policy loss": 0.37223685323260725, "Total num played games": 20197, "Total num trained steps": 39808, "Timestamp in ms": 1699897303203, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 198.17704460956156, "Avg game time in secs": 3.08639976955601, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.75, "agent_stopped_0": 0.52}, "Total num played games": 20224, "Total num trained steps": 39891, "Timestamp in ms": 1699897336526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972488392768942, "Avg loss": 0.6603638587985188, "Avg value loss": 0.3039929653168656, "Avg policy loss": 0.35637089132796973, "Total num played games": 20246, "Total num trained steps": 39936, "Timestamp in ms": 1699897354452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9740330130574033, "Avg loss": 0.7201417449396104, "Avg value loss": 0.3543998084496707, "Avg policy loss": 0.3657419332303107, "Total num played games": 20295, "Total num trained steps": 40064, "Timestamp in ms": 1699897404244, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 112.51865545101464, "Avg game time in secs": 3.1201709004380973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.75}, "Total num played games": 20352, "Total num trained steps": 40179, "Timestamp in ms": 1699897449045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.971596762325239, "Avg loss": 0.7485312628559768, "Avg value loss": 0.3908349831472151, "Avg policy loss": 0.35769627848640084, "Total num played games": 20385, "Total num trained steps": 40192, "Timestamp in ms": 1699897453753, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972360825750905, "Avg loss": 0.8706619597505778, "Avg value loss": 0.5113802560372278, "Avg policy loss": 0.3592817052267492, "Total num played games": 20442, "Total num trained steps": 40320, "Timestamp in ms": 1699897507055, "logtype": "training_step"}
{"Total num played games": 20442, "Total num trained steps": 40331, "Timestamp in ms": 1699897608152, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.8515625}
{"Avg objective": 21.828125, "Games time in secs": 164.2560172919184, "Avg game time in secs": 2.8510959265986457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.7}, "Total num played games": 20480, "Total num trained steps": 40345, "Timestamp in ms": 1699897613301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739873108833577, "Avg loss": 0.8001831015571952, "Avg value loss": 0.4251367232645862, "Avg policy loss": 0.37504637823440135, "Total num played games": 20490, "Total num trained steps": 40448, "Timestamp in ms": 1699897656885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727732399844418, "Avg loss": 0.6439585972111672, "Avg value loss": 0.2961812561843544, "Avg policy loss": 0.34777733706869185, "Total num played games": 20566, "Total num trained steps": 40576, "Timestamp in ms": 1699897706399, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 129.88022417388856, "Avg game time in secs": 3.3945033158379374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.88, "agent_stopped_0": 0.38}, "Total num played games": 20608, "Total num trained steps": 40670, "Timestamp in ms": 1699897743181, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972140123067978, "Avg loss": 0.8758377232588828, "Avg value loss": 0.5215956710744649, "Avg policy loss": 0.35424205171875656, "Total num played games": 20639, "Total num trained steps": 40704, "Timestamp in ms": 1699897756208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9735608294262652, "Avg loss": 0.6842154553160071, "Avg value loss": 0.3220379498670809, "Avg policy loss": 0.36217750795185566, "Total num played games": 20689, "Total num trained steps": 40832, "Timestamp in ms": 1699897807766, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 84.24551128782332, "Avg game time in secs": 2.844607807142893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.74, "agent_stopped_0": 0.45}, "Total num played games": 20736, "Total num trained steps": 40881, "Timestamp in ms": 1699897827427, "logtype": "played_game"}
{"Total num played games": 20740, "Total num trained steps": 40931, "Timestamp in ms": 1699897930458, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.46875}
{"Ratio train steps to played games": 1.9704623081733776, "Avg loss": 0.8241479927673936, "Avg value loss": 0.4646874282043427, "Avg policy loss": 0.35946056491229683, "Total num played games": 20787, "Total num trained steps": 40960, "Timestamp in ms": 1699897941866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9720182385409166, "Avg loss": 0.6712324793916196, "Avg value loss": 0.32517476700013503, "Avg policy loss": 0.3460577155929059, "Total num played games": 20835, "Total num trained steps": 41088, "Timestamp in ms": 1699897992505, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 199.74062474817038, "Avg game time in secs": 3.0194274422538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.74, "agent_stopped_0": 0.49}, "Total num played games": 20864, "Total num trained steps": 41171, "Timestamp in ms": 1699898027168, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973331418174854, "Avg loss": 0.7762893927283585, "Avg value loss": 0.42320246202871203, "Avg policy loss": 0.35308693582192063, "Total num played games": 20886, "Total num trained steps": 41216, "Timestamp in ms": 1699898044850, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748268449964175, "Avg loss": 0.7157266191206872, "Avg value loss": 0.36776980641297996, "Avg policy loss": 0.34795681689865887, "Total num played games": 20935, "Total num trained steps": 41344, "Timestamp in ms": 1699898095881, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 113.75283813104033, "Avg game time in secs": 3.1130694566236343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.84}, "Total num played games": 20992, "Total num trained steps": 41460, "Timestamp in ms": 1699898140921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.971992391821208, "Avg loss": 0.8093696711584926, "Avg value loss": 0.45828440418699756, "Avg policy loss": 0.3510852688923478, "Total num played games": 21030, "Total num trained steps": 41472, "Timestamp in ms": 1699898145305, "logtype": "training_step"}
{"Total num played games": 21036, "Total num trained steps": 41533, "Timestamp in ms": 1699898256915, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.046875}
{"Ratio train steps to played games": 1.9730601403908177, "Avg loss": 1.0309868352487683, "Avg value loss": 0.6625656287651509, "Avg policy loss": 0.3684212083462626, "Total num played games": 21084, "Total num trained steps": 41600, "Timestamp in ms": 1699898282400, "logtype": "training_step"}
{"Avg objective": 22.78125, "Games time in secs": 167.67774022743106, "Avg game time in secs": 2.5447961727913935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.63, "agent_stopped_0": 0.5}, "Total num played games": 21120, "Total num trained steps": 41665, "Timestamp in ms": 1699898308599, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9744487555597616, "Avg loss": 0.7823669482022524, "Avg value loss": 0.4230449224705808, "Avg policy loss": 0.35932201868854463, "Total num played games": 21134, "Total num trained steps": 41728, "Timestamp in ms": 1699898334945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9759240900722277, "Avg loss": 0.7095534002874047, "Avg value loss": 0.3603674613405019, "Avg policy loss": 0.34918594220653176, "Total num played games": 21183, "Total num trained steps": 41856, "Timestamp in ms": 1699898388332, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 122.17776854895055, "Avg game time in secs": 3.3272253763279878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.84, "agent_stopped_0": 0.46}, "Total num played games": 21248, "Total num trained steps": 41960, "Timestamp in ms": 1699898430777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727469222817404, "Avg loss": 0.8749261277262121, "Avg value loss": 0.5209639962995425, "Avg policy loss": 0.3539621306117624, "Total num played games": 21282, "Total num trained steps": 41984, "Timestamp in ms": 1699898440091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9740308442319412, "Avg loss": 0.7823013053275645, "Avg value loss": 0.4218952887458727, "Avg policy loss": 0.36040600878186524, "Total num played games": 21333, "Total num trained steps": 42112, "Timestamp in ms": 1699898491407, "logtype": "training_step"}
{"Total num played games": 21333, "Total num trained steps": 42135, "Timestamp in ms": 1699898602236, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.4765625}
{"Avg objective": 21.9609375, "Games time in secs": 176.74423417821527, "Avg game time in secs": 2.9026424226613017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.77, "agent_stopped_0": 0.39}, "Total num played games": 21376, "Total num trained steps": 42149, "Timestamp in ms": 1699898607522, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975585800477059, "Avg loss": 0.6568422014825046, "Avg value loss": 0.3104150809231214, "Avg policy loss": 0.3464271167758852, "Total num played games": 21381, "Total num trained steps": 42240, "Timestamp in ms": 1699898644164, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9728521536670547, "Avg loss": 0.8749829242005944, "Avg value loss": 0.5288411305518821, "Avg policy loss": 0.34614179946947843, "Total num played games": 21474, "Total num trained steps": 42368, "Timestamp in ms": 1699898694773, "logtype": "training_step"}
{"Avg objective": 22.546875, "Games time in secs": 121.96315041743219, "Avg game time in secs": 2.8644648702756967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.74, "agent_stopped_0": 0.52}, "Total num played games": 21504, "Total num trained steps": 42454, "Timestamp in ms": 1699898729485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739409141583055, "Avg loss": 0.7776020215824246, "Avg value loss": 0.43399642303120345, "Avg policy loss": 0.34360560262575746, "Total num played games": 21528, "Total num trained steps": 42496, "Timestamp in ms": 1699898745765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975390462066089, "Avg loss": 0.6953309525270015, "Avg value loss": 0.3514277783688158, "Avg policy loss": 0.34390317741781473, "Total num played games": 21577, "Total num trained steps": 42624, "Timestamp in ms": 1699898797252, "logtype": "training_step"}
{"Total num played games": 21627, "Total num trained steps": 42736, "Timestamp in ms": 1699898935062, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.84765625}
{"Avg objective": 20.453125, "Games time in secs": 207.04662344232202, "Avg game time in secs": 2.9561390682210913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.77}, "Total num played games": 21632, "Total num trained steps": 42739, "Timestamp in ms": 1699898936532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727285312168334, "Avg loss": 0.7430412883404642, "Avg value loss": 0.39367198722902685, "Avg policy loss": 0.34936929889954627, "Total num played games": 21671, "Total num trained steps": 42752, "Timestamp in ms": 1699898941510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9733535827695705, "Avg loss": 0.7098156288266182, "Avg value loss": 0.37217770551797, "Avg policy loss": 0.33763792528770864, "Total num played games": 21729, "Total num trained steps": 42880, "Timestamp in ms": 1699898994189, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 87.35676746815443, "Avg game time in secs": 2.413504527779878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.59}, "Total num played games": 21760, "Total num trained steps": 42954, "Timestamp in ms": 1699899023889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9748369914592707, "Avg loss": 0.606858613435179, "Avg value loss": 0.2702475494588725, "Avg policy loss": 0.3366110671777278, "Total num played games": 21778, "Total num trained steps": 43008, "Timestamp in ms": 1699899045692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9762221102304485, "Avg loss": 0.6577518701087683, "Avg value loss": 0.3229244948597625, "Avg policy loss": 0.3348273797892034, "Total num played games": 21827, "Total num trained steps": 43136, "Timestamp in ms": 1699899097909, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 116.9865506850183, "Avg game time in secs": 2.9531385824957397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.8, "agent_stopped_0": 0.45}, "Total num played games": 21888, "Total num trained steps": 43243, "Timestamp in ms": 1699899140876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732269099201825, "Avg loss": 0.6985103578772396, "Avg value loss": 0.36507408804027364, "Avg policy loss": 0.3334362714085728, "Total num played games": 21925, "Total num trained steps": 43264, "Timestamp in ms": 1699899148772, "logtype": "training_step"}
{"Total num played games": 21925, "Total num trained steps": 43337, "Timestamp in ms": 1699899250721, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.23046875}
{"Ratio train steps to played games": 1.974787238884085, "Avg loss": 0.70924251829274, "Avg value loss": 0.36753157840576023, "Avg policy loss": 0.341710944310762, "Total num played games": 21973, "Total num trained steps": 43392, "Timestamp in ms": 1699899272986, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 153.18221909925342, "Avg game time in secs": 2.3929945737472735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 22016, "Total num trained steps": 43446, "Timestamp in ms": 1699899294058, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9762056125692489, "Avg loss": 0.84145916136913, "Avg value loss": 0.5052923918119632, "Avg policy loss": 0.33616676763631403, "Total num played games": 22022, "Total num trained steps": 43520, "Timestamp in ms": 1699899323834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973326099733261, "Avg loss": 0.7301351227797568, "Avg value loss": 0.40392112638801336, "Avg policy loss": 0.3262140037259087, "Total num played games": 22119, "Total num trained steps": 43648, "Timestamp in ms": 1699899374633, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 119.82888686470687, "Avg game time in secs": 2.5282402176235337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.63, "agent_stopped_0": 0.49}, "Total num played games": 22144, "Total num trained steps": 43737, "Timestamp in ms": 1699899413887, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9746492850376651, "Avg loss": 0.8347179398406297, "Avg value loss": 0.5028672750340775, "Avg policy loss": 0.3318506650393829, "Total num played games": 22169, "Total num trained steps": 43776, "Timestamp in ms": 1699899429556, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975966515144696, "Avg loss": 0.6818152032792568, "Avg value loss": 0.3383368120994419, "Avg policy loss": 0.34347838908433914, "Total num played games": 22219, "Total num trained steps": 43904, "Timestamp in ms": 1699899479377, "logtype": "training_step"}
{"Total num played games": 22268, "Total num trained steps": 43941, "Timestamp in ms": 1699899569519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.61328125}
{"Avg objective": 22.0390625, "Games time in secs": 157.13074534758925, "Avg game time in secs": 2.895895894806017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.81}, "Total num played games": 22272, "Total num trained steps": 43944, "Timestamp in ms": 1699899571018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731134611937624, "Avg loss": 1.186151141533628, "Avg value loss": 0.8158664114307612, "Avg policy loss": 0.37028472521342337, "Total num played games": 22316, "Total num trained steps": 44032, "Timestamp in ms": 1699899606678, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744690364408675, "Avg loss": 0.5867506163194776, "Avg value loss": 0.24228279228555039, "Avg policy loss": 0.3444678212981671, "Total num played games": 22365, "Total num trained steps": 44160, "Timestamp in ms": 1699899658595, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 113.80655568651855, "Avg game time in secs": 2.3908900311071193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.62}, "Total num played games": 22400, "Total num trained steps": 44226, "Timestamp in ms": 1699899684825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757316202712347, "Avg loss": 0.692269285209477, "Avg value loss": 0.34608369489433244, "Avg policy loss": 0.34618559398222715, "Total num played games": 22416, "Total num trained steps": 44288, "Timestamp in ms": 1699899710510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770754507010906, "Avg loss": 0.6225227564573288, "Avg value loss": 0.2877009462681599, "Avg policy loss": 0.33482181082945317, "Total num played games": 22465, "Total num trained steps": 44416, "Timestamp in ms": 1699899761068, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 117.71222128346562, "Avg game time in secs": 2.510220829877653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.71, "agent_stopped_0": 0.45}, "Total num played games": 22528, "Total num trained steps": 44520, "Timestamp in ms": 1699899802537, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9742487368141122, "Avg loss": 0.6743648406118155, "Avg value loss": 0.3474489650106989, "Avg policy loss": 0.3269158733310178, "Total num played games": 22562, "Total num trained steps": 44544, "Timestamp in ms": 1699899813641, "logtype": "training_step"}
{"Total num played games": 22563, "Total num trained steps": 44544, "Timestamp in ms": 1699899929271, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.59765625}
{"Ratio train steps to played games": 1.975675556145239, "Avg loss": 0.7517017400823534, "Avg value loss": 0.40208262065425515, "Avg policy loss": 0.3496191136073321, "Total num played games": 22611, "Total num trained steps": 44672, "Timestamp in ms": 1699899982931, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 200.58649276942015, "Avg game time in secs": 2.8364812454092316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.8}, "Total num played games": 22656, "Total num trained steps": 44724, "Timestamp in ms": 1699900003124, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768334657135294, "Avg loss": 0.7670898195356131, "Avg value loss": 0.4275674894452095, "Avg policy loss": 0.33952232461888343, "Total num played games": 22662, "Total num trained steps": 44800, "Timestamp in ms": 1699900033821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742057388935272, "Avg loss": 0.8265612258110195, "Avg value loss": 0.47260056156665087, "Avg policy loss": 0.3539606649428606, "Total num played games": 22757, "Total num trained steps": 44928, "Timestamp in ms": 1699900086316, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 117.5559344291687, "Avg game time in secs": 2.808529619156616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.75, "agent_stopped_0": 0.45}, "Total num played games": 22784, "Total num trained steps": 45012, "Timestamp in ms": 1699900120680, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975403367239565, "Avg loss": 0.7053791405633092, "Avg value loss": 0.35808164556510746, "Avg policy loss": 0.34729748766403645, "Total num played games": 22808, "Total num trained steps": 45056, "Timestamp in ms": 1699900138614, "logtype": "training_step"}
{"Total num played games": 22858, "Total num trained steps": 45145, "Timestamp in ms": 1699900265137, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4609375}
{"Ratio train steps to played games": 1.972539945865712, "Avg loss": 0.8881276913452893, "Avg value loss": 0.5460830966476351, "Avg policy loss": 0.34204459958709776, "Total num played games": 22906, "Total num trained steps": 45184, "Timestamp in ms": 1699900280425, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 208.9889236278832, "Avg game time in secs": 2.9022174280689796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.88, "agent_stopped_0": 0.37}, "Total num played games": 22912, "Total num trained steps": 45303, "Timestamp in ms": 1699900329669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9747657441708433, "Avg loss": 0.5713719625491649, "Avg value loss": 0.22112160339020193, "Avg policy loss": 0.3502503589261323, "Total num played games": 22945, "Total num trained steps": 45312, "Timestamp in ms": 1699900332800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.6353846197016537, "Avg value loss": 0.2999303110409528, "Avg policy loss": 0.33545431192032993, "Total num played games": 23004, "Total num trained steps": 45440, "Timestamp in ms": 1699900383363, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 80.02373251505196, "Avg game time in secs": 2.4770537524454994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.66}, "Total num played games": 23040, "Total num trained steps": 45507, "Timestamp in ms": 1699900409693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765767328880022, "Avg loss": 0.7573737271595746, "Avg value loss": 0.41535563755314797, "Avg policy loss": 0.3420180892571807, "Total num played games": 23054, "Total num trained steps": 45568, "Timestamp in ms": 1699900433602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 0.6502134446054697, "Avg value loss": 0.31503674550913274, "Avg policy loss": 0.3351766993291676, "Total num played games": 23103, "Total num trained steps": 45696, "Timestamp in ms": 1699900486561, "logtype": "training_step"}
{"Total num played games": 23152, "Total num trained steps": 45747, "Timestamp in ms": 1699900598313, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.40625}
{"Avg objective": 21.6015625, "Games time in secs": 190.74925408698618, "Avg game time in secs": 3.032604771316983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.87, "agent_stopped_0": 0.38}, "Total num played games": 23168, "Total num trained steps": 45752, "Timestamp in ms": 1699900600442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9751724137931035, "Avg loss": 1.0056232591159642, "Avg value loss": 0.6559435345698148, "Avg policy loss": 0.3496797375846654, "Total num played games": 23200, "Total num trained steps": 45824, "Timestamp in ms": 1699900629520, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9765151189298464, "Avg loss": 0.5562028049025685, "Avg value loss": 0.22513735032407567, "Avg policy loss": 0.3310654533561319, "Total num played games": 23249, "Total num trained steps": 45952, "Timestamp in ms": 1699900681327, "logtype": "training_step"}
{"Avg objective": 20.296875, "Games time in secs": 100.08709126524627, "Avg game time in secs": 2.5894203915959224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.73}, "Total num played games": 23296, "Total num trained steps": 46000, "Timestamp in ms": 1699900700529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778521761524595, "Avg loss": 0.7346753112506121, "Avg value loss": 0.4029722836567089, "Avg policy loss": 0.33170302293729037, "Total num played games": 23298, "Total num trained steps": 46080, "Timestamp in ms": 1699900732929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9751645721125075, "Avg loss": 0.8455094592645764, "Avg value loss": 0.516556411399506, "Avg policy loss": 0.3289530420443043, "Total num played games": 23394, "Total num trained steps": 46208, "Timestamp in ms": 1699900782952, "logtype": "training_step"}
{"Avg objective": 22.1875, "Games time in secs": 114.27245727181435, "Avg game time in secs": 2.3541622089396697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.64, "agent_stopped_0": 0.5}, "Total num played games": 23424, "Total num trained steps": 46287, "Timestamp in ms": 1699900814802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9762016462660468, "Avg loss": 0.8383271165657789, "Avg value loss": 0.5078718790900894, "Avg policy loss": 0.3304552477784455, "Total num played games": 23447, "Total num trained steps": 46336, "Timestamp in ms": 1699900834147, "logtype": "training_step"}
{"Total num played games": 23447, "Total num trained steps": 46352, "Timestamp in ms": 1699900929362, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.3125}
{"Ratio train steps to played games": 1.9775696956799318, "Avg loss": 0.5766684049740434, "Avg value loss": 0.2500415046233684, "Avg policy loss": 0.3266269010491669, "Total num played games": 23495, "Total num trained steps": 46464, "Timestamp in ms": 1699900975287, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 207.47613431699574, "Avg game time in secs": 3.041232497576857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.9, "agent_stopped_0": 0.45}, "Total num played games": 23552, "Total num trained steps": 46579, "Timestamp in ms": 1699901022278, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9752416482957436, "Avg loss": 0.9692800033371896, "Avg value loss": 0.6405037372605875, "Avg policy loss": 0.32877625979017466, "Total num played games": 23588, "Total num trained steps": 46592, "Timestamp in ms": 1699901026841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758511313174032, "Avg loss": 0.9621154160704464, "Avg value loss": 0.6177127292612568, "Avg policy loss": 0.3444026871584356, "Total num played games": 23645, "Total num trained steps": 46720, "Timestamp in ms": 1699901078830, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 83.96500913612545, "Avg game time in secs": 2.407778380540549, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.63}, "Total num played games": 23680, "Total num trained steps": 46786, "Timestamp in ms": 1699901106249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977125975944292, "Avg loss": 0.689893146045506, "Avg value loss": 0.3593674579751678, "Avg policy loss": 0.3305256812600419, "Total num played games": 23695, "Total num trained steps": 46848, "Timestamp in ms": 1699901131240, "logtype": "training_step"}
{"Total num played games": 23745, "Total num trained steps": 46953, "Timestamp in ms": 1699901273565, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1328125}
{"Ratio train steps to played games": 1.9744451916610626, "Avg loss": 0.7082775579765439, "Avg value loss": 0.3875949406065047, "Avg policy loss": 0.3206826245877892, "Total num played games": 23792, "Total num trained steps": 46976, "Timestamp in ms": 1699901282839, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 219.65036847442389, "Avg game time in secs": 2.5354655386909144, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.71, "agent_stopped_0": 0.45}, "Total num played games": 23808, "Total num trained steps": 47078, "Timestamp in ms": 1699901325899, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754655259184701, "Avg loss": 0.7049195941071957, "Avg value loss": 0.37425386830000207, "Avg policy loss": 0.33066572551615536, "Total num played games": 23844, "Total num trained steps": 47104, "Timestamp in ms": 1699901336121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767714393336961, "Avg loss": 0.6515049720183015, "Avg value loss": 0.325342116469983, "Avg policy loss": 0.32616285246331245, "Total num played games": 23893, "Total num trained steps": 47232, "Timestamp in ms": 1699901387915, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 84.22887618280947, "Avg game time in secs": 2.349200216587633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.69}, "Total num played games": 23936, "Total num trained steps": 47288, "Timestamp in ms": 1699901410128, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780720073510984, "Avg loss": 0.681834263028577, "Avg value loss": 0.3579397349967621, "Avg policy loss": 0.32389452087227255, "Total num played games": 23942, "Total num trained steps": 47360, "Timestamp in ms": 1699901439220, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9754971295448873, "Avg loss": 0.7206545274239033, "Avg value loss": 0.40280060353688896, "Avg policy loss": 0.31785392737947404, "Total num played games": 24038, "Total num trained steps": 47488, "Timestamp in ms": 1699901490006, "logtype": "training_step"}
{"Total num played games": 24041, "Total num trained steps": 47557, "Timestamp in ms": 1699901622232, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.84765625}
{"Avg objective": 20.8125, "Games time in secs": 214.3019153289497, "Avg game time in secs": 2.821568665021914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.8, "agent_stopped_0": 0.45}, "Total num played games": 24064, "Total num trained steps": 47562, "Timestamp in ms": 1699901624430, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9766283365851633, "Avg loss": 0.7136165814008564, "Avg value loss": 0.39064802788197994, "Avg policy loss": 0.3229685571277514, "Total num played games": 24089, "Total num trained steps": 47616, "Timestamp in ms": 1699901646117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779186345181872, "Avg loss": 0.6330907077062875, "Avg value loss": 0.31771463371114805, "Avg policy loss": 0.31537607789505273, "Total num played games": 24138, "Total num trained steps": 47744, "Timestamp in ms": 1699901698710, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 125.28884977474809, "Avg game time in secs": 2.7922930987842847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.83}, "Total num played games": 24192, "Total num trained steps": 47871, "Timestamp in ms": 1699901749719, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97830399206546, "Avg loss": 0.712051602313295, "Avg value loss": 0.39021312637487426, "Avg policy loss": 0.3218384758802131, "Total num played games": 24198, "Total num trained steps": 47872, "Timestamp in ms": 1699901750058, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9762434123847168, "Avg loss": 0.828255663625896, "Avg value loss": 0.513212664052844, "Avg policy loss": 0.3150430036475882, "Total num played games": 24288, "Total num trained steps": 48000, "Timestamp in ms": 1699901800389, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 79.28957116417587, "Avg game time in secs": 2.3060328963474603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.61}, "Total num played games": 24320, "Total num trained steps": 48073, "Timestamp in ms": 1699901829009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775239347495583, "Avg loss": 0.6181591236963868, "Avg value loss": 0.29697312822099775, "Avg policy loss": 0.3211859941948205, "Total num played games": 24337, "Total num trained steps": 48128, "Timestamp in ms": 1699901851260, "logtype": "training_step"}
{"Total num played games": 24337, "Total num trained steps": 48159, "Timestamp in ms": 1699901958477, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.07421875}
{"Ratio train steps to played games": 1.9788804592987492, "Avg loss": 0.5723650311119854, "Avg value loss": 0.26164753537159413, "Avg policy loss": 0.3107175020268187, "Total num played games": 24385, "Total num trained steps": 48256, "Timestamp in ms": 1699901997385, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 212.0776568762958, "Avg game time in secs": 2.6105803869577358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.8, "agent_stopped_0": 0.45}, "Total num played games": 24448, "Total num trained steps": 48360, "Timestamp in ms": 1699902041087, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97618755871421, "Avg loss": 0.6448989948257804, "Avg value loss": 0.3404714318457991, "Avg policy loss": 0.3044275667052716, "Total num played games": 24483, "Total num trained steps": 48384, "Timestamp in ms": 1699902050042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774580140225013, "Avg loss": 0.619018204510212, "Avg value loss": 0.3107233091723174, "Avg policy loss": 0.30829489580355585, "Total num played games": 24532, "Total num trained steps": 48512, "Timestamp in ms": 1699902102057, "logtype": "training_step"}
{"Avg objective": 22.703125, "Games time in secs": 81.3800295908004, "Avg game time in secs": 2.368470925910515, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.72}, "Total num played games": 24576, "Total num trained steps": 48565, "Timestamp in ms": 1699902122467, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787234042553192, "Avg loss": 0.6030654101632535, "Avg value loss": 0.282975027046632, "Avg policy loss": 0.3200903822435066, "Total num played games": 24581, "Total num trained steps": 48640, "Timestamp in ms": 1699902152553, "logtype": "training_step"}
{"Total num played games": 24682, "Total num trained steps": 48759, "Timestamp in ms": 1699902283859, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.890625}
{"Avg objective": 21.5859375, "Games time in secs": 164.08552648313344, "Avg game time in secs": 2.467254431496258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.73, "agent_stopped_0": 0.45}, "Total num played games": 24704, "Total num trained steps": 48766, "Timestamp in ms": 1699902286553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9733743373932748, "Avg loss": 0.7326582896057516, "Avg value loss": 0.42217427969444543, "Avg policy loss": 0.3104840082814917, "Total num played games": 24712, "Total num trained steps": 48768, "Timestamp in ms": 1699902287382, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771532551556814, "Avg loss": 0.8054489404894412, "Avg value loss": 0.47174080373952165, "Avg policy loss": 0.33370813517831266, "Total num played games": 24730, "Total num trained steps": 48896, "Timestamp in ms": 1699902340840, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9784091367690384, "Avg loss": 0.6429066110868007, "Avg value loss": 0.31684394186595455, "Avg policy loss": 0.3260626692790538, "Total num played games": 24779, "Total num trained steps": 49024, "Timestamp in ms": 1699902393429, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 156.9534821435809, "Avg game time in secs": 2.7799278849270195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.82}, "Total num played games": 24832, "Total num trained steps": 49147, "Timestamp in ms": 1699902443506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769527793419677, "Avg loss": 0.6323589372914284, "Avg value loss": 0.30277423071675, "Avg policy loss": 0.32958470832090825, "Total num played games": 24862, "Total num trained steps": 49152, "Timestamp in ms": 1699902444964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764177428411005, "Avg loss": 0.9167913985438645, "Avg value loss": 0.5783317284658551, "Avg policy loss": 0.3384596686810255, "Total num played games": 24934, "Total num trained steps": 49280, "Timestamp in ms": 1699902495900, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 86.19905381277204, "Avg game time in secs": 2.439616219839081, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.63}, "Total num played games": 24960, "Total num trained steps": 49360, "Timestamp in ms": 1699902529706, "logtype": "played_game"}
{"Total num played games": 24983, "Total num trained steps": 49360, "Timestamp in ms": 1699902609287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.59375}
{"Ratio train steps to played games": 1.9738324477647717, "Avg loss": 0.9177197855897248, "Avg value loss": 0.5804836125462316, "Avg policy loss": 0.3372361804358661, "Total num played games": 25031, "Total num trained steps": 49408, "Timestamp in ms": 1699902629472, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789461068275338, "Avg loss": 0.5557908874470741, "Avg value loss": 0.22005822393111885, "Avg policy loss": 0.33573266537860036, "Total num played games": 25031, "Total num trained steps": 49536, "Timestamp in ms": 1699902681851, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 197.89092274941504, "Avg game time in secs": 2.6423484201950487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.7}, "Total num played games": 25088, "Total num trained steps": 49651, "Timestamp in ms": 1699902727597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9766766169154228, "Avg loss": 0.8656986693385988, "Avg value loss": 0.5413966674823314, "Avg policy loss": 0.3243020116351545, "Total num played games": 25125, "Total num trained steps": 49664, "Timestamp in ms": 1699902732476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977599491619668, "Avg loss": 0.7207162489648908, "Avg value loss": 0.3941693519009277, "Avg policy loss": 0.32654689345508814, "Total num played games": 25178, "Total num trained steps": 49792, "Timestamp in ms": 1699902783544, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 78.49105049669743, "Avg game time in secs": 2.1888126046105754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.57}, "Total num played games": 25216, "Total num trained steps": 49851, "Timestamp in ms": 1699902806088, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787925635232093, "Avg loss": 0.7141288777347654, "Avg value loss": 0.3916780886356719, "Avg policy loss": 0.322450784035027, "Total num played games": 25227, "Total num trained steps": 49920, "Timestamp in ms": 1699902833509, "logtype": "training_step"}
{"Total num played games": 25276, "Total num trained steps": 49963, "Timestamp in ms": 1699902974102, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4765625}
{"Ratio train steps to played games": 1.9762675722634655, "Avg loss": 0.8793894308619201, "Avg value loss": 0.5334864056203514, "Avg policy loss": 0.34590302826836705, "Total num played games": 25324, "Total num trained steps": 50048, "Timestamp in ms": 1699903009221, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 240.60604226402938, "Avg game time in secs": 2.1628608038445236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 25344, "Total num trained steps": 50142, "Timestamp in ms": 1699903046694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977184064310202, "Avg loss": 0.6399862575344741, "Avg value loss": 0.31855678698047996, "Avg policy loss": 0.3214294705539942, "Total num played games": 25377, "Total num trained steps": 50176, "Timestamp in ms": 1699903060089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9784079288916856, "Avg loss": 0.6544172242283821, "Avg value loss": 0.31948306993581355, "Avg policy loss": 0.3349341517314315, "Total num played games": 25426, "Total num trained steps": 50304, "Timestamp in ms": 1699903112153, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 85.51052189059556, "Avg game time in secs": 2.279655967693543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 25472, "Total num trained steps": 50354, "Timestamp in ms": 1699903132205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9796270853778213, "Avg loss": 0.6152585707604885, "Avg value loss": 0.2841747799539007, "Avg policy loss": 0.3310837942408398, "Total num played games": 25475, "Total num trained steps": 50432, "Timestamp in ms": 1699903163787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771234162365088, "Avg loss": 0.859080710215494, "Avg value loss": 0.5161212765960954, "Avg policy loss": 0.3429594471817836, "Total num played games": 25572, "Total num trained steps": 50560, "Timestamp in ms": 1699903213912, "logtype": "training_step"}
{"Total num played games": 25573, "Total num trained steps": 50564, "Timestamp in ms": 1699903311399, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.46875}
{"Avg objective": 22.5703125, "Games time in secs": 182.2123766373843, "Avg game time in secs": 2.5364145843923325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.85, "agent_stopped_0": 0.4}, "Total num played games": 25600, "Total num trained steps": 50572, "Timestamp in ms": 1699903314417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783380820420748, "Avg loss": 0.7623659686651081, "Avg value loss": 0.4062267364934087, "Avg policy loss": 0.3561392296105623, "Total num played games": 25621, "Total num trained steps": 50688, "Timestamp in ms": 1699903361879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795481106349824, "Avg loss": 0.6848769374191761, "Avg value loss": 0.33883755502756685, "Avg policy loss": 0.3460393809946254, "Total num played games": 25670, "Total num trained steps": 50816, "Timestamp in ms": 1699903412344, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 143.46867272816598, "Avg game time in secs": 2.421286648052046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.66}, "Total num played games": 25728, "Total num trained steps": 50929, "Timestamp in ms": 1699903457886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9772171550553075, "Avg loss": 0.7310057610739022, "Avg value loss": 0.3807147614425048, "Avg policy loss": 0.3502910044044256, "Total num played games": 25765, "Total num trained steps": 50944, "Timestamp in ms": 1699903464029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9781926637486926, "Avg loss": 0.752133434638381, "Avg value loss": 0.39670677680987865, "Avg policy loss": 0.35542665468528867, "Total num played games": 25817, "Total num trained steps": 51072, "Timestamp in ms": 1699903514536, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 80.1449064668268, "Avg game time in secs": 2.268214476236608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.7}, "Total num played games": 25856, "Total num trained steps": 51130, "Timestamp in ms": 1699903538037, "logtype": "played_game"}
{"Total num played games": 25866, "Total num trained steps": 51164, "Timestamp in ms": 1699903650599, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.8046875}
{"Ratio train steps to played games": 1.9757274060353476, "Avg loss": 0.8811523395124823, "Avg value loss": 0.5282995858578943, "Avg policy loss": 0.35285274987109005, "Total num played games": 25914, "Total num trained steps": 51200, "Timestamp in ms": 1699903664822, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9782240036999923, "Avg loss": 0.5728294646833092, "Avg value loss": 0.22720362182008103, "Avg policy loss": 0.34562584152445197, "Total num played games": 25945, "Total num trained steps": 51328, "Timestamp in ms": 1699903715947, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 213.35317599214613, "Avg game time in secs": 2.747967784758657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.82, "agent_stopped_0": 0.41}, "Total num played games": 25984, "Total num trained steps": 51418, "Timestamp in ms": 1699903751390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978163924342611, "Avg loss": 0.8839449244551361, "Avg value loss": 0.5379245557123795, "Avg policy loss": 0.3460203695576638, "Total num played games": 26012, "Total num trained steps": 51456, "Timestamp in ms": 1699903766138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97931775449906, "Avg loss": 0.6315726195462048, "Avg value loss": 0.2934775944449939, "Avg policy loss": 0.3380950291175395, "Total num played games": 26061, "Total num trained steps": 51584, "Timestamp in ms": 1699903817613, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 116.6030888594687, "Avg game time in secs": 2.440075305828941, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.68, "agent_stopped_0": 0.46}, "Total num played games": 26112, "Total num trained steps": 51710, "Timestamp in ms": 1699903867993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800888344310001, "Avg loss": 0.6433199620805681, "Avg value loss": 0.3132931893924251, "Avg policy loss": 0.3300267730373889, "Total num played games": 26115, "Total num trained steps": 51712, "Timestamp in ms": 1699903868387, "logtype": "training_step"}
{"Total num played games": 26160, "Total num trained steps": 51767, "Timestamp in ms": 1699903961425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.74609375}
{"Ratio train steps to played games": 1.9779838217338217, "Avg loss": 0.9360247140284628, "Avg value loss": 0.598005166859366, "Avg policy loss": 0.33801954123191535, "Total num played games": 26208, "Total num trained steps": 51840, "Timestamp in ms": 1699903992546, "logtype": "training_step"}
{"Avg objective": 23.4375, "Games time in secs": 153.67125392518938, "Avg game time in secs": 2.046701605853741, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.56}, "Total num played games": 26240, "Total num trained steps": 51910, "Timestamp in ms": 1699904021665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791674601058766, "Avg loss": 0.6028343883808702, "Avg value loss": 0.2782100890763104, "Avg policy loss": 0.32462429755833, "Total num played games": 26257, "Total num trained steps": 51968, "Timestamp in ms": 1699904044062, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803466889682961, "Avg loss": 0.6424024135340005, "Avg value loss": 0.3211002487805672, "Avg policy loss": 0.32130216469522566, "Total num played games": 26306, "Total num trained steps": 52096, "Timestamp in ms": 1699904094881, "logtype": "training_step"}
{"Avg objective": 22.5, "Games time in secs": 116.1281501930207, "Avg game time in secs": 2.291333902889164, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.62, "agent_stopped_0": 0.5}, "Total num played games": 26368, "Total num trained steps": 52203, "Timestamp in ms": 1699904137793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779940913567153, "Avg loss": 0.7821600958704948, "Avg value loss": 0.466942869767081, "Avg policy loss": 0.31521722266916186, "Total num played games": 26402, "Total num trained steps": 52224, "Timestamp in ms": 1699904146021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979019392885495, "Avg loss": 0.7900398415513337, "Avg value loss": 0.4646676338161342, "Avg policy loss": 0.3253722103545442, "Total num played games": 26453, "Total num trained steps": 52352, "Timestamp in ms": 1699904197907, "logtype": "training_step"}
{"Total num played games": 26453, "Total num trained steps": 52367, "Timestamp in ms": 1699904279085, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9296875}
{"Avg objective": 21.765625, "Games time in secs": 145.82002332806587, "Avg game time in secs": 2.5631807436293457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.77}, "Total num played games": 26496, "Total num trained steps": 52379, "Timestamp in ms": 1699904283613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803026300894306, "Avg loss": 0.6605387604795396, "Avg value loss": 0.3312348583713174, "Avg policy loss": 0.3293039028067142, "Total num played games": 26501, "Total num trained steps": 52480, "Timestamp in ms": 1699904324617, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977781119590962, "Avg loss": 0.8665533850435168, "Avg value loss": 0.5423332557547837, "Avg policy loss": 0.3242201207904145, "Total num played games": 26599, "Total num trained steps": 52608, "Timestamp in ms": 1699904375149, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 124.84782314486802, "Avg game time in secs": 2.3322303569002543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.66, "agent_stopped_0": 0.51}, "Total num played games": 26624, "Total num trained steps": 52692, "Timestamp in ms": 1699904408461, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978985289702792, "Avg loss": 0.738197983475402, "Avg value loss": 0.40986715944018215, "Avg policy loss": 0.3283308275276795, "Total num played games": 26648, "Total num trained steps": 52736, "Timestamp in ms": 1699904425891, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980110124733116, "Avg loss": 0.6252360173966736, "Avg value loss": 0.2910956327104941, "Avg policy loss": 0.3341403834056109, "Total num played games": 26697, "Total num trained steps": 52864, "Timestamp in ms": 1699904475681, "logtype": "training_step"}
{"Total num played games": 26747, "Total num trained steps": 52969, "Timestamp in ms": 1699904600865, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.625}
{"Avg objective": 21.1015625, "Games time in secs": 194.01937332190573, "Avg game time in secs": 2.761406484132749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.76, "agent_stopped_0": 0.44}, "Total num played games": 26752, "Total num trained steps": 52970, "Timestamp in ms": 1699904602481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777562140777787, "Avg loss": 0.7645807629451156, "Avg value loss": 0.43220607726834714, "Avg policy loss": 0.33237468893639743, "Total num played games": 26794, "Total num trained steps": 52992, "Timestamp in ms": 1699904611152, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788407092832663, "Avg loss": 0.7197340095881373, "Avg value loss": 0.38935023511294276, "Avg policy loss": 0.33038377366028726, "Total num played games": 26844, "Total num trained steps": 53120, "Timestamp in ms": 1699904665816, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 90.76033609732985, "Avg game time in secs": 2.457597384840483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.72, "agent_stopped_0": 0.44}, "Total num played games": 26880, "Total num trained steps": 53187, "Timestamp in ms": 1699904693241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98006842183549, "Avg loss": 0.6047934605740011, "Avg value loss": 0.28153946553356946, "Avg policy loss": 0.323254001326859, "Total num played games": 26892, "Total num trained steps": 53248, "Timestamp in ms": 1699904719101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800422895722818, "Avg loss": 0.5322299317922443, "Avg value loss": 0.22002506058197469, "Avg policy loss": 0.3122048679506406, "Total num played games": 26957, "Total num trained steps": 53376, "Timestamp in ms": 1699904771500, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 118.57254619523883, "Avg game time in secs": 2.7343488818150945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.73, "agent_stopped_0": 0.46}, "Total num played games": 27008, "Total num trained steps": 53473, "Timestamp in ms": 1699904811814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787344206516513, "Avg loss": 0.8536724364385009, "Avg value loss": 0.5361105749034323, "Avg policy loss": 0.3175618639215827, "Total num played games": 27039, "Total num trained steps": 53504, "Timestamp in ms": 1699904824063, "logtype": "training_step"}
{"Total num played games": 27088, "Total num trained steps": 53573, "Timestamp in ms": 1699904932094, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.05859375}
{"Avg objective": 20.53125, "Games time in secs": 130.34275918453932, "Avg game time in secs": 2.5517902898718603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.69}, "Total num played games": 27136, "Total num trained steps": 53593, "Timestamp in ms": 1699904942157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9763782429245282, "Avg loss": 0.9800345560070127, "Avg value loss": 0.6506123037543148, "Avg policy loss": 0.32942225376609713, "Total num played games": 27136, "Total num trained steps": 53632, "Timestamp in ms": 1699904960027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9810952240566038, "Avg loss": 0.5110944691114128, "Avg value loss": 0.19573626189958304, "Avg policy loss": 0.3153582075610757, "Total num played games": 27136, "Total num trained steps": 53760, "Timestamp in ms": 1699905019298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9787030917235808, "Avg loss": 0.6553771812468767, "Avg value loss": 0.3455459557007998, "Avg policy loss": 0.3098312299698591, "Total num played games": 27234, "Total num trained steps": 53888, "Timestamp in ms": 1699905078621, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 171.908537985757, "Avg game time in secs": 2.1798640657798387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 27264, "Total num trained steps": 53962, "Timestamp in ms": 1699905114066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979876841873763, "Avg loss": 0.6085768325719982, "Avg value loss": 0.30097352620214224, "Avg policy loss": 0.3076033017132431, "Total num played games": 27282, "Total num trained steps": 54016, "Timestamp in ms": 1699905138619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809380945411972, "Avg loss": 0.6204790307674557, "Avg value loss": 0.31915180617943406, "Avg policy loss": 0.3013272221432999, "Total num played games": 27332, "Total num trained steps": 54144, "Timestamp in ms": 1699905198752, "logtype": "training_step"}
{"Total num played games": 27381, "Total num trained steps": 54173, "Timestamp in ms": 1699905295153, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.0625}
{"Avg objective": 21.4609375, "Games time in secs": 182.96266494318843, "Avg game time in secs": 3.181516147291404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.95, "agent_stopped_0": 0.39}, "Total num played games": 27392, "Total num trained steps": 54174, "Timestamp in ms": 1699905297029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785992927193845, "Avg loss": 0.9795528948307037, "Avg value loss": 0.6553163508069701, "Avg policy loss": 0.32423653930891305, "Total num played games": 27429, "Total num trained steps": 54272, "Timestamp in ms": 1699905340257, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797656306863674, "Avg loss": 0.6643199089448899, "Avg value loss": 0.3486913494998589, "Avg policy loss": 0.3156285574659705, "Total num played games": 27478, "Total num trained steps": 54400, "Timestamp in ms": 1699905397825, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 127.04024537466466, "Avg game time in secs": 2.3269510012760293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.68}, "Total num played games": 27520, "Total num trained steps": 54461, "Timestamp in ms": 1699905424069, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980891488356886, "Avg loss": 0.6999552072957158, "Avg value loss": 0.3801826037815772, "Avg policy loss": 0.31977260182611644, "Total num played games": 27527, "Total num trained steps": 54528, "Timestamp in ms": 1699905454341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788196958725561, "Avg loss": 0.687371194595471, "Avg value loss": 0.3699344048509374, "Avg policy loss": 0.31743679544888437, "Total num played games": 27620, "Total num trained steps": 54656, "Timestamp in ms": 1699905511057, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 124.86560918390751, "Avg game time in secs": 2.5426592376461485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.7, "agent_stopped_0": 0.48}, "Total num played games": 27648, "Total num trained steps": 54742, "Timestamp in ms": 1699905548935, "logtype": "played_game"}
{"Total num played games": 27674, "Total num trained steps": 54776, "Timestamp in ms": 1699905650154, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.140625}
{"Ratio train steps to played games": 1.977618944480543, "Avg loss": 0.615890487562865, "Avg value loss": 0.3031418960308656, "Avg policy loss": 0.3127485897857696, "Total num played games": 27701, "Total num trained steps": 54784, "Timestamp in ms": 1699905653548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98077339297309, "Avg loss": 0.5651006053667516, "Avg value loss": 0.25083170842844993, "Avg policy loss": 0.3142688974039629, "Total num played games": 27722, "Total num trained steps": 54912, "Timestamp in ms": 1699905724709, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 232.56222547776997, "Avg game time in secs": 2.4042646618327126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.66, "agent_stopped_0": 0.46}, "Total num played games": 27776, "Total num trained steps": 55033, "Timestamp in ms": 1699905781497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795712847072364, "Avg loss": 0.6754888531286269, "Avg value loss": 0.35899388388497755, "Avg policy loss": 0.3164949701167643, "Total num played games": 27803, "Total num trained steps": 55040, "Timestamp in ms": 1699905783671, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795112849402563, "Avg loss": 0.864317504921928, "Avg value loss": 0.5264567510457709, "Avg policy loss": 0.33786075678654015, "Total num played games": 27869, "Total num trained steps": 55168, "Timestamp in ms": 1699905843913, "logtype": "training_step"}
{"Avg objective": 22.0390625, "Games time in secs": 96.15232321992517, "Avg game time in secs": 2.5623319494188763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.74}, "Total num played games": 27904, "Total num trained steps": 55234, "Timestamp in ms": 1699905877650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980621821047353, "Avg loss": 0.7332936599850655, "Avg value loss": 0.39641456224489957, "Avg policy loss": 0.3368790913373232, "Total num played games": 27918, "Total num trained steps": 55296, "Timestamp in ms": 1699905913171, "logtype": "training_step"}
{"Total num played games": 27967, "Total num trained steps": 55380, "Timestamp in ms": 1699906028013, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5703125}
{"Ratio train steps to played games": 1.978333035873639, "Avg loss": 0.8927406629081815, "Avg value loss": 0.5489390520378947, "Avg policy loss": 0.3438016108702868, "Total num played games": 28015, "Total num trained steps": 55424, "Timestamp in ms": 1699906055858, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 229.15989401564002, "Avg game time in secs": 2.4649135444051353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.67, "agent_stopped_0": 0.52}, "Total num played games": 28032, "Total num trained steps": 55521, "Timestamp in ms": 1699906106810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793693212185997, "Avg loss": 0.591171600157395, "Avg value loss": 0.26187785947695374, "Avg policy loss": 0.3292937360238284, "Total num played games": 28065, "Total num trained steps": 55552, "Timestamp in ms": 1699906120704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9805079319911787, "Avg loss": 0.7685537822544575, "Avg value loss": 0.42657554062316194, "Avg policy loss": 0.34197824262082577, "Total num played games": 28114, "Total num trained steps": 55680, "Timestamp in ms": 1699906186232, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 104.3513867855072, "Avg game time in secs": 2.6054152055294253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.73, "agent_stopped_0": 0.42}, "Total num played games": 28160, "Total num trained steps": 55732, "Timestamp in ms": 1699906211161, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815367135350093, "Avg loss": 0.5912884827703238, "Avg value loss": 0.24929010245250538, "Avg policy loss": 0.3419983813073486, "Total num played games": 28164, "Total num trained steps": 55808, "Timestamp in ms": 1699906253456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792293266338772, "Avg loss": 0.6542810800019652, "Avg value loss": 0.30946903134463355, "Avg policy loss": 0.3448120531393215, "Total num played games": 28261, "Total num trained steps": 55936, "Timestamp in ms": 1699906316552, "logtype": "training_step"}
{"Total num played games": 28263, "Total num trained steps": 55982, "Timestamp in ms": 1699906427217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.71484375}
{"Avg objective": 21.265625, "Games time in secs": 218.69917459227145, "Avg game time in secs": 2.71427140609012, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.8, "agent_stopped_0": 0.5}, "Total num played games": 28288, "Total num trained steps": 55988, "Timestamp in ms": 1699906429861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980255024548762, "Avg loss": 0.9082552695181221, "Avg value loss": 0.5591883938177489, "Avg policy loss": 0.3490668742451817, "Total num played games": 28311, "Total num trained steps": 56064, "Timestamp in ms": 1699906471761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813469675599436, "Avg loss": 0.652441679732874, "Avg value loss": 0.3168120626360178, "Avg policy loss": 0.3356296147685498, "Total num played games": 28360, "Total num trained steps": 56192, "Timestamp in ms": 1699906532714, "logtype": "training_step"}
{"Avg objective": 22.9453125, "Games time in secs": 161.7193054370582, "Avg game time in secs": 2.5091313243756304, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.73, "agent_stopped_0": 0.47}, "Total num played games": 28416, "Total num trained steps": 56309, "Timestamp in ms": 1699906591580, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979021716213367, "Avg loss": 0.6724150783848017, "Avg value loss": 0.34387892577797174, "Avg policy loss": 0.32853614958003163, "Total num played games": 28458, "Total num trained steps": 56320, "Timestamp in ms": 1699906597308, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800406903325383, "Avg loss": 0.7758166049607098, "Avg value loss": 0.4312797990278341, "Avg policy loss": 0.3445368034299463, "Total num played games": 28508, "Total num trained steps": 56448, "Timestamp in ms": 1699906669042, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 110.76138228178024, "Avg game time in secs": 2.1774596648901934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 28544, "Total num trained steps": 56511, "Timestamp in ms": 1699906702342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810911128230269, "Avg loss": 0.6435451263096184, "Avg value loss": 0.31381921406136826, "Avg policy loss": 0.3297259147511795, "Total num played games": 28558, "Total num trained steps": 56576, "Timestamp in ms": 1699906739278, "logtype": "training_step"}
{"Total num played games": 28558, "Total num trained steps": 56583, "Timestamp in ms": 1699906837813, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.88671875}
{"Ratio train steps to played games": 1.9816523380163555, "Avg loss": 0.6407469543628395, "Avg value loss": 0.3007680594455451, "Avg policy loss": 0.3399788956157863, "Total num played games": 28613, "Total num trained steps": 56704, "Timestamp in ms": 1699906902764, "logtype": "training_step"}
{"Avg objective": 20.4296875, "Games time in secs": 252.20611926354468, "Avg game time in secs": 2.5873112598637817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.69, "agent_stopped_0": 0.48}, "Total num played games": 28672, "Total num trained steps": 56801, "Timestamp in ms": 1699906954548, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9798982720178373, "Avg loss": 0.8452784745022655, "Avg value loss": 0.5042990332003683, "Avg policy loss": 0.3409794431645423, "Total num played games": 28704, "Total num trained steps": 56832, "Timestamp in ms": 1699906971252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809758981671477, "Avg loss": 0.7733104398939759, "Avg value loss": 0.43855842237826437, "Avg policy loss": 0.3347520160023123, "Total num played games": 28753, "Total num trained steps": 56960, "Timestamp in ms": 1699907041045, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 111.55656336061656, "Avg game time in secs": 2.8901385086937808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.84}, "Total num played games": 28800, "Total num trained steps": 57006, "Timestamp in ms": 1699907066105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819810436412875, "Avg loss": 0.6617444425355643, "Avg value loss": 0.33003471308620647, "Avg policy loss": 0.33170972880907357, "Total num played games": 28803, "Total num trained steps": 57088, "Timestamp in ms": 1699907115083, "logtype": "training_step"}
{"Total num played games": 28852, "Total num trained steps": 57183, "Timestamp in ms": 1699907266182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.42578125}
{"Ratio train steps to played games": 1.979757785467128, "Avg loss": 0.6653336016461253, "Avg value loss": 0.3382305428967811, "Avg policy loss": 0.3271030536852777, "Total num played games": 28900, "Total num trained steps": 57216, "Timestamp in ms": 1699907283679, "logtype": "training_step"}
{"Avg objective": 23.171875, "Games time in secs": 260.0999063104391, "Avg game time in secs": 2.285850395594025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.56, "agent_stopped_0": 0.57}, "Total num played games": 28928, "Total num trained steps": 57295, "Timestamp in ms": 1699907326205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808628968185429, "Avg loss": 0.5930120986886322, "Avg value loss": 0.26453916978789493, "Avg policy loss": 0.32847292942460626, "Total num played games": 28949, "Total num trained steps": 57344, "Timestamp in ms": 1699907351089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981963651412215, "Avg loss": 0.5809935766737908, "Avg value loss": 0.25661290663992986, "Avg policy loss": 0.324380666250363, "Total num played games": 28997, "Total num trained steps": 57472, "Timestamp in ms": 1699907419797, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 153.11648779548705, "Avg game time in secs": 2.452266220760066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.7, "agent_stopped_0": 0.44}, "Total num played games": 29056, "Total num trained steps": 57586, "Timestamp in ms": 1699907479322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9796191916414627, "Avg loss": 0.6459554811008275, "Avg value loss": 0.321882838383317, "Avg policy loss": 0.32407263992354274, "Total num played games": 29096, "Total num trained steps": 57600, "Timestamp in ms": 1699907487025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9806827929318922, "Avg loss": 0.6652851747348905, "Avg value loss": 0.3456418795976788, "Avg policy loss": 0.31964329502079636, "Total num played games": 29145, "Total num trained steps": 57728, "Timestamp in ms": 1699907566012, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 123.79080089181662, "Avg game time in secs": 2.4714278193132486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.77}, "Total num played games": 29184, "Total num trained steps": 57785, "Timestamp in ms": 1699907603113, "logtype": "played_game"}
{"Total num played games": 29193, "Total num trained steps": 57785, "Timestamp in ms": 1699907702075, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.98046875}
{"Ratio train steps to played games": 1.9785917034301153, "Avg loss": 0.8307190639898181, "Avg value loss": 0.5066541566629894, "Avg policy loss": 0.324064907617867, "Total num played games": 29241, "Total num trained steps": 57856, "Timestamp in ms": 1699907741772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798545429712842, "Avg loss": 0.48125512851402164, "Avg value loss": 0.1734311446780339, "Avg policy loss": 0.3078239808091894, "Total num played games": 29287, "Total num trained steps": 57984, "Timestamp in ms": 1699907807029, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 248.24881783500314, "Avg game time in secs": 2.369708804122638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.61}, "Total num played games": 29312, "Total num trained steps": 58074, "Timestamp in ms": 1699907851362, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980674187940966, "Avg loss": 0.6650157640688121, "Avg value loss": 0.3561287675402127, "Avg policy loss": 0.3088869913481176, "Total num played games": 29339, "Total num trained steps": 58112, "Timestamp in ms": 1699907868036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98172723560637, "Avg loss": 0.5717564255464822, "Avg value loss": 0.2581629955675453, "Avg policy loss": 0.313593428931199, "Total num played games": 29388, "Total num trained steps": 58240, "Timestamp in ms": 1699907931216, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 137.11288278736174, "Avg game time in secs": 2.710470936304773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.82}, "Total num played games": 29440, "Total num trained steps": 58364, "Timestamp in ms": 1699907988475, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811954787685415, "Avg loss": 0.5618009308818728, "Avg value loss": 0.24046215729322284, "Avg policy loss": 0.32133876951411366, "Total num played games": 29459, "Total num trained steps": 58368, "Timestamp in ms": 1699907989821, "logtype": "training_step"}
{"Total num played games": 29487, "Total num trained steps": 58388, "Timestamp in ms": 1699908121566, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.3828125}
{"Ratio train steps to played games": 1.9805315727103436, "Avg loss": 0.7339668152853847, "Avg value loss": 0.40213120711268857, "Avg policy loss": 0.3318356170784682, "Total num played games": 29535, "Total num trained steps": 58496, "Timestamp in ms": 1699908174969, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 220.74541371501982, "Avg game time in secs": 2.246677532719332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.65}, "Total num played games": 29568, "Total num trained steps": 58564, "Timestamp in ms": 1699908209220, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981544701706946, "Avg loss": 0.678241889225319, "Avg value loss": 0.35799301019869745, "Avg policy loss": 0.3202488855458796, "Total num played games": 29585, "Total num trained steps": 58624, "Timestamp in ms": 1699908240546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825538233110616, "Avg loss": 0.6206106613390148, "Avg value loss": 0.31062394834589213, "Avg policy loss": 0.30998671520501375, "Total num played games": 29634, "Total num trained steps": 58752, "Timestamp in ms": 1699908301631, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 142.64519058540463, "Avg game time in secs": 2.8454164834256517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.8, "agent_stopped_0": 0.44}, "Total num played games": 29696, "Total num trained steps": 58859, "Timestamp in ms": 1699908351866, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980324229786089, "Avg loss": 0.8355048827361315, "Avg value loss": 0.5307522036018781, "Avg policy loss": 0.30475266685243696, "Total num played games": 29732, "Total num trained steps": 58880, "Timestamp in ms": 1699908360459, "logtype": "training_step"}
{"Total num played games": 29780, "Total num trained steps": 58987, "Timestamp in ms": 1699908487272, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1328125}
{"Avg objective": 21.96875, "Games time in secs": 140.76313882879913, "Avg game time in secs": 2.53025329108641, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.73}, "Total num played games": 29824, "Total num trained steps": 58997, "Timestamp in ms": 1699908492629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783082442082678, "Avg loss": 0.857098862528801, "Avg value loss": 0.5471452496130951, "Avg policy loss": 0.30995361343957484, "Total num played games": 29827, "Total num trained steps": 59008, "Timestamp in ms": 1699908497582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825667158374682, "Avg loss": 0.527008940698579, "Avg value loss": 0.22121039760531858, "Avg policy loss": 0.30579854641109705, "Total num played games": 29828, "Total num trained steps": 59136, "Timestamp in ms": 1699908558155, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803515337833322, "Avg loss": 0.6672832362819463, "Avg value loss": 0.37099629949079826, "Avg policy loss": 0.296286933706142, "Total num played games": 29926, "Total num trained steps": 59264, "Timestamp in ms": 1699908613570, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 157.6759221572429, "Avg game time in secs": 1.9117915112437913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.52, "agent_stopped_0": 0.59}, "Total num played games": 29952, "Total num trained steps": 59346, "Timestamp in ms": 1699908650305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813511259382819, "Avg loss": 0.6377376057207584, "Avg value loss": 0.34146751277148724, "Avg policy loss": 0.29627008689567447, "Total num played games": 29975, "Total num trained steps": 59392, "Timestamp in ms": 1699908670905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822820222473856, "Avg loss": 0.594600593438372, "Avg value loss": 0.30012220109347254, "Avg policy loss": 0.29447838896885514, "Total num played games": 30026, "Total num trained steps": 59520, "Timestamp in ms": 1699908728613, "logtype": "training_step"}
{"Total num played games": 30075, "Total num trained steps": 59588, "Timestamp in ms": 1699908838196, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.390625}
{"Avg objective": 21.0703125, "Games time in secs": 189.6241945065558, "Avg game time in secs": 2.7673524859856116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.82}, "Total num played games": 30080, "Total num trained steps": 59592, "Timestamp in ms": 1699908839929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801148623975036, "Avg loss": 0.7787507954053581, "Avg value loss": 0.4717978033586405, "Avg policy loss": 0.30695299338549376, "Total num played games": 30123, "Total num trained steps": 59648, "Timestamp in ms": 1699908863493, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981141455654249, "Avg loss": 0.5774898822419345, "Avg value loss": 0.280011338472832, "Avg policy loss": 0.2974785481346771, "Total num played games": 30172, "Total num trained steps": 59776, "Timestamp in ms": 1699908921670, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 111.67651900649071, "Avg game time in secs": 2.1308213415468344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.55}, "Total num played games": 30208, "Total num trained steps": 59840, "Timestamp in ms": 1699908951606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821647198967605, "Avg loss": 0.5881494043860584, "Avg value loss": 0.2909738402813673, "Avg policy loss": 0.2971755613107234, "Total num played games": 30221, "Total num trained steps": 59904, "Timestamp in ms": 1699908981005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823008849557522, "Avg loss": 0.7070647643413395, "Avg value loss": 0.40755462378729135, "Avg policy loss": 0.29951013904064894, "Total num played games": 30282, "Total num trained steps": 60032, "Timestamp in ms": 1699909038755, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 131.60143479704857, "Avg game time in secs": 2.184798336122185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.62, "agent_stopped_0": 0.52}, "Total num played games": 30336, "Total num trained steps": 60130, "Timestamp in ms": 1699909083208, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810326659641728, "Avg loss": 0.6763682472519577, "Avg value loss": 0.3789644505013712, "Avg policy loss": 0.29740379576105624, "Total num played games": 30368, "Total num trained steps": 60160, "Timestamp in ms": 1699909096419, "logtype": "training_step"}
{"Total num played games": 30368, "Total num trained steps": 60189, "Timestamp in ms": 1699909187018, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.64453125}
{"Ratio train steps to played games": 1.9820817990531299, "Avg loss": 0.6353438331279904, "Avg value loss": 0.3330804178840481, "Avg policy loss": 0.30226341378875077, "Total num played games": 30416, "Total num trained steps": 60288, "Timestamp in ms": 1699909233464, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 170.52105828002095, "Avg game time in secs": 2.5245790752378525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.77, "agent_stopped_0": 0.38}, "Total num played games": 30464, "Total num trained steps": 60333, "Timestamp in ms": 1699909253729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830953553257837, "Avg loss": 0.5799647264648229, "Avg value loss": 0.27712113654706627, "Avg policy loss": 0.302843586076051, "Total num played games": 30465, "Total num trained steps": 60416, "Timestamp in ms": 1699909291111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807950269916572, "Avg loss": 0.7190214309375733, "Avg value loss": 0.4179679023800418, "Avg policy loss": 0.30105352436657995, "Total num played games": 30565, "Total num trained steps": 60544, "Timestamp in ms": 1699909346836, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 129.73296208679676, "Avg game time in secs": 1.9270720977219753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 30592, "Total num trained steps": 60623, "Timestamp in ms": 1699909383462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981708910373661, "Avg loss": 0.6380781577900052, "Avg value loss": 0.3412115431856364, "Avg policy loss": 0.2968666162341833, "Total num played games": 30616, "Total num trained steps": 60672, "Timestamp in ms": 1699909404564, "logtype": "training_step"}
{"Total num played games": 30665, "Total num trained steps": 60792, "Timestamp in ms": 1699909535805, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.67578125}
{"Ratio train steps to played games": 1.9803915181915899, "Avg loss": 0.5580733178649098, "Avg value loss": 0.2618049055454321, "Avg policy loss": 0.2962684138910845, "Total num played games": 30700, "Total num trained steps": 60800, "Timestamp in ms": 1699909538907, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 208.9908798597753, "Avg game time in secs": 2.267026800196618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.67}, "Total num played games": 30720, "Total num trained steps": 60917, "Timestamp in ms": 1699909592453, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806898345307369, "Avg loss": 0.5757181977387518, "Avg value loss": 0.27991578116780147, "Avg policy loss": 0.2958024200052023, "Total num played games": 30761, "Total num trained steps": 60928, "Timestamp in ms": 1699909596567, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815656237829418, "Avg loss": 0.7808620636351407, "Avg value loss": 0.486059655144345, "Avg policy loss": 0.2948024101788178, "Total num played games": 30812, "Total num trained steps": 61056, "Timestamp in ms": 1699909662391, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 99.89573052339256, "Avg game time in secs": 2.138091234723106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.63}, "Total num played games": 30848, "Total num trained steps": 61118, "Timestamp in ms": 1699909692349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820850071271219, "Avg loss": 0.6447089863941073, "Avg value loss": 0.33970173640409485, "Avg policy loss": 0.3050072529586032, "Total num played games": 30868, "Total num trained steps": 61184, "Timestamp in ms": 1699909724773, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831478845905033, "Avg loss": 0.5798824117518961, "Avg value loss": 0.2821393405320123, "Avg policy loss": 0.2977430745959282, "Total num played games": 30916, "Total num trained steps": 61312, "Timestamp in ms": 1699909795148, "logtype": "training_step"}
{"Total num played games": 30965, "Total num trained steps": 61392, "Timestamp in ms": 1699909915471, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.5390625}
{"Avg objective": 20.0859375, "Games time in secs": 224.9463628679514, "Avg game time in secs": 2.152792480948847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.57}, "Total num played games": 30976, "Total num trained steps": 61395, "Timestamp in ms": 1699909917296, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811046980298586, "Avg loss": 0.700519724516198, "Avg value loss": 0.4019341313978657, "Avg policy loss": 0.29858560441061854, "Total num played games": 31013, "Total num trained steps": 61440, "Timestamp in ms": 1699909939031, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821641286500757, "Avg loss": 0.6539868386462331, "Avg value loss": 0.36326038383413106, "Avg policy loss": 0.2907264508539811, "Total num played games": 31061, "Total num trained steps": 61568, "Timestamp in ms": 1699909998980, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 106.8699672948569, "Avg game time in secs": 2.3402293056278722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.66}, "Total num played games": 31104, "Total num trained steps": 61618, "Timestamp in ms": 1699910024166, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831881449098332, "Avg loss": 0.5755837387405336, "Avg value loss": 0.28592846961691976, "Avg policy loss": 0.28965526504907757, "Total num played games": 31109, "Total num trained steps": 61696, "Timestamp in ms": 1699910063879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808400884303612, "Avg loss": 0.747534240828827, "Avg value loss": 0.4528444691095501, "Avg policy loss": 0.29468977462965995, "Total num played games": 31211, "Total num trained steps": 61824, "Timestamp in ms": 1699910124765, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 147.35121455043554, "Avg game time in secs": 2.3776717164873844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.72, "agent_stopped_0": 0.46}, "Total num played games": 31232, "Total num trained steps": 61919, "Timestamp in ms": 1699910171517, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816710383212846, "Avg loss": 0.977830670773983, "Avg value loss": 0.6564031060552225, "Avg policy loss": 0.3214275765931234, "Total num played games": 31262, "Total num trained steps": 61952, "Timestamp in ms": 1699910187632, "logtype": "training_step"}
{"Total num played games": 31262, "Total num trained steps": 61995, "Timestamp in ms": 1699910286774, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.87890625}
{"Ratio train steps to played games": 1.9827211753433407, "Avg loss": 0.6739549424964935, "Avg value loss": 0.3542661680839956, "Avg policy loss": 0.319688776275143, "Total num played games": 31310, "Total num trained steps": 62080, "Timestamp in ms": 1699910333787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837367262986703, "Avg loss": 0.610822576796636, "Avg value loss": 0.3006204246194102, "Avg policy loss": 0.31020216329488903, "Total num played games": 31359, "Total num trained steps": 62208, "Timestamp in ms": 1699910400977, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 229.6870516743511, "Avg game time in secs": 2.3447272537305253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.74, "agent_stopped_0": 0.43}, "Total num played games": 31360, "Total num trained steps": 62208, "Timestamp in ms": 1699910401204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816569175991863, "Avg loss": 0.7155598804820329, "Avg value loss": 0.4134523386019282, "Avg policy loss": 0.3021075400756672, "Total num played games": 31456, "Total num trained steps": 62336, "Timestamp in ms": 1699910468226, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 104.88233872875571, "Avg game time in secs": 1.9270318838971434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.49}, "Total num played games": 31488, "Total num trained steps": 62405, "Timestamp in ms": 1699910506087, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982574747667111, "Avg loss": 0.7164789759553969, "Avg value loss": 0.405385835270863, "Avg policy loss": 0.31109314609784633, "Total num played games": 31506, "Total num trained steps": 62464, "Timestamp in ms": 1699910538391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836153894910313, "Avg loss": 0.895806975197047, "Avg value loss": 0.5891113034449518, "Avg policy loss": 0.3066956641850993, "Total num played games": 31554, "Total num trained steps": 62592, "Timestamp in ms": 1699910607121, "logtype": "training_step"}
{"Total num played games": 31602, "Total num trained steps": 62598, "Timestamp in ms": 1699910683298, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.515625}
{"Avg objective": 22.453125, "Games time in secs": 179.76642301864922, "Avg game time in secs": 2.2323988549178466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 31616, "Total num trained steps": 62600, "Timestamp in ms": 1699910685853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816429699842022, "Avg loss": 0.7566182240843773, "Avg value loss": 0.439899371820502, "Avg policy loss": 0.3167188510997221, "Total num played games": 31650, "Total num trained steps": 62720, "Timestamp in ms": 1699910754328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826177481939493, "Avg loss": 0.6427957667037845, "Avg value loss": 0.3472759567666799, "Avg policy loss": 0.2955198005074635, "Total num played games": 31699, "Total num trained steps": 62848, "Timestamp in ms": 1699910827589, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 165.56352077797055, "Avg game time in secs": 2.0517554737452883, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.56}, "Total num played games": 31744, "Total num trained steps": 62899, "Timestamp in ms": 1699910851417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836210154970393, "Avg loss": 0.5874711517244577, "Avg value loss": 0.2845295254373923, "Avg policy loss": 0.3029416184872389, "Total num played games": 31748, "Total num trained steps": 62976, "Timestamp in ms": 1699910885104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815047415687999, "Avg loss": 0.7585112364031374, "Avg value loss": 0.460444113065023, "Avg policy loss": 0.2980671206023544, "Total num played games": 31846, "Total num trained steps": 63104, "Timestamp in ms": 1699910951488, "logtype": "training_step"}
{"Avg objective": 22.921875, "Games time in secs": 138.47659858316183, "Avg game time in secs": 2.0537193651107373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 31872, "Total num trained steps": 63185, "Timestamp in ms": 1699910989894, "logtype": "played_game"}
{"Total num played games": 31895, "Total num trained steps": 63200, "Timestamp in ms": 1699911083534, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.3046875}
{"Ratio train steps to played games": 1.9795260307422597, "Avg loss": 0.8193319924175739, "Avg value loss": 0.5121670932276174, "Avg policy loss": 0.30716489674523473, "Total num played games": 31943, "Total num trained steps": 63232, "Timestamp in ms": 1699911100320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835018626929217, "Avg loss": 0.4938230237457901, "Avg value loss": 0.18764892063336447, "Avg policy loss": 0.3061741068959236, "Total num played games": 31943, "Total num trained steps": 63360, "Timestamp in ms": 1699911170069, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 236.60856240987778, "Avg game time in secs": 2.116529719423852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.64}, "Total num played games": 32000, "Total num trained steps": 63475, "Timestamp in ms": 1699911226502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816467944316125, "Avg loss": 0.8518567199353129, "Avg value loss": 0.5400794148445129, "Avg policy loss": 0.3117772970581427, "Total num played games": 32038, "Total num trained steps": 63488, "Timestamp in ms": 1699911231506, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823932689311312, "Avg loss": 0.775615609716624, "Avg value loss": 0.4569652231875807, "Avg policy loss": 0.3186503815231845, "Total num played games": 32090, "Total num trained steps": 63616, "Timestamp in ms": 1699911298007, "logtype": "training_step"}
{"Avg objective": 22.7265625, "Games time in secs": 98.24256395921111, "Avg game time in secs": 2.14810132853745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.73}, "Total num played games": 32128, "Total num trained steps": 63673, "Timestamp in ms": 1699911324745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834463874541042, "Avg loss": 0.7875910368748009, "Avg value loss": 0.4595155820134096, "Avg policy loss": 0.32807546644471586, "Total num played games": 32138, "Total num trained steps": 63744, "Timestamp in ms": 1699911364747, "logtype": "training_step"}
{"Total num played games": 32187, "Total num trained steps": 63802, "Timestamp in ms": 1699911480695, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.49609375}
{"Ratio train steps to played games": 1.9814177136652706, "Avg loss": 0.698036806890741, "Avg value loss": 0.3672305660438724, "Avg policy loss": 0.3308062452124432, "Total num played games": 32235, "Total num trained steps": 63872, "Timestamp in ms": 1699911519532, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 242.52449027448893, "Avg game time in secs": 1.8498899299302138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.48, "agent_stopped_0": 0.62}, "Total num played games": 32256, "Total num trained steps": 63962, "Timestamp in ms": 1699911567270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824365765263452, "Avg loss": 0.6236568472813815, "Avg value loss": 0.31427208485547453, "Avg policy loss": 0.30938476661685854, "Total num played games": 32283, "Total num trained steps": 64000, "Timestamp in ms": 1699911587745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834219967833726, "Avg loss": 0.553271577693522, "Avg value loss": 0.23804709903197363, "Avg policy loss": 0.3152244770899415, "Total num played games": 32332, "Total num trained steps": 64128, "Timestamp in ms": 1699911653114, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 150.84642208740115, "Avg game time in secs": 1.9561331665172474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.59}, "Total num played games": 32384, "Total num trained steps": 64251, "Timestamp in ms": 1699911718116, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819555829734732, "Avg loss": 0.5181380729191005, "Avg value loss": 0.220073314209003, "Avg policy loss": 0.298064753995277, "Total num played games": 32420, "Total num trained steps": 64256, "Timestamp in ms": 1699911720741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823572880103455, "Avg loss": 0.912993541220203, "Avg value loss": 0.601142831495963, "Avg policy loss": 0.3118507098406553, "Total num played games": 32478, "Total num trained steps": 64384, "Timestamp in ms": 1699911789217, "logtype": "training_step"}
{"Total num played games": 32478, "Total num trained steps": 64402, "Timestamp in ms": 1699911882495, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.25390625}
{"Avg objective": 21.078125, "Games time in secs": 168.37638590857387, "Avg game time in secs": 2.1095897710329155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.67}, "Total num played games": 32512, "Total num trained steps": 64409, "Timestamp in ms": 1699911886493, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833671524319005, "Avg loss": 0.5968059976585209, "Avg value loss": 0.28930592437973246, "Avg policy loss": 0.3075000732205808, "Total num played games": 32526, "Total num trained steps": 64512, "Timestamp in ms": 1699911945093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831564091550593, "Avg loss": 0.5598730312194675, "Avg value loss": 0.26372633344726637, "Avg policy loss": 0.29614669631700963, "Total num played games": 32594, "Total num trained steps": 64640, "Timestamp in ms": 1699912012602, "logtype": "training_step"}
{"Avg objective": 22.0234375, "Games time in secs": 180.98391998372972, "Avg game time in secs": 2.0665896739374148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.68, "agent_stopped_0": 0.48}, "Total num played games": 32640, "Total num trained steps": 64738, "Timestamp in ms": 1699912067477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823396180215476, "Avg loss": 0.7691899093333632, "Avg value loss": 0.46686679078266025, "Avg policy loss": 0.3023231172701344, "Total num played games": 32672, "Total num trained steps": 64768, "Timestamp in ms": 1699912082864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833134684147795, "Avg loss": 0.5644770234357566, "Avg value loss": 0.27026601013494655, "Avg policy loss": 0.2942110124276951, "Total num played games": 32721, "Total num trained steps": 64896, "Timestamp in ms": 1699912145599, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 106.78673509135842, "Avg game time in secs": 2.2098821624240372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.73}, "Total num played games": 32768, "Total num trained steps": 64943, "Timestamp in ms": 1699912174264, "logtype": "played_game"}
{"Total num played games": 32769, "Total num trained steps": 65004, "Timestamp in ms": 1699912288454, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.11328125}
{"Ratio train steps to played games": 1.9814120730109395, "Avg loss": 0.7569632341619581, "Avg value loss": 0.4683357839821838, "Avg policy loss": 0.2886274423217401, "Total num played games": 32817, "Total num trained steps": 65024, "Timestamp in ms": 1699912299208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823221566360372, "Avg loss": 0.6527707499917597, "Avg value loss": 0.35644824692280963, "Avg policy loss": 0.29632250883150846, "Total num played games": 32866, "Total num trained steps": 65152, "Timestamp in ms": 1699912368700, "logtype": "training_step"}
{"Avg objective": 23.34375, "Games time in secs": 233.09538264386356, "Avg game time in secs": 1.669708702742355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.5, "agent_stopped_0": 0.6}, "Total num played games": 32896, "Total num trained steps": 65224, "Timestamp in ms": 1699912407359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983259911894273, "Avg loss": 0.6590001210570335, "Avg value loss": 0.36033154133474454, "Avg policy loss": 0.2986685826908797, "Total num played games": 32915, "Total num trained steps": 65280, "Timestamp in ms": 1699912436963, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842252153864823, "Avg loss": 0.5702494364231825, "Avg value loss": 0.2684927698574029, "Avg policy loss": 0.3017566680209711, "Total num played games": 32964, "Total num trained steps": 65408, "Timestamp in ms": 1699912509117, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 162.9854980353266, "Avg game time in secs": 1.9562602841760963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.57}, "Total num played games": 33024, "Total num trained steps": 65516, "Timestamp in ms": 1699912570345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821849857842841, "Avg loss": 0.7400269026402384, "Avg value loss": 0.4364899139618501, "Avg policy loss": 0.3035369887948036, "Total num played games": 33062, "Total num trained steps": 65536, "Timestamp in ms": 1699912581107, "logtype": "training_step"}
{"Total num played games": 33062, "Total num trained steps": 65607, "Timestamp in ms": 1699912693645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.40234375}
{"Ratio train steps to played games": 1.9831772878284506, "Avg loss": 0.5939108349848539, "Avg value loss": 0.2888968644547276, "Avg policy loss": 0.305013972800225, "Total num played games": 33110, "Total num trained steps": 65664, "Timestamp in ms": 1699912725996, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 186.63801229558885, "Avg game time in secs": 2.027007044031052, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.66}, "Total num played games": 33152, "Total num trained steps": 65713, "Timestamp in ms": 1699912756983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841968755654744, "Avg loss": 0.6566000108141452, "Avg value loss": 0.34867381543153897, "Avg policy loss": 0.30792619625572115, "Total num played games": 33158, "Total num trained steps": 65792, "Timestamp in ms": 1699912807722, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817514956558338, "Avg loss": 0.6798956217244267, "Avg value loss": 0.3709707931848243, "Avg policy loss": 0.30892483331263065, "Total num played games": 33263, "Total num trained steps": 65920, "Timestamp in ms": 1699912878225, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 173.72511930018663, "Avg game time in secs": 1.85295436171873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 33280, "Total num trained steps": 66018, "Timestamp in ms": 1699912930709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982619397832678, "Avg loss": 0.6306728890631348, "Avg value loss": 0.3283879533992149, "Avg policy loss": 0.30228493025060743, "Total num played games": 33313, "Total num trained steps": 66048, "Timestamp in ms": 1699912946909, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983544152029255, "Avg loss": 0.676861414918676, "Avg value loss": 0.37206610589055344, "Avg policy loss": 0.30479530966840684, "Total num played games": 33362, "Total num trained steps": 66176, "Timestamp in ms": 1699913016013, "logtype": "training_step"}
{"Total num played games": 33362, "Total num trained steps": 66210, "Timestamp in ms": 1699913116176, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.390625}
{"Avg objective": 21.9375, "Games time in secs": 191.5252693220973, "Avg game time in secs": 2.1591663321160013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.78}, "Total num played games": 33408, "Total num trained steps": 66221, "Timestamp in ms": 1699913122234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845255911403772, "Avg loss": 0.6994868726469576, "Avg value loss": 0.3817995929857716, "Avg policy loss": 0.31768728140741587, "Total num played games": 33410, "Total num trained steps": 66304, "Timestamp in ms": 1699913167959, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825414826310135, "Avg loss": 0.8564781767781824, "Avg value loss": 0.533510799985379, "Avg policy loss": 0.3229673742316663, "Total num played games": 33508, "Total num trained steps": 66432, "Timestamp in ms": 1699913226481, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 142.8511041160673, "Avg game time in secs": 1.7613894736859947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.52, "agent_stopped_0": 0.6}, "Total num played games": 33536, "Total num trained steps": 66509, "Timestamp in ms": 1699913265085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834609768453675, "Avg loss": 0.6435709849465638, "Avg value loss": 0.32947323517873883, "Avg policy loss": 0.3140977459261194, "Total num played games": 33557, "Total num trained steps": 66560, "Timestamp in ms": 1699913291160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844075462714992, "Avg loss": 0.9281268655322492, "Avg value loss": 0.6211739343125373, "Avg policy loss": 0.30695293797180057, "Total num played games": 33606, "Total num trained steps": 66688, "Timestamp in ms": 1699913356196, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 150.44175395555794, "Avg game time in secs": 2.020459373743506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.67, "agent_stopped_0": 0.5}, "Total num played games": 33664, "Total num trained steps": 66807, "Timestamp in ms": 1699913415527, "logtype": "played_game"}
{"Total num played games": 33707, "Total num trained steps": 66812, "Timestamp in ms": 1699913487984, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.69140625}
{"Ratio train steps to played games": 1.98184730379071, "Avg loss": 0.6674308716319501, "Avg value loss": 0.36027881485642865, "Avg policy loss": 0.307152054971084, "Total num played games": 33713, "Total num trained steps": 66816, "Timestamp in ms": 1699913489931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832024885202193, "Avg loss": 0.7265145536512136, "Avg value loss": 0.400225990335457, "Avg policy loss": 0.3262885636650026, "Total num played games": 33755, "Total num trained steps": 66944, "Timestamp in ms": 1699913549934, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 164.71363181620836, "Avg game time in secs": 1.843274562546867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.59}, "Total num played games": 33792, "Total num trained steps": 67005, "Timestamp in ms": 1699913580241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841438882972429, "Avg loss": 0.6004279404878616, "Avg value loss": 0.2875219127163291, "Avg policy loss": 0.31290603056550026, "Total num played games": 33804, "Total num trained steps": 67072, "Timestamp in ms": 1699913612365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848475897920606, "Avg loss": 0.8186257383786142, "Avg value loss": 0.4919439621735364, "Avg policy loss": 0.3266817642142996, "Total num played games": 33856, "Total num trained steps": 67200, "Timestamp in ms": 1699913674889, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 144.95151040703058, "Avg game time in secs": 1.867315782015794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 33920, "Total num trained steps": 67305, "Timestamp in ms": 1699913725193, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982859667206597, "Avg loss": 0.705102160340175, "Avg value loss": 0.3752620096784085, "Avg policy loss": 0.32984014495741576, "Total num played games": 33955, "Total num trained steps": 67328, "Timestamp in ms": 1699913735994, "logtype": "training_step"}
{"Total num played games": 34004, "Total num trained steps": 67416, "Timestamp in ms": 1699913855101, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3046875}
{"Avg objective": 20.5703125, "Games time in secs": 134.44015330262482, "Avg game time in secs": 1.7215072650287766, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 34048, "Total num trained steps": 67425, "Timestamp in ms": 1699913859633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9809702807470926, "Avg loss": 0.9218370169401169, "Avg value loss": 0.5952824577107094, "Avg policy loss": 0.32655455626081675, "Total num played games": 34052, "Total num trained steps": 67456, "Timestamp in ms": 1699913876405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984699870785857, "Avg loss": 0.49734067381359637, "Avg value loss": 0.17780691338703036, "Avg policy loss": 0.3195337583310902, "Total num played games": 34052, "Total num trained steps": 67584, "Timestamp in ms": 1699913945932, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824042627942382, "Avg loss": 0.8759170956909657, "Avg value loss": 0.5525675438111648, "Avg policy loss": 0.32334955618716776, "Total num played games": 34156, "Total num trained steps": 67712, "Timestamp in ms": 1699914014905, "logtype": "training_step"}
{"Avg objective": 22.265625, "Games time in secs": 203.15745095908642, "Avg game time in secs": 1.788655909243971, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.53, "agent_stopped_0": 0.53}, "Total num played games": 34176, "Total num trained steps": 67805, "Timestamp in ms": 1699914062791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833065341324367, "Avg loss": 0.7863181421998888, "Avg value loss": 0.4632645191741176, "Avg policy loss": 0.3230536178452894, "Total num played games": 34205, "Total num trained steps": 67840, "Timestamp in ms": 1699914077481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984206224090617, "Avg loss": 0.7147322779055685, "Avg value loss": 0.3918934382381849, "Avg policy loss": 0.32283883600030094, "Total num played games": 34254, "Total num trained steps": 67968, "Timestamp in ms": 1699914136476, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 93.83403791859746, "Avg game time in secs": 2.019452035674476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 34304, "Total num trained steps": 68011, "Timestamp in ms": 1699914156625, "logtype": "played_game"}
{"Total num played games": 34304, "Total num trained steps": 68017, "Timestamp in ms": 1699914229079, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.171875}
{"Ratio train steps to played games": 1.9822717745691663, "Avg loss": 0.7110710749402642, "Avg value loss": 0.37584988214075565, "Avg policy loss": 0.33522119419649243, "Total num played games": 34352, "Total num trained steps": 68096, "Timestamp in ms": 1699914271887, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982996163236833, "Avg loss": 0.6083372833672911, "Avg value loss": 0.28573836578289047, "Avg policy loss": 0.3225989161292091, "Total num played games": 34404, "Total num trained steps": 68224, "Timestamp in ms": 1699914339919, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 226.96078721992671, "Avg game time in secs": 1.696511336689582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.62}, "Total num played games": 34432, "Total num trained steps": 68298, "Timestamp in ms": 1699914383586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839486822245442, "Avg loss": 0.556140904314816, "Avg value loss": 0.22643463901476935, "Avg policy loss": 0.3297062620986253, "Total num played games": 34452, "Total num trained steps": 68352, "Timestamp in ms": 1699914412880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848985507246377, "Avg loss": 0.5505470489151776, "Avg value loss": 0.22389948897762224, "Avg policy loss": 0.326647563255392, "Total num played games": 34500, "Total num trained steps": 68480, "Timestamp in ms": 1699914478412, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 150.43142166733742, "Avg game time in secs": 1.90379002597183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 34560, "Total num trained steps": 68589, "Timestamp in ms": 1699914534017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829758945603793, "Avg loss": 0.6193560063838959, "Avg value loss": 0.30047651421045884, "Avg policy loss": 0.3188794911839068, "Total num played games": 34598, "Total num trained steps": 68608, "Timestamp in ms": 1699914543901, "logtype": "training_step"}
{"Total num played games": 34598, "Total num trained steps": 68617, "Timestamp in ms": 1699914614782, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.18359375}
{"Ratio train steps to played games": 1.9839231080066964, "Avg loss": 0.6562828414607793, "Avg value loss": 0.3346102630603127, "Avg policy loss": 0.32167257205583155, "Total num played games": 34646, "Total num trained steps": 68736, "Timestamp in ms": 1699914683161, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 177.39846803434193, "Avg game time in secs": 1.9238626397273038, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.62}, "Total num played games": 34688, "Total num trained steps": 68786, "Timestamp in ms": 1699914711416, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848393140221934, "Avg loss": 0.5352039174176753, "Avg value loss": 0.22299937455682084, "Avg policy loss": 0.3122045452473685, "Total num played games": 34695, "Total num trained steps": 68864, "Timestamp in ms": 1699914755759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982898858965884, "Avg loss": 0.7532503923866898, "Avg value loss": 0.4370957360952161, "Avg policy loss": 0.316154652624391, "Total num played games": 34793, "Total num trained steps": 68992, "Timestamp in ms": 1699914825045, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 156.9533292800188, "Avg game time in secs": 1.6921935994032538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.6, "agent_stopped_0": 0.51}, "Total num played games": 34816, "Total num trained steps": 69078, "Timestamp in ms": 1699914868369, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838695789443472, "Avg loss": 0.7271887224633247, "Avg value loss": 0.4036531823221594, "Avg policy loss": 0.32353553792927414, "Total num played games": 34841, "Total num trained steps": 69120, "Timestamp in ms": 1699914888268, "logtype": "training_step"}
{"Total num played games": 34890, "Total num trained steps": 69219, "Timestamp in ms": 1699915003773, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.78125}
{"Ratio train steps to played games": 1.9820253019634781, "Avg loss": 0.7488436484709382, "Avg value loss": 0.4215007707825862, "Avg policy loss": 0.3273428870597854, "Total num played games": 34938, "Total num trained steps": 69248, "Timestamp in ms": 1699915021543, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 209.15956236422062, "Avg game time in secs": 1.814909558641375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 34944, "Total num trained steps": 69367, "Timestamp in ms": 1699915077529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829079372338296, "Avg loss": 0.5239941822364926, "Avg value loss": 0.20639676850987598, "Avg policy loss": 0.3175974184414372, "Total num played games": 34987, "Total num trained steps": 69376, "Timestamp in ms": 1699915082481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838161838161839, "Avg loss": 0.9092372362501919, "Avg value loss": 0.5911580401007086, "Avg policy loss": 0.3180791902123019, "Total num played games": 35035, "Total num trained steps": 69504, "Timestamp in ms": 1699915151186, "logtype": "training_step"}
{"Avg objective": 23.71875, "Games time in secs": 104.68031655810773, "Avg game time in secs": 1.589394246941083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 35072, "Total num trained steps": 69560, "Timestamp in ms": 1699915182210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846938775510203, "Avg loss": 0.762868785765022, "Avg value loss": 0.43551666801795363, "Avg policy loss": 0.3273521176306531, "Total num played games": 35084, "Total num trained steps": 69632, "Timestamp in ms": 1699915223928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831139665122097, "Avg loss": 0.5294022981543094, "Avg value loss": 0.21821889840066433, "Avg policy loss": 0.3111834052251652, "Total num played games": 35177, "Total num trained steps": 69760, "Timestamp in ms": 1699915293748, "logtype": "training_step"}
{"Total num played games": 35181, "Total num trained steps": 69823, "Timestamp in ms": 1699915378231, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0859375}
{"Avg objective": 22.1640625, "Games time in secs": 198.26001853123307, "Avg game time in secs": 1.6366225465608295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 35200, "Total num trained steps": 69828, "Timestamp in ms": 1699915380470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983791762468421, "Avg loss": 0.7923219094518572, "Avg value loss": 0.45476549403974786, "Avg policy loss": 0.3375564075540751, "Total num played games": 35229, "Total num trained steps": 69888, "Timestamp in ms": 1699915408906, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846084072677797, "Avg loss": 0.6918780917767435, "Avg value loss": 0.36353116104146466, "Avg policy loss": 0.3283469247398898, "Total num played games": 35279, "Total num trained steps": 70016, "Timestamp in ms": 1699915474659, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 112.05551702529192, "Avg game time in secs": 1.8104791673395084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.78, "agent_stopped_0": 0.34}, "Total num played games": 35328, "Total num trained steps": 70053, "Timestamp in ms": 1699915492526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852541605343599, "Avg loss": 0.6634280488360673, "Avg value loss": 0.34420681034680456, "Avg policy loss": 0.31922124547418207, "Total num played games": 35332, "Total num trained steps": 70144, "Timestamp in ms": 1699915539723, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834038950042336, "Avg loss": 0.7249497314915061, "Avg value loss": 0.4096255204640329, "Avg policy loss": 0.3153242120752111, "Total num played games": 35430, "Total num trained steps": 70272, "Timestamp in ms": 1699915600444, "logtype": "training_step"}
{"Avg objective": 22.4765625, "Games time in secs": 148.72127711214125, "Avg game time in secs": 1.6375081647420302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 35456, "Total num trained steps": 70352, "Timestamp in ms": 1699915641247, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841882750845548, "Avg loss": 0.6919465323444456, "Avg value loss": 0.37696243409300223, "Avg policy loss": 0.31498409365303814, "Total num played games": 35480, "Total num trained steps": 70400, "Timestamp in ms": 1699915664697, "logtype": "training_step"}
{"Total num played games": 35480, "Total num trained steps": 70424, "Timestamp in ms": 1699915773610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.796875}
{"Ratio train steps to played games": 1.985138482323801, "Avg loss": 0.6043217163532972, "Avg value loss": 0.28888010169612244, "Avg policy loss": 0.31544162426143885, "Total num played games": 35528, "Total num trained steps": 70528, "Timestamp in ms": 1699915824737, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 244.87060806527734, "Avg game time in secs": 1.694852164524491, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 35584, "Total num trained steps": 70651, "Timestamp in ms": 1699915886118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983855117225888, "Avg loss": 0.5612107969354838, "Avg value loss": 0.25194383261259645, "Avg policy loss": 0.3092669601319358, "Total num played games": 35614, "Total num trained steps": 70656, "Timestamp in ms": 1699915887815, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839677111945737, "Avg loss": 0.677595142275095, "Avg value loss": 0.3528967357124202, "Avg policy loss": 0.3246984080178663, "Total num played games": 35678, "Total num trained steps": 70784, "Timestamp in ms": 1699915950445, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 98.27333308570087, "Avg game time in secs": 1.7320714471279643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.67}, "Total num played games": 35712, "Total num trained steps": 70849, "Timestamp in ms": 1699915984391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984829400733339, "Avg loss": 0.6950964792631567, "Avg value loss": 0.37172691943123937, "Avg policy loss": 0.3233695555245504, "Total num played games": 35727, "Total num trained steps": 70912, "Timestamp in ms": 1699916016179, "logtype": "training_step"}
{"Total num played games": 35776, "Total num trained steps": 71027, "Timestamp in ms": 1699916143926, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.875}
{"Ratio train steps to played games": 1.9830002233139794, "Avg loss": 0.6428751565981656, "Avg value loss": 0.3201139007578604, "Avg policy loss": 0.32276125880889595, "Total num played games": 35824, "Total num trained steps": 71040, "Timestamp in ms": 1699916149881, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 211.22351476177573, "Avg game time in secs": 1.6747971598088043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 35840, "Total num trained steps": 71139, "Timestamp in ms": 1699916195615, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838597273715608, "Avg loss": 0.6159972110763192, "Avg value loss": 0.3042735768831335, "Avg policy loss": 0.31172363355290145, "Total num played games": 35873, "Total num trained steps": 71168, "Timestamp in ms": 1699916208034, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847168865876066, "Avg loss": 0.5773382515180856, "Avg value loss": 0.27105185959953815, "Avg policy loss": 0.30628639040514827, "Total num played games": 35922, "Total num trained steps": 71296, "Timestamp in ms": 1699916265272, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 89.18173301033676, "Avg game time in secs": 1.7199106435873546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.66}, "Total num played games": 35968, "Total num trained steps": 71341, "Timestamp in ms": 1699916284797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855717105446054, "Avg loss": 0.6561395730823278, "Avg value loss": 0.3424048798624426, "Avg policy loss": 0.31373469170648605, "Total num played games": 35971, "Total num trained steps": 71424, "Timestamp in ms": 1699916322722, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836156469185773, "Avg loss": 0.730457644443959, "Avg value loss": 0.42081576801138, "Avg policy loss": 0.3096418749773875, "Total num played games": 36071, "Total num trained steps": 71552, "Timestamp in ms": 1699916379888, "logtype": "training_step"}
{"Total num played games": 36084, "Total num trained steps": 71631, "Timestamp in ms": 1699916448786, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.12109375}
{"Avg objective": 22.5625, "Games time in secs": 165.75245985388756, "Avg game time in secs": 1.6070628805318847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.7, "agent_stopped_0": 0.46}, "Total num played games": 36096, "Total num trained steps": 71635, "Timestamp in ms": 1699916450550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838370419572677, "Avg loss": 0.6889314667787403, "Avg value loss": 0.36597274482483044, "Avg policy loss": 0.3229587221285328, "Total num played games": 36132, "Total num trained steps": 71680, "Timestamp in ms": 1699916471286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846056049969598, "Avg loss": 0.6544584769289941, "Avg value loss": 0.3488062894321047, "Avg policy loss": 0.30565218965057284, "Total num played games": 36182, "Total num trained steps": 71808, "Timestamp in ms": 1699916528849, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 102.6613435652107, "Avg game time in secs": 1.5771338310150895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 36224, "Total num trained steps": 71859, "Timestamp in ms": 1699916553211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985509246480817, "Avg loss": 0.5568622788414359, "Avg value loss": 0.24247775570256636, "Avg policy loss": 0.3143845226150006, "Total num played games": 36230, "Total num trained steps": 71936, "Timestamp in ms": 1699916588505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836765029729135, "Avg loss": 0.6488310371059924, "Avg value loss": 0.34355475299526006, "Avg policy loss": 0.3052762809675187, "Total num played games": 36328, "Total num trained steps": 72064, "Timestamp in ms": 1699916645331, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 129.73642222769558, "Avg game time in secs": 1.588478670179029, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.58, "agent_stopped_0": 0.54}, "Total num played games": 36352, "Total num trained steps": 72148, "Timestamp in ms": 1699916682948, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845231877285097, "Avg loss": 0.6035043969750404, "Avg value loss": 0.29995542706456035, "Avg policy loss": 0.3035489711910486, "Total num played games": 36377, "Total num trained steps": 72192, "Timestamp in ms": 1699916702739, "logtype": "training_step"}
{"Total num played games": 36377, "Total num trained steps": 72233, "Timestamp in ms": 1699916789134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3515625}
{"Ratio train steps to played games": 1.9854221002059025, "Avg loss": 0.5807989789173007, "Avg value loss": 0.29073970403987914, "Avg policy loss": 0.2900592733640224, "Total num played games": 36425, "Total num trained steps": 72320, "Timestamp in ms": 1699916826386, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 196.18105518259108, "Avg game time in secs": 1.6005789246992208, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 36480, "Total num trained steps": 72438, "Timestamp in ms": 1699916879129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836536881879414, "Avg loss": 0.4809447864536196, "Avg value loss": 0.1929119923734106, "Avg policy loss": 0.2880327891325578, "Total num played games": 36522, "Total num trained steps": 72448, "Timestamp in ms": 1699916883696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844689926719894, "Avg loss": 0.649082493269816, "Avg value loss": 0.34734628128353506, "Avg policy loss": 0.30173621012363583, "Total num played games": 36572, "Total num trained steps": 72576, "Timestamp in ms": 1699916949544, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 100.05575852654874, "Avg game time in secs": 1.484401163586881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.7}, "Total num played games": 36608, "Total num trained steps": 72638, "Timestamp in ms": 1699916979185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852816689877393, "Avg loss": 0.5437606878113002, "Avg value loss": 0.24679815903073177, "Avg policy loss": 0.29696253046859056, "Total num played games": 36621, "Total num trained steps": 72704, "Timestamp in ms": 1699917008512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985118155305405, "Avg loss": 0.6791580498684198, "Avg value loss": 0.38183390541234985, "Avg policy loss": 0.2973241462605074, "Total num played games": 36687, "Total num trained steps": 72832, "Timestamp in ms": 1699917071299, "logtype": "training_step"}
{"Total num played games": 36719, "Total num trained steps": 72835, "Timestamp in ms": 1699917168601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.421875}
{"Avg objective": 22.109375, "Games time in secs": 191.42860671505332, "Avg game time in secs": 1.5738214158336632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.58}, "Total num played games": 36736, "Total num trained steps": 72837, "Timestamp in ms": 1699917170613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843609758751053, "Avg loss": 0.8765609047841281, "Avg value loss": 0.5655810972675681, "Avg policy loss": 0.31097980169579387, "Total num played games": 36767, "Total num trained steps": 72960, "Timestamp in ms": 1699917234222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985196653628857, "Avg loss": 0.548065024195239, "Avg value loss": 0.2528203455149196, "Avg policy loss": 0.29524467955343425, "Total num played games": 36816, "Total num trained steps": 73088, "Timestamp in ms": 1699917301621, "logtype": "training_step"}
{"Avg objective": 20.296875, "Games time in secs": 152.17084679566324, "Avg game time in secs": 1.7266689558018697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 36864, "Total num trained steps": 73127, "Timestamp in ms": 1699917322785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860033635327945, "Avg loss": 0.49188147904351354, "Avg value loss": 0.1991057576960884, "Avg policy loss": 0.29277571593411267, "Total num played games": 36866, "Total num trained steps": 73216, "Timestamp in ms": 1699917372197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839054342827775, "Avg loss": 0.6764905112795532, "Avg value loss": 0.381408684537746, "Avg policy loss": 0.2950818244135007, "Total num played games": 36969, "Total num trained steps": 73344, "Timestamp in ms": 1699917438836, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 165.14435302093625, "Avg game time in secs": 1.52184026093164, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.63, "agent_stopped_0": 0.46}, "Total num played games": 36992, "Total num trained steps": 73428, "Timestamp in ms": 1699917487929, "logtype": "played_game"}
{"Total num played games": 37019, "Total num trained steps": 73438, "Timestamp in ms": 1699917573370, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.88671875}
{"Ratio train steps to played games": 1.9821134702026062, "Avg loss": 0.7167640132829547, "Avg value loss": 0.4086346291587688, "Avg policy loss": 0.30812938150484115, "Total num played games": 37067, "Total num trained steps": 73472, "Timestamp in ms": 1699917590586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855666765586641, "Avg loss": 0.4827666429337114, "Avg value loss": 0.1732670619385317, "Avg policy loss": 0.3094995815772563, "Total num played games": 37067, "Total num trained steps": 73600, "Timestamp in ms": 1699917659041, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 238.61534332111478, "Avg game time in secs": 1.805833389487816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.78, "agent_stopped_0": 0.38}, "Total num played games": 37120, "Total num trained steps": 73722, "Timestamp in ms": 1699917726545, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840688912809472, "Avg loss": 0.6819900800473988, "Avg value loss": 0.3776058264193125, "Avg policy loss": 0.30438426008913666, "Total num played games": 37159, "Total num trained steps": 73728, "Timestamp in ms": 1699917728704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846025689256732, "Avg loss": 0.6987287558149546, "Avg value loss": 0.39294929313473403, "Avg policy loss": 0.3057794647756964, "Total num played games": 37214, "Total num trained steps": 73856, "Timestamp in ms": 1699917792064, "logtype": "training_step"}
{"Avg objective": 22.5546875, "Games time in secs": 98.78773522004485, "Avg game time in secs": 1.3807181132870028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 37248, "Total num trained steps": 73921, "Timestamp in ms": 1699917825333, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853746243022756, "Avg loss": 0.7330362854991108, "Avg value loss": 0.4285063820425421, "Avg policy loss": 0.3045299112563953, "Total num played games": 37264, "Total num trained steps": 73984, "Timestamp in ms": 1699917853428, "logtype": "training_step"}
{"Total num played games": 37315, "Total num trained steps": 74038, "Timestamp in ms": 1699917988559, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.46875}
{"Ratio train steps to played games": 1.9835666300885904, "Avg loss": 0.8465455884579569, "Avg value loss": 0.5340068719815463, "Avg policy loss": 0.31253871391527355, "Total num played games": 37363, "Total num trained steps": 74112, "Timestamp in ms": 1699918028753, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 256.37352224066854, "Avg game time in secs": 1.7554393734317273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.69, "agent_stopped_0": 0.45}, "Total num played games": 37376, "Total num trained steps": 74217, "Timestamp in ms": 1699918081707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843633058911578, "Avg loss": 0.4897174071520567, "Avg value loss": 0.19046123331645504, "Avg policy loss": 0.29925617354456335, "Total num played games": 37412, "Total num trained steps": 74240, "Timestamp in ms": 1699918094778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851845919756548, "Avg loss": 0.5549925491213799, "Avg value loss": 0.2609472092008218, "Avg policy loss": 0.2940453430637717, "Total num played games": 37461, "Total num trained steps": 74368, "Timestamp in ms": 1699918171219, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 117.92439335770905, "Avg game time in secs": 1.7101707885740325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.75, "agent_stopped_0": 0.37}, "Total num played games": 37504, "Total num trained steps": 74414, "Timestamp in ms": 1699918199631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860037323380433, "Avg loss": 0.5792845257092267, "Avg value loss": 0.28404370095813647, "Avg policy loss": 0.29524082934949547, "Total num played games": 37510, "Total num trained steps": 74496, "Timestamp in ms": 1699918248505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843376057012179, "Avg loss": 0.5919813155196607, "Avg value loss": 0.28290018532425165, "Avg policy loss": 0.3090811325237155, "Total num played games": 37606, "Total num trained steps": 74624, "Timestamp in ms": 1699918323816, "logtype": "training_step"}
{"Total num played games": 37606, "Total num trained steps": 74640, "Timestamp in ms": 1699918391182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.5390625}
{"Avg objective": 22.7578125, "Games time in secs": 193.90206057950854, "Avg game time in secs": 1.4905645100516267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 37632, "Total num trained steps": 74643, "Timestamp in ms": 1699918393533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852074148828809, "Avg loss": 0.8611674734856933, "Avg value loss": 0.5326382484054193, "Avg policy loss": 0.3285292142536491, "Total num played games": 37654, "Total num trained steps": 74752, "Timestamp in ms": 1699918451093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860223324403894, "Avg loss": 0.61693593300879, "Avg value loss": 0.3015904964413494, "Avg policy loss": 0.31534543412271887, "Total num played games": 37703, "Total num trained steps": 74880, "Timestamp in ms": 1699918520797, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 186.47575492411852, "Avg game time in secs": 1.777039146021707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.79, "agent_stopped_0": 0.34}, "Total num played games": 37760, "Total num trained steps": 74995, "Timestamp in ms": 1699918580009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843121693121692, "Avg loss": 0.7097743880003691, "Avg value loss": 0.3848699876689352, "Avg policy loss": 0.3249043986434117, "Total num played games": 37800, "Total num trained steps": 75008, "Timestamp in ms": 1699918586453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850726552179656, "Avg loss": 0.7776561072096229, "Avg value loss": 0.4492914162692614, "Avg policy loss": 0.3283646901836619, "Total num played games": 37850, "Total num trained steps": 75136, "Timestamp in ms": 1699918651171, "logtype": "training_step"}
{"Avg objective": 23.2578125, "Games time in secs": 100.41891827993095, "Avg game time in secs": 1.6753580743388738, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.7}, "Total num played games": 37888, "Total num trained steps": 75193, "Timestamp in ms": 1699918680428, "logtype": "played_game"}
{"Total num played games": 37900, "Total num trained steps": 75242, "Timestamp in ms": 1699918811649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.30859375}
{"Ratio train steps to played games": 1.9833456308632866, "Avg loss": 0.9441641378216445, "Avg value loss": 0.6023345305002294, "Avg policy loss": 0.3418296205345541, "Total num played games": 37948, "Total num trained steps": 75264, "Timestamp in ms": 1699918823400, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841566439455747, "Avg loss": 0.6071022660471499, "Avg value loss": 0.2568403818877414, "Avg policy loss": 0.35026188532356173, "Total num played games": 37997, "Total num trained steps": 75392, "Timestamp in ms": 1699918889804, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 261.38209208101034, "Avg game time in secs": 1.655451023747446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 38016, "Total num trained steps": 75485, "Timestamp in ms": 1699918941810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850177421474569, "Avg loss": 0.8534870599396527, "Avg value loss": 0.5136615196825005, "Avg policy loss": 0.33982553763780743, "Total num played games": 38045, "Total num trained steps": 75520, "Timestamp in ms": 1699918962519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857982884443743, "Avg loss": 0.6311798815149814, "Avg value loss": 0.2941765625728294, "Avg policy loss": 0.33700331614818424, "Total num played games": 38094, "Total num trained steps": 75648, "Timestamp in ms": 1699919027759, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 103.56796405464411, "Avg game time in secs": 1.5690297357650707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.67}, "Total num played games": 38144, "Total num trained steps": 75682, "Timestamp in ms": 1699919045378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859261977146452, "Avg loss": 0.7182620668318123, "Avg value loss": 0.37097000918583944, "Avg policy loss": 0.34729205747134984, "Total num played games": 38156, "Total num trained steps": 75776, "Timestamp in ms": 1699919096601, "logtype": "training_step"}
{"Total num played games": 38204, "Total num trained steps": 75843, "Timestamp in ms": 1699919196224, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.171875}
{"Ratio train steps to played games": 1.9842884032207466, "Avg loss": 0.7552123414352536, "Avg value loss": 0.4023572495789267, "Avg policy loss": 0.35285508702509105, "Total num played games": 38252, "Total num trained steps": 75904, "Timestamp in ms": 1699919229610, "logtype": "training_step"}
{"Avg objective": 20.2421875, "Games time in secs": 236.9941182397306, "Avg game time in secs": 1.6717375506268581, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.6, "agent_stopped_0": 0.55}, "Total num played games": 38272, "Total num trained steps": 75994, "Timestamp in ms": 1699919282373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851436031331593, "Avg loss": 0.5479921910446137, "Avg value loss": 0.20889645058196038, "Avg policy loss": 0.33909574360586703, "Total num played games": 38300, "Total num trained steps": 76032, "Timestamp in ms": 1699919303489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985996662146657, "Avg loss": 0.6471977864857763, "Avg value loss": 0.3156365660834126, "Avg policy loss": 0.3315612208098173, "Total num played games": 38348, "Total num trained steps": 76160, "Timestamp in ms": 1699919378939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867184041251074, "Avg loss": 0.5694583102595061, "Avg value loss": 0.24133820767747238, "Avg policy loss": 0.3281201026402414, "Total num played games": 38399, "Total num trained steps": 76288, "Timestamp in ms": 1699919446767, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 164.40106946602464, "Avg game time in secs": 1.617293019851786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 38400, "Total num trained steps": 76288, "Timestamp in ms": 1699919446774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849598670026236, "Avg loss": 0.8083616681396961, "Avg value loss": 0.4760795463807881, "Avg policy loss": 0.3322821226902306, "Total num played games": 38497, "Total num trained steps": 76416, "Timestamp in ms": 1699919517050, "logtype": "training_step"}
{"Total num played games": 38497, "Total num trained steps": 76446, "Timestamp in ms": 1699919633026, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.921875}
{"Avg objective": 21.84375, "Games time in secs": 188.8874237164855, "Avg game time in secs": 1.4494013873918448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.51}, "Total num played games": 38528, "Total num trained steps": 76448, "Timestamp in ms": 1699919635661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858347386172006, "Avg loss": 0.6928915060125291, "Avg value loss": 0.34859302325639874, "Avg policy loss": 0.3442984720459208, "Total num played games": 38545, "Total num trained steps": 76544, "Timestamp in ms": 1699919681717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866556111211877, "Avg loss": 0.6079827635549009, "Avg value loss": 0.2878348028752953, "Avg policy loss": 0.32014795555733144, "Total num played games": 38593, "Total num trained steps": 76672, "Timestamp in ms": 1699919756174, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 175.88407262414694, "Avg game time in secs": 1.766168958041817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.73, "agent_stopped_0": 0.42}, "Total num played games": 38656, "Total num trained steps": 76775, "Timestamp in ms": 1699919811546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849318963066347, "Avg loss": 0.7312442930415273, "Avg value loss": 0.40402738231932744, "Avg policy loss": 0.32721690833568573, "Total num played games": 38691, "Total num trained steps": 76800, "Timestamp in ms": 1699919823745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985597398239682, "Avg loss": 0.6034636762924492, "Avg value loss": 0.2734294187393971, "Avg policy loss": 0.330034262733534, "Total num played games": 38743, "Total num trained steps": 76928, "Timestamp in ms": 1699919888487, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 104.85942799970508, "Avg game time in secs": 1.5343486632336862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 38784, "Total num trained steps": 76981, "Timestamp in ms": 1699919916405, "logtype": "played_game"}
{"Total num played games": 38793, "Total num trained steps": 77047, "Timestamp in ms": 1699920034435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.17578125}
{"Ratio train steps to played games": 1.9839340885684862, "Avg loss": 0.5775631729047745, "Avg value loss": 0.2531390603980981, "Avg policy loss": 0.3244241145439446, "Total num played games": 38840, "Total num trained steps": 77056, "Timestamp in ms": 1699920039540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984649010028285, "Avg loss": 0.6297861675266176, "Avg value loss": 0.2981889368966222, "Avg policy loss": 0.3315972216660157, "Total num played games": 38890, "Total num trained steps": 77184, "Timestamp in ms": 1699920109159, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 240.28775107488036, "Avg game time in secs": 1.5862212947249645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 38912, "Total num trained steps": 77269, "Timestamp in ms": 1699920156693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855154347937747, "Avg loss": 0.6595023004338145, "Avg value loss": 0.3341854606405832, "Avg policy loss": 0.3253168450901285, "Total num played games": 38938, "Total num trained steps": 77312, "Timestamp in ms": 1699920178127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862012362461208, "Avg loss": 0.6150727835483849, "Avg value loss": 0.288599633553531, "Avg policy loss": 0.3264731497038156, "Total num played games": 38989, "Total num trained steps": 77440, "Timestamp in ms": 1699920247844, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 154.7173146419227, "Avg game time in secs": 1.7821309392747935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.75, "agent_stopped_0": 0.38}, "Total num played games": 39040, "Total num trained steps": 77567, "Timestamp in ms": 1699920311411, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856137207218738, "Avg loss": 0.5038894275203347, "Avg value loss": 0.1824594828649424, "Avg policy loss": 0.3214299449464306, "Total num played games": 39064, "Total num trained steps": 77568, "Timestamp in ms": 1699920312189, "logtype": "training_step"}
{"Total num played games": 39088, "Total num trained steps": 77652, "Timestamp in ms": 1699920417689, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.296875}
{"Ratio train steps to played games": 1.9852565412919052, "Avg loss": 0.7114210680592805, "Avg value loss": 0.3954469552845694, "Avg policy loss": 0.3159741114359349, "Total num played games": 39136, "Total num trained steps": 77696, "Timestamp in ms": 1699920443269, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 167.68786137923598, "Avg game time in secs": 1.3747540491021937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.49}, "Total num played games": 39168, "Total num trained steps": 77764, "Timestamp in ms": 1699920479099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860912617394855, "Avg loss": 0.580295994412154, "Avg value loss": 0.2670216910773888, "Avg policy loss": 0.31327430298551917, "Total num played games": 39184, "Total num trained steps": 77824, "Timestamp in ms": 1699920512067, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868481419177244, "Avg loss": 0.5755145566072315, "Avg value loss": 0.27650630474090576, "Avg policy loss": 0.29900824779178947, "Total num played games": 39234, "Total num trained steps": 77952, "Timestamp in ms": 1699920582025, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 160.86715811118484, "Avg game time in secs": 1.56928938908095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.58, "agent_stopped_0": 0.53}, "Total num played games": 39296, "Total num trained steps": 78056, "Timestamp in ms": 1699920639966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985177086776334, "Avg loss": 0.6460826408583671, "Avg value loss": 0.3409322243533097, "Avg policy loss": 0.30515041295439005, "Total num played games": 39331, "Total num trained steps": 78080, "Timestamp in ms": 1699920653162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98593230237932, "Avg loss": 0.5121089145541191, "Avg value loss": 0.20387556741479784, "Avg policy loss": 0.3082333473721519, "Total num played games": 39381, "Total num trained steps": 78208, "Timestamp in ms": 1699920725235, "logtype": "training_step"}
{"Avg objective": 20.6015625, "Games time in secs": 114.25420055165887, "Avg game time in secs": 1.726093505785684, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.67}, "Total num played games": 39424, "Total num trained steps": 78255, "Timestamp in ms": 1699920754221, "logtype": "played_game"}
{"Total num played games": 39434, "Total num trained steps": 78255, "Timestamp in ms": 1699920826974, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.671875}
{"Ratio train steps to played games": 1.9840686895294057, "Avg loss": 0.8757275422103703, "Avg value loss": 0.5572080509155057, "Avg policy loss": 0.3185194793622941, "Total num played games": 39482, "Total num trained steps": 78336, "Timestamp in ms": 1699920873692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848473350029092, "Avg loss": 0.4474072519224137, "Avg value loss": 0.1597536294721067, "Avg policy loss": 0.2876536208204925, "Total num played games": 39531, "Total num trained steps": 78464, "Timestamp in ms": 1699920943981, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 238.5687350127846, "Avg game time in secs": 1.65109354913875, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 39552, "Total num trained steps": 78552, "Timestamp in ms": 1699920992789, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856240525517939, "Avg loss": 0.6576822923962027, "Avg value loss": 0.35819174896460027, "Avg policy loss": 0.29949054517783225, "Total num played games": 39580, "Total num trained steps": 78592, "Timestamp in ms": 1699921017211, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863487257128438, "Avg loss": 0.5330543238669634, "Avg value loss": 0.2346521620056592, "Avg policy loss": 0.29840215446893126, "Total num played games": 39630, "Total num trained steps": 78720, "Timestamp in ms": 1699921086280, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 113.64728512056172, "Avg game time in secs": 1.5182059927319642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 39680, "Total num trained steps": 78756, "Timestamp in ms": 1699921106437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869714228113502, "Avg loss": 0.5654061923269182, "Avg value loss": 0.2705446556210518, "Avg policy loss": 0.2948615290224552, "Total num played games": 39682, "Total num trained steps": 78848, "Timestamp in ms": 1699921156609, "logtype": "training_step"}
{"Total num played games": 39731, "Total num trained steps": 78859, "Timestamp in ms": 1699921238030, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8671875}
{"Ratio train steps to played games": 1.985369164634606, "Avg loss": 0.6535176956094801, "Avg value loss": 0.35387924185488373, "Avg policy loss": 0.29963845445308834, "Total num played games": 39779, "Total num trained steps": 78976, "Timestamp in ms": 1699921306035, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 238.84853609092534, "Avg game time in secs": 1.4202168363699457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 39808, "Total num trained steps": 79050, "Timestamp in ms": 1699921345286, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860155661561636, "Avg loss": 0.48368594981729984, "Avg value loss": 0.20495169993955642, "Avg policy loss": 0.2787342536030337, "Total num played games": 39830, "Total num trained steps": 79104, "Timestamp in ms": 1699921372949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867850246997167, "Avg loss": 0.5118000330403447, "Avg value loss": 0.233361485239584, "Avg policy loss": 0.27843854611273855, "Total num played games": 39879, "Total num trained steps": 79232, "Timestamp in ms": 1699921437793, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 156.94109871611, "Avg game time in secs": 1.7601581118360627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.73, "agent_stopped_0": 0.41}, "Total num played games": 39936, "Total num trained steps": 79346, "Timestamp in ms": 1699921502227, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851911146688013, "Avg loss": 0.6514758579432964, "Avg value loss": 0.363069683953654, "Avg policy loss": 0.2884061757940799, "Total num played games": 39976, "Total num trained steps": 79360, "Timestamp in ms": 1699921509880, "logtype": "training_step"}
{"Total num played games": 40027, "Total num trained steps": 79463, "Timestamp in ms": 1699921622134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.734375}
{"Avg objective": 21.9140625, "Games time in secs": 123.54280381649733, "Avg game time in secs": 1.5038460659125121, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 40064, "Total num trained steps": 79470, "Timestamp in ms": 1699921625770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834809731752963, "Avg loss": 0.8081694047432393, "Avg value loss": 0.517918027122505, "Avg policy loss": 0.2902513846056536, "Total num played games": 40075, "Total num trained steps": 79488, "Timestamp in ms": 1699921635862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866500311915158, "Avg loss": 0.4952926286496222, "Avg value loss": 0.1982936408603564, "Avg policy loss": 0.29699898965191096, "Total num played games": 40075, "Total num trained steps": 79616, "Timestamp in ms": 1699921709443, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850887456125066, "Avg loss": 0.546721113147214, "Avg value loss": 0.2738543036393821, "Avg policy loss": 0.2728668097406626, "Total num played games": 40171, "Total num trained steps": 79744, "Timestamp in ms": 1699921777014, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 195.83418693952262, "Avg game time in secs": 1.4669033973041223, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.51, "agent_stopped_0": 0.54}, "Total num played games": 40192, "Total num trained steps": 79833, "Timestamp in ms": 1699921821604, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858528095474888, "Avg loss": 0.571447438094765, "Avg value loss": 0.2894035649369471, "Avg policy loss": 0.2820438697235659, "Total num played games": 40220, "Total num trained steps": 79872, "Timestamp in ms": 1699921840701, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986615014030644, "Avg loss": 0.5352013192605227, "Avg value loss": 0.2513128213468008, "Avg policy loss": 0.2838884994853288, "Total num played games": 40269, "Total num trained steps": 80000, "Timestamp in ms": 1699921905314, "logtype": "training_step"}
{"Total num played games": 40317, "Total num trained steps": 80064, "Timestamp in ms": 1699921958953, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6953125}
{"Avg objective": 21.34375, "Games time in secs": 138.72698203101754, "Avg game time in secs": 1.676314957017894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.72}, "Total num played games": 40320, "Total num trained steps": 80064, "Timestamp in ms": 1699921960331, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850860894339155, "Avg loss": 0.7447204894851893, "Avg value loss": 0.4459746912471019, "Avg policy loss": 0.29874579596798867, "Total num played games": 40365, "Total num trained steps": 80128, "Timestamp in ms": 1699921990213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858217449398723, "Avg loss": 0.48344428394921124, "Avg value loss": 0.21121698297793046, "Avg policy loss": 0.2722273018443957, "Total num played games": 40414, "Total num trained steps": 80256, "Timestamp in ms": 1699922057011, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 130.43809117004275, "Avg game time in secs": 1.3641298436559737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 40448, "Total num trained steps": 80321, "Timestamp in ms": 1699922090769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986580332649581, "Avg loss": 0.6181365256197751, "Avg value loss": 0.33769223699346185, "Avg policy loss": 0.28044428466819227, "Total num played games": 40463, "Total num trained steps": 80384, "Timestamp in ms": 1699922122030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872880310023944, "Avg loss": 0.5062657706439495, "Avg value loss": 0.21491259970935062, "Avg policy loss": 0.2913531680824235, "Total num played games": 40513, "Total num trained steps": 80512, "Timestamp in ms": 1699922187129, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 146.59118292853236, "Avg game time in secs": 1.532053405928309, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 40576, "Total num trained steps": 80616, "Timestamp in ms": 1699922237361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98539984242663, "Avg loss": 0.6349889282137156, "Avg value loss": 0.3513403993565589, "Avg policy loss": 0.2836485320003703, "Total num played games": 40616, "Total num trained steps": 80640, "Timestamp in ms": 1699922249289, "logtype": "training_step"}
{"Total num played games": 40616, "Total num trained steps": 80665, "Timestamp in ms": 1699922330309, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.60546875}
{"Ratio train steps to played games": 1.9862286051544364, "Avg loss": 0.536334985634312, "Avg value loss": 0.24687177850864828, "Avg policy loss": 0.28946320503018796, "Total num played games": 40664, "Total num trained steps": 80768, "Timestamp in ms": 1699922387657, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 177.9099195972085, "Avg game time in secs": 1.3021058214217192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 40704, "Total num trained steps": 80821, "Timestamp in ms": 1699922415271, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869820450470366, "Avg loss": 0.5873799740802497, "Avg value loss": 0.3060680296039209, "Avg policy loss": 0.281311942380853, "Total num played games": 40713, "Total num trained steps": 80896, "Timestamp in ms": 1699922456496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853470877949573, "Avg loss": 0.6387218560557812, "Avg value loss": 0.34807157778413966, "Avg policy loss": 0.2906502797268331, "Total num played games": 40811, "Total num trained steps": 81024, "Timestamp in ms": 1699922525441, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 153.9014963209629, "Avg game time in secs": 1.4990696481108898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.61, "agent_stopped_0": 0.52}, "Total num played games": 40832, "Total num trained steps": 81114, "Timestamp in ms": 1699922569173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860016641378297, "Avg loss": 0.7798973645549268, "Avg value loss": 0.4776293003815226, "Avg policy loss": 0.302268055267632, "Total num played games": 40862, "Total num trained steps": 81152, "Timestamp in ms": 1699922589686, "logtype": "training_step"}
{"Total num played games": 40911, "Total num trained steps": 81266, "Timestamp in ms": 1699922709680, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.71484375}
{"Ratio train steps to played games": 1.984423447838082, "Avg loss": 0.7577455723658204, "Avg value loss": 0.4642927323584445, "Avg policy loss": 0.29345284192822874, "Total num played games": 40959, "Total num trained steps": 81280, "Timestamp in ms": 1699922718276, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98754852413389, "Avg loss": 0.4748021063860506, "Avg value loss": 0.18359930987935513, "Avg policy loss": 0.29120279802009463, "Total num played games": 40959, "Total num trained steps": 81408, "Timestamp in ms": 1699922782964, "logtype": "training_step"}
{"Avg objective": 22.265625, "Games time in secs": 213.84363504126668, "Avg game time in secs": 1.5572325142275076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.68}, "Total num played games": 40960, "Total num trained steps": 81408, "Timestamp in ms": 1699922783016, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859220108629467, "Avg loss": 0.6199095137417316, "Avg value loss": 0.33645428880117834, "Avg policy loss": 0.28345523204188794, "Total num played games": 41057, "Total num trained steps": 81536, "Timestamp in ms": 1699922848859, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 107.35067610815167, "Avg game time in secs": 1.304930206591962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.52}, "Total num played games": 41088, "Total num trained steps": 81604, "Timestamp in ms": 1699922890367, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866442855057656, "Avg loss": 0.5477151412051171, "Avg value loss": 0.26578801014693454, "Avg policy loss": 0.2819271271582693, "Total num played games": 41106, "Total num trained steps": 81664, "Timestamp in ms": 1699922923519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871959960154522, "Avg loss": 0.6617194095160812, "Avg value loss": 0.37226152390940115, "Avg policy loss": 0.2894578769337386, "Total num played games": 41159, "Total num trained steps": 81792, "Timestamp in ms": 1699922995733, "logtype": "training_step"}
{"Total num played games": 41215, "Total num trained steps": 81867, "Timestamp in ms": 1699923086213, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5703125}
{"Avg objective": 20.6171875, "Games time in secs": 196.9594071637839, "Avg game time in secs": 1.464062181970803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 41216, "Total num trained steps": 81868, "Timestamp in ms": 1699923087327, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853137193127015, "Avg loss": 0.667032910278067, "Avg value loss": 0.37499083566945046, "Avg policy loss": 0.292042080196552, "Total num played games": 41263, "Total num trained steps": 81920, "Timestamp in ms": 1699923115314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859850410282478, "Avg loss": 0.4432057251688093, "Avg value loss": 0.15925721224630252, "Avg policy loss": 0.28394851100165397, "Total num played games": 41313, "Total num trained steps": 82048, "Timestamp in ms": 1699923182384, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 128.8433112576604, "Avg game time in secs": 1.4562886442727176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 41344, "Total num trained steps": 82120, "Timestamp in ms": 1699923216170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986726947439679, "Avg loss": 0.4763704240322113, "Avg value loss": 0.1938145695021376, "Avg policy loss": 0.2825558555778116, "Total num played games": 41362, "Total num trained steps": 82176, "Timestamp in ms": 1699923245537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987539241729051, "Avg loss": 0.6213841030839831, "Avg value loss": 0.332373748999089, "Avg policy loss": 0.28901035711169243, "Total num played games": 41410, "Total num trained steps": 82304, "Timestamp in ms": 1699923313860, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 152.8884454369545, "Avg game time in secs": 1.5880787621426862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 41472, "Total num trained steps": 82406, "Timestamp in ms": 1699923369059, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985906331309627, "Avg loss": 1.0163387369830161, "Avg value loss": 0.7227414759399835, "Avg policy loss": 0.2935972772538662, "Total num played games": 41508, "Total num trained steps": 82432, "Timestamp in ms": 1699923381173, "logtype": "training_step"}
{"Total num played games": 41508, "Total num trained steps": 82469, "Timestamp in ms": 1699923458451, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.92578125}
{"Ratio train steps to played games": 1.986692655693522, "Avg loss": 0.6591417253948748, "Avg value loss": 0.3588074442814104, "Avg policy loss": 0.3003342830343172, "Total num played games": 41556, "Total num trained steps": 82560, "Timestamp in ms": 1699923507803, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 164.05548048391938, "Avg game time in secs": 1.3663000486849342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 41600, "Total num trained steps": 82606, "Timestamp in ms": 1699923533115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987429395505348, "Avg loss": 0.5258046209346503, "Avg value loss": 0.2429294606554322, "Avg policy loss": 0.2828751567285508, "Total num played games": 41605, "Total num trained steps": 82688, "Timestamp in ms": 1699923579747, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858523367623433, "Avg loss": 0.5577040566131473, "Avg value loss": 0.2717613347922452, "Avg policy loss": 0.28594272246118635, "Total num played games": 41703, "Total num trained steps": 82816, "Timestamp in ms": 1699923653349, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 170.91287346743047, "Avg game time in secs": 1.4982738487160532, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.64, "agent_stopped_0": 0.51}, "Total num played games": 41728, "Total num trained steps": 82897, "Timestamp in ms": 1699923704028, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861829501915709, "Avg loss": 0.6251876852475107, "Avg value loss": 0.3452544629108161, "Avg policy loss": 0.2799332248978317, "Total num played games": 41760, "Total num trained steps": 82944, "Timestamp in ms": 1699923731545, "logtype": "training_step"}
{"Total num played games": 41809, "Total num trained steps": 83071, "Timestamp in ms": 1699923908536, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.43359375}
{"Ratio train steps to played games": 1.9850888931370674, "Avg loss": 0.5249144909903407, "Avg value loss": 0.23994638660224155, "Avg policy loss": 0.2849681049119681, "Total num played games": 41831, "Total num trained steps": 83072, "Timestamp in ms": 1699923910882, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 207.5050440467894, "Avg game time in secs": 1.4050872375810286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 41856, "Total num trained steps": 83073, "Timestamp in ms": 1699923911533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876962037413097, "Avg loss": 0.6910503234248608, "Avg value loss": 0.4080827566795051, "Avg policy loss": 0.28296756045892835, "Total num played games": 41857, "Total num trained steps": 83200, "Timestamp in ms": 1699923984833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986222677758444, "Avg loss": 0.7930824642535299, "Avg value loss": 0.4998699616990052, "Avg policy loss": 0.29321249993517995, "Total num played games": 41953, "Total num trained steps": 83328, "Timestamp in ms": 1699924057343, "logtype": "training_step"}
{"Avg objective": 22.546875, "Games time in secs": 184.91644589416683, "Avg game time in secs": 1.2899310926295584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.49, "agent_stopped_0": 0.59}, "Total num played games": 41984, "Total num trained steps": 83396, "Timestamp in ms": 1699924096449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869530022379887, "Avg loss": 0.6126105419825763, "Avg value loss": 0.32653553993441164, "Avg policy loss": 0.28607500239741057, "Total num played games": 42002, "Total num trained steps": 83456, "Timestamp in ms": 1699924131394, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874687908691, "Avg loss": 0.6244654590263963, "Avg value loss": 0.33342753764009103, "Avg policy loss": 0.2910379178356379, "Total num played games": 42055, "Total num trained steps": 83584, "Timestamp in ms": 1699924201392, "logtype": "training_step"}
{"Total num played games": 42104, "Total num trained steps": 83674, "Timestamp in ms": 1699924297264, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0}
{"Avg objective": 22.0234375, "Games time in secs": 202.58385767787695, "Avg game time in secs": 1.5111435426806565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.6}, "Total num played games": 42112, "Total num trained steps": 83676, "Timestamp in ms": 1699924299033, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859555892958816, "Avg loss": 0.8383645026478916, "Avg value loss": 0.5275183994090185, "Avg policy loss": 0.31084610300604254, "Total num played games": 42152, "Total num trained steps": 83712, "Timestamp in ms": 1699924318613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866120089095303, "Avg loss": 0.5180683024227619, "Avg value loss": 0.2217194588156417, "Avg policy loss": 0.29634884546976537, "Total num played games": 42202, "Total num trained steps": 83840, "Timestamp in ms": 1699924382346, "logtype": "training_step"}
{"Avg objective": 22.8515625, "Games time in secs": 109.24296583049, "Avg game time in secs": 1.266666721974616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 42240, "Total num trained steps": 83897, "Timestamp in ms": 1699924408276, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873612458876713, "Avg loss": 0.488193929893896, "Avg value loss": 0.19918887899257243, "Avg policy loss": 0.2890050533460453, "Total num played games": 42251, "Total num trained steps": 83968, "Timestamp in ms": 1699924443431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985761174998229, "Avg loss": 0.550420478451997, "Avg value loss": 0.27027911617187783, "Avg policy loss": 0.28014135465491563, "Total num played games": 42349, "Total num trained steps": 84096, "Timestamp in ms": 1699924510265, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 151.50825532339513, "Avg game time in secs": 1.3152250214188825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 42368, "Total num trained steps": 84189, "Timestamp in ms": 1699924559785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865320659480623, "Avg loss": 0.7088814908638597, "Avg value loss": 0.4236592134111561, "Avg policy loss": 0.28522228030487895, "Total num played games": 42397, "Total num trained steps": 84224, "Timestamp in ms": 1699924579024, "logtype": "training_step"}
{"Total num played games": 42397, "Total num trained steps": 84274, "Timestamp in ms": 1699924680371, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2734375}
{"Ratio train steps to played games": 1.9873247732359525, "Avg loss": 0.5954271154478192, "Avg value loss": 0.30187689926242456, "Avg policy loss": 0.29355021740775555, "Total num played games": 42445, "Total num trained steps": 84352, "Timestamp in ms": 1699924720487, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879985880691846, "Avg loss": 0.5132250606548041, "Avg value loss": 0.22595580507186241, "Avg policy loss": 0.28726925887167454, "Total num played games": 42495, "Total num trained steps": 84480, "Timestamp in ms": 1699924790304, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 230.65423946268857, "Avg game time in secs": 1.3944120218075113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.6}, "Total num played games": 42496, "Total num trained steps": 84480, "Timestamp in ms": 1699924790439, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864528549962435, "Avg loss": 0.7934034653007984, "Avg value loss": 0.485986944520846, "Avg policy loss": 0.3074165275320411, "Total num played games": 42592, "Total num trained steps": 84608, "Timestamp in ms": 1699924857477, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 99.83415879122913, "Avg game time in secs": 1.3781439028243767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 42624, "Total num trained steps": 84677, "Timestamp in ms": 1699924890274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987218574108818, "Avg loss": 0.6663062905427068, "Avg value loss": 0.3601275966502726, "Avg policy loss": 0.30617869819980115, "Total num played games": 42640, "Total num trained steps": 84736, "Timestamp in ms": 1699924917869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879360022488228, "Avg loss": 0.525554867926985, "Avg value loss": 0.21447078685741872, "Avg policy loss": 0.31108408072032034, "Total num played games": 42689, "Total num trained steps": 84864, "Timestamp in ms": 1699924979217, "logtype": "training_step"}
{"Total num played games": 42738, "Total num trained steps": 84874, "Timestamp in ms": 1699925058561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.49609375}
{"Avg objective": 21.84375, "Games time in secs": 170.06737040355802, "Avg game time in secs": 1.398009410360828, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 42752, "Total num trained steps": 84876, "Timestamp in ms": 1699925060341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864207918478007, "Avg loss": 0.8532743696123362, "Avg value loss": 0.5341008736286312, "Avg policy loss": 0.3191734885331243, "Total num played games": 42786, "Total num trained steps": 84992, "Timestamp in ms": 1699925121800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870902978802876, "Avg loss": 0.46010844805277884, "Avg value loss": 0.1682876176200807, "Avg policy loss": 0.2918208288028836, "Total num played games": 42836, "Total num trained steps": 85120, "Timestamp in ms": 1699925188787, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 151.73552974127233, "Avg game time in secs": 1.2998065259453142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 42880, "Total num trained steps": 85164, "Timestamp in ms": 1699925212077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878279118572928, "Avg loss": 0.4693650109693408, "Avg value loss": 0.17677265970269218, "Avg policy loss": 0.2925923540024087, "Total num played games": 42885, "Total num trained steps": 85248, "Timestamp in ms": 1699925254812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986250378056441, "Avg loss": 0.5688175237737596, "Avg value loss": 0.273020577209536, "Avg policy loss": 0.2957969420822337, "Total num played games": 42983, "Total num trained steps": 85376, "Timestamp in ms": 1699925319413, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 145.11592863313854, "Avg game time in secs": 1.252639676356921, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 43008, "Total num trained steps": 85457, "Timestamp in ms": 1699925357193, "logtype": "played_game"}
{"Total num played games": 43031, "Total num trained steps": 85475, "Timestamp in ms": 1699925398986, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6875}
{"Ratio train steps to played games": 1.9847953759372317, "Avg loss": 0.6501055723056197, "Avg value loss": 0.34899561625206843, "Avg policy loss": 0.30110995087306947, "Total num played games": 43079, "Total num trained steps": 85504, "Timestamp in ms": 1699925414712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877666612502611, "Avg loss": 0.4023668316658586, "Avg value loss": 0.10971825217711739, "Avg policy loss": 0.29264857852831483, "Total num played games": 43079, "Total num trained steps": 85632, "Timestamp in ms": 1699925485977, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 188.3454583082348, "Avg game time in secs": 1.2957897250016686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.66, "agent_stopped_0": 0.46}, "Total num played games": 43136, "Total num trained steps": 85746, "Timestamp in ms": 1699925545539, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862195150195705, "Avg loss": 0.7093615960329771, "Avg value loss": 0.40698670089477673, "Avg policy loss": 0.30237489531282336, "Total num played games": 43177, "Total num trained steps": 85760, "Timestamp in ms": 1699925553624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986975130133025, "Avg loss": 0.6290252397302538, "Avg value loss": 0.3122770134359598, "Avg policy loss": 0.316748226294294, "Total num played games": 43225, "Total num trained steps": 85888, "Timestamp in ms": 1699925625395, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 110.16895876266062, "Avg game time in secs": 1.2714184896467486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 43264, "Total num trained steps": 85943, "Timestamp in ms": 1699925655708, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875912746094833, "Avg loss": 0.5795520907267928, "Avg value loss": 0.2594379949150607, "Avg policy loss": 0.3201140947639942, "Total num played games": 43276, "Total num trained steps": 86016, "Timestamp in ms": 1699925694002, "logtype": "training_step"}
{"Total num played games": 43329, "Total num trained steps": 86076, "Timestamp in ms": 1699925796490, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.28125}
{"Ratio train steps to played games": 1.9859141941581944, "Avg loss": 0.7533238735049963, "Avg value loss": 0.4220846902753692, "Avg policy loss": 0.3312391838990152, "Total num played games": 43377, "Total num trained steps": 86144, "Timestamp in ms": 1699925837103, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 233.31925458461046, "Avg game time in secs": 1.3697401914541842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.57, "agent_stopped_0": 0.53}, "Total num played games": 43392, "Total num trained steps": 86245, "Timestamp in ms": 1699925889027, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866666666666666, "Avg loss": 0.49664147943258286, "Avg value loss": 0.18840298222494312, "Avg policy loss": 0.308238496305421, "Total num played games": 43425, "Total num trained steps": 86272, "Timestamp in ms": 1699925902698, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865949276861878, "Avg loss": 0.640276207588613, "Avg value loss": 0.3331675522495061, "Avg policy loss": 0.3071086563868448, "Total num played games": 43491, "Total num trained steps": 86400, "Timestamp in ms": 1699925973449, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 123.8218964394182, "Avg game time in secs": 1.1880567983462242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 43520, "Total num trained steps": 86473, "Timestamp in ms": 1699926012849, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872990353697748, "Avg loss": 0.5800046895164996, "Avg value loss": 0.277832530613523, "Avg policy loss": 0.3021721570985392, "Total num played games": 43540, "Total num trained steps": 86528, "Timestamp in ms": 1699926040473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880015600266123, "Avg loss": 0.6956327797379345, "Avg value loss": 0.39244925876846537, "Avg policy loss": 0.30318352568428963, "Total num played games": 43589, "Total num trained steps": 86656, "Timestamp in ms": 1699926110536, "logtype": "training_step"}
{"Total num played games": 43638, "Total num trained steps": 86678, "Timestamp in ms": 1699926186353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7421875}
{"Avg objective": 22.5546875, "Games time in secs": 177.30082896910608, "Avg game time in secs": 1.4377975958195748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.68, "agent_stopped_0": 0.44}, "Total num played games": 43648, "Total num trained steps": 86683, "Timestamp in ms": 1699926190150, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865403103969235, "Avg loss": 0.820012136362493, "Avg value loss": 0.5001088724238798, "Avg policy loss": 0.31990326405502856, "Total num played games": 43686, "Total num trained steps": 86784, "Timestamp in ms": 1699926242045, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871730382293762, "Avg loss": 0.5422339593060315, "Avg value loss": 0.2426769106532447, "Avg policy loss": 0.2995570522034541, "Total num played games": 43736, "Total num trained steps": 86912, "Timestamp in ms": 1699926312874, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 149.85845920443535, "Avg game time in secs": 1.3802156485471642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.58}, "Total num played games": 43776, "Total num trained steps": 86966, "Timestamp in ms": 1699926340009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878953979673404, "Avg loss": 0.675994401331991, "Avg value loss": 0.36619125510333106, "Avg policy loss": 0.3098031429108232, "Total num played games": 43785, "Total num trained steps": 87040, "Timestamp in ms": 1699926376121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863500672242098, "Avg loss": 0.641405300470069, "Avg value loss": 0.32896537333726883, "Avg policy loss": 0.3124399268999696, "Total num played games": 43883, "Total num trained steps": 87168, "Timestamp in ms": 1699926447379, "logtype": "training_step"}
{"Avg objective": 22.2734375, "Games time in secs": 149.56013116426766, "Avg game time in secs": 1.3572540334280347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 43904, "Total num trained steps": 87256, "Timestamp in ms": 1699926489569, "logtype": "played_game"}
{"Total num played games": 43961, "Total num trained steps": 87278, "Timestamp in ms": 1699926582405, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.921875}
{"Ratio train steps to played games": 1.9835715421845532, "Avg loss": 1.020393012324348, "Avg value loss": 0.7029640930122696, "Avg policy loss": 0.3174289194867015, "Total num played games": 44009, "Total num trained steps": 87296, "Timestamp in ms": 1699926592618, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864800381740098, "Avg loss": 0.5854589857626706, "Avg value loss": 0.26285909698344767, "Avg policy loss": 0.3225998847046867, "Total num played games": 44009, "Total num trained steps": 87424, "Timestamp in ms": 1699926664867, "logtype": "training_step"}
{"Avg objective": 22.40625, "Games time in secs": 220.77986879833043, "Avg game time in secs": 1.227984441924491, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 44032, "Total num trained steps": 87510, "Timestamp in ms": 1699926710349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872437978073858, "Avg loss": 0.6002772606443614, "Avg value loss": 0.3004118684330024, "Avg policy loss": 0.299865388777107, "Total num played games": 44057, "Total num trained steps": 87552, "Timestamp in ms": 1699926731204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878930781962048, "Avg loss": 0.5337328175082803, "Avg value loss": 0.21781631821068004, "Avg policy loss": 0.3159165020333603, "Total num played games": 44107, "Total num trained steps": 87680, "Timestamp in ms": 1699926793971, "logtype": "training_step"}
{"Avg objective": 19.734375, "Games time in secs": 145.63954562321305, "Avg game time in secs": 1.4818402929377044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.72}, "Total num played games": 44160, "Total num trained steps": 87800, "Timestamp in ms": 1699926855989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863590091618595, "Avg loss": 0.652143815997988, "Avg value loss": 0.3443154916749336, "Avg policy loss": 0.30782831832766533, "Total num played games": 44205, "Total num trained steps": 87808, "Timestamp in ms": 1699926859692, "logtype": "training_step"}
{"Total num played games": 44205, "Total num trained steps": 87880, "Timestamp in ms": 1699926980843, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.82421875}
{"Ratio train steps to played games": 1.9871195173208596, "Avg loss": 0.7074908649083227, "Avg value loss": 0.3909988522063941, "Avg policy loss": 0.3164920136332512, "Total num played games": 44253, "Total num trained steps": 87936, "Timestamp in ms": 1699927013219, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 187.7033081240952, "Avg game time in secs": 1.1409954525151988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 44288, "Total num trained steps": 87997, "Timestamp in ms": 1699927043692, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987788361699246, "Avg loss": 0.4878199596423656, "Avg value loss": 0.17404735955642536, "Avg policy loss": 0.3137725965352729, "Total num played games": 44302, "Total num trained steps": 88064, "Timestamp in ms": 1699927079804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867312457760757, "Avg loss": 0.4820693773217499, "Avg value loss": 0.16848657332593575, "Avg policy loss": 0.313582802657038, "Total num played games": 44390, "Total num trained steps": 88192, "Timestamp in ms": 1699927147309, "logtype": "training_step"}
{"Avg objective": 20.4921875, "Games time in secs": 149.10446725785732, "Avg game time in secs": 1.364040068394388, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 44416, "Total num trained steps": 88287, "Timestamp in ms": 1699927192797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870185385169186, "Avg loss": 0.7605856938753277, "Avg value loss": 0.4378310859319754, "Avg policy loss": 0.32275460253003985, "Total num played games": 44448, "Total num trained steps": 88320, "Timestamp in ms": 1699927207930, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877070364294223, "Avg loss": 0.7015899736434221, "Avg value loss": 0.3836160983191803, "Avg policy loss": 0.31797387858387083, "Total num played games": 44497, "Total num trained steps": 88448, "Timestamp in ms": 1699927276028, "logtype": "training_step"}
{"Total num played games": 44497, "Total num trained steps": 88482, "Timestamp in ms": 1699927362338, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55078125}
{"Avg objective": 21.7578125, "Games time in secs": 172.53274646028876, "Avg game time in secs": 1.2776301048143068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.47}, "Total num played games": 44544, "Total num trained steps": 88486, "Timestamp in ms": 1699927365330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988304749932657, "Avg loss": 0.6344878396485001, "Avg value loss": 0.30124823562800884, "Avg policy loss": 0.3332396021578461, "Total num played games": 44548, "Total num trained steps": 88576, "Timestamp in ms": 1699927414278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862289796009762, "Avg loss": 0.711090442026034, "Avg value loss": 0.3856806265830528, "Avg policy loss": 0.32540981587953866, "Total num played games": 44659, "Total num trained steps": 88704, "Timestamp in ms": 1699927484002, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 171.02905201539397, "Avg game time in secs": 1.3027645275287796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 44672, "Total num trained steps": 88808, "Timestamp in ms": 1699927536359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869150934955713, "Avg loss": 0.6452370942570269, "Avg value loss": 0.3207223190693185, "Avg policy loss": 0.32451477425638586, "Total num played games": 44708, "Total num trained steps": 88832, "Timestamp in ms": 1699927548705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875997050740666, "Avg loss": 0.5644913807045668, "Avg value loss": 0.24093072721734643, "Avg policy loss": 0.3235606518574059, "Total num played games": 44757, "Total num trained steps": 88960, "Timestamp in ms": 1699927614836, "logtype": "training_step"}
{"Avg objective": 22.609375, "Games time in secs": 102.50388826802373, "Avg game time in secs": 1.3755205401103012, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.69}, "Total num played games": 44800, "Total num trained steps": 89007, "Timestamp in ms": 1699927638863, "logtype": "played_game"}
{"Total num played games": 44805, "Total num trained steps": 89084, "Timestamp in ms": 1699927749605, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7421875}
{"Ratio train steps to played games": 1.987395707848124, "Avg loss": 0.6463171909563243, "Avg value loss": 0.3154629879863933, "Avg policy loss": 0.3308542058803141, "Total num played games": 44826, "Total num trained steps": 89088, "Timestamp in ms": 1699927752254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869710467706014, "Avg loss": 0.7596560893580317, "Avg value loss": 0.4345038971514441, "Avg policy loss": 0.3251521942438558, "Total num played games": 44900, "Total num trained steps": 89216, "Timestamp in ms": 1699927812717, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 210.71946618705988, "Avg game time in secs": 1.568249170712079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 44928, "Total num trained steps": 89294, "Timestamp in ms": 1699927849583, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875864830593313, "Avg loss": 0.7064365136902779, "Avg value loss": 0.3744413967942819, "Avg policy loss": 0.3319951177109033, "Total num played games": 44951, "Total num trained steps": 89344, "Timestamp in ms": 1699927874826, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882444444444445, "Avg loss": 0.621509587392211, "Avg value loss": 0.28994392039021477, "Avg policy loss": 0.33156566601246595, "Total num played games": 45000, "Total num trained steps": 89472, "Timestamp in ms": 1699927938574, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 154.5548149123788, "Avg game time in secs": 1.390714959226898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.64}, "Total num played games": 45056, "Total num trained steps": 89592, "Timestamp in ms": 1699928004138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867402824896339, "Avg loss": 0.7377445495221764, "Avg value loss": 0.4135124437743798, "Avg policy loss": 0.32423210283741355, "Total num played games": 45099, "Total num trained steps": 89600, "Timestamp in ms": 1699928006948, "logtype": "training_step"}
{"Total num played games": 45102, "Total num trained steps": 89684, "Timestamp in ms": 1699928121862, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3203125}
{"Ratio train steps to played games": 1.987331118493909, "Avg loss": 0.8527557246852666, "Avg value loss": 0.5152967558824457, "Avg policy loss": 0.33745896571781486, "Total num played games": 45150, "Total num trained steps": 89728, "Timestamp in ms": 1699928143858, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 174.91061142645776, "Avg game time in secs": 1.2358758571208455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 45184, "Total num trained steps": 89791, "Timestamp in ms": 1699928179048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869535413395838, "Avg loss": 0.6643746169283986, "Avg value loss": 0.33021933783311397, "Avg policy loss": 0.3341552793281153, "Total num played games": 45223, "Total num trained steps": 89856, "Timestamp in ms": 1699928214448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876082346704365, "Avg loss": 0.568145555909723, "Avg value loss": 0.23390186775941402, "Avg policy loss": 0.3342436879174784, "Total num played games": 45272, "Total num trained steps": 89984, "Timestamp in ms": 1699928283478, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 131.92973629944026, "Avg game time in secs": 1.530466078344034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.76, "agent_stopped_0": 0.39}, "Total num played games": 45312, "Total num trained steps": 90036, "Timestamp in ms": 1699928310980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883274492497793, "Avg loss": 0.6491432564798743, "Avg value loss": 0.31072705175029114, "Avg policy loss": 0.33841620048042387, "Total num played games": 45320, "Total num trained steps": 90112, "Timestamp in ms": 1699928348724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98681168673903, "Avg loss": 0.8522029626183212, "Avg value loss": 0.5075141427223571, "Avg policy loss": 0.34468882449436933, "Total num played games": 45419, "Total num trained steps": 90240, "Timestamp in ms": 1699928416133, "logtype": "training_step"}
{"Total num played games": 45419, "Total num trained steps": 90284, "Timestamp in ms": 1699928531801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.03125}
{"Avg objective": 23.2890625, "Games time in secs": 222.9291346501559, "Avg game time in secs": 1.2702982136106584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 45440, "Total num trained steps": 90288, "Timestamp in ms": 1699928533909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875514109134098, "Avg loss": 0.8207394215278327, "Avg value loss": 0.4601178904995322, "Avg policy loss": 0.36062153754755855, "Total num played games": 45467, "Total num trained steps": 90368, "Timestamp in ms": 1699928576632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881582705362832, "Avg loss": 0.5766662883106619, "Avg value loss": 0.24790248443605378, "Avg policy loss": 0.3287637998582795, "Total num played games": 45517, "Total num trained steps": 90496, "Timestamp in ms": 1699928644742, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 171.7661762908101, "Avg game time in secs": 1.4435730997793144, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.66}, "Total num played games": 45568, "Total num trained steps": 90622, "Timestamp in ms": 1699928705676, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874991775774722, "Avg loss": 0.7061783482786268, "Avg value loss": 0.38580036198254675, "Avg policy loss": 0.32037798629608005, "Total num played games": 45595, "Total num trained steps": 90624, "Timestamp in ms": 1699928706332, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873426037446622, "Avg loss": 0.7938795275986195, "Avg value loss": 0.4684635372250341, "Avg policy loss": 0.32541597937233746, "Total num played games": 45665, "Total num trained steps": 90752, "Timestamp in ms": 1699928770519, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 100.8614805135876, "Avg game time in secs": 1.221124092291575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 45696, "Total num trained steps": 90820, "Timestamp in ms": 1699928806537, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880124250776567, "Avg loss": 0.780507244868204, "Avg value loss": 0.44432145613245666, "Avg policy loss": 0.3361857880372554, "Total num played games": 45714, "Total num trained steps": 90880, "Timestamp in ms": 1699928833930, "logtype": "training_step"}
{"Total num played games": 45714, "Total num trained steps": 90884, "Timestamp in ms": 1699928926234, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55078125}
{"Ratio train steps to played games": 1.988724269044185, "Avg loss": 0.592558033997193, "Avg value loss": 0.2655427671270445, "Avg policy loss": 0.32701526570599526, "Total num played games": 45762, "Total num trained steps": 91008, "Timestamp in ms": 1699928988172, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 236.1324305869639, "Avg game time in secs": 1.5079407369630644, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 45824, "Total num trained steps": 91118, "Timestamp in ms": 1699929042670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869405018858874, "Avg loss": 0.7189826564863324, "Avg value loss": 0.4008962289080955, "Avg policy loss": 0.3180864293826744, "Total num played games": 45867, "Total num trained steps": 91136, "Timestamp in ms": 1699929051265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875645185878867, "Avg loss": 0.6685635091271251, "Avg value loss": 0.34900536166969687, "Avg policy loss": 0.319558150251396, "Total num played games": 45917, "Total num trained steps": 91264, "Timestamp in ms": 1699929115505, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 103.48523647338152, "Avg game time in secs": 1.1889834792964393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 45952, "Total num trained steps": 91327, "Timestamp in ms": 1699929146155, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882089324950507, "Avg loss": 0.6911143956240267, "Avg value loss": 0.37461486883694306, "Avg policy loss": 0.31649952847510576, "Total num played games": 45967, "Total num trained steps": 91392, "Timestamp in ms": 1699929181268, "logtype": "training_step"}
{"Total num played games": 46016, "Total num trained steps": 91484, "Timestamp in ms": 1699929284940, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.703125}
{"Ratio train steps to played games": 1.9868009725599167, "Avg loss": 0.6447466383688152, "Avg value loss": 0.3262516195536591, "Avg policy loss": 0.31849501887336373, "Total num played games": 46064, "Total num trained steps": 91520, "Timestamp in ms": 1699929304968, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 211.22987203113735, "Avg game time in secs": 1.2811121453123633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 46080, "Total num trained steps": 91619, "Timestamp in ms": 1699929357385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874869882026371, "Avg loss": 0.5028108539991081, "Avg value loss": 0.2011536174104549, "Avg policy loss": 0.3016572342021391, "Total num played games": 46112, "Total num trained steps": 91648, "Timestamp in ms": 1699929373418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880640339665967, "Avg loss": 0.6579876497853547, "Avg value loss": 0.3461799098877236, "Avg policy loss": 0.31180773745290935, "Total num played games": 46163, "Total num trained steps": 91776, "Timestamp in ms": 1699929441540, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 107.4896051902324, "Avg game time in secs": 1.4460468348261202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.68}, "Total num played games": 46208, "Total num trained steps": 91820, "Timestamp in ms": 1699929464875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886828381624218, "Avg loss": 0.526836383389309, "Avg value loss": 0.21426812640856951, "Avg policy loss": 0.31256826035678387, "Total num played games": 46213, "Total num trained steps": 91904, "Timestamp in ms": 1699929513730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987302958324336, "Avg loss": 0.6658955910243094, "Avg value loss": 0.3500945445266552, "Avg policy loss": 0.31580104876775295, "Total num played games": 46310, "Total num trained steps": 92032, "Timestamp in ms": 1699929578010, "logtype": "training_step"}
{"Total num played games": 46310, "Total num trained steps": 92085, "Timestamp in ms": 1699929705158, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.21875}
{"Avg objective": 22.5703125, "Games time in secs": 242.41386440582573, "Avg game time in secs": 1.2399449143995298, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 46336, "Total num trained steps": 92089, "Timestamp in ms": 1699929707289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987984813840114, "Avg loss": 0.586341675138101, "Avg value loss": 0.27532939828233793, "Avg policy loss": 0.3110122767975554, "Total num played games": 46358, "Total num trained steps": 92160, "Timestamp in ms": 1699929746277, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988665503049109, "Avg loss": 0.5874498314224184, "Avg value loss": 0.27792056842008606, "Avg policy loss": 0.3095292616635561, "Total num played games": 46407, "Total num trained steps": 92288, "Timestamp in ms": 1699929819980, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 181.1067465506494, "Avg game time in secs": 1.2616196458548075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.63}, "Total num played games": 46464, "Total num trained steps": 92401, "Timestamp in ms": 1699929888396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872699122656117, "Avg loss": 0.7405141303315759, "Avg value loss": 0.4230823411489837, "Avg policy loss": 0.3174317965749651, "Total num played games": 46504, "Total num trained steps": 92416, "Timestamp in ms": 1699929898508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987906257384057, "Avg loss": 0.9175246271770447, "Avg value loss": 0.5906148753711022, "Avg policy loss": 0.32690976036246866, "Total num played games": 46553, "Total num trained steps": 92544, "Timestamp in ms": 1699929976115, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 118.1367170996964, "Avg game time in secs": 1.1465729511692189, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 46592, "Total num trained steps": 92598, "Timestamp in ms": 1699930006533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98856272262993, "Avg loss": 0.5314832949079573, "Avg value loss": 0.21310279937461019, "Avg policy loss": 0.31838049553334713, "Total num played games": 46602, "Total num trained steps": 92672, "Timestamp in ms": 1699930047273, "logtype": "training_step"}
{"Total num played games": 46602, "Total num trained steps": 92686, "Timestamp in ms": 1699930078469, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4921875}
{"Ratio train steps to played games": 1.9871731728730808, "Avg loss": 0.7137776708696038, "Avg value loss": 0.4044619027408771, "Avg policy loss": 0.309315774589777, "Total num played games": 46699, "Total num trained steps": 92800, "Timestamp in ms": 1699930153151, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 194.9445060864091, "Avg game time in secs": 1.1822519848210504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 46720, "Total num trained steps": 92889, "Timestamp in ms": 1699930201477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878283562933174, "Avg loss": 0.6196517487987876, "Avg value loss": 0.3114760828902945, "Avg policy loss": 0.30817566823679954, "Total num played games": 46748, "Total num trained steps": 92928, "Timestamp in ms": 1699930222495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884821676603202, "Avg loss": 0.5997452046722174, "Avg value loss": 0.28963958809617907, "Avg policy loss": 0.31010562321171165, "Total num played games": 46797, "Total num trained steps": 93056, "Timestamp in ms": 1699930294696, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 158.86817255802453, "Avg game time in secs": 1.4181802638922818, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.72, "agent_stopped_0": 0.38}, "Total num played games": 46848, "Total num trained steps": 93182, "Timestamp in ms": 1699930360346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987564788942687, "Avg loss": 0.5785188456065953, "Avg value loss": 0.2731119882664643, "Avg policy loss": 0.3054068523924798, "Total num played games": 46883, "Total num trained steps": 93184, "Timestamp in ms": 1699930362384, "logtype": "training_step"}
{"Total num played games": 46942, "Total num trained steps": 93286, "Timestamp in ms": 1699930453358, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.94140625}
{"Avg objective": 21.109375, "Games time in secs": 95.830227131024, "Avg game time in secs": 1.3026649364328478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 46976, "Total num trained steps": 93287, "Timestamp in ms": 1699930456176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857629282826132, "Avg loss": 0.7713980223052204, "Avg value loss": 0.4721864342573099, "Avg policy loss": 0.29921159229706973, "Total num played games": 46990, "Total num trained steps": 93312, "Timestamp in ms": 1699930470081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884869121089594, "Avg loss": 0.46855012723244727, "Avg value loss": 0.16899370087776333, "Avg policy loss": 0.2995564251905307, "Total num played games": 46990, "Total num trained steps": 93440, "Timestamp in ms": 1699930537341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890310786106034, "Avg loss": 0.4519865980837494, "Avg value loss": 0.17289450418320484, "Avg policy loss": 0.27909209521021694, "Total num played games": 47042, "Total num trained steps": 93568, "Timestamp in ms": 1699930604573, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 208.87657249346375, "Avg game time in secs": 1.172902981954394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.51}, "Total num played games": 47104, "Total num trained steps": 93682, "Timestamp in ms": 1699930665053, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871264660346546, "Avg loss": 0.687746825395152, "Avg value loss": 0.40292567893629894, "Avg policy loss": 0.28482114744838327, "Total num played games": 47151, "Total num trained steps": 93696, "Timestamp in ms": 1699930670873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877544967267642, "Avg loss": 0.6618202331010252, "Avg value loss": 0.3807666851207614, "Avg policy loss": 0.2810535525204614, "Total num played games": 47201, "Total num trained steps": 93824, "Timestamp in ms": 1699930732857, "logtype": "training_step"}
{"Total num played games": 47201, "Total num trained steps": 93887, "Timestamp in ms": 1699930821188, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.73046875}
{"Avg objective": 21.84375, "Games time in secs": 158.3874727282673, "Avg game time in secs": 1.1866482966725016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 47232, "Total num trained steps": 93890, "Timestamp in ms": 1699930823440, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884230354081567, "Avg loss": 0.5886479208711535, "Avg value loss": 0.30484502884792164, "Avg policy loss": 0.2838028874248266, "Total num played games": 47249, "Total num trained steps": 93952, "Timestamp in ms": 1699930858910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988732930283685, "Avg loss": 0.6080796183086932, "Avg value loss": 0.32518626790260896, "Avg policy loss": 0.28289334441069514, "Total num played games": 47306, "Total num trained steps": 94080, "Timestamp in ms": 1699930926364, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 169.4687273837626, "Avg game time in secs": 1.3055862834880827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.56}, "Total num played games": 47360, "Total num trained steps": 94200, "Timestamp in ms": 1699930992909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873636689660992, "Avg loss": 0.5291857777629048, "Avg value loss": 0.2455823059717659, "Avg policy loss": 0.2836034724023193, "Total num played games": 47403, "Total num trained steps": 94208, "Timestamp in ms": 1699930997202, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880089353451909, "Avg loss": 0.7974050513003021, "Avg value loss": 0.5023202478187159, "Avg policy loss": 0.29508479312062263, "Total num played games": 47452, "Total num trained steps": 94336, "Timestamp in ms": 1699931067825, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 107.54761711135507, "Avg game time in secs": 1.1836743197927717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 47488, "Total num trained steps": 94395, "Timestamp in ms": 1699931100457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887157894736842, "Avg loss": 0.6078768109437078, "Avg value loss": 0.31918244750704616, "Avg policy loss": 0.288694363553077, "Total num played games": 47500, "Total num trained steps": 94464, "Timestamp in ms": 1699931139783, "logtype": "training_step"}
{"Total num played games": 47548, "Total num trained steps": 94490, "Timestamp in ms": 1699931239631, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.41015625}
{"Ratio train steps to played games": 1.9873728884780233, "Avg loss": 0.8487654326017946, "Avg value loss": 0.5554563507321291, "Avg policy loss": 0.29330907156690955, "Total num played games": 47596, "Total num trained steps": 94592, "Timestamp in ms": 1699931300386, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 244.75409426167607, "Avg game time in secs": 1.0821016768168192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 47616, "Total num trained steps": 94682, "Timestamp in ms": 1699931345211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880572579968097, "Avg loss": 0.6219352053012699, "Avg value loss": 0.3443530302902218, "Avg policy loss": 0.27758217277005315, "Total num played games": 47644, "Total num trained steps": 94720, "Timestamp in ms": 1699931364241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988469359944653, "Avg loss": 0.9025340159423649, "Avg value loss": 0.6055134610505775, "Avg policy loss": 0.2970205411547795, "Total num played games": 47699, "Total num trained steps": 94848, "Timestamp in ms": 1699931430737, "logtype": "training_step"}
{"Avg objective": 23.1640625, "Games time in secs": 110.67479101195931, "Avg game time in secs": 1.2086143494962016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.58}, "Total num played games": 47744, "Total num trained steps": 94891, "Timestamp in ms": 1699931455886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890468910343673, "Avg loss": 0.6512649096548557, "Avg value loss": 0.3678176812827587, "Avg policy loss": 0.2834472289541736, "Total num played games": 47749, "Total num trained steps": 94976, "Timestamp in ms": 1699931503961, "logtype": "training_step"}
{"Total num played games": 47846, "Total num trained steps": 95092, "Timestamp in ms": 1699931626766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.58203125}
{"Avg objective": 21.59375, "Games time in secs": 172.78542723879218, "Avg game time in secs": 1.168365396282752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.54, "agent_stopped_0": 0.56}, "Total num played games": 47872, "Total num trained steps": 95096, "Timestamp in ms": 1699931628672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856975821606047, "Avg loss": 0.6689451783895493, "Avg value loss": 0.39601042034337297, "Avg policy loss": 0.27293476019985974, "Total num played games": 47894, "Total num trained steps": 95104, "Timestamp in ms": 1699931632715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988370150749572, "Avg loss": 0.49611343280412257, "Avg value loss": 0.21104064211249352, "Avg policy loss": 0.28507279010955244, "Total num played games": 47894, "Total num trained steps": 95232, "Timestamp in ms": 1699931703803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890492678653373, "Avg loss": 0.47378818690776825, "Avg value loss": 0.20417969272239134, "Avg policy loss": 0.26960849028546363, "Total num played games": 47942, "Total num trained steps": 95360, "Timestamp in ms": 1699931767904, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 204.40280243568122, "Avg game time in secs": 1.2254823329712963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.58}, "Total num played games": 48000, "Total num trained steps": 95470, "Timestamp in ms": 1699931833075, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877388733918981, "Avg loss": 0.7358862610999495, "Avg value loss": 0.4633846070501022, "Avg policy loss": 0.2725016523618251, "Total num played games": 48038, "Total num trained steps": 95488, "Timestamp in ms": 1699931842609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882925409137224, "Avg loss": 0.561772087123245, "Avg value loss": 0.2802603197633289, "Avg policy loss": 0.281511768582277, "Total num played games": 48089, "Total num trained steps": 95616, "Timestamp in ms": 1699931903772, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 100.79092102311552, "Avg game time in secs": 1.1540629904338857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 48128, "Total num trained steps": 95669, "Timestamp in ms": 1699931933866, "logtype": "played_game"}
{"Total num played games": 48138, "Total num trained steps": 95694, "Timestamp in ms": 1699931992972, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8984375}
{"Ratio train steps to played games": 1.986946415971444, "Avg loss": 0.7144490766804665, "Avg value loss": 0.43350779823958874, "Avg policy loss": 0.28094127820804715, "Total num played games": 48186, "Total num trained steps": 95744, "Timestamp in ms": 1699932019739, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876228386615251, "Avg loss": 0.42993217380717397, "Avg value loss": 0.15229680063202977, "Avg policy loss": 0.2776353732915595, "Total num played games": 48234, "Total num trained steps": 95872, "Timestamp in ms": 1699932081157, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 194.04313434287906, "Avg game time in secs": 1.2855221063655335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 48256, "Total num trained steps": 95960, "Timestamp in ms": 1699932127909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881743812778296, "Avg loss": 0.5685126222670078, "Avg value loss": 0.288918548845686, "Avg policy loss": 0.27959407528396696, "Total num played games": 48285, "Total num trained steps": 96000, "Timestamp in ms": 1699932147381, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887865935657392, "Avg loss": 0.5422247685492039, "Avg value loss": 0.26110144396079704, "Avg policy loss": 0.28112332080490887, "Total num played games": 48335, "Total num trained steps": 96128, "Timestamp in ms": 1699932218184, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 109.8826663158834, "Avg game time in secs": 1.1874595234985463, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.65}, "Total num played games": 48384, "Total num trained steps": 96165, "Timestamp in ms": 1699932237792, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893973214285714, "Avg loss": 0.4881143702659756, "Avg value loss": 0.21133577323053032, "Avg policy loss": 0.2767785966861993, "Total num played games": 48384, "Total num trained steps": 96256, "Timestamp in ms": 1699932281844, "logtype": "training_step"}
{"Total num played games": 48434, "Total num trained steps": 96296, "Timestamp in ms": 1699932331670, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.55078125}
{"Ratio train steps to played games": 1.9880161709500432, "Avg loss": 0.6528592719696462, "Avg value loss": 0.35934615798760206, "Avg policy loss": 0.2935131130507216, "Total num played games": 48482, "Total num trained steps": 96384, "Timestamp in ms": 1699932382132, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 181.83128170482814, "Avg game time in secs": 0.973084286408266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 48512, "Total num trained steps": 96453, "Timestamp in ms": 1699932419624, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887080156604162, "Avg loss": 0.4908045968040824, "Avg value loss": 0.21023197079193778, "Avg policy loss": 0.28057262673974037, "Total num played games": 48530, "Total num trained steps": 96512, "Timestamp in ms": 1699932447521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989214112222634, "Avg loss": 0.47201566328294575, "Avg value loss": 0.19656095025129616, "Avg policy loss": 0.2754547137301415, "Total num played games": 48582, "Total num trained steps": 96640, "Timestamp in ms": 1699932512652, "logtype": "training_step"}
{"Avg objective": 20.4296875, "Games time in secs": 149.369454247877, "Avg game time in secs": 1.0930886920978082, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 48640, "Total num trained steps": 96752, "Timestamp in ms": 1699932568993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987859241151215, "Avg loss": 0.6014436334371567, "Avg value loss": 0.3219708528195042, "Avg policy loss": 0.27947277028579265, "Total num played games": 48679, "Total num trained steps": 96768, "Timestamp in ms": 1699932579369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885279208652287, "Avg loss": 0.5598403625190258, "Avg value loss": 0.2725920708035119, "Avg policy loss": 0.2872482887469232, "Total num played games": 48727, "Total num trained steps": 96896, "Timestamp in ms": 1699932650036, "logtype": "training_step"}
{"Total num played games": 48727, "Total num trained steps": 96896, "Timestamp in ms": 1699932736274, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9609375}
{"Avg objective": 21.640625, "Games time in secs": 170.19189572148025, "Avg game time in secs": 1.1897431183169829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 48768, "Total num trained steps": 96902, "Timestamp in ms": 1699932739185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989195284469503, "Avg loss": 0.5226363842375576, "Avg value loss": 0.22525808465434238, "Avg policy loss": 0.29737829649820924, "Total num played games": 48775, "Total num trained steps": 97024, "Timestamp in ms": 1699932799648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987581579001207, "Avg loss": 0.677795399678871, "Avg value loss": 0.39316274115117267, "Avg policy loss": 0.2846326665021479, "Total num played games": 48879, "Total num trained steps": 97152, "Timestamp in ms": 1699932865741, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 181.66450767219067, "Avg game time in secs": 1.1676516266452381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 48896, "Total num trained steps": 97249, "Timestamp in ms": 1699932920850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988125894134478, "Avg loss": 0.808905903948471, "Avg value loss": 0.5135129855189007, "Avg policy loss": 0.2953929245704785, "Total num played games": 48930, "Total num trained steps": 97280, "Timestamp in ms": 1699932937153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887908857037855, "Avg loss": 0.6391721717081964, "Avg value loss": 0.3419043035246432, "Avg policy loss": 0.2972678708611056, "Total num played games": 48978, "Total num trained steps": 97408, "Timestamp in ms": 1699933011984, "logtype": "training_step"}
{"Avg objective": 22.46875, "Games time in secs": 113.38125080801547, "Avg game time in secs": 1.2285659304470755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.7, "agent_stopped_0": 0.42}, "Total num played games": 49024, "Total num trained steps": 97448, "Timestamp in ms": 1699933034231, "logtype": "played_game"}
{"Total num played games": 49029, "Total num trained steps": 97496, "Timestamp in ms": 1699933107199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.69921875}
{"Ratio train steps to played games": 1.9873871671047538, "Avg loss": 0.8808084281627089, "Avg value loss": 0.5723109249374829, "Avg policy loss": 0.3084974972298369, "Total num played games": 49077, "Total num trained steps": 97536, "Timestamp in ms": 1699933129765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880104221797013, "Avg loss": 0.5887261754833162, "Avg value loss": 0.2906753981951624, "Avg policy loss": 0.2980507796164602, "Total num played games": 49126, "Total num trained steps": 97664, "Timestamp in ms": 1699933202260, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 210.8596927355975, "Avg game time in secs": 1.0423028890654678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.49, "agent_stopped_0": 0.57}, "Total num played games": 49152, "Total num trained steps": 97744, "Timestamp in ms": 1699933245091, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886324351804778, "Avg loss": 0.7398816770873964, "Avg value loss": 0.4403407530626282, "Avg policy loss": 0.2995409226277843, "Total num played games": 49175, "Total num trained steps": 97792, "Timestamp in ms": 1699933267745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989293622899864, "Avg loss": 0.5027884340379387, "Avg value loss": 0.20553392614237964, "Avg policy loss": 0.2972545106895268, "Total num played games": 49223, "Total num trained steps": 97920, "Timestamp in ms": 1699933334880, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 99.63367567583919, "Avg game time in secs": 1.272175428661285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 49280, "Total num trained steps": 97938, "Timestamp in ms": 1699933344725, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989468985248463, "Avg loss": 0.5480130426585674, "Avg value loss": 0.24950139812426642, "Avg policy loss": 0.29851165041327477, "Total num played games": 49283, "Total num trained steps": 98048, "Timestamp in ms": 1699933403226, "logtype": "training_step"}
{"Total num played games": 49332, "Total num trained steps": 98097, "Timestamp in ms": 1699933502326, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.62109375}
{"Ratio train steps to played games": 1.9881530984204132, "Avg loss": 0.8036807274911553, "Avg value loss": 0.49892167490907013, "Avg policy loss": 0.30475904792547226, "Total num played games": 49380, "Total num trained steps": 98176, "Timestamp in ms": 1699933547409, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 246.64429884590209, "Avg game time in secs": 1.1349623337591765, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 49408, "Total num trained steps": 98252, "Timestamp in ms": 1699933591369, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888322408351542, "Avg loss": 0.8460088627180085, "Avg value loss": 0.5506498148024548, "Avg policy loss": 0.29535906470846385, "Total num played games": 49428, "Total num trained steps": 98304, "Timestamp in ms": 1699933623183, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892686081526243, "Avg loss": 0.7541190404444933, "Avg value loss": 0.43336242012446746, "Avg policy loss": 0.3207566246856004, "Total num played games": 49481, "Total num trained steps": 98432, "Timestamp in ms": 1699933688912, "logtype": "training_step"}
{"Avg objective": 22.9765625, "Games time in secs": 163.3162250649184, "Avg game time in secs": 1.1804184429201996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.67}, "Total num played games": 49536, "Total num trained steps": 98551, "Timestamp in ms": 1699933754686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987878176684147, "Avg loss": 0.7823256924748421, "Avg value loss": 0.4785884353914298, "Avg policy loss": 0.3037372628459707, "Total num played games": 49580, "Total num trained steps": 98560, "Timestamp in ms": 1699933758897, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885346981542678, "Avg loss": 0.7774770518299192, "Avg value loss": 0.4680345359374769, "Avg policy loss": 0.30944251036271453, "Total num played games": 49628, "Total num trained steps": 98688, "Timestamp in ms": 1699933823357, "logtype": "training_step"}
{"Total num played games": 49628, "Total num trained steps": 98699, "Timestamp in ms": 1699933899141, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.171875}
{"Avg objective": 20.796875, "Games time in secs": 146.84538734704256, "Avg game time in secs": 1.1578934989811387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 49664, "Total num trained steps": 98700, "Timestamp in ms": 1699933901531, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891899508817135, "Avg loss": 0.5799998200964183, "Avg value loss": 0.2737118625664152, "Avg policy loss": 0.3062879528151825, "Total num played games": 49676, "Total num trained steps": 98816, "Timestamp in ms": 1699933964776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987964879146491, "Avg loss": 0.5713023610878736, "Avg value loss": 0.2722853453597054, "Avg policy loss": 0.2990170164266601, "Total num played games": 49771, "Total num trained steps": 98944, "Timestamp in ms": 1699934029413, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 172.465290883556, "Avg game time in secs": 1.1593028537172358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.51, "agent_stopped_0": 0.57}, "Total num played games": 49792, "Total num trained steps": 99037, "Timestamp in ms": 1699934073997, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885389695108489, "Avg loss": 0.8082657300401479, "Avg value loss": 0.5165198277099989, "Avg policy loss": 0.2917459027376026, "Total num played games": 49821, "Total num trained steps": 99072, "Timestamp in ms": 1699934090860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891119087245093, "Avg loss": 0.7190723773092031, "Avg value loss": 0.4149815908749588, "Avg policy loss": 0.30409079045057297, "Total num played games": 49871, "Total num trained steps": 99200, "Timestamp in ms": 1699934158016, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 101.89803376607597, "Avg game time in secs": 1.194577799687977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 49920, "Total num trained steps": 99233, "Timestamp in ms": 1699934175895, "logtype": "played_game"}
{"Total num played games": 49938, "Total num trained steps": 99299, "Timestamp in ms": 1699934263353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.33203125}
{"Ratio train steps to played games": 1.9870963869883567, "Avg loss": 0.71585129853338, "Avg value loss": 0.40273644658736885, "Avg policy loss": 0.3131148498505354, "Total num played games": 49986, "Total num trained steps": 99328, "Timestamp in ms": 1699934279527, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896771095906853, "Avg loss": 0.4194136131554842, "Avg value loss": 0.11589060252299532, "Avg policy loss": 0.3035230084788054, "Total num played games": 49986, "Total num trained steps": 99456, "Timestamp in ms": 1699934347538, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 220.97141822613776, "Avg game time in secs": 1.2068540191830834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.6}, "Total num played games": 50048, "Total num trained steps": 99561, "Timestamp in ms": 1699934396867, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882601924689534, "Avg loss": 0.7477728859521449, "Avg value loss": 0.4391410618554801, "Avg policy loss": 0.30863181955646724, "Total num played games": 50086, "Total num trained steps": 99584, "Timestamp in ms": 1699934409558, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888501047172633, "Avg loss": 0.6471299885306507, "Avg value loss": 0.33102568791946396, "Avg policy loss": 0.3161043004365638, "Total num played games": 50135, "Total num trained steps": 99712, "Timestamp in ms": 1699934479160, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 108.47043902799487, "Avg game time in secs": 1.1385902698821155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 50176, "Total num trained steps": 99763, "Timestamp in ms": 1699934505337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894984357252457, "Avg loss": 0.5424947100691497, "Avg value loss": 0.2284351694979705, "Avg policy loss": 0.314059542841278, "Total num played games": 50183, "Total num trained steps": 99840, "Timestamp in ms": 1699934541901, "logtype": "training_step"}
{"Total num played games": 50233, "Total num trained steps": 99899, "Timestamp in ms": 1699934620645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.80859375}
{"Ratio train steps to played games": 1.9881665042461367, "Avg loss": 0.8613903059158474, "Avg value loss": 0.5438513996195979, "Avg policy loss": 0.3175389014650136, "Total num played games": 50281, "Total num trained steps": 99968, "Timestamp in ms": 1699934658920, "logtype": "training_step"}
{"Avg objective": 22.4375, "Games time in secs": 199.55358308553696, "Avg game time in secs": 1.2115601689874893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 50304, "Total num trained steps": 100052, "Timestamp in ms": 1699934704891, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988813606469431, "Avg loss": 0.5838577458634973, "Avg value loss": 0.27525174285983667, "Avg policy loss": 0.30860599980223924, "Total num played games": 50329, "Total num trained steps": 100096, "Timestamp in ms": 1699934728669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894594755543205, "Avg loss": 0.4981672714930028, "Avg value loss": 0.19313401530962437, "Avg policy loss": 0.3050332594430074, "Total num played games": 50377, "Total num trained steps": 100224, "Timestamp in ms": 1699934796963, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 155.4716733172536, "Avg game time in secs": 1.226283665295341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 50432, "Total num trained steps": 100340, "Timestamp in ms": 1699934860363, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881525507677067, "Avg loss": 0.6739515536464751, "Avg value loss": 0.36353675194550306, "Avg policy loss": 0.31041479913983494, "Total num played games": 50475, "Total num trained steps": 100352, "Timestamp in ms": 1699934866086, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887971814817014, "Avg loss": 0.8281485950574279, "Avg value loss": 0.5156183913932182, "Avg policy loss": 0.3125301911495626, "Total num played games": 50523, "Total num trained steps": 100480, "Timestamp in ms": 1699934937348, "logtype": "training_step"}
{"Total num played games": 50523, "Total num trained steps": 100500, "Timestamp in ms": 1699935015457, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.26171875}
{"Avg objective": 22.1171875, "Games time in secs": 157.65022825077176, "Avg game time in secs": 1.082694902914227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 50560, "Total num trained steps": 100503, "Timestamp in ms": 1699935018013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894405884795634, "Avg loss": 0.529171455418691, "Avg value loss": 0.214878112077713, "Avg policy loss": 0.31429333868436515, "Total num played games": 50571, "Total num trained steps": 100608, "Timestamp in ms": 1699935074168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881777093571753, "Avg loss": 0.6632268819957972, "Avg value loss": 0.3619493414298631, "Avg policy loss": 0.30127754050772637, "Total num played games": 50667, "Total num trained steps": 100736, "Timestamp in ms": 1699935142184, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 173.51973674818873, "Avg game time in secs": 1.1237435113289393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.5}, "Total num played games": 50688, "Total num trained steps": 100824, "Timestamp in ms": 1699935191533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887414476408305, "Avg loss": 0.7170902444049716, "Avg value loss": 0.4041833546361886, "Avg policy loss": 0.31290688610170037, "Total num played games": 50717, "Total num trained steps": 100864, "Timestamp in ms": 1699935211003, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893040754821045, "Avg loss": 0.6952027063816786, "Avg value loss": 0.3905480314861052, "Avg policy loss": 0.3046546730911359, "Total num played games": 50767, "Total num trained steps": 100992, "Timestamp in ms": 1699935276678, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 104.92838638462126, "Avg game time in secs": 1.4092421501409262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.8, "agent_stopped_0": 0.32}, "Total num played games": 50816, "Total num trained steps": 101034, "Timestamp in ms": 1699935296462, "logtype": "played_game"}
{"Total num played games": 50816, "Total num trained steps": 101104, "Timestamp in ms": 1699935402576, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1171875}
{"Ratio train steps to played games": 1.9880268952500786, "Avg loss": 0.5927000569645315, "Avg value loss": 0.2860054048942402, "Avg policy loss": 0.3066946540493518, "Total num played games": 50864, "Total num trained steps": 101120, "Timestamp in ms": 1699935411299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886276589476166, "Avg loss": 0.6058252521324903, "Avg value loss": 0.2935144173097797, "Avg policy loss": 0.3123108318541199, "Total num played games": 50913, "Total num trained steps": 101248, "Timestamp in ms": 1699935488507, "logtype": "training_step"}
{"Avg objective": 22.8515625, "Games time in secs": 229.2917189784348, "Avg game time in secs": 1.0584511542401742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 50944, "Total num trained steps": 101315, "Timestamp in ms": 1699935525754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891688250529787, "Avg loss": 0.8363576959818602, "Avg value loss": 0.5133505299454555, "Avg policy loss": 0.323007165803574, "Total num played games": 50964, "Total num trained steps": 101376, "Timestamp in ms": 1699935559867, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989767314214024, "Avg loss": 0.5766004531178623, "Avg value loss": 0.25869133247761056, "Avg policy loss": 0.31790911441203207, "Total num played games": 51013, "Total num trained steps": 101504, "Timestamp in ms": 1699935631808, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 165.2033832333982, "Avg game time in secs": 1.2670954908244312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 51072, "Total num trained steps": 101611, "Timestamp in ms": 1699935690957, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884758364312267, "Avg loss": 0.6386869663838297, "Avg value loss": 0.32912208867492154, "Avg policy loss": 0.30956487904768437, "Total num played games": 51110, "Total num trained steps": 101632, "Timestamp in ms": 1699935702655, "logtype": "training_step"}
{"Total num played games": 51110, "Total num trained steps": 101706, "Timestamp in ms": 1699935788995, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6171875}
{"Ratio train steps to played games": 1.9888984442185913, "Avg loss": 0.647343497723341, "Avg value loss": 0.3381745802471414, "Avg policy loss": 0.3091689172433689, "Total num played games": 51164, "Total num trained steps": 101760, "Timestamp in ms": 1699935820355, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 164.54475857131183, "Avg game time in secs": 1.0707014393265126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 51200, "Total num trained steps": 101820, "Timestamp in ms": 1699935855502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894753285298654, "Avg loss": 0.6836299754213542, "Avg value loss": 0.36918728199088946, "Avg policy loss": 0.3144426919752732, "Total num played games": 51213, "Total num trained steps": 101888, "Timestamp in ms": 1699935892594, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887710542732377, "Avg loss": 0.6280739123467356, "Avg value loss": 0.31116306100739166, "Avg policy loss": 0.3169108509318903, "Total num played games": 51290, "Total num trained steps": 102016, "Timestamp in ms": 1699935962969, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 157.06145760789514, "Avg game time in secs": 1.1656888909928966, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 51328, "Total num trained steps": 102113, "Timestamp in ms": 1699936012564, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886301689899542, "Avg loss": 0.6933045042678714, "Avg value loss": 0.39496218925341964, "Avg policy loss": 0.2983423180412501, "Total num played games": 51364, "Total num trained steps": 102144, "Timestamp in ms": 1699936027190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892437563214813, "Avg loss": 0.5088538059499115, "Avg value loss": 0.21769535762723535, "Avg policy loss": 0.2911584482062608, "Total num played games": 51412, "Total num trained steps": 102272, "Timestamp in ms": 1699936093927, "logtype": "training_step"}
{"Total num played games": 51412, "Total num trained steps": 102306, "Timestamp in ms": 1699936215542, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1875}
{"Avg objective": 22.3203125, "Games time in secs": 205.55493192002177, "Avg game time in secs": 1.1134798155108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 51456, "Total num trained steps": 102309, "Timestamp in ms": 1699936218119, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898950641274777, "Avg loss": 0.5849671608302742, "Avg value loss": 0.29771723924204707, "Avg policy loss": 0.28724992007482797, "Total num played games": 51460, "Total num trained steps": 102400, "Timestamp in ms": 1699936264344, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988383142951341, "Avg loss": 0.5879459988791496, "Avg value loss": 0.3199741393327713, "Avg policy loss": 0.2679718555882573, "Total num played games": 51563, "Total num trained steps": 102528, "Timestamp in ms": 1699936326024, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 150.53721232526004, "Avg game time in secs": 1.1039393404644215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.44, "agent_stopped_0": 0.62}, "Total num played games": 51584, "Total num trained steps": 102617, "Timestamp in ms": 1699936368656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888792017824275, "Avg loss": 0.5954306162893772, "Avg value loss": 0.3030404185410589, "Avg policy loss": 0.29239019856322557, "Total num played games": 51615, "Total num trained steps": 102656, "Timestamp in ms": 1699936386452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989374056439438, "Avg loss": 0.6432348843663931, "Avg value loss": 0.35329260904109105, "Avg policy loss": 0.28994227771181613, "Total num played games": 51666, "Total num trained steps": 102784, "Timestamp in ms": 1699936446043, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 96.78433563187718, "Avg game time in secs": 1.2499892699852353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.69, "agent_stopped_0": 0.42}, "Total num played games": 51712, "Total num trained steps": 102826, "Timestamp in ms": 1699936465441, "logtype": "played_game"}
{"Total num played games": 51714, "Total num trained steps": 102906, "Timestamp in ms": 1699936566935, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.87890625}
{"Ratio train steps to played games": 1.9881573354970827, "Avg loss": 0.6681977140251547, "Avg value loss": 0.36803818331100047, "Avg policy loss": 0.30015952861867845, "Total num played games": 51762, "Total num trained steps": 102912, "Timestamp in ms": 1699936571464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888052499517468, "Avg loss": 0.7580676001962274, "Avg value loss": 0.4622748967958614, "Avg policy loss": 0.29579271050170064, "Total num played games": 51810, "Total num trained steps": 103040, "Timestamp in ms": 1699936642375, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 212.26854226738214, "Avg game time in secs": 1.1333166689873906, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 51840, "Total num trained steps": 103112, "Timestamp in ms": 1699936677709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892599591222861, "Avg loss": 0.681433851365, "Avg value loss": 0.37282158387824893, "Avg policy loss": 0.3086122691165656, "Total num played games": 51862, "Total num trained steps": 103168, "Timestamp in ms": 1699936705550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897906112149173, "Avg loss": 0.6137923491187394, "Avg value loss": 0.3144724261946976, "Avg policy loss": 0.299319927347824, "Total num played games": 51913, "Total num trained steps": 103296, "Timestamp in ms": 1699936775839, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 159.52442156337202, "Avg game time in secs": 1.235193053551484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 51968, "Total num trained steps": 103416, "Timestamp in ms": 1699936837234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988368516168724, "Avg loss": 0.5981872740667313, "Avg value loss": 0.30052391724893823, "Avg policy loss": 0.2976633553626016, "Total num played games": 52014, "Total num trained steps": 103424, "Timestamp in ms": 1699936842073, "logtype": "training_step"}
{"Total num played games": 52014, "Total num trained steps": 103508, "Timestamp in ms": 1699936962615, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.890625}
{"Ratio train steps to played games": 1.9889938918981214, "Avg loss": 0.7387399710714817, "Avg value loss": 0.4254223394091241, "Avg policy loss": 0.3133176467381418, "Total num played games": 52062, "Total num trained steps": 103552, "Timestamp in ms": 1699936989781, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 189.39857046864927, "Avg game time in secs": 1.1457871447491925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 52096, "Total num trained steps": 103616, "Timestamp in ms": 1699937026633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989541756217378, "Avg loss": 0.5455837699119002, "Avg value loss": 0.24228431895608082, "Avg policy loss": 0.3032994457753375, "Total num played games": 52112, "Total num trained steps": 103680, "Timestamp in ms": 1699937061834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901267230306168, "Avg loss": 0.6073097300250083, "Avg value loss": 0.30243377306032926, "Avg policy loss": 0.3048759624361992, "Total num played games": 52161, "Total num trained steps": 103808, "Timestamp in ms": 1699937127645, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 156.59650497697294, "Avg game time in secs": 1.2075986452837242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 52224, "Total num trained steps": 103908, "Timestamp in ms": 1699937183229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889201446696136, "Avg loss": 0.8319095463957638, "Avg value loss": 0.5159551394754089, "Avg policy loss": 0.31595440790988505, "Total num played games": 52257, "Total num trained steps": 103936, "Timestamp in ms": 1699937197783, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989561227416117, "Avg loss": 0.7374179856851697, "Avg value loss": 0.4232861941563897, "Avg policy loss": 0.31413179251831025, "Total num played games": 52305, "Total num trained steps": 104064, "Timestamp in ms": 1699937268451, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 107.29575957357883, "Avg game time in secs": 1.2828207127022324, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.69}, "Total num played games": 52352, "Total num trained steps": 104101, "Timestamp in ms": 1699937290525, "logtype": "played_game"}
{"Total num played games": 52355, "Total num trained steps": 104109, "Timestamp in ms": 1699937370223, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.4453125}
{"Ratio train steps to played games": 1.9882640306852661, "Avg loss": 0.9107662246096879, "Avg value loss": 0.5964411876047961, "Avg policy loss": 0.31432503450196236, "Total num played games": 52403, "Total num trained steps": 104192, "Timestamp in ms": 1699937417073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887331998856161, "Avg loss": 0.46376886684447527, "Avg value loss": 0.1727178646833636, "Avg policy loss": 0.29105100443121046, "Total num played games": 52455, "Total num trained steps": 104320, "Timestamp in ms": 1699937482648, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 232.51166917011142, "Avg game time in secs": 1.087145843062899, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 52480, "Total num trained steps": 104402, "Timestamp in ms": 1699937523037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893150998019198, "Avg loss": 0.7224689822178334, "Avg value loss": 0.4190980853745714, "Avg policy loss": 0.3033708946313709, "Total num played games": 52504, "Total num trained steps": 104448, "Timestamp in ms": 1699937543079, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899528086466738, "Avg loss": 0.7703973317984492, "Avg value loss": 0.45519716042326763, "Avg policy loss": 0.31520016270224005, "Total num played games": 52552, "Total num trained steps": 104576, "Timestamp in ms": 1699937608792, "logtype": "training_step"}
{"Avg objective": 22.90625, "Games time in secs": 152.231327470392, "Avg game time in secs": 1.256948135443963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.64, "agent_stopped_0": 0.44}, "Total num played games": 52608, "Total num trained steps": 104692, "Timestamp in ms": 1699937675272, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886609686609686, "Avg loss": 0.6205197898671031, "Avg value loss": 0.3182301642955281, "Avg policy loss": 0.3022896258626133, "Total num played games": 52650, "Total num trained steps": 104704, "Timestamp in ms": 1699937682235, "logtype": "training_step"}
{"Total num played games": 52650, "Total num trained steps": 104712, "Timestamp in ms": 1699937759926, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.21875}
{"Ratio train steps to played games": 1.989297506546738, "Avg loss": 0.5532822345849127, "Avg value loss": 0.2552043544128537, "Avg policy loss": 0.29807788401376456, "Total num played games": 52698, "Total num trained steps": 104832, "Timestamp in ms": 1699937835151, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 189.3976004421711, "Avg game time in secs": 1.0397488348680781, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 52736, "Total num trained steps": 104888, "Timestamp in ms": 1699937864670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989781796811314, "Avg loss": 0.5285986652597785, "Avg value loss": 0.2447042382264044, "Avg policy loss": 0.2838944289833307, "Total num played games": 52749, "Total num trained steps": 104960, "Timestamp in ms": 1699937899146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902840909090909, "Avg loss": 0.5938426882494241, "Avg value loss": 0.3078584317700006, "Avg policy loss": 0.28598425607196987, "Total num played games": 52800, "Total num trained steps": 105088, "Timestamp in ms": 1699937963318, "logtype": "training_step"}
{"Avg objective": 21.234375, "Games time in secs": 152.3279537074268, "Avg game time in secs": 1.2531976540776668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.46, "agent_stopped_0": 0.62}, "Total num played games": 52864, "Total num trained steps": 105186, "Timestamp in ms": 1699938016998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989091802782819, "Avg loss": 0.6412569496314973, "Avg value loss": 0.34786765626631677, "Avg policy loss": 0.2933892906876281, "Total num played games": 52896, "Total num trained steps": 105216, "Timestamp in ms": 1699938032822, "logtype": "training_step"}
{"Total num played games": 52950, "Total num trained steps": 105314, "Timestamp in ms": 1699938152449, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3515625}
{"Avg objective": 21.1875, "Games time in secs": 138.11501999944448, "Avg game time in secs": 1.1916917484631995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 52992, "Total num trained steps": 105318, "Timestamp in ms": 1699938155113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876976489678855, "Avg loss": 0.712133628083393, "Avg value loss": 0.42382360727060586, "Avg policy loss": 0.28831002477090806, "Total num played games": 52998, "Total num trained steps": 105344, "Timestamp in ms": 1699938169457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901128344465828, "Avg loss": 0.41660250118002295, "Avg value loss": 0.12984661851078272, "Avg policy loss": 0.28675588173791766, "Total num played games": 52998, "Total num trained steps": 105472, "Timestamp in ms": 1699938243131, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889064677741364, "Avg loss": 0.5810543915722519, "Avg value loss": 0.2983214127307292, "Avg policy loss": 0.2827329761348665, "Total num played games": 53094, "Total num trained steps": 105600, "Timestamp in ms": 1699938319690, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 212.39366235025227, "Avg game time in secs": 1.074914096694556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 53120, "Total num trained steps": 105678, "Timestamp in ms": 1699938367507, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895000282257305, "Avg loss": 0.48484904412180185, "Avg value loss": 0.20024127600481734, "Avg policy loss": 0.2846077694557607, "Total num played games": 53143, "Total num trained steps": 105728, "Timestamp in ms": 1699938396209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900174835034685, "Avg loss": 0.494416969595477, "Avg value loss": 0.21479085617465898, "Avg policy loss": 0.2796261056791991, "Total num played games": 53193, "Total num trained steps": 105856, "Timestamp in ms": 1699938468649, "logtype": "training_step"}
{"Total num played games": 53246, "Total num trained steps": 105916, "Timestamp in ms": 1699938578386, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.48046875}
{"Avg objective": 21.8984375, "Games time in secs": 211.81059305742383, "Avg game time in secs": 1.1720881114451913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.62}, "Total num played games": 53248, "Total num trained steps": 105916, "Timestamp in ms": 1699938579319, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886666416482155, "Avg loss": 0.8919526839163154, "Avg value loss": 0.5759908220497891, "Avg policy loss": 0.31596186466049403, "Total num played games": 53294, "Total num trained steps": 105984, "Timestamp in ms": 1699938618561, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892394503496242, "Avg loss": 0.45091718691401184, "Avg value loss": 0.1626762840896845, "Avg policy loss": 0.28824090550187975, "Total num played games": 53343, "Total num trained steps": 106112, "Timestamp in ms": 1699938688096, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 148.57495678029954, "Avg game time in secs": 1.089157120368327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 53376, "Total num trained steps": 106177, "Timestamp in ms": 1699938727893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988917178373521, "Avg loss": 0.6766884913668036, "Avg value loss": 0.3795815122430213, "Avg policy loss": 0.29710697603877634, "Total num played games": 53416, "Total num trained steps": 106240, "Timestamp in ms": 1699938762696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895069579530151, "Avg loss": 0.6492949915118515, "Avg value loss": 0.35016489698318765, "Avg policy loss": 0.29913009773008525, "Total num played games": 53464, "Total num trained steps": 106368, "Timestamp in ms": 1699938841075, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 143.19326719269156, "Avg game time in secs": 1.201535492335097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 53504, "Total num trained steps": 106421, "Timestamp in ms": 1699938871086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900028029524433, "Avg loss": 0.4610737035982311, "Avg value loss": 0.16187787853414193, "Avg policy loss": 0.29919582698494196, "Total num played games": 53515, "Total num trained steps": 106496, "Timestamp in ms": 1699938913844, "logtype": "training_step"}
{"Total num played games": 53515, "Total num trained steps": 106518, "Timestamp in ms": 1699938978670, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4375}
{"Ratio train steps to played games": 1.9886414503133394, "Avg loss": 0.5038705803453922, "Avg value loss": 0.21198214299511164, "Avg policy loss": 0.2918884357204661, "Total num played games": 53616, "Total num trained steps": 106624, "Timestamp in ms": 1699939038984, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 218.49986677616835, "Avg game time in secs": 1.2540608156996313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.57, "agent_stopped_0": 0.54}, "Total num played games": 53632, "Total num trained steps": 106725, "Timestamp in ms": 1699939089586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892294791763718, "Avg loss": 0.6444739634171128, "Avg value loss": 0.3516033981577493, "Avg policy loss": 0.2928705723024905, "Total num played games": 53665, "Total num trained steps": 106752, "Timestamp in ms": 1699939101636, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898162456016235, "Avg loss": 0.6637402987107635, "Avg value loss": 0.37194448965601623, "Avg policy loss": 0.2917958090547472, "Total num played games": 53713, "Total num trained steps": 106880, "Timestamp in ms": 1699939161610, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 92.6471431851387, "Avg game time in secs": 1.2735419924574671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.73}, "Total num played games": 53760, "Total num trained steps": 106919, "Timestamp in ms": 1699939182234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904205650936553, "Avg loss": 0.5518439365550876, "Avg value loss": 0.2615032432368025, "Avg policy loss": 0.29034069215413183, "Total num played games": 53761, "Total num trained steps": 107008, "Timestamp in ms": 1699939232556, "logtype": "training_step"}
{"Total num played games": 53860, "Total num trained steps": 107120, "Timestamp in ms": 1699939350932, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.47265625}
{"Avg objective": 21.9453125, "Games time in secs": 170.77096595987678, "Avg game time in secs": 0.9995420910418034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.42, "agent_stopped_0": 0.62}, "Total num played games": 53888, "Total num trained steps": 107123, "Timestamp in ms": 1699939353005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873859167470505, "Avg loss": 0.7152879070490599, "Avg value loss": 0.4269631007045973, "Avg policy loss": 0.28832480020355433, "Total num played games": 53908, "Total num trained steps": 107136, "Timestamp in ms": 1699939359328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897417822957633, "Avg loss": 0.6381669437978417, "Avg value loss": 0.3419015611289069, "Avg policy loss": 0.2962653925642371, "Total num played games": 53908, "Total num trained steps": 107264, "Timestamp in ms": 1699939426743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903439839869523, "Avg loss": 0.48760270327329636, "Avg value loss": 0.21315933036385104, "Avg policy loss": 0.2744433704065159, "Total num played games": 53956, "Total num trained steps": 107392, "Timestamp in ms": 1699939488164, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 193.2802533507347, "Avg game time in secs": 1.2518138249142794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.59}, "Total num played games": 54016, "Total num trained steps": 107506, "Timestamp in ms": 1699939546289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890115988678616, "Avg loss": 0.5351679529994726, "Avg value loss": 0.26468473789282143, "Avg policy loss": 0.2704832124290988, "Total num played games": 54057, "Total num trained steps": 107520, "Timestamp in ms": 1699939553097, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894104601737201, "Avg loss": 0.549734138417989, "Avg value loss": 0.27835979382507503, "Avg policy loss": 0.27137434389442205, "Total num played games": 54110, "Total num trained steps": 107648, "Timestamp in ms": 1699939617062, "logtype": "training_step"}
{"Avg objective": 20.5546875, "Games time in secs": 107.2367028016597, "Avg game time in secs": 1.1216402911086334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 54144, "Total num trained steps": 107709, "Timestamp in ms": 1699939653526, "logtype": "played_game"}
{"Total num played games": 54190, "Total num trained steps": 107721, "Timestamp in ms": 1699939695753, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1015625}
{"Ratio train steps to played games": 1.987093919392308, "Avg loss": 0.936026202281937, "Avg value loss": 0.6407786209601909, "Avg policy loss": 0.2952475812053308, "Total num played games": 54238, "Total num trained steps": 107776, "Timestamp in ms": 1699939722843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894354511597034, "Avg loss": 0.4320476532448083, "Avg value loss": 0.13301208248594776, "Avg policy loss": 0.2990355684887618, "Total num played games": 54238, "Total num trained steps": 107904, "Timestamp in ms": 1699939788892, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 168.43397516943514, "Avg game time in secs": 1.1150164920836687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 54272, "Total num trained steps": 107968, "Timestamp in ms": 1699939821960, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900342629775634, "Avg loss": 0.4804969276301563, "Avg value loss": 0.19605615860200487, "Avg policy loss": 0.2844407686498016, "Total num played games": 54286, "Total num trained steps": 108032, "Timestamp in ms": 1699939855345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905405156707217, "Avg loss": 0.5094042266719043, "Avg value loss": 0.2282466519100126, "Avg policy loss": 0.28115757182240486, "Total num played games": 54337, "Total num trained steps": 108160, "Timestamp in ms": 1699939918204, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 149.33213960006833, "Avg game time in secs": 1.2195126978331245, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 54400, "Total num trained steps": 108260, "Timestamp in ms": 1699939971293, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893265238637616, "Avg loss": 0.5832033180631697, "Avg value loss": 0.30091929278569296, "Avg policy loss": 0.28228401695378125, "Total num played games": 54434, "Total num trained steps": 108288, "Timestamp in ms": 1699939983802, "logtype": "training_step"}
{"Total num played games": 54434, "Total num trained steps": 108321, "Timestamp in ms": 1699940072582, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.69921875}
{"Ratio train steps to played games": 1.9899232774127236, "Avg loss": 0.5972762037999928, "Avg value loss": 0.2976579088717699, "Avg policy loss": 0.2996182976057753, "Total num played games": 54482, "Total num trained steps": 108416, "Timestamp in ms": 1699940126891, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 177.58067769929767, "Avg game time in secs": 1.1524468768184306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 54528, "Total num trained steps": 108458, "Timestamp in ms": 1699940148873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905189803777736, "Avg loss": 0.4618715834803879, "Avg value loss": 0.17965706391260028, "Avg policy loss": 0.2822145218960941, "Total num played games": 54530, "Total num trained steps": 108544, "Timestamp in ms": 1699940200394, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892183781804869, "Avg loss": 0.5677941534668207, "Avg value loss": 0.2715182312531397, "Avg policy loss": 0.2962759247748181, "Total num played games": 54630, "Total num trained steps": 108672, "Timestamp in ms": 1699940267875, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 163.90011869557202, "Avg game time in secs": 1.1249427749135066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.53, "agent_stopped_0": 0.53}, "Total num played games": 54656, "Total num trained steps": 108750, "Timestamp in ms": 1699940312774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989813087530634, "Avg loss": 0.5118006269913167, "Avg value loss": 0.22475820980616845, "Avg policy loss": 0.28704241977538913, "Total num played games": 54678, "Total num trained steps": 108800, "Timestamp in ms": 1699940341881, "logtype": "training_step"}
{"Total num played games": 54726, "Total num trained steps": 108921, "Timestamp in ms": 1699940461895, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.23828125}
{"Ratio train steps to played games": 1.9887896879735627, "Avg loss": 0.49801134690642357, "Avg value loss": 0.21783005105680786, "Avg policy loss": 0.2801812943071127, "Total num played games": 54771, "Total num trained steps": 108928, "Timestamp in ms": 1699940465417, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 214.3630877621472, "Avg game time in secs": 1.1822825501585612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 54784, "Total num trained steps": 109037, "Timestamp in ms": 1699940527137, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892561380467695, "Avg loss": 0.615833927411586, "Avg value loss": 0.3369032477203291, "Avg policy loss": 0.2789306823397055, "Total num played games": 54822, "Total num trained steps": 109056, "Timestamp in ms": 1699940538669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898487333697832, "Avg loss": 0.5832395872566849, "Avg value loss": 0.304534389229957, "Avg policy loss": 0.27870520192664117, "Total num played games": 54870, "Total num trained steps": 109184, "Timestamp in ms": 1699940615535, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 110.78862827643752, "Avg game time in secs": 1.1380115393403685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 54912, "Total num trained steps": 109233, "Timestamp in ms": 1699940637926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903860160233067, "Avg loss": 0.5055116198491305, "Avg value loss": 0.22453262592898682, "Avg policy loss": 0.2809789951425046, "Total num played games": 54920, "Total num trained steps": 109312, "Timestamp in ms": 1699940677859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891490057799266, "Avg loss": 0.5174208856187761, "Avg value loss": 0.2466321587562561, "Avg policy loss": 0.2707887247670442, "Total num played games": 55018, "Total num trained steps": 109440, "Timestamp in ms": 1699940747828, "logtype": "training_step"}
{"Total num played games": 55018, "Total num trained steps": 109521, "Timestamp in ms": 1699940864974, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.10546875}
{"Avg objective": 21.171875, "Games time in secs": 228.8197927288711, "Avg game time in secs": 1.1436333143210504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 55040, "Total num trained steps": 109524, "Timestamp in ms": 1699940866746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897395852250028, "Avg loss": 0.8220129273831844, "Avg value loss": 0.5419445254665334, "Avg policy loss": 0.2800684056710452, "Total num played games": 55066, "Total num trained steps": 109568, "Timestamp in ms": 1699940886683, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990329135972711, "Avg loss": 0.6376166029367596, "Avg value loss": 0.34868730581365526, "Avg policy loss": 0.2889292928157374, "Total num played games": 55114, "Total num trained steps": 109696, "Timestamp in ms": 1699940955913, "logtype": "training_step"}
{"Avg objective": 23.265625, "Games time in secs": 148.40363115631044, "Avg game time in secs": 1.222024330694694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 55168, "Total num trained steps": 109820, "Timestamp in ms": 1699941015149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989366905171633, "Avg loss": 0.6325140949338675, "Avg value loss": 0.3465462896274403, "Avg policy loss": 0.2859678058885038, "Total num played games": 55203, "Total num trained steps": 109824, "Timestamp in ms": 1699941016452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894693035627047, "Avg loss": 0.7250381053891033, "Avg value loss": 0.4374683474889025, "Avg policy loss": 0.2875697606941685, "Total num played games": 55267, "Total num trained steps": 109952, "Timestamp in ms": 1699941073366, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 97.77660534344614, "Avg game time in secs": 1.1889996237878222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 55296, "Total num trained steps": 110026, "Timestamp in ms": 1699941112926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899669179456587, "Avg loss": 0.5444826257880777, "Avg value loss": 0.26363895554095507, "Avg policy loss": 0.2808436785126105, "Total num played games": 55317, "Total num trained steps": 110080, "Timestamp in ms": 1699941141930, "logtype": "training_step"}
{"Total num played games": 55353, "Total num trained steps": 110123, "Timestamp in ms": 1699941224790, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.71484375}
{"Ratio train steps to played games": 1.9892601216584538, "Avg loss": 0.7517643061000854, "Avg value loss": 0.46090336283668876, "Avg policy loss": 0.29086094081867486, "Total num played games": 55401, "Total num trained steps": 110208, "Timestamp in ms": 1699941271829, "logtype": "training_step"}
{"Avg objective": 22.421875, "Games time in secs": 204.42077671177685, "Avg game time in secs": 1.1853948684583884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 55424, "Total num trained steps": 110291, "Timestamp in ms": 1699941317347, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989774756090963, "Avg loss": 0.4692933149635792, "Avg value loss": 0.1852990006445907, "Avg policy loss": 0.28399431332945824, "Total num played games": 55451, "Total num trained steps": 110336, "Timestamp in ms": 1699941340051, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902526035097834, "Avg loss": 0.5933483738917857, "Avg value loss": 0.30879768793238327, "Avg policy loss": 0.28455068764742464, "Total num played games": 55502, "Total num trained steps": 110464, "Timestamp in ms": 1699941402973, "logtype": "training_step"}
{"Avg objective": 20.59375, "Games time in secs": 149.62389240041375, "Avg game time in secs": 1.2201350288669346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 55552, "Total num trained steps": 110590, "Timestamp in ms": 1699941466971, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899595141700406, "Avg loss": 0.47325378796085715, "Avg value loss": 0.2002140452095773, "Avg policy loss": 0.2730397410923615, "Total num played games": 55573, "Total num trained steps": 110592, "Timestamp in ms": 1699941467575, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894704687977287, "Avg loss": 0.6590227254200727, "Avg value loss": 0.370224587386474, "Avg policy loss": 0.28879814001265913, "Total num played games": 55653, "Total num trained steps": 110720, "Timestamp in ms": 1699941529371, "logtype": "training_step"}
{"Total num played games": 55653, "Total num trained steps": 110725, "Timestamp in ms": 1699941584982, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.484375}
{"Avg objective": 20.453125, "Games time in secs": 120.70266808196902, "Avg game time in secs": 1.073129543205141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 55680, "Total num trained steps": 110727, "Timestamp in ms": 1699941587674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900360855280874, "Avg loss": 0.7374404130969197, "Avg value loss": 0.44452826026827097, "Avg policy loss": 0.29291215306147933, "Total num played games": 55701, "Total num trained steps": 110848, "Timestamp in ms": 1699941645713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906186658056646, "Avg loss": 0.6285620771814138, "Avg value loss": 0.34014423232292756, "Avg policy loss": 0.2884178472450003, "Total num played games": 55749, "Total num trained steps": 110976, "Timestamp in ms": 1699941707591, "logtype": "training_step"}
{"Avg objective": 23.265625, "Games time in secs": 184.7645167913288, "Avg game time in secs": 1.2293897009367356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.67}, "Total num played games": 55808, "Total num trained steps": 111101, "Timestamp in ms": 1699941772439, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893818937115026, "Avg loss": 0.6745007417630404, "Avg value loss": 0.37513849313836545, "Avg policy loss": 0.29936224315315485, "Total num played games": 55846, "Total num trained steps": 111104, "Timestamp in ms": 1699941773508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897143266014345, "Avg loss": 0.6629367754794657, "Avg value loss": 0.3658089436357841, "Avg policy loss": 0.2971278326585889, "Total num played games": 55903, "Total num trained steps": 111232, "Timestamp in ms": 1699941837512, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 95.90277544409037, "Avg game time in secs": 1.1472927756694844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.51}, "Total num played games": 55936, "Total num trained steps": 111298, "Timestamp in ms": 1699941868342, "logtype": "played_game"}
{"Total num played games": 55957, "Total num trained steps": 111326, "Timestamp in ms": 1699941950665, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.00390625}
{"Ratio train steps to played games": 1.9883760378537632, "Avg loss": 0.6926607196219265, "Avg value loss": 0.3777244703960605, "Avg policy loss": 0.3149362519616261, "Total num played games": 56005, "Total num trained steps": 111360, "Timestamp in ms": 1699941972067, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906794036246764, "Avg loss": 0.4263766484800726, "Avg value loss": 0.12787691835546866, "Avg policy loss": 0.29849973041564226, "Total num played games": 56005, "Total num trained steps": 111488, "Timestamp in ms": 1699942041489, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 229.81510998867452, "Avg game time in secs": 1.1251289182691835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.57, "agent_stopped_0": 0.49}, "Total num played games": 56064, "Total num trained steps": 111600, "Timestamp in ms": 1699942098157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893239702710892, "Avg loss": 0.6729530475568026, "Avg value loss": 0.3800611984333955, "Avg policy loss": 0.2928918548859656, "Total num played games": 56107, "Total num trained steps": 111616, "Timestamp in ms": 1699942104866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898320779243905, "Avg loss": 0.5990271237678826, "Avg value loss": 0.3113753242068924, "Avg policy loss": 0.28765179810579866, "Total num played games": 56157, "Total num trained steps": 111744, "Timestamp in ms": 1699942170954, "logtype": "training_step"}
{"Avg objective": 22.46875, "Games time in secs": 105.26040983758867, "Avg game time in secs": 1.174056333999033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 56192, "Total num trained steps": 111805, "Timestamp in ms": 1699942203418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990374693093264, "Avg loss": 0.740431101527065, "Avg value loss": 0.44273737783078104, "Avg policy loss": 0.2976937263738364, "Total num played games": 56206, "Total num trained steps": 111872, "Timestamp in ms": 1699942234200, "logtype": "training_step"}
{"Total num played games": 56254, "Total num trained steps": 111927, "Timestamp in ms": 1699942340178, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.28125}
{"Ratio train steps to played games": 1.9892721395332316, "Avg loss": 0.9886463889852166, "Avg value loss": 0.6749237742624246, "Avg policy loss": 0.3137226236285642, "Total num played games": 56302, "Total num trained steps": 112000, "Timestamp in ms": 1699942381481, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 228.04735193029046, "Avg game time in secs": 1.1553439008275745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.56, "agent_stopped_0": 0.56}, "Total num played games": 56320, "Total num trained steps": 112094, "Timestamp in ms": 1699942431465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98974322573776, "Avg loss": 0.4725213667843491, "Avg value loss": 0.18173389887670055, "Avg policy loss": 0.2907874633092433, "Total num played games": 56353, "Total num trained steps": 112128, "Timestamp in ms": 1699942448433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903193205794223, "Avg loss": 0.6239504020195454, "Avg value loss": 0.3204069939092733, "Avg policy loss": 0.303543409332633, "Total num played games": 56401, "Total num trained steps": 112256, "Timestamp in ms": 1699942518572, "logtype": "training_step"}
{"Avg objective": 22.8203125, "Games time in secs": 108.68604668416083, "Avg game time in secs": 1.1456284674204653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 56448, "Total num trained steps": 112294, "Timestamp in ms": 1699942540151, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908767205796383, "Avg loss": 0.640046885702759, "Avg value loss": 0.3279433607822284, "Avg policy loss": 0.3121035258518532, "Total num played games": 56449, "Total num trained steps": 112384, "Timestamp in ms": 1699942590320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897251794998763, "Avg loss": 0.8065504101105034, "Avg value loss": 0.4946494454634376, "Avg policy loss": 0.3119009693618864, "Total num played games": 56546, "Total num trained steps": 112512, "Timestamp in ms": 1699942659608, "logtype": "training_step"}
{"Total num played games": 56546, "Total num trained steps": 112529, "Timestamp in ms": 1699942729849, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.20703125}
{"Avg objective": 20.515625, "Games time in secs": 191.84143785573542, "Avg game time in secs": 1.1429317434958648, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 56576, "Total num trained steps": 112531, "Timestamp in ms": 1699942731993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903169947344241, "Avg loss": 0.5813909207936376, "Avg value loss": 0.2673037089407444, "Avg policy loss": 0.314087214297615, "Total num played games": 56594, "Total num trained steps": 112640, "Timestamp in ms": 1699942794057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908901521838918, "Avg loss": 0.6582663550507277, "Avg value loss": 0.3572607788955793, "Avg policy loss": 0.30100557347759604, "Total num played games": 56642, "Total num trained steps": 112768, "Timestamp in ms": 1699942860017, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 181.49227476492524, "Avg game time in secs": 1.1940144996042363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 56704, "Total num trained steps": 112874, "Timestamp in ms": 1699942913485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896723709486968, "Avg loss": 0.7880570406559855, "Avg value loss": 0.472847365308553, "Avg policy loss": 0.31520967243704945, "Total num played games": 56741, "Total num trained steps": 112896, "Timestamp in ms": 1699942922258, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902269805772244, "Avg loss": 0.6081211813725531, "Avg value loss": 0.30074318044353276, "Avg policy loss": 0.3073779937112704, "Total num played games": 56789, "Total num trained steps": 113024, "Timestamp in ms": 1699942991262, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 98.93526763282716, "Avg game time in secs": 1.0926081669458654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 56832, "Total num trained steps": 113069, "Timestamp in ms": 1699943012421, "logtype": "played_game"}
{"Total num played games": 56837, "Total num trained steps": 113130, "Timestamp in ms": 1699943103610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.01171875}
{"Ratio train steps to played games": 1.9891359760921157, "Avg loss": 0.9138533843215555, "Avg value loss": 0.5947113287402317, "Avg policy loss": 0.31914205162320286, "Total num played games": 56885, "Total num trained steps": 113152, "Timestamp in ms": 1699943115145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989619741810837, "Avg loss": 0.5621482708957046, "Avg value loss": 0.2393216710188426, "Avg policy loss": 0.32282659655902535, "Total num played games": 56935, "Total num trained steps": 113280, "Timestamp in ms": 1699943183001, "logtype": "training_step"}
{"Avg objective": 22.78125, "Games time in secs": 214.75230305083096, "Avg game time in secs": 1.0603100641747005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.43, "agent_stopped_0": 0.59}, "Total num played games": 56960, "Total num trained steps": 113360, "Timestamp in ms": 1699943227173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898757720381808, "Avg loss": 0.6343886095564812, "Avg value loss": 0.3108046426787041, "Avg policy loss": 0.3235839599510655, "Total num played games": 56992, "Total num trained steps": 113408, "Timestamp in ms": 1699943250893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990445301542777, "Avg loss": 0.5615293488372117, "Avg value loss": 0.2548174189578276, "Avg policy loss": 0.3067119336919859, "Total num played games": 57040, "Total num trained steps": 113536, "Timestamp in ms": 1699943317941, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 109.8098246473819, "Avg game time in secs": 1.167942933010636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 57088, "Total num trained steps": 113574, "Timestamp in ms": 1699943336983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909965142146473, "Avg loss": 0.6596872843801975, "Avg value loss": 0.3449886896996759, "Avg policy loss": 0.314698601141572, "Total num played games": 57089, "Total num trained steps": 113664, "Timestamp in ms": 1699943379700, "logtype": "training_step"}
{"Total num played games": 57142, "Total num trained steps": 113730, "Timestamp in ms": 1699943472055, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.39453125}
{"Ratio train steps to played games": 1.9897009966777408, "Avg loss": 0.730116872349754, "Avg value loss": 0.40814401279203594, "Avg policy loss": 0.3219728594413027, "Total num played games": 57190, "Total num trained steps": 113792, "Timestamp in ms": 1699943506732, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 204.7023765798658, "Avg game time in secs": 1.0220711668516742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 57216, "Total num trained steps": 113871, "Timestamp in ms": 1699943541686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902861735210875, "Avg loss": 0.5511021327693015, "Avg value loss": 0.2467605642741546, "Avg policy loss": 0.3043415719876066, "Total num played games": 57238, "Total num trained steps": 113920, "Timestamp in ms": 1699943564166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990765954475632, "Avg loss": 0.606300313025713, "Avg value loss": 0.2903914829948917, "Avg policy loss": 0.3159088345710188, "Total num played games": 57288, "Total num trained steps": 114048, "Timestamp in ms": 1699943623167, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 142.96188971586525, "Avg game time in secs": 1.286382978898473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 57344, "Total num trained steps": 114166, "Timestamp in ms": 1699943684648, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895620959450746, "Avg loss": 0.5672492336016148, "Avg value loss": 0.263771497819107, "Avg policy loss": 0.3034777344437316, "Total num played games": 57387, "Total num trained steps": 114176, "Timestamp in ms": 1699943690564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990127970749543, "Avg loss": 0.6038957703858614, "Avg value loss": 0.2893693890364375, "Avg policy loss": 0.31452637375332415, "Total num played games": 57435, "Total num trained steps": 114304, "Timestamp in ms": 1699943760051, "logtype": "training_step"}
{"Total num played games": 57435, "Total num trained steps": 114331, "Timestamp in ms": 1699943834949, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.51171875}
{"Avg objective": 20.9296875, "Games time in secs": 152.47091445326805, "Avg game time in secs": 1.0699830235244008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 57472, "Total num trained steps": 114335, "Timestamp in ms": 1699943837119, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906929005097158, "Avg loss": 0.6271039864514023, "Avg value loss": 0.3208650270826183, "Avg policy loss": 0.3062389639671892, "Total num played games": 57483, "Total num trained steps": 114432, "Timestamp in ms": 1699943888239, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989545162466786, "Avg loss": 0.6449149022810161, "Avg value loss": 0.3281470069778152, "Avg policy loss": 0.3167678941972554, "Total num played games": 57581, "Total num trained steps": 114560, "Timestamp in ms": 1699943956757, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 170.78306661732495, "Avg game time in secs": 1.0518516180745792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.5, "agent_stopped_0": 0.57}, "Total num played games": 57600, "Total num trained steps": 114653, "Timestamp in ms": 1699944007902, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900917940620173, "Avg loss": 0.6148261621128768, "Avg value loss": 0.2995409050199669, "Avg policy loss": 0.3152852657949552, "Total num played games": 57629, "Total num trained steps": 114688, "Timestamp in ms": 1699944027756, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906376781441797, "Avg loss": 0.6097594953607768, "Avg value loss": 0.3022050333674997, "Avg policy loss": 0.30755446245893836, "Total num played games": 57678, "Total num trained steps": 114816, "Timestamp in ms": 1699944094671, "logtype": "training_step"}
{"Total num played games": 57726, "Total num trained steps": 114934, "Timestamp in ms": 1699944218518, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83203125}
{"Avg objective": 21.3046875, "Games time in secs": 211.82658987864852, "Avg game time in secs": 1.1342489615344675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 57728, "Total num trained steps": 114936, "Timestamp in ms": 1699944219729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895281614567106, "Avg loss": 0.6626571295782924, "Avg value loss": 0.34680287376977503, "Avg policy loss": 0.3158542599994689, "Total num played games": 57774, "Total num trained steps": 114944, "Timestamp in ms": 1699944223995, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900214443829551, "Avg loss": 0.806853688089177, "Avg value loss": 0.4811670703929849, "Avg policy loss": 0.3256866163574159, "Total num played games": 57824, "Total num trained steps": 115072, "Timestamp in ms": 1699944296247, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 112.60297826677561, "Avg game time in secs": 1.1233832442085259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 57856, "Total num trained steps": 115138, "Timestamp in ms": 1699944332332, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905482694866345, "Avg loss": 0.7143574820365757, "Avg value loss": 0.3888481541071087, "Avg policy loss": 0.3255093292100355, "Total num played games": 57873, "Total num trained steps": 115200, "Timestamp in ms": 1699944366924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910054554243493, "Avg loss": 0.5785049851983786, "Avg value loss": 0.24914035631809384, "Avg policy loss": 0.32936463155783713, "Total num played games": 57924, "Total num trained steps": 115328, "Timestamp in ms": 1699944434689, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 155.01700460538268, "Avg game time in secs": 1.1890198144101305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 57984, "Total num trained steps": 115433, "Timestamp in ms": 1699944487349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989934505342985, "Avg loss": 0.7890715200919658, "Avg value loss": 0.4565036421408877, "Avg policy loss": 0.33256787643767893, "Total num played games": 58020, "Total num trained steps": 115456, "Timestamp in ms": 1699944497124, "logtype": "training_step"}
{"Total num played games": 58068, "Total num trained steps": 115536, "Timestamp in ms": 1699944611343, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.78515625}
{"Avg objective": 21.671875, "Games time in secs": 126.3742139711976, "Avg game time in secs": 1.1177162845997373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 58112, "Total num trained steps": 115538, "Timestamp in ms": 1699944613723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888326794686488, "Avg loss": 0.8129055688623339, "Avg value loss": 0.48865063866833225, "Avg policy loss": 0.32425493304617703, "Total num played games": 58116, "Total num trained steps": 115584, "Timestamp in ms": 1699944638072, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910523780026155, "Avg loss": 0.44594746734946966, "Avg value loss": 0.12419833784224465, "Avg policy loss": 0.3217491335235536, "Total num played games": 58116, "Total num trained steps": 115712, "Timestamp in ms": 1699944709213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989745439554777, "Avg loss": 0.7753723680507392, "Avg value loss": 0.4548096602666192, "Avg policy loss": 0.3205627095885575, "Total num played games": 58218, "Total num trained steps": 115840, "Timestamp in ms": 1699944775437, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 207.34580113738775, "Avg game time in secs": 1.0899896945193177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 58240, "Total num trained steps": 115926, "Timestamp in ms": 1699944821070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903202553804964, "Avg loss": 0.5697501199319959, "Avg value loss": 0.2530395006760955, "Avg policy loss": 0.31671062274836004, "Total num played games": 58266, "Total num trained steps": 115968, "Timestamp in ms": 1699944841856, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990876976369311, "Avg loss": 0.5325114112347364, "Avg value loss": 0.23659907298861071, "Avg policy loss": 0.2959123372565955, "Total num played games": 58314, "Total num trained steps": 116096, "Timestamp in ms": 1699944902292, "logtype": "training_step"}
{"Total num played games": 58365, "Total num trained steps": 116140, "Timestamp in ms": 1699945008837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.4453125}
{"Avg objective": 22.3046875, "Games time in secs": 191.2156847678125, "Avg game time in secs": 1.1385470197710674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 58368, "Total num trained steps": 116145, "Timestamp in ms": 1699945012285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896940749490695, "Avg loss": 0.8049040553160012, "Avg value loss": 0.4853152976720594, "Avg policy loss": 0.3195887631736696, "Total num played games": 58413, "Total num trained steps": 116224, "Timestamp in ms": 1699945055066, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901477832512315, "Avg loss": 0.5023098583333194, "Avg value loss": 0.20836863035219721, "Avg policy loss": 0.2939412322593853, "Total num played games": 58464, "Total num trained steps": 116352, "Timestamp in ms": 1699945125265, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 150.0681109186262, "Avg game time in secs": 0.9204901190969395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.42}, "Total num played games": 58496, "Total num trained steps": 116417, "Timestamp in ms": 1699945162354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906516500606704, "Avg loss": 0.8583752675913274, "Avg value loss": 0.5594779014936648, "Avg policy loss": 0.2988973691826686, "Total num played games": 58513, "Total num trained steps": 116480, "Timestamp in ms": 1699945197323, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912057512679087, "Avg loss": 0.5815413165837526, "Avg value loss": 0.28593263315269724, "Avg policy loss": 0.2956086869817227, "Total num played games": 58561, "Total num trained steps": 116608, "Timestamp in ms": 1699945266409, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 159.61230768077075, "Avg game time in secs": 1.1061330248921877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 58624, "Total num trained steps": 116709, "Timestamp in ms": 1699945321966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899933516305552, "Avg loss": 0.8109179011080414, "Avg value loss": 0.5186937761609443, "Avg policy loss": 0.2922241179039702, "Total num played games": 58661, "Total num trained steps": 116736, "Timestamp in ms": 1699945336229, "logtype": "training_step"}
{"Total num played games": 58661, "Total num trained steps": 116743, "Timestamp in ms": 1699945411106, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.93359375}
{"Ratio train steps to played games": 1.9905465942189442, "Avg loss": 0.6799126961268485, "Avg value loss": 0.3796238040085882, "Avg policy loss": 0.3002888939809054, "Total num played games": 58709, "Total num trained steps": 116864, "Timestamp in ms": 1699945479434, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 183.99193901009858, "Avg game time in secs": 1.0769500284513924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 58752, "Total num trained steps": 116911, "Timestamp in ms": 1699945505958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910650464617583, "Avg loss": 0.4732615011744201, "Avg value loss": 0.18830109859118238, "Avg policy loss": 0.2849604062503204, "Total num played games": 58758, "Total num trained steps": 116992, "Timestamp in ms": 1699945549129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899753631806982, "Avg loss": 0.7646813162136823, "Avg value loss": 0.4725628114538267, "Avg policy loss": 0.2921185066225007, "Total num played games": 58855, "Total num trained steps": 117120, "Timestamp in ms": 1699945617578, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 155.59643011540174, "Avg game time in secs": 1.036275269507314, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 58880, "Total num trained steps": 117201, "Timestamp in ms": 1699945661555, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904760287926118, "Avg loss": 0.6419910085387528, "Avg value loss": 0.34629437868716195, "Avg policy loss": 0.29569663444999605, "Total num played games": 58904, "Total num trained steps": 117248, "Timestamp in ms": 1699945685380, "logtype": "training_step"}
{"Total num played games": 58952, "Total num trained steps": 117343, "Timestamp in ms": 1699945766388, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.12109375}
{"Ratio train steps to played games": 1.9894237288135592, "Avg loss": 0.6926006064750254, "Avg value loss": 0.40105695876991376, "Avg policy loss": 0.2915436492767185, "Total num played games": 59000, "Total num trained steps": 117376, "Timestamp in ms": 1699945783429, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 183.75675782561302, "Avg game time in secs": 1.1077015617775032, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 59008, "Total num trained steps": 117490, "Timestamp in ms": 1699945845312, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899573228559815, "Avg loss": 0.47562660463154316, "Avg value loss": 0.18688786527491175, "Avg policy loss": 0.2887387399096042, "Total num played games": 59048, "Total num trained steps": 117504, "Timestamp in ms": 1699945853167, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905238933261133, "Avg loss": 0.6545604546554387, "Avg value loss": 0.3616930650896393, "Avg policy loss": 0.29286738531664014, "Total num played games": 59096, "Total num trained steps": 117632, "Timestamp in ms": 1699945914324, "logtype": "training_step"}
{"Avg objective": 22.828125, "Games time in secs": 94.7347347419709, "Avg game time in secs": 1.1321641831891611, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 59136, "Total num trained steps": 117683, "Timestamp in ms": 1699945940047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991022064417956, "Avg loss": 0.717453335179016, "Avg value loss": 0.4217682011658326, "Avg policy loss": 0.29568513797130436, "Total num played games": 59145, "Total num trained steps": 117760, "Timestamp in ms": 1699945981285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899562802788608, "Avg loss": 0.6638453954365104, "Avg value loss": 0.37178801582194865, "Avg policy loss": 0.29205737938173115, "Total num played games": 59241, "Total num trained steps": 117888, "Timestamp in ms": 1699946043689, "logtype": "training_step"}
{"Total num played games": 59242, "Total num trained steps": 117945, "Timestamp in ms": 1699946136475, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.796875}
{"Avg objective": 21.2578125, "Games time in secs": 198.2149403244257, "Avg game time in secs": 1.1351621779467678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 59264, "Total num trained steps": 117949, "Timestamp in ms": 1699946138262, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904874346432788, "Avg loss": 0.7837230935692787, "Avg value loss": 0.4706284944550134, "Avg policy loss": 0.3130945961456746, "Total num played games": 59290, "Total num trained steps": 118016, "Timestamp in ms": 1699946174611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908833541168145, "Avg loss": 0.4760850742459297, "Avg value loss": 0.18718889605952427, "Avg policy loss": 0.28889617847744375, "Total num played games": 59342, "Total num trained steps": 118144, "Timestamp in ms": 1699946239881, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 162.14434298872948, "Avg game time in secs": 1.0791620866948506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.58}, "Total num played games": 59392, "Total num trained steps": 118271, "Timestamp in ms": 1699946300407, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913457814894011, "Avg loss": 0.5140030514448881, "Avg value loss": 0.23412115016253665, "Avg policy loss": 0.2798819037852809, "Total num played games": 59392, "Total num trained steps": 118272, "Timestamp in ms": 1699946300477, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903005648197956, "Avg loss": 0.7446643963921815, "Avg value loss": 0.4489887877134606, "Avg policy loss": 0.29567561158910394, "Total num played games": 59488, "Total num trained steps": 118400, "Timestamp in ms": 1699946369484, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 101.7944897543639, "Avg game time in secs": 0.9933120671776123, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.44}, "Total num played games": 59520, "Total num trained steps": 118467, "Timestamp in ms": 1699946402201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907789982868085, "Avg loss": 0.518646274227649, "Avg value loss": 0.22569868329446763, "Avg policy loss": 0.2929475858109072, "Total num played games": 59538, "Total num trained steps": 118528, "Timestamp in ms": 1699946437035, "logtype": "training_step"}
{"Total num played games": 59538, "Total num trained steps": 118547, "Timestamp in ms": 1699946492104, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.890625}
{"Ratio train steps to played games": 1.9913234652435137, "Avg loss": 0.49353504250757396, "Avg value loss": 0.20620406937086955, "Avg policy loss": 0.28733097633812577, "Total num played games": 59586, "Total num trained steps": 118656, "Timestamp in ms": 1699946548748, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 203.39604081586003, "Avg game time in secs": 1.0302582410367904, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 59648, "Total num trained steps": 118758, "Timestamp in ms": 1699946605597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902818270165208, "Avg loss": 0.6765562135260552, "Avg value loss": 0.39245149758062325, "Avg policy loss": 0.2841047204565257, "Total num played games": 59682, "Total num trained steps": 118784, "Timestamp in ms": 1699946619630, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907419808477869, "Avg loss": 0.6496145408600569, "Avg value loss": 0.3521759911964182, "Avg policy loss": 0.2974385478300974, "Total num played games": 59732, "Total num trained steps": 118912, "Timestamp in ms": 1699946684398, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 101.17919434420764, "Avg game time in secs": 1.1002009613148402, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 59776, "Total num trained steps": 118956, "Timestamp in ms": 1699946706777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911847849723165, "Avg loss": 0.6049826841335744, "Avg value loss": 0.3096398140187375, "Avg policy loss": 0.2953428615583107, "Total num played games": 59783, "Total num trained steps": 119040, "Timestamp in ms": 1699946747643, "logtype": "training_step"}
{"Total num played games": 59836, "Total num trained steps": 119147, "Timestamp in ms": 1699946854900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.703125}
{"Ratio train steps to played games": 1.9899806292164852, "Avg loss": 0.6373817047569901, "Avg value loss": 0.33980590372812003, "Avg policy loss": 0.2975758007960394, "Total num played games": 59884, "Total num trained steps": 119168, "Timestamp in ms": 1699946866376, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 203.59350504353642, "Avg game time in secs": 1.138940764372819, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 59904, "Total num trained steps": 119259, "Timestamp in ms": 1699946910370, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904726945088682, "Avg loss": 0.6101441092323512, "Avg value loss": 0.3068510106240865, "Avg policy loss": 0.30329310544766486, "Total num played games": 59933, "Total num trained steps": 119296, "Timestamp in ms": 1699946930564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909806275215898, "Avg loss": 0.5678384643979371, "Avg value loss": 0.26044412032933906, "Avg policy loss": 0.30739434401039034, "Total num played games": 59982, "Total num trained steps": 119424, "Timestamp in ms": 1699946994919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914712153518124, "Avg loss": 0.6024412915576249, "Avg value loss": 0.2905157988425344, "Avg policy loss": 0.31192549027036875, "Total num played games": 60031, "Total num trained steps": 119552, "Timestamp in ms": 1699947061650, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 151.28066680394113, "Avg game time in secs": 1.2259843492793152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 60032, "Total num trained steps": 119552, "Timestamp in ms": 1699947061651, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903542324962582, "Avg loss": 0.8072310376446694, "Avg value loss": 0.47866656963014975, "Avg policy loss": 0.32856446341611445, "Total num played games": 60130, "Total num trained steps": 119680, "Timestamp in ms": 1699947127881, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 103.9138915091753, "Avg game time in secs": 0.9739101574377855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 60160, "Total num trained steps": 119750, "Timestamp in ms": 1699947165565, "logtype": "played_game"}
{"Total num played games": 60177, "Total num trained steps": 119750, "Timestamp in ms": 1699947245440, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1171875}
{"Ratio train steps to played games": 1.9893399750933998, "Avg loss": 0.7760747682768852, "Avg value loss": 0.4557385095395148, "Avg policy loss": 0.3203362573403865, "Total num played games": 60225, "Total num trained steps": 119808, "Timestamp in ms": 1699947275836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914487339144873, "Avg loss": 0.41640039067715406, "Avg value loss": 0.10660892393207178, "Avg policy loss": 0.3097914670361206, "Total num played games": 60225, "Total num trained steps": 119936, "Timestamp in ms": 1699947341784, "logtype": "training_step"}
{"Avg objective": 22.8984375, "Games time in secs": 229.4852434489876, "Avg game time in secs": 0.9604338940553134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 60288, "Total num trained steps": 120034, "Timestamp in ms": 1699947395051, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904179307372225, "Avg loss": 0.6392798684537411, "Avg value loss": 0.3394985133490991, "Avg policy loss": 0.29978135193232447, "Total num played games": 60321, "Total num trained steps": 120064, "Timestamp in ms": 1699947411718, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909390581258593, "Avg loss": 0.5916640707291663, "Avg value loss": 0.2827225560322404, "Avg policy loss": 0.3089415073627606, "Total num played games": 60369, "Total num trained steps": 120192, "Timestamp in ms": 1699947482955, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 109.09138187766075, "Avg game time in secs": 1.0919261109665968, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 60416, "Total num trained steps": 120234, "Timestamp in ms": 1699947504142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914594988248535, "Avg loss": 0.6278192810714245, "Avg value loss": 0.31857038466841914, "Avg policy loss": 0.30924890493042767, "Total num played games": 60418, "Total num trained steps": 120320, "Timestamp in ms": 1699947551096, "logtype": "training_step"}
{"Total num played games": 60466, "Total num trained steps": 120351, "Timestamp in ms": 1699947627027, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.16015625}
{"Ratio train steps to played games": 1.9904154410549626, "Avg loss": 0.8071025996468961, "Avg value loss": 0.4930898382444866, "Avg policy loss": 0.31401276029646397, "Total num played games": 60514, "Total num trained steps": 120448, "Timestamp in ms": 1699947677181, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 209.75102497637272, "Avg game time in secs": 1.018918056768598, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 60544, "Total num trained steps": 120519, "Timestamp in ms": 1699947713893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990754193633602, "Avg loss": 0.526634102454409, "Avg value loss": 0.2400544864940457, "Avg policy loss": 0.2865796209080145, "Total num played games": 60568, "Total num trained steps": 120576, "Timestamp in ms": 1699947746615, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908131288141184, "Avg loss": 0.6226292233914137, "Avg value loss": 0.3268175584380515, "Avg policy loss": 0.29581165313720703, "Total num played games": 60630, "Total num trained steps": 120704, "Timestamp in ms": 1699947818029, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 129.35584400221705, "Avg game time in secs": 1.0794516747264424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 60672, "Total num trained steps": 120753, "Timestamp in ms": 1699947843249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912986156888597, "Avg loss": 0.676258981693536, "Avg value loss": 0.3791597534727771, "Avg policy loss": 0.2970992267364636, "Total num played games": 60680, "Total num trained steps": 120832, "Timestamp in ms": 1699947883207, "logtype": "training_step"}
{"Total num played games": 60777, "Total num trained steps": 120952, "Timestamp in ms": 1699948014337, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.60546875}
{"Avg objective": 21.515625, "Games time in secs": 172.97205551154912, "Avg game time in secs": 1.0286636002565501, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 60800, "Total num trained steps": 120954, "Timestamp in ms": 1699948016221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886722346442194, "Avg loss": 0.6903385738842189, "Avg value loss": 0.3993584989802912, "Avg policy loss": 0.2909800710622221, "Total num played games": 60824, "Total num trained steps": 120960, "Timestamp in ms": 1699948019936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907603781339909, "Avg loss": 0.7242405626457185, "Avg value loss": 0.42690415831748396, "Avg policy loss": 0.29733639617916197, "Total num played games": 60825, "Total num trained steps": 121088, "Timestamp in ms": 1699948090091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912442093504616, "Avg loss": 0.4447604918386787, "Avg value loss": 0.17310641074436717, "Avg policy loss": 0.27165407687425613, "Total num played games": 60874, "Total num trained steps": 121216, "Timestamp in ms": 1699948161748, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 210.51940175704658, "Avg game time in secs": 1.1784139886440244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 60928, "Total num trained steps": 121337, "Timestamp in ms": 1699948226741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901430164665748, "Avg loss": 0.511482966132462, "Avg value loss": 0.23366816819179803, "Avg policy loss": 0.277814797940664, "Total num played games": 60972, "Total num trained steps": 121344, "Timestamp in ms": 1699948230179, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906751884627991, "Avg loss": 0.6883650228846818, "Avg value loss": 0.407985168218147, "Avg policy loss": 0.2803798533277586, "Total num played games": 61020, "Total num trained steps": 121472, "Timestamp in ms": 1699948303676, "logtype": "training_step"}
{"Avg objective": 22.828125, "Games time in secs": 113.47201503068209, "Avg game time in secs": 0.9907208228687523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 61056, "Total num trained steps": 121531, "Timestamp in ms": 1699948340213, "logtype": "played_game"}
{"Total num played games": 61072, "Total num trained steps": 121554, "Timestamp in ms": 1699948410193, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3828125}
{"Ratio train steps to played games": 1.9895124345549737, "Avg loss": 1.0304758874699473, "Avg value loss": 0.7398520192364231, "Avg policy loss": 0.2906238635769114, "Total num played games": 61120, "Total num trained steps": 121600, "Timestamp in ms": 1699948436581, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916066753926702, "Avg loss": 0.44221702963113785, "Avg value loss": 0.15772113774437457, "Avg policy loss": 0.2844958887435496, "Total num played games": 61120, "Total num trained steps": 121728, "Timestamp in ms": 1699948513061, "logtype": "training_step"}
{"Avg objective": 22.7109375, "Games time in secs": 229.02376002818346, "Avg game time in secs": 1.071833991081803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 61184, "Total num trained steps": 121828, "Timestamp in ms": 1699948569238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905093273220296, "Avg loss": 0.8797860995400697, "Avg value loss": 0.5849748805048876, "Avg policy loss": 0.29481121653225273, "Total num played games": 61218, "Total num trained steps": 121856, "Timestamp in ms": 1699948584309, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910553977736427, "Avg loss": 0.4961120586376637, "Avg value loss": 0.20789288368541747, "Avg policy loss": 0.28821917879395187, "Total num played games": 61266, "Total num trained steps": 121984, "Timestamp in ms": 1699948652489, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 105.91858307644725, "Avg game time in secs": 1.1019479586102534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 61312, "Total num trained steps": 122025, "Timestamp in ms": 1699948675157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915355133327897, "Avg loss": 0.6937336071860045, "Avg value loss": 0.4062749180593528, "Avg policy loss": 0.2874586854595691, "Total num played games": 61315, "Total num trained steps": 122112, "Timestamp in ms": 1699948723603, "logtype": "training_step"}
{"Total num played games": 61363, "Total num trained steps": 122155, "Timestamp in ms": 1699948808886, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.078125}
{"Ratio train steps to played games": 1.9905065867678429, "Avg loss": 0.6660782874096185, "Avg value loss": 0.3685622870689258, "Avg policy loss": 0.2975159988272935, "Total num played games": 61411, "Total num trained steps": 122240, "Timestamp in ms": 1699948860942, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 229.8520979359746, "Avg game time in secs": 1.0829583956074202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 61440, "Total num trained steps": 122312, "Timestamp in ms": 1699948905009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991002277904328, "Avg loss": 0.649153683334589, "Avg value loss": 0.3579282963182777, "Avg policy loss": 0.29122539528179914, "Total num played games": 61460, "Total num trained steps": 122368, "Timestamp in ms": 1699948937162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914971792745777, "Avg loss": 0.5680680812802166, "Avg value loss": 0.27983931128983386, "Avg policy loss": 0.28822877001948655, "Total num played games": 61509, "Total num trained steps": 122496, "Timestamp in ms": 1699949013624, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 168.77643902786076, "Avg game time in secs": 1.2730102600180544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.68}, "Total num played games": 61568, "Total num trained steps": 122606, "Timestamp in ms": 1699949073785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904554751160601, "Avg loss": 0.6427691166754812, "Avg value loss": 0.35348138216068037, "Avg policy loss": 0.2892877303529531, "Total num played games": 61606, "Total num trained steps": 122624, "Timestamp in ms": 1699949083621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909496391209147, "Avg loss": 0.6017841978464276, "Avg value loss": 0.3105399213382043, "Avg policy loss": 0.29124427877832204, "Total num played games": 61655, "Total num trained steps": 122752, "Timestamp in ms": 1699949154665, "logtype": "training_step"}
{"Total num played games": 61655, "Total num trained steps": 122755, "Timestamp in ms": 1699949219395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4375}
{"Avg objective": 21.3515625, "Games time in secs": 148.01129715517163, "Avg game time in secs": 0.9592414762155386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.42}, "Total num played games": 61696, "Total num trained steps": 122757, "Timestamp in ms": 1699949221797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914590862680908, "Avg loss": 0.5912840669043362, "Avg value loss": 0.3068540387030225, "Avg policy loss": 0.2844300330616534, "Total num played games": 61703, "Total num trained steps": 122880, "Timestamp in ms": 1699949285877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990436738458551, "Avg loss": 0.662490060320124, "Avg value loss": 0.3734095867257565, "Avg policy loss": 0.2890804734779522, "Total num played games": 61799, "Total num trained steps": 123008, "Timestamp in ms": 1699949355109, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 176.7918129079044, "Avg game time in secs": 1.0677469867805485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 61824, "Total num trained steps": 123088, "Timestamp in ms": 1699949398589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909615664462301, "Avg loss": 0.6311112567782402, "Avg value loss": 0.3273244188167155, "Avg policy loss": 0.3037868356332183, "Total num played games": 61847, "Total num trained steps": 123136, "Timestamp in ms": 1699949424821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914855804184506, "Avg loss": 0.5580393369309604, "Avg value loss": 0.25644383468898013, "Avg policy loss": 0.3015954971779138, "Total num played games": 61895, "Total num trained steps": 123264, "Timestamp in ms": 1699949491573, "logtype": "training_step"}
{"Total num played games": 61943, "Total num trained steps": 123356, "Timestamp in ms": 1699949606192, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.84375}
{"Avg objective": 21.8515625, "Games time in secs": 208.952117620036, "Avg game time in secs": 1.1270111243211431, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 61952, "Total num trained steps": 123357, "Timestamp in ms": 1699949607541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904663580197126, "Avg loss": 0.651014490518719, "Avg value loss": 0.3554599859053269, "Avg policy loss": 0.2955545063596219, "Total num played games": 61991, "Total num trained steps": 123392, "Timestamp in ms": 1699949626193, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991005657731427, "Avg loss": 0.5725851056631655, "Avg value loss": 0.27785069978563115, "Avg policy loss": 0.29473440314177424, "Total num played games": 62039, "Total num trained steps": 123520, "Timestamp in ms": 1699949698139, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 116.81258347816765, "Avg game time in secs": 0.9855120463762432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 62080, "Total num trained steps": 123568, "Timestamp in ms": 1699949724354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991511910705945, "Avg loss": 0.6153882187791169, "Avg value loss": 0.32319425308378413, "Avg policy loss": 0.2921939683146775, "Total num played games": 62087, "Total num trained steps": 123648, "Timestamp in ms": 1699949770691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904478572002895, "Avg loss": 0.6314788185991347, "Avg value loss": 0.3405778424930759, "Avg policy loss": 0.29090097616426647, "Total num played games": 62185, "Total num trained steps": 123776, "Timestamp in ms": 1699949840300, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 162.87609502859414, "Avg game time in secs": 1.0553781364142196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.51, "agent_stopped_0": 0.56}, "Total num played games": 62208, "Total num trained steps": 123861, "Timestamp in ms": 1699949887230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908734494504787, "Avg loss": 0.654287931509316, "Avg value loss": 0.35811547585763037, "Avg policy loss": 0.2961724562337622, "Total num played games": 62236, "Total num trained steps": 123904, "Timestamp in ms": 1699949911351, "logtype": "training_step"}
{"Total num played games": 62236, "Total num trained steps": 123957, "Timestamp in ms": 1699950000547, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.49609375}
{"Ratio train steps to played games": 1.9913782030698093, "Avg loss": 0.6528119926806539, "Avg value loss": 0.3529040605062619, "Avg policy loss": 0.299907932523638, "Total num played games": 62284, "Total num trained steps": 124032, "Timestamp in ms": 1699950041728, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 219.47173792123795, "Avg game time in secs": 1.106441941272351, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 62336, "Total num trained steps": 124153, "Timestamp in ms": 1699950106702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903335951651946, "Avg loss": 0.5813651061616838, "Avg value loss": 0.28627259633503854, "Avg policy loss": 0.29509250062983483, "Total num played games": 62381, "Total num trained steps": 124160, "Timestamp in ms": 1699950109925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990837738266859, "Avg loss": 0.6392495797481388, "Avg value loss": 0.33434513048268855, "Avg policy loss": 0.3049044506624341, "Total num played games": 62430, "Total num trained steps": 124288, "Timestamp in ms": 1699950173382, "logtype": "training_step"}
{"Avg objective": 22.6015625, "Games time in secs": 100.60601708292961, "Avg game time in secs": 0.9561153646791354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 62464, "Total num trained steps": 124352, "Timestamp in ms": 1699950207308, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912294740885375, "Avg loss": 0.7077769993338734, "Avg value loss": 0.40248952884576283, "Avg policy loss": 0.3052874729037285, "Total num played games": 62482, "Total num trained steps": 124416, "Timestamp in ms": 1699950237374, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917479609787303, "Avg loss": 0.6252673366107047, "Avg value loss": 0.33053563415887766, "Avg policy loss": 0.29473170079290867, "Total num played games": 62530, "Total num trained steps": 124544, "Timestamp in ms": 1699950301886, "logtype": "training_step"}
{"Total num played games": 62581, "Total num trained steps": 124559, "Timestamp in ms": 1699950365132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.67578125}
{"Avg objective": 22.328125, "Games time in secs": 159.11037488281727, "Avg game time in secs": 1.0785874303837772, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 62592, "Total num trained steps": 124561, "Timestamp in ms": 1699950366419, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906433122036118, "Avg loss": 0.7932410824578255, "Avg value loss": 0.4902282211696729, "Avg policy loss": 0.3030128621030599, "Total num played games": 62629, "Total num trained steps": 124672, "Timestamp in ms": 1699950427092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911133092951274, "Avg loss": 0.7360157675575465, "Avg value loss": 0.4409811406803783, "Avg policy loss": 0.295034620561637, "Total num played games": 62678, "Total num trained steps": 124800, "Timestamp in ms": 1699950492823, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 151.57612529583275, "Avg game time in secs": 1.0715198640682502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 62720, "Total num trained steps": 124848, "Timestamp in ms": 1699950517995, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914239714344921, "Avg loss": 0.6595877767540514, "Avg value loss": 0.35385464038699865, "Avg policy loss": 0.3057331374147907, "Total num played games": 62733, "Total num trained steps": 124928, "Timestamp in ms": 1699950561767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903708419544803, "Avg loss": 0.5445832891855389, "Avg value loss": 0.2539042215212248, "Avg policy loss": 0.29067906842101365, "Total num played games": 62829, "Total num trained steps": 125056, "Timestamp in ms": 1699950619682, "logtype": "training_step"}
{"Avg objective": 22.65625, "Games time in secs": 146.97435230761766, "Avg game time in secs": 0.9969412776699755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 62848, "Total num trained steps": 125151, "Timestamp in ms": 1699950664970, "logtype": "played_game"}
{"Total num played games": 62883, "Total num trained steps": 125162, "Timestamp in ms": 1699950738443, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.95703125}
{"Ratio train steps to played games": 1.9892104050467974, "Avg loss": 0.8830399843864143, "Avg value loss": 0.5827131992555223, "Avg policy loss": 0.30032679915893823, "Total num played games": 62931, "Total num trained steps": 125184, "Timestamp in ms": 1699950751789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912602691837091, "Avg loss": 0.5430496216285974, "Avg value loss": 0.2435296366456896, "Avg policy loss": 0.2995199878932908, "Total num played games": 62931, "Total num trained steps": 125312, "Timestamp in ms": 1699950824923, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 182.3083086553961, "Avg game time in secs": 1.0553103993297555, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 62976, "Total num trained steps": 125355, "Timestamp in ms": 1699950847278, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917275325500159, "Avg loss": 0.548952589277178, "Avg value loss": 0.26971412694547325, "Avg policy loss": 0.27923846046905965, "Total num played games": 62980, "Total num trained steps": 125440, "Timestamp in ms": 1699950893187, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907254740313274, "Avg loss": 0.6327335913665593, "Avg value loss": 0.35292127076536417, "Avg policy loss": 0.2798123280517757, "Total num played games": 63076, "Total num trained steps": 125568, "Timestamp in ms": 1699950961193, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 150.80328309349716, "Avg game time in secs": 0.9928493592451559, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 63104, "Total num trained steps": 125643, "Timestamp in ms": 1699950998082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912394651796463, "Avg loss": 0.5308603171724826, "Avg value loss": 0.24852916999952868, "Avg policy loss": 0.2823311489773914, "Total num played games": 63124, "Total num trained steps": 125696, "Timestamp in ms": 1699951025758, "logtype": "training_step"}
{"Total num played games": 63172, "Total num trained steps": 125763, "Timestamp in ms": 1699951137261, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.82421875}
{"Ratio train steps to played games": 1.9902404302435939, "Avg loss": 0.8000195762142539, "Avg value loss": 0.501391271915054, "Avg policy loss": 0.29862830811180174, "Total num played games": 63220, "Total num trained steps": 125824, "Timestamp in ms": 1699951169717, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 232.552673894912, "Avg game time in secs": 1.1184486992133316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 63232, "Total num trained steps": 125930, "Timestamp in ms": 1699951230634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906592277662751, "Avg loss": 0.5542562701739371, "Avg value loss": 0.2708593694260344, "Avg policy loss": 0.2833969050552696, "Total num played games": 63271, "Total num trained steps": 125952, "Timestamp in ms": 1699951239829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911716862237243, "Avg loss": 0.7109574296046048, "Avg value loss": 0.4072544100927189, "Avg policy loss": 0.30370302009396255, "Total num played games": 63319, "Total num trained steps": 126080, "Timestamp in ms": 1699951302872, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 98.97612636163831, "Avg game time in secs": 1.0905194529914297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 63360, "Total num trained steps": 126128, "Timestamp in ms": 1699951329611, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991683368314738, "Avg loss": 0.5478765110019594, "Avg value loss": 0.2483750906540081, "Avg policy loss": 0.2995014116168022, "Total num played games": 63367, "Total num trained steps": 126208, "Timestamp in ms": 1699951372694, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906247538013078, "Avg loss": 0.6529065838549286, "Avg value loss": 0.3544760773074813, "Avg policy loss": 0.29843051359057426, "Total num played games": 63465, "Total num trained steps": 126336, "Timestamp in ms": 1699951438160, "logtype": "training_step"}
{"Total num played games": 63465, "Total num trained steps": 126364, "Timestamp in ms": 1699951509122, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3203125}
{"Avg objective": 21.8203125, "Games time in secs": 182.17508806474507, "Avg game time in secs": 1.0460141885851044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 63488, "Total num trained steps": 126368, "Timestamp in ms": 1699951511786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911356730118244, "Avg loss": 0.8019687307532877, "Avg value loss": 0.49855184654006734, "Avg policy loss": 0.30341688683256507, "Total num played games": 63513, "Total num trained steps": 126464, "Timestamp in ms": 1699951563283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916144866429628, "Avg loss": 0.4909221918787807, "Avg value loss": 0.19714835105696693, "Avg policy loss": 0.2937738405307755, "Total num played games": 63562, "Total num trained steps": 126592, "Timestamp in ms": 1699951623789, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 173.86410411261022, "Avg game time in secs": 1.0818107323284494, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 63616, "Total num trained steps": 126709, "Timestamp in ms": 1699951685650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905904899542877, "Avg loss": 0.7574744112789631, "Avg value loss": 0.45312544325133786, "Avg policy loss": 0.3043489765841514, "Total num played games": 63659, "Total num trained steps": 126720, "Timestamp in ms": 1699951691460, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991099879134161, "Avg loss": 0.5888914761599153, "Avg value loss": 0.2901095883571543, "Avg policy loss": 0.29878188495058566, "Total num played games": 63707, "Total num trained steps": 126848, "Timestamp in ms": 1699951756673, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 97.0954901240766, "Avg game time in secs": 0.9234151454875246, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 63744, "Total num trained steps": 126905, "Timestamp in ms": 1699951782746, "logtype": "played_game"}
{"Total num played games": 63776, "Total num trained steps": 126967, "Timestamp in ms": 1699951872312, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.48828125}
{"Ratio train steps to played games": 1.989486548736349, "Avg loss": 0.7925540299620479, "Avg value loss": 0.4997413062956184, "Avg policy loss": 0.29281272331718355, "Total num played games": 63823, "Total num trained steps": 126976, "Timestamp in ms": 1699951877559, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914608924542492, "Avg loss": 0.5689393286593258, "Avg value loss": 0.2778813763288781, "Avg policy loss": 0.291057953145355, "Total num played games": 63824, "Total num trained steps": 127104, "Timestamp in ms": 1699951944664, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 182.64043634198606, "Avg game time in secs": 1.0349429469933966, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 63872, "Total num trained steps": 127142, "Timestamp in ms": 1699951965392, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919683116232465, "Avg loss": 0.5724591708276421, "Avg value loss": 0.30320525326533243, "Avg policy loss": 0.2692539229756221, "Total num played games": 63872, "Total num trained steps": 127232, "Timestamp in ms": 1699952011504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909954977488744, "Avg loss": 0.6659761981572956, "Avg value loss": 0.37992977094836533, "Avg policy loss": 0.2860464366385713, "Total num played games": 63968, "Total num trained steps": 127360, "Timestamp in ms": 1699952082862, "logtype": "training_step"}
{"Avg objective": 21.96875, "Games time in secs": 152.48486800678074, "Avg game time in secs": 0.9543473703524796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 64000, "Total num trained steps": 127426, "Timestamp in ms": 1699952117877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991362074351765, "Avg loss": 0.5023733975831419, "Avg value loss": 0.22366606345167384, "Avg policy loss": 0.2787073340732604, "Total num played games": 64020, "Total num trained steps": 127488, "Timestamp in ms": 1699952148876, "logtype": "training_step"}
{"Total num played games": 64069, "Total num trained steps": 127568, "Timestamp in ms": 1699952255039, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8203125}
{"Ratio train steps to played games": 1.9903457741316655, "Avg loss": 0.7674789745360613, "Avg value loss": 0.49322102509904653, "Avg policy loss": 0.27425794501323253, "Total num played games": 64117, "Total num trained steps": 127616, "Timestamp in ms": 1699952283155, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 225.91262322105467, "Avg game time in secs": 1.0224609118304215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 64128, "Total num trained steps": 127724, "Timestamp in ms": 1699952343790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908362684287628, "Avg loss": 0.39521043514832854, "Avg value loss": 0.14744608488399535, "Avg policy loss": 0.2477643541060388, "Total num played games": 64166, "Total num trained steps": 127744, "Timestamp in ms": 1699952352027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913414520198087, "Avg loss": 0.6257645068690181, "Avg value loss": 0.3649529093527235, "Avg policy loss": 0.26081159722525626, "Total num played games": 64214, "Total num trained steps": 127872, "Timestamp in ms": 1699952411472, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 90.71525306254625, "Avg game time in secs": 1.055358203666401, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 64256, "Total num trained steps": 127918, "Timestamp in ms": 1699952434505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918458809249635, "Avg loss": 0.5866193324327469, "Avg value loss": 0.32347058987943456, "Avg policy loss": 0.2631487416801974, "Total num played games": 64262, "Total num trained steps": 128000, "Timestamp in ms": 1699952478788, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908480686161782, "Avg loss": 0.6985661799553782, "Avg value loss": 0.43388871173374355, "Avg policy loss": 0.2646774717140943, "Total num played games": 64358, "Total num trained steps": 128128, "Timestamp in ms": 1699952546965, "logtype": "training_step"}
{"Total num played games": 64358, "Total num trained steps": 128170, "Timestamp in ms": 1699952596495, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.63671875}
{"Avg objective": 21.796875, "Games time in secs": 164.20678205788136, "Avg game time in secs": 1.025524827055051, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 64384, "Total num trained steps": 128172, "Timestamp in ms": 1699952598712, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913672639195106, "Avg loss": 0.5137873769272119, "Avg value loss": 0.24762405041838065, "Avg policy loss": 0.26616332423873246, "Total num played games": 64406, "Total num trained steps": 128256, "Timestamp in ms": 1699952645853, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918392677061516, "Avg loss": 0.7213272505905479, "Avg value loss": 0.45801752628176473, "Avg policy loss": 0.2633097164798528, "Total num played games": 64455, "Total num trained steps": 128384, "Timestamp in ms": 1699952714509, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 184.72049822099507, "Avg game time in secs": 1.058138661494013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 64512, "Total num trained steps": 128496, "Timestamp in ms": 1699952783433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908290990209443, "Avg loss": 0.720872784499079, "Avg value loss": 0.46450453097349964, "Avg policy loss": 0.2563682598993182, "Total num played games": 64552, "Total num trained steps": 128512, "Timestamp in ms": 1699952791553, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913157894736842, "Avg loss": 0.667997928801924, "Avg value loss": 0.40010262664873153, "Avg policy loss": 0.2678953038994223, "Total num played games": 64600, "Total num trained steps": 128640, "Timestamp in ms": 1699952858368, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 101.43661712296307, "Avg game time in secs": 0.9806890610052506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 64640, "Total num trained steps": 128692, "Timestamp in ms": 1699952884870, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918172255908921, "Avg loss": 0.4878271317575127, "Avg value loss": 0.22864914004458115, "Avg policy loss": 0.25917799212038517, "Total num played games": 64648, "Total num trained steps": 128768, "Timestamp in ms": 1699952925522, "logtype": "training_step"}
{"Total num played games": 64648, "Total num trained steps": 128774, "Timestamp in ms": 1699952995227, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8125}
{"Ratio train steps to played games": 1.9907793531646742, "Avg loss": 0.5830126127693802, "Avg value loss": 0.3247888585610781, "Avg policy loss": 0.25822375586722046, "Total num played games": 64746, "Total num trained steps": 128896, "Timestamp in ms": 1699953055282, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 217.0368336495012, "Avg game time in secs": 1.0492124016891466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 64768, "Total num trained steps": 128984, "Timestamp in ms": 1699953101906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912647580831855, "Avg loss": 0.521809637430124, "Avg value loss": 0.2689007314329501, "Avg policy loss": 0.2529089010786265, "Total num played games": 64795, "Total num trained steps": 129024, "Timestamp in ms": 1699953122745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917493021606032, "Avg loss": 0.5370107726193964, "Avg value loss": 0.2920321014826186, "Avg policy loss": 0.24497867026366293, "Total num played games": 64843, "Total num trained steps": 129152, "Timestamp in ms": 1699953187537, "logtype": "training_step"}
{"Avg objective": 22.4375, "Games time in secs": 153.35801300778985, "Avg game time in secs": 0.9125026231777156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.54, "agent_stopped_0": 0.47}, "Total num played games": 64896, "Total num trained steps": 129272, "Timestamp in ms": 1699953255265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907453033569449, "Avg loss": 0.5860739373601973, "Avg value loss": 0.33698961275513284, "Avg policy loss": 0.24908432294614613, "Total num played games": 64940, "Total num trained steps": 129280, "Timestamp in ms": 1699953258848, "logtype": "training_step"}
{"Total num played games": 64995, "Total num trained steps": 129374, "Timestamp in ms": 1699953371633, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2578125}
{"Avg objective": 20.2578125, "Games time in secs": 118.3201652392745, "Avg game time in secs": 0.9674155423708726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 65024, "Total num trained steps": 129375, "Timestamp in ms": 1699953373585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895607521178298, "Avg loss": 0.8502097278833389, "Avg value loss": 0.5901496488950215, "Avg policy loss": 0.26006008009426296, "Total num played games": 65043, "Total num trained steps": 129408, "Timestamp in ms": 1699953390601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991528681026398, "Avg loss": 0.39963497524149716, "Avg value loss": 0.14530975191155449, "Avg policy loss": 0.254325223271735, "Total num played games": 65043, "Total num trained steps": 129536, "Timestamp in ms": 1699953461039, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992026547448956, "Avg loss": 0.44354249094612896, "Avg value loss": 0.2015412733599078, "Avg policy loss": 0.2420012173242867, "Total num played games": 65091, "Total num trained steps": 129664, "Timestamp in ms": 1699953532829, "logtype": "training_step"}
{"Avg objective": 22.4765625, "Games time in secs": 214.46678648516536, "Avg game time in secs": 1.0175343992304988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 65152, "Total num trained steps": 129767, "Timestamp in ms": 1699953588052, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910564989951984, "Avg loss": 0.7118641322012991, "Avg value loss": 0.47336226009065285, "Avg policy loss": 0.2385018701897934, "Total num played games": 65187, "Total num trained steps": 129792, "Timestamp in ms": 1699953601029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915230854129622, "Avg loss": 0.6481993386987597, "Avg value loss": 0.4055842440575361, "Avg policy loss": 0.24261509394273162, "Total num played games": 65236, "Total num trained steps": 129920, "Timestamp in ms": 1699953676215, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 110.50260249525309, "Avg game time in secs": 0.9437115045293467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 65280, "Total num trained steps": 129965, "Timestamp in ms": 1699953698555, "logtype": "played_game"}
{"Total num played games": 65284, "Total num trained steps": 129978, "Timestamp in ms": 1699953760052, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.79296875}
{"Ratio train steps to played games": 1.9905559297128512, "Avg loss": 0.932937943842262, "Avg value loss": 0.6624858566210605, "Avg policy loss": 0.2704520806437358, "Total num played games": 65332, "Total num trained steps": 130048, "Timestamp in ms": 1699953793141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910218565026536, "Avg loss": 0.459477033931762, "Avg value loss": 0.213201132544782, "Avg policy loss": 0.2462758992332965, "Total num played games": 65381, "Total num trained steps": 130176, "Timestamp in ms": 1699953865668, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 210.52253209799528, "Avg game time in secs": 0.9826560637447983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.53, "agent_stopped_0": 0.54}, "Total num played games": 65408, "Total num trained steps": 130253, "Timestamp in ms": 1699953909077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915328065536688, "Avg loss": 0.4444012176245451, "Avg value loss": 0.1939095421694219, "Avg policy loss": 0.2504916745238006, "Total num played games": 65429, "Total num trained steps": 130304, "Timestamp in ms": 1699953936018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920277349298228, "Avg loss": 0.6086653118254617, "Avg value loss": 0.3566083157493267, "Avg policy loss": 0.2520569987827912, "Total num played games": 65477, "Total num trained steps": 130432, "Timestamp in ms": 1699953996221, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 140.05844675190747, "Avg game time in secs": 1.1064630486798706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 65536, "Total num trained steps": 130539, "Timestamp in ms": 1699954049136, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910633949948913, "Avg loss": 0.5720000746659935, "Avg value loss": 0.3225762555957772, "Avg policy loss": 0.2494238215731457, "Total num played games": 65573, "Total num trained steps": 130560, "Timestamp in ms": 1699954061661, "logtype": "training_step"}
{"Total num played games": 65573, "Total num trained steps": 130580, "Timestamp in ms": 1699954133183, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2578125}
{"Ratio train steps to played games": 1.991557580652535, "Avg loss": 0.7002901148516685, "Avg value loss": 0.4404639900312759, "Avg policy loss": 0.25982612231746316, "Total num played games": 65621, "Total num trained steps": 130688, "Timestamp in ms": 1699954181179, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 152.42540659755468, "Avg game time in secs": 1.0447093036345905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 65664, "Total num trained steps": 130734, "Timestamp in ms": 1699954201562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919751488480455, "Avg loss": 0.4564921148121357, "Avg value loss": 0.20658977041603066, "Avg policy loss": 0.24990234652068466, "Total num played games": 65671, "Total num trained steps": 130816, "Timestamp in ms": 1699954237299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990953184631057, "Avg loss": 0.5646966851782054, "Avg value loss": 0.3116889431257732, "Avg policy loss": 0.2530077430419624, "Total num played games": 65769, "Total num trained steps": 130944, "Timestamp in ms": 1699954292724, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 132.89638323150575, "Avg game time in secs": 0.969150264019845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 65792, "Total num trained steps": 131036, "Timestamp in ms": 1699954334458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913401498002157, "Avg loss": 0.8383962460793555, "Avg value loss": 0.5789580354467034, "Avg policy loss": 0.25943821272812784, "Total num played games": 65821, "Total num trained steps": 131072, "Timestamp in ms": 1699954349033, "logtype": "training_step"}
{"Total num played games": 65875, "Total num trained steps": 131181, "Timestamp in ms": 1699954455130, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.40234375}
{"Avg objective": 21.5234375, "Games time in secs": 123.45951400324702, "Avg game time in secs": 1.1047599920420907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.65}, "Total num played games": 65920, "Total num trained steps": 131186, "Timestamp in ms": 1699954457918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901855194696842, "Avg loss": 0.7408838914707303, "Avg value loss": 0.47140496323117986, "Avg policy loss": 0.2694789308588952, "Total num played games": 65923, "Total num trained steps": 131200, "Timestamp in ms": 1699954463874, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992127178678155, "Avg loss": 0.4644362913677469, "Avg value loss": 0.18451249148347415, "Avg policy loss": 0.27992380503565073, "Total num played games": 65923, "Total num trained steps": 131328, "Timestamp in ms": 1699954520221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911692088641149, "Avg loss": 0.737518206005916, "Avg value loss": 0.4683413142920472, "Avg policy loss": 0.2691768881632015, "Total num played games": 66019, "Total num trained steps": 131456, "Timestamp in ms": 1699954575915, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 149.6393665485084, "Avg game time in secs": 1.0212450698018074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 66048, "Total num trained steps": 131529, "Timestamp in ms": 1699954607557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915394045799215, "Avg loss": 0.5617982295807451, "Avg value loss": 0.2932689515291713, "Avg policy loss": 0.2685292841633782, "Total num played games": 66071, "Total num trained steps": 131584, "Timestamp in ms": 1699954631113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920446467732422, "Avg loss": 0.5507943767588586, "Avg value loss": 0.2830204034980852, "Avg policy loss": 0.2677739745704457, "Total num played games": 66119, "Total num trained steps": 131712, "Timestamp in ms": 1699954689252, "logtype": "training_step"}
{"Total num played games": 66168, "Total num trained steps": 131783, "Timestamp in ms": 1699954798089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.34765625}
{"Avg objective": 21.890625, "Games time in secs": 191.91586622223258, "Avg game time in secs": 1.115910593420267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.68, "agent_stopped_0": 0.42}, "Total num played games": 66176, "Total num trained steps": 131786, "Timestamp in ms": 1699954799473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910444605533406, "Avg loss": 0.7668261933140457, "Avg value loss": 0.4989076769561507, "Avg policy loss": 0.26791851327288896, "Total num played games": 66216, "Total num trained steps": 131840, "Timestamp in ms": 1699954823938, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915038104580096, "Avg loss": 0.5689619015902281, "Avg value loss": 0.2958700750605203, "Avg policy loss": 0.27309182204771787, "Total num played games": 66265, "Total num trained steps": 131968, "Timestamp in ms": 1699954878190, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 101.22114432416856, "Avg game time in secs": 1.0436084826069418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 66304, "Total num trained steps": 132022, "Timestamp in ms": 1699954900705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919775612992732, "Avg loss": 0.5674307434819639, "Avg value loss": 0.2973732557729818, "Avg policy loss": 0.27005748788360506, "Total num played games": 66314, "Total num trained steps": 132096, "Timestamp in ms": 1699954933915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909954676183161, "Avg loss": 0.7100216422695667, "Avg value loss": 0.4223548238223884, "Avg policy loss": 0.2876668116077781, "Total num played games": 66411, "Total num trained steps": 132224, "Timestamp in ms": 1699954990578, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 127.38791144825518, "Avg game time in secs": 1.1319448015565285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 66432, "Total num trained steps": 132313, "Timestamp in ms": 1699955028093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914084952077158, "Avg loss": 0.5310835964046419, "Avg value loss": 0.24877108735381626, "Avg policy loss": 0.28231250355020165, "Total num played games": 66461, "Total num trained steps": 132352, "Timestamp in ms": 1699955045017, "logtype": "training_step"}
{"Total num played games": 66461, "Total num trained steps": 132387, "Timestamp in ms": 1699955142633, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.35546875}
{"Ratio train steps to played games": 1.9919108692056715, "Avg loss": 0.7344869109801948, "Avg value loss": 0.44580323819536716, "Avg policy loss": 0.28868367127142847, "Total num played games": 66509, "Total num trained steps": 132480, "Timestamp in ms": 1699955184375, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 209.66037334874272, "Avg game time in secs": 1.034710360923782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 66560, "Total num trained steps": 132604, "Timestamp in ms": 1699955237754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991006411122622, "Avg loss": 0.4892215633299202, "Avg value loss": 0.20885178842581809, "Avg policy loss": 0.28036977362353355, "Total num played games": 66603, "Total num trained steps": 132608, "Timestamp in ms": 1699955239354, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914033666396616, "Avg loss": 0.6259035100229084, "Avg value loss": 0.3531785008381121, "Avg policy loss": 0.27272501250263304, "Total num played games": 66654, "Total num trained steps": 132736, "Timestamp in ms": 1699955296111, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 85.00986631214619, "Avg game time in secs": 0.9756484988174634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 66688, "Total num trained steps": 132800, "Timestamp in ms": 1699955322764, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917101397133776, "Avg loss": 0.48824054445140064, "Avg value loss": 0.21763990650651976, "Avg policy loss": 0.2706006368389353, "Total num played games": 66708, "Total num trained steps": 132864, "Timestamp in ms": 1699955349380, "logtype": "training_step"}
{"Total num played games": 66756, "Total num trained steps": 132990, "Timestamp in ms": 1699955474029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2421875}
{"Ratio train steps to played games": 1.9922104380130625, "Avg loss": 0.5102315240073949, "Avg value loss": 0.24015678183059208, "Avg policy loss": 0.27007474133279175, "Total num played games": 66756, "Total num trained steps": 132992, "Timestamp in ms": 1699955475014, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 197.81912175938487, "Avg game time in secs": 1.0633159240678651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 66816, "Total num trained steps": 133098, "Timestamp in ms": 1699955520583, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912493268712979, "Avg loss": 0.631000176537782, "Avg value loss": 0.3601262518786825, "Avg policy loss": 0.27087392564862967, "Total num played games": 66852, "Total num trained steps": 133120, "Timestamp in ms": 1699955529829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991689336641655, "Avg loss": 0.6205797700677067, "Avg value loss": 0.345421738922596, "Avg policy loss": 0.27515802741982043, "Total num played games": 66902, "Total num trained steps": 133248, "Timestamp in ms": 1699955585269, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 85.55743231996894, "Avg game time in secs": 0.9812391019222559, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 66944, "Total num trained steps": 133296, "Timestamp in ms": 1699955606141, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921435079386416, "Avg loss": 0.6065818313509226, "Avg value loss": 0.3327601883211173, "Avg policy loss": 0.27382164367008954, "Total num played games": 66951, "Total num trained steps": 133376, "Timestamp in ms": 1699955642939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991185287932346, "Avg loss": 0.5625763121061027, "Avg value loss": 0.3052445828798227, "Avg policy loss": 0.2573317299829796, "Total num played games": 67047, "Total num trained steps": 133504, "Timestamp in ms": 1699955703653, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 133.9503715801984, "Avg game time in secs": 0.9916516094526742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 67072, "Total num trained steps": 133585, "Timestamp in ms": 1699955740091, "logtype": "played_game"}
{"Total num played games": 67095, "Total num trained steps": 133593, "Timestamp in ms": 1699955789234, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.91796875}
{"Ratio train steps to played games": 1.990244701607018, "Avg loss": 0.7043011689092964, "Avg value loss": 0.4301753558102064, "Avg policy loss": 0.2741258073365316, "Total num played games": 67143, "Total num trained steps": 133632, "Timestamp in ms": 1699955807149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921659741149487, "Avg loss": 0.3716270658187568, "Avg value loss": 0.10826544824521989, "Avg policy loss": 0.2633616173407063, "Total num played games": 67143, "Total num trained steps": 133760, "Timestamp in ms": 1699955868161, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 180.0044597517699, "Avg game time in secs": 1.0432924138585804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.6}, "Total num played games": 67200, "Total num trained steps": 133874, "Timestamp in ms": 1699955920098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911957168352172, "Avg loss": 0.6192483527120203, "Avg value loss": 0.354470499267336, "Avg policy loss": 0.2647778547834605, "Total num played games": 67240, "Total num trained steps": 133888, "Timestamp in ms": 1699955925793, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916627036024255, "Avg loss": 0.6008715960197151, "Avg value loss": 0.3384831384755671, "Avg policy loss": 0.2623884610366076, "Total num played games": 67288, "Total num trained steps": 134016, "Timestamp in ms": 1699955980462, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 81.93059446662664, "Avg game time in secs": 0.9407560672116233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 67328, "Total num trained steps": 134068, "Timestamp in ms": 1699956002029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921438754900795, "Avg loss": 0.6646893115248531, "Avg value loss": 0.4045246812165715, "Avg policy loss": 0.26016462163534015, "Total num played games": 67336, "Total num trained steps": 134144, "Timestamp in ms": 1699956034248, "logtype": "training_step"}
{"Total num played games": 67389, "Total num trained steps": 134194, "Timestamp in ms": 1699956122804, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55859375}
{"Ratio train steps to played games": 1.991058321099693, "Avg loss": 0.6292166807688773, "Avg value loss": 0.366845736047253, "Avg policy loss": 0.2623709498438984, "Total num played games": 67437, "Total num trained steps": 134272, "Timestamp in ms": 1699956157973, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 194.81546536274254, "Avg game time in secs": 0.9993231858243234, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 67456, "Total num trained steps": 134364, "Timestamp in ms": 1699956196845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915093500874255, "Avg loss": 0.5138923078775406, "Avg value loss": 0.2646438681113068, "Avg policy loss": 0.24924844095949084, "Total num played games": 67486, "Total num trained steps": 134400, "Timestamp in ms": 1699956210590, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919892202446174, "Avg loss": 0.42359270935412496, "Avg value loss": 0.171839796268614, "Avg policy loss": 0.2517529189353809, "Total num played games": 67534, "Total num trained steps": 134528, "Timestamp in ms": 1699956263690, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 120.56035334430635, "Avg game time in secs": 1.09995131319738, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.71}, "Total num played games": 67584, "Total num trained steps": 134655, "Timestamp in ms": 1699956317405, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992188424665641, "Avg loss": 0.5080021226312965, "Avg value loss": 0.24981674694572575, "Avg policy loss": 0.2581853767624125, "Total num played games": 67588, "Total num trained steps": 134656, "Timestamp in ms": 1699956317537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991474586288416, "Avg loss": 0.7820809290278703, "Avg value loss": 0.5146811999147758, "Avg policy loss": 0.2673997188685462, "Total num played games": 67680, "Total num trained steps": 134784, "Timestamp in ms": 1699956372256, "logtype": "training_step"}
{"Total num played games": 67680, "Total num trained steps": 134795, "Timestamp in ms": 1699956418645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.296875}
{"Avg objective": 21.484375, "Games time in secs": 103.25974690169096, "Avg game time in secs": 0.9925820921052946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 67712, "Total num trained steps": 134800, "Timestamp in ms": 1699956420665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919531065438223, "Avg loss": 0.47698875004425645, "Avg value loss": 0.21651927882339805, "Avg policy loss": 0.26046947459690273, "Total num played games": 67728, "Total num trained steps": 134912, "Timestamp in ms": 1699956469661, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992401552148959, "Avg loss": 0.42238063109107316, "Avg value loss": 0.17324299982283264, "Avg policy loss": 0.24913763219956309, "Total num played games": 67777, "Total num trained steps": 135040, "Timestamp in ms": 1699956524882, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 150.02406578511, "Avg game time in secs": 0.9660826741019264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 67840, "Total num trained steps": 135148, "Timestamp in ms": 1699956570689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913373994519579, "Avg loss": 0.5635666775051504, "Avg value loss": 0.3148555285006296, "Avg policy loss": 0.2487111504888162, "Total num played games": 67878, "Total num trained steps": 135168, "Timestamp in ms": 1699956578964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917705772373282, "Avg loss": 0.43637010047677904, "Avg value loss": 0.19301998367882334, "Avg policy loss": 0.24335011991206557, "Total num played games": 67927, "Total num trained steps": 135296, "Timestamp in ms": 1699956634764, "logtype": "training_step"}
{"Avg objective": 19.6484375, "Games time in secs": 84.98910838924348, "Avg game time in secs": 0.9161371031514136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 67968, "Total num trained steps": 135345, "Timestamp in ms": 1699956655679, "logtype": "played_game"}
{"Total num played games": 67975, "Total num trained steps": 135400, "Timestamp in ms": 1699956736417, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4453125}
{"Ratio train steps to played games": 1.990856033988504, "Avg loss": 0.5189274045405909, "Avg value loss": 0.2821140256419312, "Avg policy loss": 0.2368133815471083, "Total num played games": 68023, "Total num trained steps": 135424, "Timestamp in ms": 1699956747540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913178886750598, "Avg loss": 0.42637413984630257, "Avg value loss": 0.18682759953662753, "Avg policy loss": 0.239546540658921, "Total num played games": 68071, "Total num trained steps": 135552, "Timestamp in ms": 1699956802885, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 186.09395903907716, "Avg game time in secs": 0.9029848387872335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.42, "agent_stopped_0": 0.58}, "Total num played games": 68096, "Total num trained steps": 135632, "Timestamp in ms": 1699956841773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917645331767468, "Avg loss": 0.5046415112446994, "Avg value loss": 0.270855282782577, "Avg policy loss": 0.23378623044118285, "Total num played games": 68120, "Total num trained steps": 135680, "Timestamp in ms": 1699956864592, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992093644111305, "Avg loss": 0.493697896017693, "Avg value loss": 0.25719875551294535, "Avg policy loss": 0.23649913957342505, "Total num played games": 68173, "Total num trained steps": 135808, "Timestamp in ms": 1699956923627, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 135.75255091674626, "Avg game time in secs": 0.9595692684379173, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 68224, "Total num trained steps": 135932, "Timestamp in ms": 1699956977526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912256287811094, "Avg loss": 0.4233321597566828, "Avg value loss": 0.19476277535432018, "Avg policy loss": 0.22856938536278903, "Total num played games": 68267, "Total num trained steps": 135936, "Timestamp in ms": 1699956978848, "logtype": "training_step"}
{"Total num played games": 68272, "Total num trained steps": 136004, "Timestamp in ms": 1699957023105, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.09765625}
{"Ratio train steps to played games": 1.9915544496487119, "Avg loss": 0.624602114316076, "Avg value loss": 0.38727659452706575, "Avg policy loss": 0.237325519323349, "Total num played games": 68320, "Total num trained steps": 136064, "Timestamp in ms": 1699957050256, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 102.05905421823263, "Avg game time in secs": 0.9213160970684839, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 68352, "Total num trained steps": 136132, "Timestamp in ms": 1699957079585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920430610812077, "Avg loss": 0.4104187049670145, "Avg value loss": 0.183680399088189, "Avg policy loss": 0.22673830552957952, "Total num played games": 68368, "Total num trained steps": 136192, "Timestamp in ms": 1699957106157, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923852674656533, "Avg loss": 0.417901654727757, "Avg value loss": 0.18885886803036556, "Avg policy loss": 0.22904278768692166, "Total num played games": 68420, "Total num trained steps": 136320, "Timestamp in ms": 1699957162278, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 128.46792462468147, "Avg game time in secs": 0.9867556574026821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 68480, "Total num trained steps": 136426, "Timestamp in ms": 1699957208053, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914764434584622, "Avg loss": 0.6303400797769427, "Avg value loss": 0.3969919934752397, "Avg policy loss": 0.23334808147046715, "Total num played games": 68516, "Total num trained steps": 136448, "Timestamp in ms": 1699957217257, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917602450051042, "Avg loss": 0.47057475603651255, "Avg value loss": 0.23600547801470384, "Avg policy loss": 0.23456927621737123, "Total num played games": 68570, "Total num trained steps": 136576, "Timestamp in ms": 1699957271800, "logtype": "training_step"}
{"Total num played games": 68570, "Total num trained steps": 136604, "Timestamp in ms": 1699957341061, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.546875}
{"Avg objective": 21.3359375, "Games time in secs": 135.06479267962277, "Avg game time in secs": 0.9735833629092667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 68608, "Total num trained steps": 136608, "Timestamp in ms": 1699957343118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922323588562767, "Avg loss": 0.5607300187693909, "Avg value loss": 0.3262793003814295, "Avg policy loss": 0.2344507247908041, "Total num played games": 68618, "Total num trained steps": 136704, "Timestamp in ms": 1699957387441, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991297387761042, "Avg loss": 0.5600446674507111, "Avg value loss": 0.3171425037435256, "Avg policy loss": 0.2429021685384214, "Total num played games": 68715, "Total num trained steps": 136832, "Timestamp in ms": 1699957440948, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 135.76575038954616, "Avg game time in secs": 0.9435182513552718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 68736, "Total num trained steps": 136921, "Timestamp in ms": 1699957478884, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915515486403956, "Avg loss": 0.6671988073503599, "Avg value loss": 0.4096796553058084, "Avg policy loss": 0.2575191503856331, "Total num played games": 68770, "Total num trained steps": 136960, "Timestamp in ms": 1699957495415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992008021040701, "Avg loss": 0.47100915177725255, "Avg value loss": 0.21731452905805781, "Avg policy loss": 0.2536946174222976, "Total num played games": 68819, "Total num trained steps": 137088, "Timestamp in ms": 1699957550161, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 90.63747872412205, "Avg game time in secs": 1.0147116150619695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 68864, "Total num trained steps": 137133, "Timestamp in ms": 1699957569521, "logtype": "played_game"}
{"Total num played games": 68867, "Total num trained steps": 137207, "Timestamp in ms": 1699957661141, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3046875}
{"Ratio train steps to played games": 1.9911048553269293, "Avg loss": 0.5745736011303961, "Avg value loss": 0.3274064748547971, "Avg policy loss": 0.24716712499503046, "Total num played games": 68914, "Total num trained steps": 137216, "Timestamp in ms": 1699957664816, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915461914359873, "Avg loss": 0.5719489777693525, "Avg value loss": 0.3304619429691229, "Avg policy loss": 0.24148703005630523, "Total num played games": 68963, "Total num trained steps": 137344, "Timestamp in ms": 1699957720718, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 181.78120833076537, "Avg game time in secs": 0.9612435963354073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.43, "agent_stopped_0": 0.62}, "Total num played games": 68992, "Total num trained steps": 137417, "Timestamp in ms": 1699957751303, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920157656025852, "Avg loss": 0.5718318794388324, "Avg value loss": 0.32203792058862746, "Avg policy loss": 0.24979395512491465, "Total num played games": 69011, "Total num trained steps": 137472, "Timestamp in ms": 1699957774670, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923115905306594, "Avg loss": 0.6483214370673522, "Avg value loss": 0.4024161810229998, "Avg policy loss": 0.2459052555495873, "Total num played games": 69065, "Total num trained steps": 137600, "Timestamp in ms": 1699957829389, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 88.74215430021286, "Avg game time in secs": 1.06751604587771, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 69120, "Total num trained steps": 137627, "Timestamp in ms": 1699957840045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925204710511848, "Avg loss": 0.5721576765645295, "Avg value loss": 0.3169964351109229, "Avg policy loss": 0.2551612430252135, "Total num played games": 69122, "Total num trained steps": 137728, "Timestamp in ms": 1699957880133, "logtype": "training_step"}
{"Total num played games": 69170, "Total num trained steps": 137811, "Timestamp in ms": 1699957978776, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.39453125}
{"Ratio train steps to played games": 1.991620676702592, "Avg loss": 0.761359938653186, "Avg value loss": 0.5152844748226926, "Avg policy loss": 0.24607546895276755, "Total num played games": 69218, "Total num trained steps": 137856, "Timestamp in ms": 1699957996550, "logtype": "training_step"}
{"Avg objective": 22.9296875, "Games time in secs": 184.97166299074888, "Avg game time in secs": 0.968084500200348, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 69248, "Total num trained steps": 137927, "Timestamp in ms": 1699958025017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920452740843404, "Avg loss": 0.49776146828662604, "Avg value loss": 0.25202526670182124, "Avg policy loss": 0.24573619500733912, "Total num played games": 69267, "Total num trained steps": 137984, "Timestamp in ms": 1699958047324, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992512443194114, "Avg loss": 0.4450466923881322, "Avg value loss": 0.1990923652483616, "Avg policy loss": 0.24595432926435024, "Total num played games": 69315, "Total num trained steps": 138112, "Timestamp in ms": 1699958099172, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 116.64368582703173, "Avg game time in secs": 0.9175032701605232, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 69376, "Total num trained steps": 138216, "Timestamp in ms": 1699958141661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914286125876945, "Avg loss": 0.7421915433369577, "Avg value loss": 0.4914296284550801, "Avg policy loss": 0.250761907431297, "Total num played games": 69417, "Total num trained steps": 138240, "Timestamp in ms": 1699958150310, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918951990210898, "Avg loss": 0.5462435698136687, "Avg value loss": 0.2749852212728001, "Avg policy loss": 0.2712583470856771, "Total num played games": 69465, "Total num trained steps": 138368, "Timestamp in ms": 1699958202449, "logtype": "training_step"}
{"Total num played games": 69465, "Total num trained steps": 138413, "Timestamp in ms": 1699958280079, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1953125}
{"Avg objective": 21.6640625, "Games time in secs": 141.02861847542226, "Avg game time in secs": 1.0296088365430478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 69504, "Total num trained steps": 138419, "Timestamp in ms": 1699958282689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923611410815243, "Avg loss": 0.43074512714520097, "Avg value loss": 0.17673901174566709, "Avg policy loss": 0.2540061154868454, "Total num played games": 69513, "Total num trained steps": 138496, "Timestamp in ms": 1699958315124, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912234080756137, "Avg loss": 0.6644795662723482, "Avg value loss": 0.4200041192525532, "Avg policy loss": 0.24447544722352177, "Total num played games": 69617, "Total num trained steps": 138624, "Timestamp in ms": 1699958366343, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 123.69513629376888, "Avg game time in secs": 1.0238961333525367, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 69632, "Total num trained steps": 138724, "Timestamp in ms": 1699958406385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916745614790572, "Avg loss": 0.5736885461956263, "Avg value loss": 0.3149960064329207, "Avg policy loss": 0.2586925339419395, "Total num played games": 69666, "Total num trained steps": 138752, "Timestamp in ms": 1699958417034, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921249677252775, "Avg loss": 0.5223085338948295, "Avg value loss": 0.26847022035508417, "Avg policy loss": 0.2538383163046092, "Total num played games": 69714, "Total num trained steps": 138880, "Timestamp in ms": 1699958466944, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 77.24577853828669, "Avg game time in secs": 1.0124919093213975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 69760, "Total num trained steps": 138921, "Timestamp in ms": 1699958483631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926034230669993, "Avg loss": 0.5117356340633705, "Avg value loss": 0.2498735273256898, "Avg policy loss": 0.26186210266314447, "Total num played games": 69762, "Total num trained steps": 139008, "Timestamp in ms": 1699958518278, "logtype": "training_step"}
{"Total num played games": 69762, "Total num trained steps": 139012, "Timestamp in ms": 1699958573201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2734375}
{"Ratio train steps to played games": 1.991640423704552, "Avg loss": 0.5465857018716633, "Avg value loss": 0.29445963047328405, "Avg policy loss": 0.25212606601417065, "Total num played games": 69860, "Total num trained steps": 139136, "Timestamp in ms": 1699958622671, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 169.21195005252957, "Avg game time in secs": 0.9300038205547025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 69888, "Total num trained steps": 139211, "Timestamp in ms": 1699958652843, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992004119523394, "Avg loss": 0.5464660979341716, "Avg value loss": 0.29834865126758814, "Avg policy loss": 0.24811744777252898, "Total num played games": 69911, "Total num trained steps": 139264, "Timestamp in ms": 1699958674602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924670163953173, "Avg loss": 0.5353809451917186, "Avg value loss": 0.28162369097117335, "Avg policy loss": 0.25375724968034774, "Total num played games": 69959, "Total num trained steps": 139392, "Timestamp in ms": 1699958725834, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 120.94500493817031, "Avg game time in secs": 1.021386611755588, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 70016, "Total num trained steps": 139506, "Timestamp in ms": 1699958773788, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991549617448898, "Avg loss": 0.6445882555563003, "Avg value loss": 0.3938071287702769, "Avg policy loss": 0.2507811163086444, "Total num played games": 70056, "Total num trained steps": 139520, "Timestamp in ms": 1699958779424, "logtype": "training_step"}
{"Total num played games": 70105, "Total num trained steps": 139614, "Timestamp in ms": 1699958872399, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.32421875}
{"Avg objective": 22.609375, "Games time in secs": 100.86870907060802, "Avg game time in secs": 0.9487954555806937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 70144, "Total num trained steps": 139619, "Timestamp in ms": 1699958874657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906062463472696, "Avg loss": 0.9587103091180325, "Avg value loss": 0.6835388258914463, "Avg policy loss": 0.27517147292383015, "Total num played games": 70153, "Total num trained steps": 139648, "Timestamp in ms": 1699958885844, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99244508431571, "Avg loss": 0.49203687091358006, "Avg value loss": 0.21332726045511663, "Avg policy loss": 0.27870961430016905, "Total num played games": 70153, "Total num trained steps": 139776, "Timestamp in ms": 1699958937886, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915017793594305, "Avg loss": 0.5900405393913388, "Avg value loss": 0.33239991788286716, "Avg policy loss": 0.2576406222069636, "Total num played games": 70250, "Total num trained steps": 139904, "Timestamp in ms": 1699958990779, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 151.36269950307906, "Avg game time in secs": 0.9982466281944653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 70272, "Total num trained steps": 139990, "Timestamp in ms": 1699959026020, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991977012148283, "Avg loss": 0.547482785070315, "Avg value loss": 0.27735886396840215, "Avg policy loss": 0.2701239224988967, "Total num played games": 70298, "Total num trained steps": 140032, "Timestamp in ms": 1699959042475, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924231654962614, "Avg loss": 0.6043600313132629, "Avg value loss": 0.33430189502541907, "Avg policy loss": 0.2700581431854516, "Total num played games": 70346, "Total num trained steps": 140160, "Timestamp in ms": 1699959093734, "logtype": "training_step"}
{"Total num played games": 70397, "Total num trained steps": 140216, "Timestamp in ms": 1699959168749, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.171875}
{"Avg objective": 21.5078125, "Games time in secs": 143.66520468704402, "Avg game time in secs": 1.0573220521764597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 70400, "Total num trained steps": 140217, "Timestamp in ms": 1699959169685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914401305983391, "Avg loss": 0.7399056123103946, "Avg value loss": 0.4509780019870959, "Avg policy loss": 0.28892761294264346, "Total num played games": 70445, "Total num trained steps": 140288, "Timestamp in ms": 1699959197572, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918999049551018, "Avg loss": 0.4566234032390639, "Avg value loss": 0.19323772907955572, "Avg policy loss": 0.26338567037601024, "Total num played games": 70493, "Total num trained steps": 140416, "Timestamp in ms": 1699959250608, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 105.79270375333726, "Avg game time in secs": 0.9538414404960349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 70528, "Total num trained steps": 140478, "Timestamp in ms": 1699959275478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923308100138923, "Avg loss": 0.5208754744380713, "Avg value loss": 0.2603521258861292, "Avg policy loss": 0.2605233497451991, "Total num played games": 70542, "Total num trained steps": 140544, "Timestamp in ms": 1699959301010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918299728137743, "Avg loss": 0.49948366009630263, "Avg value loss": 0.24658376569277607, "Avg policy loss": 0.2528998957714066, "Total num played games": 70623, "Total num trained steps": 140672, "Timestamp in ms": 1699959351733, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 116.20118854939938, "Avg game time in secs": 1.0571162827691296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 70656, "Total num trained steps": 140775, "Timestamp in ms": 1699959391680, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916824624437717, "Avg loss": 0.7011741169262677, "Avg value loss": 0.4466836288047489, "Avg policy loss": 0.2544904893729836, "Total num played games": 70694, "Total num trained steps": 140800, "Timestamp in ms": 1699959401072, "logtype": "training_step"}
{"Total num played games": 70694, "Total num trained steps": 140818, "Timestamp in ms": 1699959427489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.203125}
{"Ratio train steps to played games": 1.9921263181702524, "Avg loss": 0.5155511018820107, "Avg value loss": 0.2567828164319508, "Avg policy loss": 0.25876828737091273, "Total num played games": 70742, "Total num trained steps": 140928, "Timestamp in ms": 1699959472769, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 100.76935187727213, "Avg game time in secs": 0.9434501926007215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 70784, "Total num trained steps": 140976, "Timestamp in ms": 1699959492449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925696769363337, "Avg loss": 0.5850337643641979, "Avg value loss": 0.33251273914356716, "Avg policy loss": 0.25252102757804096, "Total num played games": 70791, "Total num trained steps": 141056, "Timestamp in ms": 1699959525090, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927451340174174, "Avg loss": 0.5460119242779911, "Avg value loss": 0.2886474816186819, "Avg policy loss": 0.25736444094218314, "Total num played games": 70849, "Total num trained steps": 141184, "Timestamp in ms": 1699959575702, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 130.7075794097036, "Avg game time in secs": 1.021769834391307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 70912, "Total num trained steps": 141306, "Timestamp in ms": 1699959623157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916141671247163, "Avg loss": 0.7330079219536856, "Avg value loss": 0.4783173520700075, "Avg policy loss": 0.25469056877773255, "Total num played games": 70953, "Total num trained steps": 141312, "Timestamp in ms": 1699959625593, "logtype": "training_step"}
{"Total num played games": 71004, "Total num trained steps": 141422, "Timestamp in ms": 1699959689610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8125}
{"Avg objective": 22.125, "Games time in secs": 68.81574824824929, "Avg game time in secs": 0.9919598754640901, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 71040, "Total num trained steps": 141428, "Timestamp in ms": 1699959691973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906406575465856, "Avg loss": 0.7040537758730352, "Avg value loss": 0.42702204835950397, "Avg policy loss": 0.2770317327231169, "Total num played games": 71052, "Total num trained steps": 141440, "Timestamp in ms": 1699959696758, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924421550413782, "Avg loss": 0.3892316168639809, "Avg value loss": 0.12045808811672032, "Avg policy loss": 0.26877353014424443, "Total num played games": 71052, "Total num trained steps": 141568, "Timestamp in ms": 1699959749796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915248281774867, "Avg loss": 0.5997269528452307, "Avg value loss": 0.34223236885736696, "Avg policy loss": 0.25749457627534866, "Total num played games": 71149, "Total num trained steps": 141696, "Timestamp in ms": 1699959800697, "logtype": "training_step"}
{"Avg objective": 22.2734375, "Games time in secs": 146.21194344386458, "Avg game time in secs": 1.1393055507796817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 71168, "Total num trained steps": 141791, "Timestamp in ms": 1699959838185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918401168506503, "Avg loss": 0.7385007182601839, "Avg value loss": 0.4644039018894546, "Avg policy loss": 0.27409680921118706, "Total num played games": 71202, "Total num trained steps": 141824, "Timestamp in ms": 1699959850738, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923087719298245, "Avg loss": 0.8001568110194057, "Avg value loss": 0.5275107309571467, "Avg policy loss": 0.2726460782578215, "Total num played games": 71250, "Total num trained steps": 141952, "Timestamp in ms": 1699959901666, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 80.33529320731759, "Avg game time in secs": 0.9999424397828989, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 71296, "Total num trained steps": 141993, "Timestamp in ms": 1699959918520, "logtype": "played_game"}
{"Total num played games": 71298, "Total num trained steps": 142025, "Timestamp in ms": 1699959949459, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.02734375}
{"Ratio train steps to played games": 1.991422083929022, "Avg loss": 0.8045186859089881, "Avg value loss": 0.5328495080466382, "Avg policy loss": 0.2716691680252552, "Total num played games": 71346, "Total num trained steps": 142080, "Timestamp in ms": 1699959971392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918760680169203, "Avg loss": 0.5627886913716793, "Avg value loss": 0.2957769629138056, "Avg policy loss": 0.26701172173488885, "Total num played games": 71394, "Total num trained steps": 142208, "Timestamp in ms": 1699960022538, "logtype": "training_step"}
{"Avg objective": 22.6328125, "Games time in secs": 132.31249603256583, "Avg game time in secs": 0.9446414514968637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.44, "agent_stopped_0": 0.57}, "Total num played games": 71424, "Total num trained steps": 142279, "Timestamp in ms": 1699960050833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922875579133015, "Avg loss": 0.8287041757721454, "Avg value loss": 0.5492278302554041, "Avg policy loss": 0.27947634120937437, "Total num played games": 71443, "Total num trained steps": 142336, "Timestamp in ms": 1699960073088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927403449385237, "Avg loss": 0.5239589549601078, "Avg value loss": 0.25348970014601946, "Avg policy loss": 0.27046925493050367, "Total num played games": 71491, "Total num trained steps": 142464, "Timestamp in ms": 1699960123280, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 115.33963170275092, "Avg game time in secs": 0.9979111920110881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 71552, "Total num trained steps": 142570, "Timestamp in ms": 1699960166173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918004162650687, "Avg loss": 0.7955047704745084, "Avg value loss": 0.5212600980885327, "Avg policy loss": 0.27424467622768134, "Total num played games": 71589, "Total num trained steps": 142592, "Timestamp in ms": 1699960175261, "logtype": "training_step"}
{"Total num played games": 71589, "Total num trained steps": 142626, "Timestamp in ms": 1699960244170, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.53125}
{"Ratio train steps to played games": 1.9922665661599452, "Avg loss": 0.5734005437698215, "Avg value loss": 0.2896723058074713, "Avg policy loss": 0.28372823959216475, "Total num played games": 71637, "Total num trained steps": 142720, "Timestamp in ms": 1699960281854, "logtype": "training_step"}
{"Avg objective": 22.71875, "Games time in secs": 133.8205797560513, "Avg game time in secs": 1.0277918721403694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 71680, "Total num trained steps": 142767, "Timestamp in ms": 1699960299993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927041919508963, "Avg loss": 0.5731909312307835, "Avg value loss": 0.30252174599445425, "Avg policy loss": 0.2706691938219592, "Total num played games": 71685, "Total num trained steps": 142848, "Timestamp in ms": 1699960331837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917807837510273, "Avg loss": 0.6714015598408878, "Avg value loss": 0.4057769295759499, "Avg policy loss": 0.26562463538721204, "Total num played games": 71783, "Total num trained steps": 142976, "Timestamp in ms": 1699960381387, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 114.56324049830437, "Avg game time in secs": 1.006183943070937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 71808, "Total num trained steps": 143057, "Timestamp in ms": 1699960414557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920653702131215, "Avg loss": 0.5701201052870601, "Avg value loss": 0.29534861171850935, "Avg policy loss": 0.27477149351034313, "Total num played games": 71837, "Total num trained steps": 143104, "Timestamp in ms": 1699960433197, "logtype": "training_step"}
{"Total num played games": 71886, "Total num trained steps": 143229, "Timestamp in ms": 1699960547263, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2265625}
{"Ratio train steps to played games": 1.9912000222432298, "Avg loss": 0.594012500718236, "Avg value loss": 0.3223433930252213, "Avg policy loss": 0.27166910318192095, "Total num played games": 71932, "Total num trained steps": 143232, "Timestamp in ms": 1699960549957, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 184.78415698371828, "Avg game time in secs": 1.0265020397782791, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 71936, "Total num trained steps": 143358, "Timestamp in ms": 1699960599344, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991747363741195, "Avg loss": 0.6196556601207703, "Avg value loss": 0.3483269173593726, "Avg policy loss": 0.2713287326041609, "Total num played games": 71977, "Total num trained steps": 143360, "Timestamp in ms": 1699960600192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920173258735823, "Avg loss": 0.7385256504639983, "Avg value loss": 0.4734775206889026, "Avg policy loss": 0.2650481222663075, "Total num played games": 72031, "Total num trained steps": 143488, "Timestamp in ms": 1699960651038, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 77.98520549573004, "Avg game time in secs": 0.8453811571089318, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.4}, "Total num played games": 72064, "Total num trained steps": 143553, "Timestamp in ms": 1699960677329, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992466599148157, "Avg loss": 0.5848376743961126, "Avg value loss": 0.30988567922031507, "Avg policy loss": 0.2749519976787269, "Total num played games": 72079, "Total num trained steps": 143616, "Timestamp in ms": 1699960702225, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928047580097323, "Avg loss": 0.5356319367419928, "Avg value loss": 0.2623725014855154, "Avg policy loss": 0.27325943391770124, "Total num played games": 72131, "Total num trained steps": 143744, "Timestamp in ms": 1699960752554, "logtype": "training_step"}
{"Total num played games": 72179, "Total num trained steps": 143829, "Timestamp in ms": 1699960843923, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.03515625}
{"Avg objective": 22.296875, "Games time in secs": 167.98772456496954, "Avg game time in secs": 0.9571086304495111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 72192, "Total num trained steps": 143832, "Timestamp in ms": 1699960845317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991942071524499, "Avg loss": 0.9538743901066482, "Avg value loss": 0.6850383635610342, "Avg policy loss": 0.26883603213354945, "Total num played games": 72227, "Total num trained steps": 143872, "Timestamp in ms": 1699960860980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923763403666552, "Avg loss": 0.5540317369159311, "Avg value loss": 0.2763641325873323, "Avg policy loss": 0.27766759670339525, "Total num played games": 72275, "Total num trained steps": 144000, "Timestamp in ms": 1699960912627, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 84.68509392812848, "Avg game time in secs": 1.004844084061915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 72320, "Total num trained steps": 144043, "Timestamp in ms": 1699960930002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928101321829546, "Avg loss": 0.4759850720874965, "Avg value loss": 0.20360511564649642, "Avg policy loss": 0.27237995620816946, "Total num played games": 72324, "Total num trained steps": 144128, "Timestamp in ms": 1699960967542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919221209610605, "Avg loss": 0.6686092424206436, "Avg value loss": 0.38575712725287303, "Avg policy loss": 0.2828521105693653, "Total num played games": 72420, "Total num trained steps": 144256, "Timestamp in ms": 1699961025256, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 124.53481365740299, "Avg game time in secs": 0.9075585101963952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 72448, "Total num trained steps": 144331, "Timestamp in ms": 1699961054538, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923828448418612, "Avg loss": 0.5223103614989668, "Avg value loss": 0.24588831944856793, "Avg policy loss": 0.2764220426324755, "Total num played games": 72468, "Total num trained steps": 144384, "Timestamp in ms": 1699961075969, "logtype": "training_step"}
{"Total num played games": 72524, "Total num trained steps": 144430, "Timestamp in ms": 1699961142751, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2421875}
{"Ratio train steps to played games": 1.9912914071542744, "Avg loss": 1.0086900091264397, "Avg value loss": 0.7184541535971221, "Avg policy loss": 0.29023584304377437, "Total num played games": 72572, "Total num trained steps": 144512, "Timestamp in ms": 1699961176978, "logtype": "training_step"}
{"Avg objective": 22.0859375, "Games time in secs": 170.99606812372804, "Avg game time in secs": 1.1562023087171838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 72576, "Total num trained steps": 144633, "Timestamp in ms": 1699961225534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917103868027155, "Avg loss": 0.3976899798726663, "Avg value loss": 0.13296213545254432, "Avg policy loss": 0.26472784765064716, "Total num played games": 72621, "Total num trained steps": 144640, "Timestamp in ms": 1699961228160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921424541413808, "Avg loss": 0.7272018478251994, "Avg value loss": 0.4623572959098965, "Avg policy loss": 0.26484454970341176, "Total num played games": 72669, "Total num trained steps": 144768, "Timestamp in ms": 1699961278684, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 77.79795723222196, "Avg game time in secs": 0.9767022251762683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 72704, "Total num trained steps": 144830, "Timestamp in ms": 1699961303332, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925877030130505, "Avg loss": 0.5457555609755218, "Avg value loss": 0.28579766128677875, "Avg policy loss": 0.2599579015513882, "Total num played games": 72717, "Total num trained steps": 144896, "Timestamp in ms": 1699961330373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991814311220986, "Avg loss": 0.518599352799356, "Avg value loss": 0.2643394650367554, "Avg policy loss": 0.25425988528877497, "Total num played games": 72809, "Total num trained steps": 145024, "Timestamp in ms": 1699961381395, "logtype": "training_step"}
{"Total num played games": 72813, "Total num trained steps": 145031, "Timestamp in ms": 1699961450213, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.02734375}
{"Avg objective": 21.828125, "Games time in secs": 148.26209416240454, "Avg game time in secs": 0.9857655705854995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 72832, "Total num trained steps": 145034, "Timestamp in ms": 1699961451594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921768847531602, "Avg loss": 0.5368250705068931, "Avg value loss": 0.2835170528560411, "Avg policy loss": 0.25330801284871995, "Total num played games": 72861, "Total num trained steps": 145152, "Timestamp in ms": 1699961496968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924569704450388, "Avg loss": 0.5592243252322078, "Avg value loss": 0.31565729569410905, "Avg policy loss": 0.24356702924706042, "Total num played games": 72915, "Total num trained steps": 145280, "Timestamp in ms": 1699961547308, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 112.8643024917692, "Avg game time in secs": 1.009479394851951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 72960, "Total num trained steps": 145324, "Timestamp in ms": 1699961564459, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928185730340158, "Avg loss": 0.5040571165736765, "Avg value loss": 0.2671103104366921, "Avg policy loss": 0.2369468043325469, "Total num played games": 72966, "Total num trained steps": 145408, "Timestamp in ms": 1699961598042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918157307676516, "Avg loss": 0.7239931719377637, "Avg value loss": 0.4729300402686931, "Avg policy loss": 0.2510631348704919, "Total num played games": 73067, "Total num trained steps": 145536, "Timestamp in ms": 1699961648462, "logtype": "training_step"}
{"Avg objective": 22.2421875, "Games time in secs": 118.61571658588946, "Avg game time in secs": 1.0520639797468903, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.51, "agent_stopped_0": 0.57}, "Total num played games": 73088, "Total num trained steps": 145624, "Timestamp in ms": 1699961683074, "logtype": "played_game"}
{"Total num played games": 73116, "Total num trained steps": 145636, "Timestamp in ms": 1699961751921, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6953125}
{"Ratio train steps to played games": 1.9909108304630692, "Avg loss": 0.7708152420818806, "Avg value loss": 0.5148106947890483, "Avg policy loss": 0.2560045482823625, "Total num played games": 73164, "Total num trained steps": 145664, "Timestamp in ms": 1699961762821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992660324749877, "Avg loss": 0.37011604756116867, "Avg value loss": 0.13278856640681624, "Avg policy loss": 0.23732748278416693, "Total num played games": 73164, "Total num trained steps": 145792, "Timestamp in ms": 1699961812814, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 178.71614939533174, "Avg game time in secs": 1.0854659172764514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 73216, "Total num trained steps": 145914, "Timestamp in ms": 1699961861791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918507193753583, "Avg loss": 0.5080899676540866, "Avg value loss": 0.2854707346414216, "Avg policy loss": 0.22261922631878406, "Total num played games": 73258, "Total num trained steps": 145920, "Timestamp in ms": 1699961863974, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922110518490226, "Avg loss": 0.5559878497151658, "Avg value loss": 0.3312022983736824, "Avg policy loss": 0.22478555038105696, "Total num played games": 73309, "Total num trained steps": 146048, "Timestamp in ms": 1699961915595, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 77.67670200392604, "Avg game time in secs": 0.9131018813641276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 73344, "Total num trained steps": 146109, "Timestamp in ms": 1699961939468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925573533621406, "Avg loss": 0.5009527852525935, "Avg value loss": 0.2776626621489413, "Avg policy loss": 0.22329012618865818, "Total num played games": 73361, "Total num trained steps": 146176, "Timestamp in ms": 1699961965656, "logtype": "training_step"}
{"Total num played games": 73414, "Total num trained steps": 146238, "Timestamp in ms": 1699962040993, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.484375}
{"Ratio train steps to played games": 1.9915466499686914, "Avg loss": 0.7253543599508703, "Avg value loss": 0.49038796516833827, "Avg policy loss": 0.23496640229132026, "Total num played games": 73462, "Total num trained steps": 146304, "Timestamp in ms": 1699962068746, "logtype": "training_step"}
{"Avg objective": 23.21875, "Games time in secs": 174.05710324272513, "Avg game time in secs": 0.9838607076380868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 73472, "Total num trained steps": 146414, "Timestamp in ms": 1699962113525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919874846959598, "Avg loss": 0.4673785459017381, "Avg value loss": 0.24254460906377062, "Avg policy loss": 0.2248339308425784, "Total num played games": 73510, "Total num trained steps": 146432, "Timestamp in ms": 1699962120757, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922923208678276, "Avg loss": 0.5429141976637766, "Avg value loss": 0.30837303906446323, "Avg policy loss": 0.23454116459470242, "Total num played games": 73563, "Total num trained steps": 146560, "Timestamp in ms": 1699962171265, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 81.22268938273191, "Avg game time in secs": 0.9564319132769015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 73600, "Total num trained steps": 146618, "Timestamp in ms": 1699962194748, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927456494273954, "Avg loss": 0.5236590694403276, "Avg value loss": 0.2978384740417823, "Avg policy loss": 0.22582059598062187, "Total num played games": 73611, "Total num trained steps": 146688, "Timestamp in ms": 1699962221835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918462039398708, "Avg loss": 0.5605791711714119, "Avg value loss": 0.3254132923902944, "Avg policy loss": 0.23516586888581514, "Total num played games": 73708, "Total num trained steps": 146816, "Timestamp in ms": 1699962273439, "logtype": "training_step"}
{"Total num played games": 73708, "Total num trained steps": 146842, "Timestamp in ms": 1699962369265, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.53515625}
{"Avg objective": 22.1796875, "Games time in secs": 176.10555273480713, "Avg game time in secs": 0.9313406936416868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 73728, "Total num trained steps": 146843, "Timestamp in ms": 1699962370853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992285373393351, "Avg loss": 0.595393365714699, "Avg value loss": 0.3517609137343243, "Avg policy loss": 0.24363245104905218, "Total num played games": 73756, "Total num trained steps": 146944, "Timestamp in ms": 1699962412376, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927375210015716, "Avg loss": 0.658619545516558, "Avg value loss": 0.42634388330043294, "Avg policy loss": 0.23227564711123705, "Total num played games": 73804, "Total num trained steps": 147072, "Timestamp in ms": 1699962463844, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 141.67215038649738, "Avg game time in secs": 1.037785764056025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 73856, "Total num trained steps": 147198, "Timestamp in ms": 1699962512526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921639215580127, "Avg loss": 0.46929168491624296, "Avg value loss": 0.23813530831830576, "Avg policy loss": 0.23115637828595936, "Total num played games": 73889, "Total num trained steps": 147200, "Timestamp in ms": 1699962513162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919821525148729, "Avg loss": 0.5660736885620281, "Avg value loss": 0.3457852503634058, "Avg policy loss": 0.22028842684812844, "Total num played games": 73960, "Total num trained steps": 147328, "Timestamp in ms": 1699962564200, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 85.88328569382429, "Avg game time in secs": 0.9664139316009823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.45}, "Total num played games": 73984, "Total num trained steps": 147411, "Timestamp in ms": 1699962598409, "logtype": "played_game"}
{"Total num played games": 74009, "Total num trained steps": 147443, "Timestamp in ms": 1699962643552, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7265625}
{"Ratio train steps to played games": 1.9911014488839678, "Avg loss": 0.6020978213055059, "Avg value loss": 0.3714066279644612, "Avg policy loss": 0.230691195349209, "Total num played games": 74057, "Total num trained steps": 147456, "Timestamp in ms": 1699962649043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992829847279798, "Avg loss": 0.3824074234580621, "Avg value loss": 0.14907461489201523, "Avg policy loss": 0.23333281080704182, "Total num played games": 74057, "Total num trained steps": 147584, "Timestamp in ms": 1699962701014, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 153.7861385755241, "Avg game time in secs": 1.1052793588023633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 74112, "Total num trained steps": 147711, "Timestamp in ms": 1699962752195, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993037752651321, "Avg loss": 0.4507339915726334, "Avg value loss": 0.22473612331668846, "Avg policy loss": 0.22599786904174834, "Total num played games": 74113, "Total num trained steps": 147712, "Timestamp in ms": 1699962752300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922111873222925, "Avg loss": 0.5176017053890973, "Avg value loss": 0.2964716628775932, "Avg policy loss": 0.2211300462950021, "Total num played games": 74209, "Total num trained steps": 147840, "Timestamp in ms": 1699962802079, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 77.6882027760148, "Avg game time in secs": 0.9605533357680542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 74240, "Total num trained steps": 147909, "Timestamp in ms": 1699962829884, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992633691099829, "Avg loss": 0.38884629285894334, "Avg value loss": 0.1549172418890521, "Avg policy loss": 0.23392905294895172, "Total num played games": 74257, "Total num trained steps": 147968, "Timestamp in ms": 1699962854195, "logtype": "training_step"}
{"Total num played games": 74305, "Total num trained steps": 148046, "Timestamp in ms": 1699962940089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.23828125}
{"Ratio train steps to played games": 1.9917958925665407, "Avg loss": 1.0201325006783009, "Avg value loss": 0.7769351760507561, "Avg policy loss": 0.24319731071591377, "Total num played games": 74353, "Total num trained steps": 148096, "Timestamp in ms": 1699962959942, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 169.23884390480816, "Avg game time in secs": 1.0497977032791823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.55, "agent_stopped_0": 0.54}, "Total num played games": 74368, "Total num trained steps": 148196, "Timestamp in ms": 1699962999123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921642944504925, "Avg loss": 0.5256366482935846, "Avg value loss": 0.2888260901090689, "Avg policy loss": 0.23681055777706206, "Total num played games": 74403, "Total num trained steps": 148224, "Timestamp in ms": 1699963010160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925858271100843, "Avg loss": 0.5583803646732122, "Avg value loss": 0.31091815684339963, "Avg policy loss": 0.24746219743974507, "Total num played games": 74452, "Total num trained steps": 148352, "Timestamp in ms": 1699963061558, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 81.00760711915791, "Avg game time in secs": 0.9660996581660584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 74496, "Total num trained steps": 148397, "Timestamp in ms": 1699963080130, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928596354656, "Avg loss": 0.5116442082216963, "Avg value loss": 0.2649504358123522, "Avg policy loss": 0.24669377354439348, "Total num played games": 74506, "Total num trained steps": 148480, "Timestamp in ms": 1699963111970, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917839431711566, "Avg loss": 0.5116585931973532, "Avg value loss": 0.2666474496945739, "Avg policy loss": 0.24501114222221076, "Total num played games": 74610, "Total num trained steps": 148608, "Timestamp in ms": 1699963160894, "logtype": "training_step"}
{"Total num played games": 74610, "Total num trained steps": 148650, "Timestamp in ms": 1699963234385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1328125}
{"Avg objective": 21.296875, "Games time in secs": 155.59893853217363, "Avg game time in secs": 1.0422783100948436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 74624, "Total num trained steps": 148652, "Timestamp in ms": 1699963235730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922312411262022, "Avg loss": 0.6559516515117139, "Avg value loss": 0.4002172877662815, "Avg policy loss": 0.25573435763362795, "Total num played games": 74658, "Total num trained steps": 148736, "Timestamp in ms": 1699963269972, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925711761635145, "Avg loss": 0.507036043331027, "Avg value loss": 0.2668126988282893, "Avg policy loss": 0.24022334453184158, "Total num played games": 74709, "Total num trained steps": 148864, "Timestamp in ms": 1699963320936, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 102.82751484028995, "Avg game time in secs": 0.9788943285384448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 74752, "Total num trained steps": 148911, "Timestamp in ms": 1699963338557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992790744332241, "Avg loss": 0.46382428507786244, "Avg value loss": 0.21266522334190086, "Avg policy loss": 0.2511590579524636, "Total num played games": 74765, "Total num trained steps": 148992, "Timestamp in ms": 1699963370046, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923442802554578, "Avg loss": 0.4669422092847526, "Avg value loss": 0.2126254008617252, "Avg policy loss": 0.2543168101692572, "Total num played games": 74846, "Total num trained steps": 149120, "Timestamp in ms": 1699963420616, "logtype": "training_step"}
{"Avg objective": 19.953125, "Games time in secs": 124.94412582367659, "Avg game time in secs": 1.029906454772572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.6, "agent_stopped_0": 0.5}, "Total num played games": 74880, "Total num trained steps": 149228, "Timestamp in ms": 1699963463501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921380709575802, "Avg loss": 0.7488185592228547, "Avg value loss": 0.4928090179164428, "Avg policy loss": 0.2560095431981608, "Total num played games": 74918, "Total num trained steps": 149248, "Timestamp in ms": 1699963471620, "logtype": "training_step"}
{"Total num played games": 74918, "Total num trained steps": 149250, "Timestamp in ms": 1699963530542, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.23046875}
{"Ratio train steps to played games": 1.992569965050823, "Avg loss": 0.7776556101161987, "Avg value loss": 0.5025486323283985, "Avg policy loss": 0.2751069881487638, "Total num played games": 74966, "Total num trained steps": 149376, "Timestamp in ms": 1699963582152, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 138.29412149637938, "Avg game time in secs": 0.9885958601080347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 75008, "Total num trained steps": 149424, "Timestamp in ms": 1699963601796, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928950385240876, "Avg loss": 0.5373979213181883, "Avg value loss": 0.2900147732871119, "Avg policy loss": 0.24738314596470445, "Total num played games": 75018, "Total num trained steps": 149504, "Timestamp in ms": 1699963633551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992038873726952, "Avg loss": 0.5146069441689178, "Avg value loss": 0.26098873556475155, "Avg policy loss": 0.2536182105541229, "Total num played games": 75115, "Total num trained steps": 149632, "Timestamp in ms": 1699963684331, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 117.94158074446023, "Avg game time in secs": 0.9847478208102984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 75136, "Total num trained steps": 149722, "Timestamp in ms": 1699963719737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924298866478634, "Avg loss": 0.5481771857012063, "Avg value loss": 0.2948001607437618, "Avg policy loss": 0.25337702652905136, "Total num played games": 75164, "Total num trained steps": 149760, "Timestamp in ms": 1699963734131, "logtype": "training_step"}
{"Total num played games": 75213, "Total num trained steps": 149853, "Timestamp in ms": 1699963837593, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9765625}
{"Ratio train steps to played games": 1.991575982248442, "Avg loss": 0.5747778861550614, "Avg value loss": 0.3122391818615142, "Avg policy loss": 0.2625387031584978, "Total num played games": 75261, "Total num trained steps": 149888, "Timestamp in ms": 1699963851892, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 180.61163334921002, "Avg game time in secs": 1.0534704119490925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 75264, "Total num trained steps": 150012, "Timestamp in ms": 1699963900349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992178162598603, "Avg loss": 0.36074094276409596, "Avg value loss": 0.1052655617822893, "Avg policy loss": 0.2554753803415224, "Total num played games": 75302, "Total num trained steps": 150016, "Timestamp in ms": 1699963901648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923962950184453, "Avg loss": 0.7126337082590908, "Avg value loss": 0.4453850756690372, "Avg policy loss": 0.26724861946422607, "Total num played games": 75358, "Total num trained steps": 150144, "Timestamp in ms": 1699963951112, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 77.30811742320657, "Avg game time in secs": 1.0243152164621279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 75392, "Total num trained steps": 150207, "Timestamp in ms": 1699963977657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925876814957237, "Avg loss": 0.47516477131284773, "Avg value loss": 0.20727595148491673, "Avg policy loss": 0.2678888209629804, "Total num played games": 75415, "Total num trained steps": 150272, "Timestamp in ms": 1699964003609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993016445145303, "Avg loss": 0.46770471753552556, "Avg value loss": 0.213725523208268, "Avg policy loss": 0.2539791971212253, "Total num played games": 75463, "Total num trained steps": 150400, "Timestamp in ms": 1699964054884, "logtype": "training_step"}
{"Total num played games": 75519, "Total num trained steps": 150453, "Timestamp in ms": 1699964100821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.171875}
{"Avg objective": 21.6171875, "Games time in secs": 123.98132872395217, "Avg game time in secs": 1.0769738076633075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 75520, "Total num trained steps": 150454, "Timestamp in ms": 1699964101639, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919673931742692, "Avg loss": 0.6369159938767552, "Avg value loss": 0.3781209518201649, "Avg policy loss": 0.2587950403103605, "Total num played games": 75567, "Total num trained steps": 150528, "Timestamp in ms": 1699964130899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923956886861072, "Avg loss": 0.4320232009049505, "Avg value loss": 0.19054817548021674, "Avg policy loss": 0.24147502495907247, "Total num played games": 75615, "Total num trained steps": 150656, "Timestamp in ms": 1699964181550, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 106.29819801822305, "Avg game time in secs": 0.9250012149714166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 75648, "Total num trained steps": 150722, "Timestamp in ms": 1699964207937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928234407834742, "Avg loss": 0.5541228391230106, "Avg value loss": 0.3019211912760511, "Avg policy loss": 0.2522016461007297, "Total num played games": 75663, "Total num trained steps": 150784, "Timestamp in ms": 1699964232894, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930795847750864, "Avg loss": 0.820861296961084, "Avg value loss": 0.5609100025321823, "Avg policy loss": 0.25995130196679384, "Total num played games": 75718, "Total num trained steps": 150912, "Timestamp in ms": 1699964284810, "logtype": "training_step"}
{"Avg objective": 22.8515625, "Games time in secs": 120.65628797002137, "Avg game time in secs": 0.9743670671596192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 75776, "Total num trained steps": 151024, "Timestamp in ms": 1699964328594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921390698778654, "Avg loss": 0.7128707952797413, "Avg value loss": 0.45548150880495086, "Avg policy loss": 0.25738928467035294, "Total num played games": 75818, "Total num trained steps": 151040, "Timestamp in ms": 1699964334381, "logtype": "training_step"}
{"Total num played games": 75818, "Total num trained steps": 151057, "Timestamp in ms": 1699964380613, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.65234375}
{"Ratio train steps to played games": 1.9925526586349616, "Avg loss": 0.8788539305096492, "Avg value loss": 0.6040126585867256, "Avg policy loss": 0.2748412569053471, "Total num played games": 75866, "Total num trained steps": 151168, "Timestamp in ms": 1699964424561, "logtype": "training_step"}
{"Avg objective": 25.078125, "Games time in secs": 118.6079509370029, "Avg game time in secs": 0.9229066455736756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 75904, "Total num trained steps": 151224, "Timestamp in ms": 1699964447202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927951423189896, "Avg loss": 0.5806565030943602, "Avg value loss": 0.32211499990080483, "Avg policy loss": 0.25854150066152215, "Total num played games": 75921, "Total num trained steps": 151296, "Timestamp in ms": 1699964475941, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993063507732807, "Avg loss": 0.5024898762349039, "Avg value loss": 0.23687056053313427, "Avg policy loss": 0.2656193149741739, "Total num played games": 75975, "Total num trained steps": 151424, "Timestamp in ms": 1699964526791, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 124.42040864750743, "Avg game time in secs": 1.097957552250591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 76032, "Total num trained steps": 151538, "Timestamp in ms": 1699964571622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992204753391524, "Avg loss": 0.5675668285693973, "Avg value loss": 0.29483970810542814, "Avg policy loss": 0.2727271227631718, "Total num played games": 76072, "Total num trained steps": 151552, "Timestamp in ms": 1699964576763, "logtype": "training_step"}
{"Total num played games": 76120, "Total num trained steps": 151660, "Timestamp in ms": 1699964681209, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.515625}
{"Avg objective": 21.640625, "Games time in secs": 111.76801987923682, "Avg game time in secs": 0.9625970372726442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 76160, "Total num trained steps": 151664, "Timestamp in ms": 1699964683391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991374330427476, "Avg loss": 0.5583139164373279, "Avg value loss": 0.2933438856562134, "Avg policy loss": 0.26497003051918, "Total num played games": 76168, "Total num trained steps": 151680, "Timestamp in ms": 1699964689467, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930548261737213, "Avg loss": 0.4006670161616057, "Avg value loss": 0.13662275328533724, "Avg policy loss": 0.2640442638657987, "Total num played games": 76168, "Total num trained steps": 151808, "Timestamp in ms": 1699964741305, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922113682554252, "Avg loss": 0.527546362252906, "Avg value loss": 0.2739329311007168, "Avg policy loss": 0.2536134336842224, "Total num played games": 76265, "Total num trained steps": 151936, "Timestamp in ms": 1699964791923, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 142.7545042168349, "Avg game time in secs": 1.0186753202724503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 76288, "Total num trained steps": 152023, "Timestamp in ms": 1699964826145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925963781219698, "Avg loss": 0.46595500770490617, "Avg value loss": 0.21482066583121195, "Avg policy loss": 0.251134340884164, "Total num played games": 76314, "Total num trained steps": 152064, "Timestamp in ms": 1699964841696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929809858048295, "Avg loss": 0.5658213917631656, "Avg value loss": 0.31681832851609215, "Avg policy loss": 0.24900305969640613, "Total num played games": 76364, "Total num trained steps": 152192, "Timestamp in ms": 1699964891798, "logtype": "training_step"}
{"Total num played games": 76412, "Total num trained steps": 152261, "Timestamp in ms": 1699964977024, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.72265625}
{"Avg objective": 22.5703125, "Games time in secs": 151.92519928514957, "Avg game time in secs": 1.1200505778251681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 76416, "Total num trained steps": 152263, "Timestamp in ms": 1699964978071, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921527596128694, "Avg loss": 0.8342966474592686, "Avg value loss": 0.559509553364478, "Avg policy loss": 0.27478709688875824, "Total num played games": 76460, "Total num trained steps": 152320, "Timestamp in ms": 1699964999769, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925628692424322, "Avg loss": 0.4499990767799318, "Avg value loss": 0.1944215589610394, "Avg policy loss": 0.2555775166256353, "Total num played games": 76508, "Total num trained steps": 152448, "Timestamp in ms": 1699965050193, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 95.5420075301081, "Avg game time in secs": 1.0064641058706911, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 76544, "Total num trained steps": 152508, "Timestamp in ms": 1699965073613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928684317080498, "Avg loss": 0.45502410526387393, "Avg value loss": 0.2023438208270818, "Avg policy loss": 0.25268028560094535, "Total num played games": 76561, "Total num trained steps": 152576, "Timestamp in ms": 1699965099672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930954369844418, "Avg loss": 0.49530939175747335, "Avg value loss": 0.25141765974694863, "Avg policy loss": 0.243891732650809, "Total num played games": 76616, "Total num trained steps": 152704, "Timestamp in ms": 1699965150173, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 122.54121606983244, "Avg game time in secs": 1.0514302722149296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 76672, "Total num trained steps": 152818, "Timestamp in ms": 1699965196154, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922697882990927, "Avg loss": 0.48151351721026003, "Avg value loss": 0.2379955122305546, "Avg policy loss": 0.24351800442673266, "Total num played games": 76712, "Total num trained steps": 152832, "Timestamp in ms": 1699965201388, "logtype": "training_step"}
{"Total num played games": 76713, "Total num trained steps": 152865, "Timestamp in ms": 1699965274380, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.41796875}
{"Ratio train steps to played games": 1.9926785737549015, "Avg loss": 0.6181500230450183, "Avg value loss": 0.35727044456871226, "Avg policy loss": 0.26087958295829594, "Total num played games": 76761, "Total num trained steps": 152960, "Timestamp in ms": 1699965311666, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 136.67986088246107, "Avg game time in secs": 1.0662148926930968, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.61}, "Total num played games": 76800, "Total num trained steps": 153014, "Timestamp in ms": 1699965332834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9930997669543933, "Avg loss": 0.43456231779418886, "Avg value loss": 0.19516803015721962, "Avg policy loss": 0.23939428373705596, "Total num played games": 76809, "Total num trained steps": 153088, "Timestamp in ms": 1699965361736, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992185468351797, "Avg loss": 0.45849803485907614, "Avg value loss": 0.22723081559524871, "Avg policy loss": 0.23126722406595945, "Total num played games": 76908, "Total num trained steps": 153216, "Timestamp in ms": 1699965412509, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 120.05398630909622, "Avg game time in secs": 0.9967658327368554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 76928, "Total num trained steps": 153313, "Timestamp in ms": 1699965452888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925414831273796, "Avg loss": 0.5354440355440602, "Avg value loss": 0.303147825790802, "Avg policy loss": 0.23229621059726924, "Total num played games": 76959, "Total num trained steps": 153344, "Timestamp in ms": 1699965465421, "logtype": "training_step"}
{"Total num played games": 77007, "Total num trained steps": 153468, "Timestamp in ms": 1699965560693, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.01171875}
{"Ratio train steps to played games": 1.9920433010565666, "Avg loss": 0.5636287837987766, "Avg value loss": 0.3257436959538609, "Avg policy loss": 0.23788508668076247, "Total num played games": 77041, "Total num trained steps": 153472, "Timestamp in ms": 1699965562865, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 160.30488374456763, "Avg game time in secs": 1.0780680713796755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.67}, "Total num played games": 77056, "Total num trained steps": 153599, "Timestamp in ms": 1699965613193, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933296131435172, "Avg loss": 0.44235827191732824, "Avg value loss": 0.1973273629846517, "Avg policy loss": 0.24503091140650213, "Total num played games": 77056, "Total num trained steps": 153600, "Timestamp in ms": 1699965613270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992456742920096, "Avg loss": 0.7279536388814449, "Avg value loss": 0.4737445723148994, "Avg policy loss": 0.25420906441286206, "Total num played games": 77155, "Total num trained steps": 153728, "Timestamp in ms": 1699965664687, "logtype": "training_step"}
{"Avg objective": 22.8984375, "Games time in secs": 80.70794257894158, "Avg game time in secs": 0.982604477510904, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 77184, "Total num trained steps": 153801, "Timestamp in ms": 1699965693901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928371586964406, "Avg loss": 0.46638857142534107, "Avg value loss": 0.21179161782492884, "Avg policy loss": 0.2545969549100846, "Total num played games": 77204, "Total num trained steps": 153856, "Timestamp in ms": 1699965715411, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931655793724758, "Avg loss": 0.5203630287433043, "Avg value loss": 0.26803083380218595, "Avg policy loss": 0.25233219808433205, "Total num played games": 77256, "Total num trained steps": 153984, "Timestamp in ms": 1699965765680, "logtype": "training_step"}
{"Total num played games": 77308, "Total num trained steps": 154072, "Timestamp in ms": 1699965866146, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1953125}
{"Avg objective": 21.8984375, "Games time in secs": 173.29916518367827, "Avg game time in secs": 1.0325435287086293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 77312, "Total num trained steps": 154072, "Timestamp in ms": 1699965867201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922307254770153, "Avg loss": 0.7077014346141368, "Avg value loss": 0.44839448906714097, "Avg policy loss": 0.2593069433933124, "Total num played games": 77356, "Total num trained steps": 154112, "Timestamp in ms": 1699965882768, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992571731238777, "Avg loss": 0.45726006920449436, "Avg value loss": 0.2002074766496662, "Avg policy loss": 0.25705259444657713, "Total num played games": 77407, "Total num trained steps": 154240, "Timestamp in ms": 1699965933712, "logtype": "training_step"}
{"Avg objective": 22.203125, "Games time in secs": 92.42206710204482, "Avg game time in secs": 1.026147384181968, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 77440, "Total num trained steps": 154305, "Timestamp in ms": 1699965959623, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929894777612807, "Avg loss": 0.5429292893968523, "Avg value loss": 0.2946629881334957, "Avg policy loss": 0.24826630158349872, "Total num played games": 77455, "Total num trained steps": 154368, "Timestamp in ms": 1699965983672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932781132270216, "Avg loss": 0.4777204922866076, "Avg value loss": 0.229534379002871, "Avg policy loss": 0.24818611121736467, "Total num played games": 77508, "Total num trained steps": 154496, "Timestamp in ms": 1699966033964, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 115.92166956327856, "Avg game time in secs": 0.9386070112523157, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 77568, "Total num trained steps": 154603, "Timestamp in ms": 1699966075545, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923205772452004, "Avg loss": 0.6943840197054669, "Avg value loss": 0.44108257081825286, "Avg policy loss": 0.2533014406217262, "Total num played games": 77610, "Total num trained steps": 154624, "Timestamp in ms": 1699966083550, "logtype": "training_step"}
{"Total num played games": 77610, "Total num trained steps": 154673, "Timestamp in ms": 1699966150594, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.59375}
{"Ratio train steps to played games": 1.9927245100311624, "Avg loss": 0.5927796921459958, "Avg value loss": 0.3216790636652149, "Avg policy loss": 0.27110062539577484, "Total num played games": 77658, "Total num trained steps": 154752, "Timestamp in ms": 1699966183385, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 129.6838708538562, "Avg game time in secs": 1.0415114223142155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 77696, "Total num trained steps": 154808, "Timestamp in ms": 1699966205229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931151633700954, "Avg loss": 0.46385403687600046, "Avg value loss": 0.205934795900248, "Avg policy loss": 0.25791923818178475, "Total num played games": 77707, "Total num trained steps": 154880, "Timestamp in ms": 1699966234036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922242500578362, "Avg loss": 0.4673644477734342, "Avg value loss": 0.22091505359276198, "Avg policy loss": 0.24644939240533859, "Total num played games": 77806, "Total num trained steps": 155008, "Timestamp in ms": 1699966283269, "logtype": "training_step"}
{"Avg objective": 19.9140625, "Games time in secs": 115.86376518756151, "Avg game time in secs": 1.0382608301879372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 77824, "Total num trained steps": 155107, "Timestamp in ms": 1699966321093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992512105215839, "Avg loss": 0.6057598902843893, "Avg value loss": 0.35708304480067454, "Avg policy loss": 0.2486768503440544, "Total num played games": 77859, "Total num trained steps": 155136, "Timestamp in ms": 1699966332444, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929274647977717, "Avg loss": 0.51352110481821, "Avg value loss": 0.2724218654911965, "Avg policy loss": 0.24109924130607396, "Total num played games": 77907, "Total num trained steps": 155264, "Timestamp in ms": 1699966384754, "logtype": "training_step"}
{"Total num played games": 77907, "Total num trained steps": 155273, "Timestamp in ms": 1699966470293, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.82421875}
{"Avg objective": 22.671875, "Games time in secs": 151.81188977696002, "Avg game time in secs": 0.9520886888058158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 77952, "Total num trained steps": 155278, "Timestamp in ms": 1699966472905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933423128728112, "Avg loss": 0.4095040219835937, "Avg value loss": 0.17072908830596134, "Avg policy loss": 0.2387749357149005, "Total num played games": 77955, "Total num trained steps": 155392, "Timestamp in ms": 1699966518108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992300794260825, "Avg loss": 0.5341630335897207, "Avg value loss": 0.29704849200788885, "Avg policy loss": 0.2371145428624004, "Total num played games": 78060, "Total num trained steps": 155520, "Timestamp in ms": 1699966570342, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 133.9486839491874, "Avg game time in secs": 0.9859140503394883, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 78080, "Total num trained steps": 155610, "Timestamp in ms": 1699966606854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992587661464801, "Avg loss": 0.45578878524247557, "Avg value loss": 0.22362821851857007, "Avg policy loss": 0.2321605613688007, "Total num played games": 78113, "Total num trained steps": 155648, "Timestamp in ms": 1699966622353, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927721632339772, "Avg loss": 0.48520038777496666, "Avg value loss": 0.25609221134800464, "Avg policy loss": 0.22910817444790155, "Total num played games": 78170, "Total num trained steps": 155776, "Timestamp in ms": 1699966672909, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 88.36871857009828, "Avg game time in secs": 0.973011104404577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 78208, "Total num trained steps": 155831, "Timestamp in ms": 1699966695223, "logtype": "played_game"}
{"Total num played games": 78218, "Total num trained steps": 155875, "Timestamp in ms": 1699966838087, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.51171875}
{"Ratio train steps to played games": 1.9919633046278078, "Avg loss": 0.6202447776449844, "Avg value loss": 0.38532991532702, "Avg policy loss": 0.23491486255079508, "Total num played games": 78266, "Total num trained steps": 155904, "Timestamp in ms": 1699966850201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922496456798477, "Avg loss": 0.39168513170443475, "Avg value loss": 0.16239586533629335, "Avg policy loss": 0.22928926965687424, "Total num played games": 78319, "Total num trained steps": 156032, "Timestamp in ms": 1699966901639, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 246.23021093010902, "Avg game time in secs": 1.069939735069056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 78336, "Total num trained steps": 156128, "Timestamp in ms": 1699966941453, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925992088809494, "Avg loss": 0.4453685147454962, "Avg value loss": 0.2199594384583179, "Avg policy loss": 0.2254090775968507, "Total num played games": 78370, "Total num trained steps": 156160, "Timestamp in ms": 1699966954110, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929736415919612, "Avg loss": 0.39093230629805475, "Avg value loss": 0.16461314575280994, "Avg policy loss": 0.2263191599631682, "Total num played games": 78419, "Total num trained steps": 156288, "Timestamp in ms": 1699967003997, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 80.58778711222112, "Avg game time in secs": 1.0819166191213299, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.6}, "Total num played games": 78464, "Total num trained steps": 156331, "Timestamp in ms": 1699967022041, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993271485370578, "Avg loss": 0.5519625060260296, "Avg value loss": 0.32398910805932246, "Avg policy loss": 0.22797340562101454, "Total num played games": 78472, "Total num trained steps": 156416, "Timestamp in ms": 1699967055792, "logtype": "training_step"}
{"Total num played games": 78520, "Total num trained steps": 156475, "Timestamp in ms": 1699967147675, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.83203125}
{"Ratio train steps to played games": 1.9924651257509418, "Avg loss": 0.7628716093022376, "Avg value loss": 0.5220291771693155, "Avg policy loss": 0.24084242747630924, "Total num played games": 78568, "Total num trained steps": 156544, "Timestamp in ms": 1699967175458, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 185.9132568705827, "Avg game time in secs": 1.0695657179312548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 78592, "Total num trained steps": 156627, "Timestamp in ms": 1699967207954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927753752225896, "Avg loss": 0.5459056000690907, "Avg value loss": 0.31907656238763593, "Avg policy loss": 0.22682903753593564, "Total num played games": 78620, "Total num trained steps": 156672, "Timestamp in ms": 1699967225697, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930725035590808, "Avg loss": 0.5492755771847442, "Avg value loss": 0.3273013890720904, "Avg policy loss": 0.22197418636642396, "Total num played games": 78672, "Total num trained steps": 156800, "Timestamp in ms": 1699967275583, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 84.27929669618607, "Avg game time in secs": 1.2362245170370443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 78720, "Total num trained steps": 156842, "Timestamp in ms": 1699967292234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934959349593495, "Avg loss": 0.4095918253296986, "Avg value loss": 0.18512587866280228, "Avg policy loss": 0.22446594526991248, "Total num played games": 78720, "Total num trained steps": 156928, "Timestamp in ms": 1699967327504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992691839220463, "Avg loss": 0.6443628376582637, "Avg value loss": 0.41251999369706027, "Avg policy loss": 0.23184284940361977, "Total num played games": 78816, "Total num trained steps": 157056, "Timestamp in ms": 1699967377737, "logtype": "training_step"}
{"Total num played games": 78816, "Total num trained steps": 157075, "Timestamp in ms": 1699967430993, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6875}
{"Avg objective": 22.6875, "Games time in secs": 140.77125195227563, "Avg game time in secs": 0.9877488492056727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 78848, "Total num trained steps": 157079, "Timestamp in ms": 1699967433005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99310204909718, "Avg loss": 0.4035863537574187, "Avg value loss": 0.16575488954549655, "Avg policy loss": 0.2378314674133435, "Total num played games": 78864, "Total num trained steps": 157184, "Timestamp in ms": 1699967476268, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935117599351175, "Avg loss": 0.44921378255821764, "Avg value loss": 0.22609271702822298, "Avg policy loss": 0.22312106157187372, "Total num played games": 78912, "Total num trained steps": 157312, "Timestamp in ms": 1699967527552, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 141.15498509816825, "Avg game time in secs": 1.074806488060858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 78976, "Total num trained steps": 157426, "Timestamp in ms": 1699967574160, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924195446664725, "Avg loss": 0.49747133860364556, "Avg value loss": 0.27364146025502123, "Avg policy loss": 0.22382987290620804, "Total num played games": 79019, "Total num trained steps": 157440, "Timestamp in ms": 1699967579283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928036626701067, "Avg loss": 0.5841971531044692, "Avg value loss": 0.34639574491302483, "Avg policy loss": 0.23780141049064696, "Total num played games": 79068, "Total num trained steps": 157568, "Timestamp in ms": 1699967631365, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 80.84878499992192, "Avg game time in secs": 1.086479918754776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.65}, "Total num played games": 79104, "Total num trained steps": 157628, "Timestamp in ms": 1699967655009, "logtype": "played_game"}
{"Total num played games": 79121, "Total num trained steps": 157678, "Timestamp in ms": 1699967738911, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5546875}
{"Ratio train steps to played games": 1.9918907653248115, "Avg loss": 0.6786150108091533, "Avg value loss": 0.4254019899526611, "Avg policy loss": 0.2532130192266777, "Total num played games": 79169, "Total num trained steps": 157696, "Timestamp in ms": 1699967746105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935075597771854, "Avg loss": 0.3649768379982561, "Avg value loss": 0.1190987077425234, "Avg policy loss": 0.24587813299149275, "Total num played games": 79169, "Total num trained steps": 157824, "Timestamp in ms": 1699967800064, "logtype": "training_step"}
{"Avg objective": 23.1171875, "Games time in secs": 184.95342648774385, "Avg game time in secs": 1.0420537006721133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.6, "agent_stopped_0": 0.5}, "Total num played games": 79232, "Total num trained steps": 157924, "Timestamp in ms": 1699967839963, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926702495395252, "Avg loss": 0.7568277416285127, "Avg value loss": 0.5200446530943736, "Avg policy loss": 0.2367830800358206, "Total num played games": 79266, "Total num trained steps": 157952, "Timestamp in ms": 1699967850913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929776343326862, "Avg loss": 0.6116624339483678, "Avg value loss": 0.36463493172777817, "Avg policy loss": 0.24702750239521265, "Total num played games": 79318, "Total num trained steps": 158080, "Timestamp in ms": 1699967902934, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 81.91257384419441, "Avg game time in secs": 1.0281356386985863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 79360, "Total num trained steps": 158129, "Timestamp in ms": 1699967921876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993284616353786, "Avg loss": 0.6741474807495251, "Avg value loss": 0.4275145501305815, "Avg policy loss": 0.2466329188318923, "Total num played games": 79370, "Total num trained steps": 158208, "Timestamp in ms": 1699967954077, "logtype": "training_step"}
{"Total num played games": 79420, "Total num trained steps": 158282, "Timestamp in ms": 1699968033996, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.93359375}
{"Ratio train steps to played games": 1.9924497911108874, "Avg loss": 0.6239182215649635, "Avg value loss": 0.3617883627885021, "Avg policy loss": 0.2621298616286367, "Total num played games": 79468, "Total num trained steps": 158336, "Timestamp in ms": 1699968055441, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 170.86926339752972, "Avg game time in secs": 1.0843165880651213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 79488, "Total num trained steps": 158427, "Timestamp in ms": 1699968092745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928191455915087, "Avg loss": 0.4235694134840742, "Avg value loss": 0.18793099021422677, "Avg policy loss": 0.23563841928262264, "Total num played games": 79517, "Total num trained steps": 158464, "Timestamp in ms": 1699968107067, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931380311427818, "Avg loss": 0.4740586553234607, "Avg value loss": 0.2341323661385104, "Avg policy loss": 0.23992628674022853, "Total num played games": 79569, "Total num trained steps": 158592, "Timestamp in ms": 1699968157794, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 81.09180844016373, "Avg game time in secs": 1.0842928386991844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.69}, "Total num played games": 79616, "Total num trained steps": 158632, "Timestamp in ms": 1699968173837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935315322104576, "Avg loss": 0.523687845445238, "Avg value loss": 0.2747930744662881, "Avg policy loss": 0.24889476888347417, "Total num played games": 79617, "Total num trained steps": 158720, "Timestamp in ms": 1699968208598, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992698990152418, "Avg loss": 0.7277675946243107, "Avg value loss": 0.47992442606482655, "Avg policy loss": 0.24784315831493586, "Total num played games": 79715, "Total num trained steps": 158848, "Timestamp in ms": 1699968259093, "logtype": "training_step"}
{"Total num played games": 79715, "Total num trained steps": 158884, "Timestamp in ms": 1699968329905, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0625}
{"Avg objective": 22.609375, "Games time in secs": 158.18161959387362, "Avg game time in secs": 1.068805989008979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 79744, "Total num trained steps": 158888, "Timestamp in ms": 1699968332019, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931045722954253, "Avg loss": 0.46188830176834017, "Avg value loss": 0.21350523113505915, "Avg policy loss": 0.24838307313621044, "Total num played games": 79763, "Total num trained steps": 158976, "Timestamp in ms": 1699968367196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933223082512717, "Avg loss": 0.5274393806466833, "Avg value loss": 0.27917926406371407, "Avg policy loss": 0.24826011655386537, "Total num played games": 79818, "Total num trained steps": 159104, "Timestamp in ms": 1699968417280, "logtype": "training_step"}
{"Avg objective": 22.5234375, "Games time in secs": 135.89422739483416, "Avg game time in secs": 1.2506981161859585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.6, "agent_stopped_0": 0.46}, "Total num played games": 79872, "Total num trained steps": 159230, "Timestamp in ms": 1699968467913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929409997747127, "Avg loss": 0.4541865033097565, "Avg value loss": 0.19972170607070439, "Avg policy loss": 0.2544647988397628, "Total num played games": 79898, "Total num trained steps": 159232, "Timestamp in ms": 1699968468600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928095339327472, "Avg loss": 0.5676087546162307, "Avg value loss": 0.3128765699220821, "Avg policy loss": 0.25473218446131796, "Total num played games": 79967, "Total num trained steps": 159360, "Timestamp in ms": 1699968520503, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 79.35614935867488, "Avg game time in secs": 1.012337033986114, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 80000, "Total num trained steps": 159426, "Timestamp in ms": 1699968547269, "logtype": "played_game"}
{"Total num played games": 80015, "Total num trained steps": 159430, "Timestamp in ms": 1699968613488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0}
{"Total num played games": 80020, "Total num trained steps": 159430, "Timestamp in ms": 1699968677152, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.0703125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700045166208, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.76171875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700045626270, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.328125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701706686525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.71875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701707282081, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.37109375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701787536008, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.71875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702303240604, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702303775661, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702304445132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702305417839, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.40625}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702306029458, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702306494996, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.859375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702307931338, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.859375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702308845957, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.859375}
