{"Avg objective": 17.78125, "Games time in secs": 289.4987861234695, "Avg game time in secs": 79.1311571229744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.14, "agent_stopped_more": 0.63, "played_steps": 9.17, "reached_maximum_moves": 0.23}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1699609422604, "logtype": "played_game"}
{"Ratio train steps to played games": 0.7987421383647799, "Avg loss": 96.85501209646463, "Avg value loss": 95.95541870594025, "Avg policy loss": 0.8995945146307349, "Total num played games": 159, "Total num trained steps": 128, "Timestamp in ms": 1699609485509, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3212435233160622, "Avg loss": 13.260915260761976, "Avg value loss": 12.403576970100403, "Avg policy loss": 0.8573383246548474, "Total num played games": 193, "Total num trained steps": 256, "Timestamp in ms": 1699609543395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6872246696035242, "Avg loss": 9.047254486009479, "Avg value loss": 8.209276404231787, "Avg policy loss": 0.837977962102741, "Total num played games": 227, "Total num trained steps": 384, "Timestamp in ms": 1699609600561, "logtype": "training_step"}
{"Avg objective": 17.609375, "Games time in secs": 232.0047631636262, "Avg game time in secs": 89.74843636307924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2265625, "Avg reasons for ending game": {"reached_maximum_moves": 0.31, "played_steps": 10.11, "agent_stopped_more": 0.47, "agent_stopped_0": 0.22}, "Total num played games": 256, "Total num trained steps": 502, "Timestamp in ms": 1699609654609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768339768339769, "Avg loss": 5.817657859995961, "Avg value loss": 5.0186148807406425, "Avg policy loss": 0.7990429867058992, "Total num played games": 259, "Total num trained steps": 512, "Timestamp in ms": 1699609658332, "logtype": "training_step"}
{"Total num played games": 322, "Total num trained steps": 604, "Timestamp in ms": 1699610084018, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0234375}
{"Ratio train steps to played games": 1.8658892128279883, "Avg loss": 7.0207439213991165, "Avg value loss": 6.264298429712653, "Avg policy loss": 0.7564454837702215, "Total num played games": 343, "Total num trained steps": 640, "Timestamp in ms": 1699610097435, "logtype": "training_step"}
{"Ratio train steps to played games": 2.1452513966480447, "Avg loss": 7.011632792651653, "Avg value loss": 6.286725599318743, "Avg policy loss": 0.7249071332626045, "Total num played games": 358, "Total num trained steps": 768, "Timestamp in ms": 1699610142994, "logtype": "training_step"}
{"Ratio train steps to played games": 2.382978723404255, "Avg loss": 5.0363657381385565, "Avg value loss": 4.319549857638776, "Avg policy loss": 0.7168158856220543, "Total num played games": 376, "Total num trained steps": 896, "Timestamp in ms": 1699610189639, "logtype": "training_step"}
{"Avg objective": 18.3515625, "Games time in secs": 573.3248896915466, "Avg game time in secs": 85.27805037789221, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"reached_maximum_moves": 0.32, "played_steps": 9.69, "agent_stopped_more": 0.4, "agent_stopped_0": 0.28}, "Total num played games": 384, "Total num trained steps": 1003, "Timestamp in ms": 1699610227934, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6030534351145036, "Avg loss": 3.265279460698366, "Avg value loss": 2.556930711492896, "Avg policy loss": 0.7083487380295992, "Total num played games": 393, "Total num trained steps": 1024, "Timestamp in ms": 1699610235088, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7105882352941175, "Avg loss": 3.2615309515967965, "Avg value loss": 2.567589810118079, "Avg policy loss": 0.6939411326311529, "Total num played games": 425, "Total num trained steps": 1152, "Timestamp in ms": 1699610281426, "logtype": "training_step"}
{"Total num played games": 483, "Total num trained steps": 1207, "Timestamp in ms": 1699610674275, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.91015625}
{"Ratio train steps to played games": 2.585858585858586, "Avg loss": 3.7631912529468536, "Avg value loss": 3.093301620334387, "Avg policy loss": 0.6698896121233702, "Total num played games": 495, "Total num trained steps": 1280, "Timestamp in ms": 1699610701762, "logtype": "training_step"}
{"Ratio train steps to played games": 2.777120315581854, "Avg loss": 2.7204828886315227, "Avg value loss": 2.055016364902258, "Avg policy loss": 0.6654665181413293, "Total num played games": 507, "Total num trained steps": 1408, "Timestamp in ms": 1699610746684, "logtype": "training_step"}
{"Avg objective": 16.875, "Games time in secs": 539.5358633194119, "Avg game time in secs": 94.71876702900045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.4453125, "Avg reasons for ending game": {"reached_maximum_moves": 0.37, "played_steps": 10.89, "agent_stopped_0": 0.24, "agent_stopped_more": 0.39}, "Total num played games": 512, "Total num trained steps": 1465, "Timestamp in ms": 1699610767470, "logtype": "played_game"}
{"Ratio train steps to played games": 2.959537572254335, "Avg loss": 2.150984345935285, "Avg value loss": 1.4938238826580346, "Avg policy loss": 0.6571604767814279, "Total num played games": 519, "Total num trained steps": 1536, "Timestamp in ms": 1699610791914, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0476190476190474, "Avg loss": 1.833321863785386, "Avg value loss": 1.1807126239873469, "Avg policy loss": 0.6526092444546521, "Total num played games": 546, "Total num trained steps": 1664, "Timestamp in ms": 1699610837652, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1549295774647885, "Avg loss": 1.8543563149869442, "Avg value loss": 1.211802335921675, "Avg policy loss": 0.6425539730116725, "Total num played games": 568, "Total num trained steps": 1792, "Timestamp in ms": 1699610884067, "logtype": "training_step"}
{"Total num played games": 626, "Total num trained steps": 1810, "Timestamp in ms": 1699611284905, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.62109375}
{"Avg objective": 16.171875, "Games time in secs": 524.5483864154667, "Avg game time in secs": 100.83108365131193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 11.27, "agent_stopped_0": 0.29, "reached_maximum_moves": 0.38}, "Total num played games": 640, "Total num trained steps": 1827, "Timestamp in ms": 1699611292018, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8402366863905324, "Avg loss": 3.571990651078522, "Avg value loss": 2.9425369072705507, "Avg policy loss": 0.6294537484645844, "Total num played games": 676, "Total num trained steps": 1920, "Timestamp in ms": 1699611325393, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9552669552669553, "Avg loss": 2.277914418838918, "Avg value loss": 1.6506496355868876, "Avg policy loss": 0.6272647832520306, "Total num played games": 693, "Total num trained steps": 2048, "Timestamp in ms": 1699611371337, "logtype": "training_step"}
{"Ratio train steps to played games": 3.069111424541608, "Avg loss": 2.483814493753016, "Avg value loss": 1.8654351304285228, "Avg policy loss": 0.6183793386444449, "Total num played games": 709, "Total num trained steps": 2176, "Timestamp in ms": 1699611416797, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1346938775510202, "Avg loss": 2.7038517836481333, "Avg value loss": 2.0880643436685205, "Avg policy loss": 0.6157874530181289, "Total num played games": 735, "Total num trained steps": 2304, "Timestamp in ms": 1699611462020, "logtype": "training_step"}
{"Avg objective": 18.890625, "Games time in secs": 209.51467136479914, "Avg game time in secs": 54.28232043478056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.33, "played_steps": 5.89, "reached_maximum_moves": 0.17}, "Total num played games": 768, "Total num trained steps": 2410, "Timestamp in ms": 1699611501533, "logtype": "played_game"}
{"Total num played games": 810, "Total num trained steps": 2410, "Timestamp in ms": 1699611867154, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4453125}
{"Ratio train steps to played games": 2.923076923076923, "Avg loss": 2.888241839595139, "Avg value loss": 2.279433977790177, "Avg policy loss": 0.6088078473694623, "Total num played games": 831, "Total num trained steps": 2432, "Timestamp in ms": 1699611875587, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9698375870069604, "Avg loss": 3.4665236230939627, "Avg value loss": 2.8615297311916947, "Avg policy loss": 0.604993911460042, "Total num played games": 862, "Total num trained steps": 2560, "Timestamp in ms": 1699611922311, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0545454545454547, "Avg loss": 2.08176158554852, "Avg value loss": 1.487593269906938, "Avg policy loss": 0.5941683226265013, "Total num played games": 880, "Total num trained steps": 2688, "Timestamp in ms": 1699611968417, "logtype": "training_step"}
{"Avg objective": 18.796875, "Games time in secs": 511.17118624038994, "Avg game time in secs": 68.63022480612563, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.34, "played_steps": 7.44, "reached_maximum_moves": 0.21}, "Total num played games": 896, "Total num trained steps": 2813, "Timestamp in ms": 1699612012704, "logtype": "played_game"}
{"Ratio train steps to played games": 3.1393534002229653, "Avg loss": 1.7139212796464562, "Avg value loss": 1.1211021966300905, "Avg policy loss": 0.5928190820850432, "Total num played games": 897, "Total num trained steps": 2816, "Timestamp in ms": 1699612013427, "logtype": "training_step"}
{"Ratio train steps to played games": 3.1792656587473003, "Avg loss": 3.115289348177612, "Avg value loss": 2.5274525680579245, "Avg policy loss": 0.5878368183039129, "Total num played games": 926, "Total num trained steps": 2944, "Timestamp in ms": 1699612057969, "logtype": "training_step"}
{"Total num played games": 998, "Total num trained steps": 3014, "Timestamp in ms": 1699612448341, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.63671875}
{"Avg objective": 20.6640625, "Games time in secs": 444.2421173583716, "Avg game time in secs": 88.19709611176222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "reached_maximum_moves": 0.36, "played_steps": 9.64, "agent_stopped_more": 0.17}, "Total num played games": 1024, "Total num trained steps": 3033, "Timestamp in ms": 1699612456947, "logtype": "played_game"}
{"Ratio train steps to played games": 2.9146110056925996, "Avg loss": 4.150087716057897, "Avg value loss": 3.565298051107675, "Avg policy loss": 0.5847897385247052, "Total num played games": 1054, "Total num trained steps": 3072, "Timestamp in ms": 1699612471244, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9565619223659887, "Avg loss": 2.7794533781707287, "Avg value loss": 2.2038586768321693, "Avg policy loss": 0.5755946920253336, "Total num played games": 1082, "Total num trained steps": 3200, "Timestamp in ms": 1699612516971, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0309653916211294, "Avg loss": 1.9233543379232287, "Avg value loss": 1.3540622857399285, "Avg policy loss": 0.5692920498549938, "Total num played games": 1098, "Total num trained steps": 3328, "Timestamp in ms": 1699612561993, "logtype": "training_step"}
{"Ratio train steps to played games": 3.0584070796460177, "Avg loss": 2.1204528100788593, "Avg value loss": 1.555952557362616, "Avg policy loss": 0.5645002368837595, "Total num played games": 1130, "Total num trained steps": 3456, "Timestamp in ms": 1699612606202, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 168.75052935257554, "Avg game time in secs": 28.46686287446937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.19, "played_steps": 2.92, "reached_maximum_moves": 0.08}, "Total num played games": 1152, "Total num trained steps": 3508, "Timestamp in ms": 1699612625697, "logtype": "played_game"}
{"Ratio train steps to played games": 3.086993970714901, "Avg loss": 3.1290433229878545, "Avg value loss": 2.5585603998042643, "Avg policy loss": 0.5704828891903162, "Total num played games": 1161, "Total num trained steps": 3584, "Timestamp in ms": 1699612652188, "logtype": "training_step"}
{"Total num played games": 1219, "Total num trained steps": 3614, "Timestamp in ms": 1699613016874, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.453125}
{"Avg objective": 19.1015625, "Games time in secs": 417.0418441146612, "Avg game time in secs": 81.02589607187838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "reached_maximum_moves": 0.33, "played_steps": 8.68, "agent_stopped_more": 0.14}, "Total num played games": 1280, "Total num trained steps": 3684, "Timestamp in ms": 1699613042739, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8686244204018547, "Avg loss": 4.227081854827702, "Avg value loss": 3.671042067464441, "Avg policy loss": 0.5560397929511964, "Total num played games": 1294, "Total num trained steps": 3712, "Timestamp in ms": 1699613053493, "logtype": "training_step"}
{"Ratio train steps to played games": 2.922374429223744, "Avg loss": 2.769128833897412, "Avg value loss": 2.218617396429181, "Avg policy loss": 0.5505114479456097, "Total num played games": 1314, "Total num trained steps": 3840, "Timestamp in ms": 1699613099753, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9767441860465116, "Avg loss": 2.340613448061049, "Avg value loss": 1.7889556209556758, "Avg policy loss": 0.5516578266397119, "Total num played games": 1333, "Total num trained steps": 3968, "Timestamp in ms": 1699613145284, "logtype": "training_step"}
{"Ratio train steps to played games": 2.9652425778421434, "Avg loss": 2.1573246056213975, "Avg value loss": 1.6166826160624623, "Avg policy loss": 0.5406419865321368, "Total num played games": 1381, "Total num trained steps": 4096, "Timestamp in ms": 1699613191448, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 165.85903305746615, "Avg game time in secs": 38.676857176978956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.23, "played_steps": 4.12, "reached_maximum_moves": 0.11}, "Total num played games": 1408, "Total num trained steps": 4144, "Timestamp in ms": 1699613208598, "logtype": "played_game"}
{"Total num played games": 1493, "Total num trained steps": 4216, "Timestamp in ms": 1699613586714, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.19921875}
{"Ratio train steps to played games": 2.829202947086403, "Avg loss": 2.6244754875078797, "Avg value loss": 2.0837392690591514, "Avg policy loss": 0.5407362058758736, "Total num played games": 1493, "Total num trained steps": 4224, "Timestamp in ms": 1699613590518, "logtype": "training_step"}
{"Avg objective": 18.8046875, "Games time in secs": 396.09528393112123, "Avg game time in secs": 68.04093808446487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "reached_maximum_moves": 0.23, "played_steps": 7.38, "agent_stopped_more": 0.2}, "Total num played games": 1536, "Total num trained steps": 4262, "Timestamp in ms": 1699613604694, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7790549169859515, "Avg loss": 2.8643429335206747, "Avg value loss": 2.3526119105517864, "Avg policy loss": 0.5117310541681945, "Total num played games": 1566, "Total num trained steps": 4352, "Timestamp in ms": 1699613638293, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8240857503152585, "Avg loss": 1.8296282915398479, "Avg value loss": 1.3302196017466486, "Avg policy loss": 0.4994086907245219, "Total num played games": 1586, "Total num trained steps": 4480, "Timestamp in ms": 1699613684237, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8692403486924034, "Avg loss": 3.212762695737183, "Avg value loss": 2.71949649322778, "Avg policy loss": 0.4932661415077746, "Total num played games": 1606, "Total num trained steps": 4608, "Timestamp in ms": 1699613731430, "logtype": "training_step"}
{"Ratio train steps to played games": 2.884287454323995, "Avg loss": 1.824963946826756, "Avg value loss": 1.3429005672223866, "Avg policy loss": 0.4820633977651596, "Total num played games": 1642, "Total num trained steps": 4736, "Timestamp in ms": 1699613779534, "logtype": "training_step"}
{"Avg objective": 19.046875, "Games time in secs": 194.23562251776457, "Avg game time in secs": 42.61052651089267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.25, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.18, "played_steps": 4.53, "reached_maximum_moves": 0.15}, "Total num played games": 1664, "Total num trained steps": 4790, "Timestamp in ms": 1699613798930, "logtype": "played_game"}
{"Total num played games": 1730, "Total num trained steps": 4821, "Timestamp in ms": 1699614123074, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.265625}
{"Avg objective": 20.8671875, "Games time in secs": 339.3332485444844, "Avg game time in secs": 63.34178274885926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "reached_maximum_moves": 0.25, "played_steps": 6.81, "agent_stopped_more": 0.11}, "Total num played games": 1792, "Total num trained steps": 4858, "Timestamp in ms": 1699614138263, "logtype": "played_game"}
{"Ratio train steps to played games": 2.709192200557103, "Avg loss": 3.561281464062631, "Avg value loss": 3.093143632169813, "Avg policy loss": 0.46813782397657633, "Total num played games": 1795, "Total num trained steps": 4864, "Timestamp in ms": 1699614140319, "logtype": "training_step"}
{"Ratio train steps to played games": 2.638477801268499, "Avg loss": 4.561146784573793, "Avg value loss": 4.1115568075329065, "Avg policy loss": 0.4495900021865964, "Total num played games": 1892, "Total num trained steps": 4992, "Timestamp in ms": 1699614186354, "logtype": "training_step"}
{"Avg objective": 23.6640625, "Games time in secs": 64.98881324753165, "Avg game time in secs": 8.770038950024173, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.29}, "Total num played games": 1920, "Total num trained steps": 5039, "Timestamp in ms": 1699614203252, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6296866974833075, "Avg loss": 2.9190047262236476, "Avg value loss": 2.482831654138863, "Avg policy loss": 0.4361730550881475, "Total num played games": 1947, "Total num trained steps": 5120, "Timestamp in ms": 1699614232208, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6187624750499, "Avg loss": 2.5487265596166253, "Avg value loss": 2.1183949783444405, "Avg policy loss": 0.43033161014318466, "Total num played games": 2004, "Total num trained steps": 5248, "Timestamp in ms": 1699614279531, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 102.89116868749261, "Avg game time in secs": 32.45274199676351, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.19, "played_steps": 3.39, "agent_stopped_0": 0.73, "reached_maximum_moves": 0.09}, "Total num played games": 2048, "Total num trained steps": 5323, "Timestamp in ms": 1699614306143, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5846153846153848, "Avg loss": 2.6458321074023843, "Avg value loss": 2.2285410361364484, "Avg policy loss": 0.4172910419292748, "Total num played games": 2080, "Total num trained steps": 5376, "Timestamp in ms": 1699614324392, "logtype": "training_step"}
{"Total num played games": 2164, "Total num trained steps": 5425, "Timestamp in ms": 1699614658366, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.328125}
{"Avg objective": 20.5859375, "Games time in secs": 359.4028656594455, "Avg game time in secs": 60.00485351556563, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.18, "played_steps": 6.44, "reached_maximum_moves": 0.2}, "Total num played games": 2176, "Total num trained steps": 5441, "Timestamp in ms": 1699614665546, "logtype": "played_game"}
{"Ratio train steps to played games": 2.398257080610022, "Avg loss": 6.124538458883762, "Avg value loss": 5.729168088175356, "Avg policy loss": 0.3953703469596803, "Total num played games": 2295, "Total num trained steps": 5504, "Timestamp in ms": 1699614687468, "logtype": "training_step"}
{"Avg objective": 23.5078125, "Games time in secs": 24.935983054339886, "Avg game time in secs": 6.505780395353213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.03}, "Total num played games": 2304, "Total num trained steps": 5512, "Timestamp in ms": 1699614690482, "logtype": "played_game"}
{"Ratio train steps to played games": 2.340814630091438, "Avg loss": 4.634572999551892, "Avg value loss": 4.2690332643687725, "Avg policy loss": 0.36553971795365214, "Total num played games": 2406, "Total num trained steps": 5632, "Timestamp in ms": 1699614735916, "logtype": "training_step"}
{"Avg objective": 24.078125, "Games time in secs": 61.4378647506237, "Avg game time in secs": 6.960248378411052, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.08}, "Total num played games": 2432, "Total num trained steps": 5676, "Timestamp in ms": 1699614751920, "logtype": "played_game"}
{"Ratio train steps to played games": 2.324455205811138, "Avg loss": 3.0808434262871742, "Avg value loss": 2.733999199233949, "Avg policy loss": 0.3468442817684263, "Total num played games": 2478, "Total num trained steps": 5760, "Timestamp in ms": 1699614780976, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 74.70284653641284, "Avg game time in secs": 20.419545727869263, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "agent_stopped_more": 0.1, "played_steps": 1.77, "reached_maximum_moves": 0.05}, "Total num played games": 2560, "Total num trained steps": 5884, "Timestamp in ms": 1699614826627, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2919423900350333, "Avg loss": 2.825295401737094, "Avg value loss": 2.4902397841215134, "Avg policy loss": 0.3350556087680161, "Total num played games": 2567, "Total num trained steps": 5888, "Timestamp in ms": 1699614828127, "logtype": "training_step"}
{"Ratio train steps to played games": 2.254872563718141, "Avg loss": 2.9963452788069844, "Avg value loss": 2.6752219796180725, "Avg policy loss": 0.3211232826579362, "Total num played games": 2668, "Total num trained steps": 6016, "Timestamp in ms": 1699614874796, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 57.32035574875772, "Avg game time in secs": 23.294419260811992, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.03, "played_steps": 2.07, "reached_maximum_moves": 0.09}, "Total num played games": 2688, "Total num trained steps": 6028, "Timestamp in ms": 1699614883948, "logtype": "played_game"}
{"Total num played games": 2723, "Total num trained steps": 6028, "Timestamp in ms": 1699615202148, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.86328125}
{"Avg objective": 21.921875, "Games time in secs": 337.0123264696449, "Avg game time in secs": 48.13254775098176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"reached_maximum_moves": 0.18, "played_steps": 4.9, "agent_stopped_0": 0.73, "agent_stopped_more": 0.09}, "Total num played games": 2816, "Total num trained steps": 6074, "Timestamp in ms": 1699615220962, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0990775538093613, "Avg loss": 5.62529862113297, "Avg value loss": 5.33702002838254, "Avg policy loss": 0.2882786507252604, "Total num played games": 2927, "Total num trained steps": 6144, "Timestamp in ms": 1699615246049, "logtype": "training_step"}
{"Avg objective": 24.671875, "Games time in secs": 31.489473460242152, "Avg game time in secs": 6.597587287251372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.03}, "Total num played games": 2944, "Total num trained steps": 6161, "Timestamp in ms": 1699615252452, "logtype": "played_game"}
{"Ratio train steps to played games": 2.074760172014555, "Avg loss": 3.2995230378583074, "Avg value loss": 3.0322868563234806, "Avg policy loss": 0.2672361379954964, "Total num played games": 3023, "Total num trained steps": 6272, "Timestamp in ms": 1699615292885, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 61.89199225977063, "Avg game time in secs": 10.703656853511347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.58}, "Total num played games": 3072, "Total num trained steps": 6331, "Timestamp in ms": 1699615314344, "logtype": "played_game"}
{"Ratio train steps to played games": 2.050304389618712, "Avg loss": 2.2375064780935645, "Avg value loss": 1.9830741183832288, "Avg policy loss": 0.25443234958220273, "Total num played games": 3121, "Total num trained steps": 6400, "Timestamp in ms": 1699615338253, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 65.10127562098205, "Avg game time in secs": 18.249777276141685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.87, "agent_stopped_more": 0.1, "played_steps": 1.58, "reached_maximum_moves": 0.03}, "Total num played games": 3200, "Total num trained steps": 6521, "Timestamp in ms": 1699615379445, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0358702432938243, "Avg loss": 1.9577816259115934, "Avg value loss": 1.716349427588284, "Avg policy loss": 0.24143218365497887, "Total num played games": 3206, "Total num trained steps": 6528, "Timestamp in ms": 1699615381699, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 38.26764151081443, "Avg game time in secs": 16.748910413691192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.05, "played_steps": 1.36, "reached_maximum_moves": 0.05}, "Total num played games": 3328, "Total num trained steps": 6629, "Timestamp in ms": 1699615417713, "logtype": "played_game"}
{"Total num played games": 3370, "Total num trained steps": 6629, "Timestamp in ms": 1699615675061, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.91796875}
{"Ratio train steps to played games": 1.9487554904831625, "Avg loss": 3.3011076087132096, "Avg value loss": 3.078782736323774, "Avg policy loss": 0.22232489078305662, "Total num played games": 3415, "Total num trained steps": 6656, "Timestamp in ms": 1699615685565, "logtype": "training_step"}
{"Avg objective": 22.3515625, "Games time in secs": 275.3797885887325, "Avg game time in secs": 38.56608102445898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.82, "reached_maximum_moves": 0.12, "played_steps": 3.77, "agent_stopped_more": 0.05}, "Total num played games": 3456, "Total num trained steps": 6678, "Timestamp in ms": 1699615693093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9126021990414435, "Avg loss": 4.652239635586739, "Avg value loss": 4.453302372246981, "Avg policy loss": 0.1989372333046049, "Total num played games": 3547, "Total num trained steps": 6784, "Timestamp in ms": 1699615735823, "logtype": "training_step"}
{"Avg objective": 23.203125, "Games time in secs": 80.44819808192551, "Avg game time in secs": 8.803140291071031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.93, "agent_stopped_more": 0.07, "played_steps": 0.41}, "Total num played games": 3584, "Total num trained steps": 6874, "Timestamp in ms": 1699615773541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9170596393897366, "Avg loss": 2.385169902816415, "Avg value loss": 2.1963078058324754, "Avg policy loss": 0.18886209034826607, "Total num played games": 3605, "Total num trained steps": 6912, "Timestamp in ms": 1699615789929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.925601750547046, "Avg loss": 1.883459753356874, "Avg value loss": 1.7041189726442099, "Avg policy loss": 0.17934079933911562, "Total num played games": 3656, "Total num trained steps": 7040, "Timestamp in ms": 1699615845248, "logtype": "training_step"}
{"Avg objective": 23.28125, "Games time in secs": 123.21929775364697, "Avg game time in secs": 14.625854718091432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.06, "played_steps": 1.29, "reached_maximum_moves": 0.04}, "Total num played games": 3712, "Total num trained steps": 7164, "Timestamp in ms": 1699615896761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9299946149703824, "Avg loss": 1.4786455859430134, "Avg value loss": 1.303022879641503, "Avg policy loss": 0.17562271317001432, "Total num played games": 3714, "Total num trained steps": 7168, "Timestamp in ms": 1699615897976, "logtype": "training_step"}
{"Total num played games": 3757, "Total num trained steps": 7230, "Timestamp in ms": 1699616096587, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.6484375}
{"Ratio train steps to played games": 1.9197368421052632, "Avg loss": 2.061510694678873, "Avg value loss": 1.8782529579475522, "Avg policy loss": 0.18325772578828037, "Total num played games": 3800, "Total num trained steps": 7296, "Timestamp in ms": 1699616125565, "logtype": "training_step"}
{"Avg objective": 22.8203125, "Games time in secs": 258.8516747020185, "Avg game time in secs": 17.835035843236255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "agent_stopped_more": 0.09, "played_steps": 1.76, "reached_maximum_moves": 0.05}, "Total num played games": 3840, "Total num trained steps": 7365, "Timestamp in ms": 1699616155613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.928051948051948, "Avg loss": 1.3524488033726811, "Avg value loss": 1.1699794260784984, "Avg policy loss": 0.18246939219534397, "Total num played games": 3850, "Total num trained steps": 7424, "Timestamp in ms": 1699616182355, "logtype": "training_step"}
{"Ratio train steps to played games": 1.923331635252165, "Avg loss": 1.5367830055765808, "Avg value loss": 1.3529211482964456, "Avg policy loss": 0.1838618628680706, "Total num played games": 3926, "Total num trained steps": 7552, "Timestamp in ms": 1699616239937, "logtype": "training_step"}
{"Avg objective": 22.8984375, "Games time in secs": 119.9263749346137, "Avg game time in secs": 8.913013058758224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.89, "agent_stopped_more": 0.11, "played_steps": 0.52}, "Total num played games": 3968, "Total num trained steps": 7630, "Timestamp in ms": 1699616275539, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9337698312767564, "Avg loss": 2.943309652619064, "Avg value loss": 2.754721133969724, "Avg policy loss": 0.18858853250276297, "Total num played games": 3971, "Total num trained steps": 7680, "Timestamp in ms": 1699616297970, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9295600593178448, "Avg loss": 1.9463983536697924, "Avg value loss": 1.7582347211427987, "Avg policy loss": 0.18816364230588078, "Total num played games": 4046, "Total num trained steps": 7808, "Timestamp in ms": 1699616351471, "logtype": "training_step"}
{"Total num played games": 4066, "Total num trained steps": 7832, "Timestamp in ms": 1699616520176, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.7890625}
{"Avg objective": 22.7421875, "Games time in secs": 251.63012729026377, "Avg game time in secs": 32.78267253213562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"reached_maximum_moves": 0.14, "played_steps": 3.85, "agent_stopped_more": 0.09, "agent_stopped_0": 0.77}, "Total num played games": 4096, "Total num trained steps": 7848, "Timestamp in ms": 1699616527169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9309002433090023, "Avg loss": 3.34682871773839, "Avg value loss": 3.1534913880750537, "Avg policy loss": 0.19333730859216303, "Total num played games": 4110, "Total num trained steps": 7936, "Timestamp in ms": 1699616566342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.936359269932757, "Avg loss": 1.851690975483507, "Avg value loss": 1.6572652477771044, "Avg policy loss": 0.19442574388813227, "Total num played games": 4164, "Total num trained steps": 8064, "Timestamp in ms": 1699616621759, "logtype": "training_step"}
{"Avg objective": 24.5859375, "Games time in secs": 139.01787626184523, "Avg game time in secs": 7.484984163878835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.12, "played_steps": 0.45}, "Total num played games": 4224, "Total num trained steps": 8172, "Timestamp in ms": 1699616666187, "logtype": "played_game"}
{"Ratio train steps to played games": 1.930018850141376, "Avg loss": 1.7705601919442415, "Avg value loss": 1.5743101169355214, "Avg policy loss": 0.19625005463603884, "Total num played games": 4244, "Total num trained steps": 8192, "Timestamp in ms": 1699616674358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9333023471996282, "Avg loss": 2.4074904690496624, "Avg value loss": 2.2115340968593955, "Avg policy loss": 0.19595636031590402, "Total num played games": 4303, "Total num trained steps": 8320, "Timestamp in ms": 1699616724914, "logtype": "training_step"}
{"Avg objective": 23.0625, "Games time in secs": 103.57403177581728, "Avg game time in secs": 15.606321393264807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_0": 0.82, "agent_stopped_more": 0.15, "played_steps": 1.58, "reached_maximum_moves": 0.03}, "Total num played games": 4352, "Total num trained steps": 8432, "Timestamp in ms": 1699616769762, "logtype": "played_game"}
{"Total num played games": 4384, "Total num trained steps": 8432, "Timestamp in ms": 1699616885471, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.046875}
{"Ratio train steps to played games": 1.911744738628649, "Avg loss": 2.64997464325279, "Avg value loss": 2.4473827155306935, "Avg policy loss": 0.20259194250684232, "Total num played games": 4419, "Total num trained steps": 8448, "Timestamp in ms": 1699616895587, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9354547506206274, "Avg loss": 2.619061113335192, "Avg value loss": 2.4012889522127807, "Avg policy loss": 0.21777216449845582, "Total num played games": 4431, "Total num trained steps": 8576, "Timestamp in ms": 1699616963443, "logtype": "training_step"}
{"Avg objective": 23.8203125, "Games time in secs": 257.19588796794415, "Avg game time in secs": 34.591185128243524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.19, "played_steps": 4.26, "reached_maximum_moves": 0.13}, "Total num played games": 4480, "Total num trained steps": 8692, "Timestamp in ms": 1699617026958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9426339285714285, "Avg loss": 2.2425468410365283, "Avg value loss": 2.026160341221839, "Avg policy loss": 0.21638647944200784, "Total num played games": 4480, "Total num trained steps": 8704, "Timestamp in ms": 1699617033892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.93006993006993, "Avg loss": 2.499114892911166, "Avg value loss": 2.2758492273278534, "Avg policy loss": 0.2232656206469983, "Total num played games": 4576, "Total num trained steps": 8832, "Timestamp in ms": 1699617100897, "logtype": "training_step"}
{"Avg objective": 23.3125, "Games time in secs": 115.18627225793898, "Avg game time in secs": 5.2923510023683775, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.1, "played_steps": 0.31}, "Total num played games": 4608, "Total num trained steps": 8908, "Timestamp in ms": 1699617142144, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9385547382085677, "Avg loss": 1.9396972521208227, "Avg value loss": 1.7096433038823307, "Avg policy loss": 0.23005395708605647, "Total num played games": 4622, "Total num trained steps": 8960, "Timestamp in ms": 1699617169844, "logtype": "training_step"}
{"Total num played games": 4671, "Total num trained steps": 9034, "Timestamp in ms": 1699617353580, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.7265625}
{"Ratio train steps to played games": 1.926436294254823, "Avg loss": 1.9787118947133422, "Avg value loss": 1.7437263110186905, "Avg policy loss": 0.23498558066785336, "Total num played games": 4717, "Total num trained steps": 9088, "Timestamp in ms": 1699617384124, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 296.5613505207002, "Avg game time in secs": 15.970158491429174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.78, "agent_stopped_more": 0.16, "played_steps": 1.84, "reached_maximum_moves": 0.05}, "Total num played games": 4736, "Total num trained steps": 9189, "Timestamp in ms": 1699617438706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.933291378225299, "Avg loss": 1.8508612308651209, "Avg value loss": 1.5989136814605445, "Avg policy loss": 0.25194755394477397, "Total num played games": 4767, "Total num trained steps": 9216, "Timestamp in ms": 1699617452809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9414086848119676, "Avg loss": 1.9364596125669777, "Avg value loss": 1.6745687029324472, "Avg policy loss": 0.26189090101979673, "Total num played games": 4813, "Total num trained steps": 9344, "Timestamp in ms": 1699617521338, "logtype": "training_step"}
{"Avg objective": 23.53125, "Games time in secs": 151.3029187899083, "Avg game time in secs": 6.304279199554003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.82, "agent_stopped_more": 0.18, "played_steps": 0.45}, "Total num played games": 4864, "Total num trained steps": 9471, "Timestamp in ms": 1699617590009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9465680230168516, "Avg loss": 1.7016525650396943, "Avg value loss": 1.4343736455775797, "Avg policy loss": 0.26727893168572336, "Total num played games": 4866, "Total num trained steps": 9472, "Timestamp in ms": 1699617590344, "logtype": "training_step"}
{"Ratio train steps to played games": 1.939002221773379, "Avg loss": 3.0341769764199853, "Avg value loss": 2.765372249763459, "Avg policy loss": 0.2688047307310626, "Total num played games": 4951, "Total num trained steps": 9600, "Timestamp in ms": 1699617657519, "logtype": "training_step"}
{"Total num played games": 4954, "Total num trained steps": 9636, "Timestamp in ms": 1699617841564, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.35546875}
{"Avg objective": 24.1875, "Games time in secs": 257.19159798696637, "Avg game time in secs": 9.608441164367832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.11, "played_steps": 0.95, "reached_maximum_moves": 0.02}, "Total num played games": 4992, "Total num trained steps": 9644, "Timestamp in ms": 1699617847201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9461784713885555, "Avg loss": 1.7653156723827124, "Avg value loss": 1.4858948623295873, "Avg policy loss": 0.27942081924993545, "Total num played games": 4998, "Total num trained steps": 9728, "Timestamp in ms": 1699617891122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9371069182389937, "Avg loss": 1.8627615571022034, "Avg value loss": 1.569941996363923, "Avg policy loss": 0.29281955712940544, "Total num played games": 5088, "Total num trained steps": 9856, "Timestamp in ms": 1699617960441, "logtype": "training_step"}
{"Avg objective": 24.140625, "Games time in secs": 157.6552958767861, "Avg game time in secs": 6.453545069278334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.83, "agent_stopped_more": 0.17, "played_steps": 0.51}, "Total num played games": 5120, "Total num trained steps": 9939, "Timestamp in ms": 1699618004856, "logtype": "played_game"}
{"Ratio train steps to played games": 1.94146246596655, "Avg loss": 2.080725278239697, "Avg value loss": 1.7893006182275712, "Avg policy loss": 0.29142466571647674, "Total num played games": 5142, "Total num trained steps": 9984, "Timestamp in ms": 1699618029234, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9483622350674374, "Avg loss": 1.790799653623253, "Avg value loss": 1.4968802542425692, "Avg policy loss": 0.2939193919301033, "Total num played games": 5190, "Total num trained steps": 10112, "Timestamp in ms": 1699618100026, "logtype": "training_step"}
{"Avg objective": 23.171875, "Games time in secs": 156.58254258707166, "Avg game time in secs": 9.778206046452397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.18, "played_steps": 1.01, "reached_maximum_moves": 0.02}, "Total num played games": 5248, "Total num trained steps": 10226, "Timestamp in ms": 1699618161439, "logtype": "played_game"}
{"Total num played games": 5287, "Total num trained steps": 10236, "Timestamp in ms": 1699618270826, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.828125}
{"Ratio train steps to played games": 1.9368261774163043, "Avg loss": 2.865354295819998, "Avg value loss": 2.5594334311317652, "Avg policy loss": 0.3059208580525592, "Total num played games": 5287, "Total num trained steps": 10240, "Timestamp in ms": 1699618273313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9441215075942246, "Avg loss": 2.549191329162568, "Avg value loss": 2.2442036075517535, "Avg policy loss": 0.30498776526656, "Total num played games": 5333, "Total num trained steps": 10368, "Timestamp in ms": 1699618340707, "logtype": "training_step"}
{"Avg objective": 22.828125, "Games time in secs": 207.90133819170296, "Avg game time in secs": 7.379531241676887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.15, "played_steps": 0.73, "reached_maximum_moves": 0.02}, "Total num played games": 5376, "Total num trained steps": 10419, "Timestamp in ms": 1699618369340, "logtype": "played_game"}
{"Ratio train steps to played games": 1.950566809143282, "Avg loss": 2.3410552735440433, "Avg value loss": 2.0251432766672224, "Avg policy loss": 0.31591203552670777, "Total num played games": 5381, "Total num trained steps": 10496, "Timestamp in ms": 1699618410044, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9408111070515162, "Avg loss": 2.750072497408837, "Avg value loss": 2.429176550824195, "Avg policy loss": 0.3208959809271619, "Total num played games": 5474, "Total num trained steps": 10624, "Timestamp in ms": 1699618477373, "logtype": "training_step"}
{"Avg objective": 24.6015625, "Games time in secs": 151.10111215524375, "Avg game time in secs": 6.860700445831753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.16, "played_steps": 0.63, "agent_stopped_0": 0.82, "reached_maximum_moves": 0.02}, "Total num played games": 5504, "Total num trained steps": 10705, "Timestamp in ms": 1699618520442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9455302207745204, "Avg loss": 2.008621535729617, "Avg value loss": 1.684854342136532, "Avg policy loss": 0.3237671760143712, "Total num played games": 5526, "Total num trained steps": 10752, "Timestamp in ms": 1699618545238, "logtype": "training_step"}
{"Total num played games": 5575, "Total num trained steps": 10839, "Timestamp in ms": 1699618691827, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.80859375}
{"Ratio train steps to played games": 1.935254357879758, "Avg loss": 2.8967107189819217, "Avg value loss": 2.5818478369619697, "Avg policy loss": 0.31486289529129863, "Total num played games": 5622, "Total num trained steps": 10880, "Timestamp in ms": 1699618714678, "logtype": "training_step"}
{"Avg objective": 24.4375, "Games time in secs": 256.01549754850566, "Avg game time in secs": 5.0539662666851655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.16, "played_steps": 0.37, "reached_maximum_moves": 0.01}, "Total num played games": 5632, "Total num trained steps": 10997, "Timestamp in ms": 1699618776457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9414462081128747, "Avg loss": 1.3086793283000588, "Avg value loss": 0.9842107621952891, "Avg policy loss": 0.3244685650570318, "Total num played games": 5670, "Total num trained steps": 11008, "Timestamp in ms": 1699618781721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.945997902831178, "Avg loss": 2.1540036317892373, "Avg value loss": 1.8212028394918889, "Avg policy loss": 0.3328007939271629, "Total num played games": 5722, "Total num trained steps": 11136, "Timestamp in ms": 1699618852333, "logtype": "training_step"}
{"Avg objective": 24.9140625, "Games time in secs": 108.27364481240511, "Avg game time in secs": 4.325811147267814, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.16, "played_steps": 0.27}, "Total num played games": 5760, "Total num trained steps": 11197, "Timestamp in ms": 1699618884731, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9514899514899515, "Avg loss": 1.7832962214015424, "Avg value loss": 1.4455270471516997, "Avg policy loss": 0.3377691655186936, "Total num played games": 5772, "Total num trained steps": 11264, "Timestamp in ms": 1699618920503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948016415868673, "Avg loss": 1.760067766532302, "Avg value loss": 1.4193687331862748, "Avg policy loss": 0.34069901634939015, "Total num played games": 5848, "Total num trained steps": 11392, "Timestamp in ms": 1699618988548, "logtype": "training_step"}
{"Total num played games": 5870, "Total num trained steps": 11442, "Timestamp in ms": 1699619158352, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.2578125}
{"Avg objective": 24.359375, "Games time in secs": 278.23858397454023, "Avg game time in secs": 5.984183864726219, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.24, "played_steps": 0.56, "reached_maximum_moves": 0.01}, "Total num played games": 5888, "Total num trained steps": 11450, "Timestamp in ms": 1699619162970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9469325671793138, "Avg loss": 1.9027255261316895, "Avg value loss": 1.5632178385276347, "Avg policy loss": 0.3395076602464542, "Total num played games": 5917, "Total num trained steps": 11520, "Timestamp in ms": 1699619199302, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9523969158565202, "Avg loss": 2.877635212149471, "Avg value loss": 2.524915433488786, "Avg policy loss": 0.3527198005467653, "Total num played games": 5966, "Total num trained steps": 11648, "Timestamp in ms": 1699619266335, "logtype": "training_step"}
{"Avg objective": 24.3046875, "Games time in secs": 156.35209861956537, "Avg game time in secs": 6.277696477220161, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.18, "played_steps": 0.58, "reached_maximum_moves": 0.01}, "Total num played games": 6016, "Total num trained steps": 11747, "Timestamp in ms": 1699619319322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957280585106383, "Avg loss": 1.6331709357909858, "Avg value loss": 1.2916123224422336, "Avg policy loss": 0.34155863360501826, "Total num played games": 6016, "Total num trained steps": 11776, "Timestamp in ms": 1699619333945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9466884709730172, "Avg loss": 2.2889187172986567, "Avg value loss": 1.9476103647612035, "Avg policy loss": 0.34130837314296514, "Total num played games": 6115, "Total num trained steps": 11904, "Timestamp in ms": 1699619399812, "logtype": "training_step"}
{"Avg objective": 23.1875, "Games time in secs": 121.3671560101211, "Avg game time in secs": 4.151051842403831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.19, "played_steps": 0.26}, "Total num played games": 6144, "Total num trained steps": 11983, "Timestamp in ms": 1699619440689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.951662611516626, "Avg loss": 2.6406535087153316, "Avg value loss": 2.3030837217811495, "Avg policy loss": 0.3375697780866176, "Total num played games": 6165, "Total num trained steps": 12032, "Timestamp in ms": 1699619466271, "logtype": "training_step"}
{"Total num played games": 6165, "Total num trained steps": 12042, "Timestamp in ms": 1699619573533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.27734375}
{"Ratio train steps to played games": 1.9571865443425076, "Avg loss": 1.774197713471949, "Avg value loss": 1.4343351309653372, "Avg policy loss": 0.33986257889773697, "Total num played games": 6213, "Total num trained steps": 12160, "Timestamp in ms": 1699619635873, "logtype": "training_step"}
{"Avg objective": 24.8359375, "Games time in secs": 254.06335813179612, "Avg game time in secs": 4.18349628924625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.38, "agent_stopped_0": 0.73}, "Total num played games": 6272, "Total num trained steps": 12275, "Timestamp in ms": 1699619694753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9473851030110936, "Avg loss": 1.6014659269712865, "Avg value loss": 1.2593518160283566, "Avg policy loss": 0.3421141125727445, "Total num played games": 6310, "Total num trained steps": 12288, "Timestamp in ms": 1699619701972, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9520440251572326, "Avg loss": 1.7096802117303014, "Avg value loss": 1.3778028015512973, "Avg policy loss": 0.33187740482389927, "Total num played games": 6360, "Total num trained steps": 12416, "Timestamp in ms": 1699619767558, "logtype": "training_step"}
{"Avg objective": 23.15625, "Games time in secs": 102.1504636965692, "Avg game time in secs": 3.8754469697742024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.16, "played_steps": 0.26}, "Total num played games": 6400, "Total num trained steps": 12471, "Timestamp in ms": 1699619796903, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957553058676654, "Avg loss": 1.5500129163265228, "Avg value loss": 1.198287050705403, "Avg policy loss": 0.3517258551437408, "Total num played games": 6408, "Total num trained steps": 12544, "Timestamp in ms": 1699619833386, "logtype": "training_step"}
{"Total num played games": 6458, "Total num trained steps": 12642, "Timestamp in ms": 1699620003038, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.73828125}
{"Ratio train steps to played games": 1.9480399692544197, "Avg loss": 3.163525230716914, "Avg value loss": 2.8192794357892126, "Avg policy loss": 0.34424580936320126, "Total num played games": 6505, "Total num trained steps": 12672, "Timestamp in ms": 1699620019492, "logtype": "training_step"}
{"Avg objective": 25.015625, "Games time in secs": 267.40217318199575, "Avg game time in secs": 4.2071173793810885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.44}, "Total num played games": 6528, "Total num trained steps": 12761, "Timestamp in ms": 1699620064306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9527078565980167, "Avg loss": 1.916771444492042, "Avg value loss": 1.5647810695227236, "Avg policy loss": 0.3519903658889234, "Total num played games": 6555, "Total num trained steps": 12800, "Timestamp in ms": 1699620084241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9577464788732395, "Avg loss": 2.9522409699857235, "Avg value loss": 2.5994509030133486, "Avg policy loss": 0.35279006068594754, "Total num played games": 6603, "Total num trained steps": 12928, "Timestamp in ms": 1699620148783, "logtype": "training_step"}
{"Avg objective": 24.9765625, "Games time in secs": 149.36034782789648, "Avg game time in secs": 3.668123920549988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.36}, "Total num played games": 6656, "Total num trained steps": 13054, "Timestamp in ms": 1699620213666, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9584458445844584, "Avg loss": 1.9446405530907214, "Avg value loss": 1.5885266000404954, "Avg policy loss": 0.3561139506055042, "Total num played games": 6665, "Total num trained steps": 13056, "Timestamp in ms": 1699620214760, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9523174885236192, "Avg loss": 2.559049755334854, "Avg value loss": 2.209218179108575, "Avg policy loss": 0.3498315482866019, "Total num played games": 6753, "Total num trained steps": 13184, "Timestamp in ms": 1699620279636, "logtype": "training_step"}
{"Total num played games": 6754, "Total num trained steps": 13244, "Timestamp in ms": 1699620432621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.3671875}
{"Avg objective": 23.8828125, "Games time in secs": 223.0626904051751, "Avg game time in secs": 4.246544255685876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.86, "agent_stopped_more": 0.13, "played_steps": 0.37, "reached_maximum_moves": 0.01}, "Total num played games": 6784, "Total num trained steps": 13250, "Timestamp in ms": 1699620436729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9570714495736548, "Avg loss": 2.1317283804528415, "Avg value loss": 1.7846940166782588, "Avg policy loss": 0.34703437285497785, "Total num played games": 6802, "Total num trained steps": 13312, "Timestamp in ms": 1699620468447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9616114435848782, "Avg loss": 1.879400237929076, "Avg value loss": 1.5412572564091533, "Avg policy loss": 0.3381429791916162, "Total num played games": 6851, "Total num trained steps": 13440, "Timestamp in ms": 1699620534562, "logtype": "training_step"}
{"Avg objective": 23.8984375, "Games time in secs": 150.7687074020505, "Avg game time in secs": 3.0425078251428204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.25}, "Total num played games": 6912, "Total num trained steps": 13547, "Timestamp in ms": 1699620587498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9527921704087507, "Avg loss": 1.6481803860515356, "Avg value loss": 1.3159977190662175, "Avg policy loss": 0.33218267501797527, "Total num played games": 6948, "Total num trained steps": 13568, "Timestamp in ms": 1699620597200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9572674003144204, "Avg loss": 1.4501895383000374, "Avg value loss": 1.125101232668385, "Avg policy loss": 0.32508830924052745, "Total num played games": 6997, "Total num trained steps": 13696, "Timestamp in ms": 1699620660299, "logtype": "training_step"}
{"Avg objective": 24.0234375, "Games time in secs": 100.25315876677632, "Avg game time in secs": 3.4629273438476957, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.34}, "Total num played games": 7040, "Total num trained steps": 13749, "Timestamp in ms": 1699620687751, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9615439193983255, "Avg loss": 1.5652112499810755, "Avg value loss": 1.2300386084243655, "Avg policy loss": 0.3351726351538673, "Total num played games": 7047, "Total num trained steps": 13824, "Timestamp in ms": 1699620725930, "logtype": "training_step"}
{"Total num played games": 7096, "Total num trained steps": 13847, "Timestamp in ms": 1699620805181, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.13671875}
{"Ratio train steps to played games": 1.9528275475923853, "Avg loss": 3.6663897200487554, "Avg value loss": 3.311816185247153, "Avg policy loss": 0.3545735323568806, "Total num played games": 7144, "Total num trained steps": 13952, "Timestamp in ms": 1699620854793, "logtype": "training_step"}
{"Avg objective": 26.03125, "Games time in secs": 209.2926382496953, "Avg game time in secs": 3.422740379188326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.39, "agent_stopped_0": 0.73}, "Total num played games": 7168, "Total num trained steps": 14040, "Timestamp in ms": 1699620897044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9567755385684502, "Avg loss": 1.9383471878245473, "Avg value loss": 1.598382799886167, "Avg policy loss": 0.3399644000455737, "Total num played games": 7195, "Total num trained steps": 14080, "Timestamp in ms": 1699620914628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9610766045548653, "Avg loss": 1.7215051855891943, "Avg value loss": 1.3830304429866374, "Avg policy loss": 0.33847473631612957, "Total num played games": 7245, "Total num trained steps": 14208, "Timestamp in ms": 1699620968240, "logtype": "training_step"}
{"Avg objective": 24.1640625, "Games time in secs": 124.0931945014745, "Avg game time in secs": 3.0886002703919075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 7296, "Total num trained steps": 14335, "Timestamp in ms": 1699621021139, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9641046718728592, "Avg loss": 1.3255026312544942, "Avg value loss": 0.9971087367739528, "Avg policy loss": 0.32839390146546066, "Total num played games": 7298, "Total num trained steps": 14336, "Timestamp in ms": 1699621021366, "logtype": "training_step"}
{"Total num played games": 7393, "Total num trained steps": 14449, "Timestamp in ms": 1699621173822, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.57421875}
{"Avg objective": 23.109375, "Games time in secs": 155.98916283249855, "Avg game time in secs": 2.142280732092331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.16, "played_steps": 0.16}, "Total num played games": 7424, "Total num trained steps": 14457, "Timestamp in ms": 1699621177128, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9452589105581708, "Avg loss": 2.5434357267804444, "Avg value loss": 2.214897948782891, "Avg policy loss": 0.3285377786960453, "Total num played games": 7435, "Total num trained steps": 14464, "Timestamp in ms": 1699621179609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9610267437172424, "Avg loss": 1.5982153010554612, "Avg value loss": 1.278415001463145, "Avg policy loss": 0.3198002902790904, "Total num played games": 7441, "Total num trained steps": 14592, "Timestamp in ms": 1699621234224, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648912027766654, "Avg loss": 1.5661327703855932, "Avg value loss": 1.2590403475333005, "Avg policy loss": 0.307092436007224, "Total num played games": 7491, "Total num trained steps": 14720, "Timestamp in ms": 1699621289793, "logtype": "training_step"}
{"Avg objective": 24.390625, "Games time in secs": 157.21169461123645, "Avg game time in secs": 2.8079535728611518, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.41}, "Total num played games": 7552, "Total num trained steps": 14828, "Timestamp in ms": 1699621334340, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956384240347872, "Avg loss": 2.04537419276312, "Avg value loss": 1.7336206724867225, "Avg policy loss": 0.311753515037708, "Total num played games": 7589, "Total num trained steps": 14848, "Timestamp in ms": 1699621342338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9602094240837695, "Avg loss": 1.607697311323136, "Avg value loss": 1.2901711713057011, "Avg policy loss": 0.3175261488649994, "Total num played games": 7640, "Total num trained steps": 14976, "Timestamp in ms": 1699621394570, "logtype": "training_step"}
{"Avg objective": 24.5859375, "Games time in secs": 85.68777006864548, "Avg game time in secs": 2.381241374911042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.33}, "Total num played games": 7680, "Total num trained steps": 15035, "Timestamp in ms": 1699621420028, "logtype": "played_game"}
{"Total num played games": 7689, "Total num trained steps": 15049, "Timestamp in ms": 1699621457846, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.1171875}
{"Ratio train steps to played games": 1.9521778467106115, "Avg loss": 3.1314415810629725, "Avg value loss": 2.8182389971334487, "Avg policy loss": 0.31320256053004414, "Total num played games": 7737, "Total num trained steps": 15104, "Timestamp in ms": 1699621480639, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9568345323741008, "Avg loss": 1.5512734525837004, "Avg value loss": 1.242821453139186, "Avg policy loss": 0.3084520411211997, "Total num played games": 7784, "Total num trained steps": 15232, "Timestamp in ms": 1699621540874, "logtype": "training_step"}
{"Avg objective": 24.9765625, "Games time in secs": 163.43785079941154, "Avg game time in secs": 2.3660124392044963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.34, "agent_stopped_0": 0.71}, "Total num played games": 7808, "Total num trained steps": 15318, "Timestamp in ms": 1699621583466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960934507851398, "Avg loss": 2.6584132127463818, "Avg value loss": 2.3406975246034563, "Avg policy loss": 0.31771564274095, "Total num played games": 7833, "Total num trained steps": 15360, "Timestamp in ms": 1699621603826, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965232838472275, "Avg loss": 2.343661187682301, "Avg value loss": 2.0284393539186567, "Avg policy loss": 0.3152218443574384, "Total num played games": 7881, "Total num trained steps": 15488, "Timestamp in ms": 1699621669122, "logtype": "training_step"}
{"Avg objective": 24.3046875, "Games time in secs": 144.9077884145081, "Avg game time in secs": 2.3611274527793285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.32}, "Total num played games": 7936, "Total num trained steps": 15604, "Timestamp in ms": 1699621728374, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9581191222570533, "Avg loss": 1.5202933317050338, "Avg value loss": 1.2100098198279738, "Avg policy loss": 0.3102835202589631, "Total num played games": 7975, "Total num trained steps": 15616, "Timestamp in ms": 1699621734092, "logtype": "training_step"}
{"Total num played games": 7977, "Total num trained steps": 15650, "Timestamp in ms": 1699621808278, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4453125}
{"Ratio train steps to played games": 1.9618691588785047, "Avg loss": 1.6606764295138419, "Avg value loss": 1.367289792979136, "Avg policy loss": 0.293386617093347, "Total num played games": 8025, "Total num trained steps": 15744, "Timestamp in ms": 1699621853303, "logtype": "training_step"}
{"Avg objective": 24.5390625, "Games time in secs": 151.4435932096094, "Avg game time in secs": 1.9482277626520954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.82, "agent_stopped_more": 0.18, "played_steps": 0.2}, "Total num played games": 8064, "Total num trained steps": 15799, "Timestamp in ms": 1699621879817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96605970519014, "Avg loss": 1.7215788480825722, "Avg value loss": 1.4233333698939532, "Avg policy loss": 0.29824548272881657, "Total num played games": 8073, "Total num trained steps": 15872, "Timestamp in ms": 1699621915018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.958741429970617, "Avg loss": 2.49935967894271, "Avg value loss": 2.189771115081385, "Avg policy loss": 0.3095885639777407, "Total num played games": 8168, "Total num trained steps": 16000, "Timestamp in ms": 1699621977557, "logtype": "training_step"}
{"Avg objective": 25.2421875, "Games time in secs": 141.01719203591347, "Avg game time in secs": 2.2058849748282228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.33, "agent_stopped_0": 0.72}, "Total num played games": 8192, "Total num trained steps": 16087, "Timestamp in ms": 1699622020835, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9625212947189097, "Avg loss": 2.055154521483928, "Avg value loss": 1.7521313251927495, "Avg policy loss": 0.30302318022586405, "Total num played games": 8218, "Total num trained steps": 16128, "Timestamp in ms": 1699622040362, "logtype": "training_step"}
{"Total num played games": 8266, "Total num trained steps": 16250, "Timestamp in ms": 1699622126028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.87890625}
{"Ratio train steps to played games": 1.9571394172887069, "Avg loss": 1.6719951583072543, "Avg value loss": 1.3562124320305884, "Avg policy loss": 0.3157827139366418, "Total num played games": 8306, "Total num trained steps": 16256, "Timestamp in ms": 1699622130115, "logtype": "training_step"}
{"Avg objective": 26.6171875, "Games time in secs": 166.6994751188904, "Avg game time in secs": 2.3096352262218716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.42}, "Total num played games": 8320, "Total num trained steps": 16374, "Timestamp in ms": 1699622187534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9598086124401914, "Avg loss": 2.7934007113799453, "Avg value loss": 2.4731448218226433, "Avg policy loss": 0.32025589793920517, "Total num played games": 8360, "Total num trained steps": 16384, "Timestamp in ms": 1699622192088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9633769322235435, "Avg loss": 1.591071955859661, "Avg value loss": 1.2729572672396898, "Avg policy loss": 0.3181147037539631, "Total num played games": 8410, "Total num trained steps": 16512, "Timestamp in ms": 1699622254235, "logtype": "training_step"}
{"Avg objective": 23.53125, "Games time in secs": 93.99165040813386, "Avg game time in secs": 1.8933491365460213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.28}, "Total num played games": 8448, "Total num trained steps": 16567, "Timestamp in ms": 1699622281526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9672499408843698, "Avg loss": 1.9078460927121341, "Avg value loss": 1.588361506583169, "Avg policy loss": 0.31948458473198116, "Total num played games": 8458, "Total num trained steps": 16640, "Timestamp in ms": 1699622319793, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9600233781414378, "Avg loss": 1.8975577265955508, "Avg value loss": 1.5761773935519159, "Avg policy loss": 0.32138035830575973, "Total num played games": 8555, "Total num trained steps": 16768, "Timestamp in ms": 1699622375884, "logtype": "training_step"}
{"Total num played games": 8556, "Total num trained steps": 16850, "Timestamp in ms": 1699622430927, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1328125}
{"Avg objective": 25.125, "Games time in secs": 151.35970304347575, "Avg game time in secs": 1.7723385359859094, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.27}, "Total num played games": 8576, "Total num trained steps": 16853, "Timestamp in ms": 1699622432886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9636215713621572, "Avg loss": 1.6571731939911842, "Avg value loss": 1.3563643619418144, "Avg policy loss": 0.30080882273614407, "Total num played games": 8604, "Total num trained steps": 16896, "Timestamp in ms": 1699622450704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674101467699063, "Avg loss": 2.570166213437915, "Avg value loss": 2.2559052787255496, "Avg policy loss": 0.31426093506161124, "Total num played games": 8653, "Total num trained steps": 17024, "Timestamp in ms": 1699622503820, "logtype": "training_step"}
{"Avg objective": 24.515625, "Games time in secs": 86.76178641617298, "Avg game time in secs": 1.9073123908310663, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 8704, "Total num trained steps": 17065, "Timestamp in ms": 1699622519648, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9704733455882353, "Avg loss": 1.3167168982326984, "Avg value loss": 0.9977199141867459, "Avg policy loss": 0.31899697333574295, "Total num played games": 8704, "Total num trained steps": 17152, "Timestamp in ms": 1699622555176, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9630765735060214, "Avg loss": 1.8310688557103276, "Avg value loss": 1.5199887747876346, "Avg policy loss": 0.3110800815047696, "Total num played games": 8802, "Total num trained steps": 17280, "Timestamp in ms": 1699622604573, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 115.24704040773213, "Avg game time in secs": 1.6472376953315688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.22}, "Total num played games": 8832, "Total num trained steps": 17354, "Timestamp in ms": 1699622634895, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9660040659588887, "Avg loss": 2.0326128397136927, "Avg value loss": 1.723277296172455, "Avg policy loss": 0.3093355396995321, "Total num played games": 8854, "Total num trained steps": 17408, "Timestamp in ms": 1699622657095, "logtype": "training_step"}
{"Total num played games": 8854, "Total num trained steps": 17451, "Timestamp in ms": 1699622770493, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.3515625}
{"Ratio train steps to played games": 1.969673143884084, "Avg loss": 1.9823859874159098, "Avg value loss": 1.6513302146922797, "Avg policy loss": 0.3310557754011825, "Total num played games": 8903, "Total num trained steps": 17536, "Timestamp in ms": 1699622807124, "logtype": "training_step"}
{"Avg objective": 25.90625, "Games time in secs": 224.3110076598823, "Avg game time in secs": 1.9258257898909505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.44, "agent_stopped_0": 0.64}, "Total num played games": 8960, "Total num trained steps": 17663, "Timestamp in ms": 1699622859206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968899788206443, "Avg loss": 1.827416763175279, "Avg value loss": 1.4935825357679278, "Avg policy loss": 0.3338342073839158, "Total num played games": 8971, "Total num trained steps": 17664, "Timestamp in ms": 1699622859489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964553886925795, "Avg loss": 2.0528074870817363, "Avg value loss": 1.716517626075074, "Avg policy loss": 0.33628985681571066, "Total num played games": 9056, "Total num trained steps": 17792, "Timestamp in ms": 1699622912962, "logtype": "training_step"}
{"Avg objective": 24.28125, "Games time in secs": 81.58038976788521, "Avg game time in secs": 1.602500233129831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.27}, "Total num played games": 9088, "Total num trained steps": 17859, "Timestamp in ms": 1699622940787, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9680395387149918, "Avg loss": 1.3075176980346441, "Avg value loss": 0.9771091737784445, "Avg policy loss": 0.33040851855184883, "Total num played games": 9105, "Total num trained steps": 17920, "Timestamp in ms": 1699622965010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9714878741533757, "Avg loss": 1.5408047763630748, "Avg value loss": 1.1984490863978863, "Avg policy loss": 0.34235569392330945, "Total num played games": 9154, "Total num trained steps": 18048, "Timestamp in ms": 1699623017329, "logtype": "training_step"}
{"Total num played games": 9203, "Total num trained steps": 18056, "Timestamp in ms": 1699623086562, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.92578125}
{"Avg objective": 24.6015625, "Games time in secs": 147.6201662570238, "Avg game time in secs": 1.8688842639676295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 9216, "Total num trained steps": 18060, "Timestamp in ms": 1699623088407, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9646524700032428, "Avg loss": 3.1465279939584434, "Avg value loss": 2.7970454087480903, "Avg policy loss": 0.3494826062815264, "Total num played games": 9251, "Total num trained steps": 18176, "Timestamp in ms": 1699623135352, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674298613350532, "Avg loss": 1.7057077614590526, "Avg value loss": 1.3714383845217526, "Avg policy loss": 0.33426937216427177, "Total num played games": 9303, "Total num trained steps": 18304, "Timestamp in ms": 1699623189545, "logtype": "training_step"}
{"Avg objective": 25.3515625, "Games time in secs": 123.04791044443846, "Avg game time in secs": 1.871486010713852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.39}, "Total num played games": 9344, "Total num trained steps": 18359, "Timestamp in ms": 1699623211455, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701763762693747, "Avg loss": 1.895428519230336, "Avg value loss": 1.5589904584921896, "Avg policy loss": 0.33643807971384376, "Total num played games": 9355, "Total num trained steps": 18432, "Timestamp in ms": 1699623240921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9665183301546938, "Avg loss": 1.230814031790942, "Avg value loss": 0.8859060709364712, "Avg policy loss": 0.34490797540638596, "Total num played games": 9438, "Total num trained steps": 18560, "Timestamp in ms": 1699623292029, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 120.33079288713634, "Avg game time in secs": 2.1595774695888394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 9472, "Total num trained steps": 18658, "Timestamp in ms": 1699623331786, "logtype": "played_game"}
{"Total num played games": 9504, "Total num trained steps": 18661, "Timestamp in ms": 1699623412248, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.8125}
{"Ratio train steps to played games": 1.9563442211055277, "Avg loss": 1.9669305747374892, "Avg value loss": 1.6104121163953096, "Avg policy loss": 0.35651842423249036, "Total num played games": 9552, "Total num trained steps": 18688, "Timestamp in ms": 1699623422939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9697445561139029, "Avg loss": 1.1044624792411923, "Avg value loss": 0.7510906346142292, "Avg policy loss": 0.3533718506805599, "Total num played games": 9552, "Total num trained steps": 18816, "Timestamp in ms": 1699623476008, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 165.1733474638313, "Avg game time in secs": 1.7606159931601724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.38}, "Total num played games": 9600, "Total num trained steps": 18862, "Timestamp in ms": 1699623496960, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731277991875846, "Avg loss": 1.183699999935925, "Avg value loss": 0.8458475715015084, "Avg policy loss": 0.3378524297149852, "Total num played games": 9601, "Total num trained steps": 18944, "Timestamp in ms": 1699623531044, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9662851840395916, "Avg loss": 2.2463301909156144, "Avg value loss": 1.9213076184969395, "Avg policy loss": 0.3250225610099733, "Total num played games": 9699, "Total num trained steps": 19072, "Timestamp in ms": 1699623582477, "logtype": "training_step"}
{"Avg objective": 24.25, "Games time in secs": 115.55504147149622, "Avg game time in secs": 1.6736134341481375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.33, "agent_stopped_0": 0.69}, "Total num played games": 9728, "Total num trained steps": 19147, "Timestamp in ms": 1699623612515, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9695322117357406, "Avg loss": 2.2380747171118855, "Avg value loss": 1.9076501231174916, "Avg policy loss": 0.33042460097931325, "Total num played games": 9748, "Total num trained steps": 19200, "Timestamp in ms": 1699623633217, "logtype": "training_step"}
{"Total num played games": 9797, "Total num trained steps": 19264, "Timestamp in ms": 1699623733692, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.3515625}
{"Ratio train steps to played games": 1.9631284916201117, "Avg loss": 2.2163234846666455, "Avg value loss": 1.8832778770010918, "Avg policy loss": 0.33304561697877944, "Total num played games": 9845, "Total num trained steps": 19328, "Timestamp in ms": 1699623759765, "logtype": "training_step"}
{"Avg objective": 23.359375, "Games time in secs": 191.42948938533664, "Avg game time in secs": 1.747875567889423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 9856, "Total num trained steps": 19437, "Timestamp in ms": 1699623803944, "logtype": "played_game"}
{"Ratio train steps to played games": 1.965151515151515, "Avg loss": 1.5813413900323212, "Avg value loss": 1.2609730692347512, "Avg policy loss": 0.3203683226602152, "Total num played games": 9900, "Total num trained steps": 19456, "Timestamp in ms": 1699623811013, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9675474731236813, "Avg loss": 2.3380307951010764, "Avg value loss": 2.0114387806970626, "Avg policy loss": 0.32659201335627586, "Total num played games": 9953, "Total num trained steps": 19584, "Timestamp in ms": 1699623861897, "logtype": "training_step"}
{"Avg objective": 25.796875, "Games time in secs": 87.47231516055763, "Avg game time in secs": 1.725750165656791, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 9984, "Total num trained steps": 19656, "Timestamp in ms": 1699623891417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707058588282345, "Avg loss": 1.4711695960722864, "Avg value loss": 1.125379404751584, "Avg policy loss": 0.3457901906222105, "Total num played games": 10002, "Total num trained steps": 19712, "Timestamp in ms": 1699623915041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738334494080192, "Avg loss": 1.559868366457522, "Avg value loss": 1.2158347128424793, "Avg policy loss": 0.3440336517523974, "Total num played games": 10051, "Total num trained steps": 19840, "Timestamp in ms": 1699623966425, "logtype": "training_step"}
{"Total num played games": 10100, "Total num trained steps": 19867, "Timestamp in ms": 1699624044734, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.71484375}
{"Avg objective": 24.34375, "Games time in secs": 155.080335624516, "Avg game time in secs": 1.8767345515079796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 10112, "Total num trained steps": 19871, "Timestamp in ms": 1699624046503, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9675798186834845, "Avg loss": 2.5407771239988506, "Avg value loss": 2.1769138041418046, "Avg policy loss": 0.3638633480295539, "Total num played games": 10148, "Total num trained steps": 19968, "Timestamp in ms": 1699624087114, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9706776502893009, "Avg loss": 2.438967406284064, "Avg value loss": 2.093532659811899, "Avg policy loss": 0.3454347753431648, "Total num played games": 10197, "Total num trained steps": 20096, "Timestamp in ms": 1699624139618, "logtype": "training_step"}
{"Avg objective": 25.3515625, "Games time in secs": 112.57754866965115, "Avg game time in secs": 1.7632023842452327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.38}, "Total num played games": 10240, "Total num trained steps": 20144, "Timestamp in ms": 1699624159081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737458520398203, "Avg loss": 1.9487756113521755, "Avg value loss": 1.5948274785187095, "Avg policy loss": 0.35394811630249023, "Total num played games": 10246, "Total num trained steps": 20224, "Timestamp in ms": 1699624191192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674207269914927, "Avg loss": 1.829371264204383, "Avg value loss": 1.4729629242792726, "Avg policy loss": 0.3564083168748766, "Total num played games": 10344, "Total num trained steps": 20352, "Timestamp in ms": 1699624244493, "logtype": "training_step"}
{"Avg objective": 23.984375, "Games time in secs": 120.11086509376764, "Avg game time in secs": 1.7274555822223192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 10368, "Total num trained steps": 20437, "Timestamp in ms": 1699624279192, "logtype": "played_game"}
{"Total num played games": 10393, "Total num trained steps": 20470, "Timestamp in ms": 1699624407096, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.578125}
{"Ratio train steps to played games": 1.9630943251533743, "Avg loss": 2.5526620550081134, "Avg value loss": 2.1953982543200254, "Avg policy loss": 0.3572638558689505, "Total num played games": 10432, "Total num trained steps": 20480, "Timestamp in ms": 1699624410855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737573029403315, "Avg loss": 1.8624185975641012, "Avg value loss": 1.4773639449849725, "Avg policy loss": 0.38505463826004416, "Total num played games": 10441, "Total num trained steps": 20608, "Timestamp in ms": 1699624464899, "logtype": "training_step"}
{"Avg objective": 25.4140625, "Games time in secs": 232.8060331288725, "Avg game time in secs": 1.852673017187044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.48}, "Total num played games": 10496, "Total num trained steps": 20725, "Timestamp in ms": 1699624512001, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9678276549302458, "Avg loss": 1.2153956140391529, "Avg value loss": 0.8576285394374281, "Avg policy loss": 0.35776706831529737, "Total num played games": 10537, "Total num trained steps": 20736, "Timestamp in ms": 1699624515801, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9702521484559448, "Avg loss": 3.068996006157249, "Avg value loss": 2.6960952756926417, "Avg policy loss": 0.37290075584314764, "Total num played games": 10589, "Total num trained steps": 20864, "Timestamp in ms": 1699624568037, "logtype": "training_step"}
{"Avg objective": 24.3359375, "Games time in secs": 82.4974021203816, "Avg game time in secs": 1.6153083920798963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 10624, "Total num trained steps": 20928, "Timestamp in ms": 1699624594499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973117774226901, "Avg loss": 2.566413115244359, "Avg value loss": 2.186844580573961, "Avg policy loss": 0.37956853094510734, "Total num played games": 10639, "Total num trained steps": 20992, "Timestamp in ms": 1699624620831, "logtype": "training_step"}
{"Total num played games": 10688, "Total num trained steps": 21073, "Timestamp in ms": 1699624773114, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.453125}
{"Ratio train steps to played games": 1.9672131147540983, "Avg loss": 2.2580102514475584, "Avg value loss": 1.8766927323304117, "Avg policy loss": 0.3813175328541547, "Total num played games": 10736, "Total num trained steps": 21120, "Timestamp in ms": 1699624793143, "logtype": "training_step"}
{"Avg objective": 24.5234375, "Games time in secs": 239.54962479136884, "Avg game time in secs": 1.6364541801158339, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.42, "agent_stopped_0": 0.64}, "Total num played games": 10752, "Total num trained steps": 21219, "Timestamp in ms": 1699624834048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969868347858335, "Avg loss": 1.8294854504056275, "Avg value loss": 1.4651522133499384, "Avg policy loss": 0.3643332141218707, "Total num played games": 10786, "Total num trained steps": 21248, "Timestamp in ms": 1699624844908, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972773419473927, "Avg loss": 2.1951482510194182, "Avg value loss": 1.832462778314948, "Avg policy loss": 0.3626854420872405, "Total num played games": 10835, "Total num trained steps": 21376, "Timestamp in ms": 1699624896676, "logtype": "training_step"}
{"Avg objective": 24.78125, "Games time in secs": 81.34771608002484, "Avg game time in secs": 1.575713361002272, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.51}, "Total num played games": 10880, "Total num trained steps": 21422, "Timestamp in ms": 1699624915396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756523337008454, "Avg loss": 1.740382479969412, "Avg value loss": 1.3738862939644605, "Avg policy loss": 0.36649618833325803, "Total num played games": 10884, "Total num trained steps": 21504, "Timestamp in ms": 1699624950329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9693190094683175, "Avg loss": 2.1040331283584237, "Avg value loss": 1.7376893940381706, "Avg policy loss": 0.366343738976866, "Total num played games": 10984, "Total num trained steps": 21632, "Timestamp in ms": 1699625001103, "logtype": "training_step"}
{"Total num played games": 10986, "Total num trained steps": 21676, "Timestamp in ms": 1699625102763, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.74609375}
{"Avg objective": 24.5546875, "Games time in secs": 189.86015268787742, "Avg game time in secs": 1.7813124976237305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.4, "agent_stopped_0": 0.66}, "Total num played games": 11008, "Total num trained steps": 21678, "Timestamp in ms": 1699625105257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9719956498096791, "Avg loss": 2.8903617351315916, "Avg value loss": 2.5140799379441887, "Avg policy loss": 0.376281822565943, "Total num played games": 11034, "Total num trained steps": 21760, "Timestamp in ms": 1699625139828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748263105657313, "Avg loss": 2.907018765807152, "Avg value loss": 2.536451016087085, "Avg policy loss": 0.3705677513498813, "Total num played games": 11083, "Total num trained steps": 21888, "Timestamp in ms": 1699625192449, "logtype": "training_step"}
{"Avg objective": 26.3046875, "Games time in secs": 135.8114671036601, "Avg game time in secs": 1.7575425661925692, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 11136, "Total num trained steps": 22008, "Timestamp in ms": 1699625241068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9703750111876845, "Avg loss": 1.9938222113996744, "Avg value loss": 1.6195085651706904, "Avg policy loss": 0.3743136761477217, "Total num played games": 11173, "Total num trained steps": 22016, "Timestamp in ms": 1699625243632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9716855133113702, "Avg loss": 2.205099605489522, "Avg value loss": 1.8343205247074366, "Avg policy loss": 0.3707791343331337, "Total num played games": 11231, "Total num trained steps": 22144, "Timestamp in ms": 1699625296298, "logtype": "training_step"}
{"Avg objective": 25.0078125, "Games time in secs": 83.42350621894002, "Avg game time in secs": 1.5501624694297789, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.36}, "Total num played games": 11264, "Total num trained steps": 22211, "Timestamp in ms": 1699625324492, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974293059125964, "Avg loss": 2.1473833988420665, "Avg value loss": 1.7695555216632783, "Avg policy loss": 0.3778278552927077, "Total num played games": 11281, "Total num trained steps": 22272, "Timestamp in ms": 1699625348347, "logtype": "training_step"}
{"Total num played games": 11281, "Total num trained steps": 22281, "Timestamp in ms": 1699625418161, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.78515625}
{"Ratio train steps to played games": 1.9771383175920205, "Avg loss": 1.0567127540707588, "Avg value loss": 0.6856573380064219, "Avg policy loss": 0.3710554155986756, "Total num played games": 11329, "Total num trained steps": 22400, "Timestamp in ms": 1699625468749, "logtype": "training_step"}
{"Avg objective": 23.3671875, "Games time in secs": 186.90565501898527, "Avg game time in secs": 1.692803290017764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 11392, "Total num trained steps": 22503, "Timestamp in ms": 1699625511397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708661417322835, "Avg loss": 2.6170616885647178, "Avg value loss": 2.240918410476297, "Avg policy loss": 0.3761433137115091, "Total num played games": 11430, "Total num trained steps": 22528, "Timestamp in ms": 1699625521433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9736039724714696, "Avg loss": 1.9493047008290887, "Avg value loss": 1.5631652346346527, "Avg policy loss": 0.3861394526902586, "Total num played games": 11479, "Total num trained steps": 22656, "Timestamp in ms": 1699625575186, "logtype": "training_step"}
{"Avg objective": 23.1484375, "Games time in secs": 85.80257933959365, "Avg game time in secs": 1.710854725111858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 11520, "Total num trained steps": 22711, "Timestamp in ms": 1699625597200, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976318528799445, "Avg loss": 1.6865376443602145, "Avg value loss": 1.3133338715415448, "Avg policy loss": 0.3732037525624037, "Total num played games": 11528, "Total num trained steps": 22784, "Timestamp in ms": 1699625626884, "logtype": "training_step"}
{"Total num played games": 11577, "Total num trained steps": 22884, "Timestamp in ms": 1699625704249, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.9296875}
{"Ratio train steps to played games": 1.9709247311827958, "Avg loss": 1.5041816369630396, "Avg value loss": 1.1524555108044297, "Avg policy loss": 0.35172614082694054, "Total num played games": 11625, "Total num trained steps": 22912, "Timestamp in ms": 1699625718178, "logtype": "training_step"}
{"Avg objective": 24.140625, "Games time in secs": 156.40795522741973, "Avg game time in secs": 1.6318783270544372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.43, "agent_stopped_0": 0.66}, "Total num played games": 11648, "Total num trained steps": 22998, "Timestamp in ms": 1699625753608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973192874272011, "Avg loss": 1.5636085662990808, "Avg value loss": 1.2129185694502667, "Avg policy loss": 0.3506899729836732, "Total num played games": 11676, "Total num trained steps": 23040, "Timestamp in ms": 1699625771281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975863539445629, "Avg loss": 1.7432499851565808, "Avg value loss": 1.3884360159281641, "Avg policy loss": 0.35481397074181587, "Total num played games": 11725, "Total num trained steps": 23168, "Timestamp in ms": 1699625825926, "logtype": "training_step"}
{"Avg objective": 23.1484375, "Games time in secs": 127.59066045284271, "Avg game time in secs": 1.5649668441619724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 11776, "Total num trained steps": 23294, "Timestamp in ms": 1699625881199, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973902728351127, "Avg loss": 1.8261608202010393, "Avg value loss": 1.4647050274070352, "Avg policy loss": 0.3614558121189475, "Total num played games": 11799, "Total num trained steps": 23296, "Timestamp in ms": 1699625881634, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9729615902964959, "Avg loss": 3.1908019804395735, "Avg value loss": 2.8227358560543507, "Avg policy loss": 0.3680660866666585, "Total num played games": 11872, "Total num trained steps": 23424, "Timestamp in ms": 1699625933023, "logtype": "training_step"}
{"Total num played games": 11872, "Total num trained steps": 23487, "Timestamp in ms": 1699626011824, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.19921875}
{"Avg objective": 26.375, "Games time in secs": 132.73661841452122, "Avg game time in secs": 1.299877062367159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.32}, "Total num played games": 11904, "Total num trained steps": 23492, "Timestamp in ms": 1699626013936, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758389261744966, "Avg loss": 1.8794523542746902, "Avg value loss": 1.509234166936949, "Avg policy loss": 0.3702182264532894, "Total num played games": 11920, "Total num trained steps": 23552, "Timestamp in ms": 1699626039351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783607653103852, "Avg loss": 1.6543516591191292, "Avg value loss": 1.2859191817697138, "Avg policy loss": 0.3684324719943106, "Total num played games": 11969, "Total num trained steps": 23680, "Timestamp in ms": 1699626093026, "logtype": "training_step"}
{"Avg objective": 24.2734375, "Games time in secs": 121.26810831576586, "Avg game time in secs": 1.6140358995326096, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 12032, "Total num trained steps": 23782, "Timestamp in ms": 1699626135204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730648102105088, "Avg loss": 1.8343676966615021, "Avg value loss": 1.475078912684694, "Avg policy loss": 0.3592887695413083, "Total num played games": 12066, "Total num trained steps": 23808, "Timestamp in ms": 1699626146226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9756500206355758, "Avg loss": 2.369136155117303, "Avg value loss": 2.012660047970712, "Avg policy loss": 0.35647613275796175, "Total num played games": 12115, "Total num trained steps": 23936, "Timestamp in ms": 1699626199616, "logtype": "training_step"}
{"Avg objective": 25.6796875, "Games time in secs": 83.66983811557293, "Avg game time in secs": 1.49370299965085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 12160, "Total num trained steps": 23983, "Timestamp in ms": 1699626218874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978051787916153, "Avg loss": 1.658639734145254, "Avg value loss": 1.2888017976656556, "Avg policy loss": 0.36983793252147734, "Total num played games": 12165, "Total num trained steps": 24064, "Timestamp in ms": 1699626252589, "logtype": "training_step"}
{"Total num played games": 12214, "Total num trained steps": 24089, "Timestamp in ms": 1699626302739, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.08203125}
{"Ratio train steps to played games": 1.9729244821399445, "Avg loss": 4.149390258826315, "Avg value loss": 3.760816690977663, "Avg policy loss": 0.38857365818694234, "Total num played games": 12262, "Total num trained steps": 24192, "Timestamp in ms": 1699626346833, "logtype": "training_step"}
{"Avg objective": 25.8671875, "Games time in secs": 162.59882280416787, "Avg game time in secs": 1.477611137466738, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.33}, "Total num played games": 12288, "Total num trained steps": 24272, "Timestamp in ms": 1699626381473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754690926813419, "Avg loss": 1.2894025626592338, "Avg value loss": 0.9158409637166187, "Avg policy loss": 0.3735615878831595, "Total num played games": 12311, "Total num trained steps": 24320, "Timestamp in ms": 1699626401303, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774326619752487, "Avg loss": 1.4152745697647333, "Avg value loss": 1.0496668051928282, "Avg policy loss": 0.3656077687628567, "Total num played games": 12363, "Total num trained steps": 24448, "Timestamp in ms": 1699626453341, "logtype": "training_step"}
{"Avg objective": 24.1484375, "Games time in secs": 121.05267171189189, "Avg game time in secs": 1.649523866159143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 12416, "Total num trained steps": 24571, "Timestamp in ms": 1699626502526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731031714171017, "Avg loss": 1.704900287091732, "Avg value loss": 1.333639800781384, "Avg policy loss": 0.37126050097867846, "Total num played games": 12455, "Total num trained steps": 24576, "Timestamp in ms": 1699626504349, "logtype": "training_step"}
{"Total num played games": 12511, "Total num trained steps": 24695, "Timestamp in ms": 1699626577006, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.41015625}
{"Avg objective": 25.3203125, "Games time in secs": 76.59956282190979, "Avg game time in secs": 1.328855470768758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.36}, "Total num played games": 12544, "Total num trained steps": 24700, "Timestamp in ms": 1699626579125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967739365939143, "Avg loss": 2.9432402346283197, "Avg value loss": 2.578935269964859, "Avg policy loss": 0.36430495232343674, "Total num played games": 12554, "Total num trained steps": 24704, "Timestamp in ms": 1699626580624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771478620909309, "Avg loss": 2.886343467514962, "Avg value loss": 2.512490082066506, "Avg policy loss": 0.37385338556487113, "Total num played games": 12559, "Total num trained steps": 24832, "Timestamp in ms": 1699626633059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796161167512691, "Avg loss": 2.2881220085546374, "Avg value loss": 1.9236087752506137, "Avg policy loss": 0.364513267762959, "Total num played games": 12608, "Total num trained steps": 24960, "Timestamp in ms": 1699626686183, "logtype": "training_step"}
{"Avg objective": 25.734375, "Games time in secs": 150.2096795719117, "Avg game time in secs": 1.6301908084424213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 12672, "Total num trained steps": 25065, "Timestamp in ms": 1699626729335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739554646313635, "Avg loss": 2.973745687864721, "Avg value loss": 2.6064405667129904, "Avg policy loss": 0.36730516143143177, "Total num played games": 12709, "Total num trained steps": 25088, "Timestamp in ms": 1699626738064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976406960338611, "Avg loss": 2.0725342272780836, "Avg value loss": 1.6973452782258391, "Avg policy loss": 0.37518896092660725, "Total num played games": 12758, "Total num trained steps": 25216, "Timestamp in ms": 1699626790073, "logtype": "training_step"}
{"Avg objective": 24.953125, "Games time in secs": 81.1964860856533, "Avg game time in secs": 1.4210341291036457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.4}, "Total num played games": 12800, "Total num trained steps": 25267, "Timestamp in ms": 1699626810532, "logtype": "played_game"}
{"Total num played games": 12811, "Total num trained steps": 25298, "Timestamp in ms": 1699626900525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.984375}
{"Ratio train steps to played games": 1.970837545687845, "Avg loss": 2.510122451465577, "Avg value loss": 2.1198086026124656, "Avg policy loss": 0.39031383697874844, "Total num played games": 12859, "Total num trained steps": 25344, "Timestamp in ms": 1699626919557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738840669559827, "Avg loss": 1.1798325539566576, "Avg value loss": 0.8026398653164506, "Avg policy loss": 0.37719268584623933, "Total num played games": 12904, "Total num trained steps": 25472, "Timestamp in ms": 1699626971648, "logtype": "training_step"}
{"Avg objective": 24.484375, "Games time in secs": 199.78165138699114, "Avg game time in secs": 1.5932167028513504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.46, "agent_stopped_0": 0.63}, "Total num played games": 12928, "Total num trained steps": 25564, "Timestamp in ms": 1699627010313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756888168557536, "Avg loss": 3.049367986153811, "Avg value loss": 2.6641892150510103, "Avg policy loss": 0.38517875177785754, "Total num played games": 12957, "Total num trained steps": 25600, "Timestamp in ms": 1699627025620, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978163924342611, "Avg loss": 2.2745471000671387, "Avg value loss": 1.8890965953469276, "Avg policy loss": 0.38545045210048556, "Total num played games": 13006, "Total num trained steps": 25728, "Timestamp in ms": 1699627078691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980543852929912, "Avg loss": 2.109021481592208, "Avg value loss": 1.7132043498568237, "Avg policy loss": 0.3958171184640378, "Total num played games": 13055, "Total num trained steps": 25856, "Timestamp in ms": 1699627131620, "logtype": "training_step"}
{"Avg objective": 25.203125, "Games time in secs": 121.50041636824608, "Avg game time in secs": 1.7390262489498127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 13056, "Total num trained steps": 25856, "Timestamp in ms": 1699627131814, "logtype": "played_game"}
{"Total num played games": 13104, "Total num trained steps": 25903, "Timestamp in ms": 1699627224791, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.03125}
{"Ratio train steps to played games": 1.9755930656934306, "Avg loss": 3.0760971042327583, "Avg value loss": 2.6829551972914487, "Avg policy loss": 0.39314190368168056, "Total num played games": 13152, "Total num trained steps": 25984, "Timestamp in ms": 1699627257876, "logtype": "training_step"}
{"Avg objective": 23.359375, "Games time in secs": 154.30886344239116, "Avg game time in secs": 1.3227964842517395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.38}, "Total num played games": 13184, "Total num trained steps": 26052, "Timestamp in ms": 1699627286123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780319672752065, "Avg loss": 1.183123561553657, "Avg value loss": 0.7948949348647147, "Avg policy loss": 0.3882286266889423, "Total num played games": 13201, "Total num trained steps": 26112, "Timestamp in ms": 1699627310628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804513548192317, "Avg loss": 1.547110877931118, "Avg value loss": 1.1442696531303227, "Avg policy loss": 0.4028412209590897, "Total num played games": 13249, "Total num trained steps": 26240, "Timestamp in ms": 1699627364378, "logtype": "training_step"}
{"Avg objective": 24.6796875, "Games time in secs": 120.64640768431127, "Avg game time in secs": 1.5462953570531681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.49, "agent_stopped_0": 0.59}, "Total num played games": 13312, "Total num trained steps": 26343, "Timestamp in ms": 1699627406769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755001123848055, "Avg loss": 3.0744316088967025, "Avg value loss": 2.673367663519457, "Avg policy loss": 0.4010638576000929, "Total num played games": 13347, "Total num trained steps": 26368, "Timestamp in ms": 1699627416628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9778292027470887, "Avg loss": 1.617753497324884, "Avg value loss": 1.2227856495883316, "Avg policy loss": 0.39496783539652824, "Total num played games": 13396, "Total num trained steps": 26496, "Timestamp in ms": 1699627468731, "logtype": "training_step"}
{"Total num played games": 13396, "Total num trained steps": 26505, "Timestamp in ms": 1699627495562, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.1640625}
{"Avg objective": 24.265625, "Games time in secs": 92.5301504060626, "Avg game time in secs": 1.412910595201538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.46}, "Total num played games": 13440, "Total num trained steps": 26514, "Timestamp in ms": 1699627499300, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802886045819696, "Avg loss": 2.121795187704265, "Avg value loss": 1.7245771137531847, "Avg policy loss": 0.39721808047033846, "Total num played games": 13444, "Total num trained steps": 26624, "Timestamp in ms": 1699627543533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975263974008713, "Avg loss": 2.7919062436558306, "Avg value loss": 2.4021017840132117, "Avg policy loss": 0.38980447058565915, "Total num played games": 13543, "Total num trained steps": 26752, "Timestamp in ms": 1699627596772, "logtype": "training_step"}
{"Avg objective": 23.328125, "Games time in secs": 131.4308543521911, "Avg game time in secs": 1.4418098978785565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.35, "agent_stopped_0": 0.68}, "Total num played games": 13568, "Total num trained steps": 26833, "Timestamp in ms": 1699627630731, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776339022954679, "Avg loss": 2.061331074219197, "Avg value loss": 1.6755400616675615, "Avg policy loss": 0.38579100486822426, "Total num played games": 13592, "Total num trained steps": 26880, "Timestamp in ms": 1699627650025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979913496078, "Avg loss": 2.453782045748085, "Avg value loss": 2.0707572281826288, "Avg policy loss": 0.38302480592392385, "Total num played games": 13641, "Total num trained steps": 27008, "Timestamp in ms": 1699627701621, "logtype": "training_step"}
{"Total num played games": 13692, "Total num trained steps": 27110, "Timestamp in ms": 1699627809129, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.9921875}
{"Avg objective": 24.8046875, "Games time in secs": 179.76278822124004, "Avg game time in secs": 1.606437232796452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 13696, "Total num trained steps": 27111, "Timestamp in ms": 1699627810494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974890829694323, "Avg loss": 3.1176793165504932, "Avg value loss": 2.7438435384538025, "Avg policy loss": 0.37383578019216657, "Total num played games": 13740, "Total num trained steps": 27136, "Timestamp in ms": 1699627820291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977012327773749, "Avg loss": 2.1848351694643497, "Avg value loss": 1.8002821889240295, "Avg policy loss": 0.3845529726240784, "Total num played games": 13790, "Total num trained steps": 27264, "Timestamp in ms": 1699627873039, "logtype": "training_step"}
{"Avg objective": 24.9453125, "Games time in secs": 88.58023157343268, "Avg game time in secs": 1.3651019651006209, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.36}, "Total num played games": 13824, "Total num trained steps": 27328, "Timestamp in ms": 1699627899074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979261507334345, "Avg loss": 1.3599008088931441, "Avg value loss": 0.9858802850358188, "Avg policy loss": 0.37402050173841417, "Total num played games": 13839, "Total num trained steps": 27392, "Timestamp in ms": 1699627926583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814948156682028, "Avg loss": 2.664718029089272, "Avg value loss": 2.2985705914907157, "Avg policy loss": 0.3661474499385804, "Total num played games": 13888, "Total num trained steps": 27520, "Timestamp in ms": 1699627979247, "logtype": "training_step"}
{"Avg objective": 25.5234375, "Games time in secs": 120.66013273596764, "Avg game time in secs": 1.5952408107259544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 13952, "Total num trained steps": 27621, "Timestamp in ms": 1699628019734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767624767624767, "Avg loss": 2.551210645120591, "Avg value loss": 2.1685315743088722, "Avg policy loss": 0.38267906475812197, "Total num played games": 13986, "Total num trained steps": 27648, "Timestamp in ms": 1699628030765, "logtype": "training_step"}
{"Total num played games": 13986, "Total num trained steps": 27710, "Timestamp in ms": 1699628080700, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.07421875}
{"Ratio train steps to played games": 1.9791221319652272, "Avg loss": 2.7608100660145283, "Avg value loss": 2.3708788850344718, "Avg policy loss": 0.3899312245193869, "Total num played games": 14034, "Total num trained steps": 27776, "Timestamp in ms": 1699628108442, "logtype": "training_step"}
{"Avg objective": 25.9609375, "Games time in secs": 106.19895910099149, "Avg game time in secs": 1.4994363025034545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 14080, "Total num trained steps": 27820, "Timestamp in ms": 1699628125933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98132500177519, "Avg loss": 1.887178429402411, "Avg value loss": 1.4965149231720716, "Avg policy loss": 0.39066351228393614, "Total num played games": 14083, "Total num trained steps": 27904, "Timestamp in ms": 1699628161748, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767983074753173, "Avg loss": 2.2884410177357495, "Avg value loss": 1.8859176635742188, "Avg policy loss": 0.4025233427528292, "Total num played games": 14180, "Total num trained steps": 28032, "Timestamp in ms": 1699628214390, "logtype": "training_step"}
{"Avg objective": 23.765625, "Games time in secs": 119.68452615663409, "Avg game time in secs": 1.322058262929204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.39, "agent_stopped_0": 0.66}, "Total num played games": 14208, "Total num trained steps": 28109, "Timestamp in ms": 1699628245618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978986576709537, "Avg loss": 2.054816067684442, "Avg value loss": 1.6531341506633908, "Avg policy loss": 0.4016819142270833, "Total num played games": 14229, "Total num trained steps": 28160, "Timestamp in ms": 1699628267721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812298641266284, "Avg loss": 1.8620597696863115, "Avg value loss": 1.4556310118641704, "Avg policy loss": 0.4064287443179637, "Total num played games": 14278, "Total num trained steps": 28288, "Timestamp in ms": 1699628321770, "logtype": "training_step"}
{"Total num played games": 14329, "Total num trained steps": 28312, "Timestamp in ms": 1699628346775, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.15625}
{"Avg objective": 25.734375, "Games time in secs": 102.5591680817306, "Avg game time in secs": 1.5503804465115536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 14336, "Total num trained steps": 28314, "Timestamp in ms": 1699628348177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976490227446616, "Avg loss": 4.4785113097168505, "Avg value loss": 4.066368895582855, "Avg policy loss": 0.41214246512390673, "Total num played games": 14377, "Total num trained steps": 28416, "Timestamp in ms": 1699628388930, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977690015935703, "Avg loss": 1.9180207471363246, "Avg value loss": 1.5144858392886817, "Avg policy loss": 0.4035349013283849, "Total num played games": 14433, "Total num trained steps": 28544, "Timestamp in ms": 1699628443734, "logtype": "training_step"}
{"Avg objective": 25.484375, "Games time in secs": 124.84060028009117, "Avg game time in secs": 1.3389469491812633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 14464, "Total num trained steps": 28613, "Timestamp in ms": 1699628473018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9797679878469825, "Avg loss": 1.4132630117237568, "Avg value loss": 1.0188609664328396, "Avg policy loss": 0.3944020257331431, "Total num played games": 14482, "Total num trained steps": 28672, "Timestamp in ms": 1699628497105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819007638841097, "Avg loss": 2.065807305276394, "Avg value loss": 1.6699839727953076, "Avg policy loss": 0.3958233571611345, "Total num played games": 14531, "Total num trained steps": 28800, "Timestamp in ms": 1699628549139, "logtype": "training_step"}
{"Avg objective": 24.8671875, "Games time in secs": 118.80757294781506, "Avg game time in secs": 1.3733823757065693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 14592, "Total num trained steps": 28907, "Timestamp in ms": 1699628591826, "logtype": "played_game"}
{"Total num played games": 14629, "Total num trained steps": 28914, "Timestamp in ms": 1699628645295, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.62890625}
{"Ratio train steps to played games": 1.9709068610751517, "Avg loss": 2.6801310158334672, "Avg value loss": 2.2855937068816274, "Avg policy loss": 0.3945372924208641, "Total num played games": 14677, "Total num trained steps": 28928, "Timestamp in ms": 1699628651360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796279893711248, "Avg loss": 2.1840457343496382, "Avg value loss": 1.7792278314009309, "Avg policy loss": 0.4048178941011429, "Total num played games": 14677, "Total num trained steps": 29056, "Timestamp in ms": 1699628704503, "logtype": "training_step"}
{"Avg objective": 24.5078125, "Games time in secs": 132.42769998311996, "Avg game time in secs": 1.1648858776316047, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.38}, "Total num played games": 14720, "Total num trained steps": 29104, "Timestamp in ms": 1699628724253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814638783269962, "Avg loss": 1.1325234919786453, "Avg value loss": 0.7478120133746415, "Avg policy loss": 0.384711479768157, "Total num played games": 14728, "Total num trained steps": 29184, "Timestamp in ms": 1699628757176, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977133220910624, "Avg loss": 3.1521996022202075, "Avg value loss": 2.7707464455161244, "Avg policy loss": 0.3814531157258898, "Total num played games": 14825, "Total num trained steps": 29312, "Timestamp in ms": 1699628809413, "logtype": "training_step"}
{"Avg objective": 24.1484375, "Games time in secs": 121.68309872411191, "Avg game time in secs": 1.3793733184429584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 14848, "Total num trained steps": 29398, "Timestamp in ms": 1699628845937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97909243697479, "Avg loss": 2.564618209376931, "Avg value loss": 2.1821000576019287, "Avg policy loss": 0.3825181284919381, "Total num played games": 14875, "Total num trained steps": 29440, "Timestamp in ms": 1699628862570, "logtype": "training_step"}
{"Total num played games": 14924, "Total num trained steps": 29518, "Timestamp in ms": 1699628919954, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.08203125}
{"Ratio train steps to played games": 1.974819663371627, "Avg loss": 3.0439070453867316, "Avg value loss": 2.648239279165864, "Avg policy loss": 0.39566778228618205, "Total num played games": 14972, "Total num trained steps": 29568, "Timestamp in ms": 1699628940709, "logtype": "training_step"}
{"Avg objective": 24.921875, "Games time in secs": 145.46571975015104, "Avg game time in secs": 1.4858892421470955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 14976, "Total num trained steps": 29690, "Timestamp in ms": 1699628991402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776889776889777, "Avg loss": 1.1699154181405902, "Avg value loss": 0.779232733650133, "Avg policy loss": 0.39068267797119915, "Total num played games": 15015, "Total num trained steps": 29696, "Timestamp in ms": 1699628993412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789648307896484, "Avg loss": 2.6990596624091268, "Avg value loss": 2.3041510032489896, "Avg policy loss": 0.394908674294129, "Total num played games": 15070, "Total num trained steps": 29824, "Timestamp in ms": 1699629046192, "logtype": "training_step"}
{"Avg objective": 25.1171875, "Games time in secs": 81.25528503209352, "Avg game time in secs": 1.3279060826462228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 15104, "Total num trained steps": 29889, "Timestamp in ms": 1699629072658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807552410554858, "Avg loss": 2.2189121493138373, "Avg value loss": 1.8163982529658824, "Avg policy loss": 0.40251385094597936, "Total num played games": 15121, "Total num trained steps": 29952, "Timestamp in ms": 1699629098820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827949901120634, "Avg loss": 2.5515295122750103, "Avg value loss": 2.1528116478584707, "Avg policy loss": 0.3987178886309266, "Total num played games": 15170, "Total num trained steps": 30080, "Timestamp in ms": 1699629152981, "logtype": "training_step"}
{"Total num played games": 15220, "Total num trained steps": 30122, "Timestamp in ms": 1699629185147, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.96484375}
{"Avg objective": 26.609375, "Games time in secs": 113.97861399315298, "Avg game time in secs": 1.4935795712517574, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 15232, "Total num trained steps": 30124, "Timestamp in ms": 1699629186637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978517160073356, "Avg loss": 3.5811081221327186, "Avg value loss": 3.1508687955792993, "Avg policy loss": 0.4302393498364836, "Total num played games": 15268, "Total num trained steps": 30208, "Timestamp in ms": 1699629222088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800913838120104, "Avg loss": 2.6402133936062455, "Avg value loss": 2.2317083622328937, "Avg policy loss": 0.4085050045978278, "Total num played games": 15320, "Total num trained steps": 30336, "Timestamp in ms": 1699629274899, "logtype": "training_step"}
{"Avg objective": 25.90625, "Games time in secs": 110.47739013656974, "Avg game time in secs": 1.3787175213074079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 15360, "Total num trained steps": 30391, "Timestamp in ms": 1699629297114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819778789850357, "Avg loss": 1.6311589092947543, "Avg value loss": 1.2087097715120763, "Avg policy loss": 0.422449151519686, "Total num played games": 15370, "Total num trained steps": 30464, "Timestamp in ms": 1699629328963, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9778237537984096, "Avg loss": 1.9382247161120176, "Avg value loss": 1.5223462958820164, "Avg policy loss": 0.41587843210436404, "Total num played games": 15467, "Total num trained steps": 30592, "Timestamp in ms": 1699629381521, "logtype": "training_step"}
{"Avg objective": 24.5, "Games time in secs": 123.42822789400816, "Avg game time in secs": 1.4896483722113771, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 15488, "Total num trained steps": 30687, "Timestamp in ms": 1699629420543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793170103092783, "Avg loss": 1.852604913059622, "Avg value loss": 1.452698717592284, "Avg policy loss": 0.399906191509217, "Total num played games": 15520, "Total num trained steps": 30720, "Timestamp in ms": 1699629433723, "logtype": "training_step"}
{"Total num played games": 15520, "Total num trained steps": 30724, "Timestamp in ms": 1699629449677, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 34.40625}
{"Ratio train steps to played games": 1.9815005138746147, "Avg loss": 1.6123341186903417, "Avg value loss": 1.2074607694521546, "Avg policy loss": 0.40487335808575153, "Total num played games": 15568, "Total num trained steps": 30848, "Timestamp in ms": 1699629501466, "logtype": "training_step"}
{"Avg objective": 24.3359375, "Games time in secs": 96.67802514880896, "Avg game time in secs": 1.272366396675352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 15616, "Total num trained steps": 30887, "Timestamp in ms": 1699629517221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827806938932275, "Avg loss": 1.7203740323893726, "Avg value loss": 1.3297928201500326, "Avg policy loss": 0.3905812092125416, "Total num played games": 15622, "Total num trained steps": 30976, "Timestamp in ms": 1699629553834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9781848247789862, "Avg loss": 1.74010511348024, "Avg value loss": 1.3578213963191956, "Avg policy loss": 0.38228371809236705, "Total num played games": 15723, "Total num trained steps": 31104, "Timestamp in ms": 1699629604481, "logtype": "training_step"}
{"Avg objective": 24.765625, "Games time in secs": 122.62410181388259, "Avg game time in secs": 1.3003094109590165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 15744, "Total num trained steps": 31192, "Timestamp in ms": 1699629639845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980280261238983, "Avg loss": 3.2891523642465472, "Avg value loss": 2.8896060476545244, "Avg policy loss": 0.39954629563726485, "Total num played games": 15771, "Total num trained steps": 31232, "Timestamp in ms": 1699629656158, "logtype": "training_step"}
{"Total num played games": 15821, "Total num trained steps": 31325, "Timestamp in ms": 1699629718820, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.01171875}
{"Ratio train steps to played games": 1.9761169575902704, "Avg loss": 4.19793760869652, "Avg value loss": 3.7797859655693173, "Avg policy loss": 0.4181516105309129, "Total num played games": 15869, "Total num trained steps": 31360, "Timestamp in ms": 1699629733990, "logtype": "training_step"}
{"Avg objective": 26.4765625, "Games time in secs": 145.51702890731394, "Avg game time in secs": 1.3567929012933746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 15872, "Total num trained steps": 31484, "Timestamp in ms": 1699629785362, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786966631056369, "Avg loss": 1.299997290596366, "Avg value loss": 0.896466848673299, "Avg policy loss": 0.4035304426215589, "Total num played games": 15912, "Total num trained steps": 31488, "Timestamp in ms": 1699629787023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795253897689562, "Avg loss": 2.606734102591872, "Avg value loss": 2.1950195708777755, "Avg policy loss": 0.4117145398631692, "Total num played games": 15971, "Total num trained steps": 31616, "Timestamp in ms": 1699629838411, "logtype": "training_step"}
{"Avg objective": 23.59375, "Games time in secs": 84.35344802029431, "Avg game time in secs": 1.258172692352673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.35}, "Total num played games": 16000, "Total num trained steps": 31690, "Timestamp in ms": 1699629869716, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813369951938082, "Avg loss": 2.084719361271709, "Avg value loss": 1.6774016574490815, "Avg policy loss": 0.4073177338577807, "Total num played games": 16021, "Total num trained steps": 31744, "Timestamp in ms": 1699629892313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832607342874922, "Avg loss": 2.204205417074263, "Avg value loss": 1.8004034541081637, "Avg policy loss": 0.4038019485305995, "Total num played games": 16070, "Total num trained steps": 31872, "Timestamp in ms": 1699629945380, "logtype": "training_step"}
{"Total num played games": 16120, "Total num trained steps": 31930, "Timestamp in ms": 1699629987044, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.09765625}
{"Avg objective": 24.6015625, "Games time in secs": 118.52241254411638, "Avg game time in secs": 1.5235603879991686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 16128, "Total num trained steps": 31932, "Timestamp in ms": 1699629988238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979156358238496, "Avg loss": 1.6853204178623855, "Avg value loss": 1.278293474810198, "Avg policy loss": 0.40702692745253444, "Total num played games": 16168, "Total num trained steps": 32000, "Timestamp in ms": 1699630016661, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807028360049321, "Avg loss": 1.7384862401522696, "Avg value loss": 1.34959823184181, "Avg policy loss": 0.3888879984151572, "Total num played games": 16220, "Total num trained steps": 32128, "Timestamp in ms": 1699630069430, "logtype": "training_step"}
{"Avg objective": 23.59375, "Games time in secs": 105.43498247303069, "Avg game time in secs": 1.0748398894647835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 16256, "Total num trained steps": 32189, "Timestamp in ms": 1699630093673, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826049542073882, "Avg loss": 1.744867600966245, "Avg value loss": 1.3423798130825162, "Avg policy loss": 0.4024877690244466, "Total num played games": 16269, "Total num trained steps": 32256, "Timestamp in ms": 1699630121088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841308743336805, "Avg loss": 1.736667627003044, "Avg value loss": 1.3396851290017366, "Avg policy loss": 0.3969825142994523, "Total num played games": 16321, "Total num trained steps": 32384, "Timestamp in ms": 1699630172705, "logtype": "training_step"}
{"Avg objective": 23.734375, "Games time in secs": 123.19760338962078, "Avg game time in secs": 1.3038354071759386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 16384, "Total num trained steps": 32490, "Timestamp in ms": 1699630216871, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9797223237120936, "Avg loss": 2.1378673133440316, "Avg value loss": 1.7421138635836542, "Avg policy loss": 0.3957534416113049, "Total num played games": 16422, "Total num trained steps": 32512, "Timestamp in ms": 1699630225754, "logtype": "training_step"}
{"Total num played games": 16422, "Total num trained steps": 32533, "Timestamp in ms": 1699630293917, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.3984375}
{"Ratio train steps to played games": 1.9817243472981179, "Avg loss": 2.8798422780819237, "Avg value loss": 2.4699840350076556, "Avg policy loss": 0.40985826309770346, "Total num played games": 16470, "Total num trained steps": 32640, "Timestamp in ms": 1699630337254, "logtype": "training_step"}
{"Avg objective": 25.2421875, "Games time in secs": 139.82072669640183, "Avg game time in secs": 1.1155091242544586, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 16512, "Total num trained steps": 32689, "Timestamp in ms": 1699630356692, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832344752451276, "Avg loss": 1.6008893912658095, "Avg value loss": 1.205461369594559, "Avg policy loss": 0.39542804611846805, "Total num played games": 16522, "Total num trained steps": 32768, "Timestamp in ms": 1699630389865, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794211444731933, "Avg loss": 0.8395862290635705, "Avg value loss": 0.4608740545809269, "Avg policy loss": 0.3787121744826436, "Total num played games": 16619, "Total num trained steps": 32896, "Timestamp in ms": 1699630441169, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 122.70863983035088, "Avg game time in secs": 1.246604746513185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.37, "agent_stopped_0": 0.66}, "Total num played games": 16640, "Total num trained steps": 32992, "Timestamp in ms": 1699630479401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980746161228407, "Avg loss": 1.212744168471545, "Avg value loss": 0.842782577383332, "Avg policy loss": 0.36996159702539444, "Total num played games": 16672, "Total num trained steps": 33024, "Timestamp in ms": 1699630491910, "logtype": "training_step"}
{"Total num played games": 16721, "Total num trained steps": 33133, "Timestamp in ms": 1699630574582, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.875}
{"Avg objective": 23.7109375, "Games time in secs": 98.34940490871668, "Avg game time in secs": 1.2807180836971384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 16768, "Total num trained steps": 33141, "Timestamp in ms": 1699630577750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769217007573499, "Avg loss": 2.267817824613303, "Avg value loss": 1.901515422621742, "Avg policy loss": 0.3663024252746254, "Total num played games": 16769, "Total num trained steps": 33152, "Timestamp in ms": 1699630582315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845548333233944, "Avg loss": 1.3154997290112078, "Avg value loss": 0.9351434099953622, "Avg policy loss": 0.3803563091205433, "Total num played games": 16769, "Total num trained steps": 33280, "Timestamp in ms": 1699630639653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804956129950202, "Avg loss": 3.061134787276387, "Avg value loss": 2.6814792489167303, "Avg policy loss": 0.37965552997775376, "Total num played games": 16868, "Total num trained steps": 33408, "Timestamp in ms": 1699630692000, "logtype": "training_step"}
{"Avg objective": 25.7890625, "Games time in secs": 145.42771587334573, "Avg game time in secs": 1.1521278671862092, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.32, "agent_stopped_0": 0.71}, "Total num played games": 16896, "Total num trained steps": 33483, "Timestamp in ms": 1699630723178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823254714192824, "Avg loss": 3.1691998108290136, "Avg value loss": 2.7834418662823737, "Avg policy loss": 0.38575800065882504, "Total num played games": 16917, "Total num trained steps": 33536, "Timestamp in ms": 1699630746261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984144760108452, "Avg loss": 3.748919924721122, "Avg value loss": 3.3552192349452525, "Avg policy loss": 0.39370070677250624, "Total num played games": 16966, "Total num trained steps": 33664, "Timestamp in ms": 1699630799902, "logtype": "training_step"}
{"Total num played games": 17015, "Total num trained steps": 33734, "Timestamp in ms": 1699630843991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.94140625}
{"Avg objective": 27.3125, "Games time in secs": 122.15347850136459, "Avg game time in secs": 1.4167647072317777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 17024, "Total num trained steps": 33736, "Timestamp in ms": 1699630845332, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803668756959503, "Avg loss": 3.3792450856417418, "Avg value loss": 2.962105386191979, "Avg policy loss": 0.41713967989198864, "Total num played games": 17063, "Total num trained steps": 33792, "Timestamp in ms": 1699630867866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818288051416886, "Avg loss": 1.2461905661039054, "Avg value loss": 0.8470912852790207, "Avg policy loss": 0.3990992824546993, "Total num played games": 17115, "Total num trained steps": 33920, "Timestamp in ms": 1699630920523, "logtype": "training_step"}
{"Avg objective": 23.625, "Games time in secs": 99.36673196405172, "Avg game time in secs": 1.313778077645111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.47}, "Total num played games": 17152, "Total num trained steps": 33979, "Timestamp in ms": 1699630944700, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836867862969005, "Avg loss": 2.624250642955303, "Avg value loss": 2.2333329839166254, "Avg policy loss": 0.3909176988527179, "Total num played games": 17164, "Total num trained steps": 34048, "Timestamp in ms": 1699630971757, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9810445771259637, "Avg loss": 1.6285063647665083, "Avg value loss": 1.2330343364737928, "Avg policy loss": 0.39547201804816723, "Total num played games": 17251, "Total num trained steps": 34176, "Timestamp in ms": 1699631023266, "logtype": "training_step"}
{"Avg objective": 24.2734375, "Games time in secs": 119.2097047585994, "Avg game time in secs": 1.3828277042339323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.5, "agent_stopped_0": 0.56}, "Total num played games": 17280, "Total num trained steps": 34273, "Timestamp in ms": 1699631063910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815724106059731, "Avg loss": 2.130936619825661, "Avg value loss": 1.742410165257752, "Avg policy loss": 0.3885264650452882, "Total num played games": 17311, "Total num trained steps": 34304, "Timestamp in ms": 1699631076272, "logtype": "training_step"}
{"Total num played games": 17311, "Total num trained steps": 34337, "Timestamp in ms": 1699631117961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.5234375}
{"Ratio train steps to played games": 1.9834667895616107, "Avg loss": 1.9410064714029431, "Avg value loss": 1.5416181269101799, "Avg policy loss": 0.3993883468210697, "Total num played games": 17359, "Total num trained steps": 34432, "Timestamp in ms": 1699631157370, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852941176470589, "Avg loss": 1.7089642849750817, "Avg value loss": 1.311488812090829, "Avg policy loss": 0.3974754544906318, "Total num played games": 17407, "Total num trained steps": 34560, "Timestamp in ms": 1699631209209, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 145.30118273571134, "Avg game time in secs": 1.3270109331351705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 17408, "Total num trained steps": 34560, "Timestamp in ms": 1699631209211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981095436632589, "Avg loss": 1.9039754290133715, "Avg value loss": 1.5099853952415287, "Avg policy loss": 0.39399000396952033, "Total num played games": 17509, "Total num trained steps": 34688, "Timestamp in ms": 1699631260201, "logtype": "training_step"}
{"Avg objective": 23.28125, "Games time in secs": 82.85397201217711, "Avg game time in secs": 1.2501723155146465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 17536, "Total num trained steps": 34766, "Timestamp in ms": 1699631292065, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825750242013553, "Avg loss": 1.8595876153558493, "Avg value loss": 1.4715305583085865, "Avg policy loss": 0.3880570519249886, "Total num played games": 17561, "Total num trained steps": 34816, "Timestamp in ms": 1699631312898, "logtype": "training_step"}
{"Total num played games": 17610, "Total num trained steps": 34941, "Timestamp in ms": 1699631397947, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.58984375}
{"Ratio train steps to played games": 1.9824133431667328, "Avg loss": 1.8789470889605582, "Avg value loss": 1.487464975565672, "Avg policy loss": 0.3914821078069508, "Total num played games": 17626, "Total num trained steps": 34944, "Timestamp in ms": 1699631399748, "logtype": "training_step"}
{"Avg objective": 23.8984375, "Games time in secs": 156.10061445832253, "Avg game time in secs": 1.479324183135759, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 17664, "Total num trained steps": 35062, "Timestamp in ms": 1699631448166, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801818079159845, "Avg loss": 1.815697823651135, "Avg value loss": 1.42318495339714, "Avg policy loss": 0.39251288189552724, "Total num played games": 17711, "Total num trained steps": 35072, "Timestamp in ms": 1699631451833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981647244271801, "Avg loss": 1.6558622969314456, "Avg value loss": 1.268768209265545, "Avg policy loss": 0.38709408324211836, "Total num played games": 17763, "Total num trained steps": 35200, "Timestamp in ms": 1699631505024, "logtype": "training_step"}
{"Avg objective": 22.5, "Games time in secs": 86.88006331212819, "Avg game time in secs": 1.1634646637394326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.38}, "Total num played games": 17792, "Total num trained steps": 35273, "Timestamp in ms": 1699631535046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829366861248316, "Avg loss": 1.96917234826833, "Avg value loss": 1.584278464433737, "Avg policy loss": 0.38489386974833906, "Total num played games": 17816, "Total num trained steps": 35328, "Timestamp in ms": 1699631557277, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984717868338558, "Avg loss": 1.5695090224035084, "Avg value loss": 1.1826334905344993, "Avg policy loss": 0.3868755411822349, "Total num played games": 17864, "Total num trained steps": 35456, "Timestamp in ms": 1699631609458, "logtype": "training_step"}
{"Total num played games": 17914, "Total num trained steps": 35544, "Timestamp in ms": 1699631669360, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.8125}
{"Avg objective": 24.359375, "Games time in secs": 135.80898972414434, "Avg game time in secs": 1.3838199929014081, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 17920, "Total num trained steps": 35546, "Timestamp in ms": 1699631670856, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981015477118361, "Avg loss": 2.7396183921955526, "Avg value loss": 2.363531514070928, "Avg policy loss": 0.37608684273436666, "Total num played games": 17962, "Total num trained steps": 35584, "Timestamp in ms": 1699631686207, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824025757743977, "Avg loss": 1.724456315394491, "Avg value loss": 1.336401604115963, "Avg policy loss": 0.3880546875298023, "Total num played games": 18014, "Total num trained steps": 35712, "Timestamp in ms": 1699631738497, "logtype": "training_step"}
{"Avg objective": 23.875, "Games time in secs": 92.62177796661854, "Avg game time in secs": 1.2816496729356004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 18048, "Total num trained steps": 35776, "Timestamp in ms": 1699631763477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984001328609389, "Avg loss": 1.7155720675364137, "Avg value loss": 1.3394801854155958, "Avg policy loss": 0.37609189515933394, "Total num played games": 18064, "Total num trained steps": 35840, "Timestamp in ms": 1699631790730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858105123674912, "Avg loss": 1.6304427655413747, "Avg value loss": 1.2527609190437943, "Avg policy loss": 0.3776818532496691, "Total num played games": 18112, "Total num trained steps": 35968, "Timestamp in ms": 1699631845236, "logtype": "training_step"}
{"Avg objective": 24.1953125, "Games time in secs": 127.6924038734287, "Avg game time in secs": 1.2410250524117146, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 18176, "Total num trained steps": 36072, "Timestamp in ms": 1699631891170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982098731535885, "Avg loss": 2.3326490209437907, "Avg value loss": 1.951602378161624, "Avg policy loss": 0.38104664045386016, "Total num played games": 18211, "Total num trained steps": 36096, "Timestamp in ms": 1699631901002, "logtype": "training_step"}
{"Total num played games": 18211, "Total num trained steps": 36148, "Timestamp in ms": 1699632043414, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.85546875}
{"Ratio train steps to played games": 1.9838983514978914, "Avg loss": 2.286852822639048, "Avg value loss": 1.897077288478613, "Avg policy loss": 0.3897755229845643, "Total num played games": 18259, "Total num trained steps": 36224, "Timestamp in ms": 1699632074943, "logtype": "training_step"}
{"Avg objective": 24.4921875, "Games time in secs": 202.35376215726137, "Avg game time in secs": 1.1933337953087175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 18304, "Total num trained steps": 36268, "Timestamp in ms": 1699632093524, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853085745494266, "Avg loss": 2.091034423559904, "Avg value loss": 1.6993924118578434, "Avg policy loss": 0.39164204453118145, "Total num played games": 18310, "Total num trained steps": 36352, "Timestamp in ms": 1699632128338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816927422859627, "Avg loss": 2.732815718278289, "Avg value loss": 2.3223231171723455, "Avg policy loss": 0.4104926222935319, "Total num played games": 18408, "Total num trained steps": 36480, "Timestamp in ms": 1699632183525, "logtype": "training_step"}
{"Avg objective": 25.296875, "Games time in secs": 125.33729307726026, "Avg game time in secs": 1.2021690199908335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 18432, "Total num trained steps": 36563, "Timestamp in ms": 1699632218861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834209243105596, "Avg loss": 2.1242890362627804, "Avg value loss": 1.724748210515827, "Avg policy loss": 0.399540847633034, "Total num played games": 18457, "Total num trained steps": 36608, "Timestamp in ms": 1699632236948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848173762697212, "Avg loss": 1.5720364078879356, "Avg value loss": 1.1813711890717968, "Avg policy loss": 0.39066521637141705, "Total num played games": 18508, "Total num trained steps": 36736, "Timestamp in ms": 1699632287495, "logtype": "training_step"}
{"Total num played games": 18508, "Total num trained steps": 36750, "Timestamp in ms": 1699632373796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.82421875}
{"Avg objective": 23.8828125, "Games time in secs": 199.39942147955298, "Avg game time in secs": 1.3065135086071678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 18560, "Total num trained steps": 36858, "Timestamp in ms": 1699632418261, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816158684083212, "Avg loss": 1.9963722843676805, "Avg value loss": 1.614927189424634, "Avg policy loss": 0.3814450609497726, "Total num played games": 18603, "Total num trained steps": 36864, "Timestamp in ms": 1699632420547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982900026802466, "Avg loss": 2.4601211179979146, "Avg value loss": 2.076588039053604, "Avg policy loss": 0.3835330435540527, "Total num played games": 18655, "Total num trained steps": 36992, "Timestamp in ms": 1699632475253, "logtype": "training_step"}
{"Avg objective": 24.9296875, "Games time in secs": 85.33306011930108, "Avg game time in secs": 1.0565735189447878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.34}, "Total num played games": 18688, "Total num trained steps": 37058, "Timestamp in ms": 1699632503594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984654868202962, "Avg loss": 2.3508630958385766, "Avg value loss": 1.9625231684185565, "Avg policy loss": 0.38833992276340723, "Total num played games": 18703, "Total num trained steps": 37120, "Timestamp in ms": 1699632530533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860829689666204, "Avg loss": 1.9180981060490012, "Avg value loss": 1.5403859779471532, "Avg policy loss": 0.37771212798543274, "Total num played games": 18754, "Total num trained steps": 37248, "Timestamp in ms": 1699632582157, "logtype": "training_step"}
{"Avg objective": 24.3046875, "Games time in secs": 120.09618497081101, "Avg game time in secs": 1.2287040705559775, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.41, "agent_stopped_0": 0.66}, "Total num played games": 18816, "Total num trained steps": 37350, "Timestamp in ms": 1699632623690, "logtype": "played_game"}
{"Total num played games": 18851, "Total num trained steps": 37352, "Timestamp in ms": 1699632668064, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.39453125}
{"Ratio train steps to played games": 1.9776178633790147, "Avg loss": 2.410311058163643, "Avg value loss": 2.0375844878144562, "Avg policy loss": 0.37272654939442873, "Total num played games": 18899, "Total num trained steps": 37376, "Timestamp in ms": 1699632678566, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843907085030954, "Avg loss": 1.9767199740745127, "Avg value loss": 1.5889081603381783, "Avg policy loss": 0.38781185378320515, "Total num played games": 18899, "Total num trained steps": 37504, "Timestamp in ms": 1699632733394, "logtype": "training_step"}
{"Avg objective": 25.609375, "Games time in secs": 129.6817472949624, "Avg game time in secs": 1.357283355857362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 18944, "Total num trained steps": 37550, "Timestamp in ms": 1699632753372, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986014355077053, "Avg loss": 2.1870415275916457, "Avg value loss": 1.813954439945519, "Avg policy loss": 0.37308709835633636, "Total num played games": 18948, "Total num trained steps": 37632, "Timestamp in ms": 1699632787313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824119283876727, "Avg loss": 2.0930032823234797, "Avg value loss": 1.7091427468694746, "Avg policy loss": 0.3838605487253517, "Total num played games": 19047, "Total num trained steps": 37760, "Timestamp in ms": 1699632838336, "logtype": "training_step"}
{"Avg objective": 24.1953125, "Games time in secs": 119.83998633176088, "Avg game time in secs": 1.2821862319251522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.34, "agent_stopped_0": 0.73}, "Total num played games": 19072, "Total num trained steps": 37841, "Timestamp in ms": 1699632873212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839241765722364, "Avg loss": 1.6431869533844292, "Avg value loss": 1.2573852282948792, "Avg policy loss": 0.38580172904767096, "Total num played games": 19097, "Total num trained steps": 37888, "Timestamp in ms": 1699632892721, "logtype": "training_step"}
{"Total num played games": 19151, "Total num trained steps": 37952, "Timestamp in ms": 1699632985092, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 33.09375}
{"Ratio train steps to played games": 1.9800510443252253, "Avg loss": 6.071920432616025, "Avg value loss": 5.6773633495904505, "Avg policy loss": 0.3945570692885667, "Total num played games": 19199, "Total num trained steps": 38016, "Timestamp in ms": 1699633013655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867701442783479, "Avg loss": 1.2346218121238053, "Avg value loss": 0.8357160978484899, "Avg policy loss": 0.3989057098515332, "Total num played games": 19199, "Total num trained steps": 38144, "Timestamp in ms": 1699633068425, "logtype": "training_step"}
{"Avg objective": 28.390625, "Games time in secs": 195.21447321213782, "Avg game time in secs": 1.344613692315761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 19200, "Total num trained steps": 38144, "Timestamp in ms": 1699633068427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982747901771837, "Avg loss": 2.5515897222794592, "Avg value loss": 2.147921289782971, "Avg policy loss": 0.40366846323013306, "Total num played games": 19302, "Total num trained steps": 38272, "Timestamp in ms": 1699633120653, "logtype": "training_step"}
{"Avg objective": 24.234375, "Games time in secs": 84.41705987788737, "Avg game time in secs": 1.1684645695640938, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.3}, "Total num played games": 19328, "Total num trained steps": 38351, "Timestamp in ms": 1699633152844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842393551054154, "Avg loss": 2.4949669535271823, "Avg value loss": 2.0935099604539573, "Avg policy loss": 0.40145697980187833, "Total num played games": 19352, "Total num trained steps": 38400, "Timestamp in ms": 1699633173010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857231213276982, "Avg loss": 1.4341906607151031, "Avg value loss": 1.0301021097693592, "Avg policy loss": 0.4040885448921472, "Total num played games": 19402, "Total num trained steps": 38528, "Timestamp in ms": 1699633226133, "logtype": "training_step"}
{"Total num played games": 19452, "Total num trained steps": 38556, "Timestamp in ms": 1699633271612, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.73828125}
{"Avg objective": 24.5625, "Games time in secs": 119.75847337022424, "Avg game time in secs": 1.2998265922942664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 19456, "Total num trained steps": 38558, "Timestamp in ms": 1699633272603, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823076923076923, "Avg loss": 2.637465277686715, "Avg value loss": 2.237034577294253, "Avg policy loss": 0.4004307119175792, "Total num played games": 19500, "Total num trained steps": 38656, "Timestamp in ms": 1699633311833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837851662404091, "Avg loss": 1.108036547433585, "Avg value loss": 0.7198012871667743, "Avg policy loss": 0.3882352861110121, "Total num played games": 19550, "Total num trained steps": 38784, "Timestamp in ms": 1699633362622, "logtype": "training_step"}
{"Avg objective": 23.2734375, "Games time in secs": 116.52744967862964, "Avg game time in secs": 1.1262140565668233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.28}, "Total num played games": 19584, "Total num trained steps": 38848, "Timestamp in ms": 1699633389130, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851538186827202, "Avg loss": 2.0854302900843322, "Avg value loss": 1.682848493102938, "Avg policy loss": 0.4025817883666605, "Total num played games": 19601, "Total num trained steps": 38912, "Timestamp in ms": 1699633414764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986515367392632, "Avg loss": 2.779928925447166, "Avg value loss": 2.3889649498742074, "Avg policy loss": 0.390963994897902, "Total num played games": 19652, "Total num trained steps": 39040, "Timestamp in ms": 1699633466052, "logtype": "training_step"}
{"Avg objective": 25.2421875, "Games time in secs": 123.31661599501967, "Avg game time in secs": 1.3600902668840718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 19712, "Total num trained steps": 39154, "Timestamp in ms": 1699633512447, "logtype": "played_game"}
{"Total num played games": 19759, "Total num trained steps": 39160, "Timestamp in ms": 1699633534712, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.7734375}
{"Ratio train steps to played games": 1.9780819150547952, "Avg loss": 3.8230912345461547, "Avg value loss": 3.426505561452359, "Avg policy loss": 0.39658578718081117, "Total num played games": 19801, "Total num trained steps": 39168, "Timestamp in ms": 1699633538598, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838945827232797, "Avg loss": 3.437536852899939, "Avg value loss": 3.033129142364487, "Avg policy loss": 0.40440767095424235, "Total num played games": 19807, "Total num trained steps": 39296, "Timestamp in ms": 1699633593379, "logtype": "training_step"}
{"Avg objective": 24.7734375, "Games time in secs": 108.08217980712652, "Avg game time in secs": 1.220970704962383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 19840, "Total num trained steps": 39362, "Timestamp in ms": 1699633620529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985345218310923, "Avg loss": 1.4483954929746687, "Avg value loss": 1.057743472745642, "Avg policy loss": 0.39065200579352677, "Total num played games": 19857, "Total num trained steps": 39424, "Timestamp in ms": 1699633645893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869386114739274, "Avg loss": 1.932635790668428, "Avg value loss": 1.556023159995675, "Avg policy loss": 0.3766126115806401, "Total num played games": 19906, "Total num trained steps": 39552, "Timestamp in ms": 1699633697278, "logtype": "training_step"}
{"Avg objective": 24.4609375, "Games time in secs": 120.78951237536967, "Avg game time in secs": 1.2274189074669266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 19968, "Total num trained steps": 39656, "Timestamp in ms": 1699633741319, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834541364658835, "Avg loss": 1.8523420272395015, "Avg value loss": 1.4700662670657039, "Avg policy loss": 0.3822757815942168, "Total num played games": 20005, "Total num trained steps": 39680, "Timestamp in ms": 1699633751349, "logtype": "training_step"}
{"Total num played games": 20053, "Total num trained steps": 39765, "Timestamp in ms": 1699633803123, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.22265625}
{"Avg objective": 23.4921875, "Games time in secs": 64.81201829016209, "Avg game time in secs": 1.2589728105958784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 20096, "Total num trained steps": 39770, "Timestamp in ms": 1699633806131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803492363564001, "Avg loss": 2.0370274246670306, "Avg value loss": 1.6663267593830824, "Avg policy loss": 0.3707006548065692, "Total num played games": 20101, "Total num trained steps": 39808, "Timestamp in ms": 1699633821640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986717078752301, "Avg loss": 0.9280430455692112, "Avg value loss": 0.5528512574965134, "Avg policy loss": 0.3751917937770486, "Total num played games": 20101, "Total num trained steps": 39936, "Timestamp in ms": 1699633874073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830223234173143, "Avg loss": 2.8187919319607317, "Avg value loss": 2.450561882695183, "Avg policy loss": 0.36823003634344786, "Total num played games": 20203, "Total num trained steps": 40064, "Timestamp in ms": 1699633927914, "logtype": "training_step"}
{"Avg objective": 25.5, "Games time in secs": 158.41995567455888, "Avg game time in secs": 1.2908161154919071, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 20224, "Total num trained steps": 40153, "Timestamp in ms": 1699633964551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844467486298327, "Avg loss": 2.5157516156323254, "Avg value loss": 2.135851932805963, "Avg policy loss": 0.37989962194114923, "Total num played games": 20253, "Total num trained steps": 40192, "Timestamp in ms": 1699633980433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985961974189735, "Avg loss": 2.0959169724956155, "Avg value loss": 1.7007174016907811, "Avg policy loss": 0.3951995524112135, "Total num played games": 20302, "Total num trained steps": 40320, "Timestamp in ms": 1699634037061, "logtype": "training_step"}
{"Total num played games": 20351, "Total num trained steps": 40366, "Timestamp in ms": 1699634079349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.74609375}
{"Avg objective": 24.5859375, "Games time in secs": 115.70887582749128, "Avg game time in secs": 1.6384705650707474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.58}, "Total num played games": 20352, "Total num trained steps": 40367, "Timestamp in ms": 1699634080260, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828422961909897, "Avg loss": 3.313754593487829, "Avg value loss": 2.902755798539147, "Avg policy loss": 0.4109987912233919, "Total num played games": 20399, "Total num trained steps": 40448, "Timestamp in ms": 1699634113503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984398689294273, "Avg loss": 2.5792614091187716, "Avg value loss": 2.1842509403359145, "Avg policy loss": 0.3950105046387762, "Total num played games": 20447, "Total num trained steps": 40576, "Timestamp in ms": 1699634166901, "logtype": "training_step"}
{"Avg objective": 25.09375, "Games time in secs": 116.00491962768137, "Avg game time in secs": 1.1887348590244073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.36}, "Total num played games": 20480, "Total num trained steps": 40642, "Timestamp in ms": 1699634196265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985996584532813, "Avg loss": 1.7084753448143601, "Avg value loss": 1.3201732221059501, "Avg policy loss": 0.3883021380752325, "Total num played games": 20495, "Total num trained steps": 40704, "Timestamp in ms": 1699634222811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873935264054514, "Avg loss": 2.1573116863146424, "Avg value loss": 1.7766955508850515, "Avg policy loss": 0.3806161161046475, "Total num played games": 20545, "Total num trained steps": 40832, "Timestamp in ms": 1699634278301, "logtype": "training_step"}
{"Avg objective": 25.9140625, "Games time in secs": 126.3782866653055, "Avg game time in secs": 1.5151945027610054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 20608, "Total num trained steps": 40938, "Timestamp in ms": 1699634322643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839670622426737, "Avg loss": 2.000321072526276, "Avg value loss": 1.6229378308635205, "Avg policy loss": 0.37738323770463467, "Total num played games": 20645, "Total num trained steps": 40960, "Timestamp in ms": 1699634330812, "logtype": "training_step"}
{"Total num played games": 20645, "Total num trained steps": 40966, "Timestamp in ms": 1699634346505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.265625}
{"Ratio train steps to played games": 1.9855506693084617, "Avg loss": 1.7333699339069426, "Avg value loss": 1.3448170160409063, "Avg policy loss": 0.388552907621488, "Total num played games": 20693, "Total num trained steps": 41088, "Timestamp in ms": 1699634395061, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 92.26988844014704, "Avg game time in secs": 1.2064749174023746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 20736, "Total num trained steps": 41137, "Timestamp in ms": 1699634414913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871751603104961, "Avg loss": 1.315154588315636, "Avg value loss": 0.9333306852495298, "Avg policy loss": 0.3818238985259086, "Total num played games": 20741, "Total num trained steps": 41216, "Timestamp in ms": 1699634447732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841627873494265, "Avg loss": 3.829212846234441, "Avg value loss": 3.441747564356774, "Avg policy loss": 0.38746524997986853, "Total num played games": 20836, "Total num trained steps": 41344, "Timestamp in ms": 1699634498277, "logtype": "training_step"}
{"Avg objective": 25.8203125, "Games time in secs": 119.36123683489859, "Avg game time in secs": 1.5336533403460635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.51, "agent_stopped_0": 0.56}, "Total num played games": 20864, "Total num trained steps": 41431, "Timestamp in ms": 1699634534275, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849231800124443, "Avg loss": 1.9888791590929031, "Avg value loss": 1.5886705077718943, "Avg policy loss": 0.4002086683176458, "Total num played games": 20893, "Total num trained steps": 41472, "Timestamp in ms": 1699634550238, "logtype": "training_step"}
{"Total num played games": 20946, "Total num trained steps": 41570, "Timestamp in ms": 1699634606945, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.97265625}
{"Avg objective": 25.6875, "Games time in secs": 76.38635748811066, "Avg game time in secs": 1.3971150486177066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 20992, "Total num trained steps": 41578, "Timestamp in ms": 1699634610661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815185291035533, "Avg loss": 2.692438351456076, "Avg value loss": 2.288816669024527, "Avg policy loss": 0.403621694073081, "Total num played games": 20994, "Total num trained steps": 41600, "Timestamp in ms": 1699634619373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987567876536153, "Avg loss": 1.5126857957802713, "Avg value loss": 1.1061971688177437, "Avg policy loss": 0.40648863138630986, "Total num played games": 20994, "Total num trained steps": 41728, "Timestamp in ms": 1699634671370, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98411945958758, "Avg loss": 3.4623105521313846, "Avg value loss": 3.0630360727664083, "Avg policy loss": 0.399274452123791, "Total num played games": 21095, "Total num trained steps": 41856, "Timestamp in ms": 1699634722530, "logtype": "training_step"}
{"Avg objective": 25.28125, "Games time in secs": 145.82437093183398, "Avg game time in secs": 1.3811038730782457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.38, "agent_stopped_0": 0.73}, "Total num played games": 21120, "Total num trained steps": 41939, "Timestamp in ms": 1699634756486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851056787554968, "Avg loss": 2.9343578941188753, "Avg value loss": 2.5132193779572845, "Avg policy loss": 0.42113850568421185, "Total num played games": 21149, "Total num trained steps": 41984, "Timestamp in ms": 1699634774565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866025096707236, "Avg loss": 1.5837522819638252, "Avg value loss": 1.1801206306554377, "Avg policy loss": 0.4036316894926131, "Total num played games": 21198, "Total num trained steps": 42112, "Timestamp in ms": 1699634826777, "logtype": "training_step"}
{"Avg objective": 23.4765625, "Games time in secs": 85.23587141372263, "Avg game time in secs": 1.5155111194908386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 21248, "Total num trained steps": 42150, "Timestamp in ms": 1699634841722, "logtype": "played_game"}
{"Total num played games": 21248, "Total num trained steps": 42173, "Timestamp in ms": 1699634866896, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.40234375}
{"Ratio train steps to played games": 1.983424117205109, "Avg loss": 3.362557525280863, "Avg value loss": 2.9477975578047335, "Avg policy loss": 0.41475995001383126, "Total num played games": 21296, "Total num trained steps": 42240, "Timestamp in ms": 1699634894321, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984774665042631, "Avg loss": 1.6461627134121954, "Avg value loss": 1.233647418441251, "Avg policy loss": 0.4125153173226863, "Total num played games": 21346, "Total num trained steps": 42368, "Timestamp in ms": 1699634947035, "logtype": "training_step"}
{"Avg objective": 24.3125, "Games time in secs": 135.21554814651608, "Avg game time in secs": 1.1954584267077735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.39}, "Total num played games": 21376, "Total num trained steps": 42440, "Timestamp in ms": 1699634976937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859332647911019, "Avg loss": 2.545529672410339, "Avg value loss": 2.1384342382662, "Avg policy loss": 0.4070954641792923, "Total num played games": 21398, "Total num trained steps": 42496, "Timestamp in ms": 1699634999698, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987364200121229, "Avg loss": 1.281009185127914, "Avg value loss": 0.872563699260354, "Avg policy loss": 0.40844547585584223, "Total num played games": 21447, "Total num trained steps": 42624, "Timestamp in ms": 1699635052178, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 121.84106145240366, "Avg game time in secs": 1.5317660629516467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 21504, "Total num trained steps": 42738, "Timestamp in ms": 1699635098779, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836210096510765, "Avg loss": 2.6138986558653414, "Avg value loss": 2.2098316468764096, "Avg policy loss": 0.40406698314473033, "Total num played games": 21552, "Total num trained steps": 42752, "Timestamp in ms": 1699635104321, "logtype": "training_step"}
{"Total num played games": 21552, "Total num trained steps": 42776, "Timestamp in ms": 1699635136904, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.28515625}
{"Ratio train steps to played games": 1.9851851851851852, "Avg loss": 2.747925232630223, "Avg value loss": 2.3332310053519905, "Avg policy loss": 0.41469425591640174, "Total num played games": 21600, "Total num trained steps": 42880, "Timestamp in ms": 1699635181293, "logtype": "training_step"}
{"Avg objective": 24.0078125, "Games time in secs": 113.7677128072828, "Avg game time in secs": 1.254144690479734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.34}, "Total num played games": 21632, "Total num trained steps": 42949, "Timestamp in ms": 1699635212546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862830223535932, "Avg loss": 1.1360470340587199, "Avg value loss": 0.747673616046086, "Avg policy loss": 0.38837343570776284, "Total num played games": 21652, "Total num trained steps": 43008, "Timestamp in ms": 1699635236619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876964195198379, "Avg loss": 2.2019748939201236, "Avg value loss": 1.8071384860668331, "Avg policy loss": 0.39483641157858074, "Total num played games": 21701, "Total num trained steps": 43136, "Timestamp in ms": 1699635289095, "logtype": "training_step"}
{"Avg objective": 23.078125, "Games time in secs": 128.1181837003678, "Avg game time in secs": 1.4752317492384464, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 21760, "Total num trained steps": 43256, "Timestamp in ms": 1699635340665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984450254575478, "Avg loss": 1.8005747091956437, "Avg value loss": 1.4142859450075775, "Avg policy loss": 0.386288768844679, "Total num played games": 21801, "Total num trained steps": 43264, "Timestamp in ms": 1699635343923, "logtype": "training_step"}
{"Total num played games": 21854, "Total num trained steps": 43380, "Timestamp in ms": 1699635425097, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.06640625}
{"Avg objective": 24.0703125, "Games time in secs": 87.04664971120656, "Avg game time in secs": 1.2778843030828284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 21888, "Total num trained steps": 43385, "Timestamp in ms": 1699635427711, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981414676469245, "Avg loss": 2.8106011990457773, "Avg value loss": 2.425397164421156, "Avg policy loss": 0.3852039803750813, "Total num played games": 21899, "Total num trained steps": 43392, "Timestamp in ms": 1699635430174, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869874897269655, "Avg loss": 1.937101420480758, "Avg value loss": 1.5394115268718451, "Avg policy loss": 0.3976898896507919, "Total num played games": 21902, "Total num trained steps": 43520, "Timestamp in ms": 1699635484670, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884287731766206, "Avg loss": 1.9091433761641383, "Avg value loss": 1.5229012204799801, "Avg policy loss": 0.38624217989854515, "Total num played games": 21951, "Total num trained steps": 43648, "Timestamp in ms": 1699635539547, "logtype": "training_step"}
{"Avg objective": 22.6953125, "Games time in secs": 153.5778901744634, "Avg game time in secs": 1.3778780108841602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 22016, "Total num trained steps": 43752, "Timestamp in ms": 1699635581289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843608340888486, "Avg loss": 2.6145145911723375, "Avg value loss": 2.2251002020202577, "Avg policy loss": 0.38941441127099097, "Total num played games": 22060, "Total num trained steps": 43776, "Timestamp in ms": 1699635590564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856625961103573, "Avg loss": 2.0592265292070806, "Avg value loss": 1.6626531763467938, "Avg policy loss": 0.3965733549557626, "Total num played games": 22110, "Total num trained steps": 43904, "Timestamp in ms": 1699635642055, "logtype": "training_step"}
{"Avg objective": 25.359375, "Games time in secs": 87.53211087360978, "Avg game time in secs": 1.3644916063640267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 22144, "Total num trained steps": 43969, "Timestamp in ms": 1699635668822, "logtype": "played_game"}
{"Total num played games": 22159, "Total num trained steps": 43984, "Timestamp in ms": 1699635694508, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.6875}
{"Ratio train steps to played games": 1.9827982167784932, "Avg loss": 4.889228640124202, "Avg value loss": 4.489375685341656, "Avg policy loss": 0.39985294197686017, "Total num played games": 22207, "Total num trained steps": 44032, "Timestamp in ms": 1699635715808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885621650830818, "Avg loss": 1.3630087850615382, "Avg value loss": 0.9490427415585145, "Avg policy loss": 0.41396604129113257, "Total num played games": 22207, "Total num trained steps": 44160, "Timestamp in ms": 1699635768965, "logtype": "training_step"}
{"Avg objective": 26.265625, "Games time in secs": 141.480215376243, "Avg game time in secs": 1.4061150190245826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 22272, "Total num trained steps": 44261, "Timestamp in ms": 1699635810302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985340924373515, "Avg loss": 2.2050355011597276, "Avg value loss": 1.800236924784258, "Avg policy loss": 0.40479859011247754, "Total num played games": 22307, "Total num trained steps": 44288, "Timestamp in ms": 1699635821262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867149758454106, "Avg loss": 2.244995019864291, "Avg value loss": 1.8274483946152031, "Avg policy loss": 0.41754664084874094, "Total num played games": 22356, "Total num trained steps": 44416, "Timestamp in ms": 1699635873437, "logtype": "training_step"}
{"Avg objective": 24.4765625, "Games time in secs": 81.43192282877862, "Avg game time in secs": 1.4516861504380358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.58, "agent_stopped_0": 0.47}, "Total num played games": 22400, "Total num trained steps": 44462, "Timestamp in ms": 1699635891734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987994287244488, "Avg loss": 2.2991949040442705, "Avg value loss": 1.889621663140133, "Avg policy loss": 0.40957323950715363, "Total num played games": 22406, "Total num trained steps": 44544, "Timestamp in ms": 1699635925194, "logtype": "training_step"}
{"Total num played games": 22456, "Total num trained steps": 44587, "Timestamp in ms": 1699635970687, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.15625}
{"Ratio train steps to played games": 1.985024884464984, "Avg loss": 3.1396271931007504, "Avg value loss": 2.7344087036326528, "Avg policy loss": 0.40521849459037185, "Total num played games": 22504, "Total num trained steps": 44672, "Timestamp in ms": 1699636007131, "logtype": "training_step"}
{"Avg objective": 23.8359375, "Games time in secs": 151.36319853551686, "Avg game time in secs": 1.2722718016593717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.35, "agent_stopped_0": 0.68}, "Total num played games": 22528, "Total num trained steps": 44756, "Timestamp in ms": 1699636043097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862114830414541, "Avg loss": 1.8984168241731822, "Avg value loss": 1.4956021916586906, "Avg policy loss": 0.4028146266937256, "Total num played games": 22555, "Total num trained steps": 44800, "Timestamp in ms": 1699636061673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98770074768836, "Avg loss": 1.1942098969593644, "Avg value loss": 0.7718130750581622, "Avg policy loss": 0.4223968202713877, "Total num played games": 22603, "Total num trained steps": 44928, "Timestamp in ms": 1699636117035, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887883469432797, "Avg loss": 1.9458027118816972, "Avg value loss": 1.5280399846378714, "Avg policy loss": 0.4177627209573984, "Total num played games": 22655, "Total num trained steps": 45056, "Timestamp in ms": 1699636169676, "logtype": "training_step"}
{"Avg objective": 24.25, "Games time in secs": 126.63172369264066, "Avg game time in secs": 1.4446171400340972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 22656, "Total num trained steps": 45056, "Timestamp in ms": 1699636169729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853244870161255, "Avg loss": 2.4741662330925465, "Avg value loss": 2.0726011756341904, "Avg policy loss": 0.40156503743492067, "Total num played games": 22759, "Total num trained steps": 45184, "Timestamp in ms": 1699636222109, "logtype": "training_step"}
{"Total num played games": 22759, "Total num trained steps": 45189, "Timestamp in ms": 1699636337401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.07421875}
{"Avg objective": 26.09375, "Games time in secs": 169.48542997054756, "Avg game time in secs": 1.1830210531770717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.31}, "Total num played games": 22784, "Total num trained steps": 45193, "Timestamp in ms": 1699636339215, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867584513526548, "Avg loss": 2.3629989717155695, "Avg value loss": 1.9578763972967863, "Avg policy loss": 0.40512260468676686, "Total num played games": 22807, "Total num trained steps": 45312, "Timestamp in ms": 1699636389700, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880556527826392, "Avg loss": 1.5040483577176929, "Avg value loss": 1.1167180243646726, "Avg policy loss": 0.38733034604229033, "Total num played games": 22856, "Total num trained steps": 45440, "Timestamp in ms": 1699636442367, "logtype": "training_step"}
{"Avg objective": 25.7890625, "Games time in secs": 151.65625879913568, "Avg game time in secs": 1.3443872585776262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 22912, "Total num trained steps": 45556, "Timestamp in ms": 1699636490871, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852306887988498, "Avg loss": 2.242953491397202, "Avg value loss": 1.83286184433382, "Avg policy loss": 0.4100916215684265, "Total num played games": 22953, "Total num trained steps": 45568, "Timestamp in ms": 1699636495382, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986350793305803, "Avg loss": 2.076096447650343, "Avg value loss": 1.6735635509248823, "Avg policy loss": 0.40253289067186415, "Total num played games": 23005, "Total num trained steps": 45696, "Timestamp in ms": 1699636549689, "logtype": "training_step"}
{"Avg objective": 24.2578125, "Games time in secs": 85.1593139320612, "Avg game time in secs": 1.316124813442002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.42}, "Total num played games": 23040, "Total num trained steps": 45759, "Timestamp in ms": 1699636576031, "logtype": "played_game"}
{"Total num played games": 23055, "Total num trained steps": 45791, "Timestamp in ms": 1699636613275, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.14453125}
{"Ratio train steps to played games": 1.9834653508202398, "Avg loss": 1.9147967523895204, "Avg value loss": 1.51574237679597, "Avg policy loss": 0.3990543431136757, "Total num played games": 23103, "Total num trained steps": 45824, "Timestamp in ms": 1699636627261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889196675900278, "Avg loss": 1.0930732288397849, "Avg value loss": 0.686326271854341, "Avg policy loss": 0.40674696303904057, "Total num played games": 23103, "Total num trained steps": 45952, "Timestamp in ms": 1699636682155, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 149.63460631482303, "Avg game time in secs": 1.4773406845633872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 23168, "Total num trained steps": 46056, "Timestamp in ms": 1699636725665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858645061196345, "Avg loss": 2.1324599934741855, "Avg value loss": 1.7313736609648913, "Avg policy loss": 0.4010863471776247, "Total num played games": 23204, "Total num trained steps": 46080, "Timestamp in ms": 1699636735608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987226905212455, "Avg loss": 2.2019002698361874, "Avg value loss": 1.8035479250829667, "Avg policy loss": 0.3983523172792047, "Total num played games": 23252, "Total num trained steps": 46208, "Timestamp in ms": 1699636788459, "logtype": "training_step"}
{"Avg objective": 25.4609375, "Games time in secs": 81.68744844384491, "Avg game time in secs": 1.3344881920347689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 23296, "Total num trained steps": 46253, "Timestamp in ms": 1699636807353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988370596060593, "Avg loss": 1.8653499288484454, "Avg value loss": 1.4751941105350852, "Avg policy loss": 0.39015581947751343, "Total num played games": 23303, "Total num trained steps": 46336, "Timestamp in ms": 1699636841342, "logtype": "training_step"}
{"Total num played games": 23353, "Total num trained steps": 46392, "Timestamp in ms": 1699636882451, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.97265625}
{"Ratio train steps to played games": 1.9855134395965985, "Avg loss": 2.7487309682182968, "Avg value loss": 2.341564503731206, "Avg policy loss": 0.40716643701307476, "Total num played games": 23401, "Total num trained steps": 46464, "Timestamp in ms": 1699636912130, "logtype": "training_step"}
{"Avg objective": 23.7109375, "Games time in secs": 142.1202719323337, "Avg game time in secs": 1.3414636824163608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.44, "agent_stopped_0": 0.58}, "Total num played games": 23424, "Total num trained steps": 46549, "Timestamp in ms": 1699636949473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863148021828103, "Avg loss": 1.7636644365265965, "Avg value loss": 1.3610835585277528, "Avg policy loss": 0.4025808989536017, "Total num played games": 23456, "Total num trained steps": 46592, "Timestamp in ms": 1699636966786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987366003062787, "Avg loss": 2.007604818791151, "Avg value loss": 1.6031417411286384, "Avg policy loss": 0.4044630895368755, "Total num played games": 23508, "Total num trained steps": 46720, "Timestamp in ms": 1699637020041, "logtype": "training_step"}
{"Avg objective": 23.484375, "Games time in secs": 89.91013149172068, "Avg game time in secs": 1.344364351243712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 23552, "Total num trained steps": 46768, "Timestamp in ms": 1699637039384, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885394116898, "Avg loss": 1.3600654546171427, "Avg value loss": 0.9770474056713283, "Avg policy loss": 0.38301805150695145, "Total num played games": 23559, "Total num trained steps": 46848, "Timestamp in ms": 1699637072865, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856702033224838, "Avg loss": 2.1161515335552394, "Avg value loss": 1.7387063176138327, "Avg policy loss": 0.37744525563903153, "Total num played games": 23657, "Total num trained steps": 46976, "Timestamp in ms": 1699637127267, "logtype": "training_step"}
{"Total num played games": 23657, "Total num trained steps": 46993, "Timestamp in ms": 1699637157803, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.5625}
{"Avg objective": 25.21875, "Games time in secs": 120.48213916830719, "Avg game time in secs": 1.4125649564957712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 23680, "Total num trained steps": 46997, "Timestamp in ms": 1699637159866, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987091330942839, "Avg loss": 2.2127615096978843, "Avg value loss": 1.812687824247405, "Avg policy loss": 0.40007368475198746, "Total num played games": 23705, "Total num trained steps": 47104, "Timestamp in ms": 1699637203478, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880877215136592, "Avg loss": 1.9705953560769558, "Avg value loss": 1.586210931185633, "Avg policy loss": 0.38438442070037127, "Total num played games": 23757, "Total num trained steps": 47232, "Timestamp in ms": 1699637257417, "logtype": "training_step"}
{"Avg objective": 24.625, "Games time in secs": 149.32949729450047, "Avg game time in secs": 1.3137550351239042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.51, "agent_stopped_0": 0.56}, "Total num played games": 23808, "Total num trained steps": 47355, "Timestamp in ms": 1699637309196, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857855675290368, "Avg loss": 1.8729091137647629, "Avg value loss": 1.4819020699942484, "Avg policy loss": 0.39100707112811506, "Total num played games": 23849, "Total num trained steps": 47360, "Timestamp in ms": 1699637311157, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861558408967335, "Avg loss": 3.8510009655728936, "Avg value loss": 3.4582908283919096, "Avg policy loss": 0.39271017466671765, "Total num played games": 23909, "Total num trained steps": 47488, "Timestamp in ms": 1699637363273, "logtype": "training_step"}
{"Avg objective": 25.796875, "Games time in secs": 85.52115366980433, "Avg game time in secs": 1.3103447574394522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 23936, "Total num trained steps": 47566, "Timestamp in ms": 1699637394717, "logtype": "played_game"}
{"Total num played games": 23959, "Total num trained steps": 47594, "Timestamp in ms": 1699637420537, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.5546875}
{"Ratio train steps to played games": 1.9833798475444662, "Avg loss": 2.286752636078745, "Avg value loss": 1.8848328974563628, "Avg policy loss": 0.40191975655034184, "Total num played games": 24007, "Total num trained steps": 47616, "Timestamp in ms": 1699637430037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887116257758153, "Avg loss": 1.3751828358508646, "Avg value loss": 0.970669275149703, "Avg policy loss": 0.40451356302946806, "Total num played games": 24007, "Total num trained steps": 47744, "Timestamp in ms": 1699637485824, "logtype": "training_step"}
{"Avg objective": 23.390625, "Games time in secs": 139.74395201727748, "Avg game time in secs": 1.3806833303679014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.49, "agent_stopped_0": 0.59}, "Total num played games": 24064, "Total num trained steps": 47856, "Timestamp in ms": 1699637534461, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857717675364002, "Avg loss": 1.6080356230959296, "Avg value loss": 1.2148368384223431, "Avg policy loss": 0.39319877978414297, "Total num played games": 24107, "Total num trained steps": 47872, "Timestamp in ms": 1699637540663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866313480402302, "Avg loss": 2.2450857586227357, "Avg value loss": 1.8703032891498879, "Avg policy loss": 0.3747824577149004, "Total num played games": 24161, "Total num trained steps": 48000, "Timestamp in ms": 1699637595961, "logtype": "training_step"}
{"Avg objective": 23.671875, "Games time in secs": 91.42635427229106, "Avg game time in secs": 1.211237747935229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.4}, "Total num played games": 24192, "Total num trained steps": 48070, "Timestamp in ms": 1699637625888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876512617189113, "Avg loss": 2.2143349745310843, "Avg value loss": 1.8235629678238183, "Avg policy loss": 0.3907719838898629, "Total num played games": 24213, "Total num trained steps": 48128, "Timestamp in ms": 1699637649520, "logtype": "training_step"}
{"Total num played games": 24263, "Total num trained steps": 48198, "Timestamp in ms": 1699637705527, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.28515625}
{"Ratio train steps to played games": 1.9849039529431123, "Avg loss": 2.653360739350319, "Avg value loss": 2.250990444328636, "Avg policy loss": 0.40237027895636857, "Total num played games": 24311, "Total num trained steps": 48256, "Timestamp in ms": 1699637730326, "logtype": "training_step"}
{"Avg objective": 24.4296875, "Games time in secs": 150.93474834784865, "Avg game time in secs": 1.5025860709720291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 24320, "Total num trained steps": 48368, "Timestamp in ms": 1699637776823, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859212740631285, "Avg loss": 1.1898031658492982, "Avg value loss": 0.7892681983066723, "Avg policy loss": 0.40053496719338, "Total num played games": 24363, "Total num trained steps": 48384, "Timestamp in ms": 1699637782912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987097038463114, "Avg loss": 1.7649799706414342, "Avg value loss": 1.367625217186287, "Avg policy loss": 0.39735475461930037, "Total num played games": 24413, "Total num trained steps": 48512, "Timestamp in ms": 1699637837185, "logtype": "training_step"}
{"Avg objective": 23.40625, "Games time in secs": 91.23462377861142, "Avg game time in secs": 1.2986096869135508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.42}, "Total num played games": 24448, "Total num trained steps": 48576, "Timestamp in ms": 1699637868057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881054567749847, "Avg loss": 1.4258306487463415, "Avg value loss": 1.026147408876568, "Avg policy loss": 0.39968323055654764, "Total num played games": 24465, "Total num trained steps": 48640, "Timestamp in ms": 1699637895427, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893126657148685, "Avg loss": 1.8193894498981535, "Avg value loss": 1.4205510423053056, "Avg policy loss": 0.3988384180702269, "Total num played games": 24515, "Total num trained steps": 48768, "Timestamp in ms": 1699637947541, "logtype": "training_step"}
{"Total num played games": 24568, "Total num trained steps": 48802, "Timestamp in ms": 1699637977040, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.625}
{"Avg objective": 23.953125, "Games time in secs": 110.35637370869517, "Avg game time in secs": 1.6512631442165002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 24576, "Total num trained steps": 48805, "Timestamp in ms": 1699637978414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863097172570685, "Avg loss": 3.0874127978459, "Avg value loss": 2.6648616567254066, "Avg policy loss": 0.4225511646363884, "Total num played games": 24616, "Total num trained steps": 48896, "Timestamp in ms": 1699638015600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873920622694288, "Avg loss": 1.3597210641019046, "Avg value loss": 0.9561741064535454, "Avg policy loss": 0.40354695939458907, "Total num played games": 24667, "Total num trained steps": 49024, "Timestamp in ms": 1699638069206, "logtype": "training_step"}
{"Avg objective": 24.828125, "Games time in secs": 115.86857361719012, "Avg game time in secs": 1.3396138807729585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 24704, "Total num trained steps": 49083, "Timestamp in ms": 1699638094283, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887113089217074, "Avg loss": 2.803333624266088, "Avg value loss": 2.3949055774137378, "Avg policy loss": 0.4084280739771202, "Total num played games": 24715, "Total num trained steps": 49152, "Timestamp in ms": 1699638123498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986736010320916, "Avg loss": 2.011141082737595, "Avg value loss": 1.5816663093864918, "Avg policy loss": 0.4294747656676918, "Total num played games": 24804, "Total num trained steps": 49280, "Timestamp in ms": 1699638175359, "logtype": "training_step"}
{"Avg objective": 24.84375, "Games time in secs": 119.28979519195855, "Avg game time in secs": 1.4554798427707283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.5, "agent_stopped_0": 0.57}, "Total num played games": 24832, "Total num trained steps": 49373, "Timestamp in ms": 1699638213573, "logtype": "played_game"}
{"Total num played games": 24861, "Total num trained steps": 49407, "Timestamp in ms": 1699638242809, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.28125}
{"Ratio train steps to played games": 1.9873697759543059, "Avg loss": 2.184972087852657, "Avg value loss": 1.7807440836913884, "Avg policy loss": 0.40422802814282477, "Total num played games": 24861, "Total num trained steps": 49408, "Timestamp in ms": 1699638243383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886787907985066, "Avg loss": 1.6538900015875697, "Avg value loss": 1.2355021354742348, "Avg policy loss": 0.41838783817365766, "Total num played games": 24909, "Total num trained steps": 49536, "Timestamp in ms": 1699638296663, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 99.35280004888773, "Avg game time in secs": 1.4874485808541067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 24960, "Total num trained steps": 49575, "Timestamp in ms": 1699638312926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896238131485118, "Avg loss": 1.7599369077943265, "Avg value loss": 1.3548540271585807, "Avg policy loss": 0.40508284815587103, "Total num played games": 24961, "Total num trained steps": 49664, "Timestamp in ms": 1699638348805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867922269662024, "Avg loss": 3.2431238307617605, "Avg value loss": 2.8315721275284886, "Avg policy loss": 0.41155168949626386, "Total num played games": 25061, "Total num trained steps": 49792, "Timestamp in ms": 1699638400389, "logtype": "training_step"}
{"Avg objective": 27.0234375, "Games time in secs": 118.90497967600822, "Avg game time in secs": 1.2495010728744091, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.37, "agent_stopped_0": 0.67}, "Total num played games": 25088, "Total num trained steps": 49870, "Timestamp in ms": 1699638431831, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98805256869773, "Avg loss": 2.066308327950537, "Avg value loss": 1.6500560899730772, "Avg policy loss": 0.4162522228434682, "Total num played games": 25110, "Total num trained steps": 49920, "Timestamp in ms": 1699638451848, "logtype": "training_step"}
{"Total num played games": 25158, "Total num trained steps": 50010, "Timestamp in ms": 1699638519649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.1015625}
{"Ratio train steps to played games": 1.9855193207966357, "Avg loss": 2.1651523406617343, "Avg value loss": 1.7588754566386342, "Avg policy loss": 0.40627689845860004, "Total num played games": 25206, "Total num trained steps": 50048, "Timestamp in ms": 1699638535348, "logtype": "training_step"}
{"Avg objective": 23.984375, "Games time in secs": 148.40828922577202, "Avg game time in secs": 1.3529209250409622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 25216, "Total num trained steps": 50158, "Timestamp in ms": 1699638580239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868139700641483, "Avg loss": 1.2007194804027677, "Avg value loss": 0.7933056870242581, "Avg policy loss": 0.4074137944262475, "Total num played games": 25254, "Total num trained steps": 50176, "Timestamp in ms": 1699638586932, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98778945704576, "Avg loss": 1.7713511446490884, "Avg value loss": 1.3704363513970748, "Avg policy loss": 0.4009147947654128, "Total num played games": 25306, "Total num trained steps": 50304, "Timestamp in ms": 1699638643377, "logtype": "training_step"}
{"Avg objective": 24.25, "Games time in secs": 87.87218452990055, "Avg game time in secs": 1.5107818540709559, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 25344, "Total num trained steps": 50361, "Timestamp in ms": 1699638668111, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890747022166129, "Avg loss": 1.5665944828651845, "Avg value loss": 1.1587711533065885, "Avg policy loss": 0.40782331908121705, "Total num played games": 25354, "Total num trained steps": 50432, "Timestamp in ms": 1699638696818, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877339204277402, "Avg loss": 2.5338996737264097, "Avg value loss": 2.1310444904956967, "Avg policy loss": 0.40285515785217285, "Total num played games": 25433, "Total num trained steps": 50560, "Timestamp in ms": 1699638747329, "logtype": "training_step"}
{"Total num played games": 25455, "Total num trained steps": 50612, "Timestamp in ms": 1699638788004, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 32.58203125}
{"Avg objective": 25.6328125, "Games time in secs": 121.27741768397391, "Avg game time in secs": 1.54699997548596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 25472, "Total num trained steps": 50615, "Timestamp in ms": 1699638789389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874916676469434, "Avg loss": 2.9694020552560687, "Avg value loss": 2.5501216230913997, "Avg policy loss": 0.4192804591730237, "Total num played games": 25503, "Total num trained steps": 50688, "Timestamp in ms": 1699638819627, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988767562913389, "Avg loss": 1.337438385002315, "Avg value loss": 0.9293908484978601, "Avg policy loss": 0.4080475461669266, "Total num played games": 25551, "Total num trained steps": 50816, "Timestamp in ms": 1699638872692, "logtype": "training_step"}
{"Avg objective": 25.2578125, "Games time in secs": 99.24450778216124, "Avg game time in secs": 1.4340047226141905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 25600, "Total num trained steps": 50855, "Timestamp in ms": 1699638888633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897277662773893, "Avg loss": 2.676720259245485, "Avg value loss": 2.2429511642549187, "Avg policy loss": 0.4337691243272275, "Total num played games": 25603, "Total num trained steps": 50944, "Timestamp in ms": 1699638924083, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871984435797665, "Avg loss": 2.6372941858135164, "Avg value loss": 2.204543036641553, "Avg policy loss": 0.4327510935254395, "Total num played games": 25700, "Total num trained steps": 51072, "Timestamp in ms": 1699638976318, "logtype": "training_step"}
{"Avg objective": 25.078125, "Games time in secs": 119.8818497210741, "Avg game time in secs": 1.4402087812777609, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 25728, "Total num trained steps": 51148, "Timestamp in ms": 1699639008515, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882723001048503, "Avg loss": 1.9251708602532744, "Avg value loss": 1.4923127428628504, "Avg policy loss": 0.4328580885194242, "Total num played games": 25751, "Total num trained steps": 51200, "Timestamp in ms": 1699639030026, "logtype": "training_step"}
{"Total num played games": 25751, "Total num trained steps": 51215, "Timestamp in ms": 1699639054972, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.4921875}
{"Ratio train steps to played games": 1.9894957168882514, "Avg loss": 1.7909990632906556, "Avg value loss": 1.3663109696935862, "Avg policy loss": 0.42468807310797274, "Total num played games": 25799, "Total num trained steps": 51328, "Timestamp in ms": 1699639101249, "logtype": "training_step"}
{"Avg objective": 24.3203125, "Games time in secs": 140.56236196868122, "Avg game time in secs": 1.588889920967631, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.57}, "Total num played games": 25856, "Total num trained steps": 51446, "Timestamp in ms": 1699639149082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867948569442835, "Avg loss": 1.8573586298152804, "Avg value loss": 1.4440304825548083, "Avg policy loss": 0.41332815354689956, "Total num played games": 25899, "Total num trained steps": 51456, "Timestamp in ms": 1699639152699, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876310110974107, "Avg loss": 2.4529785104095936, "Avg value loss": 2.0215534805320203, "Avg policy loss": 0.4314250375609845, "Total num played games": 25952, "Total num trained steps": 51584, "Timestamp in ms": 1699639208143, "logtype": "training_step"}
{"Avg objective": 24.0546875, "Games time in secs": 92.25369335338473, "Avg game time in secs": 1.4075878212315729, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 25984, "Total num trained steps": 51652, "Timestamp in ms": 1699639241336, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888081227645091, "Avg loss": 2.0443195244297385, "Avg value loss": 1.6231008416507393, "Avg policy loss": 0.4212186746299267, "Total num played games": 26001, "Total num trained steps": 51712, "Timestamp in ms": 1699639266443, "logtype": "training_step"}
{"Total num played games": 26052, "Total num trained steps": 51818, "Timestamp in ms": 1699639333311, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.234375}
{"Ratio train steps to played games": 1.986206896551724, "Avg loss": 3.110776492860168, "Avg value loss": 2.677068112650886, "Avg policy loss": 0.43370838509872556, "Total num played games": 26100, "Total num trained steps": 51840, "Timestamp in ms": 1699639342061, "logtype": "training_step"}
{"Avg objective": 25.0703125, "Games time in secs": 145.1884125676006, "Avg game time in secs": 1.6601322775677545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 26112, "Total num trained steps": 51946, "Timestamp in ms": 1699639386525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874560195808475, "Avg loss": 2.5191065561957657, "Avg value loss": 2.0648390259593725, "Avg policy loss": 0.454267508815974, "Total num played games": 26148, "Total num trained steps": 51968, "Timestamp in ms": 1699639395214, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883587786259542, "Avg loss": 1.241132814437151, "Avg value loss": 0.8090972872450948, "Avg policy loss": 0.4320355353411287, "Total num played games": 26200, "Total num trained steps": 52096, "Timestamp in ms": 1699639447802, "logtype": "training_step"}
{"Avg objective": 23.625, "Games time in secs": 82.30855941213667, "Avg game time in secs": 1.3420494490419514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 26240, "Total num trained steps": 52149, "Timestamp in ms": 1699639468833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894857142857143, "Avg loss": 1.6727169803343713, "Avg value loss": 1.2556944525567815, "Avg policy loss": 0.4170225253328681, "Total num played games": 26250, "Total num trained steps": 52224, "Timestamp in ms": 1699639498762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870568587261823, "Avg loss": 2.2608004771173, "Avg value loss": 1.8342594932764769, "Avg policy loss": 0.4265409871004522, "Total num played games": 26346, "Total num trained steps": 52352, "Timestamp in ms": 1699639550344, "logtype": "training_step"}
{"Total num played games": 26347, "Total num trained steps": 52421, "Timestamp in ms": 1699639624426, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.0390625}
{"Avg objective": 24.859375, "Games time in secs": 157.81690366379917, "Avg game time in secs": 1.5074231684702681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 26368, "Total num trained steps": 52424, "Timestamp in ms": 1699639626650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882174654290585, "Avg loss": 1.986915374174714, "Avg value loss": 1.5496321432292461, "Avg policy loss": 0.43728323467075825, "Total num played games": 26395, "Total num trained steps": 52480, "Timestamp in ms": 1699639649357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988960302457467, "Avg loss": 1.5147394351661205, "Avg value loss": 1.080392997013405, "Avg policy loss": 0.4343464409466833, "Total num played games": 26450, "Total num trained steps": 52608, "Timestamp in ms": 1699639702525, "logtype": "training_step"}
{"Avg objective": 24.53125, "Games time in secs": 92.29323770664632, "Avg game time in secs": 1.4113453733880306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 26496, "Total num trained steps": 52651, "Timestamp in ms": 1699639718944, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894744784396574, "Avg loss": 2.0054254862479866, "Avg value loss": 1.575433379970491, "Avg policy loss": 0.42999212187714875, "Total num played games": 26507, "Total num trained steps": 52736, "Timestamp in ms": 1699639753633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98748026167381, "Avg loss": 1.3541679084300995, "Avg value loss": 0.9327061888761818, "Avg policy loss": 0.4214617090765387, "Total num played games": 26598, "Total num trained steps": 52864, "Timestamp in ms": 1699639804045, "logtype": "training_step"}
{"Avg objective": 24.203125, "Games time in secs": 122.97980230115354, "Avg game time in secs": 1.412056187633425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 26624, "Total num trained steps": 52957, "Timestamp in ms": 1699639841924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881068507541082, "Avg loss": 3.6050431355834007, "Avg value loss": 3.1542044344823807, "Avg policy loss": 0.4508387225214392, "Total num played games": 26654, "Total num trained steps": 52992, "Timestamp in ms": 1699639856057, "logtype": "training_step"}
{"Total num played games": 26654, "Total num trained steps": 53021, "Timestamp in ms": 1699639881766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.81640625}
{"Ratio train steps to played games": 1.989364092577335, "Avg loss": 3.1891918936744332, "Avg value loss": 2.7277540841605514, "Avg policy loss": 0.4614377962425351, "Total num played games": 26702, "Total num trained steps": 53120, "Timestamp in ms": 1699639923988, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905050278494263, "Avg loss": 1.6036461214534938, "Avg value loss": 1.1526393298991024, "Avg policy loss": 0.4510067861992866, "Total num played games": 26751, "Total num trained steps": 53248, "Timestamp in ms": 1699639976011, "logtype": "training_step"}
{"Avg objective": 26.546875, "Games time in secs": 134.19409710913897, "Avg game time in secs": 1.419679618673399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 26752, "Total num trained steps": 53248, "Timestamp in ms": 1699639976118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878216826188968, "Avg loss": 2.765688615385443, "Avg value loss": 2.3000248826574534, "Avg policy loss": 0.46566375670954585, "Total num played games": 26851, "Total num trained steps": 53376, "Timestamp in ms": 1699640026434, "logtype": "training_step"}
{"Avg objective": 24.5, "Games time in secs": 82.26395497471094, "Avg game time in secs": 1.2812136385182384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 26880, "Total num trained steps": 53451, "Timestamp in ms": 1699640058383, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988996282527881, "Avg loss": 1.8421012605540454, "Avg value loss": 1.3791406443342566, "Avg policy loss": 0.4629606534726918, "Total num played games": 26900, "Total num trained steps": 53504, "Timestamp in ms": 1699640079688, "logtype": "training_step"}
{"Total num played games": 26953, "Total num trained steps": 53624, "Timestamp in ms": 1699640148224, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9453125}
{"Ratio train steps to played games": 1.9869956652217406, "Avg loss": 2.037864153739065, "Avg value loss": 1.5607666801661253, "Avg policy loss": 0.4770974663551897, "Total num played games": 26991, "Total num trained steps": 53632, "Timestamp in ms": 1699640151553, "logtype": "training_step"}
{"Avg objective": 24.3515625, "Games time in secs": 140.43103879876435, "Avg game time in secs": 1.7913136453571497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.68, "agent_stopped_0": 0.43}, "Total num played games": 27008, "Total num trained steps": 53749, "Timestamp in ms": 1699640198814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873202469409634, "Avg loss": 2.2995365345850587, "Avg value loss": 1.8218006510287523, "Avg policy loss": 0.4777359098661691, "Total num played games": 27051, "Total num trained steps": 53760, "Timestamp in ms": 1699640203045, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884870848708487, "Avg loss": 2.2301998524926603, "Avg value loss": 1.7575522649567574, "Avg policy loss": 0.472647592658177, "Total num played games": 27100, "Total num trained steps": 53888, "Timestamp in ms": 1699640256250, "logtype": "training_step"}
{"Avg objective": 25.53125, "Games time in secs": 82.92379792407155, "Avg game time in secs": 1.4484063956333557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 27136, "Total num trained steps": 53950, "Timestamp in ms": 1699640281738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989466317999337, "Avg loss": 3.624772785231471, "Avg value loss": 3.1463463080581278, "Avg policy loss": 0.4784265428315848, "Total num played games": 27151, "Total num trained steps": 54016, "Timestamp in ms": 1699640309931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906614213757858, "Avg loss": 1.6440686848945916, "Avg value loss": 1.1727939688134938, "Avg policy loss": 0.47127470187842846, "Total num played games": 27199, "Total num trained steps": 54144, "Timestamp in ms": 1699640361287, "logtype": "training_step"}
{"Total num played games": 27248, "Total num trained steps": 54225, "Timestamp in ms": 1699640414536, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.390625}
{"Avg objective": 24.5078125, "Games time in secs": 134.5275864135474, "Avg game time in secs": 1.632685151489568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 27264, "Total num trained steps": 54229, "Timestamp in ms": 1699640416265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882400351699883, "Avg loss": 2.4314986229874194, "Avg value loss": 1.9683304624632, "Avg policy loss": 0.4631681642495096, "Total num played games": 27296, "Total num trained steps": 54272, "Timestamp in ms": 1699640434320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989067241946689, "Avg loss": 1.7114462512545288, "Avg value loss": 1.2409718967974186, "Avg policy loss": 0.4704743353649974, "Total num played games": 27349, "Total num trained steps": 54400, "Timestamp in ms": 1699640484967, "logtype": "training_step"}
{"Avg objective": 24.1328125, "Games time in secs": 87.92360771261156, "Avg game time in secs": 1.410282604439999, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 27392, "Total num trained steps": 54449, "Timestamp in ms": 1699640504189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899638699317543, "Avg loss": 1.6597512648440897, "Avg value loss": 1.1902507017366588, "Avg policy loss": 0.46950056380592287, "Total num played games": 27401, "Total num trained steps": 54528, "Timestamp in ms": 1699640537794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907120743034055, "Avg loss": 1.9829928553663194, "Avg value loss": 1.5157109720166773, "Avg policy loss": 0.46728185983374715, "Total num played games": 27455, "Total num trained steps": 54656, "Timestamp in ms": 1699640593448, "logtype": "training_step"}
{"Avg objective": 24.2421875, "Games time in secs": 129.22899189405143, "Avg game time in secs": 1.4811965237167897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 27520, "Total num trained steps": 54757, "Timestamp in ms": 1699640633418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880606764407025, "Avg loss": 2.6691169436089694, "Avg value loss": 2.218374356161803, "Avg policy loss": 0.45074261631816626, "Total num played games": 27556, "Total num trained steps": 54784, "Timestamp in ms": 1699640643939, "logtype": "training_step"}
{"Total num played games": 27556, "Total num trained steps": 54825, "Timestamp in ms": 1699640685505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.62890625}
{"Ratio train steps to played games": 1.989240689755108, "Avg loss": 2.8205979727208614, "Avg value loss": 2.3561803644988686, "Avg policy loss": 0.4644176079891622, "Total num played games": 27604, "Total num trained steps": 54912, "Timestamp in ms": 1699640721349, "logtype": "training_step"}
{"Avg objective": 23.0390625, "Games time in secs": 108.72732874937356, "Avg game time in secs": 1.5239432764064986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 27648, "Total num trained steps": 54962, "Timestamp in ms": 1699640742146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902726549504592, "Avg loss": 1.3849101481027901, "Avg value loss": 0.9353263329248875, "Avg policy loss": 0.44958380702883005, "Total num played games": 27654, "Total num trained steps": 55040, "Timestamp in ms": 1699640773985, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987856731046411, "Avg loss": 1.9878046037629247, "Avg value loss": 1.544247368350625, "Avg policy loss": 0.4435572426300496, "Total num played games": 27752, "Total num trained steps": 55168, "Timestamp in ms": 1699640827540, "logtype": "training_step"}
{"Avg objective": 23.6328125, "Games time in secs": 121.09353155270219, "Avg game time in secs": 1.545836380115361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 27776, "Total num trained steps": 55251, "Timestamp in ms": 1699640863239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988814156745675, "Avg loss": 2.1709056911058724, "Avg value loss": 1.7284177769906819, "Avg policy loss": 0.44248789199627936, "Total num played games": 27803, "Total num trained steps": 55296, "Timestamp in ms": 1699640880640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989839514594478, "Avg loss": 2.512296966742724, "Avg value loss": 2.068617060314864, "Avg policy loss": 0.4436799029354006, "Total num played games": 27853, "Total num trained steps": 55424, "Timestamp in ms": 1699640935773, "logtype": "training_step"}
{"Total num played games": 27853, "Total num trained steps": 55429, "Timestamp in ms": 1699640953771, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.46484375}
{"Avg objective": 24.8984375, "Games time in secs": 139.67406783252954, "Avg game time in secs": 1.7130000560136978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 27904, "Total num trained steps": 55548, "Timestamp in ms": 1699641002914, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893285586392122, "Avg loss": 1.2639909498393536, "Avg value loss": 0.8292356294114143, "Avg policy loss": 0.4347553211264312, "Total num played games": 27924, "Total num trained steps": 55552, "Timestamp in ms": 1699641004093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886424515161256, "Avg loss": 2.6197089636698365, "Avg value loss": 2.1991629456169903, "Avg policy loss": 0.4205460462253541, "Total num played games": 27999, "Total num trained steps": 55680, "Timestamp in ms": 1699641055203, "logtype": "training_step"}
{"Avg objective": 25.734375, "Games time in secs": 82.06022216379642, "Avg game time in secs": 1.5447704275138676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 28032, "Total num trained steps": 55747, "Timestamp in ms": 1699641084974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989554367201426, "Avg loss": 2.5518834153190255, "Avg value loss": 2.1243823145050555, "Avg policy loss": 0.4275010973215103, "Total num played games": 28050, "Total num trained steps": 55808, "Timestamp in ms": 1699641110571, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907110826393337, "Avg loss": 1.7827828866429627, "Avg value loss": 1.3542297624517232, "Avg policy loss": 0.42855313909240067, "Total num played games": 28098, "Total num trained steps": 55936, "Timestamp in ms": 1699641164390, "logtype": "training_step"}
{"Total num played games": 28150, "Total num trained steps": 56033, "Timestamp in ms": 1699641218286, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.3671875}
{"Avg objective": 24.015625, "Games time in secs": 134.6360185071826, "Avg game time in secs": 1.6213718401122605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 28160, "Total num trained steps": 56035, "Timestamp in ms": 1699641219610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988190651819278, "Avg loss": 2.323359094094485, "Avg value loss": 1.9040257357992232, "Avg policy loss": 0.4193333014845848, "Total num played games": 28198, "Total num trained steps": 56064, "Timestamp in ms": 1699641230957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989343623875947, "Avg loss": 2.1671853912994266, "Avg value loss": 1.747920824913308, "Avg policy loss": 0.41926456498913467, "Total num played games": 28246, "Total num trained steps": 56192, "Timestamp in ms": 1699641287365, "logtype": "training_step"}
{"Avg objective": 24.578125, "Games time in secs": 88.71508647687733, "Avg game time in secs": 1.5346796641824767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.53}, "Total num played games": 28288, "Total num trained steps": 56241, "Timestamp in ms": 1699641308325, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904926839612638, "Avg loss": 2.3578508882783353, "Avg value loss": 1.9384775150101632, "Avg policy loss": 0.4193733574356884, "Total num played games": 28294, "Total num trained steps": 56320, "Timestamp in ms": 1699641341242, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884105960264902, "Avg loss": 2.5562266958877444, "Avg value loss": 2.14573702798225, "Avg policy loss": 0.4104896595235914, "Total num played games": 28388, "Total num trained steps": 56448, "Timestamp in ms": 1699641392024, "logtype": "training_step"}
{"Avg objective": 26.8671875, "Games time in secs": 121.88911108858883, "Avg game time in secs": 1.5272258782788413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.5, "agent_stopped_0": 0.57}, "Total num played games": 28416, "Total num trained steps": 56542, "Timestamp in ms": 1699641430215, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888560781832243, "Avg loss": 2.568125617224723, "Avg value loss": 2.157026321394369, "Avg policy loss": 0.4110992734786123, "Total num played games": 28446, "Total num trained steps": 56576, "Timestamp in ms": 1699641444216, "logtype": "training_step"}
{"Total num played games": 28446, "Total num trained steps": 56633, "Timestamp in ms": 1699641482900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.01171875}
{"Ratio train steps to played games": 1.9899978942935355, "Avg loss": 1.5237429696135223, "Avg value loss": 1.1141981771215796, "Avg policy loss": 0.40954478341154754, "Total num played games": 28494, "Total num trained steps": 56704, "Timestamp in ms": 1699641515914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910661107802263, "Avg loss": 2.7423015399836004, "Avg value loss": 2.3251338838599622, "Avg policy loss": 0.4171676195692271, "Total num played games": 28543, "Total num trained steps": 56832, "Timestamp in ms": 1699641569711, "logtype": "training_step"}
{"Avg objective": 25.765625, "Games time in secs": 139.5525118112564, "Avg game time in secs": 1.7274699955596589, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.7}, "Total num played games": 28544, "Total num trained steps": 56832, "Timestamp in ms": 1699641569767, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885835980867925, "Avg loss": 2.1640251325443387, "Avg value loss": 1.7593147361185402, "Avg policy loss": 0.40471040131524205, "Total num played games": 28643, "Total num trained steps": 56960, "Timestamp in ms": 1699641625406, "logtype": "training_step"}
{"Avg objective": 24.1484375, "Games time in secs": 87.28312161564827, "Avg game time in secs": 1.3485436650080374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 28672, "Total num trained steps": 57035, "Timestamp in ms": 1699641657050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896141916146795, "Avg loss": 1.6614375398494303, "Avg value loss": 1.259247136535123, "Avg policy loss": 0.4021904398687184, "Total num played games": 28693, "Total num trained steps": 57088, "Timestamp in ms": 1699641679846, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906408739823256, "Avg loss": 2.108801297377795, "Avg value loss": 1.7062705603893846, "Avg policy loss": 0.40253072255291045, "Total num played games": 28742, "Total num trained steps": 57216, "Timestamp in ms": 1699641731509, "logtype": "training_step"}
{"Total num played games": 28794, "Total num trained steps": 57235, "Timestamp in ms": 1699641756443, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.30859375}
{"Avg objective": 25.09375, "Games time in secs": 100.69850879535079, "Avg game time in secs": 1.8581850404880242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.71, "agent_stopped_0": 0.4}, "Total num played games": 28800, "Total num trained steps": 57237, "Timestamp in ms": 1699641757749, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882116358088897, "Avg loss": 3.479051284492016, "Avg value loss": 3.070655716350302, "Avg policy loss": 0.40839555114507675, "Total num played games": 28842, "Total num trained steps": 57344, "Timestamp in ms": 1699641801230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890977053265497, "Avg loss": 1.9007407296448946, "Avg value loss": 1.5042949615744874, "Avg policy loss": 0.3964457942638546, "Total num played games": 28893, "Total num trained steps": 57472, "Timestamp in ms": 1699641854903, "logtype": "training_step"}
{"Avg objective": 25.578125, "Games time in secs": 122.91443568095565, "Avg game time in secs": 1.436121675753384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 28928, "Total num trained steps": 57535, "Timestamp in ms": 1699641880664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902214850903563, "Avg loss": 1.3398937629535794, "Avg value loss": 0.9391728825867176, "Avg policy loss": 0.40072088851593435, "Total num played games": 28941, "Total num trained steps": 57600, "Timestamp in ms": 1699641906936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911354856512142, "Avg loss": 2.061858001165092, "Avg value loss": 1.656171369832009, "Avg policy loss": 0.4056866627652198, "Total num played games": 28992, "Total num trained steps": 57728, "Timestamp in ms": 1699641959351, "logtype": "training_step"}
{"Avg objective": 24.140625, "Games time in secs": 120.82168378867209, "Avg game time in secs": 1.4867050214670599, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 29056, "Total num trained steps": 57829, "Timestamp in ms": 1699642001485, "logtype": "played_game"}
{"Total num played games": 29091, "Total num trained steps": 57836, "Timestamp in ms": 1699642024029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5234375}
{"Ratio train steps to played games": 1.985483372799341, "Avg loss": 2.8753484399057925, "Avg value loss": 2.4621171748731285, "Avg policy loss": 0.41323128272779286, "Total num played games": 29139, "Total num trained steps": 57856, "Timestamp in ms": 1699642033260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989876111053914, "Avg loss": 2.286787146702409, "Avg value loss": 1.8487421981990337, "Avg policy loss": 0.4380449578166008, "Total num played games": 29139, "Total num trained steps": 57984, "Timestamp in ms": 1699642086321, "logtype": "training_step"}
{"Avg objective": 24.109375, "Games time in secs": 102.62361993826926, "Avg game time in secs": 1.4193077275558608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 29184, "Total num trained steps": 58028, "Timestamp in ms": 1699642104109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908527184898421, "Avg loss": 1.533822465222329, "Avg value loss": 1.1186817060224712, "Avg policy loss": 0.4151407745666802, "Total num played games": 29189, "Total num trained steps": 58112, "Timestamp in ms": 1699642138385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882220401474806, "Avg loss": 3.061795420013368, "Avg value loss": 2.635482267360203, "Avg policy loss": 0.4263132237829268, "Total num played games": 29292, "Total num trained steps": 58240, "Timestamp in ms": 1699642190264, "logtype": "training_step"}
{"Avg objective": 24.3359375, "Games time in secs": 123.37449054792523, "Avg game time in secs": 1.4042035740421852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 29312, "Total num trained steps": 58330, "Timestamp in ms": 1699642227484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893319700068166, "Avg loss": 1.929313720203936, "Avg value loss": 1.493777064140886, "Avg policy loss": 0.4355366544332355, "Total num played games": 29340, "Total num trained steps": 58368, "Timestamp in ms": 1699642242906, "logtype": "training_step"}
{"Total num played games": 29396, "Total num trained steps": 58441, "Timestamp in ms": 1699642294406, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9453125}
{"Avg objective": 26.1328125, "Games time in secs": 70.30075309798121, "Avg game time in secs": 1.295458595486707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.5}, "Total num played games": 29440, "Total num trained steps": 58449, "Timestamp in ms": 1699642297785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866865914957208, "Avg loss": 3.0924235470592976, "Avg value loss": 2.657883023843169, "Avg policy loss": 0.43454049970023334, "Total num played games": 29444, "Total num trained steps": 58496, "Timestamp in ms": 1699642317166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909998641488929, "Avg loss": 1.0850257370620966, "Avg value loss": 0.6625857348553836, "Avg policy loss": 0.4224400126840919, "Total num played games": 29444, "Total num trained steps": 58624, "Timestamp in ms": 1699642372271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886605964187793, "Avg loss": 2.7759376289322972, "Avg value loss": 2.3581577092409134, "Avg policy loss": 0.4177799252793193, "Total num played games": 29543, "Total num trained steps": 58752, "Timestamp in ms": 1699642423843, "logtype": "training_step"}
{"Avg objective": 25.5859375, "Games time in secs": 158.9363386183977, "Avg game time in secs": 1.5451480189803988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 29568, "Total num trained steps": 58833, "Timestamp in ms": 1699642456721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895586943299317, "Avg loss": 2.017909300979227, "Avg value loss": 1.5982978318352252, "Avg policy loss": 0.4196114558726549, "Total num played games": 29594, "Total num trained steps": 58880, "Timestamp in ms": 1699642475745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906888873895148, "Avg loss": 1.9529656735248864, "Avg value loss": 1.5358033508528024, "Avg policy loss": 0.41716232779435813, "Total num played games": 29642, "Total num trained steps": 59008, "Timestamp in ms": 1699642526637, "logtype": "training_step"}
{"Total num played games": 29695, "Total num trained steps": 59042, "Timestamp in ms": 1699642564382, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.515625}
{"Avg objective": 24.5390625, "Games time in secs": 108.69593294896185, "Avg game time in secs": 1.6046179935365217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 29696, "Total num trained steps": 59044, "Timestamp in ms": 1699642565417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882325253000706, "Avg loss": 2.5185003424994648, "Avg value loss": 2.0813791018445045, "Avg policy loss": 0.4371212748810649, "Total num played games": 29743, "Total num trained steps": 59136, "Timestamp in ms": 1699642602605, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890917634423038, "Avg loss": 1.3086817357689142, "Avg value loss": 0.8819269484374672, "Avg policy loss": 0.42675479827448726, "Total num played games": 29794, "Total num trained steps": 59264, "Timestamp in ms": 1699642653781, "logtype": "training_step"}
{"Avg objective": 24.6640625, "Games time in secs": 119.523137928918, "Avg game time in secs": 1.3753062896284973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 29824, "Total num trained steps": 59336, "Timestamp in ms": 1699642684940, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901149348255873, "Avg loss": 1.8349084523506463, "Avg value loss": 1.4057226132135838, "Avg policy loss": 0.4291858540382236, "Total num played games": 29843, "Total num trained steps": 59392, "Timestamp in ms": 1699642708033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911347517730495, "Avg loss": 1.3735946058295667, "Avg value loss": 0.9479422939475626, "Avg policy loss": 0.425652330275625, "Total num played games": 29892, "Total num trained steps": 59520, "Timestamp in ms": 1699642760713, "logtype": "training_step"}
{"Avg objective": 23.3359375, "Games time in secs": 119.34319113381207, "Avg game time in secs": 1.3918784622801468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 29952, "Total num trained steps": 59631, "Timestamp in ms": 1699642804284, "logtype": "played_game"}
{"Total num played games": 29992, "Total num trained steps": 59646, "Timestamp in ms": 1699642828214, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.765625}
{"Ratio train steps to played games": 1.9876703655569996, "Avg loss": 3.0948314629495144, "Avg value loss": 2.6562635579612106, "Avg policy loss": 0.43856787169352174, "Total num played games": 30008, "Total num trained steps": 59648, "Timestamp in ms": 1699642829782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898468708388815, "Avg loss": 2.1307037104852498, "Avg value loss": 1.6977705163881183, "Avg policy loss": 0.43293320620432496, "Total num played games": 30040, "Total num trained steps": 59776, "Timestamp in ms": 1699642882556, "logtype": "training_step"}
{"Avg objective": 23.046875, "Games time in secs": 100.59727676212788, "Avg game time in secs": 1.361745956732193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 30080, "Total num trained steps": 59831, "Timestamp in ms": 1699642904881, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908936820765064, "Avg loss": 1.5177590274251997, "Avg value loss": 1.089242716669105, "Avg policy loss": 0.42851629364304245, "Total num played games": 30089, "Total num trained steps": 59904, "Timestamp in ms": 1699642934754, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988439880755217, "Avg loss": 2.4435593765228987, "Avg value loss": 1.9984114918624982, "Avg policy loss": 0.4451478961855173, "Total num played games": 30190, "Total num trained steps": 60032, "Timestamp in ms": 1699642985032, "logtype": "training_step"}
{"Avg objective": 26.171875, "Games time in secs": 120.45468445681036, "Avg game time in secs": 1.4799202334397705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 30208, "Total num trained steps": 60131, "Timestamp in ms": 1699643025336, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891218092844862, "Avg loss": 3.5268090232275426, "Avg value loss": 3.075156110106036, "Avg policy loss": 0.45165291777811944, "Total num played games": 30244, "Total num trained steps": 60160, "Timestamp in ms": 1699643036888, "logtype": "training_step"}
{"Total num played games": 30294, "Total num trained steps": 60248, "Timestamp in ms": 1699643093345, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.51171875}
{"Avg objective": 27.7265625, "Games time in secs": 71.06929653137922, "Avg game time in secs": 1.4690965282934485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 30336, "Total num trained steps": 60255, "Timestamp in ms": 1699643096405, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869158262474458, "Avg loss": 6.162769742775708, "Avg value loss": 5.687834782991558, "Avg policy loss": 0.47493490972556174, "Total num played games": 30342, "Total num trained steps": 60288, "Timestamp in ms": 1699643109295, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911344011601082, "Avg loss": 1.8839722354896367, "Avg value loss": 1.415259571513161, "Avg policy loss": 0.46871267608366907, "Total num played games": 30342, "Total num trained steps": 60416, "Timestamp in ms": 1699643161919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886352438824109, "Avg loss": 1.9260529628954828, "Avg value loss": 1.4807335096411407, "Avg policy loss": 0.445319450693205, "Total num played games": 30445, "Total num trained steps": 60544, "Timestamp in ms": 1699643213573, "logtype": "training_step"}
{"Avg objective": 25.4140625, "Games time in secs": 155.74338163621724, "Avg game time in secs": 1.3122372024081415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 30464, "Total num trained steps": 60638, "Timestamp in ms": 1699643252149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989539268732579, "Avg loss": 2.137428800575435, "Avg value loss": 1.7058141669258475, "Avg policy loss": 0.4316146234050393, "Total num played games": 30495, "Total num trained steps": 60672, "Timestamp in ms": 1699643265047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905382399161864, "Avg loss": 1.7907072380185127, "Avg value loss": 1.342154680751264, "Avg policy loss": 0.4485525474883616, "Total num played games": 30544, "Total num trained steps": 60800, "Timestamp in ms": 1699643316437, "logtype": "training_step"}
{"Avg objective": 25.1015625, "Games time in secs": 80.7879460863769, "Avg game time in secs": 1.52982719548163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 30592, "Total num trained steps": 60842, "Timestamp in ms": 1699643332937, "logtype": "played_game"}
{"Total num played games": 30594, "Total num trained steps": 60848, "Timestamp in ms": 1699643353794, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.73828125}
{"Ratio train steps to played games": 1.9883493244566282, "Avg loss": 2.8431242434307933, "Avg value loss": 2.401654798304662, "Avg policy loss": 0.4414694430306554, "Total num played games": 30642, "Total num trained steps": 60928, "Timestamp in ms": 1699643386984, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893454107067219, "Avg loss": 2.2818011133931577, "Avg value loss": 1.844467589398846, "Avg policy loss": 0.4373335603158921, "Total num played games": 30691, "Total num trained steps": 61056, "Timestamp in ms": 1699643438966, "logtype": "training_step"}
{"Avg objective": 27.453125, "Games time in secs": 135.71638310328126, "Avg game time in secs": 1.2486925688426709, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.42, "agent_stopped_0": 0.62}, "Total num played games": 30720, "Total num trained steps": 61130, "Timestamp in ms": 1699643468653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990241363606792, "Avg loss": 3.6518212626688182, "Avg value loss": 3.2064293581061065, "Avg policy loss": 0.44539189734496176, "Total num played games": 30742, "Total num trained steps": 61184, "Timestamp in ms": 1699643491276, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911987269007176, "Avg loss": 1.6267315903678536, "Avg value loss": 1.1840439999941736, "Avg policy loss": 0.4426875999197364, "Total num played games": 30791, "Total num trained steps": 61312, "Timestamp in ms": 1699643543450, "logtype": "training_step"}
{"Avg objective": 25.9375, "Games time in secs": 123.5999094620347, "Avg game time in secs": 1.5333776964980643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 30848, "Total num trained steps": 61432, "Timestamp in ms": 1699643592253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889608287471674, "Avg loss": 2.412155609577894, "Avg value loss": 1.9727807082235813, "Avg policy loss": 0.439374886918813, "Total num played games": 30890, "Total num trained steps": 61440, "Timestamp in ms": 1699643594925, "logtype": "training_step"}
{"Total num played games": 30893, "Total num trained steps": 61452, "Timestamp in ms": 1699643612816, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.32421875}
{"Ratio train steps to played games": 1.9898193335703436, "Avg loss": 3.5769774671643972, "Avg value loss": 3.1187682647723705, "Avg policy loss": 0.458209159784019, "Total num played games": 30941, "Total num trained steps": 61568, "Timestamp in ms": 1699643660554, "logtype": "training_step"}
{"Avg objective": 25.953125, "Games time in secs": 93.64486776664853, "Avg game time in secs": 1.3321292834589258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 30976, "Total num trained steps": 61631, "Timestamp in ms": 1699643685899, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990835753468861, "Avg loss": 2.2453559059649706, "Avg value loss": 1.8067949139513075, "Avg policy loss": 0.43856101972050965, "Total num played games": 30990, "Total num trained steps": 61696, "Timestamp in ms": 1699643712276, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915278806816352, "Avg loss": 1.2560914508067071, "Avg value loss": 0.8239552667364478, "Avg policy loss": 0.43213618779554963, "Total num played games": 31043, "Total num trained steps": 61824, "Timestamp in ms": 1699643765353, "logtype": "training_step"}
{"Avg objective": 25.6484375, "Games time in secs": 123.240798054263, "Avg game time in secs": 1.4138882030674722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 31104, "Total num trained steps": 61931, "Timestamp in ms": 1699643809139, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894030377958318, "Avg loss": 2.143646744545549, "Avg value loss": 1.7105677998624742, "Avg policy loss": 0.43307891581207514, "Total num played games": 31141, "Total num trained steps": 61952, "Timestamp in ms": 1699643817649, "logtype": "training_step"}
{"Total num played games": 31191, "Total num trained steps": 62052, "Timestamp in ms": 1699643872031, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.82421875}
{"Avg objective": 24.578125, "Games time in secs": 65.76088582538068, "Avg game time in secs": 1.4310040059499443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 31232, "Total num trained steps": 62060, "Timestamp in ms": 1699643874900, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987259515349403, "Avg loss": 3.2301632217131555, "Avg value loss": 2.782354023307562, "Avg policy loss": 0.44780922937206924, "Total num played games": 31239, "Total num trained steps": 62080, "Timestamp in ms": 1699643883127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913249463811262, "Avg loss": 1.504630932584405, "Avg value loss": 1.0610862236935645, "Avg policy loss": 0.44354469259269536, "Total num played games": 31239, "Total num trained steps": 62208, "Timestamp in ms": 1699643938020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890870799961708, "Avg loss": 1.3843376571312547, "Avg value loss": 0.964027123642154, "Avg policy loss": 0.42031052778474987, "Total num played games": 31339, "Total num trained steps": 62336, "Timestamp in ms": 1699643990382, "logtype": "training_step"}
{"Avg objective": 23.34375, "Games time in secs": 153.79491648823023, "Avg game time in secs": 1.3912787835870404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.49}, "Total num played games": 31360, "Total num trained steps": 62427, "Timestamp in ms": 1699644028695, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899646372933193, "Avg loss": 2.3611812493763864, "Avg value loss": 1.9399299481883645, "Avg policy loss": 0.4212513386737555, "Total num played games": 31389, "Total num trained steps": 62464, "Timestamp in ms": 1699644043893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909663464596985, "Avg loss": 1.8095104647800326, "Avg value loss": 1.3785122078843415, "Avg policy loss": 0.43099823757074773, "Total num played games": 31438, "Total num trained steps": 62592, "Timestamp in ms": 1699644100347, "logtype": "training_step"}
{"Total num played games": 31487, "Total num trained steps": 62652, "Timestamp in ms": 1699644144554, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5390625}
{"Avg objective": 26.1328125, "Games time in secs": 116.70630938373506, "Avg game time in secs": 1.4011756720283302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 31488, "Total num trained steps": 62652, "Timestamp in ms": 1699644145402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888695100681781, "Avg loss": 3.6402253173291683, "Avg value loss": 3.208982555195689, "Avg policy loss": 0.4312427754048258, "Total num played games": 31535, "Total num trained steps": 62720, "Timestamp in ms": 1699644173682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898682877406282, "Avg loss": 1.3693348076194525, "Avg value loss": 0.944812037050724, "Avg policy loss": 0.4245227687060833, "Total num played games": 31584, "Total num trained steps": 62848, "Timestamp in ms": 1699644226055, "logtype": "training_step"}
{"Avg objective": 25.03125, "Games time in secs": 108.64552761055529, "Avg game time in secs": 1.222588103832095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 31616, "Total num trained steps": 62916, "Timestamp in ms": 1699644254048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908007460563335, "Avg loss": 1.724967947229743, "Avg value loss": 1.3059922924730927, "Avg policy loss": 0.41897562122903764, "Total num played games": 31633, "Total num trained steps": 62976, "Timestamp in ms": 1699644280477, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917618837194622, "Avg loss": 1.4373307786881924, "Avg value loss": 1.0248697109054774, "Avg policy loss": 0.41246105963364244, "Total num played games": 31682, "Total num trained steps": 63104, "Timestamp in ms": 1699644332676, "logtype": "training_step"}
{"Avg objective": 22.6953125, "Games time in secs": 122.64179274067283, "Avg game time in secs": 1.4885952690965496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 31744, "Total num trained steps": 63213, "Timestamp in ms": 1699644376689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989522371153483, "Avg loss": 2.184407213702798, "Avg value loss": 1.7709787525236607, "Avg policy loss": 0.413428490748629, "Total num played games": 31782, "Total num trained steps": 63232, "Timestamp in ms": 1699644384697, "logtype": "training_step"}
{"Total num played games": 31782, "Total num trained steps": 63256, "Timestamp in ms": 1699644410287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.0390625}
{"Ratio train steps to played games": 1.9905749293119699, "Avg loss": 2.0158399897627532, "Avg value loss": 1.5874874664004892, "Avg policy loss": 0.4283525177743286, "Total num played games": 31830, "Total num trained steps": 63360, "Timestamp in ms": 1699644455166, "logtype": "training_step"}
{"Avg objective": 23.4140625, "Games time in secs": 99.93619470484555, "Avg game time in secs": 1.3660127672192175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 31872, "Total num trained steps": 63412, "Timestamp in ms": 1699644476626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915615785181002, "Avg loss": 1.4984125727787614, "Avg value loss": 1.0865405544172972, "Avg policy loss": 0.41187202697619796, "Total num played games": 31878, "Total num trained steps": 63488, "Timestamp in ms": 1699644510735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989585288046538, "Avg loss": 1.198520946316421, "Avg value loss": 0.793759614112787, "Avg policy loss": 0.4047613323200494, "Total num played games": 31974, "Total num trained steps": 63616, "Timestamp in ms": 1699644563482, "logtype": "training_step"}
{"Avg objective": 22.609375, "Games time in secs": 119.27941611967981, "Avg game time in secs": 1.6002109206310706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 32000, "Total num trained steps": 63696, "Timestamp in ms": 1699644595905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905071196602548, "Avg loss": 1.9916880331002176, "Avg value loss": 1.5814814192708582, "Avg policy loss": 0.41020659916102886, "Total num played games": 32024, "Total num trained steps": 63744, "Timestamp in ms": 1699644617652, "logtype": "training_step"}
{"Total num played games": 32073, "Total num trained steps": 63859, "Timestamp in ms": 1699644684651, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.01953125}
{"Ratio train steps to played games": 1.9884499237259115, "Avg loss": 2.894800747744739, "Avg value loss": 2.4682873249985278, "Avg policy loss": 0.4265134062152356, "Total num played games": 32121, "Total num trained steps": 63872, "Timestamp in ms": 1699644690024, "logtype": "training_step"}
{"Avg objective": 24.421875, "Games time in secs": 143.1550628002733, "Avg game time in secs": 1.5822066242835717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 32128, "Total num trained steps": 63988, "Timestamp in ms": 1699644739060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894619043178214, "Avg loss": 1.70248171268031, "Avg value loss": 1.2765121643897146, "Avg policy loss": 0.4259695215150714, "Total num played games": 32169, "Total num trained steps": 64000, "Timestamp in ms": 1699644743206, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902855369335817, "Avg loss": 2.8850497431121767, "Avg value loss": 2.4553264289861545, "Avg policy loss": 0.42972326348535717, "Total num played games": 32220, "Total num trained steps": 64128, "Timestamp in ms": 1699644797993, "logtype": "training_step"}
{"Avg objective": 25.5859375, "Games time in secs": 85.29887133464217, "Avg game time in secs": 1.3859184058965184, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 32256, "Total num trained steps": 64189, "Timestamp in ms": 1699644824359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910448686167577, "Avg loss": 1.5875933370552957, "Avg value loss": 1.1518366592936218, "Avg policy loss": 0.43575668055564165, "Total num played games": 32272, "Total num trained steps": 64256, "Timestamp in ms": 1699644853529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991986634076916, "Avg loss": 1.199064461980015, "Avg value loss": 0.7811754930298775, "Avg policy loss": 0.41788895218633115, "Total num played games": 32321, "Total num trained steps": 64384, "Timestamp in ms": 1699644905613, "logtype": "training_step"}
{"Total num played games": 32369, "Total num trained steps": 64458, "Timestamp in ms": 1699644952750, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.05859375}
{"Avg objective": 24.953125, "Games time in secs": 130.01373547688127, "Avg game time in secs": 1.8316221908899024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.73, "agent_stopped_0": 0.4}, "Total num played games": 32384, "Total num trained steps": 64460, "Timestamp in ms": 1699644954373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990066940185705, "Avg loss": 3.834112575277686, "Avg value loss": 3.4038820108398795, "Avg policy loss": 0.4302305201999843, "Total num played games": 32417, "Total num trained steps": 64512, "Timestamp in ms": 1699644975695, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910059754820428, "Avg loss": 1.9832204831764102, "Avg value loss": 1.5484142629429698, "Avg policy loss": 0.4348062148783356, "Total num played games": 32466, "Total num trained steps": 64640, "Timestamp in ms": 1699645029885, "logtype": "training_step"}
{"Avg objective": 25.1796875, "Games time in secs": 96.32205242477357, "Avg game time in secs": 1.713417222024873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.7}, "Total num played games": 32512, "Total num trained steps": 64691, "Timestamp in ms": 1699645050695, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919726886879499, "Avg loss": 1.407859378028661, "Avg value loss": 0.9666070695966482, "Avg policy loss": 0.4412522993516177, "Total num played games": 32514, "Total num trained steps": 64768, "Timestamp in ms": 1699645081772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897286524605242, "Avg loss": 2.361073676031083, "Avg value loss": 1.9211649256758392, "Avg policy loss": 0.439908760599792, "Total num played games": 32615, "Total num trained steps": 64896, "Timestamp in ms": 1699645134353, "logtype": "training_step"}
{"Avg objective": 25.5234375, "Games time in secs": 117.7271219510585, "Avg game time in secs": 1.3836247124127112, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.39, "agent_stopped_0": 0.67}, "Total num played games": 32640, "Total num trained steps": 64977, "Timestamp in ms": 1699645168423, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907540642316994, "Avg loss": 2.1552635710686445, "Avg value loss": 1.7351371885742992, "Avg policy loss": 0.42012636992149055, "Total num played games": 32663, "Total num trained steps": 65024, "Timestamp in ms": 1699645187448, "logtype": "training_step"}
{"Total num played games": 32663, "Total num trained steps": 65060, "Timestamp in ms": 1699645222593, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2578125}
{"Ratio train steps to played games": 1.9917153251199902, "Avg loss": 1.8319915244355798, "Avg value loss": 1.408952293684706, "Avg policy loss": 0.42303920607082546, "Total num played games": 32711, "Total num trained steps": 65152, "Timestamp in ms": 1699645261509, "logtype": "training_step"}
{"Avg objective": 26.34375, "Games time in secs": 143.21490202471614, "Avg game time in secs": 1.5962330247275531, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 32768, "Total num trained steps": 65274, "Timestamp in ms": 1699645311638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989758595464521, "Avg loss": 1.8481496181339025, "Avg value loss": 1.426359326695092, "Avg policy loss": 0.42179029039107263, "Total num played games": 32807, "Total num trained steps": 65280, "Timestamp in ms": 1699645313756, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990414168771492, "Avg loss": 1.8729341495782137, "Avg value loss": 1.4517747714417055, "Avg policy loss": 0.42115940316580236, "Total num played games": 32861, "Total num trained steps": 65408, "Timestamp in ms": 1699645367104, "logtype": "training_step"}
{"Avg objective": 23.3984375, "Games time in secs": 81.51788190566003, "Avg game time in secs": 1.461223665086436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 32896, "Total num trained steps": 65472, "Timestamp in ms": 1699645393156, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913400182315406, "Avg loss": 1.5940336543135345, "Avg value loss": 1.1640771094243973, "Avg policy loss": 0.4299565658438951, "Total num played games": 32910, "Total num trained steps": 65536, "Timestamp in ms": 1699645419843, "logtype": "training_step"}
{"Total num played games": 32961, "Total num trained steps": 65662, "Timestamp in ms": 1699645489546, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.87109375}
{"Ratio train steps to played games": 1.9921422286945178, "Avg loss": 2.2283148947171867, "Avg value loss": 1.8023906170856208, "Avg policy loss": 0.4259242811240256, "Total num played games": 32961, "Total num trained steps": 65664, "Timestamp in ms": 1699645490446, "logtype": "training_step"}
{"Avg objective": 26.3203125, "Games time in secs": 139.0083226468414, "Avg game time in secs": 1.5134425444266526, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 33024, "Total num trained steps": 65765, "Timestamp in ms": 1699645532164, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902289983967087, "Avg loss": 2.565670591779053, "Avg value loss": 2.142526175128296, "Avg policy loss": 0.42314441013149917, "Total num played games": 33057, "Total num trained steps": 65792, "Timestamp in ms": 1699645542514, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910894976893103, "Avg loss": 1.7326604132540524, "Avg value loss": 1.30913257796783, "Avg policy loss": 0.4235278363339603, "Total num played games": 33107, "Total num trained steps": 65920, "Timestamp in ms": 1699645594560, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 81.3605247233063, "Avg game time in secs": 1.5860179561859695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 33152, "Total num trained steps": 65966, "Timestamp in ms": 1699645613525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920675614537777, "Avg loss": 0.918511854019016, "Avg value loss": 0.5081995688378811, "Avg policy loss": 0.41031227982603014, "Total num played games": 33155, "Total num trained steps": 66048, "Timestamp in ms": 1699645647127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900162386479823, "Avg loss": 2.566336919553578, "Avg value loss": 2.1531696167076007, "Avg policy loss": 0.41316727572120726, "Total num played games": 33254, "Total num trained steps": 66176, "Timestamp in ms": 1699645699045, "logtype": "training_step"}
{"Avg objective": 26.9453125, "Games time in secs": 117.60394461080432, "Avg game time in secs": 1.4682832133985357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 33280, "Total num trained steps": 66256, "Timestamp in ms": 1699645731129, "logtype": "played_game"}
{"Total num played games": 33303, "Total num trained steps": 66263, "Timestamp in ms": 1699645747625, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.87890625}
{"Ratio train steps to played games": 1.9880363407394082, "Avg loss": 3.348175928927958, "Avg value loss": 2.9192676714155823, "Avg policy loss": 0.428908284753561, "Total num played games": 33351, "Total num trained steps": 66304, "Timestamp in ms": 1699645765269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918743066174927, "Avg loss": 1.0096072466112673, "Avg value loss": 0.5978214431088418, "Avg policy loss": 0.4117857988458127, "Total num played games": 33351, "Total num trained steps": 66432, "Timestamp in ms": 1699645817400, "logtype": "training_step"}
{"Avg objective": 23.359375, "Games time in secs": 132.86650348082185, "Avg game time in secs": 1.464581874126452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 33408, "Total num trained steps": 66546, "Timestamp in ms": 1699645863996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899246591724469, "Avg loss": 1.3925142446532845, "Avg value loss": 0.984630313469097, "Avg policy loss": 0.4078839202411473, "Total num played games": 33448, "Total num trained steps": 66560, "Timestamp in ms": 1699645870037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908350001492672, "Avg loss": 1.9309047400020063, "Avg value loss": 1.522229995811358, "Avg policy loss": 0.408674756065011, "Total num played games": 33497, "Total num trained steps": 66688, "Timestamp in ms": 1699645925397, "logtype": "training_step"}
{"Avg objective": 24.3671875, "Games time in secs": 83.73246887885034, "Avg game time in secs": 1.5120560146024218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.5}, "Total num played games": 33536, "Total num trained steps": 66744, "Timestamp in ms": 1699645947728, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914458585437096, "Avg loss": 1.5658748913556337, "Avg value loss": 1.1521190067287534, "Avg policy loss": 0.41375589137896895, "Total num played games": 33551, "Total num trained steps": 66816, "Timestamp in ms": 1699645979098, "logtype": "training_step"}
{"Total num played games": 33604, "Total num trained steps": 66865, "Timestamp in ms": 1699646025049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.30078125}
{"Ratio train steps to played games": 1.989272554380126, "Avg loss": 3.412704643327743, "Avg value loss": 2.980774137424305, "Avg policy loss": 0.4319304341915995, "Total num played games": 33652, "Total num trained steps": 66944, "Timestamp in ms": 1699646062738, "logtype": "training_step"}
{"Avg objective": 23.5234375, "Games time in secs": 162.44966923631728, "Avg game time in secs": 1.5532827851566253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 33664, "Total num trained steps": 67051, "Timestamp in ms": 1699646110178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901192807548513, "Avg loss": 1.7249121041968465, "Avg value loss": 1.305876842350699, "Avg policy loss": 0.41903526638634503, "Total num played games": 33702, "Total num trained steps": 67072, "Timestamp in ms": 1699646119065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991022488222571, "Avg loss": 2.9748076666146517, "Avg value loss": 2.551561343832873, "Avg policy loss": 0.4232463345397264, "Total num played games": 33751, "Total num trained steps": 67200, "Timestamp in ms": 1699646175947, "logtype": "training_step"}
{"Avg objective": 26.8046875, "Games time in secs": 90.3582891728729, "Avg game time in secs": 1.4300929399614688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 33792, "Total num trained steps": 67254, "Timestamp in ms": 1699646200536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919526627218935, "Avg loss": 2.2139547620899975, "Avg value loss": 1.7822804567404091, "Avg policy loss": 0.4316742850933224, "Total num played games": 33800, "Total num trained steps": 67328, "Timestamp in ms": 1699646236511, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899404094636852, "Avg loss": 2.0672400114126503, "Avg value loss": 1.6409599974285811, "Avg policy loss": 0.4262800198048353, "Total num played games": 33898, "Total num trained steps": 67456, "Timestamp in ms": 1699646295298, "logtype": "training_step"}
{"Total num played games": 33899, "Total num trained steps": 67468, "Timestamp in ms": 1699646317851, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.03515625}
{"Avg objective": 24.8046875, "Games time in secs": 118.9888194128871, "Avg game time in secs": 1.6145650171529269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.53, "agent_stopped_0": 0.54}, "Total num played games": 33920, "Total num trained steps": 67472, "Timestamp in ms": 1699646319525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99083866026453, "Avg loss": 1.9925233977846801, "Avg value loss": 1.5507874465547502, "Avg policy loss": 0.44173594494350255, "Total num played games": 33947, "Total num trained steps": 67584, "Timestamp in ms": 1699646369099, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917637369102248, "Avg loss": 1.611007075291127, "Avg value loss": 1.2028909857617691, "Avg policy loss": 0.40811606403440237, "Total num played games": 33996, "Total num trained steps": 67712, "Timestamp in ms": 1699646426386, "logtype": "training_step"}
{"Avg objective": 23.9921875, "Games time in secs": 160.46844271570444, "Avg game time in secs": 1.6712451380153652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 34048, "Total num trained steps": 67836, "Timestamp in ms": 1699646479994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907855738474631, "Avg loss": 1.01724112033844, "Avg value loss": 0.603546008002013, "Avg policy loss": 0.41369510954245925, "Total num played games": 34077, "Total num trained steps": 67840, "Timestamp in ms": 1699646481217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904820476776197, "Avg loss": 2.406722355633974, "Avg value loss": 1.9818552515935153, "Avg policy loss": 0.4248670570086688, "Total num played games": 34146, "Total num trained steps": 67968, "Timestamp in ms": 1699646536681, "logtype": "training_step"}
{"Avg objective": 24.46875, "Games time in secs": 90.62744569219649, "Avg game time in secs": 1.4117788190196734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 34176, "Total num trained steps": 68041, "Timestamp in ms": 1699646570621, "logtype": "played_game"}
{"Total num played games": 34195, "Total num trained steps": 68070, "Timestamp in ms": 1699646598097, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.609375}
{"Ratio train steps to played games": 1.9885816079198668, "Avg loss": 2.8643126199021935, "Avg value loss": 2.4421260450035334, "Avg policy loss": 0.4221866053994745, "Total num played games": 34243, "Total num trained steps": 68096, "Timestamp in ms": 1699646610008, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992348801214847, "Avg loss": 1.3584282924421132, "Avg value loss": 0.9377852795878425, "Avg policy loss": 0.4206430136691779, "Total num played games": 34243, "Total num trained steps": 68224, "Timestamp in ms": 1699646668045, "logtype": "training_step"}
{"Avg objective": 24.7109375, "Games time in secs": 145.5412564855069, "Avg game time in secs": 1.5307304845482577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 34304, "Total num trained steps": 68331, "Timestamp in ms": 1699646716163, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990361375615154, "Avg loss": 2.72191339218989, "Avg value loss": 2.297777775558643, "Avg policy loss": 0.4241356090642512, "Total num played games": 34341, "Total num trained steps": 68352, "Timestamp in ms": 1699646725313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913053592718601, "Avg loss": 1.7581323352642357, "Avg value loss": 1.3410393211524934, "Avg policy loss": 0.4170930234249681, "Total num played games": 34389, "Total num trained steps": 68480, "Timestamp in ms": 1699646782766, "logtype": "training_step"}
{"Avg objective": 25.9140625, "Games time in secs": 87.89803161658347, "Avg game time in secs": 1.5961961685243296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 34432, "Total num trained steps": 68528, "Timestamp in ms": 1699646804061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921310142570923, "Avg loss": 3.64833179814741, "Avg value loss": 3.2130646898876876, "Avg policy loss": 0.4352671520318836, "Total num played games": 34439, "Total num trained steps": 68608, "Timestamp in ms": 1699646839166, "logtype": "training_step"}
{"Total num played games": 34490, "Total num trained steps": 68672, "Timestamp in ms": 1699646882721, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.42578125}
{"Ratio train steps to played games": 1.9901268168394233, "Avg loss": 1.9205421581864357, "Avg value loss": 1.4783742807339877, "Avg policy loss": 0.44216787070035934, "Total num played games": 34538, "Total num trained steps": 68736, "Timestamp in ms": 1699646911968, "logtype": "training_step"}
{"Avg objective": 24.6640625, "Games time in secs": 147.49205562658608, "Avg game time in secs": 1.659907296372694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 34560, "Total num trained steps": 68823, "Timestamp in ms": 1699646951553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910946625802348, "Avg loss": 1.2799620386213064, "Avg value loss": 0.8530407248763368, "Avg policy loss": 0.4269213113002479, "Total num played games": 34586, "Total num trained steps": 68864, "Timestamp in ms": 1699646973271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917720422657197, "Avg loss": 1.9693817319348454, "Avg value loss": 1.540368635673076, "Avg policy loss": 0.4290130748413503, "Total num played games": 34638, "Total num trained steps": 68992, "Timestamp in ms": 1699647032768, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992562483784485, "Avg loss": 2.3507416513748467, "Avg value loss": 1.9283696496859193, "Avg policy loss": 0.42237198166549206, "Total num played games": 34687, "Total num trained steps": 69120, "Timestamp in ms": 1699647092653, "logtype": "training_step"}
{"Avg objective": 23.9609375, "Games time in secs": 141.1036132965237, "Avg game time in secs": 1.5262635159597266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.58}, "Total num played games": 34688, "Total num trained steps": 69120, "Timestamp in ms": 1699647092657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907716191352345, "Avg loss": 2.7101466502062976, "Avg value loss": 2.277118445141241, "Avg policy loss": 0.4330281999427825, "Total num played games": 34784, "Total num trained steps": 69248, "Timestamp in ms": 1699647149249, "logtype": "training_step"}
{"Total num played games": 34784, "Total num trained steps": 69273, "Timestamp in ms": 1699647176450, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.16796875}
{"Avg objective": 24.4453125, "Games time in secs": 86.6321223191917, "Avg game time in secs": 1.4711284776130924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 34816, "Total num trained steps": 69280, "Timestamp in ms": 1699647179289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991703031694993, "Avg loss": 1.6648000068962574, "Avg value loss": 1.235686230007559, "Avg policy loss": 0.4291137848049402, "Total num played games": 34832, "Total num trained steps": 69376, "Timestamp in ms": 1699647220655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992574754164158, "Avg loss": 2.0376037526875734, "Avg value loss": 1.5992252542637289, "Avg policy loss": 0.4383784979581833, "Total num played games": 34881, "Total num trained steps": 69504, "Timestamp in ms": 1699647279445, "logtype": "training_step"}
{"Avg objective": 24.9765625, "Games time in secs": 145.53518371470273, "Avg game time in secs": 1.6541748761083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 34944, "Total num trained steps": 69608, "Timestamp in ms": 1699647324824, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903670249256804, "Avg loss": 2.258399909362197, "Avg value loss": 1.8258459139615297, "Avg policy loss": 0.43255400005728006, "Total num played games": 34984, "Total num trained steps": 69632, "Timestamp in ms": 1699647334879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912368338423772, "Avg loss": 1.655377026181668, "Avg value loss": 1.2290852149017155, "Avg policy loss": 0.4262917854357511, "Total num played games": 35033, "Total num trained steps": 69760, "Timestamp in ms": 1699647392547, "logtype": "training_step"}
{"Avg objective": 24.328125, "Games time in secs": 92.68454711139202, "Avg game time in secs": 1.4243481297162361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 35072, "Total num trained steps": 69816, "Timestamp in ms": 1699647417509, "logtype": "played_game"}
{"Total num played games": 35082, "Total num trained steps": 69873, "Timestamp in ms": 1699647462945, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.3046875}
{"Ratio train steps to played games": 1.9894107600341588, "Avg loss": 3.1255375775508583, "Avg value loss": 2.6882675962988287, "Avg policy loss": 0.43726999475620687, "Total num played games": 35130, "Total num trained steps": 69888, "Timestamp in ms": 1699647469642, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902217168845935, "Avg loss": 1.573704220354557, "Avg value loss": 1.1341036827070639, "Avg policy loss": 0.4396005608141422, "Total num played games": 35180, "Total num trained steps": 70016, "Timestamp in ms": 1699647528310, "logtype": "training_step"}
{"Avg objective": 24.046875, "Games time in secs": 151.71575714834034, "Avg game time in secs": 1.3299401874974137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 35200, "Total num trained steps": 70108, "Timestamp in ms": 1699647569225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911434086522084, "Avg loss": 2.9667466217651963, "Avg value loss": 2.526308306492865, "Avg policy loss": 0.4404382861685008, "Total num played games": 35228, "Total num trained steps": 70144, "Timestamp in ms": 1699647585211, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919777758879724, "Avg loss": 2.425327862147242, "Avg value loss": 1.9698019449133426, "Avg policy loss": 0.4555259086191654, "Total num played games": 35277, "Total num trained steps": 70272, "Timestamp in ms": 1699647642524, "logtype": "training_step"}
{"Avg objective": 24.171875, "Games time in secs": 88.73300076648593, "Avg game time in secs": 1.776864409999689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.67, "agent_stopped_0": 0.44}, "Total num played games": 35328, "Total num trained steps": 70309, "Timestamp in ms": 1699647657960, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926689122250842, "Avg loss": 2.0024951426312327, "Avg value loss": 1.5624841556418687, "Avg policy loss": 0.4400109751150012, "Total num played games": 35329, "Total num trained steps": 70400, "Timestamp in ms": 1699647696761, "logtype": "training_step"}
{"Total num played games": 35378, "Total num trained steps": 70477, "Timestamp in ms": 1699647743743, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.72265625}
{"Ratio train steps to played games": 1.9908259470445435, "Avg loss": 2.6085649309679866, "Avg value loss": 2.162234138697386, "Avg policy loss": 0.4463308120612055, "Total num played games": 35426, "Total num trained steps": 70528, "Timestamp in ms": 1699647766589, "logtype": "training_step"}
{"Avg objective": 23.765625, "Games time in secs": 142.6177652273327, "Avg game time in secs": 1.568506957977661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 35456, "Total num trained steps": 70600, "Timestamp in ms": 1699647800578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915720043972152, "Avg loss": 1.6252111895009875, "Avg value loss": 1.1946571588050574, "Avg policy loss": 0.4305540269706398, "Total num played games": 35477, "Total num trained steps": 70656, "Timestamp in ms": 1699647827431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924562292405563, "Avg loss": 1.5646477360278368, "Avg value loss": 1.125075208954513, "Avg policy loss": 0.439572547795251, "Total num played games": 35526, "Total num trained steps": 70784, "Timestamp in ms": 1699647885217, "logtype": "training_step"}
{"Avg objective": 25.1796875, "Games time in secs": 136.8636634591967, "Avg game time in secs": 1.5257503133179853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 35584, "Total num trained steps": 70897, "Timestamp in ms": 1699647937441, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904842105263159, "Avg loss": 2.7456973022781312, "Avg value loss": 2.2998311733826995, "Avg policy loss": 0.44586613099090755, "Total num played games": 35625, "Total num trained steps": 70912, "Timestamp in ms": 1699647944583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913382295229018, "Avg loss": 1.9958297545090318, "Avg value loss": 1.5461286220233887, "Avg policy loss": 0.44970113039016724, "Total num played games": 35674, "Total num trained steps": 71040, "Timestamp in ms": 1699648004664, "logtype": "training_step"}
{"Total num played games": 35674, "Total num trained steps": 71078, "Timestamp in ms": 1699648036007, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.6953125}
{"Avg objective": 23.125, "Games time in secs": 102.0698228571564, "Avg game time in secs": 1.750549794480321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 35712, "Total num trained steps": 71087, "Timestamp in ms": 1699648039511, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922456749342141, "Avg loss": 1.7718616821803153, "Avg value loss": 1.3227255567908287, "Avg policy loss": 0.4491361053660512, "Total num played games": 35722, "Total num trained steps": 71168, "Timestamp in ms": 1699648075717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992900069881202, "Avg loss": 1.2018555938266218, "Avg value loss": 0.7584823233773932, "Avg policy loss": 0.4433732863981277, "Total num played games": 35775, "Total num trained steps": 71296, "Timestamp in ms": 1699648131933, "logtype": "training_step"}
{"Avg objective": 24.8515625, "Games time in secs": 137.161358429119, "Avg game time in secs": 1.785184989857953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 35840, "Total num trained steps": 71397, "Timestamp in ms": 1699648176673, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908850174216028, "Avg loss": 2.9733251743018627, "Avg value loss": 2.5295431190170348, "Avg policy loss": 0.4437820459716022, "Total num played games": 35875, "Total num trained steps": 71424, "Timestamp in ms": 1699648188327, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917325464870281, "Avg loss": 1.921801685821265, "Avg value loss": 1.4886238523758948, "Avg policy loss": 0.4331778292544186, "Total num played games": 35924, "Total num trained steps": 71552, "Timestamp in ms": 1699648243652, "logtype": "training_step"}
{"Avg objective": 24.203125, "Games time in secs": 88.50414973497391, "Avg game time in secs": 1.7258027801581193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.65}, "Total num played games": 35968, "Total num trained steps": 71602, "Timestamp in ms": 1699648265177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992577766658327, "Avg loss": 1.5368909337557852, "Avg value loss": 1.1003562207333744, "Avg policy loss": 0.4365347269922495, "Total num played games": 35973, "Total num trained steps": 71680, "Timestamp in ms": 1699648300605, "logtype": "training_step"}
{"Total num played games": 35973, "Total num trained steps": 71681, "Timestamp in ms": 1699648319508, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.03515625}
{"Ratio train steps to played games": 1.9907127609436943, "Avg loss": 2.240430659148842, "Avg value loss": 1.7984606542158872, "Avg policy loss": 0.4419699658174068, "Total num played games": 36071, "Total num trained steps": 71808, "Timestamp in ms": 1699648373596, "logtype": "training_step"}
{"Avg objective": 24.7421875, "Games time in secs": 144.89740937575698, "Avg game time in secs": 1.6264115153899183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 36096, "Total num trained steps": 71891, "Timestamp in ms": 1699648410075, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915007890147005, "Avg loss": 2.1962176617234945, "Avg value loss": 1.7452775810379535, "Avg policy loss": 0.45094009791500866, "Total num played games": 36121, "Total num trained steps": 71936, "Timestamp in ms": 1699648429386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992314284924387, "Avg loss": 1.4217595448717475, "Avg value loss": 0.9818087455350906, "Avg policy loss": 0.43995078722946346, "Total num played games": 36171, "Total num trained steps": 72064, "Timestamp in ms": 1699648485620, "logtype": "training_step"}
{"Avg objective": 23.8203125, "Games time in secs": 129.14668539352715, "Avg game time in secs": 1.83198569790693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 36224, "Total num trained steps": 72186, "Timestamp in ms": 1699648539224, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909266409266408, "Avg loss": 1.5281702824868262, "Avg value loss": 1.0731140410061926, "Avg policy loss": 0.455056227510795, "Total num played games": 36260, "Total num trained steps": 72192, "Timestamp in ms": 1699648541270, "logtype": "training_step"}
{"Total num played games": 36306, "Total num trained steps": 72285, "Timestamp in ms": 1699648601410, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.828125}
{"Avg objective": 23.78125, "Games time in secs": 68.31607863679528, "Avg game time in secs": 1.7370149038761156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.63}, "Total num played games": 36352, "Total num trained steps": 72300, "Timestamp in ms": 1699648607540, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989299664411069, "Avg loss": 3.380496822297573, "Avg value loss": 2.9376570854801685, "Avg policy loss": 0.4428398029413074, "Total num played games": 36354, "Total num trained steps": 72320, "Timestamp in ms": 1699648616192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928205974583264, "Avg loss": 1.442696669138968, "Avg value loss": 0.9888713408727199, "Avg policy loss": 0.45382534922100604, "Total num played games": 36354, "Total num trained steps": 72448, "Timestamp in ms": 1699648673193, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905921720288544, "Avg loss": 2.8572051762603223, "Avg value loss": 2.408190211863257, "Avg policy loss": 0.44901492772623897, "Total num played games": 36459, "Total num trained steps": 72576, "Timestamp in ms": 1699648728311, "logtype": "training_step"}
{"Avg objective": 25.15625, "Games time in secs": 160.1116986013949, "Avg game time in secs": 1.564192213190836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.54, "agent_stopped_0": 0.57}, "Total num played games": 36480, "Total num trained steps": 72665, "Timestamp in ms": 1699648767652, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991481085819158, "Avg loss": 1.7676385478116572, "Avg value loss": 1.311171017587185, "Avg policy loss": 0.45646751299500465, "Total num played games": 36507, "Total num trained steps": 72704, "Timestamp in ms": 1699648783896, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992313163365795, "Avg loss": 1.6491552302613854, "Avg value loss": 1.1973781320266426, "Avg policy loss": 0.45177709264680743, "Total num played games": 36556, "Total num trained steps": 72832, "Timestamp in ms": 1699648843234, "logtype": "training_step"}
{"Total num played games": 36606, "Total num trained steps": 72884, "Timestamp in ms": 1699648886866, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.09375}
{"Avg objective": 23.3046875, "Games time in secs": 120.16112593747675, "Avg game time in secs": 1.7118414905125974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 36608, "Total num trained steps": 72886, "Timestamp in ms": 1699648887813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904785289463633, "Avg loss": 4.422844409476966, "Avg value loss": 3.9574376482050866, "Avg policy loss": 0.4654068255331367, "Total num played games": 36654, "Total num trained steps": 72960, "Timestamp in ms": 1699648919233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991362868508528, "Avg loss": 1.7000402943231165, "Avg value loss": 1.2425052259350196, "Avg policy loss": 0.45753506175242364, "Total num played games": 36702, "Total num trained steps": 73088, "Timestamp in ms": 1699648974573, "logtype": "training_step"}
{"Avg objective": 26.171875, "Games time in secs": 115.57740028575063, "Avg game time in secs": 1.4531122665066505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 36736, "Total num trained steps": 73153, "Timestamp in ms": 1699649003391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922178988326849, "Avg loss": 1.8540225587785244, "Avg value loss": 1.394630067050457, "Avg policy loss": 0.45939248288050294, "Total num played games": 36751, "Total num trained steps": 73216, "Timestamp in ms": 1699649031773, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927996956852516, "Avg loss": 1.4740400845184922, "Avg value loss": 1.0216054572956637, "Avg policy loss": 0.4524346296675503, "Total num played games": 36804, "Total num trained steps": 73344, "Timestamp in ms": 1699649088769, "logtype": "training_step"}
{"Avg objective": 22.75, "Games time in secs": 133.60709512978792, "Avg game time in secs": 1.7292813390376978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 36864, "Total num trained steps": 73455, "Timestamp in ms": 1699649136998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909760988564305, "Avg loss": 1.4820638075470924, "Avg value loss": 1.0484060316812247, "Avg policy loss": 0.4336577942594886, "Total num played games": 36902, "Total num trained steps": 73472, "Timestamp in ms": 1699649144130, "logtype": "training_step"}
{"Total num played games": 36902, "Total num trained steps": 73488, "Timestamp in ms": 1699649166984, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.24609375}
{"Ratio train steps to played games": 1.991853856562923, "Avg loss": 2.4066393659450114, "Avg value loss": 1.9563871258869767, "Avg policy loss": 0.45025226869620383, "Total num played games": 36950, "Total num trained steps": 73600, "Timestamp in ms": 1699649219774, "logtype": "training_step"}
{"Avg objective": 25.015625, "Games time in secs": 105.0703239981085, "Avg game time in secs": 1.5725888854212826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 36992, "Total num trained steps": 73652, "Timestamp in ms": 1699649242068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992675477715614, "Avg loss": 1.964647253509611, "Avg value loss": 1.5330917047103867, "Avg policy loss": 0.4315555435605347, "Total num played games": 36999, "Total num trained steps": 73728, "Timestamp in ms": 1699649275566, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908081298183191, "Avg loss": 2.451108708512038, "Avg value loss": 2.014861944364384, "Avg policy loss": 0.43624673527665436, "Total num played games": 37098, "Total num trained steps": 73856, "Timestamp in ms": 1699649330475, "logtype": "training_step"}
{"Avg objective": 25.3828125, "Games time in secs": 131.98773324489594, "Avg game time in secs": 1.6197234272985952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.55, "agent_stopped_0": 0.56}, "Total num played games": 37120, "Total num trained steps": 73945, "Timestamp in ms": 1699649374056, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914670255720053, "Avg loss": 2.296837540343404, "Avg value loss": 1.8650701299775392, "Avg policy loss": 0.4317674287594855, "Total num played games": 37150, "Total num trained steps": 73984, "Timestamp in ms": 1699649391530, "logtype": "training_step"}
{"Total num played games": 37199, "Total num trained steps": 74088, "Timestamp in ms": 1699649468074, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.94140625}
{"Ratio train steps to played games": 1.9897441404676888, "Avg loss": 3.067898714914918, "Avg value loss": 2.630544990999624, "Avg policy loss": 0.4373537020292133, "Total num played games": 37247, "Total num trained steps": 74112, "Timestamp in ms": 1699649478521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931538110451847, "Avg loss": 1.259932501707226, "Avg value loss": 0.8290017759427428, "Avg policy loss": 0.43093074345961213, "Total num played games": 37247, "Total num trained steps": 74240, "Timestamp in ms": 1699649536093, "logtype": "training_step"}
{"Avg objective": 25.46875, "Games time in secs": 162.0424842275679, "Avg game time in secs": 1.7564836268284125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.75}, "Total num played games": 37248, "Total num trained steps": 74240, "Timestamp in ms": 1699649536100, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991350917124113, "Avg loss": 3.6187378335744143, "Avg value loss": 3.1749293396715075, "Avg policy loss": 0.4438084701541811, "Total num played games": 37345, "Total num trained steps": 74368, "Timestamp in ms": 1699649593910, "logtype": "training_step"}
{"Avg objective": 24.0703125, "Games time in secs": 89.07714246585965, "Avg game time in secs": 1.3705544138501864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 37376, "Total num trained steps": 74439, "Timestamp in ms": 1699649625178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921645183719314, "Avg loss": 1.1601229785010219, "Avg value loss": 0.7346855767536908, "Avg policy loss": 0.425437408965081, "Total num played games": 37394, "Total num trained steps": 74496, "Timestamp in ms": 1699649649475, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992922764661895, "Avg loss": 1.901027999818325, "Avg value loss": 1.4820210669422522, "Avg policy loss": 0.4190069439355284, "Total num played games": 37444, "Total num trained steps": 74624, "Timestamp in ms": 1699649706866, "logtype": "training_step"}
{"Total num played games": 37495, "Total num trained steps": 74688, "Timestamp in ms": 1699649746954, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55078125}
{"Avg objective": 24.0703125, "Games time in secs": 123.3957292381674, "Avg game time in secs": 1.579194047677447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 37504, "Total num trained steps": 74690, "Timestamp in ms": 1699649748573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910768984897318, "Avg loss": 3.702550849877298, "Avg value loss": 3.2559180543757975, "Avg policy loss": 0.44663279759697616, "Total num played games": 37543, "Total num trained steps": 74752, "Timestamp in ms": 1699649777191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991886571610981, "Avg loss": 1.219948602374643, "Avg value loss": 0.8038137969560921, "Avg policy loss": 0.41613481543026865, "Total num played games": 37592, "Total num trained steps": 74880, "Timestamp in ms": 1699649834014, "logtype": "training_step"}
{"Avg objective": 23.8359375, "Games time in secs": 112.99577492848039, "Avg game time in secs": 1.4668893665802898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 37632, "Total num trained steps": 74934, "Timestamp in ms": 1699649861569, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927470775770457, "Avg loss": 1.2627376290038228, "Avg value loss": 0.8546846196986735, "Avg policy loss": 0.4080530102364719, "Total num played games": 37640, "Total num trained steps": 75008, "Timestamp in ms": 1699649896361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909905135407282, "Avg loss": 1.913215596228838, "Avg value loss": 1.5123259259853512, "Avg policy loss": 0.40088967559859157, "Total num played games": 37738, "Total num trained steps": 75136, "Timestamp in ms": 1699649951879, "logtype": "training_step"}
{"Avg objective": 24.1953125, "Games time in secs": 130.02400838956237, "Avg game time in secs": 1.4212225878727622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 37760, "Total num trained steps": 75228, "Timestamp in ms": 1699649991593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991664240916669, "Avg loss": 2.276353480294347, "Avg value loss": 1.8821861119940877, "Avg policy loss": 0.39416737714782357, "Total num played games": 37789, "Total num trained steps": 75264, "Timestamp in ms": 1699650007753, "logtype": "training_step"}
{"Total num played games": 37789, "Total num trained steps": 75290, "Timestamp in ms": 1699650035157, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5078125}
{"Ratio train steps to played games": 1.992520548669292, "Avg loss": 2.2278445987030864, "Avg value loss": 1.8274319579359144, "Avg policy loss": 0.40041265869513154, "Total num played games": 37837, "Total num trained steps": 75392, "Timestamp in ms": 1699650082477, "logtype": "training_step"}
{"Avg objective": 23.546875, "Games time in secs": 104.90604055672884, "Avg game time in secs": 1.4338167750684079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 37888, "Total num trained steps": 75424, "Timestamp in ms": 1699650096500, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931380311427818, "Avg loss": 1.5873895841650665, "Avg value loss": 1.200721129309386, "Avg policy loss": 0.3866684357635677, "Total num played games": 37890, "Total num trained steps": 75520, "Timestamp in ms": 1699650139796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912869514859564, "Avg loss": 2.445466844830662, "Avg value loss": 2.0538518505636603, "Avg policy loss": 0.3916150280274451, "Total num played games": 37989, "Total num trained steps": 75648, "Timestamp in ms": 1699650195718, "logtype": "training_step"}
{"Avg objective": 24.71875, "Games time in secs": 135.00608565285802, "Avg game time in secs": 1.5296707426314242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.55, "agent_stopped_0": 0.56}, "Total num played games": 38016, "Total num trained steps": 75726, "Timestamp in ms": 1699650231506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919821240799158, "Avg loss": 2.4305384852923453, "Avg value loss": 2.051556969061494, "Avg policy loss": 0.3789815134368837, "Total num played games": 38040, "Total num trained steps": 75776, "Timestamp in ms": 1699650253365, "logtype": "training_step"}
{"Total num played games": 38089, "Total num trained steps": 75894, "Timestamp in ms": 1699650317982, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2421875}
{"Ratio train steps to played games": 1.990271914413824, "Avg loss": 1.8682627957314253, "Avg value loss": 1.491433012764901, "Avg policy loss": 0.37682979577220976, "Total num played games": 38137, "Total num trained steps": 75904, "Timestamp in ms": 1699650323429, "logtype": "training_step"}
{"Avg objective": 23.8671875, "Games time in secs": 143.02016999199986, "Avg game time in secs": 1.5829772333527217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 38144, "Total num trained steps": 76020, "Timestamp in ms": 1699650374526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910178856678975, "Avg loss": 1.6270389277487993, "Avg value loss": 1.2559547240380198, "Avg policy loss": 0.37108419579453766, "Total num played games": 38187, "Total num trained steps": 76032, "Timestamp in ms": 1699650379591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917619060072704, "Avg loss": 1.5515037141740322, "Avg value loss": 1.1688709061127156, "Avg policy loss": 0.38263282959815115, "Total num played games": 38237, "Total num trained steps": 76160, "Timestamp in ms": 1699650437341, "logtype": "training_step"}
{"Avg objective": 23.2265625, "Games time in secs": 89.70636046491563, "Avg game time in secs": 1.287585872298223, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 38272, "Total num trained steps": 76223, "Timestamp in ms": 1699650464233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925301016010657, "Avg loss": 1.817225503269583, "Avg value loss": 1.4428835761500522, "Avg policy loss": 0.3743419130332768, "Total num played games": 38287, "Total num trained steps": 76288, "Timestamp in ms": 1699650492311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932702089365366, "Avg loss": 1.5696223070845008, "Avg value loss": 1.1860767586622387, "Avg policy loss": 0.3835455416701734, "Total num played games": 38337, "Total num trained steps": 76416, "Timestamp in ms": 1699650547683, "logtype": "training_step"}
{"Total num played games": 38386, "Total num trained steps": 76497, "Timestamp in ms": 1699650594864, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1875}
{"Avg objective": 24.0703125, "Games time in secs": 132.05698952451348, "Avg game time in secs": 1.3430011141754221, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 38400, "Total num trained steps": 76500, "Timestamp in ms": 1699650596290, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915439454649528, "Avg loss": 3.222336233127862, "Avg value loss": 2.830526391044259, "Avg policy loss": 0.3918098749127239, "Total num played games": 38434, "Total num trained steps": 76544, "Timestamp in ms": 1699650616041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99233427747317, "Avg loss": 0.9232947779819369, "Avg value loss": 0.5458818862680346, "Avg policy loss": 0.3774128865916282, "Total num played games": 38483, "Total num trained steps": 76672, "Timestamp in ms": 1699650671259, "logtype": "training_step"}
{"Avg objective": 23.2421875, "Games time in secs": 94.19781743362546, "Avg game time in secs": 1.3708710739883827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 38528, "Total num trained steps": 76717, "Timestamp in ms": 1699650690488, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931743271651396, "Avg loss": 2.121070702560246, "Avg value loss": 1.7316520866006613, "Avg policy loss": 0.38941861083731055, "Total num played games": 38531, "Total num trained steps": 76800, "Timestamp in ms": 1699650725871, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991405643282423, "Avg loss": 1.9277583500370383, "Avg value loss": 1.5268731720279902, "Avg policy loss": 0.40088514680974185, "Total num played games": 38630, "Total num trained steps": 76928, "Timestamp in ms": 1699650781175, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 122.69577730447054, "Avg game time in secs": 1.2976504924008623, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 38656, "Total num trained steps": 77008, "Timestamp in ms": 1699650813184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921147880041365, "Avg loss": 1.3820237615145743, "Avg value loss": 0.9721455486724153, "Avg policy loss": 0.40987821109592915, "Total num played games": 38680, "Total num trained steps": 77056, "Timestamp in ms": 1699650831949, "logtype": "training_step"}
{"Total num played games": 38680, "Total num trained steps": 77097, "Timestamp in ms": 1699650859110, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9453125}
{"Ratio train steps to played games": 1.9929508366040074, "Avg loss": 1.4864087314344943, "Avg value loss": 1.1044358727522194, "Avg policy loss": 0.3819728677626699, "Total num played games": 38728, "Total num trained steps": 77184, "Timestamp in ms": 1699650893059, "logtype": "training_step"}
{"Avg objective": 24.75, "Games time in secs": 127.468874219805, "Avg game time in secs": 1.5731622354796855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 38784, "Total num trained steps": 77298, "Timestamp in ms": 1699650940653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912685125563425, "Avg loss": 2.5715074993204325, "Avg value loss": 2.1842013810528442, "Avg policy loss": 0.3873061367776245, "Total num played games": 38825, "Total num trained steps": 77312, "Timestamp in ms": 1699650946269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992, "Avg loss": 1.9351477236486971, "Avg value loss": 1.5417851090896875, "Avg policy loss": 0.39336262736469507, "Total num played games": 38875, "Total num trained steps": 77440, "Timestamp in ms": 1699650998589, "logtype": "training_step"}
{"Avg objective": 27.0390625, "Games time in secs": 81.02805222384632, "Avg game time in secs": 1.185076461362769, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 38912, "Total num trained steps": 77499, "Timestamp in ms": 1699651021681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927296082209378, "Avg loss": 2.192212227266282, "Avg value loss": 1.8002335495548323, "Avg policy loss": 0.3919786848127842, "Total num played games": 38925, "Total num trained steps": 77568, "Timestamp in ms": 1699651049008, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933550555455781, "Avg loss": 1.2020997982472181, "Avg value loss": 0.8066773852333426, "Avg policy loss": 0.395422417903319, "Total num played games": 38977, "Total num trained steps": 77696, "Timestamp in ms": 1699651101689, "logtype": "training_step"}
{"Total num played games": 39024, "Total num trained steps": 77700, "Timestamp in ms": 1699651113701, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1875}
{"Avg objective": 24.9453125, "Games time in secs": 93.77068303897977, "Avg game time in secs": 1.198007276369026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.42}, "Total num played games": 39040, "Total num trained steps": 77703, "Timestamp in ms": 1699651115452, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991784398034398, "Avg loss": 2.5798392351716757, "Avg value loss": 2.178759543458, "Avg policy loss": 0.40107967471703887, "Total num played games": 39072, "Total num trained steps": 77824, "Timestamp in ms": 1699651164558, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924087516613844, "Avg loss": 1.4195526437833905, "Avg value loss": 1.0392635572934523, "Avg policy loss": 0.380289098713547, "Total num played games": 39124, "Total num trained steps": 77952, "Timestamp in ms": 1699651215482, "logtype": "training_step"}
{"Avg objective": 23.015625, "Games time in secs": 119.54908671043813, "Avg game time in secs": 1.2624121991539141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.46}, "Total num played games": 39168, "Total num trained steps": 77998, "Timestamp in ms": 1699651235001, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931840808720291, "Avg loss": 0.949766403529793, "Avg value loss": 0.5805050682974979, "Avg policy loss": 0.3692613347666338, "Total num played games": 39173, "Total num trained steps": 78080, "Timestamp in ms": 1699651269722, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912667091024825, "Avg loss": 2.357973902951926, "Avg value loss": 1.9860223298892379, "Avg policy loss": 0.37195156374946237, "Total num played games": 39275, "Total num trained steps": 78208, "Timestamp in ms": 1699651322229, "logtype": "training_step"}
{"Avg objective": 24.3828125, "Games time in secs": 124.50786549970508, "Avg game time in secs": 1.1599358254898107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 39296, "Total num trained steps": 78297, "Timestamp in ms": 1699651359509, "logtype": "played_game"}
{"Total num played games": 39323, "Total num trained steps": 78304, "Timestamp in ms": 1699651376672, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.45703125}
{"Ratio train steps to played games": 1.9896624418988595, "Avg loss": 2.2231008685193956, "Avg value loss": 1.8531782523496076, "Avg policy loss": 0.36992261558771133, "Total num played games": 39371, "Total num trained steps": 78336, "Timestamp in ms": 1699651389753, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929135658225599, "Avg loss": 1.3221408179961145, "Avg value loss": 0.9299671859480441, "Avg policy loss": 0.39217364764772356, "Total num played games": 39371, "Total num trained steps": 78464, "Timestamp in ms": 1699651442097, "logtype": "training_step"}
{"Avg objective": 24.734375, "Games time in secs": 134.22334824874997, "Avg game time in secs": 1.3985049229377182, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 39424, "Total num trained steps": 78588, "Timestamp in ms": 1699651493733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991536375845729, "Avg loss": 1.6250929420348257, "Avg value loss": 1.2418011503759772, "Avg policy loss": 0.3832917807158083, "Total num played games": 39460, "Total num trained steps": 78592, "Timestamp in ms": 1699651494946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99172633656352, "Avg loss": 1.4713989431038499, "Avg value loss": 1.0860164498444647, "Avg policy loss": 0.38538251584395766, "Total num played games": 39523, "Total num trained steps": 78720, "Timestamp in ms": 1699651547917, "logtype": "training_step"}
{"Avg objective": 23.53125, "Games time in secs": 87.76641360856593, "Avg game time in secs": 1.2138499938155292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.43}, "Total num played games": 39552, "Total num trained steps": 78793, "Timestamp in ms": 1699651581499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925703166460287, "Avg loss": 1.3014277080073953, "Avg value loss": 0.9164412410464138, "Avg policy loss": 0.3849864488001913, "Total num played games": 39571, "Total num trained steps": 78848, "Timestamp in ms": 1699651606006, "logtype": "training_step"}
{"Total num played games": 39624, "Total num trained steps": 78906, "Timestamp in ms": 1699651641641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.390625}
{"Ratio train steps to played games": 1.990698729582577, "Avg loss": 2.4248144146986306, "Avg value loss": 2.038803127943538, "Avg policy loss": 0.3860113029368222, "Total num played games": 39672, "Total num trained steps": 78976, "Timestamp in ms": 1699651672139, "logtype": "training_step"}
{"Avg objective": 24.65625, "Games time in secs": 138.13171128742397, "Avg game time in secs": 1.323207459965488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 39680, "Total num trained steps": 79090, "Timestamp in ms": 1699651719631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991515609264854, "Avg loss": 0.9646780919283628, "Avg value loss": 0.5722340166103095, "Avg policy loss": 0.3924440701957792, "Total num played games": 39720, "Total num trained steps": 79104, "Timestamp in ms": 1699651725062, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992055111379293, "Avg loss": 1.9363618749193847, "Avg value loss": 1.5514956938568503, "Avg policy loss": 0.3848661750089377, "Total num played games": 39774, "Total num trained steps": 79232, "Timestamp in ms": 1699651777007, "logtype": "training_step"}
{"Avg objective": 26.5, "Games time in secs": 83.98310693725944, "Avg game time in secs": 1.1632965600292664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 39808, "Total num trained steps": 79296, "Timestamp in ms": 1699651803614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928182206262712, "Avg loss": 2.207360596396029, "Avg value loss": 1.821405625436455, "Avg policy loss": 0.38595495210029185, "Total num played games": 39823, "Total num trained steps": 79360, "Timestamp in ms": 1699651830789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934543813010985, "Avg loss": 1.9626409960910678, "Avg value loss": 1.55255939043127, "Avg policy loss": 0.4100815858691931, "Total num played games": 39874, "Total num trained steps": 79488, "Timestamp in ms": 1699651883665, "logtype": "training_step"}
{"Total num played games": 39924, "Total num trained steps": 79509, "Timestamp in ms": 1699651908900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.09765625}
{"Avg objective": 26.46875, "Games time in secs": 106.92162138037384, "Avg game time in secs": 1.2744834872864885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 39936, "Total num trained steps": 79511, "Timestamp in ms": 1699651910536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917692384669268, "Avg loss": 2.479901507962495, "Avg value loss": 2.0661820142995566, "Avg policy loss": 0.4137195034418255, "Total num played games": 39972, "Total num trained steps": 79616, "Timestamp in ms": 1699651954269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992504122732497, "Avg loss": 1.216185124590993, "Avg value loss": 0.8193565943511203, "Avg policy loss": 0.3968285326845944, "Total num played games": 40022, "Total num trained steps": 79744, "Timestamp in ms": 1699652008310, "logtype": "training_step"}
{"Avg objective": 24.0, "Games time in secs": 119.71086507849395, "Avg game time in secs": 1.3422301649843575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 40064, "Total num trained steps": 79794, "Timestamp in ms": 1699652030247, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932867481906664, "Avg loss": 1.147287488449365, "Avg value loss": 0.7606755130691454, "Avg policy loss": 0.3866119678132236, "Total num played games": 40070, "Total num trained steps": 79872, "Timestamp in ms": 1699652062116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915359721184964, "Avg loss": 1.870876788161695, "Avg value loss": 1.4776760551612824, "Avg policy loss": 0.3932007362600416, "Total num played games": 40170, "Total num trained steps": 80000, "Timestamp in ms": 1699652115557, "logtype": "training_step"}
{"Avg objective": 25.3203125, "Games time in secs": 121.20762162283063, "Avg game time in secs": 1.1920466199953808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 40192, "Total num trained steps": 80088, "Timestamp in ms": 1699652151455, "logtype": "played_game"}
{"Total num played games": 40223, "Total num trained steps": 80109, "Timestamp in ms": 1699652170466, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.828125}
{"Ratio train steps to played games": 1.9897196493754812, "Avg loss": 2.102129617705941, "Avg value loss": 1.7009653919376433, "Avg policy loss": 0.4011642560362816, "Total num played games": 40271, "Total num trained steps": 80128, "Timestamp in ms": 1699652178154, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928732835042586, "Avg loss": 1.306480659171939, "Avg value loss": 0.9173012735554948, "Avg policy loss": 0.38917938666418195, "Total num played games": 40271, "Total num trained steps": 80256, "Timestamp in ms": 1699652231376, "logtype": "training_step"}
{"Avg objective": 23.0703125, "Games time in secs": 95.85514445789158, "Avg game time in secs": 1.417122487560846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 40320, "Total num trained steps": 80296, "Timestamp in ms": 1699652247310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935765482006895, "Avg loss": 0.859724392183125, "Avg value loss": 0.4743317475076765, "Avg policy loss": 0.3853926418814808, "Total num played games": 40321, "Total num trained steps": 80384, "Timestamp in ms": 1699652282765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918852053438891, "Avg loss": 2.6561102299019694, "Avg value loss": 2.249196934630163, "Avg policy loss": 0.4069132674485445, "Total num played games": 40420, "Total num trained steps": 80512, "Timestamp in ms": 1699652335308, "logtype": "training_step"}
{"Avg objective": 26.359375, "Games time in secs": 119.44921970553696, "Avg game time in secs": 1.1795919726719148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.42, "agent_stopped_0": 0.61}, "Total num played games": 40448, "Total num trained steps": 80588, "Timestamp in ms": 1699652366759, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924394040471425, "Avg loss": 1.5491040060296655, "Avg value loss": 1.1337157677626237, "Avg policy loss": 0.41538824746385217, "Total num played games": 40473, "Total num trained steps": 80640, "Timestamp in ms": 1699652389073, "logtype": "training_step"}
{"Total num played games": 40526, "Total num trained steps": 80710, "Timestamp in ms": 1699652433392, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.765625}
{"Ratio train steps to played games": 1.990609750086262, "Avg loss": 3.498837200924754, "Avg value loss": 3.0852386245969683, "Avg policy loss": 0.4135985327884555, "Total num played games": 40574, "Total num trained steps": 80768, "Timestamp in ms": 1699652457705, "logtype": "training_step"}
{"Avg objective": 25.3671875, "Games time in secs": 143.12796287983656, "Avg game time in secs": 1.4733106776693603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.65}, "Total num played games": 40576, "Total num trained steps": 80894, "Timestamp in ms": 1699652509887, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926840082766775, "Avg loss": 0.9015993769280612, "Avg value loss": 0.4765321402810514, "Avg policy loss": 0.4250672310590744, "Total num played games": 40596, "Total num trained steps": 80896, "Timestamp in ms": 1699652510458, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920096376063332, "Avg loss": 2.4287707088515162, "Avg value loss": 2.003779322723858, "Avg policy loss": 0.4249913808889687, "Total num played games": 40674, "Total num trained steps": 81024, "Timestamp in ms": 1699652564459, "logtype": "training_step"}
{"Avg objective": 24.640625, "Games time in secs": 84.04778085462749, "Avg game time in secs": 1.4362507798796287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.61}, "Total num played games": 40704, "Total num trained steps": 81097, "Timestamp in ms": 1699652593935, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992658072437078, "Avg loss": 2.3624784550629556, "Avg value loss": 1.9404028852004558, "Avg policy loss": 0.42207558057270944, "Total num played games": 40725, "Total num trained steps": 81152, "Timestamp in ms": 1699652615419, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934026585569236, "Avg loss": 1.79003548854962, "Avg value loss": 1.3622765354812145, "Avg policy loss": 0.4277589423581958, "Total num played games": 40774, "Total num trained steps": 81280, "Timestamp in ms": 1699652666558, "logtype": "training_step"}
{"Total num played games": 40824, "Total num trained steps": 81312, "Timestamp in ms": 1699652693797, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.890625}
{"Avg objective": 24.5234375, "Games time in secs": 101.12982699647546, "Avg game time in secs": 1.3965897677117027, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.61, "agent_stopped_0": 0.49}, "Total num played games": 40832, "Total num trained steps": 81314, "Timestamp in ms": 1699652695077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917547465257388, "Avg loss": 1.932574037462473, "Avg value loss": 1.4982734702061862, "Avg policy loss": 0.4343005931004882, "Total num played games": 40872, "Total num trained steps": 81408, "Timestamp in ms": 1699652734357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992546432062561, "Avg loss": 1.5230331080965698, "Avg value loss": 1.1032546971691772, "Avg policy loss": 0.41977840196341276, "Total num played games": 40920, "Total num trained steps": 81536, "Timestamp in ms": 1699652786587, "logtype": "training_step"}
{"Avg objective": 24.3046875, "Games time in secs": 113.31938010826707, "Avg game time in secs": 1.356503513699863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 40960, "Total num trained steps": 81591, "Timestamp in ms": 1699652808397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931903053379219, "Avg loss": 1.8931155246682465, "Avg value loss": 1.4729679983574897, "Avg policy loss": 0.42014753073453903, "Total num played games": 40971, "Total num trained steps": 81664, "Timestamp in ms": 1699652838796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991744794837453, "Avg loss": 1.8293299884535372, "Avg value loss": 1.4067375476006418, "Avg policy loss": 0.4225924499332905, "Total num played games": 41065, "Total num trained steps": 81792, "Timestamp in ms": 1699652893983, "logtype": "training_step"}
{"Avg objective": 25.6171875, "Games time in secs": 121.95871920511127, "Avg game time in secs": 1.3998885244800476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 41088, "Total num trained steps": 81881, "Timestamp in ms": 1699652930355, "logtype": "played_game"}
{"Total num played games": 41119, "Total num trained steps": 81915, "Timestamp in ms": 1699652958340, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.23828125}
{"Ratio train steps to played games": 1.990596068330377, "Avg loss": 2.615526028908789, "Avg value loss": 2.1777473324909806, "Avg policy loss": 0.43777872947975993, "Total num played games": 41153, "Total num trained steps": 81920, "Timestamp in ms": 1699652961115, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930283965312021, "Avg loss": 2.381035433616489, "Avg value loss": 1.917441676137969, "Avg policy loss": 0.4635937646962702, "Total num played games": 41167, "Total num trained steps": 82048, "Timestamp in ms": 1699653012411, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9938371951959237, "Avg loss": 1.5091153029352427, "Avg value loss": 1.0614606154849753, "Avg policy loss": 0.4476546610239893, "Total num played games": 41215, "Total num trained steps": 82176, "Timestamp in ms": 1699653067801, "logtype": "training_step"}
{"Avg objective": 24.6796875, "Games time in secs": 137.48282519169152, "Avg game time in secs": 1.4642918377358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.67, "agent_stopped_0": 0.39}, "Total num played games": 41216, "Total num trained steps": 82176, "Timestamp in ms": 1699653067851, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919887697557905, "Avg loss": 2.3926223958842456, "Avg value loss": 1.957715430879034, "Avg policy loss": 0.43490694649517536, "Total num played games": 41317, "Total num trained steps": 82304, "Timestamp in ms": 1699653120198, "logtype": "training_step"}
{"Avg objective": 25.078125, "Games time in secs": 84.46224352903664, "Avg game time in secs": 1.3570902028295677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 41344, "Total num trained steps": 82382, "Timestamp in ms": 1699653152313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926271514213885, "Avg loss": 2.022061157040298, "Avg value loss": 1.5781469313660637, "Avg policy loss": 0.4439142213668674, "Total num played games": 41368, "Total num trained steps": 82432, "Timestamp in ms": 1699653172689, "logtype": "training_step"}
{"Total num played games": 41417, "Total num trained steps": 82519, "Timestamp in ms": 1699653218351, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1875}
{"Ratio train steps to played games": 1.991052695044013, "Avg loss": 2.4209304903633893, "Avg value loss": 1.9823808316141367, "Avg policy loss": 0.43854968855157495, "Total num played games": 41465, "Total num trained steps": 82560, "Timestamp in ms": 1699653235679, "logtype": "training_step"}
{"Avg objective": 23.609375, "Games time in secs": 133.40726512297988, "Avg game time in secs": 1.334045048977714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 41472, "Total num trained steps": 82676, "Timestamp in ms": 1699653285721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918099918099919, "Avg loss": 1.5644365311600268, "Avg value loss": 1.1156475114403293, "Avg policy loss": 0.4487890105228871, "Total num played games": 41514, "Total num trained steps": 82688, "Timestamp in ms": 1699653290569, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925893845339493, "Avg loss": 2.067658811341971, "Avg value loss": 1.625003791647032, "Avg policy loss": 0.4426550208590925, "Total num played games": 41562, "Total num trained steps": 82816, "Timestamp in ms": 1699653343747, "logtype": "training_step"}
{"Avg objective": 26.4375, "Games time in secs": 81.83639835193753, "Avg game time in secs": 1.203221245406894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.46}, "Total num played games": 41600, "Total num trained steps": 82872, "Timestamp in ms": 1699653367557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933429464071137, "Avg loss": 2.5310901585035026, "Avg value loss": 2.0849441858008504, "Avg policy loss": 0.44614595570601523, "Total num played games": 41610, "Total num trained steps": 82944, "Timestamp in ms": 1699653398021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916804526600973, "Avg loss": 2.6074137832038105, "Avg value loss": 2.145519053330645, "Avg policy loss": 0.4618947026319802, "Total num played games": 41709, "Total num trained steps": 83072, "Timestamp in ms": 1699653450996, "logtype": "training_step"}
{"Total num played games": 41710, "Total num trained steps": 83121, "Timestamp in ms": 1699653482103, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.22265625}
{"Avg objective": 23.0859375, "Games time in secs": 116.18666275963187, "Avg game time in secs": 1.4066928258253029, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 41728, "Total num trained steps": 83125, "Timestamp in ms": 1699653483744, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992408640260549, "Avg loss": 1.7133028851822019, "Avg value loss": 1.2447031196206808, "Avg policy loss": 0.46859975974075496, "Total num played games": 41758, "Total num trained steps": 83200, "Timestamp in ms": 1699653514113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928967760451546, "Avg loss": 2.2296311226673424, "Avg value loss": 1.7746847525704652, "Avg policy loss": 0.45494635961949825, "Total num played games": 41812, "Total num trained steps": 83328, "Timestamp in ms": 1699653566817, "logtype": "training_step"}
{"Avg objective": 25.140625, "Games time in secs": 102.32543763518333, "Avg game time in secs": 1.4150988755718572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.63}, "Total num played games": 41856, "Total num trained steps": 83375, "Timestamp in ms": 1699653586070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936932632584807, "Avg loss": 1.44980310741812, "Avg value loss": 1.003329200670123, "Avg policy loss": 0.4464739270042628, "Total num played games": 41860, "Total num trained steps": 83456, "Timestamp in ms": 1699653619872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919210695645957, "Avg loss": 1.9302930240519345, "Avg value loss": 1.4817736223340034, "Avg policy loss": 0.4485193882137537, "Total num played games": 41961, "Total num trained steps": 83584, "Timestamp in ms": 1699653673339, "logtype": "training_step"}
{"Avg objective": 25.296875, "Games time in secs": 121.60385487601161, "Avg game time in secs": 1.3634629071457312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 41984, "Total num trained steps": 83669, "Timestamp in ms": 1699653707674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926446084265652, "Avg loss": 2.740636656060815, "Avg value loss": 2.3079540338367224, "Avg policy loss": 0.4326825924217701, "Total num played games": 42010, "Total num trained steps": 83712, "Timestamp in ms": 1699653725156, "logtype": "training_step"}
{"Total num played games": 42010, "Total num trained steps": 83721, "Timestamp in ms": 1699653745743, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.41796875}
{"Ratio train steps to played games": 1.9934138570545437, "Avg loss": 2.237425783649087, "Avg value loss": 1.790999326389283, "Avg policy loss": 0.44642646121792495, "Total num played games": 42058, "Total num trained steps": 83840, "Timestamp in ms": 1699653799431, "logtype": "training_step"}
{"Avg objective": 24.9140625, "Games time in secs": 142.88643203675747, "Avg game time in secs": 1.4639163823012495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 42112, "Total num trained steps": 83966, "Timestamp in ms": 1699653850560, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929034248688677, "Avg loss": 1.523749217391014, "Avg value loss": 1.0774293700233102, "Avg policy loss": 0.4463198618032038, "Total num played games": 42132, "Total num trained steps": 83968, "Timestamp in ms": 1699653851158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920172446465796, "Avg loss": 2.116188788320869, "Avg value loss": 1.6739103423897177, "Avg policy loss": 0.4422784405760467, "Total num played games": 42216, "Total num trained steps": 84096, "Timestamp in ms": 1699653905818, "logtype": "training_step"}
{"Avg objective": 24.2109375, "Games time in secs": 91.04050368256867, "Avg game time in secs": 1.313718954930664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 42240, "Total num trained steps": 84180, "Timestamp in ms": 1699653941601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925005914360066, "Avg loss": 1.9604396228678524, "Avg value loss": 1.5239820834249258, "Avg policy loss": 0.43645752407610416, "Total num played games": 42270, "Total num trained steps": 84224, "Timestamp in ms": 1699653960962, "logtype": "training_step"}
{"Total num played games": 42318, "Total num trained steps": 84322, "Timestamp in ms": 1699654013555, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.35546875}
{"Ratio train steps to played games": 1.9910069395269792, "Avg loss": 1.6501942691393197, "Avg value loss": 1.205175910377875, "Avg policy loss": 0.4450183834414929, "Total num played games": 42366, "Total num trained steps": 84352, "Timestamp in ms": 1699654026296, "logtype": "training_step"}
{"Avg objective": 23.46875, "Games time in secs": 136.55512391589582, "Avg game time in secs": 1.597896010032855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 42368, "Total num trained steps": 84478, "Timestamp in ms": 1699654078156, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932049830124576, "Avg loss": 0.726754947565496, "Avg value loss": 0.30066281626932323, "Avg policy loss": 0.42609213199466467, "Total num played games": 42383, "Total num trained steps": 84480, "Timestamp in ms": 1699654078830, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924875774203423, "Avg loss": 2.979506173171103, "Avg value loss": 2.542381562292576, "Avg policy loss": 0.4371246653608978, "Total num played games": 42463, "Total num trained steps": 84608, "Timestamp in ms": 1699654133231, "logtype": "training_step"}
{"Avg objective": 24.3125, "Games time in secs": 82.48135356791317, "Avg game time in secs": 1.2801947586558526, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 42496, "Total num trained steps": 84675, "Timestamp in ms": 1699654160637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932019194580355, "Avg loss": 2.5999796502292156, "Avg value loss": 2.149483763612807, "Avg policy loss": 0.4504958991892636, "Total num played games": 42512, "Total num trained steps": 84736, "Timestamp in ms": 1699654184558, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9939146166678414, "Avg loss": 2.701642571017146, "Avg value loss": 2.246779967099428, "Avg policy loss": 0.45486263604834676, "Total num played games": 42561, "Total num trained steps": 84864, "Timestamp in ms": 1699654238579, "logtype": "training_step"}
{"Total num played games": 42610, "Total num trained steps": 84924, "Timestamp in ms": 1699654281270, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7265625}
{"Avg objective": 26.234375, "Games time in secs": 122.56652655079961, "Avg game time in secs": 1.6167509704973781, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.69, "agent_stopped_0": 0.39}, "Total num played games": 42624, "Total num trained steps": 84928, "Timestamp in ms": 1699654283204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924047072061513, "Avg loss": 2.7580224219709635, "Avg value loss": 2.2992337527684867, "Avg policy loss": 0.45878866827115417, "Total num played games": 42658, "Total num trained steps": 84992, "Timestamp in ms": 1699654310097, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930924672770272, "Avg loss": 1.3962518721818924, "Avg value loss": 0.9489269573241472, "Avg policy loss": 0.44732493977062404, "Total num played games": 42707, "Total num trained steps": 85120, "Timestamp in ms": 1699654364378, "logtype": "training_step"}
{"Avg objective": 23.6875, "Games time in secs": 99.51027119718492, "Avg game time in secs": 1.4291353378648637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 42752, "Total num trained steps": 85166, "Timestamp in ms": 1699654382714, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993802039479839, "Avg loss": 1.316331713926047, "Avg value loss": 0.8853541655698791, "Avg policy loss": 0.43097754567861557, "Total num played games": 42756, "Total num trained steps": 85248, "Timestamp in ms": 1699654417353, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99199701346275, "Avg loss": 1.6411163145676255, "Avg value loss": 1.228658804204315, "Avg policy loss": 0.41245749732479453, "Total num played games": 42859, "Total num trained steps": 85376, "Timestamp in ms": 1699654470040, "logtype": "training_step"}
{"Avg objective": 24.5, "Games time in secs": 124.2904976438731, "Avg game time in secs": 1.2467976573389024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 42880, "Total num trained steps": 85465, "Timestamp in ms": 1699654507005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927286286939498, "Avg loss": 2.0816234378144145, "Avg value loss": 1.6697992292465642, "Avg policy loss": 0.4118241991382092, "Total num played games": 42908, "Total num trained steps": 85504, "Timestamp in ms": 1699654522495, "logtype": "training_step"}
{"Total num played games": 42908, "Total num trained steps": 85525, "Timestamp in ms": 1699654542606, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.48828125}
{"Ratio train steps to played games": 1.9934817022069093, "Avg loss": 1.2481933804228902, "Avg value loss": 0.8268346765544266, "Avg policy loss": 0.42135870293714106, "Total num played games": 42956, "Total num trained steps": 85632, "Timestamp in ms": 1699654586623, "logtype": "training_step"}
{"Avg objective": 24.9453125, "Games time in secs": 131.28064204007387, "Avg game time in secs": 1.3493648243165808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 43008, "Total num trained steps": 85754, "Timestamp in ms": 1699654638286, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921252526191084, "Avg loss": 3.385693993419409, "Avg value loss": 2.956018299330026, "Avg policy loss": 0.4296756978146732, "Total num played games": 43049, "Total num trained steps": 85760, "Timestamp in ms": 1699654640153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926453528838568, "Avg loss": 2.599073718767613, "Avg value loss": 2.181156675796956, "Avg policy loss": 0.41791706532239914, "Total num played games": 43102, "Total num trained steps": 85888, "Timestamp in ms": 1699654691919, "logtype": "training_step"}
{"Avg objective": 24.4375, "Games time in secs": 79.9662423003465, "Avg game time in secs": 1.377969423934701, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 43136, "Total num trained steps": 85952, "Timestamp in ms": 1699654718252, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934183082271146, "Avg loss": 1.255831282120198, "Avg value loss": 0.8426602096296847, "Avg policy loss": 0.41317106736823916, "Total num played games": 43150, "Total num trained steps": 86016, "Timestamp in ms": 1699654744435, "logtype": "training_step"}
{"Total num played games": 43199, "Total num trained steps": 86129, "Timestamp in ms": 1699654799823, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7578125}
{"Ratio train steps to played games": 1.9918838300922608, "Avg loss": 1.6566308485344052, "Avg value loss": 1.250784917618148, "Avg policy loss": 0.4058459256775677, "Total num played games": 43247, "Total num trained steps": 86144, "Timestamp in ms": 1699654805860, "logtype": "training_step"}
{"Avg objective": 23.578125, "Games time in secs": 130.6659474056214, "Avg game time in secs": 1.4533748664980521, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 43264, "Total num trained steps": 86241, "Timestamp in ms": 1699654848918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925859201773837, "Avg loss": 1.8296970785595477, "Avg value loss": 1.4219182753004134, "Avg policy loss": 0.40777882980182767, "Total num played games": 43296, "Total num trained steps": 86272, "Timestamp in ms": 1699654861586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993286422886146, "Avg loss": 2.1224850644357502, "Avg value loss": 1.7298337139654905, "Avg policy loss": 0.3926513826008886, "Total num played games": 43345, "Total num trained steps": 86400, "Timestamp in ms": 1699654915464, "logtype": "training_step"}
{"Avg objective": 25.46875, "Games time in secs": 83.36039056256413, "Avg game time in secs": 1.3819973066420062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 43392, "Total num trained steps": 86441, "Timestamp in ms": 1699654932279, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938246002119913, "Avg loss": 2.305270279292017, "Avg value loss": 1.9077192361000925, "Avg policy loss": 0.3975510601885617, "Total num played games": 43398, "Total num trained steps": 86528, "Timestamp in ms": 1699654968404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921147612588794, "Avg loss": 1.6999010401777923, "Avg value loss": 1.302588929887861, "Avg policy loss": 0.3973121023736894, "Total num played games": 43499, "Total num trained steps": 86656, "Timestamp in ms": 1699655021483, "logtype": "training_step"}
{"Total num played games": 43499, "Total num trained steps": 86730, "Timestamp in ms": 1699655061511, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.18359375}
{"Avg objective": 24.4609375, "Games time in secs": 131.11191423609853, "Avg game time in secs": 1.369264701163047, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 43520, "Total num trained steps": 86734, "Timestamp in ms": 1699655063391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992881254736262, "Avg loss": 2.4936007913202047, "Avg value loss": 2.085224442416802, "Avg policy loss": 0.4083763170056045, "Total num played games": 43547, "Total num trained steps": 86784, "Timestamp in ms": 1699655085534, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993600183507283, "Avg loss": 1.8358364417217672, "Avg value loss": 1.4154875914100558, "Avg policy loss": 0.4203488554339856, "Total num played games": 43595, "Total num trained steps": 86912, "Timestamp in ms": 1699655138183, "logtype": "training_step"}
{"Avg objective": 23.875, "Games time in secs": 125.45864163525403, "Avg game time in secs": 1.3536192781466525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 43648, "Total num trained steps": 87036, "Timestamp in ms": 1699655188850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925142503948905, "Avg loss": 2.1168280974961817, "Avg value loss": 1.6987710807006806, "Avg policy loss": 0.41805703612044454, "Total num played games": 43683, "Total num trained steps": 87040, "Timestamp in ms": 1699655190116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927074046133095, "Avg loss": 2.1023486186750233, "Avg value loss": 1.6901553720235825, "Avg policy loss": 0.41219323431141675, "Total num played games": 43743, "Total num trained steps": 87168, "Timestamp in ms": 1699655242458, "logtype": "training_step"}
{"Avg objective": 25.1875, "Games time in secs": 81.0664916858077, "Avg game time in secs": 1.3302390552125871, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 43776, "Total num trained steps": 87236, "Timestamp in ms": 1699655269916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933095857880074, "Avg loss": 1.9440059447661042, "Avg value loss": 1.5335945775732398, "Avg policy loss": 0.4104113618377596, "Total num played games": 43794, "Total num trained steps": 87296, "Timestamp in ms": 1699655295321, "logtype": "training_step"}
{"Total num played games": 43794, "Total num trained steps": 87332, "Timestamp in ms": 1699655323282, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.42578125}
{"Ratio train steps to played games": 1.9940013229021736, "Avg loss": 1.5884089572355151, "Avg value loss": 1.166794447810389, "Avg policy loss": 0.4216145279351622, "Total num played games": 43843, "Total num trained steps": 87424, "Timestamp in ms": 1699655362923, "logtype": "training_step"}
{"Avg objective": 24.8125, "Games time in secs": 136.31308939307928, "Avg game time in secs": 1.6545950950530823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 43904, "Total num trained steps": 87531, "Timestamp in ms": 1699655406230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925125170687301, "Avg loss": 2.189873868599534, "Avg value loss": 1.774003958562389, "Avg policy loss": 0.41586990701034665, "Total num played games": 43940, "Total num trained steps": 87552, "Timestamp in ms": 1699655415747, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931802682427824, "Avg loss": 1.3097821231931448, "Avg value loss": 0.8986684519331902, "Avg policy loss": 0.41111366963014007, "Total num played games": 43990, "Total num trained steps": 87680, "Timestamp in ms": 1699655468740, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 83.02951311133802, "Avg game time in secs": 1.4293428157980088, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.67, "agent_stopped_0": 0.4}, "Total num played games": 44032, "Total num trained steps": 87730, "Timestamp in ms": 1699655489259, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938463634505779, "Avg loss": 0.9722923538647592, "Avg value loss": 0.5651612435467541, "Avg policy loss": 0.4071311086881906, "Total num played games": 44039, "Total num trained steps": 87808, "Timestamp in ms": 1699655520633, "logtype": "training_step"}
{"Total num played games": 44136, "Total num trained steps": 87932, "Timestamp in ms": 1699655583395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.69921875}
{"Ratio train steps to played games": 1.9920936976122514, "Avg loss": 1.2881560698151588, "Avg value loss": 0.8892278075218201, "Avg policy loss": 0.3989282767288387, "Total num played games": 44140, "Total num trained steps": 87936, "Timestamp in ms": 1699655584831, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 96.21675720065832, "Avg game time in secs": 1.4395608426857507, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 44160, "Total num trained steps": 87938, "Timestamp in ms": 1699655585476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993119681332609, "Avg loss": 2.132849669083953, "Avg value loss": 1.7102057577576488, "Avg policy loss": 0.42264390853233635, "Total num played games": 44184, "Total num trained steps": 88064, "Timestamp in ms": 1699655637201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9937378487136592, "Avg loss": 1.1553004244342446, "Avg value loss": 0.7511978013208136, "Avg policy loss": 0.40410261950455606, "Total num played games": 44234, "Total num trained steps": 88192, "Timestamp in ms": 1699655688876, "logtype": "training_step"}
{"Avg objective": 24.03125, "Games time in secs": 151.19510857574642, "Avg game time in secs": 1.5168674392189132, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 44288, "Total num trained steps": 88311, "Timestamp in ms": 1699655736671, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922853082493064, "Avg loss": 1.72770492779091, "Avg value loss": 1.3179317462490872, "Avg policy loss": 0.40977317723445594, "Total num played games": 44331, "Total num trained steps": 88320, "Timestamp in ms": 1699655740249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992722766700462, "Avg loss": 1.902603738475591, "Avg value loss": 1.4937731924001127, "Avg policy loss": 0.40883055166341364, "Total num played games": 44385, "Total num trained steps": 88448, "Timestamp in ms": 1699655792161, "logtype": "training_step"}
{"Avg objective": 25.03125, "Games time in secs": 84.22679832018912, "Avg game time in secs": 1.3340354881365784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 44416, "Total num trained steps": 88519, "Timestamp in ms": 1699655820898, "logtype": "played_game"}
{"Total num played games": 44434, "Total num trained steps": 88532, "Timestamp in ms": 1699655837090, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.87890625}
{"Ratio train steps to played games": 1.9912548896182725, "Avg loss": 2.4888971797190607, "Avg value loss": 2.0783574029337615, "Avg policy loss": 0.4105397202074528, "Total num played games": 44482, "Total num trained steps": 88576, "Timestamp in ms": 1699655856495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9941324580729283, "Avg loss": 0.9388178219087422, "Avg value loss": 0.5299554128432646, "Avg policy loss": 0.40886241220869124, "Total num played games": 44482, "Total num trained steps": 88704, "Timestamp in ms": 1699655911371, "logtype": "training_step"}
{"Avg objective": 23.265625, "Games time in secs": 133.80824086256325, "Avg game time in secs": 1.5514284191158367, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 44544, "Total num trained steps": 88811, "Timestamp in ms": 1699655954707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992575312352796, "Avg loss": 1.474028802011162, "Avg value loss": 1.071011871448718, "Avg policy loss": 0.40301694977097213, "Total num played games": 44581, "Total num trained steps": 88832, "Timestamp in ms": 1699655962917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932556576293972, "Avg loss": 1.9774585529230535, "Avg value loss": 1.5699689883040264, "Avg policy loss": 0.4074895700905472, "Total num played games": 44630, "Total num trained steps": 88960, "Timestamp in ms": 1699656013741, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 80.73478075489402, "Avg game time in secs": 1.42395995008701, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 44672, "Total num trained steps": 89011, "Timestamp in ms": 1699656035442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938898836168308, "Avg loss": 1.4420592333190143, "Avg value loss": 1.0400714845163748, "Avg policy loss": 0.40198773064184934, "Total num played games": 44680, "Total num trained steps": 89088, "Timestamp in ms": 1699656066147, "logtype": "training_step"}
{"Total num played games": 44729, "Total num trained steps": 89134, "Timestamp in ms": 1699656094438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.40234375}
{"Ratio train steps to played games": 1.9924291488934052, "Avg loss": 2.299488885793835, "Avg value loss": 1.8753417667467147, "Avg policy loss": 0.4241471088025719, "Total num played games": 44777, "Total num trained steps": 89216, "Timestamp in ms": 1699656126941, "logtype": "training_step"}
{"Avg objective": 24.640625, "Games time in secs": 125.88591936603189, "Avg game time in secs": 1.3134822338324739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.56, "agent_stopped_0": 0.54}, "Total num played games": 44800, "Total num trained steps": 89302, "Timestamp in ms": 1699656161328, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9930622169674526, "Avg loss": 2.2779480405151844, "Avg value loss": 1.8651872145710513, "Avg policy loss": 0.41276080114766955, "Total num played games": 44827, "Total num trained steps": 89344, "Timestamp in ms": 1699656179767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9937383010963543, "Avg loss": 2.8333580680191517, "Avg value loss": 2.398130068089813, "Avg policy loss": 0.4352280185557902, "Total num played games": 44876, "Total num trained steps": 89472, "Timestamp in ms": 1699656231971, "logtype": "training_step"}
{"Avg objective": 25.6484375, "Games time in secs": 89.6241793949157, "Avg game time in secs": 1.622904036208638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.73, "agent_stopped_0": 0.35}, "Total num played games": 44928, "Total num trained steps": 89519, "Timestamp in ms": 1699656250952, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9942797364672364, "Avg loss": 1.8658018442802131, "Avg value loss": 1.422489894554019, "Avg policy loss": 0.4433119541499764, "Total num played games": 44928, "Total num trained steps": 89600, "Timestamp in ms": 1699656283510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927819482077023, "Avg loss": 3.598116079811007, "Avg value loss": 3.157041826751083, "Avg policy loss": 0.44107415922917426, "Total num played games": 45026, "Total num trained steps": 89728, "Timestamp in ms": 1699656334065, "logtype": "training_step"}
{"Total num played games": 45026, "Total num trained steps": 89734, "Timestamp in ms": 1699656346048, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1015625}
{"Avg objective": 23.4453125, "Games time in secs": 97.2948916759342, "Avg game time in secs": 1.2494132346910192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 45056, "Total num trained steps": 89738, "Timestamp in ms": 1699656348247, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934995784709588, "Avg loss": 2.6864356119185686, "Avg value loss": 2.236722852801904, "Avg policy loss": 0.4497127977665514, "Total num played games": 45074, "Total num trained steps": 89856, "Timestamp in ms": 1699656397225, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9941714868249008, "Avg loss": 2.195480569265783, "Avg value loss": 1.7587456026813015, "Avg policy loss": 0.436734979506582, "Total num played games": 45123, "Total num trained steps": 89984, "Timestamp in ms": 1699656451061, "logtype": "training_step"}
{"Avg objective": 23.875, "Games time in secs": 149.4947362896055, "Avg game time in secs": 1.3840462059743004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 45184, "Total num trained steps": 90096, "Timestamp in ms": 1699656497742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925482044931895, "Avg loss": 1.5054373224265873, "Avg value loss": 1.0742717167595401, "Avg policy loss": 0.4311656185891479, "Total num played games": 45224, "Total num trained steps": 90112, "Timestamp in ms": 1699656503734, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932189163519096, "Avg loss": 1.606805108487606, "Avg value loss": 1.1620588977821171, "Avg policy loss": 0.44474622095003724, "Total num played games": 45273, "Total num trained steps": 90240, "Timestamp in ms": 1699656555886, "logtype": "training_step"}
{"Avg objective": 24.3125, "Games time in secs": 80.81111577153206, "Avg game time in secs": 1.3733785543008707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 45312, "Total num trained steps": 90296, "Timestamp in ms": 1699656578553, "logtype": "played_game"}
{"Total num played games": 45325, "Total num trained steps": 90336, "Timestamp in ms": 1699656606389, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.046875}
{"Ratio train steps to played games": 1.9916470147444516, "Avg loss": 2.0497807320207357, "Avg value loss": 1.5957596402149647, "Avg policy loss": 0.4540210906416178, "Total num played games": 45373, "Total num trained steps": 90368, "Timestamp in ms": 1699656620232, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928211226354848, "Avg loss": 0.917806738987565, "Avg value loss": 0.4791715432656929, "Avg policy loss": 0.4386351970024407, "Total num played games": 45410, "Total num trained steps": 90496, "Timestamp in ms": 1699656672477, "logtype": "training_step"}
{"Avg objective": 24.5625, "Games time in secs": 132.7520748451352, "Avg game time in secs": 1.295273959491169, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 45440, "Total num trained steps": 90593, "Timestamp in ms": 1699656711306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992984539596666, "Avg loss": 1.6010561008006334, "Avg value loss": 1.1572891962714493, "Avg policy loss": 0.44376691174693406, "Total num played games": 45471, "Total num trained steps": 90624, "Timestamp in ms": 1699656724017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9936073460600603, "Avg loss": 1.5590891521424055, "Avg value loss": 1.122395591577515, "Avg policy loss": 0.4366935605648905, "Total num played games": 45521, "Total num trained steps": 90752, "Timestamp in ms": 1699656776330, "logtype": "training_step"}
{"Avg objective": 25.140625, "Games time in secs": 82.61529492586851, "Avg game time in secs": 1.5231598389655119, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.72}, "Total num played games": 45568, "Total num trained steps": 90797, "Timestamp in ms": 1699656793921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9942725477287688, "Avg loss": 1.5383843937888741, "Avg value loss": 1.0905879811616614, "Avg policy loss": 0.4477964201942086, "Total num played games": 45570, "Total num trained steps": 90880, "Timestamp in ms": 1699656827418, "logtype": "training_step"}
{"Total num played games": 45620, "Total num trained steps": 90939, "Timestamp in ms": 1699656863983, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.65234375}
{"Ratio train steps to played games": 1.992817727949549, "Avg loss": 2.915346251334995, "Avg value loss": 2.4560270172078162, "Avg policy loss": 0.459319235291332, "Total num played games": 45668, "Total num trained steps": 91008, "Timestamp in ms": 1699656893966, "logtype": "training_step"}
{"Avg objective": 22.9296875, "Games time in secs": 132.32962524145842, "Avg game time in secs": 1.4123106597253354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 45696, "Total num trained steps": 91084, "Timestamp in ms": 1699656926251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932853612125718, "Avg loss": 1.423492276109755, "Avg value loss": 0.9667151222238317, "Avg policy loss": 0.45677715027704835, "Total num played games": 45721, "Total num trained steps": 91136, "Timestamp in ms": 1699656948102, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9938608756444989, "Avg loss": 1.9152973601594567, "Avg value loss": 1.446913443156518, "Avg policy loss": 0.46838391572237015, "Total num played games": 45772, "Total num trained steps": 91264, "Timestamp in ms": 1699657000311, "logtype": "training_step"}
{"Avg objective": 26.3828125, "Games time in secs": 123.58985904790461, "Avg game time in secs": 1.555631363618886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.77, "agent_stopped_0": 0.38}, "Total num played games": 45824, "Total num trained steps": 91386, "Timestamp in ms": 1699657049841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926087430502561, "Avg loss": 1.7999682105146348, "Avg value loss": 1.3316530515439808, "Avg policy loss": 0.468315152451396, "Total num played games": 45865, "Total num trained steps": 91392, "Timestamp in ms": 1699657051659, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928793850575963, "Avg loss": 2.673931820783764, "Avg value loss": 2.1911747630219907, "Avg policy loss": 0.48275704565458, "Total num played games": 45923, "Total num trained steps": 91520, "Timestamp in ms": 1699657105365, "logtype": "training_step"}
{"Total num played games": 45923, "Total num trained steps": 91540, "Timestamp in ms": 1699657124550, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6953125}
{"Avg objective": 24.84375, "Games time in secs": 77.03610081039369, "Avg game time in secs": 1.3599822299001971, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 45952, "Total num trained steps": 91546, "Timestamp in ms": 1699657126877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935829109656087, "Avg loss": 2.1135504757985473, "Avg value loss": 1.6297618355602026, "Avg policy loss": 0.48378861090168357, "Total num played games": 45971, "Total num trained steps": 91648, "Timestamp in ms": 1699657169856, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9942416340721425, "Avg loss": 1.5993980811908841, "Avg value loss": 1.1326427697204053, "Avg policy loss": 0.4667553270701319, "Total num played games": 46020, "Total num trained steps": 91776, "Timestamp in ms": 1699657221840, "logtype": "training_step"}
{"Avg objective": 26.03125, "Games time in secs": 142.3102892320603, "Avg game time in secs": 1.4422201928537106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 46080, "Total num trained steps": 91888, "Timestamp in ms": 1699657269188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992714657415438, "Avg loss": 1.9890848277136683, "Avg value loss": 1.5140905734151602, "Avg policy loss": 0.47499423613771796, "Total num played games": 46120, "Total num trained steps": 91904, "Timestamp in ms": 1699657275899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933505165803895, "Avg loss": 2.328153580892831, "Avg value loss": 1.8459105836227536, "Avg policy loss": 0.482243002159521, "Total num played games": 46169, "Total num trained steps": 92032, "Timestamp in ms": 1699657327980, "logtype": "training_step"}
{"Avg objective": 27.6015625, "Games time in secs": 82.3892447091639, "Avg game time in secs": 1.3545556633762317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.6}, "Total num played games": 46208, "Total num trained steps": 92088, "Timestamp in ms": 1699657351577, "logtype": "played_game"}
{"Total num played games": 46220, "Total num trained steps": 92142, "Timestamp in ms": 1699657382653, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9375}
{"Ratio train steps to played games": 1.9918518198322814, "Avg loss": 2.373942465055734, "Avg value loss": 1.8834820659831166, "Avg policy loss": 0.490460412343964, "Total num played games": 46268, "Total num trained steps": 92160, "Timestamp in ms": 1699657389762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927662974239382, "Avg loss": 1.3273059423081577, "Avg value loss": 0.8283771796850488, "Avg policy loss": 0.49892875109799206, "Total num played games": 46311, "Total num trained steps": 92288, "Timestamp in ms": 1699657442932, "logtype": "training_step"}
{"Avg objective": 24.7421875, "Games time in secs": 129.42167961969972, "Avg game time in secs": 1.4014207623549737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 46336, "Total num trained steps": 92379, "Timestamp in ms": 1699657480999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931201069726314, "Avg loss": 2.047734214924276, "Avg value loss": 1.5511122094467282, "Avg policy loss": 0.4966220282949507, "Total num played games": 46367, "Total num trained steps": 92416, "Timestamp in ms": 1699657496345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9937307452011117, "Avg loss": 1.7391275437548757, "Avg value loss": 1.242238258710131, "Avg policy loss": 0.49688929063268006, "Total num played games": 46417, "Total num trained steps": 92544, "Timestamp in ms": 1699657548268, "logtype": "training_step"}
{"Avg objective": 24.8203125, "Games time in secs": 84.05958291515708, "Avg game time in secs": 1.4705367853312055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.71}, "Total num played games": 46464, "Total num trained steps": 92587, "Timestamp in ms": 1699657565059, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943400692964899, "Avg loss": 1.8667195574380457, "Avg value loss": 1.3725094344699755, "Avg policy loss": 0.4942101405467838, "Total num played games": 46467, "Total num trained steps": 92672, "Timestamp in ms": 1699657600460, "logtype": "training_step"}
{"Total num played games": 46516, "Total num trained steps": 92746, "Timestamp in ms": 1699657642204, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.75390625}
{"Ratio train steps to played games": 1.9929559316209948, "Avg loss": 1.7840373255312443, "Avg value loss": 1.2836074982769787, "Avg policy loss": 0.5004298368003219, "Total num played games": 46564, "Total num trained steps": 92800, "Timestamp in ms": 1699657665320, "logtype": "training_step"}
{"Avg objective": 23.046875, "Games time in secs": 133.44642260670662, "Avg game time in secs": 1.3748189083853504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.56, "agent_stopped_0": 0.45}, "Total num played games": 46592, "Total num trained steps": 92875, "Timestamp in ms": 1699657698505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936282502359908, "Avg loss": 1.237198419868946, "Avg value loss": 0.7560522384010255, "Avg policy loss": 0.48114618193358183, "Total num played games": 46612, "Total num trained steps": 92928, "Timestamp in ms": 1699657720856, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9942778765993014, "Avg loss": 1.2636411716230214, "Avg value loss": 0.7905853036791086, "Avg policy loss": 0.4730558693408966, "Total num played games": 46661, "Total num trained steps": 93056, "Timestamp in ms": 1699657773000, "logtype": "training_step"}
{"Avg objective": 24.7265625, "Games time in secs": 123.51618402078748, "Avg game time in secs": 1.4169712975126458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.65, "agent_stopped_0": 0.4}, "Total num played games": 46720, "Total num trained steps": 93164, "Timestamp in ms": 1699657822021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928356038409718, "Avg loss": 2.446634752675891, "Avg value loss": 1.974441958242096, "Avg policy loss": 0.47219279618002474, "Total num played games": 46759, "Total num trained steps": 93184, "Timestamp in ms": 1699657830373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935266092678445, "Avg loss": 1.504048221744597, "Avg value loss": 1.0239174249581993, "Avg policy loss": 0.4801307904999703, "Total num played games": 46807, "Total num trained steps": 93312, "Timestamp in ms": 1699657888901, "logtype": "training_step"}
{"Total num played games": 46807, "Total num trained steps": 93350, "Timestamp in ms": 1699657915219, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.40234375}
{"Avg objective": 23.734375, "Games time in secs": 96.57660957425833, "Avg game time in secs": 1.4038328816968715, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 46848, "Total num trained steps": 93357, "Timestamp in ms": 1699657918598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9942161989115357, "Avg loss": 1.6715442026033998, "Avg value loss": 1.201935585704632, "Avg policy loss": 0.46960861748084426, "Total num played games": 46855, "Total num trained steps": 93440, "Timestamp in ms": 1699657955845, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928013119502481, "Avg loss": 1.6530508762225509, "Avg value loss": 1.1903092387365177, "Avg policy loss": 0.46274164062924683, "Total num played games": 46953, "Total num trained steps": 93568, "Timestamp in ms": 1699658010857, "logtype": "training_step"}
{"Avg objective": 24.1875, "Games time in secs": 130.2082648742944, "Avg game time in secs": 1.3433307547529694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 46976, "Total num trained steps": 93654, "Timestamp in ms": 1699658048807, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934682240803387, "Avg loss": 2.3899436709471047, "Avg value loss": 1.9124795835232362, "Avg policy loss": 0.47746409638784826, "Total num played games": 47001, "Total num trained steps": 93696, "Timestamp in ms": 1699658067797, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940278840431862, "Avg loss": 1.8438625992275774, "Avg value loss": 1.3811033689416945, "Avg policy loss": 0.4627592535689473, "Total num played games": 47052, "Total num trained steps": 93824, "Timestamp in ms": 1699658128662, "logtype": "training_step"}
{"Avg objective": 25.8046875, "Games time in secs": 135.315539451316, "Avg game time in secs": 1.5134643887577113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.66, "agent_stopped_0": 0.45}, "Total num played games": 47104, "Total num trained steps": 93946, "Timestamp in ms": 1699658184122, "logtype": "played_game"}
{"Total num played games": 47151, "Total num trained steps": 93951, "Timestamp in ms": 1699658198627, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.52734375}
{"Ratio train steps to played games": 1.992534781133356, "Avg loss": 1.5814092941582203, "Avg value loss": 1.1386962973047048, "Avg policy loss": 0.4427129898685962, "Total num played games": 47151, "Total num trained steps": 93952, "Timestamp in ms": 1699658199416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932413822326744, "Avg loss": 4.3557775765657425, "Avg value loss": 3.870599411195144, "Avg policy loss": 0.48517819843254983, "Total num played games": 47199, "Total num trained steps": 94080, "Timestamp in ms": 1699658256533, "logtype": "training_step"}
{"Avg objective": 26.359375, "Games time in secs": 102.65044270083308, "Avg game time in secs": 1.3536227779986802, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 47232, "Total num trained steps": 94146, "Timestamp in ms": 1699658286773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9939045038943448, "Avg loss": 1.472662590444088, "Avg value loss": 1.011627547442913, "Avg policy loss": 0.4610350381117314, "Total num played games": 47248, "Total num trained steps": 94208, "Timestamp in ms": 1699658315726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9945239655792122, "Avg loss": 1.6973645468242466, "Avg value loss": 1.234842334757559, "Avg policy loss": 0.4625222042668611, "Total num played games": 47297, "Total num trained steps": 94336, "Timestamp in ms": 1699658371382, "logtype": "training_step"}
{"Avg objective": 23.8671875, "Games time in secs": 127.75075987912714, "Avg game time in secs": 1.44385482443613, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 47360, "Total num trained steps": 94436, "Timestamp in ms": 1699658414524, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931846475217858, "Avg loss": 1.7525200694799423, "Avg value loss": 1.3023505271412432, "Avg policy loss": 0.4501695139333606, "Total num played games": 47393, "Total num trained steps": 94464, "Timestamp in ms": 1699658426759, "logtype": "training_step"}
{"Total num played games": 47445, "Total num trained steps": 94554, "Timestamp in ms": 1699658478874, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0}
{"Avg objective": 23.015625, "Games time in secs": 67.87949255295098, "Avg game time in secs": 1.3259955916728359, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 47488, "Total num trained steps": 94561, "Timestamp in ms": 1699658482403, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916829848609268, "Avg loss": 2.2706969743594527, "Avg value loss": 1.8072348905261606, "Avg policy loss": 0.463462091749534, "Total num played games": 47493, "Total num trained steps": 94592, "Timestamp in ms": 1699658497051, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994378118880677, "Avg loss": 0.8655931930989027, "Avg value loss": 0.41014928300864995, "Avg policy loss": 0.4554439156781882, "Total num played games": 47493, "Total num trained steps": 94720, "Timestamp in ms": 1699658557350, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930027316663164, "Avg loss": 1.9552742429077625, "Avg value loss": 1.5085518145933747, "Avg policy loss": 0.44672239222563803, "Total num played games": 47590, "Total num trained steps": 94848, "Timestamp in ms": 1699658612726, "logtype": "training_step"}
{"Avg objective": 26.3828125, "Games time in secs": 166.19803461432457, "Avg game time in secs": 1.3087775705644162, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 47616, "Total num trained steps": 94927, "Timestamp in ms": 1699658648602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936396649803731, "Avg loss": 2.345196946989745, "Avg value loss": 1.8932578614912927, "Avg policy loss": 0.4519390701316297, "Total num played games": 47639, "Total num trained steps": 94976, "Timestamp in ms": 1699658669645, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9943171094847651, "Avg loss": 2.3777328324504197, "Avg value loss": 1.9068250965792686, "Avg policy loss": 0.4709077049046755, "Total num played games": 47687, "Total num trained steps": 95104, "Timestamp in ms": 1699658728244, "logtype": "training_step"}
{"Total num played games": 47736, "Total num trained steps": 95155, "Timestamp in ms": 1699658764559, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0859375}
{"Avg objective": 26.6640625, "Games time in secs": 117.33327324874699, "Avg game time in secs": 1.4276867260341533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 47744, "Total num trained steps": 95157, "Timestamp in ms": 1699658765935, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929474301021262, "Avg loss": 3.529306943528354, "Avg value loss": 3.066373009234667, "Avg policy loss": 0.4629339617677033, "Total num played games": 47784, "Total num trained steps": 95232, "Timestamp in ms": 1699658798757, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935818368072251, "Avg loss": 1.1510735000483692, "Avg value loss": 0.6943108757259324, "Avg policy loss": 0.4567626260686666, "Total num played games": 47833, "Total num trained steps": 95360, "Timestamp in ms": 1699658855808, "logtype": "training_step"}
{"Avg objective": 24.1015625, "Games time in secs": 114.72579526901245, "Avg game time in secs": 1.2063508244318655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 47872, "Total num trained steps": 95414, "Timestamp in ms": 1699658880661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9941732974124429, "Avg loss": 1.7740362952463329, "Avg value loss": 1.3287987657822669, "Avg policy loss": 0.4452375241089612, "Total num played games": 47883, "Total num trained steps": 95488, "Timestamp in ms": 1699658912996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929341142630843, "Avg loss": 1.6858421289362013, "Avg value loss": 1.2487490688217804, "Avg policy loss": 0.43709308141842484, "Total num played games": 47977, "Total num trained steps": 95616, "Timestamp in ms": 1699658968176, "logtype": "training_step"}
{"Avg objective": 25.3125, "Games time in secs": 129.05648119933903, "Avg game time in secs": 1.3291568608838134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 48000, "Total num trained steps": 95711, "Timestamp in ms": 1699659009717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933999583593587, "Avg loss": 2.470937667414546, "Avg value loss": 2.0288905469933525, "Avg policy loss": 0.442047125659883, "Total num played games": 48030, "Total num trained steps": 95744, "Timestamp in ms": 1699659024846, "logtype": "training_step"}
{"Total num played games": 48030, "Total num trained steps": 95758, "Timestamp in ms": 1699659042731, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5234375}
{"Ratio train steps to played games": 1.994092932318316, "Avg loss": 1.6382634239271283, "Avg value loss": 1.1883553946390748, "Avg policy loss": 0.4499080025125295, "Total num played games": 48078, "Total num trained steps": 95872, "Timestamp in ms": 1699659093712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994722297255179, "Avg loss": 1.9058259595185518, "Avg value loss": 1.4718733592890203, "Avg policy loss": 0.43395262584090233, "Total num played games": 48127, "Total num trained steps": 96000, "Timestamp in ms": 1699659148940, "logtype": "training_step"}
{"Avg objective": 22.921875, "Games time in secs": 139.31741268001497, "Avg game time in secs": 1.5371679282106925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.75, "agent_stopped_0": 0.3}, "Total num played games": 48128, "Total num trained steps": 96000, "Timestamp in ms": 1699659149035, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931369093284124, "Avg loss": 2.8693604059517384, "Avg value loss": 2.421698536723852, "Avg policy loss": 0.4476618655025959, "Total num played games": 48229, "Total num trained steps": 96128, "Timestamp in ms": 1699659204382, "logtype": "training_step"}
{"Avg objective": 25.4453125, "Games time in secs": 90.03236446902156, "Avg game time in secs": 1.230023276672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 48256, "Total num trained steps": 96206, "Timestamp in ms": 1699659239068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9937446923092856, "Avg loss": 1.4387679155915976, "Avg value loss": 0.9931518683442846, "Avg policy loss": 0.4456160443369299, "Total num played games": 48279, "Total num trained steps": 96256, "Timestamp in ms": 1699659260633, "logtype": "training_step"}
{"Total num played games": 48328, "Total num trained steps": 96361, "Timestamp in ms": 1699659318954, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.63671875}
{"Ratio train steps to played games": 1.9923722507028279, "Avg loss": 2.1659445143304765, "Avg value loss": 1.7284621575381607, "Avg policy loss": 0.4374823903199285, "Total num played games": 48376, "Total num trained steps": 96384, "Timestamp in ms": 1699659328702, "logtype": "training_step"}
{"Avg objective": 25.5234375, "Games time in secs": 141.29295072890818, "Avg game time in secs": 1.4229284436441958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 48384, "Total num trained steps": 96498, "Timestamp in ms": 1699659380361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993020134228188, "Avg loss": 1.588706612586975, "Avg value loss": 1.150569538003765, "Avg policy loss": 0.43813707400113344, "Total num played games": 48425, "Total num trained steps": 96512, "Timestamp in ms": 1699659387132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935227014873032, "Avg loss": 2.0031689959578216, "Avg value loss": 1.5736513703595847, "Avg policy loss": 0.4295176190789789, "Total num played games": 48477, "Total num trained steps": 96640, "Timestamp in ms": 1699659442707, "logtype": "training_step"}
{"Avg objective": 25.0078125, "Games time in secs": 90.44061968661845, "Avg game time in secs": 1.380100188194774, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 48512, "Total num trained steps": 96703, "Timestamp in ms": 1699659470801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940035854849678, "Avg loss": 1.1055250545032322, "Avg value loss": 0.6841957969591022, "Avg policy loss": 0.4213292612694204, "Total num played games": 48529, "Total num trained steps": 96768, "Timestamp in ms": 1699659499489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946271974968093, "Avg loss": 1.9638425270095468, "Avg value loss": 1.5492072185734287, "Avg policy loss": 0.41463534627109766, "Total num played games": 48578, "Total num trained steps": 96896, "Timestamp in ms": 1699659557379, "logtype": "training_step"}
{"Total num played games": 48627, "Total num trained steps": 96962, "Timestamp in ms": 1699659595796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.42578125}
{"Avg objective": 25.5, "Games time in secs": 126.41698116064072, "Avg game time in secs": 1.3908487950247945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 48640, "Total num trained steps": 96963, "Timestamp in ms": 1699659597218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933025166923473, "Avg loss": 3.9806428430601954, "Avg value loss": 3.530530667863786, "Avg policy loss": 0.45011217263527215, "Total num played games": 48675, "Total num trained steps": 97024, "Timestamp in ms": 1699659622194, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9938225998440258, "Avg loss": 1.695675236172974, "Avg value loss": 1.2558670663274825, "Avg policy loss": 0.43980816495604813, "Total num played games": 48726, "Total num trained steps": 97152, "Timestamp in ms": 1699659679530, "logtype": "training_step"}
{"Avg objective": 23.59375, "Games time in secs": 104.42641916312277, "Avg game time in secs": 1.3055502047936898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 48768, "Total num trained steps": 97202, "Timestamp in ms": 1699659701647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943620968899276, "Avg loss": 1.130984521470964, "Avg value loss": 0.6971740253502503, "Avg policy loss": 0.43381048552691936, "Total num played games": 48777, "Total num trained steps": 97280, "Timestamp in ms": 1699659736259, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930636547787122, "Avg loss": 2.4192629544995725, "Avg value loss": 1.9979300793493167, "Avg policy loss": 0.4213328540790826, "Total num played games": 48873, "Total num trained steps": 97408, "Timestamp in ms": 1699659792386, "logtype": "training_step"}
{"Avg objective": 27.109375, "Games time in secs": 130.45169399678707, "Avg game time in secs": 1.3013937023933977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 48896, "Total num trained steps": 97497, "Timestamp in ms": 1699659832099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936430717658362, "Avg loss": 3.062479372136295, "Avg value loss": 2.629430283792317, "Avg policy loss": 0.433049053652212, "Total num played games": 48923, "Total num trained steps": 97536, "Timestamp in ms": 1699659847966, "logtype": "training_step"}
{"Total num played games": 48923, "Total num trained steps": 97565, "Timestamp in ms": 1699659869402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.796875}
{"Ratio train steps to played games": 1.9943027506075024, "Avg loss": 1.834797441959381, "Avg value loss": 1.3970945647452027, "Avg policy loss": 0.43770286859944463, "Total num played games": 48971, "Total num trained steps": 97664, "Timestamp in ms": 1699659914291, "logtype": "training_step"}
{"Avg objective": 25.5390625, "Games time in secs": 137.17407835647464, "Avg game time in secs": 1.4468584184214706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 49024, "Total num trained steps": 97788, "Timestamp in ms": 1699659969273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993415822410665, "Avg loss": 1.8854861203581095, "Avg value loss": 1.4333516925107688, "Avg policy loss": 0.4521344241220504, "Total num played games": 49056, "Total num trained steps": 97792, "Timestamp in ms": 1699659970763, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934649837133551, "Avg loss": 3.3698497847653925, "Avg value loss": 2.927421163767576, "Avg policy loss": 0.4424286119174212, "Total num played games": 49120, "Total num trained steps": 97920, "Timestamp in ms": 1699660025745, "logtype": "training_step"}
{"Avg objective": 25.8828125, "Games time in secs": 87.6242243219167, "Avg game time in secs": 1.3593126330233645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 49152, "Total num trained steps": 97988, "Timestamp in ms": 1699660056897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940614195647752, "Avg loss": 2.431936075910926, "Avg value loss": 1.9987257511820644, "Avg policy loss": 0.4332103696651757, "Total num played games": 49170, "Total num trained steps": 98048, "Timestamp in ms": 1699660084461, "logtype": "training_step"}
{"Total num played games": 49219, "Total num trained steps": 98167, "Timestamp in ms": 1699660147895, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7578125}
{"Ratio train steps to played games": 1.9927131751476648, "Avg loss": 1.2422259035520256, "Avg value loss": 0.8185704223578796, "Avg policy loss": 0.4236554780509323, "Total num played games": 49267, "Total num trained steps": 98176, "Timestamp in ms": 1699660152997, "logtype": "training_step"}
{"Avg objective": 24.203125, "Games time in secs": 141.54239153862, "Avg game time in secs": 1.4257761765329633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 49280, "Total num trained steps": 98280, "Timestamp in ms": 1699660198440, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993369157457163, "Avg loss": 2.098573153372854, "Avg value loss": 1.6624549634288996, "Avg policy loss": 0.4361181971617043, "Total num played games": 49315, "Total num trained steps": 98304, "Timestamp in ms": 1699660207962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9939834697350296, "Avg loss": 2.0589959430508316, "Avg value loss": 1.628220802405849, "Avg policy loss": 0.4307751674205065, "Total num played games": 49364, "Total num trained steps": 98432, "Timestamp in ms": 1699660266162, "logtype": "training_step"}
{"Avg objective": 24.671875, "Games time in secs": 88.68531155586243, "Avg game time in secs": 1.2730797891126713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 49408, "Total num trained steps": 98479, "Timestamp in ms": 1699660287125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945561986481564, "Avg loss": 1.3504991908557713, "Avg value loss": 0.9263692901004106, "Avg policy loss": 0.4241298665292561, "Total num played games": 49414, "Total num trained steps": 98560, "Timestamp in ms": 1699660322194, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931935692357408, "Avg loss": 2.3943567126989365, "Avg value loss": 1.9631978694815189, "Avg policy loss": 0.4311588432174176, "Total num played games": 49512, "Total num trained steps": 98688, "Timestamp in ms": 1699660380871, "logtype": "training_step"}
{"Avg objective": 26.453125, "Games time in secs": 132.6645840778947, "Avg game time in secs": 1.3319871066050837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 49536, "Total num trained steps": 98770, "Timestamp in ms": 1699660419790, "logtype": "played_game"}
{"Total num played games": 49560, "Total num trained steps": 98770, "Timestamp in ms": 1699660434237, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2734375}
{"Ratio train steps to played games": 1.9919166263505885, "Avg loss": 2.1267772568389773, "Avg value loss": 1.6945371011970565, "Avg policy loss": 0.4322401445824653, "Total num played games": 49608, "Total num trained steps": 98816, "Timestamp in ms": 1699660456457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994496855345912, "Avg loss": 0.8563116323202848, "Avg value loss": 0.43937982979696244, "Avg policy loss": 0.41693179588764906, "Total num played games": 49608, "Total num trained steps": 98944, "Timestamp in ms": 1699660512802, "logtype": "training_step"}
{"Avg objective": 23.9921875, "Games time in secs": 144.07301987707615, "Avg game time in secs": 1.5440223961195443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 49664, "Total num trained steps": 99061, "Timestamp in ms": 1699660563863, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931597795034806, "Avg loss": 2.1036638389341533, "Avg value loss": 1.6835317907389253, "Avg policy loss": 0.42013200791552663, "Total num played games": 49706, "Total num trained steps": 99072, "Timestamp in ms": 1699660568449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99374937192242, "Avg loss": 2.330918727442622, "Avg value loss": 1.9007641640491784, "Avg policy loss": 0.4301545557100326, "Total num played games": 49755, "Total num trained steps": 99200, "Timestamp in ms": 1699660627317, "logtype": "training_step"}
{"Avg objective": 22.9921875, "Games time in secs": 90.09907907806337, "Avg game time in secs": 1.4046350858698133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.65}, "Total num played games": 49792, "Total num trained steps": 99259, "Timestamp in ms": 1699660653962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943578829009718, "Avg loss": 1.6057128999382257, "Avg value loss": 1.1714974115602672, "Avg policy loss": 0.4342154967598617, "Total num played games": 49804, "Total num trained steps": 99328, "Timestamp in ms": 1699660683926, "logtype": "training_step"}
{"Total num played games": 49854, "Total num trained steps": 99374, "Timestamp in ms": 1699660713332, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.015625}
{"Ratio train steps to played games": 1.9930062923329726, "Avg loss": 2.617299199104309, "Avg value loss": 2.1643324915785342, "Avg policy loss": 0.45296671497635543, "Total num played games": 49902, "Total num trained steps": 99456, "Timestamp in ms": 1699660750298, "logtype": "training_step"}
{"Avg objective": 24.296875, "Games time in secs": 138.97261885553598, "Avg game time in secs": 1.4010339421365643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 49920, "Total num trained steps": 99551, "Timestamp in ms": 1699660792935, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936137414666373, "Avg loss": 1.598653741646558, "Avg value loss": 1.153711955412291, "Avg policy loss": 0.4449417614378035, "Total num played games": 49951, "Total num trained steps": 99584, "Timestamp in ms": 1699660807248, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99420011599768, "Avg loss": 1.7111247349530458, "Avg value loss": 1.2520155961392447, "Avg policy loss": 0.45910913962870836, "Total num played games": 50001, "Total num trained steps": 99712, "Timestamp in ms": 1699660863273, "logtype": "training_step"}
{"Avg objective": 23.421875, "Games time in secs": 87.60610350593925, "Avg game time in secs": 1.391472456365591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.7, "agent_stopped_0": 0.37}, "Total num played games": 50048, "Total num trained steps": 99752, "Timestamp in ms": 1699660880543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947852147852148, "Avg loss": 1.6731307194568217, "Avg value loss": 1.2247980722459033, "Avg policy loss": 0.4483326480258256, "Total num played games": 50050, "Total num trained steps": 99840, "Timestamp in ms": 1699660920013, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933996689864204, "Avg loss": 2.3542339764535427, "Avg value loss": 1.907228039111942, "Avg policy loss": 0.4470059780869633, "Total num played games": 50149, "Total num trained steps": 99968, "Timestamp in ms": 1699660978554, "logtype": "training_step"}
{"Total num played games": 50149, "Total num trained steps": 99974, "Timestamp in ms": 1699660996708, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.765625}
{"Avg objective": 25.6796875, "Games time in secs": 118.34299279749393, "Avg game time in secs": 1.3351975830446463, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 50176, "Total num trained steps": 99978, "Timestamp in ms": 1699660998886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940434687331912, "Avg loss": 2.4671388510614634, "Avg value loss": 1.9988603580277413, "Avg policy loss": 0.468278503511101, "Total num played games": 50197, "Total num trained steps": 100096, "Timestamp in ms": 1699661051171, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946463400071648, "Avg loss": 1.4823330263607204, "Avg value loss": 1.0368387384805828, "Avg policy loss": 0.44549429207108915, "Total num played games": 50246, "Total num trained steps": 100224, "Timestamp in ms": 1699661106516, "logtype": "training_step"}
{"Avg objective": 26.3984375, "Games time in secs": 157.68499650992453, "Avg game time in secs": 1.3967771988682216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 50304, "Total num trained steps": 100336, "Timestamp in ms": 1699661156571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933456488488965, "Avg loss": 2.1369364797137678, "Avg value loss": 1.6940769472857937, "Avg policy loss": 0.4428595413919538, "Total num played games": 50343, "Total num trained steps": 100352, "Timestamp in ms": 1699661163087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9939474519765041, "Avg loss": 2.1894839419983327, "Avg value loss": 1.7432627198286355, "Avg policy loss": 0.4462212303187698, "Total num played games": 50392, "Total num trained steps": 100480, "Timestamp in ms": 1699661218983, "logtype": "training_step"}
{"Avg objective": 26.09375, "Games time in secs": 87.3322543296963, "Avg game time in secs": 1.3083084613463143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 50432, "Total num trained steps": 100534, "Timestamp in ms": 1699661243903, "logtype": "played_game"}
{"Total num played games": 50441, "Total num trained steps": 100576, "Timestamp in ms": 1699661274102, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.75390625}
{"Ratio train steps to played games": 1.9926518647626215, "Avg loss": 3.0093766301870346, "Avg value loss": 2.55346804484725, "Avg policy loss": 0.45590858021751046, "Total num played games": 50489, "Total num trained steps": 100608, "Timestamp in ms": 1699661288159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932526020024537, "Avg loss": 1.7075589885935187, "Avg value loss": 1.2419483412522823, "Avg policy loss": 0.4656106282491237, "Total num played games": 50538, "Total num trained steps": 100736, "Timestamp in ms": 1699661347058, "logtype": "training_step"}
{"Avg objective": 24.0234375, "Games time in secs": 141.42828208766878, "Avg game time in secs": 1.4464047164219664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 50560, "Total num trained steps": 100824, "Timestamp in ms": 1699661385332, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938521754600984, "Avg loss": 2.221051377709955, "Avg value loss": 1.7578710680827498, "Avg policy loss": 0.46318029472604394, "Total num played games": 50587, "Total num trained steps": 100864, "Timestamp in ms": 1699661403824, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944899772884368, "Avg loss": 1.8439458128996193, "Avg value loss": 1.3685026755556464, "Avg policy loss": 0.4754431410692632, "Total num played games": 50635, "Total num trained steps": 100992, "Timestamp in ms": 1699661464989, "logtype": "training_step"}
{"Avg objective": 26.2265625, "Games time in secs": 134.99575502052903, "Avg game time in secs": 1.4828078756981995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 50688, "Total num trained steps": 101114, "Timestamp in ms": 1699661520328, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99333714443415, "Avg loss": 2.2590500698424876, "Avg value loss": 1.7797205910319462, "Avg policy loss": 0.4793294696137309, "Total num played games": 50729, "Total num trained steps": 101120, "Timestamp in ms": 1699661522578, "logtype": "training_step"}
{"Total num played games": 50732, "Total num trained steps": 101178, "Timestamp in ms": 1699661560549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.85546875}
{"Ratio train steps to played games": 1.9938361559669162, "Avg loss": 2.9268116201274097, "Avg value loss": 2.4515501589048654, "Avg policy loss": 0.47526147426106036, "Total num played games": 50780, "Total num trained steps": 101248, "Timestamp in ms": 1699661592602, "logtype": "training_step"}
{"Avg objective": 24.03125, "Games time in secs": 98.48454259708524, "Avg game time in secs": 1.3862837584892986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 50816, "Total num trained steps": 101309, "Timestamp in ms": 1699661618812, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9944715511135596, "Avg loss": 1.244410673622042, "Avg value loss": 0.7866169348126277, "Avg policy loss": 0.45779373589903116, "Total num played games": 50828, "Total num trained steps": 101376, "Timestamp in ms": 1699661649183, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9947528741279354, "Avg loss": 1.7145763211883605, "Avg value loss": 1.2659844531444833, "Avg policy loss": 0.4485918669961393, "Total num played games": 50883, "Total num trained steps": 101504, "Timestamp in ms": 1699661706941, "logtype": "training_step"}
{"Avg objective": 25.3984375, "Games time in secs": 131.20927339419723, "Avg game time in secs": 1.414748709241394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 50944, "Total num trained steps": 101601, "Timestamp in ms": 1699661750022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9936247008513477, "Avg loss": 2.5348061718977988, "Avg value loss": 2.0801077177748084, "Avg policy loss": 0.4546984429471195, "Total num played games": 50978, "Total num trained steps": 101632, "Timestamp in ms": 1699661763017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9942187469378956, "Avg loss": 2.8741326918825507, "Avg value loss": 2.416291016037576, "Avg policy loss": 0.45784165477380157, "Total num played games": 51027, "Total num trained steps": 101760, "Timestamp in ms": 1699661820258, "logtype": "training_step"}
{"Total num played games": 51027, "Total num trained steps": 101781, "Timestamp in ms": 1699661841012, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5703125}
{"Avg objective": 25.5234375, "Games time in secs": 94.2744792420417, "Avg game time in secs": 1.601372180171893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.77}, "Total num played games": 51072, "Total num trained steps": 101787, "Timestamp in ms": 1699661844296, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948702887909937, "Avg loss": 1.7215343220159411, "Avg value loss": 1.2646105343010277, "Avg policy loss": 0.45692379702813923, "Total num played games": 51075, "Total num trained steps": 101888, "Timestamp in ms": 1699661890412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935512868114045, "Avg loss": 1.7679024538956583, "Avg value loss": 1.3193367522908375, "Avg policy loss": 0.4485656823962927, "Total num played games": 51173, "Total num trained steps": 102016, "Timestamp in ms": 1699661953038, "logtype": "training_step"}
{"Avg objective": 24.6796875, "Games time in secs": 144.31688783317804, "Avg game time in secs": 1.455028595708427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 51200, "Total num trained steps": 102093, "Timestamp in ms": 1699661988613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9941820737588098, "Avg loss": 1.9927916987799108, "Avg value loss": 1.533375958679244, "Avg policy loss": 0.45941572543233633, "Total num played games": 51221, "Total num trained steps": 102144, "Timestamp in ms": 1699662012635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9947921746084378, "Avg loss": 1.9729970670305192, "Avg value loss": 1.514106814051047, "Avg policy loss": 0.458890235517174, "Total num played games": 51269, "Total num trained steps": 102272, "Timestamp in ms": 1699662074609, "logtype": "training_step"}
{"Avg objective": 25.3046875, "Games time in secs": 137.49161870777607, "Avg game time in secs": 1.6208937857154524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.73, "agent_stopped_0": 0.36}, "Total num played games": 51328, "Total num trained steps": 102380, "Timestamp in ms": 1699662126105, "logtype": "played_game"}
{"Total num played games": 51365, "Total num trained steps": 102381, "Timestamp in ms": 1699662138175, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.21484375}
{"Ratio train steps to played games": 1.991714157897808, "Avg loss": 2.295673389919102, "Avg value loss": 1.84079043881502, "Avg policy loss": 0.454882949590683, "Total num played games": 51413, "Total num trained steps": 102400, "Timestamp in ms": 1699662147878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994184350261607, "Avg loss": 1.6024256288073957, "Avg value loss": 1.1603896680753678, "Avg policy loss": 0.4420359709765762, "Total num played games": 51413, "Total num trained steps": 102528, "Timestamp in ms": 1699662209441, "logtype": "training_step"}
{"Avg objective": 26.7109375, "Games time in secs": 105.94009911827743, "Avg game time in secs": 1.5627956327225547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.68}, "Total num played games": 51456, "Total num trained steps": 102574, "Timestamp in ms": 1699662232045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948310370960534, "Avg loss": 1.8914898573420942, "Avg value loss": 1.4638093897374347, "Avg policy loss": 0.4276804528199136, "Total num played games": 51461, "Total num trained steps": 102656, "Timestamp in ms": 1699662270961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935993172605078, "Avg loss": 3.5138687365688384, "Avg value loss": 3.0724862846545875, "Avg policy loss": 0.44138254621066153, "Total num played games": 51557, "Total num trained steps": 102784, "Timestamp in ms": 1699662335074, "logtype": "training_step"}
{"Avg objective": 24.4375, "Games time in secs": 139.95080981217325, "Avg game time in secs": 1.4505445463291835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 51584, "Total num trained steps": 102862, "Timestamp in ms": 1699662371996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9941480806867284, "Avg loss": 1.8740931255742908, "Avg value loss": 1.432922288775444, "Avg policy loss": 0.44117083749733865, "Total num played games": 51607, "Total num trained steps": 102912, "Timestamp in ms": 1699662396341, "logtype": "training_step"}
{"Total num played games": 51657, "Total num trained steps": 102982, "Timestamp in ms": 1699662442532, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.38671875}
{"Ratio train steps to played games": 1.992824678464365, "Avg loss": 3.407942177262157, "Avg value loss": 2.9677876252681017, "Avg policy loss": 0.44015451427549124, "Total num played games": 51705, "Total num trained steps": 103040, "Timestamp in ms": 1699662470269, "logtype": "training_step"}
{"Avg objective": 22.734375, "Games time in secs": 155.85788766294718, "Avg game time in secs": 1.6930996180453803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.78, "agent_stopped_0": 0.34}, "Total num played games": 51712, "Total num trained steps": 103156, "Timestamp in ms": 1699662527854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934496550924583, "Avg loss": 1.5502424351871014, "Avg value loss": 1.1170968636870384, "Avg policy loss": 0.4331455584615469, "Total num played games": 51753, "Total num trained steps": 103168, "Timestamp in ms": 1699662534293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940542836183932, "Avg loss": 1.9672571462579072, "Avg value loss": 1.5479393531568348, "Avg policy loss": 0.4193177667912096, "Total num played games": 51802, "Total num trained steps": 103296, "Timestamp in ms": 1699662595871, "logtype": "training_step"}
{"Avg objective": 25.5078125, "Games time in secs": 95.54448280856013, "Avg game time in secs": 1.5890978378010914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 51840, "Total num trained steps": 103351, "Timestamp in ms": 1699662623399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946769527483124, "Avg loss": 1.4594546407461166, "Avg value loss": 1.0383586955722421, "Avg policy loss": 0.4210959377232939, "Total num played games": 51850, "Total num trained steps": 103424, "Timestamp in ms": 1699662659047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993493117720666, "Avg loss": 2.0080131953582168, "Avg value loss": 1.5726985984947532, "Avg policy loss": 0.43531459057703614, "Total num played games": 51945, "Total num trained steps": 103552, "Timestamp in ms": 1699662720980, "logtype": "training_step"}
{"Total num played games": 51946, "Total num trained steps": 103585, "Timestamp in ms": 1699662749025, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.64453125}
{"Avg objective": 24.703125, "Games time in secs": 127.5548597574234, "Avg game time in secs": 1.7317788140790071, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.69, "agent_stopped_0": 0.37}, "Total num played games": 51968, "Total num trained steps": 103588, "Timestamp in ms": 1699662750954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940570065776821, "Avg loss": 2.2389526613987982, "Avg value loss": 1.7986064772121608, "Avg policy loss": 0.4403461564797908, "Total num played games": 51994, "Total num trained steps": 103680, "Timestamp in ms": 1699662797987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994696591214788, "Avg loss": 1.4413697812706232, "Avg value loss": 1.0175475523574278, "Avg policy loss": 0.423822236713022, "Total num played games": 52042, "Total num trained steps": 103808, "Timestamp in ms": 1699662861483, "logtype": "training_step"}
{"Avg objective": 25.53125, "Games time in secs": 170.06317344866693, "Avg game time in secs": 1.8141683099674992, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.79, "agent_stopped_0": 0.29}, "Total num played games": 52096, "Total num trained steps": 103925, "Timestamp in ms": 1699662921017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934214311743608, "Avg loss": 2.493347837589681, "Avg value loss": 2.059382128994912, "Avg policy loss": 0.4339656629599631, "Total num played games": 52139, "Total num trained steps": 103936, "Timestamp in ms": 1699662925763, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940598233276488, "Avg loss": 2.776564941275865, "Avg value loss": 2.3540619753766805, "Avg policy loss": 0.4225029598455876, "Total num played games": 52187, "Total num trained steps": 104064, "Timestamp in ms": 1699662988141, "logtype": "training_step"}
{"Avg objective": 23.28125, "Games time in secs": 96.72903007641435, "Avg game time in secs": 1.5802722069784068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 52224, "Total num trained steps": 104122, "Timestamp in ms": 1699663017746, "logtype": "played_game"}
{"Total num played games": 52235, "Total num trained steps": 104188, "Timestamp in ms": 1699663061835, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.56640625}
{"Ratio train steps to played games": 1.9938190098934114, "Avg loss": 1.984375667758286, "Avg value loss": 1.5596968615427613, "Avg policy loss": 0.42467878945171833, "Total num played games": 52257, "Total num trained steps": 104192, "Timestamp in ms": 1699663064029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934455676367737, "Avg loss": 1.5828051660209894, "Avg value loss": 1.1612664203858003, "Avg policy loss": 0.42153875064104795, "Total num played games": 52331, "Total num trained steps": 104320, "Timestamp in ms": 1699663125897, "logtype": "training_step"}
{"Avg objective": 23.2265625, "Games time in secs": 151.66977090202272, "Avg game time in secs": 1.5929555130569497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.68, "agent_stopped_0": 0.36}, "Total num played games": 52352, "Total num trained steps": 104411, "Timestamp in ms": 1699663169416, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940435280641466, "Avg loss": 1.7263909643515944, "Avg value loss": 1.3090808573178947, "Avg policy loss": 0.4173101270571351, "Total num played games": 52380, "Total num trained steps": 104448, "Timestamp in ms": 1699663187206, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946402685587854, "Avg loss": 1.2373417536728084, "Avg value loss": 0.8335019514197484, "Avg policy loss": 0.403839802602306, "Total num played games": 52428, "Total num trained steps": 104576, "Timestamp in ms": 1699663255383, "logtype": "training_step"}
{"Avg objective": 22.8203125, "Games time in secs": 147.69220992177725, "Avg game time in secs": 1.7610841832211008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.76, "agent_stopped_0": 0.33}, "Total num played games": 52480, "Total num trained steps": 104699, "Timestamp in ms": 1699663317109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993469527635512, "Avg loss": 1.0730515625327826, "Avg value loss": 0.6728609926067293, "Avg policy loss": 0.40019057411700487, "Total num played games": 52523, "Total num trained steps": 104704, "Timestamp in ms": 1699663319334, "logtype": "training_step"}
{"Total num played games": 52526, "Total num trained steps": 104791, "Timestamp in ms": 1699663373936, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.640625}
{"Ratio train steps to played games": 1.993970403621562, "Avg loss": 2.6442834339104593, "Avg value loss": 2.24050477379933, "Avg policy loss": 0.40377864916808903, "Total num played games": 52574, "Total num trained steps": 104832, "Timestamp in ms": 1699663393107, "logtype": "training_step"}
{"Avg objective": 25.5859375, "Games time in secs": 106.71681796386838, "Avg game time in secs": 1.4036069388239412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 52608, "Total num trained steps": 104895, "Timestamp in ms": 1699663423825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946030177492304, "Avg loss": 1.44640300469473, "Avg value loss": 1.0362450388493016, "Avg policy loss": 0.41015797294676304, "Total num played games": 52622, "Total num trained steps": 104960, "Timestamp in ms": 1699663454574, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935689488361505, "Avg loss": 1.261950063984841, "Avg value loss": 0.8812767477938905, "Avg policy loss": 0.38067333633080125, "Total num played games": 52712, "Total num trained steps": 105088, "Timestamp in ms": 1699663517465, "logtype": "training_step"}
{"Avg objective": 23.421875, "Games time in secs": 139.7365039922297, "Avg game time in secs": 1.4448900528805098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 52736, "Total num trained steps": 105182, "Timestamp in ms": 1699663563562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9939923435545617, "Avg loss": 2.7833330556750298, "Avg value loss": 2.3787380431313068, "Avg policy loss": 0.40459500392898917, "Total num played games": 52766, "Total num trained steps": 105216, "Timestamp in ms": 1699663579294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946226379369107, "Avg loss": 1.9761557886376977, "Avg value loss": 1.5796658592298627, "Avg policy loss": 0.3964899298734963, "Total num played games": 52814, "Total num trained steps": 105344, "Timestamp in ms": 1699663641581, "logtype": "training_step"}
{"Total num played games": 52862, "Total num trained steps": 105391, "Timestamp in ms": 1699663681150, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.20703125}
{"Avg objective": 25.2109375, "Games time in secs": 118.45540773496032, "Avg game time in secs": 1.622216523741372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.75, "agent_stopped_0": 0.32}, "Total num played games": 52864, "Total num trained steps": 105392, "Timestamp in ms": 1699663682018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9934227934227935, "Avg loss": 3.280201488174498, "Avg value loss": 2.8486694684252143, "Avg policy loss": 0.431532034650445, "Total num played games": 52910, "Total num trained steps": 105472, "Timestamp in ms": 1699663720915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940330072887948, "Avg loss": 0.9935978408902884, "Avg value loss": 0.5876486226916313, "Avg policy loss": 0.40594922145828605, "Total num played games": 52958, "Total num trained steps": 105600, "Timestamp in ms": 1699663782922, "logtype": "training_step"}
{"Avg objective": 25.6796875, "Games time in secs": 131.34113618917763, "Avg game time in secs": 1.4063341249129735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 52992, "Total num trained steps": 105664, "Timestamp in ms": 1699663813359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946421159868695, "Avg loss": 2.0137277711182833, "Avg value loss": 1.6198861829470843, "Avg policy loss": 0.39384159399196506, "Total num played games": 53006, "Total num trained steps": 105728, "Timestamp in ms": 1699663845776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994329100568974, "Avg loss": 1.7572226827032864, "Avg value loss": 1.3562853003386408, "Avg policy loss": 0.40093736234121025, "Total num played games": 53077, "Total num trained steps": 105856, "Timestamp in ms": 1699663907955, "logtype": "training_step"}
{"Avg objective": 23.2734375, "Games time in secs": 145.44296103529632, "Avg game time in secs": 1.6039377546985634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 53120, "Total num trained steps": 105950, "Timestamp in ms": 1699663958802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940545625587958, "Avg loss": 1.6148930033668876, "Avg value loss": 1.2120266626589, "Avg policy loss": 0.40286632161587477, "Total num played games": 53150, "Total num trained steps": 105984, "Timestamp in ms": 1699663977037, "logtype": "training_step"}
{"Total num played games": 53150, "Total num trained steps": 105994, "Timestamp in ms": 1699664017617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.01953125}
{"Ratio train steps to played games": 1.994661453438099, "Avg loss": 1.8357630730606616, "Avg value loss": 1.425990371615626, "Avg policy loss": 0.4097726948093623, "Total num played games": 53198, "Total num trained steps": 106112, "Timestamp in ms": 1699664077206, "logtype": "training_step"}
{"Avg objective": 24.40625, "Games time in secs": 178.3438745327294, "Avg game time in secs": 1.5556860474607674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.73}, "Total num played games": 53248, "Total num trained steps": 106237, "Timestamp in ms": 1699664137146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940126503875824, "Avg loss": 1.2506899824365973, "Avg value loss": 0.8466362595790997, "Avg policy loss": 0.40405373089015484, "Total num played games": 53278, "Total num trained steps": 106240, "Timestamp in ms": 1699664138255, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940572157024483, "Avg loss": 1.8195222672075033, "Avg value loss": 1.4295731321908534, "Avg policy loss": 0.38994913501664996, "Total num played games": 53342, "Total num trained steps": 106368, "Timestamp in ms": 1699664200123, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 93.87147992663085, "Avg game time in secs": 1.3770654869731516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 53376, "Total num trained steps": 106431, "Timestamp in ms": 1699664231017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946806518074547, "Avg loss": 1.3742011548019946, "Avg value loss": 0.9798609189456329, "Avg policy loss": 0.3943402348086238, "Total num played games": 53390, "Total num trained steps": 106496, "Timestamp in ms": 1699664263036, "logtype": "training_step"}
{"Total num played games": 53439, "Total num trained steps": 106594, "Timestamp in ms": 1699664323462, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.07421875}
{"Ratio train steps to played games": 1.9934376577486117, "Avg loss": 1.7474743435159326, "Avg value loss": 1.360765079385601, "Avg policy loss": 0.38670925702899694, "Total num played games": 53487, "Total num trained steps": 106624, "Timestamp in ms": 1699664338474, "logtype": "training_step"}
{"Avg objective": 23.5234375, "Games time in secs": 154.55129522643983, "Avg game time in secs": 1.4947587755304994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.69, "agent_stopped_0": 0.4}, "Total num played games": 53504, "Total num trained steps": 106720, "Timestamp in ms": 1699664385569, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940599607733258, "Avg loss": 1.4692560876719654, "Avg value loss": 1.0832619732245803, "Avg policy loss": 0.3859941258560866, "Total num played games": 53535, "Total num trained steps": 106752, "Timestamp in ms": 1699664400689, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946438236007689, "Avg loss": 1.7594716714229435, "Avg value loss": 1.376582509605214, "Avg policy loss": 0.38288912805728614, "Total num played games": 53583, "Total num trained steps": 106880, "Timestamp in ms": 1699664463131, "logtype": "training_step"}
{"Avg objective": 24.6875, "Games time in secs": 141.88844449818134, "Avg game time in secs": 1.4153497335792053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.69}, "Total num played games": 53632, "Total num trained steps": 107007, "Timestamp in ms": 1699664527457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994706035864743, "Avg loss": 1.457542977295816, "Avg value loss": 1.0772791114868596, "Avg policy loss": 0.3802638528868556, "Total num played games": 53644, "Total num trained steps": 107008, "Timestamp in ms": 1699664528101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9940811882293819, "Avg loss": 1.830513320863247, "Avg value loss": 1.441993162385188, "Avg policy loss": 0.3885201527737081, "Total num played games": 53727, "Total num trained steps": 107136, "Timestamp in ms": 1699664591514, "logtype": "training_step"}
{"Total num played games": 53727, "Total num trained steps": 107197, "Timestamp in ms": 1699664637128, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.35546875}
{"Avg objective": 24.5625, "Games time in secs": 112.35530652850866, "Avg game time in secs": 1.491199540279922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.77}, "Total num played games": 53760, "Total num trained steps": 107202, "Timestamp in ms": 1699664639813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946629474662947, "Avg loss": 1.549265917390585, "Avg value loss": 1.1605641399510205, "Avg policy loss": 0.3887017834931612, "Total num played games": 53775, "Total num trained steps": 107264, "Timestamp in ms": 1699664669962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995243757431629, "Avg loss": 1.6456466596573591, "Avg value loss": 1.2428156462265179, "Avg policy loss": 0.4028309811837971, "Total num played games": 53824, "Total num trained steps": 107392, "Timestamp in ms": 1699664727466, "logtype": "training_step"}
{"Avg objective": 26.7890625, "Games time in secs": 131.3885462936014, "Avg game time in secs": 1.4658437776670326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.65, "agent_stopped_0": 0.43}, "Total num played games": 53888, "Total num trained steps": 107494, "Timestamp in ms": 1699664771202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9939727754905234, "Avg loss": 2.228596585802734, "Avg value loss": 1.8088846360333264, "Avg policy loss": 0.41971194674260914, "Total num played games": 53922, "Total num trained steps": 107520, "Timestamp in ms": 1699664781409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944232408196538, "Avg loss": 1.9617840540595353, "Avg value loss": 1.545515900827013, "Avg policy loss": 0.4162681836169213, "Total num played games": 53974, "Total num trained steps": 107648, "Timestamp in ms": 1699664838568, "logtype": "training_step"}
{"Avg objective": 25.34375, "Games time in secs": 88.94637970998883, "Avg game time in secs": 1.4444646992051275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.74}, "Total num played games": 54016, "Total num trained steps": 107698, "Timestamp in ms": 1699664860148, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99494669035984, "Avg loss": 1.4978194711729884, "Avg value loss": 1.0851510285865515, "Avg policy loss": 0.41266844677738845, "Total num played games": 54024, "Total num trained steps": 107776, "Timestamp in ms": 1699664894919, "logtype": "training_step"}
{"Total num played games": 54075, "Total num trained steps": 107800, "Timestamp in ms": 1699664919023, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3203125}
{"Ratio train steps to played games": 1.9936625833749053, "Avg loss": 1.9702035444788635, "Avg value loss": 1.5539445143658668, "Avg policy loss": 0.41625898564234376, "Total num played games": 54123, "Total num trained steps": 107904, "Timestamp in ms": 1699664965333, "logtype": "training_step"}
{"Avg objective": 25.390625, "Games time in secs": 144.74611983634531, "Avg game time in secs": 1.4851120279345196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 54144, "Total num trained steps": 107993, "Timestamp in ms": 1699665004894, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9942589208247956, "Avg loss": 1.416264556813985, "Avg value loss": 0.999497803975828, "Avg policy loss": 0.41676674992777407, "Total num played games": 54171, "Total num trained steps": 108032, "Timestamp in ms": 1699665022380, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948174105496126, "Avg loss": 1.373145951423794, "Avg value loss": 0.9633603069232777, "Avg policy loss": 0.4097856559092179, "Total num played games": 54220, "Total num trained steps": 108160, "Timestamp in ms": 1699665078659, "logtype": "training_step"}
{"Avg objective": 24.9375, "Games time in secs": 126.58684069477022, "Avg game time in secs": 1.6720300919550937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.84, "agent_stopped_0": 0.24}, "Total num played games": 54272, "Total num trained steps": 108282, "Timestamp in ms": 1699665131481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99350147275405, "Avg loss": 2.1708757150918245, "Avg value loss": 1.7527438654797152, "Avg policy loss": 0.41813185764476657, "Total num played games": 54320, "Total num trained steps": 108288, "Timestamp in ms": 1699665134487, "logtype": "training_step"}
{"Total num played games": 54373, "Total num trained steps": 108401, "Timestamp in ms": 1699665198496, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.08984375}
{"Avg objective": 25.578125, "Games time in secs": 69.40159250982106, "Avg game time in secs": 1.361538959070458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.65}, "Total num played games": 54400, "Total num trained steps": 108403, "Timestamp in ms": 1699665200883, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992153764171919, "Avg loss": 3.0781357591040432, "Avg value loss": 2.6411294292192906, "Avg policy loss": 0.43700633803382516, "Total num played games": 54421, "Total num trained steps": 108416, "Timestamp in ms": 1699665206191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9945057973943883, "Avg loss": 2.313065141439438, "Avg value loss": 1.876224595704116, "Avg policy loss": 0.4368405269924551, "Total num played games": 54421, "Total num trained steps": 108544, "Timestamp in ms": 1699665263170, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950615017440794, "Avg loss": 1.8483742349781096, "Avg value loss": 1.4251781937200576, "Avg policy loss": 0.42319606244564056, "Total num played games": 54470, "Total num trained steps": 108672, "Timestamp in ms": 1699665317920, "logtype": "training_step"}
{"Avg objective": 23.28125, "Games time in secs": 166.75510860793293, "Avg game time in secs": 1.6926556129765231, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.8, "agent_stopped_0": 0.33}, "Total num played games": 54528, "Total num trained steps": 108784, "Timestamp in ms": 1699665367638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938790844283174, "Avg loss": 1.5600161412730813, "Avg value loss": 1.142347957356833, "Avg policy loss": 0.4176681919489056, "Total num played games": 54567, "Total num trained steps": 108800, "Timestamp in ms": 1699665375279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944155558810606, "Avg loss": 2.3078550552017987, "Avg value loss": 1.8945757818873972, "Avg policy loss": 0.41327926563099027, "Total num played games": 54616, "Total num trained steps": 108928, "Timestamp in ms": 1699665431819, "logtype": "training_step"}
{"Avg objective": 24.9921875, "Games time in secs": 88.24304074794054, "Avg game time in secs": 1.4738489498849958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.73}, "Total num played games": 54656, "Total num trained steps": 108982, "Timestamp in ms": 1699665455881, "logtype": "played_game"}
{"Total num played games": 54665, "Total num trained steps": 109002, "Timestamp in ms": 1699665475446, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0703125}
{"Ratio train steps to played games": 1.9932374389998722, "Avg loss": 2.9725322746671736, "Avg value loss": 2.544760567136109, "Avg policy loss": 0.4277717461809516, "Total num played games": 54713, "Total num trained steps": 109056, "Timestamp in ms": 1699665499591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9937913151455389, "Avg loss": 1.5753668611869216, "Avg value loss": 1.1490595332579687, "Avg policy loss": 0.4263073375914246, "Total num played games": 54762, "Total num trained steps": 109184, "Timestamp in ms": 1699665556928, "logtype": "training_step"}
{"Avg objective": 23.9765625, "Games time in secs": 139.76311908476055, "Avg game time in secs": 1.4083825372217689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 54784, "Total num trained steps": 109272, "Timestamp in ms": 1699665595647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9941440455341506, "Avg loss": 2.5898813507519662, "Avg value loss": 2.1608497330453247, "Avg policy loss": 0.4290316249243915, "Total num played games": 54816, "Total num trained steps": 109312, "Timestamp in ms": 1699665613503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994696072177162, "Avg loss": 1.0471869329921901, "Avg value loss": 0.6339663687394932, "Avg policy loss": 0.4132205741479993, "Total num played games": 54865, "Total num trained steps": 109440, "Timestamp in ms": 1699665670298, "logtype": "training_step"}
{"Avg objective": 23.2578125, "Games time in secs": 93.32758443430066, "Avg game time in secs": 1.6227362670906587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.84, "agent_stopped_0": 0.28}, "Total num played games": 54912, "Total num trained steps": 109481, "Timestamp in ms": 1699665688973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9952107802968224, "Avg loss": 1.1853216541931033, "Avg value loss": 0.7683184819761664, "Avg policy loss": 0.41700318129733205, "Total num played games": 54915, "Total num trained steps": 109568, "Timestamp in ms": 1699665728160, "logtype": "training_step"}
{"Total num played games": 54963, "Total num trained steps": 109602, "Timestamp in ms": 1699665754316, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.68359375}
{"Ratio train steps to played games": 1.9940739124902291, "Avg loss": 2.6089963032864034, "Avg value loss": 2.1749479037243873, "Avg policy loss": 0.4340483942069113, "Total num played games": 55011, "Total num trained steps": 109696, "Timestamp in ms": 1699665797368, "logtype": "training_step"}
{"Avg objective": 25.1953125, "Games time in secs": 139.95678909495473, "Avg game time in secs": 1.2887212979840115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.66, "agent_stopped_0": 0.42}, "Total num played games": 55040, "Total num trained steps": 109772, "Timestamp in ms": 1699665828930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945696591053559, "Avg loss": 1.7426174888387322, "Avg value loss": 1.3155136803397909, "Avg policy loss": 0.42710382491350174, "Total num played games": 55061, "Total num trained steps": 109824, "Timestamp in ms": 1699665852066, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950826513763134, "Avg loss": 1.3485938222147524, "Avg value loss": 0.9230447227600962, "Avg policy loss": 0.42554909898899496, "Total num played games": 55111, "Total num trained steps": 109952, "Timestamp in ms": 1699665910095, "logtype": "training_step"}
{"Avg objective": 27.1796875, "Games time in secs": 129.21002945490181, "Avg game time in secs": 1.4884129367856076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 55168, "Total num trained steps": 110064, "Timestamp in ms": 1699665958140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993931928922057, "Avg loss": 2.3064244193956256, "Avg value loss": 1.874374826438725, "Avg policy loss": 0.43204962089657784, "Total num played games": 55207, "Total num trained steps": 110080, "Timestamp in ms": 1699665964644, "logtype": "training_step"}
{"Total num played games": 55258, "Total num trained steps": 110203, "Timestamp in ms": 1699666030643, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4140625}
{"Avg objective": 22.640625, "Games time in secs": 75.07184247113764, "Avg game time in secs": 1.5280087780556642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.82}, "Total num played games": 55296, "Total num trained steps": 110207, "Timestamp in ms": 1699666033212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928933092224232, "Avg loss": 2.3612289233133197, "Avg value loss": 1.930360045749694, "Avg policy loss": 0.4308688538148999, "Total num played games": 55299, "Total num trained steps": 110208, "Timestamp in ms": 1699666033385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9949915018262032, "Avg loss": 1.426436415873468, "Avg value loss": 0.980559425894171, "Avg policy loss": 0.44587699230760336, "Total num played games": 55306, "Total num trained steps": 110336, "Timestamp in ms": 1699666091146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993844987545576, "Avg loss": 1.7611267031170428, "Avg value loss": 1.3388430855702609, "Avg policy loss": 0.42228362732566893, "Total num played games": 55402, "Total num trained steps": 110464, "Timestamp in ms": 1699666145966, "logtype": "training_step"}
{"Avg objective": 24.421875, "Games time in secs": 151.18540938943624, "Avg game time in secs": 1.4507590865105158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.65, "agent_stopped_0": 0.43}, "Total num played games": 55424, "Total num trained steps": 110554, "Timestamp in ms": 1699666184397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943195138225163, "Avg loss": 1.5750804413110018, "Avg value loss": 1.1532136566238478, "Avg policy loss": 0.4218667696695775, "Total num played games": 55453, "Total num trained steps": 110592, "Timestamp in ms": 1699666201103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948650499081113, "Avg loss": 3.1392613183707, "Avg value loss": 2.719522893661633, "Avg policy loss": 0.4197384403087199, "Total num played games": 55502, "Total num trained steps": 110720, "Timestamp in ms": 1699666258746, "logtype": "training_step"}
{"Avg objective": 24.5234375, "Games time in secs": 92.69538239017129, "Avg game time in secs": 1.6266701008426026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.76, "agent_stopped_0": 0.3}, "Total num played games": 55552, "Total num trained steps": 110763, "Timestamp in ms": 1699666277093, "logtype": "played_game"}
{"Total num played games": 55552, "Total num trained steps": 110806, "Timestamp in ms": 1699666311408, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7265625}
{"Ratio train steps to played games": 1.9936690647482014, "Avg loss": 2.445169670972973, "Avg value loss": 1.990333108464256, "Avg policy loss": 0.4548365664668381, "Total num played games": 55600, "Total num trained steps": 110848, "Timestamp in ms": 1699666329641, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9942137325019318, "Avg loss": 2.2912136423401535, "Avg value loss": 1.8680119997588918, "Avg policy loss": 0.4232016203459352, "Total num played games": 55649, "Total num trained steps": 110976, "Timestamp in ms": 1699666388198, "logtype": "training_step"}
{"Avg objective": 25.21875, "Games time in secs": 142.65714313462377, "Avg game time in secs": 1.521722806734033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.74}, "Total num played games": 55680, "Total num trained steps": 111047, "Timestamp in ms": 1699666419750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947036751108638, "Avg loss": 3.4543616115115583, "Avg value loss": 2.9964049831032753, "Avg policy loss": 0.4579565692692995, "Total num played games": 55699, "Total num trained steps": 111104, "Timestamp in ms": 1699666445585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952106764246893, "Avg loss": 2.556178760714829, "Avg value loss": 2.1042795770335943, "Avg policy loss": 0.45189914922229946, "Total num played games": 55749, "Total num trained steps": 111232, "Timestamp in ms": 1699666503965, "logtype": "training_step"}
{"Avg objective": 25.9921875, "Games time in secs": 135.71349117532372, "Avg game time in secs": 1.68288221709372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 55808, "Total num trained steps": 111350, "Timestamp in ms": 1699666555464, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9938051671351584, "Avg loss": 1.7738920538686216, "Avg value loss": 1.3313494867179543, "Avg policy loss": 0.44254256854765117, "Total num played games": 55853, "Total num trained steps": 111360, "Timestamp in ms": 1699666559541, "logtype": "training_step"}
{"Total num played games": 55853, "Total num trained steps": 111406, "Timestamp in ms": 1699666597560, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.75}
{"Ratio train steps to played games": 1.9943650381925189, "Avg loss": 1.6963607389479876, "Avg value loss": 1.2751246551051736, "Avg policy loss": 0.4212360833771527, "Total num played games": 55901, "Total num trained steps": 111488, "Timestamp in ms": 1699666634941, "logtype": "training_step"}
{"Avg objective": 24.640625, "Games time in secs": 106.6193850748241, "Avg game time in secs": 1.6385067773517221, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.8}, "Total num played games": 55936, "Total num trained steps": 111551, "Timestamp in ms": 1699666662083, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9949596954369158, "Avg loss": 2.7649817587807775, "Avg value loss": 2.3398603880777955, "Avg policy loss": 0.4251213737297803, "Total num played games": 55949, "Total num trained steps": 111616, "Timestamp in ms": 1699666689977, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944847035305038, "Avg loss": 2.076544010080397, "Avg value loss": 1.644317765487358, "Avg policy loss": 0.4322262513451278, "Total num played games": 56026, "Total num trained steps": 111744, "Timestamp in ms": 1699666747364, "logtype": "training_step"}
{"Avg objective": 23.96875, "Games time in secs": 129.94564122706652, "Avg game time in secs": 1.6356236411083955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.78, "agent_stopped_0": 0.33}, "Total num played games": 56064, "Total num trained steps": 111841, "Timestamp in ms": 1699666792029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943132186469383, "Avg loss": 1.589716522488743, "Avg value loss": 1.1648593711433932, "Avg policy loss": 0.4248571735806763, "Total num played games": 56095, "Total num trained steps": 111872, "Timestamp in ms": 1699666805621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948525220860645, "Avg loss": 1.6913621043786407, "Avg value loss": 1.2540429043583572, "Avg policy loss": 0.4373192142229527, "Total num played games": 56144, "Total num trained steps": 112000, "Timestamp in ms": 1699666862738, "logtype": "training_step"}
{"Total num played games": 56144, "Total num trained steps": 112008, "Timestamp in ms": 1699666880831, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.37890625}
{"Avg objective": 24.734375, "Games time in secs": 94.54114046879113, "Avg game time in secs": 1.577217780664796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.77, "agent_stopped_0": 0.28}, "Total num played games": 56192, "Total num trained steps": 112019, "Timestamp in ms": 1699666886570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954263952164009, "Avg loss": 1.861957102548331, "Avg value loss": 1.4118230724707246, "Avg policy loss": 0.4501340319402516, "Total num played games": 56192, "Total num trained steps": 112128, "Timestamp in ms": 1699666939125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9942263279445727, "Avg loss": 1.9372540949843824, "Avg value loss": 1.5029735208954662, "Avg policy loss": 0.43428059201687574, "Total num played games": 56290, "Total num trained steps": 112256, "Timestamp in ms": 1699666994796, "logtype": "training_step"}
{"Avg objective": 23.03125, "Games time in secs": 139.75309138186276, "Avg game time in secs": 1.391149503440829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.67}, "Total num played games": 56320, "Total num trained steps": 112329, "Timestamp in ms": 1699667026323, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947284345047924, "Avg loss": 2.010264232289046, "Avg value loss": 1.5802306025289, "Avg policy loss": 0.43003360903821886, "Total num played games": 56340, "Total num trained steps": 112384, "Timestamp in ms": 1699667049954, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951588877855015, "Avg loss": 1.92914571845904, "Avg value loss": 1.505334101151675, "Avg policy loss": 0.4238116187043488, "Total num played games": 56392, "Total num trained steps": 112512, "Timestamp in ms": 1699667106680, "logtype": "training_step"}
{"Total num played games": 56441, "Total num trained steps": 112611, "Timestamp in ms": 1699667168470, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.984375}
{"Avg objective": 25.3515625, "Games time in secs": 143.4681468270719, "Avg game time in secs": 1.5515021147293737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.76, "agent_stopped_0": 0.32}, "Total num played games": 56448, "Total num trained steps": 112613, "Timestamp in ms": 1699667169792, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993998831630937, "Avg loss": 2.54926530783996, "Avg value loss": 2.1177816784475, "Avg policy loss": 0.4314836570993066, "Total num played games": 56489, "Total num trained steps": 112640, "Timestamp in ms": 1699667181829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944993721148234, "Avg loss": 1.5182690564543009, "Avg value loss": 1.090821006684564, "Avg policy loss": 0.42744803451932967, "Total num played games": 56539, "Total num trained steps": 112768, "Timestamp in ms": 1699667240585, "logtype": "training_step"}
{"Avg objective": 24.0078125, "Games time in secs": 102.43912213295698, "Avg game time in secs": 1.3283960097905947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 56576, "Total num trained steps": 112826, "Timestamp in ms": 1699667272231, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950695389400392, "Avg loss": 1.4218715126626194, "Avg value loss": 0.991052913130261, "Avg policy loss": 0.43081859312951565, "Total num played games": 56587, "Total num trained steps": 112896, "Timestamp in ms": 1699667306081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9939312680827042, "Avg loss": 1.3867771858349442, "Avg value loss": 0.9733327208086848, "Avg policy loss": 0.4134444613009691, "Total num played games": 56684, "Total num trained steps": 113024, "Timestamp in ms": 1699667367985, "logtype": "training_step"}
{"Avg objective": 23.734375, "Games time in secs": 139.2596826273948, "Avg game time in secs": 1.6191605258645723, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 56704, "Total num trained steps": 113114, "Timestamp in ms": 1699667411491, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9944828315589085, "Avg loss": 1.9373123631812632, "Avg value loss": 1.5266667933901772, "Avg policy loss": 0.4106455610599369, "Total num played games": 56732, "Total num trained steps": 113152, "Timestamp in ms": 1699667429409, "logtype": "training_step"}
{"Total num played games": 56780, "Total num trained steps": 113214, "Timestamp in ms": 1699667473304, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.36328125}
{"Ratio train steps to played games": 1.9933835433237137, "Avg loss": 2.395417701918632, "Avg value loss": 1.9600985054858029, "Avg policy loss": 0.4353191931731999, "Total num played games": 56828, "Total num trained steps": 113280, "Timestamp in ms": 1699667506355, "logtype": "training_step"}
{"Avg objective": 24.703125, "Games time in secs": 155.18268395774066, "Avg game time in secs": 1.6089181345596444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.81, "agent_stopped_0": 0.27}, "Total num played games": 56832, "Total num trained steps": 113401, "Timestamp in ms": 1699667566674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994056933870202, "Avg loss": 0.8462273962795734, "Avg value loss": 0.44987923849839717, "Avg policy loss": 0.39634815882891417, "Total num played games": 56873, "Total num trained steps": 113408, "Timestamp in ms": 1699667569894, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944664031620554, "Avg loss": 2.29660413460806, "Avg value loss": 1.8751415717415512, "Avg policy loss": 0.42146259103901684, "Total num played games": 56925, "Total num trained steps": 113536, "Timestamp in ms": 1699667633318, "logtype": "training_step"}
{"Avg objective": 24.953125, "Games time in secs": 96.09598355740309, "Avg game time in secs": 1.4446157089987537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.68}, "Total num played games": 56960, "Total num trained steps": 113598, "Timestamp in ms": 1699667662770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950502869780422, "Avg loss": 1.7284765355288982, "Avg value loss": 1.3148267540382221, "Avg policy loss": 0.4136497874278575, "Total num played games": 56973, "Total num trained steps": 113664, "Timestamp in ms": 1699667693654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944613874574963, "Avg loss": 1.2941447445191443, "Avg value loss": 0.8844836987555027, "Avg policy loss": 0.40966103156097233, "Total num played games": 57054, "Total num trained steps": 113792, "Timestamp in ms": 1699667756585, "logtype": "training_step"}
{"Total num played games": 57070, "Total num trained steps": 113816, "Timestamp in ms": 1699667779832, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.85546875}
{"Avg objective": 23.65625, "Games time in secs": 118.88258257694542, "Avg game time in secs": 1.5392190312268212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 57088, "Total num trained steps": 113818, "Timestamp in ms": 1699667781652, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9944675934031304, "Avg loss": 2.306781968101859, "Avg value loss": 1.8960384838283062, "Avg policy loss": 0.41074350755661726, "Total num played games": 57118, "Total num trained steps": 113920, "Timestamp in ms": 1699667829804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950145191197566, "Avg loss": 1.426824995316565, "Avg value loss": 1.036689651897177, "Avg policy loss": 0.39013532898388803, "Total num played games": 57166, "Total num trained steps": 114048, "Timestamp in ms": 1699667891096, "logtype": "training_step"}
{"Avg objective": 24.8046875, "Games time in secs": 170.96314447559416, "Avg game time in secs": 1.5949615533463657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.28, "agent_stopped_more": 0.72, "played_steps": 0.76}, "Total num played games": 57216, "Total num trained steps": 114173, "Timestamp in ms": 1699667952616, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945148047864443, "Avg loss": 1.6028366470709443, "Avg value loss": 1.1966703278012574, "Avg policy loss": 0.40616632415913045, "Total num played games": 57244, "Total num trained steps": 114176, "Timestamp in ms": 1699667953958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944861280753796, "Avg loss": 2.1314801489934325, "Avg value loss": 1.7392302920343354, "Avg policy loss": 0.3922498372849077, "Total num played games": 57310, "Total num trained steps": 114304, "Timestamp in ms": 1699668019200, "logtype": "training_step"}
{"Avg objective": 25.5703125, "Games time in secs": 97.75012349151075, "Avg game time in secs": 1.521763833341538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.23, "agent_stopped_more": 0.77, "played_steps": 0.85}, "Total num played games": 57344, "Total num trained steps": 114368, "Timestamp in ms": 1699668050366, "logtype": "played_game"}
{"Total num played games": 57358, "Total num trained steps": 114419, "Timestamp in ms": 1699668087335, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5859375}
{"Ratio train steps to played games": 1.993415207734518, "Avg loss": 3.6174082518555224, "Avg value loss": 3.1993467286229134, "Avg policy loss": 0.418061530450359, "Total num played games": 57405, "Total num trained steps": 114432, "Timestamp in ms": 1699668094507, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9943942480110026, "Avg loss": 1.9732595742680132, "Avg value loss": 1.5467683661263436, "Avg policy loss": 0.42649116297252476, "Total num played games": 57441, "Total num trained steps": 114560, "Timestamp in ms": 1699668156229, "logtype": "training_step"}
{"Avg objective": 24.875, "Games time in secs": 152.0858287680894, "Avg game time in secs": 1.5385061993874842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 57472, "Total num trained steps": 114654, "Timestamp in ms": 1699668202452, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945045389725575, "Avg loss": 1.6007612654939294, "Avg value loss": 1.1846320207696408, "Avg policy loss": 0.4161292491480708, "Total num played games": 57502, "Total num trained steps": 114688, "Timestamp in ms": 1699668218600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950651607298002, "Avg loss": 1.977224220521748, "Avg value loss": 1.5574832207057625, "Avg policy loss": 0.41974100284278393, "Total num played games": 57550, "Total num trained steps": 114816, "Timestamp in ms": 1699668281824, "logtype": "training_step"}
{"Avg objective": 25.15625, "Games time in secs": 139.1436341777444, "Avg game time in secs": 1.5914199862309033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.82, "agent_stopped_0": 0.26}, "Total num played games": 57600, "Total num trained steps": 114941, "Timestamp in ms": 1699668341596, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9944301776790672, "Avg loss": 1.459295951295644, "Avg value loss": 1.0454782366286963, "Avg policy loss": 0.4138177090790123, "Total num played games": 57629, "Total num trained steps": 114944, "Timestamp in ms": 1699668342631, "logtype": "training_step"}
{"Total num played games": 57646, "Total num trained steps": 115022, "Timestamp in ms": 1699668391201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.23828125}
{"Ratio train steps to played games": 1.9945054945054945, "Avg loss": 2.299438594840467, "Avg value loss": 1.8726093790028244, "Avg policy loss": 0.4268292353954166, "Total num played games": 57694, "Total num trained steps": 115072, "Timestamp in ms": 1699668416393, "logtype": "training_step"}
{"Avg objective": 24.1328125, "Games time in secs": 106.34462384693325, "Avg game time in secs": 1.384830608672928, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.7}, "Total num played games": 57728, "Total num trained steps": 115135, "Timestamp in ms": 1699668447940, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950642513248589, "Avg loss": 1.4500856096856296, "Avg value loss": 1.0204456644132733, "Avg policy loss": 0.4296399401500821, "Total num played games": 57742, "Total num trained steps": 115200, "Timestamp in ms": 1699668478474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944314742758322, "Avg loss": 2.4707268364727497, "Avg value loss": 2.0357714546844363, "Avg policy loss": 0.434955365722999, "Total num played games": 57823, "Total num trained steps": 115328, "Timestamp in ms": 1699668543595, "logtype": "training_step"}
{"Avg objective": 25.2890625, "Games time in secs": 140.9290820248425, "Avg game time in secs": 1.3987631255295128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 57856, "Total num trained steps": 115422, "Timestamp in ms": 1699668588869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994540994368241, "Avg loss": 1.9473231215961277, "Avg value loss": 1.522768575930968, "Avg policy loss": 0.4245545510202646, "Total num played games": 57886, "Total num trained steps": 115456, "Timestamp in ms": 1699668605646, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950806089688267, "Avg loss": 1.5351199670694768, "Avg value loss": 1.0986250364221632, "Avg policy loss": 0.4364949360024184, "Total num played games": 57934, "Total num trained steps": 115584, "Timestamp in ms": 1699668668071, "logtype": "training_step"}
{"Total num played games": 57982, "Total num trained steps": 115622, "Timestamp in ms": 1699668697221, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.75}
{"Avg objective": 22.90625, "Games time in secs": 109.66376097686589, "Avg game time in secs": 1.609395898936782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.22, "agent_stopped_more": 0.78, "played_steps": 0.88}, "Total num played games": 57984, "Total num trained steps": 115623, "Timestamp in ms": 1699668698533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9940031018438737, "Avg loss": 2.0303019089624286, "Avg value loss": 1.5966184163698927, "Avg policy loss": 0.43368350993841887, "Total num played games": 58030, "Total num trained steps": 115712, "Timestamp in ms": 1699668740805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9945590412893006, "Avg loss": 1.4808697551488876, "Avg value loss": 1.0581398300128058, "Avg policy loss": 0.4227299289777875, "Total num played games": 58078, "Total num trained steps": 115840, "Timestamp in ms": 1699668803904, "logtype": "training_step"}
{"Avg objective": 24.859375, "Games time in secs": 135.31312402896583, "Avg game time in secs": 1.3934829129866557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.74}, "Total num played games": 58112, "Total num trained steps": 115903, "Timestamp in ms": 1699668833847, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950797391917698, "Avg loss": 1.8791520055383444, "Avg value loss": 1.4533951703924686, "Avg policy loss": 0.4257568174507469, "Total num played games": 58127, "Total num trained steps": 115968, "Timestamp in ms": 1699668865393, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995188011273802, "Avg loss": 1.2297340328805149, "Avg value loss": 0.8132665958255529, "Avg policy loss": 0.41646744566969573, "Total num played games": 58188, "Total num trained steps": 116096, "Timestamp in ms": 1699668928105, "logtype": "training_step"}
{"Avg objective": 23.9921875, "Games time in secs": 141.3507281653583, "Avg game time in secs": 1.3552206124004442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 58240, "Total num trained steps": 116192, "Timestamp in ms": 1699668975197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994525578761305, "Avg loss": 2.8029993874952197, "Avg value loss": 2.3750824986491352, "Avg policy loss": 0.42791693028993905, "Total num played games": 58271, "Total num trained steps": 116224, "Timestamp in ms": 1699668992783, "logtype": "training_step"}
{"Total num played games": 58271, "Total num trained steps": 116224, "Timestamp in ms": 1699669002885, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.38671875}
{"Ratio train steps to played games": 1.9950959378590167, "Avg loss": 3.2421301789581776, "Avg value loss": 2.770319705363363, "Avg policy loss": 0.47181044914759696, "Total num played games": 58319, "Total num trained steps": 116352, "Timestamp in ms": 1699669067832, "logtype": "training_step"}
{"Avg objective": 27.1328125, "Games time in secs": 154.7644603997469, "Avg game time in secs": 1.5118783087382326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.77, "agent_stopped_0": 0.31}, "Total num played games": 58368, "Total num trained steps": 116479, "Timestamp in ms": 1699669129962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9952038369304557, "Avg loss": 1.655700067523867, "Avg value loss": 1.2171888703014702, "Avg policy loss": 0.43851118814200163, "Total num played games": 58378, "Total num trained steps": 116480, "Timestamp in ms": 1699669130339, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9945265462506843, "Avg loss": 1.7238657092675567, "Avg value loss": 1.2783885664539412, "Avg policy loss": 0.4454771368764341, "Total num played games": 58464, "Total num trained steps": 116608, "Timestamp in ms": 1699669191493, "logtype": "training_step"}
{"Avg objective": 24.28125, "Games time in secs": 93.55865989252925, "Avg game time in secs": 1.4079126149881631, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.73}, "Total num played games": 58496, "Total num trained steps": 116675, "Timestamp in ms": 1699669223521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950779327317474, "Avg loss": 2.393384613096714, "Avg value loss": 1.9513083074707538, "Avg policy loss": 0.4420763226225972, "Total num played games": 58512, "Total num trained steps": 116736, "Timestamp in ms": 1699669253797, "logtype": "training_step"}
{"Total num played games": 58560, "Total num trained steps": 116824, "Timestamp in ms": 1699669307170, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.87109375}
{"Ratio train steps to played games": 1.993993993993994, "Avg loss": 3.043176067993045, "Avg value loss": 2.6019188065547496, "Avg policy loss": 0.4412572563160211, "Total num played games": 58608, "Total num trained steps": 116864, "Timestamp in ms": 1699669328244, "logtype": "training_step"}
{"Avg objective": 24.5625, "Games time in secs": 152.63683731108904, "Avg game time in secs": 1.538913925513043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 58624, "Total num trained steps": 116962, "Timestamp in ms": 1699669376158, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994544462629569, "Avg loss": 2.1454940694384277, "Avg value loss": 1.6909397416748106, "Avg policy loss": 0.4545543477870524, "Total num played games": 58656, "Total num trained steps": 116992, "Timestamp in ms": 1699669390494, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950940310711365, "Avg loss": 2.4512532553635538, "Avg value loss": 1.9800088531337678, "Avg policy loss": 0.47124441899359226, "Total num played games": 58704, "Total num trained steps": 117120, "Timestamp in ms": 1699669454148, "logtype": "training_step"}
{"Avg objective": 25.8671875, "Games time in secs": 97.38635050319135, "Avg game time in secs": 1.6394878505234374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.77}, "Total num played games": 58752, "Total num trained steps": 117160, "Timestamp in ms": 1699669473544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956427015250544, "Avg loss": 0.9580292981117964, "Avg value loss": 0.5242856080876663, "Avg policy loss": 0.4337437003850937, "Total num played games": 58752, "Total num trained steps": 117248, "Timestamp in ms": 1699669517565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994562262098967, "Avg loss": 2.589883664622903, "Avg value loss": 2.1504403876606375, "Avg policy loss": 0.4394432855769992, "Total num played games": 58848, "Total num trained steps": 117376, "Timestamp in ms": 1699669579439, "logtype": "training_step"}
{"Total num played games": 58848, "Total num trained steps": 117424, "Timestamp in ms": 1699669615188, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.890625}
{"Avg objective": 27.3984375, "Games time in secs": 144.03547056019306, "Avg game time in secs": 1.4461502322665183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 58880, "Total num trained steps": 117428, "Timestamp in ms": 1699669617580, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951100244498778, "Avg loss": 3.290215360466391, "Avg value loss": 2.829928779276088, "Avg policy loss": 0.4602866454515606, "Total num played games": 58896, "Total num trained steps": 117504, "Timestamp in ms": 1699669654102, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956399294245386, "Avg loss": 1.1591457556933165, "Avg value loss": 0.7122945298906416, "Avg policy loss": 0.4468512104358524, "Total num played games": 58944, "Total num trained steps": 117632, "Timestamp in ms": 1699669715278, "logtype": "training_step"}
{"Avg objective": 25.09375, "Games time in secs": 144.9250050764531, "Avg game time in secs": 1.635520278068725, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 59008, "Total num trained steps": 117730, "Timestamp in ms": 1699669762505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994579945799458, "Avg loss": 2.375700199045241, "Avg value loss": 1.9284727366175503, "Avg policy loss": 0.4472274873405695, "Total num played games": 59040, "Total num trained steps": 117760, "Timestamp in ms": 1699669777485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950752255072857, "Avg loss": 1.2506903959438205, "Avg value loss": 0.8207934917882085, "Avg policy loss": 0.42989689391106367, "Total num played games": 59089, "Total num trained steps": 117888, "Timestamp in ms": 1699669838971, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 96.09866981208324, "Avg game time in secs": 1.5928674445458455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 59136, "Total num trained steps": 117929, "Timestamp in ms": 1699669858604, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956372490995484, "Avg loss": 1.1173096816055477, "Avg value loss": 0.6872267758008093, "Avg policy loss": 0.43008288904093206, "Total num played games": 59137, "Total num trained steps": 118016, "Timestamp in ms": 1699669900430, "logtype": "training_step"}
{"Total num played games": 59185, "Total num trained steps": 118025, "Timestamp in ms": 1699669916796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8359375}
{"Ratio train steps to played games": 1.9945638411020883, "Avg loss": 3.3309944574721158, "Avg value loss": 2.8936330499127507, "Avg policy loss": 0.4373613693751395, "Total num played games": 59233, "Total num trained steps": 118144, "Timestamp in ms": 1699669974745, "logtype": "training_step"}
{"Avg objective": 22.90625, "Games time in secs": 150.12454440444708, "Avg game time in secs": 1.4352484014816582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.7, "agent_stopped_0": 0.33}, "Total num played games": 59264, "Total num trained steps": 118213, "Timestamp in ms": 1699670008729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951080447360874, "Avg loss": 1.7940774750895798, "Avg value loss": 1.3816473846090958, "Avg policy loss": 0.41243007709272206, "Total num played games": 59281, "Total num trained steps": 118272, "Timestamp in ms": 1699670036493, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956345126329451, "Avg loss": 2.12878424115479, "Avg value loss": 1.705710779177025, "Avg policy loss": 0.4230734179727733, "Total num played games": 59329, "Total num trained steps": 118400, "Timestamp in ms": 1699670099781, "logtype": "training_step"}
{"Avg objective": 25.5078125, "Games time in secs": 140.9879803173244, "Avg game time in secs": 1.643644498413778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.78, "agent_stopped_0": 0.29}, "Total num played games": 59392, "Total num trained steps": 118500, "Timestamp in ms": 1699670149717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99458140513252, "Avg loss": 1.4017421649768949, "Avg value loss": 0.9864413610193878, "Avg policy loss": 0.4153008309658617, "Total num played games": 59425, "Total num trained steps": 118528, "Timestamp in ms": 1699670162669, "logtype": "training_step"}
{"Total num played games": 59473, "Total num trained steps": 118625, "Timestamp in ms": 1699670219964, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.48046875}
{"Avg objective": 26.1328125, "Games time in secs": 74.65568510256708, "Avg game time in secs": 1.5965964428905863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.85, "agent_stopped_0": 0.24}, "Total num played games": 59520, "Total num trained steps": 118633, "Timestamp in ms": 1699670224373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935148939029923, "Avg loss": 3.598242398351431, "Avg value loss": 3.1785249415552244, "Avg policy loss": 0.41971743130125105, "Total num played games": 59521, "Total num trained steps": 118656, "Timestamp in ms": 1699670235297, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956653954066632, "Avg loss": 1.6197623913176358, "Avg value loss": 1.185921358410269, "Avg policy loss": 0.4338410347700119, "Total num played games": 59521, "Total num trained steps": 118784, "Timestamp in ms": 1699670297101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994598856030998, "Avg loss": 1.620418956503272, "Avg value loss": 1.2059981719357893, "Avg policy loss": 0.4144208147190511, "Total num played games": 59617, "Total num trained steps": 118912, "Timestamp in ms": 1699670358063, "logtype": "training_step"}
{"Avg objective": 24.640625, "Games time in secs": 166.93101924285293, "Avg game time in secs": 1.3982443885906832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.7, "agent_stopped_0": 0.33}, "Total num played games": 59648, "Total num trained steps": 118982, "Timestamp in ms": 1699670391304, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951395290371239, "Avg loss": 2.109401574358344, "Avg value loss": 1.695318308309652, "Avg policy loss": 0.4140832575503737, "Total num played games": 59665, "Total num trained steps": 119040, "Timestamp in ms": 1699670418418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995645912181398, "Avg loss": 1.9418042404577136, "Avg value loss": 1.5093262407463044, "Avg policy loss": 0.4324779976159334, "Total num played games": 59714, "Total num trained steps": 119168, "Timestamp in ms": 1699670481111, "logtype": "training_step"}
{"Total num played games": 59762, "Total num trained steps": 119227, "Timestamp in ms": 1699670521550, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3515625}
{"Avg objective": 24.2265625, "Games time in secs": 131.9804438240826, "Avg game time in secs": 1.6874311777501134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.73, "agent_stopped_0": 0.36}, "Total num played games": 59776, "Total num trained steps": 119228, "Timestamp in ms": 1699670523285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945828456779802, "Avg loss": 2.3874918753281236, "Avg value loss": 1.9486808257643133, "Avg policy loss": 0.43881104071624577, "Total num played games": 59810, "Total num trained steps": 119296, "Timestamp in ms": 1699670557358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951217882321495, "Avg loss": 1.7787330644205213, "Avg value loss": 1.353502202196978, "Avg policy loss": 0.42523086490109563, "Total num played games": 59858, "Total num trained steps": 119424, "Timestamp in ms": 1699670621451, "logtype": "training_step"}
{"Avg objective": 23.3125, "Games time in secs": 118.44848446920514, "Avg game time in secs": 1.4868174108560197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.77}, "Total num played games": 59904, "Total num trained steps": 119467, "Timestamp in ms": 1699670641733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955599325643893, "Avg loss": 1.4942291975021362, "Avg value loss": 1.0556050461018458, "Avg policy loss": 0.4386241103056818, "Total num played games": 59909, "Total num trained steps": 119552, "Timestamp in ms": 1699670683060, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944505549445055, "Avg loss": 3.5664897873066366, "Avg value loss": 3.1221236125566065, "Avg policy loss": 0.44436615076847374, "Total num played games": 60006, "Total num trained steps": 119680, "Timestamp in ms": 1699670746144, "logtype": "training_step"}
{"Avg objective": 28.375, "Games time in secs": 143.62796199694276, "Avg game time in secs": 1.6379409070359543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.69, "agent_stopped_0": 0.4}, "Total num played games": 60032, "Total num trained steps": 119759, "Timestamp in ms": 1699670785361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948716240967066, "Avg loss": 1.8084551552310586, "Avg value loss": 1.3655545483343303, "Avg policy loss": 0.44290060130879283, "Total num played games": 60058, "Total num trained steps": 119808, "Timestamp in ms": 1699670809581, "logtype": "training_step"}
{"Total num played games": 60058, "Total num trained steps": 119827, "Timestamp in ms": 1699670830221, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.90234375}
{"Ratio train steps to played games": 1.995391475060726, "Avg loss": 1.4326361501589417, "Avg value loss": 1.0097999583231285, "Avg policy loss": 0.42283618776127696, "Total num played games": 60106, "Total num trained steps": 119936, "Timestamp in ms": 1699670887602, "logtype": "training_step"}
{"Avg objective": 26.390625, "Games time in secs": 165.12405957467854, "Avg game time in secs": 1.6120578208210645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.84, "played_steps": 0.92, "agent_stopped_0": 0.16}, "Total num played games": 60160, "Total num trained steps": 120055, "Timestamp in ms": 1699670950487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943026095045098, "Avg loss": 2.60443428857252, "Avg value loss": 2.1707188906148076, "Avg policy loss": 0.4337153872475028, "Total num played games": 60203, "Total num trained steps": 120064, "Timestamp in ms": 1699670955283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994838259945893, "Avg loss": 1.9703030148521066, "Avg value loss": 1.5482045497046784, "Avg policy loss": 0.422098457114771, "Total num played games": 60251, "Total num trained steps": 120192, "Timestamp in ms": 1699671017437, "logtype": "training_step"}
{"Avg objective": 25.6171875, "Games time in secs": 96.3598236143589, "Avg game time in secs": 1.3491324391507078, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 60288, "Total num trained steps": 120250, "Timestamp in ms": 1699671046847, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953730575963118, "Avg loss": 2.5288560087792575, "Avg value loss": 2.0858791621867567, "Avg policy loss": 0.44297685008496046, "Total num played games": 60299, "Total num trained steps": 120320, "Timestamp in ms": 1699671081079, "logtype": "training_step"}
{"Total num played games": 60348, "Total num trained steps": 120428, "Timestamp in ms": 1699671144845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8828125}
{"Ratio train steps to played games": 1.9943042585601696, "Avg loss": 1.9890012773685157, "Avg value loss": 1.5601896666921675, "Avg policy loss": 0.4288116251118481, "Total num played games": 60396, "Total num trained steps": 120448, "Timestamp in ms": 1699671155192, "logtype": "training_step"}
{"Avg objective": 23.9765625, "Games time in secs": 151.8626895379275, "Avg game time in secs": 1.41593163338257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 60416, "Total num trained steps": 120538, "Timestamp in ms": 1699671198710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948216531003904, "Avg loss": 1.835060219746083, "Avg value loss": 1.4160673640435562, "Avg policy loss": 0.41899286047555506, "Total num played games": 60444, "Total num trained steps": 120576, "Timestamp in ms": 1699671217055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9953712887654567, "Avg loss": 1.446228533051908, "Avg value loss": 1.0304904526565224, "Avg policy loss": 0.4157380748074502, "Total num played games": 60492, "Total num trained steps": 120704, "Timestamp in ms": 1699671277911, "logtype": "training_step"}
{"Avg objective": 24.828125, "Games time in secs": 139.48014690354466, "Avg game time in secs": 1.5169019944150932, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 60544, "Total num trained steps": 120825, "Timestamp in ms": 1699671338193, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994371637011851, "Avg loss": 1.5344026368111372, "Avg value loss": 1.1234585714992136, "Avg policy loss": 0.410944031085819, "Total num played games": 60586, "Total num trained steps": 120832, "Timestamp in ms": 1699671341218, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948216435509671, "Avg loss": 2.274845295585692, "Avg value loss": 1.853788245934993, "Avg policy loss": 0.4210570810828358, "Total num played games": 60637, "Total num trained steps": 120960, "Timestamp in ms": 1699671404703, "logtype": "training_step"}
{"Avg objective": 27.390625, "Games time in secs": 95.82007626630366, "Avg game time in secs": 1.437021999125136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.72}, "Total num played games": 60672, "Total num trained steps": 121021, "Timestamp in ms": 1699671434013, "logtype": "played_game"}
{"Total num played games": 60685, "Total num trained steps": 121030, "Timestamp in ms": 1699671449316, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.55859375}
{"Ratio train steps to played games": 1.9937760360924044, "Avg loss": 3.2428132258355618, "Avg value loss": 2.811619669664651, "Avg policy loss": 0.4311935354489833, "Total num played games": 60733, "Total num trained steps": 121088, "Timestamp in ms": 1699671476744, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994619143999605, "Avg loss": 1.0133956288918853, "Avg value loss": 0.5907544891815633, "Avg policy loss": 0.422641136450693, "Total num played games": 60770, "Total num trained steps": 121216, "Timestamp in ms": 1699671540007, "logtype": "training_step"}
{"Avg objective": 23.859375, "Games time in secs": 147.8484037462622, "Avg game time in secs": 1.387698074846412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 60800, "Total num trained steps": 121313, "Timestamp in ms": 1699671581861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994690381865106, "Avg loss": 1.8781484933570027, "Avg value loss": 1.4597822573268786, "Avg policy loss": 0.41836623870767653, "Total num played games": 60833, "Total num trained steps": 121344, "Timestamp in ms": 1699671595030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951874117144641, "Avg loss": 1.927498602308333, "Avg value loss": 1.5052999892504886, "Avg policy loss": 0.4221985961776227, "Total num played games": 60882, "Total num trained steps": 121472, "Timestamp in ms": 1699671651069, "logtype": "training_step"}
{"Avg objective": 24.3203125, "Games time in secs": 88.72317655198276, "Avg game time in secs": 1.6497173622919945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.26, "agent_stopped_more": 0.74, "played_steps": 0.87}, "Total num played games": 60928, "Total num trained steps": 121515, "Timestamp in ms": 1699671670585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957163958641064, "Avg loss": 1.9093429292552173, "Avg value loss": 1.4794536472763866, "Avg policy loss": 0.42988925403915346, "Total num played games": 60930, "Total num trained steps": 121600, "Timestamp in ms": 1699671709252, "logtype": "training_step"}
{"Total num played games": 60978, "Total num trained steps": 121630, "Timestamp in ms": 1699671733012, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.66015625}
{"Ratio train steps to played games": 1.9946744010749518, "Avg loss": 3.5465152598917484, "Avg value loss": 3.087403995450586, "Avg policy loss": 0.45911127841100097, "Total num played games": 61026, "Total num trained steps": 121728, "Timestamp in ms": 1699671776743, "logtype": "training_step"}
{"Avg objective": 24.0078125, "Games time in secs": 138.01194445602596, "Avg game time in secs": 1.3107895701396046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.73, "agent_stopped_0": 0.35}, "Total num played games": 61056, "Total num trained steps": 121801, "Timestamp in ms": 1699671808597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995186246418338, "Avg loss": 1.5747428555041552, "Avg value loss": 1.133068319875747, "Avg policy loss": 0.4416745286434889, "Total num played games": 61075, "Total num trained steps": 121856, "Timestamp in ms": 1699671833458, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956645507492965, "Avg loss": 1.5103647522628307, "Avg value loss": 1.0629933825694025, "Avg policy loss": 0.44737138599157333, "Total num played games": 61124, "Total num trained steps": 121984, "Timestamp in ms": 1699671889273, "logtype": "training_step"}
{"Avg objective": 23.0859375, "Games time in secs": 127.01413168758154, "Avg game time in secs": 1.6695979172218358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.8, "agent_stopped_0": 0.33}, "Total num played games": 61184, "Total num trained steps": 122095, "Timestamp in ms": 1699671935611, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945282001862046, "Avg loss": 1.2534312563948333, "Avg value loss": 0.8227375757414848, "Avg policy loss": 0.43069367995485663, "Total num played games": 61223, "Total num trained steps": 122112, "Timestamp in ms": 1699671942945, "logtype": "training_step"}
{"Total num played games": 61273, "Total num trained steps": 122231, "Timestamp in ms": 1699672009446, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.08984375}
{"Avg objective": 22.8515625, "Games time in secs": 77.11785124242306, "Avg game time in secs": 1.429971821649815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.82}, "Total num played games": 61312, "Total num trained steps": 122238, "Timestamp in ms": 1699672012729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935580670939543, "Avg loss": 1.9419301766902208, "Avg value loss": 1.5097372954478487, "Avg policy loss": 0.4321928760036826, "Total num played games": 61317, "Total num trained steps": 122240, "Timestamp in ms": 1699672013570, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955317101808516, "Avg loss": 1.1218159864656627, "Avg value loss": 0.6938443433027714, "Avg policy loss": 0.42797164199873805, "Total num played games": 61321, "Total num trained steps": 122368, "Timestamp in ms": 1699672074427, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9944478817284834, "Avg loss": 1.6452628569677472, "Avg value loss": 1.2207760917954147, "Avg policy loss": 0.4244867372326553, "Total num played games": 61418, "Total num trained steps": 122496, "Timestamp in ms": 1699672130503, "logtype": "training_step"}
{"Avg objective": 23.953125, "Games time in secs": 156.9945759512484, "Avg game time in secs": 1.3889307777717477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 61440, "Total num trained steps": 122585, "Timestamp in ms": 1699672169724, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9949403745098997, "Avg loss": 2.500030984636396, "Avg value loss": 2.0656560651259497, "Avg policy loss": 0.43437494966201484, "Total num played games": 61467, "Total num trained steps": 122624, "Timestamp in ms": 1699672187468, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9953996456264123, "Avg loss": 2.2080028881318867, "Avg value loss": 1.7755944498348981, "Avg policy loss": 0.43240843061357737, "Total num played games": 61517, "Total num trained steps": 122752, "Timestamp in ms": 1699672243372, "logtype": "training_step"}
{"Total num played games": 61565, "Total num trained steps": 122831, "Timestamp in ms": 1699672290700, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.43359375}
{"Avg objective": 27.015625, "Games time in secs": 121.99981745705009, "Avg game time in secs": 1.5813572688930435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.84, "agent_stopped_0": 0.27}, "Total num played games": 61568, "Total num trained steps": 122832, "Timestamp in ms": 1699672291724, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943680716731857, "Avg loss": 2.390909898560494, "Avg value loss": 1.942320388974622, "Avg policy loss": 0.4485894809477031, "Total num played games": 61613, "Total num trained steps": 122880, "Timestamp in ms": 1699672312385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948752878596219, "Avg loss": 1.4690432203933597, "Avg value loss": 1.0295134376501665, "Avg policy loss": 0.43952979426831007, "Total num played games": 61662, "Total num trained steps": 123008, "Timestamp in ms": 1699672369522, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 106.67225953005254, "Avg game time in secs": 1.369981053401716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.74}, "Total num played games": 61696, "Total num trained steps": 123073, "Timestamp in ms": 1699672398396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953492894297613, "Avg loss": 1.1791123263537884, "Avg value loss": 0.738434107741341, "Avg policy loss": 0.44067822047509253, "Total num played games": 61711, "Total num trained steps": 123136, "Timestamp in ms": 1699672426603, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958064150515697, "Avg loss": 1.4871294391341507, "Avg value loss": 1.0514136754209176, "Avg policy loss": 0.43571575568057597, "Total num played games": 61761, "Total num trained steps": 123264, "Timestamp in ms": 1699672483438, "logtype": "training_step"}
{"Avg objective": 24.140625, "Games time in secs": 132.31456023454666, "Avg game time in secs": 1.6472484713885933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.8, "agent_stopped_0": 0.28}, "Total num played games": 61824, "Total num trained steps": 123367, "Timestamp in ms": 1699672530711, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994713784574597, "Avg loss": 1.7128905835561454, "Avg value loss": 1.2831565899541602, "Avg policy loss": 0.4297339979093522, "Total num played games": 61859, "Total num trained steps": 123392, "Timestamp in ms": 1699672541717, "logtype": "training_step"}
{"Total num played games": 61859, "Total num trained steps": 123431, "Timestamp in ms": 1699672574743, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8046875}
{"Ratio train steps to played games": 1.9952509409275203, "Avg loss": 2.095203699544072, "Avg value loss": 1.671606330317445, "Avg policy loss": 0.423597389832139, "Total num played games": 61907, "Total num trained steps": 123520, "Timestamp in ms": 1699672615942, "logtype": "training_step"}
{"Avg objective": 26.1171875, "Games time in secs": 104.73273615166545, "Avg game time in secs": 1.3894243056565756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.78, "agent_stopped_0": 0.27}, "Total num played games": 61952, "Total num trained steps": 123564, "Timestamp in ms": 1699672635444, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995754983455734, "Avg loss": 2.1328199096024036, "Avg value loss": 1.7048201663419604, "Avg policy loss": 0.42799974069930613, "Total num played games": 61955, "Total num trained steps": 123648, "Timestamp in ms": 1699672673196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946819654166599, "Avg loss": 1.5470143859274685, "Avg value loss": 1.1158884540200233, "Avg policy loss": 0.4311259223613888, "Total num played games": 62053, "Total num trained steps": 123776, "Timestamp in ms": 1699672729427, "logtype": "training_step"}
{"Avg objective": 23.09375, "Games time in secs": 129.4049797039479, "Avg game time in secs": 1.4860082365339622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.73, "agent_stopped_0": 0.35}, "Total num played games": 62080, "Total num trained steps": 123854, "Timestamp in ms": 1699672764849, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951852627171864, "Avg loss": 1.7127594724297523, "Avg value loss": 1.271696973592043, "Avg policy loss": 0.4410625100135803, "Total num played games": 62101, "Total num trained steps": 123904, "Timestamp in ms": 1699672786913, "logtype": "training_step"}
{"Total num played games": 62152, "Total num trained steps": 124031, "Timestamp in ms": 1699672856530, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5859375}
{"Ratio train steps to played games": 1.9956075427983009, "Avg loss": 1.6008472596295178, "Avg value loss": 1.1671747710788622, "Avg policy loss": 0.4336724607273936, "Total num played games": 62152, "Total num trained steps": 124032, "Timestamp in ms": 1699672857205, "logtype": "training_step"}
{"Avg objective": 24.7734375, "Games time in secs": 142.98993992619216, "Avg game time in secs": 1.4231170174025465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 62208, "Total num trained steps": 124146, "Timestamp in ms": 1699672907839, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945541293836047, "Avg loss": 2.0248949849046767, "Avg value loss": 1.5995612593833357, "Avg policy loss": 0.4253337364643812, "Total num played games": 62249, "Total num trained steps": 124160, "Timestamp in ms": 1699672913897, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9950239971749146, "Avg loss": 2.5023149480111897, "Avg value loss": 2.067911784630269, "Avg policy loss": 0.4344031426589936, "Total num played games": 62299, "Total num trained steps": 124288, "Timestamp in ms": 1699672968964, "logtype": "training_step"}
{"Avg objective": 26.7109375, "Games time in secs": 86.7738710809499, "Avg game time in secs": 1.4188606114621507, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.73}, "Total num played games": 62336, "Total num trained steps": 124347, "Timestamp in ms": 1699672994613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955090780778855, "Avg loss": 2.7605195697396994, "Avg value loss": 2.322784750489518, "Avg policy loss": 0.43773483159020543, "Total num played games": 62348, "Total num trained steps": 124416, "Timestamp in ms": 1699673025021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958494254899761, "Avg loss": 1.5334051824174821, "Avg value loss": 1.0942171905189753, "Avg policy loss": 0.43918798631057143, "Total num played games": 62401, "Total num trained steps": 124544, "Timestamp in ms": 1699673081713, "logtype": "training_step"}
{"Total num played games": 62451, "Total num trained steps": 124634, "Timestamp in ms": 1699673135805, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.765625}
{"Avg objective": 25.0234375, "Games time in secs": 142.91933068074286, "Avg game time in secs": 1.5102758458669996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.68, "agent_stopped_0": 0.34}, "Total num played games": 62464, "Total num trained steps": 124637, "Timestamp in ms": 1699673137532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947679162866605, "Avg loss": 1.893513498827815, "Avg value loss": 1.46748381620273, "Avg policy loss": 0.4260296483989805, "Total num played games": 62499, "Total num trained steps": 124672, "Timestamp in ms": 1699673153083, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952516467353072, "Avg loss": 1.6535789927002043, "Avg value loss": 1.241075744968839, "Avg policy loss": 0.41250324179418385, "Total num played games": 62548, "Total num trained steps": 124800, "Timestamp in ms": 1699673209912, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 92.95014804042876, "Avg game time in secs": 1.4423176915297518, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.82, "agent_stopped_0": 0.25}, "Total num played games": 62592, "Total num trained steps": 124846, "Timestamp in ms": 1699673230483, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995734619869962, "Avg loss": 1.396584378555417, "Avg value loss": 0.9763399969087914, "Avg policy loss": 0.4202443645335734, "Total num played games": 62597, "Total num trained steps": 124928, "Timestamp in ms": 1699673269391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946408064310324, "Avg loss": 2.099035846069455, "Avg value loss": 1.6868883788120002, "Avg policy loss": 0.41214747563935816, "Total num played games": 62696, "Total num trained steps": 125056, "Timestamp in ms": 1699673326068, "logtype": "training_step"}
{"Avg objective": 23.90625, "Games time in secs": 133.49834000505507, "Avg game time in secs": 1.5795362310309429, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.77, "agent_stopped_0": 0.33}, "Total num played games": 62720, "Total num trained steps": 125140, "Timestamp in ms": 1699673363981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951071798549684, "Avg loss": 2.081349282991141, "Avg value loss": 1.656282959273085, "Avg policy loss": 0.4250663334969431, "Total num played games": 62745, "Total num trained steps": 125184, "Timestamp in ms": 1699673382933, "logtype": "training_step"}
{"Total num played games": 62793, "Total num trained steps": 125236, "Timestamp in ms": 1699673425851, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3828125}
{"Ratio train steps to played games": 1.994096211072389, "Avg loss": 2.4129356439225376, "Avg value loss": 1.9860796905122697, "Avg policy loss": 0.4268559510819614, "Total num played games": 62841, "Total num trained steps": 125312, "Timestamp in ms": 1699673459408, "logtype": "training_step"}
{"Avg objective": 24.7734375, "Games time in secs": 146.59108170494437, "Avg game time in secs": 1.5897094593237853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.68}, "Total num played games": 62848, "Total num trained steps": 125429, "Timestamp in ms": 1699673510573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9945937350930196, "Avg loss": 0.9763346095569432, "Avg value loss": 0.571925769909285, "Avg policy loss": 0.4044088313821703, "Total num played games": 62890, "Total num trained steps": 125440, "Timestamp in ms": 1699673515324, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995011200965984, "Avg loss": 2.0767443808726966, "Avg value loss": 1.6755143073387444, "Avg policy loss": 0.40123009169474244, "Total num played games": 62941, "Total num trained steps": 125568, "Timestamp in ms": 1699673571900, "logtype": "training_step"}
{"Avg objective": 25.390625, "Games time in secs": 90.16404808871448, "Avg game time in secs": 1.442440424740198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.77}, "Total num played games": 62976, "Total num trained steps": 125632, "Timestamp in ms": 1699673600737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954913478329894, "Avg loss": 2.4399857567623258, "Avg value loss": 2.0292917317710817, "Avg policy loss": 0.41069404501467943, "Total num played games": 62990, "Total num trained steps": 125696, "Timestamp in ms": 1699673629424, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958915626338414, "Avg loss": 2.5535385231487453, "Avg value loss": 2.125866976333782, "Avg policy loss": 0.42767151934094727, "Total num played games": 63041, "Total num trained steps": 125824, "Timestamp in ms": 1699673685695, "logtype": "training_step"}
{"Total num played games": 63090, "Total num trained steps": 125840, "Timestamp in ms": 1699673707706, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.21484375}
{"Avg objective": 25.1328125, "Games time in secs": 108.75000865757465, "Avg game time in secs": 1.5183855287759798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.8, "agent_stopped_0": 0.27}, "Total num played games": 63104, "Total num trained steps": 125844, "Timestamp in ms": 1699673709487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948525452184105, "Avg loss": 3.28760820440948, "Avg value loss": 2.8551722455304116, "Avg policy loss": 0.43243597145192325, "Total num played games": 63138, "Total num trained steps": 125952, "Timestamp in ms": 1699673757532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952997404570487, "Avg loss": 1.5942416028119624, "Avg value loss": 1.1856908705085516, "Avg policy loss": 0.40855072485283017, "Total num played games": 63188, "Total num trained steps": 126080, "Timestamp in ms": 1699673815779, "logtype": "training_step"}
{"Avg objective": 23.1328125, "Games time in secs": 127.40887617878616, "Avg game time in secs": 1.3600853671669029, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 63232, "Total num trained steps": 126126, "Timestamp in ms": 1699673836896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956989247311827, "Avg loss": 1.423027312848717, "Avg value loss": 1.0270389716606587, "Avg policy loss": 0.3959883125498891, "Total num played games": 63240, "Total num trained steps": 126208, "Timestamp in ms": 1699673874219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946319744860905, "Avg loss": 1.7575893276371062, "Avg value loss": 1.3614928741008043, "Avg policy loss": 0.3960964451543987, "Total num played games": 63338, "Total num trained steps": 126336, "Timestamp in ms": 1699673929046, "logtype": "training_step"}
{"Avg objective": 23.4921875, "Games time in secs": 131.52482897415757, "Avg game time in secs": 1.548244090154185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.79, "agent_stopped_0": 0.25}, "Total num played games": 63360, "Total num trained steps": 126424, "Timestamp in ms": 1699673968421, "logtype": "played_game"}
{"Total num played games": 63387, "Total num trained steps": 126442, "Timestamp in ms": 1699673989140, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2890625}
{"Ratio train steps to played games": 1.9935839836052653, "Avg loss": 1.6223587719723582, "Avg value loss": 1.2314235843950883, "Avg policy loss": 0.39093518862500787, "Total num played games": 63435, "Total num trained steps": 126464, "Timestamp in ms": 1699673999284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956017971151572, "Avg loss": 0.9259925801306963, "Avg value loss": 0.5317815905436873, "Avg policy loss": 0.39421099540777504, "Total num played games": 63435, "Total num trained steps": 126592, "Timestamp in ms": 1699674056297, "logtype": "training_step"}
{"Avg objective": 22.484375, "Games time in secs": 141.82353475689888, "Avg game time in secs": 1.5291936615394661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.81, "agent_stopped_0": 0.27}, "Total num played games": 63488, "Total num trained steps": 126714, "Timestamp in ms": 1699674110245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994538271449483, "Avg loss": 1.1909883487969637, "Avg value loss": 0.818815840757452, "Avg policy loss": 0.37217248999513686, "Total num played games": 63533, "Total num trained steps": 126720, "Timestamp in ms": 1699674112484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994951560140916, "Avg loss": 2.633768279105425, "Avg value loss": 2.242415977176279, "Avg policy loss": 0.3913522604852915, "Total num played games": 63584, "Total num trained steps": 126848, "Timestamp in ms": 1699674168124, "logtype": "training_step"}
{"Avg objective": 26.6640625, "Games time in secs": 88.2735416200012, "Avg game time in secs": 1.2970689197973115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.73}, "Total num played games": 63616, "Total num trained steps": 126916, "Timestamp in ms": 1699674198518, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953641863754223, "Avg loss": 2.54110695887357, "Avg value loss": 2.1305094168055803, "Avg policy loss": 0.4105975467246026, "Total num played games": 63635, "Total num trained steps": 126976, "Timestamp in ms": 1699674224508, "logtype": "training_step"}
{"Total num played games": 63687, "Total num trained steps": 127045, "Timestamp in ms": 1699674272034, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.453125}
{"Ratio train steps to played games": 1.9942574723464344, "Avg loss": 2.7009808141738176, "Avg value loss": 2.2851834994507954, "Avg policy loss": 0.4157973579131067, "Total num played games": 63735, "Total num trained steps": 127104, "Timestamp in ms": 1699674298775, "logtype": "training_step"}
{"Avg objective": 24.9609375, "Games time in secs": 150.5962422080338, "Avg game time in secs": 1.5751549590931972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.84, "agent_stopped_0": 0.29}, "Total num played games": 63744, "Total num trained steps": 127216, "Timestamp in ms": 1699674349115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946852708317002, "Avg loss": 1.1213325676508248, "Avg value loss": 0.710763449431397, "Avg policy loss": 0.41056912136264145, "Total num played games": 63785, "Total num trained steps": 127232, "Timestamp in ms": 1699674355461, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995159319484914, "Avg loss": 1.2581087364815176, "Avg value loss": 0.8652355215745047, "Avg policy loss": 0.3928732010535896, "Total num played games": 63834, "Total num trained steps": 127360, "Timestamp in ms": 1699674412364, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 88.50211706012487, "Avg game time in secs": 1.4182639956270577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.75}, "Total num played games": 63872, "Total num trained steps": 127418, "Timestamp in ms": 1699674437617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995632640921685, "Avg loss": 1.7750274259597063, "Avg value loss": 1.38213091425132, "Avg policy loss": 0.39289648458361626, "Total num played games": 63883, "Total num trained steps": 127488, "Timestamp in ms": 1699674469485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9946233197874337, "Avg loss": 2.299922600388527, "Avg value loss": 1.9008752561639994, "Avg policy loss": 0.39904735097661614, "Total num played games": 63980, "Total num trained steps": 127616, "Timestamp in ms": 1699674526352, "logtype": "training_step"}
{"Total num played games": 63981, "Total num trained steps": 127648, "Timestamp in ms": 1699674552746, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.359375}
{"Avg objective": 24.6875, "Games time in secs": 117.05651312321424, "Avg game time in secs": 1.3914826523541706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 64000, "Total num trained steps": 127651, "Timestamp in ms": 1699674554674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950803542144966, "Avg loss": 2.963378141168505, "Avg value loss": 2.5416963770985603, "Avg policy loss": 0.42168177268467844, "Total num played games": 64029, "Total num trained steps": 127744, "Timestamp in ms": 1699674595012, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954900124843946, "Avg loss": 2.487175004091114, "Avg value loss": 2.0902549338061363, "Avg policy loss": 0.39692011661827564, "Total num played games": 64080, "Total num trained steps": 127872, "Timestamp in ms": 1699674651918, "logtype": "training_step"}
{"Avg objective": 27.4453125, "Games time in secs": 115.73341388441622, "Avg game time in secs": 1.4782563293265412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.85, "agent_stopped_0": 0.25}, "Total num played games": 64128, "Total num trained steps": 127912, "Timestamp in ms": 1699674670407, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959923902195609, "Avg loss": 1.668732080142945, "Avg value loss": 1.276071731816046, "Avg policy loss": 0.39266035379841924, "Total num played games": 64128, "Total num trained steps": 128000, "Timestamp in ms": 1699674710707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994908683264048, "Avg loss": 1.9830204430036247, "Avg value loss": 1.5837949966080487, "Avg policy loss": 0.39922538911923766, "Total num played games": 64227, "Total num trained steps": 128128, "Timestamp in ms": 1699674766653, "logtype": "training_step"}
{"Avg objective": 24.21875, "Games time in secs": 129.21343029662967, "Avg game time in secs": 1.333243765620864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.7}, "Total num played games": 64256, "Total num trained steps": 128202, "Timestamp in ms": 1699674799621, "logtype": "played_game"}
{"Total num played games": 64276, "Total num trained steps": 128251, "Timestamp in ms": 1699674834285, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.79296875}
{"Ratio train steps to played games": 1.994619057246388, "Avg loss": 1.319064165931195, "Avg value loss": 0.9248481339309365, "Avg policy loss": 0.39421602920629084, "Total num played games": 64299, "Total num trained steps": 128256, "Timestamp in ms": 1699674836635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958802313288975, "Avg loss": 1.3212448065169156, "Avg value loss": 0.9123236222658306, "Avg policy loss": 0.4089211695827544, "Total num played games": 64324, "Total num trained steps": 128384, "Timestamp in ms": 1699674895052, "logtype": "training_step"}
{"Avg objective": 25.09375, "Games time in secs": 143.6289108414203, "Avg game time in secs": 1.6061089286376955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.75, "agent_stopped_0": 0.34}, "Total num played games": 64384, "Total num trained steps": 128495, "Timestamp in ms": 1699674943250, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947999937910375, "Avg loss": 1.5186392343603075, "Avg value loss": 1.128256629803218, "Avg policy loss": 0.39038258674554527, "Total num played games": 64423, "Total num trained steps": 128512, "Timestamp in ms": 1699674950787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995269264176697, "Avg loss": 3.0510476077906787, "Avg value loss": 2.651683124480769, "Avg policy loss": 0.3993644586298615, "Total num played games": 64472, "Total num trained steps": 128640, "Timestamp in ms": 1699675008843, "logtype": "training_step"}
{"Avg objective": 24.625, "Games time in secs": 90.31112273223698, "Avg game time in secs": 1.4521535869134823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.82, "agent_stopped_0": 0.24}, "Total num played games": 64512, "Total num trained steps": 128693, "Timestamp in ms": 1699675033561, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957378217944546, "Avg loss": 2.1460793227888644, "Avg value loss": 1.7355687220115215, "Avg policy loss": 0.41051057586446404, "Total num played games": 64521, "Total num trained steps": 128768, "Timestamp in ms": 1699675068513, "logtype": "training_step"}
{"Total num played games": 64570, "Total num trained steps": 128853, "Timestamp in ms": 1699675116569, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.984375}
{"Ratio train steps to played games": 1.99472283264725, "Avg loss": 2.744227477815002, "Avg value loss": 2.3240600153803825, "Avg policy loss": 0.4201674615032971, "Total num played games": 64618, "Total num trained steps": 128896, "Timestamp in ms": 1699675134867, "logtype": "training_step"}
{"Avg objective": 23.2578125, "Games time in secs": 140.8506123535335, "Avg game time in secs": 1.4816921094898134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 64640, "Total num trained steps": 128984, "Timestamp in ms": 1699675174412, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951753572091298, "Avg loss": 1.6408568257465959, "Avg value loss": 1.2247586401645094, "Avg policy loss": 0.4160981811583042, "Total num played games": 64668, "Total num trained steps": 129024, "Timestamp in ms": 1699675192306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995534610630408, "Avg loss": 1.4396120444871485, "Avg value loss": 1.0228012948064134, "Avg policy loss": 0.41681075491942465, "Total num played games": 64720, "Total num trained steps": 129152, "Timestamp in ms": 1699675249510, "logtype": "training_step"}
{"Avg objective": 23.265625, "Games time in secs": 92.64528875984251, "Avg game time in secs": 1.5147056675486965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.8, "agent_stopped_0": 0.31}, "Total num played games": 64768, "Total num trained steps": 129190, "Timestamp in ms": 1699675267057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959549798520944, "Avg loss": 1.5503032635897398, "Avg value loss": 1.1417323886416852, "Avg policy loss": 0.40857085422612727, "Total num played games": 64771, "Total num trained steps": 129280, "Timestamp in ms": 1699675306893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9948974086235336, "Avg loss": 2.2133837868459523, "Avg value loss": 1.7944573840359226, "Avg policy loss": 0.4189263789448887, "Total num played games": 64869, "Total num trained steps": 129408, "Timestamp in ms": 1699675365976, "logtype": "training_step"}
{"Total num played games": 64869, "Total num trained steps": 129453, "Timestamp in ms": 1699675402377, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3046875}
{"Avg objective": 24.5234375, "Games time in secs": 137.65538010559976, "Avg game time in secs": 1.463738821214065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.76, "agent_stopped_0": 0.32}, "Total num played games": 64896, "Total num trained steps": 129457, "Timestamp in ms": 1699675404713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953941186438067, "Avg loss": 1.950209992006421, "Avg value loss": 1.51132807508111, "Avg policy loss": 0.43888190342113376, "Total num played games": 64917, "Total num trained steps": 129536, "Timestamp in ms": 1699675440219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958593725948959, "Avg loss": 1.4787019141949713, "Avg value loss": 1.0459431933704764, "Avg policy loss": 0.43275872711092234, "Total num played games": 64966, "Total num trained steps": 129664, "Timestamp in ms": 1699675497360, "logtype": "training_step"}
{"Avg objective": 24.609375, "Games time in secs": 145.15097952075303, "Avg game time in secs": 1.565273061656626, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.77, "agent_stopped_0": 0.32}, "Total num played games": 65024, "Total num trained steps": 129778, "Timestamp in ms": 1699675549864, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9946978545521608, "Avg loss": 2.5114001156762242, "Avg value loss": 2.0654988422757015, "Avg policy loss": 0.44590125954709947, "Total num played games": 65068, "Total num trained steps": 129792, "Timestamp in ms": 1699675555184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951625535574427, "Avg loss": 2.45855092164129, "Avg value loss": 2.0131045333109796, "Avg policy loss": 0.4454463333822787, "Total num played games": 65117, "Total num trained steps": 129920, "Timestamp in ms": 1699675612095, "logtype": "training_step"}
{"Avg objective": 24.3125, "Games time in secs": 90.37664332054555, "Avg game time in secs": 1.582585787808057, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.72}, "Total num played games": 65152, "Total num trained steps": 129984, "Timestamp in ms": 1699675640241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955959304555988, "Avg loss": 1.9273535306565464, "Avg value loss": 1.4822622414212674, "Avg policy loss": 0.4450912890024483, "Total num played games": 65167, "Total num trained steps": 130048, "Timestamp in ms": 1699675668273, "logtype": "training_step"}
{"Total num played games": 65167, "Total num trained steps": 130054, "Timestamp in ms": 1699675685118, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.38671875}
{"Ratio train steps to played games": 1.9960439762638575, "Avg loss": 1.0729361269623041, "Avg value loss": 0.6406318300869316, "Avg policy loss": 0.43230429221875966, "Total num played games": 65216, "Total num trained steps": 130176, "Timestamp in ms": 1699675740470, "logtype": "training_step"}
{"Avg objective": 24.03125, "Games time in secs": 142.99705846235156, "Avg game time in secs": 1.5621314105083002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.63, "agent_stopped_0": 0.4}, "Total num played games": 65280, "Total num trained steps": 130273, "Timestamp in ms": 1699675783238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950698942017668, "Avg loss": 2.14420202979818, "Avg value loss": 1.7109789781970903, "Avg policy loss": 0.43322304356843233, "Total num played games": 65313, "Total num trained steps": 130304, "Timestamp in ms": 1699675796928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955631033796912, "Avg loss": 1.3743790425360203, "Avg value loss": 0.9484427841380239, "Avg policy loss": 0.42593626282177866, "Total num played games": 65361, "Total num trained steps": 130432, "Timestamp in ms": 1699675852957, "logtype": "training_step"}
{"Avg objective": 23.921875, "Games time in secs": 88.5226936340332, "Avg game time in secs": 1.5426728918828303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.83, "agent_stopped_0": 0.27}, "Total num played games": 65408, "Total num trained steps": 130475, "Timestamp in ms": 1699675871761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960403002644895, "Avg loss": 2.400374801363796, "Avg value loss": 1.9680668156361207, "Avg policy loss": 0.4323079457972199, "Total num played games": 65409, "Total num trained steps": 130560, "Timestamp in ms": 1699675910376, "logtype": "training_step"}
{"Total num played games": 65460, "Total num trained steps": 130657, "Timestamp in ms": 1699675964331, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8125}
{"Ratio train steps to played games": 1.9949777126457837, "Avg loss": 1.8601502925157547, "Avg value loss": 1.420307454187423, "Avg policy loss": 0.43984286091290414, "Total num played games": 65508, "Total num trained steps": 130688, "Timestamp in ms": 1699675977279, "logtype": "training_step"}
{"Avg objective": 25.4921875, "Games time in secs": 139.37007477134466, "Avg game time in secs": 1.379147257495788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.72, "agent_stopped_0": 0.33}, "Total num played games": 65536, "Total num trained steps": 130765, "Timestamp in ms": 1699676011131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954086457793099, "Avg loss": 2.0733008440583944, "Avg value loss": 1.6200315188616514, "Avg policy loss": 0.4532693042419851, "Total num played games": 65558, "Total num trained steps": 130816, "Timestamp in ms": 1699676033581, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995899765265372, "Avg loss": 1.892122254241258, "Avg value loss": 1.4474236811511219, "Avg policy loss": 0.4446985700633377, "Total num played games": 65606, "Total num trained steps": 130944, "Timestamp in ms": 1699676091907, "logtype": "training_step"}
{"Avg objective": 24.5625, "Games time in secs": 131.8380112312734, "Avg game time in secs": 1.6226209606975317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.78}, "Total num played games": 65664, "Total num trained steps": 131062, "Timestamp in ms": 1699676142969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9948102152010472, "Avg loss": 2.295788229443133, "Avg value loss": 1.8487929429393262, "Avg policy loss": 0.4469953489024192, "Total num played games": 65706, "Total num trained steps": 131072, "Timestamp in ms": 1699676146819, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9953006661191715, "Avg loss": 2.5972999883815646, "Avg value loss": 2.1515650374349207, "Avg policy loss": 0.4457349688746035, "Total num played games": 65754, "Total num trained steps": 131200, "Timestamp in ms": 1699676202207, "logtype": "training_step"}
{"Avg objective": 26.578125, "Games time in secs": 85.45726856030524, "Avg game time in secs": 1.4167811209626961, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 65792, "Total num trained steps": 131257, "Timestamp in ms": 1699676228427, "logtype": "played_game"}
{"Total num played games": 65806, "Total num trained steps": 131260, "Timestamp in ms": 1699676242675, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.71875}
{"Ratio train steps to played games": 1.9942296595499134, "Avg loss": 3.0564979566261172, "Avg value loss": 2.606735640671104, "Avg policy loss": 0.4497623285278678, "Total num played games": 65854, "Total num trained steps": 131328, "Timestamp in ms": 1699676274049, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995642999195397, "Avg loss": 1.1892594923265278, "Avg value loss": 0.7345247977646068, "Avg policy loss": 0.45473469654098153, "Total num played games": 65871, "Total num trained steps": 131456, "Timestamp in ms": 1699676330221, "logtype": "training_step"}
{"Avg objective": 24.15625, "Games time in secs": 143.71988066472113, "Avg game time in secs": 1.5636278429155936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 65920, "Total num trained steps": 131552, "Timestamp in ms": 1699676372147, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951630756167458, "Avg loss": 2.7633929080329835, "Avg value loss": 2.3168456060811877, "Avg policy loss": 0.4465472945012152, "Total num played games": 65951, "Total num trained steps": 131584, "Timestamp in ms": 1699676386100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995621212121212, "Avg loss": 1.6345254676416516, "Avg value loss": 1.1972024361602962, "Avg policy loss": 0.43732302309945226, "Total num played games": 66000, "Total num trained steps": 131712, "Timestamp in ms": 1699676445130, "logtype": "training_step"}
{"Avg objective": 25.1015625, "Games time in secs": 91.49796180799603, "Avg game time in secs": 1.5941871621907922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.83, "agent_stopped_0": 0.21}, "Total num played games": 66048, "Total num trained steps": 131754, "Timestamp in ms": 1699676463645, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996108890503876, "Avg loss": 2.3468210231512785, "Avg value loss": 1.8953427853994071, "Avg policy loss": 0.4514782598707825, "Total num played games": 66048, "Total num trained steps": 131840, "Timestamp in ms": 1699676502378, "logtype": "training_step"}
{"Total num played games": 66096, "Total num trained steps": 131862, "Timestamp in ms": 1699676523801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.921875}
{"Ratio train steps to played games": 1.9951469521044993, "Avg loss": 3.372334240935743, "Avg value loss": 2.911809612531215, "Avg policy loss": 0.46052464842796326, "Total num played games": 66144, "Total num trained steps": 131968, "Timestamp in ms": 1699676570507, "logtype": "training_step"}
{"Avg objective": 24.6484375, "Games time in secs": 137.9361629858613, "Avg game time in secs": 1.5090668894990813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.69}, "Total num played games": 66176, "Total num trained steps": 132037, "Timestamp in ms": 1699676601581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956490210297317, "Avg loss": 1.36196632636711, "Avg value loss": 0.9257550612092018, "Avg policy loss": 0.4362112544476986, "Total num played games": 66192, "Total num trained steps": 132096, "Timestamp in ms": 1699676627766, "logtype": "training_step"}
{"Ratio train steps to played games": 1.996029769183159, "Avg loss": 0.9960615639574826, "Avg value loss": 0.573086513672024, "Avg policy loss": 0.4229750551749021, "Total num played games": 66243, "Total num trained steps": 132224, "Timestamp in ms": 1699676684646, "logtype": "training_step"}
{"Avg objective": 23.390625, "Games time in secs": 128.6444389037788, "Avg game time in secs": 1.5304504149680724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 66304, "Total num trained steps": 132332, "Timestamp in ms": 1699676730226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950106269124674, "Avg loss": 2.3148435661569238, "Avg value loss": 1.8974648141302168, "Avg policy loss": 0.41737873293459415, "Total num played games": 66341, "Total num trained steps": 132352, "Timestamp in ms": 1699676739052, "logtype": "training_step"}
{"Total num played games": 66391, "Total num trained steps": 132464, "Timestamp in ms": 1699676805113, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1953125}
{"Avg objective": 24.7890625, "Games time in secs": 77.9355270024389, "Avg game time in secs": 1.260443254490383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.68}, "Total num played games": 66432, "Total num trained steps": 132471, "Timestamp in ms": 1699676808161, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993994491187405, "Avg loss": 1.7388153923675418, "Avg value loss": 1.3295929328305647, "Avg policy loss": 0.4092224375344813, "Total num played games": 66439, "Total num trained steps": 132480, "Timestamp in ms": 1699676811779, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9959361218561387, "Avg loss": 1.687400421127677, "Avg value loss": 1.2711145277135074, "Avg policy loss": 0.41628592065535486, "Total num played games": 66439, "Total num trained steps": 132608, "Timestamp in ms": 1699676867679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994815148782687, "Avg loss": 1.3905127528123558, "Avg value loss": 0.999151015537791, "Avg policy loss": 0.39136174554005265, "Total num played games": 66540, "Total num trained steps": 132736, "Timestamp in ms": 1699676923547, "logtype": "training_step"}
{"Avg objective": 25.875, "Games time in secs": 157.05631846375763, "Avg game time in secs": 1.3536880214815028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 66560, "Total num trained steps": 132830, "Timestamp in ms": 1699676965218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9951796011532916, "Avg loss": 2.6363995322026312, "Avg value loss": 2.227951457956806, "Avg policy loss": 0.40844807075336576, "Total num played games": 66592, "Total num trained steps": 132864, "Timestamp in ms": 1699676980467, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955135419011178, "Avg loss": 2.102084908634424, "Avg value loss": 1.6918117775348946, "Avg policy loss": 0.4102731170132756, "Total num played games": 66645, "Total num trained steps": 132992, "Timestamp in ms": 1699677039065, "logtype": "training_step"}
{"Avg objective": 24.6171875, "Games time in secs": 99.7830715700984, "Avg game time in secs": 1.6214136794296792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.82, "agent_stopped_0": 0.27}, "Total num played games": 66688, "Total num trained steps": 133040, "Timestamp in ms": 1699677065001, "logtype": "played_game"}
{"Total num played games": 66694, "Total num trained steps": 133067, "Timestamp in ms": 1699677092961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.91796875}
{"Ratio train steps to played games": 1.9945311797668634, "Avg loss": 2.8191472869366407, "Avg value loss": 2.3959948192350566, "Avg policy loss": 0.4231524539645761, "Total num played games": 66742, "Total num trained steps": 133120, "Timestamp in ms": 1699677117028, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9949694574200503, "Avg loss": 1.311320769134909, "Avg value loss": 0.8993585237767547, "Avg policy loss": 0.4119622386060655, "Total num played games": 66792, "Total num trained steps": 133248, "Timestamp in ms": 1699677173805, "logtype": "training_step"}
{"Avg objective": 25.6953125, "Games time in secs": 145.66856160014868, "Avg game time in secs": 1.5231645143649075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.71, "agent_stopped_0": 0.34}, "Total num played games": 66816, "Total num trained steps": 133332, "Timestamp in ms": 1699677210670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954368641532017, "Avg loss": 1.7963295276276767, "Avg value loss": 1.3860579659231007, "Avg policy loss": 0.41027154959738255, "Total num played games": 66840, "Total num trained steps": 133376, "Timestamp in ms": 1699677229205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958290352962282, "Avg loss": 2.4860923998057842, "Avg value loss": 2.0630430025048554, "Avg policy loss": 0.4230493817012757, "Total num played games": 66891, "Total num trained steps": 133504, "Timestamp in ms": 1699677284264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9961907891788537, "Avg loss": 1.706167898606509, "Avg value loss": 1.2894337030593306, "Avg policy loss": 0.41673417412675917, "Total num played games": 66943, "Total num trained steps": 133632, "Timestamp in ms": 1699677341465, "logtype": "training_step"}
{"Avg objective": 24.9765625, "Games time in secs": 130.81381737068295, "Avg game time in secs": 1.6344263395003509, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.75, "agent_stopped_0": 0.31}, "Total num played games": 66944, "Total num trained steps": 133632, "Timestamp in ms": 1699677341484, "logtype": "played_game"}
{"Total num played games": 66992, "Total num trained steps": 133671, "Timestamp in ms": 1699677374057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1171875}
{"Ratio train steps to played games": 1.9952118138424821, "Avg loss": 2.8540648529306054, "Avg value loss": 2.448974670143798, "Avg policy loss": 0.40509020863100886, "Total num played games": 67040, "Total num trained steps": 133760, "Timestamp in ms": 1699677412957, "logtype": "training_step"}
{"Avg objective": 26.765625, "Games time in secs": 101.10128425434232, "Avg game time in secs": 1.3599303067021538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 67072, "Total num trained steps": 133829, "Timestamp in ms": 1699677442585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956178921166774, "Avg loss": 2.0464972648769617, "Avg value loss": 1.6428675067145377, "Avg policy loss": 0.4036297365091741, "Total num played games": 67091, "Total num trained steps": 133888, "Timestamp in ms": 1699677468809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960530235329164, "Avg loss": 2.4661199478432536, "Avg value loss": 2.0559440134093165, "Avg policy loss": 0.41017597867175937, "Total num played games": 67140, "Total num trained steps": 134016, "Timestamp in ms": 1699677524838, "logtype": "training_step"}
{"Avg objective": 24.171875, "Games time in secs": 129.51757591962814, "Avg game time in secs": 1.6405544658191502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.8, "agent_stopped_0": 0.27}, "Total num played games": 67200, "Total num trained steps": 134125, "Timestamp in ms": 1699677572103, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9950474434099765, "Avg loss": 1.6092931148596108, "Avg value loss": 1.2002378756878898, "Avg policy loss": 0.4090552148409188, "Total num played games": 67238, "Total num trained steps": 134144, "Timestamp in ms": 1699677580306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954969013330957, "Avg loss": 2.5356693947687745, "Avg value loss": 2.129754738183692, "Avg policy loss": 0.4059146330691874, "Total num played games": 67287, "Total num trained steps": 134272, "Timestamp in ms": 1699677636113, "logtype": "training_step"}
{"Total num played games": 67287, "Total num trained steps": 134273, "Timestamp in ms": 1699677651930, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0}
{"Avg objective": 25.234375, "Games time in secs": 82.73364621214569, "Avg game time in secs": 1.3379814664513106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.72}, "Total num played games": 67328, "Total num trained steps": 134278, "Timestamp in ms": 1699677654837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959901982624193, "Avg loss": 2.2443508310243487, "Avg value loss": 1.8312503470806405, "Avg policy loss": 0.4131004740484059, "Total num played games": 67335, "Total num trained steps": 134400, "Timestamp in ms": 1699677709404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.994913620523467, "Avg loss": 2.113703112117946, "Avg value loss": 1.7134780093329027, "Avg policy loss": 0.4002250980120152, "Total num played games": 67435, "Total num trained steps": 134528, "Timestamp in ms": 1699677763210, "logtype": "training_step"}
{"Avg objective": 24.9296875, "Games time in secs": 146.8331299778074, "Avg game time in secs": 1.3692293097847141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 67456, "Total num trained steps": 134618, "Timestamp in ms": 1699677801670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953175473431526, "Avg loss": 2.7783744763582945, "Avg value loss": 2.3675710945390165, "Avg policy loss": 0.41080345143564045, "Total num played games": 67486, "Total num trained steps": 134656, "Timestamp in ms": 1699677817987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9957503516695048, "Avg loss": 1.8834031936712563, "Avg value loss": 1.465279548894614, "Avg policy loss": 0.41812363755889237, "Total num played games": 67535, "Total num trained steps": 134784, "Timestamp in ms": 1699677873768, "logtype": "training_step"}
{"Avg objective": 25.9375, "Games time in secs": 88.74688305519521, "Avg game time in secs": 1.5654736518481513, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.77, "agent_stopped_0": 0.28}, "Total num played games": 67584, "Total num trained steps": 134824, "Timestamp in ms": 1699677890417, "logtype": "played_game"}
{"Total num played games": 67585, "Total num trained steps": 134874, "Timestamp in ms": 1699677922560, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3046875}
{"Ratio train steps to played games": 1.9947510830511732, "Avg loss": 2.340813273563981, "Avg value loss": 1.9320943107595667, "Avg policy loss": 0.4087189722340554, "Total num played games": 67633, "Total num trained steps": 134912, "Timestamp in ms": 1699677937913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951981324428947, "Avg loss": 1.3687123120762408, "Avg value loss": 0.9553226071875542, "Avg policy loss": 0.4133896781131625, "Total num played games": 67682, "Total num trained steps": 135040, "Timestamp in ms": 1699677994191, "logtype": "training_step"}
{"Avg objective": 25.234375, "Games time in secs": 137.26781755499542, "Avg game time in secs": 1.4020923536154442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 67712, "Total num trained steps": 135113, "Timestamp in ms": 1699678027685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995629835232977, "Avg loss": 2.7897810665890574, "Avg value loss": 2.3785255316179246, "Avg policy loss": 0.4112554721068591, "Total num played games": 67732, "Total num trained steps": 135168, "Timestamp in ms": 1699678051537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960019473909387, "Avg loss": 2.774451487697661, "Avg value loss": 2.3473994536325336, "Avg policy loss": 0.42705206060782075, "Total num played games": 67783, "Total num trained steps": 135296, "Timestamp in ms": 1699678105374, "logtype": "training_step"}
{"Avg objective": 24.4609375, "Games time in secs": 128.20077662356198, "Avg game time in secs": 1.509058242678293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.76, "agent_stopped_0": 0.29}, "Total num played games": 67840, "Total num trained steps": 135412, "Timestamp in ms": 1699678155886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995005966323419, "Avg loss": 1.5559752047993243, "Avg value loss": 1.1351727922447026, "Avg policy loss": 0.42080240580253303, "Total num played games": 67881, "Total num trained steps": 135424, "Timestamp in ms": 1699678160692, "logtype": "training_step"}
{"Total num played games": 67881, "Total num trained steps": 135477, "Timestamp in ms": 1699678196488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.19140625}
{"Ratio train steps to played games": 1.99548057530657, "Avg loss": 2.8100675884634256, "Avg value loss": 2.394507714547217, "Avg policy loss": 0.41555984085425735, "Total num played games": 67929, "Total num trained steps": 135552, "Timestamp in ms": 1699678231566, "logtype": "training_step"}
{"Avg objective": 24.375, "Games time in secs": 101.52374519594014, "Avg game time in secs": 1.3754159864474786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.81, "agent_stopped_0": 0.27}, "Total num played games": 67968, "Total num trained steps": 135607, "Timestamp in ms": 1699678257410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959251522551413, "Avg loss": 1.595117838587612, "Avg value loss": 1.179827070911415, "Avg policy loss": 0.4152907691895962, "Total num played games": 67978, "Total num trained steps": 135680, "Timestamp in ms": 1699678294300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9949468241377284, "Avg loss": 1.392566526774317, "Avg value loss": 0.9760647970251739, "Avg policy loss": 0.41650174115784466, "Total num played games": 68075, "Total num trained steps": 135808, "Timestamp in ms": 1699678354173, "logtype": "training_step"}
{"Avg objective": 25.1015625, "Games time in secs": 137.6490362584591, "Avg game time in secs": 1.3178740351868328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 68096, "Total num trained steps": 135900, "Timestamp in ms": 1699678395059, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953761467889908, "Avg loss": 2.5570482430048287, "Avg value loss": 2.129857111023739, "Avg policy loss": 0.4271911522373557, "Total num played games": 68125, "Total num trained steps": 135936, "Timestamp in ms": 1699678410545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995702426002523, "Avg loss": 1.9634847547858953, "Avg value loss": 1.537670536665246, "Avg policy loss": 0.42581426724791527, "Total num played games": 68178, "Total num trained steps": 136064, "Timestamp in ms": 1699678465837, "logtype": "training_step"}
{"Total num played games": 68178, "Total num trained steps": 136077, "Timestamp in ms": 1699678483616, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1171875}
{"Avg objective": 25.0859375, "Games time in secs": 92.9893161803484, "Avg game time in secs": 1.4317563927470474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 68224, "Total num trained steps": 136086, "Timestamp in ms": 1699678488048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961891361064696, "Avg loss": 1.5625238162465394, "Avg value loss": 1.155368685373105, "Avg policy loss": 0.4071551291272044, "Total num played games": 68226, "Total num trained steps": 136192, "Timestamp in ms": 1699678534637, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952139103962063, "Avg loss": 2.4788591167889535, "Avg value loss": 2.0655136895366013, "Avg policy loss": 0.4133454477414489, "Total num played games": 68323, "Total num trained steps": 136320, "Timestamp in ms": 1699678587760, "logtype": "training_step"}
{"Avg objective": 27.1796875, "Games time in secs": 131.4173350352794, "Avg game time in secs": 1.3849635136284633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.67, "agent_stopped_0": 0.4}, "Total num played games": 68352, "Total num trained steps": 136395, "Timestamp in ms": 1699678619466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995626928758428, "Avg loss": 2.802768348250538, "Avg value loss": 2.3813962978310883, "Avg policy loss": 0.4213720227126032, "Total num played games": 68373, "Total num trained steps": 136448, "Timestamp in ms": 1699678642549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9959810010960906, "Avg loss": 2.474566390737891, "Avg value loss": 2.04489779449068, "Avg policy loss": 0.42966861510649323, "Total num played games": 68425, "Total num trained steps": 136576, "Timestamp in ms": 1699678701808, "logtype": "training_step"}
{"Total num played games": 68477, "Total num trained steps": 136679, "Timestamp in ms": 1699678757874, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.640625}
{"Avg objective": 26.03125, "Games time in secs": 139.6555903982371, "Avg game time in secs": 1.5976244150369894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.83, "agent_stopped_0": 0.29}, "Total num played games": 68480, "Total num trained steps": 136682, "Timestamp in ms": 1699678759122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99493615468807, "Avg loss": 2.894772213883698, "Avg value loss": 2.460503220325336, "Avg policy loss": 0.43426899309270084, "Total num played games": 68525, "Total num trained steps": 136704, "Timestamp in ms": 1699678768076, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9953772566862076, "Avg loss": 1.8353229397907853, "Avg value loss": 1.4065341020468622, "Avg policy loss": 0.42878884775564075, "Total num played games": 68574, "Total num trained steps": 136832, "Timestamp in ms": 1699678820731, "logtype": "training_step"}
{"Avg objective": 23.1328125, "Games time in secs": 90.35925400070846, "Avg game time in secs": 1.3310737006540876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 68608, "Total num trained steps": 136898, "Timestamp in ms": 1699678849481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9958468129754305, "Avg loss": 1.4284575302153826, "Avg value loss": 1.0166459965985268, "Avg policy loss": 0.41181153478100896, "Total num played games": 68622, "Total num trained steps": 136960, "Timestamp in ms": 1699678876752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962285031963072, "Avg loss": 0.8975391890853643, "Avg value loss": 0.49100906506646425, "Avg policy loss": 0.4065301234368235, "Total num played games": 68673, "Total num trained steps": 137088, "Timestamp in ms": 1699678931974, "logtype": "training_step"}
{"Avg objective": 24.2109375, "Games time in secs": 128.27157379686832, "Avg game time in secs": 1.5421363301720703, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.77, "agent_stopped_0": 0.33}, "Total num played games": 68736, "Total num trained steps": 137195, "Timestamp in ms": 1699678977753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9952160763101263, "Avg loss": 3.117683710064739, "Avg value loss": 2.7135947584174573, "Avg policy loss": 0.4040889104362577, "Total num played games": 68772, "Total num trained steps": 137216, "Timestamp in ms": 1699678986397, "logtype": "training_step"}
{"Total num played games": 68772, "Total num trained steps": 137282, "Timestamp in ms": 1699679025230, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.78125}
{"Ratio train steps to played games": 1.9956843940714908, "Avg loss": 2.3781816684640944, "Avg value loss": 1.9713793704286218, "Avg policy loss": 0.40680229128338397, "Total num played games": 68820, "Total num trained steps": 137344, "Timestamp in ms": 1699679053201, "logtype": "training_step"}
{"Avg objective": 27.046875, "Games time in secs": 96.22430390305817, "Avg game time in secs": 1.429470922666951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 68864, "Total num trained steps": 137390, "Timestamp in ms": 1699679073977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996152059011442, "Avg loss": 2.0113756582140923, "Avg value loss": 1.5997810761909932, "Avg policy loss": 0.4115946067031473, "Total num played games": 68868, "Total num trained steps": 137472, "Timestamp in ms": 1699679110102, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995084748220215, "Avg loss": 3.220488730818033, "Avg value loss": 2.7940874269697815, "Avg policy loss": 0.42640131851658225, "Total num played games": 68969, "Total num trained steps": 137600, "Timestamp in ms": 1699679165452, "logtype": "training_step"}
{"Avg objective": 26.2578125, "Games time in secs": 129.14980972371995, "Avg game time in secs": 1.3180411984649254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 68992, "Total num trained steps": 137686, "Timestamp in ms": 1699679203127, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995493994407337, "Avg loss": 3.1407029535621405, "Avg value loss": 2.696233378490433, "Avg policy loss": 0.444469575304538, "Total num played games": 69019, "Total num trained steps": 137728, "Timestamp in ms": 1699679221771, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958448552938282, "Avg loss": 1.6497771246358752, "Avg value loss": 1.2112546595744789, "Avg policy loss": 0.4385224904399365, "Total num played games": 69071, "Total num trained steps": 137856, "Timestamp in ms": 1699679279901, "logtype": "training_step"}
{"Total num played games": 69071, "Total num trained steps": 137886, "Timestamp in ms": 1699679303417, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.87890625}
{"Avg objective": 23.140625, "Games time in secs": 104.11444116197526, "Avg game time in secs": 1.422218844658346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.7, "agent_stopped_0": 0.33}, "Total num played games": 69120, "Total num trained steps": 137896, "Timestamp in ms": 1699679307242, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961951882875455, "Avg loss": 1.7823513941839337, "Avg value loss": 1.3548360879067332, "Avg policy loss": 0.42751530138775706, "Total num played games": 69123, "Total num trained steps": 137984, "Timestamp in ms": 1699679345109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952470384282, "Avg loss": 2.548309032805264, "Avg value loss": 2.1222281688824296, "Avg policy loss": 0.42608086322434247, "Total num played games": 69220, "Total num trained steps": 138112, "Timestamp in ms": 1699679401688, "logtype": "training_step"}
{"Avg objective": 23.734375, "Games time in secs": 129.36031305603683, "Avg game time in secs": 1.4338361323316349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 69248, "Total num trained steps": 138189, "Timestamp in ms": 1699679436602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995654684567634, "Avg loss": 1.9997933045960963, "Avg value loss": 1.5914476396283135, "Avg policy loss": 0.4083456420339644, "Total num played games": 69270, "Total num trained steps": 138240, "Timestamp in ms": 1699679459077, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960329481686647, "Avg loss": 1.7483427845872939, "Avg value loss": 1.324227359611541, "Avg policy loss": 0.4241153816692531, "Total num played games": 69321, "Total num trained steps": 138368, "Timestamp in ms": 1699679514185, "logtype": "training_step"}
{"Avg objective": 24.3046875, "Games time in secs": 131.918626178056, "Avg game time in secs": 1.5306149542157073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.82, "agent_stopped_0": 0.28}, "Total num played games": 69376, "Total num trained steps": 138489, "Timestamp in ms": 1699679568521, "logtype": "played_game"}
{"Total num played games": 69419, "Total num trained steps": 138489, "Timestamp in ms": 1699679580926, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.28125}
{"Ratio train steps to played games": 1.9938813705729916, "Avg loss": 2.7054745270870626, "Avg value loss": 2.2832478976342827, "Avg policy loss": 0.4222266636788845, "Total num played games": 69460, "Total num trained steps": 138496, "Timestamp in ms": 1699679584123, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955230541120244, "Avg loss": 3.3400449696928263, "Avg value loss": 2.903778802137822, "Avg policy loss": 0.4362661491613835, "Total num played games": 69467, "Total num trained steps": 138624, "Timestamp in ms": 1699679639914, "logtype": "training_step"}
{"Avg objective": 25.5546875, "Games time in secs": 96.81536781229079, "Avg game time in secs": 1.2778158623113995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 69504, "Total num trained steps": 138683, "Timestamp in ms": 1699679665337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959577651188216, "Avg loss": 1.3075546231120825, "Avg value loss": 0.8886447413824499, "Avg policy loss": 0.4189098870847374, "Total num played games": 69516, "Total num trained steps": 138752, "Timestamp in ms": 1699679695743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954452714158453, "Avg loss": 1.5677703325636685, "Avg value loss": 1.1508350861258805, "Avg policy loss": 0.4169352410826832, "Total num played games": 69598, "Total num trained steps": 138880, "Timestamp in ms": 1699679751602, "logtype": "training_step"}
{"Avg objective": 24.5390625, "Games time in secs": 130.28475197032094, "Avg game time in secs": 1.5877536546613555, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.7, "agent_stopped_0": 0.37}, "Total num played games": 69632, "Total num trained steps": 138978, "Timestamp in ms": 1699679795622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953348835874027, "Avg loss": 2.63455296959728, "Avg value loss": 2.2167869322001934, "Avg policy loss": 0.4177660138811916, "Total num played games": 69666, "Total num trained steps": 139008, "Timestamp in ms": 1699679808285, "logtype": "training_step"}
{"Total num played games": 69716, "Total num trained steps": 139092, "Timestamp in ms": 1699679854911, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.59765625}
{"Avg objective": 26.0546875, "Games time in secs": 62.6113795414567, "Avg game time in secs": 1.3794136572250864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.8, "agent_stopped_0": 0.27}, "Total num played games": 69760, "Total num trained steps": 139100, "Timestamp in ms": 1699679858233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9943667220916232, "Avg loss": 3.804203272331506, "Avg value loss": 3.372328807832673, "Avg policy loss": 0.43187446310184896, "Total num played games": 69764, "Total num trained steps": 139136, "Timestamp in ms": 1699679874101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962158133134569, "Avg loss": 1.9783470495603979, "Avg value loss": 1.533158931415528, "Avg policy loss": 0.4451881234999746, "Total num played games": 69764, "Total num trained steps": 139264, "Timestamp in ms": 1699679936567, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9951192282369106, "Avg loss": 1.8314865324646235, "Avg value loss": 1.3941318033030257, "Avg policy loss": 0.43735472299158573, "Total num played games": 69866, "Total num trained steps": 139392, "Timestamp in ms": 1699679995753, "logtype": "training_step"}
{"Avg objective": 24.8515625, "Games time in secs": 177.6594143193215, "Avg game time in secs": 1.2809266797121381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 69888, "Total num trained steps": 139479, "Timestamp in ms": 1699680035893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955231992676927, "Avg loss": 2.022588151972741, "Avg value loss": 1.575654050684534, "Avg policy loss": 0.44693416031077504, "Total num played games": 69916, "Total num trained steps": 139520, "Timestamp in ms": 1699680052821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9959694132780677, "Avg loss": 1.3870266140438616, "Avg value loss": 0.9582747147651389, "Avg policy loss": 0.42875192360952497, "Total num played games": 69965, "Total num trained steps": 139648, "Timestamp in ms": 1699680110285, "logtype": "training_step"}
{"Total num played games": 70015, "Total num trained steps": 139693, "Timestamp in ms": 1699680140105, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.66796875}
{"Avg objective": 24.671875, "Games time in secs": 105.23195636831224, "Avg game time in secs": 1.6494095088128233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.81}, "Total num played games": 70016, "Total num trained steps": 139694, "Timestamp in ms": 1699680141125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994990223084938, "Avg loss": 2.2307089772075415, "Avg value loss": 1.7725118377711624, "Avg policy loss": 0.4581971908919513, "Total num played games": 70063, "Total num trained steps": 139776, "Timestamp in ms": 1699680179538, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954500720286403, "Avg loss": 1.7370198504067957, "Avg value loss": 1.300036377971992, "Avg policy loss": 0.4369834647513926, "Total num played games": 70111, "Total num trained steps": 139904, "Timestamp in ms": 1699680236837, "logtype": "training_step"}
{"Avg objective": 25.3046875, "Games time in secs": 126.27631372772157, "Avg game time in secs": 1.3687533112388337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 70144, "Total num trained steps": 139972, "Timestamp in ms": 1699680267402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9958523966306068, "Avg loss": 2.4493054910562932, "Avg value loss": 1.9944730871357024, "Avg policy loss": 0.4548324344214052, "Total num played games": 70161, "Total num trained steps": 140032, "Timestamp in ms": 1699680295253, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9963252574456267, "Avg loss": 1.8262923215515912, "Avg value loss": 1.3691315851174295, "Avg policy loss": 0.4571607247926295, "Total num played games": 70209, "Total num trained steps": 140160, "Timestamp in ms": 1699680350467, "logtype": "training_step"}
{"Avg objective": 24.046875, "Games time in secs": 127.63859857060015, "Avg game time in secs": 1.4488174579601036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 70272, "Total num trained steps": 140261, "Timestamp in ms": 1699680395040, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954057321669867, "Avg loss": 2.391691679134965, "Avg value loss": 1.9243745692074299, "Avg policy loss": 0.46731713716872036, "Total num played games": 70305, "Total num trained steps": 140288, "Timestamp in ms": 1699680407642, "logtype": "training_step"}
{"Total num played games": 70305, "Total num trained steps": 140296, "Timestamp in ms": 1699680422271, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6953125}
{"Ratio train steps to played games": 1.9958637158330135, "Avg loss": 1.7927065752446651, "Avg value loss": 1.3149738411884755, "Avg policy loss": 0.47773274313658476, "Total num played games": 70353, "Total num trained steps": 140416, "Timestamp in ms": 1699680478468, "logtype": "training_step"}
{"Avg objective": 23.3203125, "Games time in secs": 100.67018944956362, "Avg game time in secs": 1.2779567929101177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.71}, "Total num played games": 70400, "Total num trained steps": 140456, "Timestamp in ms": 1699680495711, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996207655706271, "Avg loss": 1.5023608207702637, "Avg value loss": 1.0433608185267076, "Avg policy loss": 0.45900000538676977, "Total num played games": 70405, "Total num trained steps": 140544, "Timestamp in ms": 1699680535267, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952201293543628, "Avg loss": 2.4925310402177274, "Avg value loss": 2.0498298030579463, "Avg policy loss": 0.4427012682426721, "Total num played games": 70504, "Total num trained steps": 140672, "Timestamp in ms": 1699680591059, "logtype": "training_step"}
{"Avg objective": 24.546875, "Games time in secs": 133.60202054865658, "Avg game time in secs": 1.2541046687256312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 70528, "Total num trained steps": 140756, "Timestamp in ms": 1699680629313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995634549423137, "Avg loss": 1.7349052308127284, "Avg value loss": 1.2949042981490493, "Avg policy loss": 0.44000095361843705, "Total num played games": 70554, "Total num trained steps": 140800, "Timestamp in ms": 1699680648928, "logtype": "training_step"}
{"Total num played games": 70604, "Total num trained steps": 140896, "Timestamp in ms": 1699680701040, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.66796875}
{"Ratio train steps to played games": 1.9946781407461927, "Avg loss": 2.9826941597275436, "Avg value loss": 2.5231733419932425, "Avg policy loss": 0.45952080632559955, "Total num played games": 70652, "Total num trained steps": 140928, "Timestamp in ms": 1699680715040, "logtype": "training_step"}
{"Avg objective": 25.078125, "Games time in secs": 139.2816501520574, "Avg game time in secs": 1.3764412359305425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.78, "agent_stopped_0": 0.29}, "Total num played games": 70656, "Total num trained steps": 141050, "Timestamp in ms": 1699680768595, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995148446229791, "Avg loss": 1.3423485029488802, "Avg value loss": 0.8746571999508888, "Avg policy loss": 0.4676913090515882, "Total num played games": 70699, "Total num trained steps": 141056, "Timestamp in ms": 1699680770996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955194346289753, "Avg loss": 1.6532873180694878, "Avg value loss": 1.2082873489707708, "Avg policy loss": 0.44499999354593456, "Total num played games": 70750, "Total num trained steps": 141184, "Timestamp in ms": 1699680828307, "logtype": "training_step"}
{"Avg objective": 24.4140625, "Games time in secs": 87.97787266410887, "Avg game time in secs": 1.3711853100539884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.73}, "Total num played games": 70784, "Total num trained steps": 141249, "Timestamp in ms": 1699680856573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959180790960451, "Avg loss": 1.4114334853366017, "Avg value loss": 0.963918108958751, "Avg policy loss": 0.4475153477396816, "Total num played games": 70800, "Total num trained steps": 141312, "Timestamp in ms": 1699680884412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9963443379581929, "Avg loss": 2.1679017897695303, "Avg value loss": 1.7218728275038302, "Avg policy loss": 0.446028939448297, "Total num played games": 70849, "Total num trained steps": 141440, "Timestamp in ms": 1699680939365, "logtype": "training_step"}
{"Total num played games": 70899, "Total num trained steps": 141497, "Timestamp in ms": 1699680977273, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.65625}
{"Avg objective": 24.9140625, "Games time in secs": 122.30507912673056, "Avg game time in secs": 1.6473405331053073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.74, "agent_stopped_0": 0.32}, "Total num played games": 70912, "Total num trained steps": 141501, "Timestamp in ms": 1699680978878, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953909256205336, "Avg loss": 2.211980888620019, "Avg value loss": 1.7681390261277556, "Avg policy loss": 0.44384184922091663, "Total num played games": 70947, "Total num trained steps": 141568, "Timestamp in ms": 1699681008485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958166657276466, "Avg loss": 1.3481219885870814, "Avg value loss": 0.9084593306761235, "Avg policy loss": 0.4396626583766192, "Total num played games": 70996, "Total num trained steps": 141696, "Timestamp in ms": 1699681066437, "logtype": "training_step"}
{"Avg objective": 23.3359375, "Games time in secs": 108.29782428219914, "Avg game time in secs": 1.3874603432195727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.73}, "Total num played games": 71040, "Total num trained steps": 141743, "Timestamp in ms": 1699681087176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9962418185656978, "Avg loss": 1.617116617038846, "Avg value loss": 1.1780902277678251, "Avg policy loss": 0.43902637204155326, "Total num played games": 71045, "Total num trained steps": 141824, "Timestamp in ms": 1699681122772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9953332771077563, "Avg loss": 1.9780547665432096, "Avg value loss": 1.5311148058390245, "Avg policy loss": 0.446939954534173, "Total num played games": 71142, "Total num trained steps": 141952, "Timestamp in ms": 1699681181314, "logtype": "training_step"}
{"Avg objective": 25.3359375, "Games time in secs": 129.99663697183132, "Avg game time in secs": 1.264698476283229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.67, "agent_stopped_0": 0.39}, "Total num played games": 71168, "Total num trained steps": 142032, "Timestamp in ms": 1699681217173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995743844025228, "Avg loss": 1.8556004650890827, "Avg value loss": 1.4096777692902833, "Avg policy loss": 0.44592267903499305, "Total num played games": 71191, "Total num trained steps": 142080, "Timestamp in ms": 1699681238300, "logtype": "training_step"}
{"Total num played games": 71191, "Total num trained steps": 142097, "Timestamp in ms": 1699681257449, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.41015625}
{"Ratio train steps to played games": 1.9961959039290276, "Avg loss": 1.7681351038627326, "Avg value loss": 1.3395287743769586, "Avg policy loss": 0.42860631947405636, "Total num played games": 71239, "Total num trained steps": 142208, "Timestamp in ms": 1699681305954, "logtype": "training_step"}
{"Avg objective": 24.1875, "Games time in secs": 140.79597598686814, "Avg game time in secs": 1.546295013424242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 71296, "Total num trained steps": 142322, "Timestamp in ms": 1699681357969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995219938882503, "Avg loss": 1.926455324050039, "Avg value loss": 1.5014161403523758, "Avg policy loss": 0.4250391854438931, "Total num played games": 71338, "Total num trained steps": 142336, "Timestamp in ms": 1699681364388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956434644963368, "Avg loss": 2.2710532541386783, "Avg value loss": 1.8472203146666288, "Avg policy loss": 0.4238329220097512, "Total num played games": 71387, "Total num trained steps": 142464, "Timestamp in ms": 1699681420278, "logtype": "training_step"}
{"Avg objective": 26.890625, "Games time in secs": 87.2555623035878, "Avg game time in secs": 1.3527253009960987, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 71424, "Total num trained steps": 142523, "Timestamp in ms": 1699681445225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960105266104875, "Avg loss": 3.305958260782063, "Avg value loss": 2.8782617684919387, "Avg policy loss": 0.4276964270975441, "Total num played games": 71438, "Total num trained steps": 142592, "Timestamp in ms": 1699681476236, "logtype": "training_step"}
{"Total num played games": 71489, "Total num trained steps": 142697, "Timestamp in ms": 1699681537046, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6328125}
{"Ratio train steps to played games": 1.9950375330248682, "Avg loss": 1.8355258395895362, "Avg value loss": 1.4160976863931865, "Avg policy loss": 0.4194281587842852, "Total num played games": 71537, "Total num trained steps": 142720, "Timestamp in ms": 1699681547345, "logtype": "training_step"}
{"Avg objective": 23.5078125, "Games time in secs": 147.79275227338076, "Avg game time in secs": 1.4408979817235377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 71552, "Total num trained steps": 142821, "Timestamp in ms": 1699681593018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954461005489823, "Avg loss": 1.7947501419112086, "Avg value loss": 1.3836421348387375, "Avg policy loss": 0.41110798227600753, "Total num played games": 71587, "Total num trained steps": 142848, "Timestamp in ms": 1699681604469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958819013052278, "Avg loss": 1.4868525597266853, "Avg value loss": 1.0689854777883738, "Avg policy loss": 0.4178670784458518, "Total num played games": 71635, "Total num trained steps": 142976, "Timestamp in ms": 1699681661604, "logtype": "training_step"}
{"Avg objective": 22.921875, "Games time in secs": 89.63416152261198, "Avg game time in secs": 1.4956054393405793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.79}, "Total num played games": 71680, "Total num trained steps": 143022, "Timestamp in ms": 1699681682652, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9963032196864015, "Avg loss": 0.9769341787323356, "Avg value loss": 0.5636339703341946, "Avg policy loss": 0.41330020199529827, "Total num played games": 71684, "Total num trained steps": 143104, "Timestamp in ms": 1699681720653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9952497701501686, "Avg loss": 2.4043669481761754, "Avg value loss": 1.9954834858654067, "Avg policy loss": 0.40888345474377275, "Total num played games": 71786, "Total num trained steps": 143232, "Timestamp in ms": 1699681776204, "logtype": "training_step"}
{"Total num played games": 71786, "Total num trained steps": 143300, "Timestamp in ms": 1699681818681, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.76953125}
{"Avg objective": 24.3046875, "Games time in secs": 138.27305133268237, "Avg game time in secs": 1.461584678690997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.77, "agent_stopped_0": 0.33}, "Total num played games": 71808, "Total num trained steps": 143306, "Timestamp in ms": 1699681820925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956984157919648, "Avg loss": 2.2724164142273366, "Avg value loss": 1.8582611415768042, "Avg policy loss": 0.4141552534420043, "Total num played games": 71834, "Total num trained steps": 143360, "Timestamp in ms": 1699681845368, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9961464622575888, "Avg loss": 1.481771252118051, "Avg value loss": 1.0663762000622228, "Avg policy loss": 0.4153950586915016, "Total num played games": 71882, "Total num trained steps": 143488, "Timestamp in ms": 1699681903377, "logtype": "training_step"}
{"Avg objective": 23.6796875, "Games time in secs": 133.25964500382543, "Avg game time in secs": 1.512039568828186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.8, "agent_stopped_0": 0.3}, "Total num played games": 71936, "Total num trained steps": 143606, "Timestamp in ms": 1699681954185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995234721238139, "Avg loss": 1.2584711804520339, "Avg value loss": 0.8582391479285434, "Avg policy loss": 0.40023202961310744, "Total num played games": 71979, "Total num trained steps": 143616, "Timestamp in ms": 1699681958216, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955713512237787, "Avg loss": 2.414657248184085, "Avg value loss": 2.0011009972076863, "Avg policy loss": 0.413556220009923, "Total num played games": 72031, "Total num trained steps": 143744, "Timestamp in ms": 1699682016564, "logtype": "training_step"}
{"Avg objective": 25.1640625, "Games time in secs": 91.71382253244519, "Avg game time in secs": 1.293650603853166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 72064, "Total num trained steps": 143810, "Timestamp in ms": 1699682045899, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995990566037736, "Avg loss": 1.9913750062696636, "Avg value loss": 1.5684258647961542, "Avg policy loss": 0.4229491618461907, "Total num played games": 72080, "Total num trained steps": 143872, "Timestamp in ms": 1699682072938, "logtype": "training_step"}
{"Total num played games": 72080, "Total num trained steps": 143901, "Timestamp in ms": 1699682095539, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.00390625}
{"Ratio train steps to played games": 1.9964368899733806, "Avg loss": 2.052472960203886, "Avg value loss": 1.6416904835496098, "Avg policy loss": 0.4107824731618166, "Total num played games": 72128, "Total num trained steps": 144000, "Timestamp in ms": 1699682138083, "logtype": "training_step"}
{"Avg objective": 27.6796875, "Games time in secs": 136.02567459456623, "Avg game time in secs": 1.3049405823112465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.65, "agent_stopped_0": 0.39}, "Total num played games": 72192, "Total num trained steps": 144100, "Timestamp in ms": 1699682181925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955140808019274, "Avg loss": 2.6940992400050163, "Avg value loss": 2.2813752403017133, "Avg policy loss": 0.4127240041270852, "Total num played games": 72226, "Total num trained steps": 144128, "Timestamp in ms": 1699682194243, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995945983341174, "Avg loss": 2.9145837132818997, "Avg value loss": 2.499820125522092, "Avg policy loss": 0.4147636105772108, "Total num played games": 72274, "Total num trained steps": 144256, "Timestamp in ms": 1699682253657, "logtype": "training_step"}
{"Avg objective": 24.984375, "Games time in secs": 90.99186461791396, "Avg game time in secs": 1.4392081671248889, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.79}, "Total num played games": 72320, "Total num trained steps": 144300, "Timestamp in ms": 1699682272917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996363535804654, "Avg loss": 1.5043264632113278, "Avg value loss": 1.0914096304913983, "Avg policy loss": 0.4129168586805463, "Total num played games": 72323, "Total num trained steps": 144384, "Timestamp in ms": 1699682309333, "logtype": "training_step"}
{"Total num played games": 72424, "Total num trained steps": 144505, "Timestamp in ms": 1699682371386, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.83203125}
{"Avg objective": 24.6328125, "Games time in secs": 100.35398282110691, "Avg game time in secs": 1.3182847899297485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 72448, "Total num trained steps": 144509, "Timestamp in ms": 1699682373271, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994107825415005, "Avg loss": 1.351872538216412, "Avg value loss": 0.943525783601217, "Avg policy loss": 0.40834674541838467, "Total num played games": 72467, "Total num trained steps": 144512, "Timestamp in ms": 1699682374333, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9957914780880892, "Avg loss": 2.3170846574939787, "Avg value loss": 1.8954189792275429, "Avg policy loss": 0.4216657185461372, "Total num played games": 72472, "Total num trained steps": 144640, "Timestamp in ms": 1699682433118, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962079949256077, "Avg loss": 1.0912111797370017, "Avg value loss": 0.6954111494123936, "Avg policy loss": 0.3958000373095274, "Total num played games": 72521, "Total num trained steps": 144768, "Timestamp in ms": 1699682489050, "logtype": "training_step"}
{"Avg objective": 24.7890625, "Games time in secs": 164.21871464326978, "Avg game time in secs": 1.3315827822952997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.74, "agent_stopped_0": 0.33}, "Total num played games": 72576, "Total num trained steps": 144884, "Timestamp in ms": 1699682537490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995194293740189, "Avg loss": 2.8657950162887573, "Avg value loss": 2.4615554615156725, "Avg policy loss": 0.40423956443555653, "Total num played games": 72622, "Total num trained steps": 144896, "Timestamp in ms": 1699682542447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9955279742411316, "Avg loss": 2.2238337700255215, "Avg value loss": 1.8146039366256446, "Avg policy loss": 0.4092298489995301, "Total num played games": 72674, "Total num trained steps": 145024, "Timestamp in ms": 1699682598523, "logtype": "training_step"}
{"Avg objective": 25.9375, "Games time in secs": 93.62734875455499, "Avg game time in secs": 1.4422269209317164, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.71}, "Total num played games": 72704, "Total num trained steps": 145097, "Timestamp in ms": 1699682631117, "logtype": "played_game"}
{"Total num played games": 72723, "Total num trained steps": 145109, "Timestamp in ms": 1699682647349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.17578125}
{"Ratio train steps to played games": 1.9946269805279575, "Avg loss": 3.201699369121343, "Avg value loss": 2.7817922797985375, "Avg policy loss": 0.41990710562095046, "Total num played games": 72771, "Total num trained steps": 145152, "Timestamp in ms": 1699682666693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.996385922963818, "Avg loss": 1.1160720270127058, "Avg value loss": 0.6962366106454283, "Avg policy loss": 0.4198354196269065, "Total num played games": 72771, "Total num trained steps": 145280, "Timestamp in ms": 1699682723095, "logtype": "training_step"}
{"Avg objective": 23.609375, "Games time in secs": 138.71124813705683, "Avg game time in secs": 1.3660279613977764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 72832, "Total num trained steps": 145386, "Timestamp in ms": 1699682769829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954849865510238, "Avg loss": 1.4657518761232495, "Avg value loss": 1.0591070951195434, "Avg policy loss": 0.4066447666846216, "Total num played games": 72868, "Total num trained steps": 145408, "Timestamp in ms": 1699682779201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958720754820483, "Avg loss": 2.0547583615407348, "Avg value loss": 1.641245377017185, "Avg policy loss": 0.41351298592053354, "Total num played games": 72918, "Total num trained steps": 145536, "Timestamp in ms": 1699682834433, "logtype": "training_step"}
{"Avg objective": 25.171875, "Games time in secs": 86.25628380477428, "Avg game time in secs": 1.1878453855606494, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 72960, "Total num trained steps": 145584, "Timestamp in ms": 1699682856085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996299697123357, "Avg loss": 1.9446253129281104, "Avg value loss": 1.5258537494810298, "Avg policy loss": 0.4187715444713831, "Total num played games": 72967, "Total num trained steps": 145664, "Timestamp in ms": 1699682891485, "logtype": "training_step"}
{"Total num played games": 73017, "Total num trained steps": 145713, "Timestamp in ms": 1699682926378, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.671875}
{"Ratio train steps to played games": 1.9953602956271812, "Avg loss": 2.6108280611224473, "Avg value loss": 2.186634939862415, "Avg policy loss": 0.4241931028664112, "Total num played games": 73065, "Total num trained steps": 145792, "Timestamp in ms": 1699682962501, "logtype": "training_step"}
{"Avg objective": 24.421875, "Games time in secs": 143.2076076362282, "Avg game time in secs": 1.2211994687531842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 73088, "Total num trained steps": 145878, "Timestamp in ms": 1699682999293, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957191312435034, "Avg loss": 1.5881530961487442, "Avg value loss": 1.185270099900663, "Avg policy loss": 0.4028829967137426, "Total num played games": 73116, "Total num trained steps": 145920, "Timestamp in ms": 1699683017150, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960911339811664, "Avg loss": 1.7783554084599018, "Avg value loss": 1.3626788849942386, "Avg policy loss": 0.4156765134539455, "Total num played games": 73167, "Total num trained steps": 146048, "Timestamp in ms": 1699683074953, "logtype": "training_step"}
{"Avg objective": 24.140625, "Games time in secs": 133.0613769069314, "Avg game time in secs": 1.4780156299530063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 73216, "Total num trained steps": 146174, "Timestamp in ms": 1699683132355, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959991260889751, "Avg loss": 1.4148768289014697, "Avg value loss": 1.0162452931981534, "Avg policy loss": 0.3986315494403243, "Total num played games": 73233, "Total num trained steps": 146176, "Timestamp in ms": 1699683133083, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954989975039896, "Avg loss": 2.309315273538232, "Avg value loss": 1.8907813313417137, "Avg policy loss": 0.4185339182149619, "Total num played games": 73317, "Total num trained steps": 146304, "Timestamp in ms": 1699683199217, "logtype": "training_step"}
{"Total num played games": 73317, "Total num trained steps": 146313, "Timestamp in ms": 1699683213713, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.86328125}
{"Avg objective": 24.4453125, "Games time in secs": 83.46253080107272, "Avg game time in secs": 1.2238538339152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.58}, "Total num played games": 73344, "Total num trained steps": 146319, "Timestamp in ms": 1699683215817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995938117631023, "Avg loss": 1.7110788831487298, "Avg value loss": 1.3000660159159452, "Avg policy loss": 0.41101286723278463, "Total num played games": 73365, "Total num trained steps": 146432, "Timestamp in ms": 1699683267137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9963358487481953, "Avg loss": 1.668368823826313, "Avg value loss": 1.262520634336397, "Avg policy loss": 0.40584818040952086, "Total num played games": 73414, "Total num trained steps": 146560, "Timestamp in ms": 1699683322409, "logtype": "training_step"}
{"Avg objective": 24.8828125, "Games time in secs": 153.4114372767508, "Avg game time in secs": 1.4096561314654537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 73472, "Total num trained steps": 146671, "Timestamp in ms": 1699683369229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954293176624225, "Avg loss": 2.179218197707087, "Avg value loss": 1.755397332366556, "Avg policy loss": 0.42382087046280503, "Total num played games": 73512, "Total num trained steps": 146688, "Timestamp in ms": 1699683375917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995826592895692, "Avg loss": 1.858692055568099, "Avg value loss": 1.4363953397842124, "Avg policy loss": 0.422296701464802, "Total num played games": 73561, "Total num trained steps": 146816, "Timestamp in ms": 1699683431560, "logtype": "training_step"}
{"Avg objective": 24.703125, "Games time in secs": 85.15209333598614, "Avg game time in secs": 1.2901262868836056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 73600, "Total num trained steps": 146871, "Timestamp in ms": 1699683454381, "logtype": "played_game"}
{"Total num played games": 73615, "Total num trained steps": 146913, "Timestamp in ms": 1699683482609, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.89453125}
{"Ratio train steps to played games": 1.9948142215223381, "Avg loss": 2.346924223471433, "Avg value loss": 1.922579844482243, "Avg policy loss": 0.424344380851835, "Total num played games": 73663, "Total num trained steps": 146944, "Timestamp in ms": 1699683495812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965518645724447, "Avg loss": 0.979874330572784, "Avg value loss": 0.5660423808731139, "Avg policy loss": 0.4138319483026862, "Total num played games": 73663, "Total num trained steps": 147072, "Timestamp in ms": 1699683552079, "logtype": "training_step"}
{"Avg objective": 23.3125, "Games time in secs": 140.31982855126262, "Avg game time in secs": 1.3022209600894712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 73728, "Total num trained steps": 147171, "Timestamp in ms": 1699683594701, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955939372576665, "Avg loss": 1.330671951873228, "Avg value loss": 0.9194201127393171, "Avg policy loss": 0.4112518480978906, "Total num played games": 73762, "Total num trained steps": 147200, "Timestamp in ms": 1699683607110, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995962770785634, "Avg loss": 1.1066601425409317, "Avg value loss": 0.7079375999746844, "Avg policy loss": 0.39872253802604973, "Total num played games": 73813, "Total num trained steps": 147328, "Timestamp in ms": 1699683661645, "logtype": "training_step"}
{"Avg objective": 23.5234375, "Games time in secs": 87.74749664776027, "Avg game time in secs": 1.350058374897344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 73856, "Total num trained steps": 147377, "Timestamp in ms": 1699683682449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9963310453136212, "Avg loss": 1.2990098954178393, "Avg value loss": 0.8997550052590668, "Avg policy loss": 0.3992548913229257, "Total num played games": 73863, "Total num trained steps": 147456, "Timestamp in ms": 1699683718267, "logtype": "training_step"}
{"Total num played games": 73916, "Total num trained steps": 147515, "Timestamp in ms": 1699683756889, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.47265625}
{"Ratio train steps to played games": 1.9953490887458765, "Avg loss": 1.8217778247781098, "Avg value loss": 1.4191235856851563, "Avg policy loss": 0.40265425364486873, "Total num played games": 73964, "Total num trained steps": 147584, "Timestamp in ms": 1699683787993, "logtype": "training_step"}
{"Avg objective": 22.1875, "Games time in secs": 145.43885157257318, "Avg game time in secs": 1.3533196260978002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 73984, "Total num trained steps": 147675, "Timestamp in ms": 1699683827888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957709560611792, "Avg loss": 0.9342619813978672, "Avg value loss": 0.5558986511314288, "Avg policy loss": 0.37836333410814404, "Total num played games": 74012, "Total num trained steps": 147712, "Timestamp in ms": 1699683843166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962057790980285, "Avg loss": 1.3867226713337004, "Avg value loss": 1.0002217908622697, "Avg policy loss": 0.38650087732821703, "Total num played games": 74060, "Total num trained steps": 147840, "Timestamp in ms": 1699683897675, "logtype": "training_step"}
{"Avg objective": 25.1953125, "Games time in secs": 121.34101746790111, "Avg game time in secs": 1.4613214453856926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.8, "agent_stopped_0": 0.28}, "Total num played games": 74112, "Total num trained steps": 147962, "Timestamp in ms": 1699683949229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9953476455040724, "Avg loss": 1.572912897914648, "Avg value loss": 1.1879262268776074, "Avg policy loss": 0.3849866536911577, "Total num played games": 74156, "Total num trained steps": 147968, "Timestamp in ms": 1699683951576, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995674320827943, "Avg loss": 2.210397230926901, "Avg value loss": 1.8268631951650605, "Avg policy loss": 0.3835340596269816, "Total num played games": 74208, "Total num trained steps": 148096, "Timestamp in ms": 1699684002141, "logtype": "training_step"}
{"Total num played games": 74208, "Total num trained steps": 148115, "Timestamp in ms": 1699684022762, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.54296875}
{"Avg objective": 23.1953125, "Games time in secs": 75.9555167350918, "Avg game time in secs": 1.2045010832953267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 74240, "Total num trained steps": 148119, "Timestamp in ms": 1699684025185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961080586080586, "Avg loss": 1.1534287151880562, "Avg value loss": 0.753105869749561, "Avg policy loss": 0.4003228300716728, "Total num played games": 74256, "Total num trained steps": 148224, "Timestamp in ms": 1699684067315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965278245070992, "Avg loss": 2.4224108301568776, "Avg value loss": 2.020008228661027, "Avg policy loss": 0.40240264334715903, "Total num played games": 74305, "Total num trained steps": 148352, "Timestamp in ms": 1699684119931, "logtype": "training_step"}
{"Avg objective": 27.078125, "Games time in secs": 140.0640531256795, "Avg game time in secs": 1.4037478363170521, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 74368, "Total num trained steps": 148462, "Timestamp in ms": 1699684165249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955379942477758, "Avg loss": 2.311404613312334, "Avg value loss": 1.9161620184313506, "Avg policy loss": 0.3952426314353943, "Total num played games": 74406, "Total num trained steps": 148480, "Timestamp in ms": 1699684172189, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958500094012732, "Avg loss": 1.9024633476510644, "Avg value loss": 1.4993712287396193, "Avg policy loss": 0.40309212426654994, "Total num played games": 74458, "Total num trained steps": 148608, "Timestamp in ms": 1699684223609, "logtype": "training_step"}
{"Avg objective": 24.6640625, "Games time in secs": 81.29645913280547, "Avg game time in secs": 1.433613246990717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.71}, "Total num played games": 74496, "Total num trained steps": 148666, "Timestamp in ms": 1699684246545, "logtype": "played_game"}
{"Total num played games": 74507, "Total num trained steps": 148716, "Timestamp in ms": 1699684277154, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5390625}
{"Ratio train steps to played games": 1.994970156260479, "Avg loss": 2.049923587590456, "Avg value loss": 1.6361923645017669, "Avg policy loss": 0.41373124648816884, "Total num played games": 74555, "Total num trained steps": 148736, "Timestamp in ms": 1699684285473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954157339517178, "Avg loss": 1.5468126526102424, "Avg value loss": 1.1365144328447059, "Avg policy loss": 0.41029821638949215, "Total num played games": 74603, "Total num trained steps": 148864, "Timestamp in ms": 1699684338167, "logtype": "training_step"}
{"Avg objective": 25.390625, "Games time in secs": 128.17174282483757, "Avg game time in secs": 1.1774740886612562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 74624, "Total num trained steps": 148953, "Timestamp in ms": 1699684374717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9958339473014428, "Avg loss": 3.2707772911526263, "Avg value loss": 2.840619899565354, "Avg policy loss": 0.43015736574307084, "Total num played games": 74651, "Total num trained steps": 148992, "Timestamp in ms": 1699684391197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962382864792503, "Avg loss": 0.8643691609613597, "Avg value loss": 0.45084535237401724, "Avg policy loss": 0.41352381254546344, "Total num played games": 74700, "Total num trained steps": 149120, "Timestamp in ms": 1699684442756, "logtype": "training_step"}
{"Avg objective": 24.421875, "Games time in secs": 117.90968648530543, "Avg game time in secs": 1.4220914564357372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.73}, "Total num played games": 74752, "Total num trained steps": 149246, "Timestamp in ms": 1699684492627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960946903838437, "Avg loss": 1.9103740812279284, "Avg value loss": 1.5090639758855104, "Avg policy loss": 0.40131015377119184, "Total num played games": 74765, "Total num trained steps": 149248, "Timestamp in ms": 1699684493209, "logtype": "training_step"}
{"Total num played games": 74801, "Total num trained steps": 149320, "Timestamp in ms": 1699684535042, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.14453125}
{"Ratio train steps to played games": 1.9956980053173723, "Avg loss": 2.9985348423942924, "Avg value loss": 2.59949596459046, "Avg policy loss": 0.3990389166865498, "Total num played games": 74849, "Total num trained steps": 149376, "Timestamp in ms": 1699684558100, "logtype": "training_step"}
{"Avg objective": 25.109375, "Games time in secs": 93.39579155482352, "Avg game time in secs": 1.360793327272404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 74880, "Total num trained steps": 149447, "Timestamp in ms": 1699684586023, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960347129506009, "Avg loss": 1.6733163464814425, "Avg value loss": 1.2661944841966033, "Avg policy loss": 0.40712185157462955, "Total num played games": 74900, "Total num trained steps": 149504, "Timestamp in ms": 1699684608663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9964509199589053, "Avg loss": 1.6604593419469893, "Avg value loss": 1.2480960946995765, "Avg policy loss": 0.41236324794590473, "Total num played games": 74949, "Total num trained steps": 149632, "Timestamp in ms": 1699684662555, "logtype": "training_step"}
{"Avg objective": 23.703125, "Games time in secs": 121.82212424091995, "Avg game time in secs": 1.3694964783935575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.67, "agent_stopped_0": 0.39}, "Total num played games": 75008, "Total num trained steps": 149742, "Timestamp in ms": 1699684707845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995429774420061, "Avg loss": 2.0224101387429982, "Avg value loss": 1.626677580876276, "Avg policy loss": 0.3957325585652143, "Total num played games": 75051, "Total num trained steps": 149760, "Timestamp in ms": 1699684714583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958721154742407, "Avg loss": 1.2155920939985663, "Avg value loss": 0.8230733033269644, "Avg policy loss": 0.39251878461800516, "Total num played games": 75099, "Total num trained steps": 149888, "Timestamp in ms": 1699684766425, "logtype": "training_step"}
{"Total num played games": 75099, "Total num trained steps": 149922, "Timestamp in ms": 1699684789934, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.41796875}
{"Avg objective": 24.3359375, "Games time in secs": 84.86036950722337, "Avg game time in secs": 1.1859390648896806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 75136, "Total num trained steps": 149928, "Timestamp in ms": 1699684792706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996287276937203, "Avg loss": 1.7871839604340494, "Avg value loss": 1.3904843027703464, "Avg policy loss": 0.3966996385715902, "Total num played games": 75147, "Total num trained steps": 150016, "Timestamp in ms": 1699684829151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965426451424164, "Avg loss": 0.8933397368527949, "Avg value loss": 0.5154848790261894, "Avg policy loss": 0.37785484874621034, "Total num played games": 75201, "Total num trained steps": 150144, "Timestamp in ms": 1699684882077, "logtype": "training_step"}
{"Avg objective": 24.59375, "Games time in secs": 127.67493653669953, "Avg game time in secs": 1.2219304182508495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 75264, "Total num trained steps": 150241, "Timestamp in ms": 1699684920381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957368253293668, "Avg loss": 1.8404814500827342, "Avg value loss": 1.4513132228748873, "Avg policy loss": 0.3891682156827301, "Total num played games": 75296, "Total num trained steps": 150272, "Timestamp in ms": 1699684932889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.996177532384795, "Avg loss": 1.2783824065700173, "Avg value loss": 0.9070782026974484, "Avg policy loss": 0.3713042113231495, "Total num played games": 75344, "Total num trained steps": 150400, "Timestamp in ms": 1699684987376, "logtype": "training_step"}
{"Avg objective": 25.4921875, "Games time in secs": 84.1196591630578, "Avg game time in secs": 1.2746346910425927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 75392, "Total num trained steps": 150440, "Timestamp in ms": 1699685004501, "logtype": "played_game"}
{"Total num played games": 75392, "Total num trained steps": 150526, "Timestamp in ms": 1699685049209, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9375}
{"Ratio train steps to played games": 1.9964322661078544, "Avg loss": 2.3659767620265484, "Avg value loss": 1.9791736672632396, "Avg policy loss": 0.38680305634625256, "Total num played games": 75396, "Total num trained steps": 150528, "Timestamp in ms": 1699685050479, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9957212309078143, "Avg loss": 2.6640165708959103, "Avg value loss": 2.253071041079238, "Avg policy loss": 0.4109455517027527, "Total num played games": 75489, "Total num trained steps": 150656, "Timestamp in ms": 1699685100623, "logtype": "training_step"}
{"Avg objective": 25.6875, "Games time in secs": 124.44200809672475, "Avg game time in secs": 1.2107578901486704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 75520, "Total num trained steps": 150727, "Timestamp in ms": 1699685128943, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961211575630808, "Avg loss": 1.6659277617000043, "Avg value loss": 1.2574045164510608, "Avg policy loss": 0.40852320729754865, "Total num played games": 75538, "Total num trained steps": 150784, "Timestamp in ms": 1699685151964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965337954939342, "Avg loss": 1.1592345461249352, "Avg value loss": 0.753814694005996, "Avg policy loss": 0.4054198432713747, "Total num played games": 75587, "Total num trained steps": 150912, "Timestamp in ms": 1699685204129, "logtype": "training_step"}
{"Avg objective": 22.6328125, "Games time in secs": 117.95379080064595, "Avg game time in secs": 1.3812536414334318, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 75648, "Total num trained steps": 151017, "Timestamp in ms": 1699685246897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99560024310969, "Avg loss": 1.4546676338650286, "Avg value loss": 1.0560798081569374, "Avg policy loss": 0.3985878243111074, "Total num played games": 75686, "Total num trained steps": 151040, "Timestamp in ms": 1699685255461, "logtype": "training_step"}
{"Total num played games": 75736, "Total num trained steps": 151127, "Timestamp in ms": 1699685301347, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7265625}
{"Avg objective": 24.6484375, "Games time in secs": 57.27174157835543, "Avg game time in secs": 1.2644239379733335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 75776, "Total num trained steps": 151133, "Timestamp in ms": 1699685304169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9947086456244063, "Avg loss": 2.4337212045211345, "Avg value loss": 2.034351311856881, "Avg policy loss": 0.39936986984685063, "Total num played games": 75784, "Total num trained steps": 151168, "Timestamp in ms": 1699685317756, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9963976564974137, "Avg loss": 0.9460357809439301, "Avg value loss": 0.5449040051316842, "Avg policy loss": 0.4011317640542984, "Total num played games": 75784, "Total num trained steps": 151296, "Timestamp in ms": 1699685371044, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9954535870539245, "Avg loss": 1.7909954639617354, "Avg value loss": 1.3921139515005052, "Avg policy loss": 0.3988815320190042, "Total num played games": 75884, "Total num trained steps": 151424, "Timestamp in ms": 1699685422192, "logtype": "training_step"}
{"Avg objective": 24.265625, "Games time in secs": 153.92406331002712, "Avg game time in secs": 1.2424920095945708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 75904, "Total num trained steps": 151515, "Timestamp in ms": 1699685458093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957201927888542, "Avg loss": 1.8670156649313867, "Avg value loss": 1.476119861123152, "Avg policy loss": 0.39089579856954515, "Total num played games": 75938, "Total num trained steps": 151552, "Timestamp in ms": 1699685472595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9961177569847475, "Avg loss": 1.2894304296933115, "Avg value loss": 0.9020912832347676, "Avg policy loss": 0.38733913854230195, "Total num played games": 75987, "Total num trained steps": 151680, "Timestamp in ms": 1699685523774, "logtype": "training_step"}
{"Avg objective": 26.5546875, "Games time in secs": 83.58760842308402, "Avg game time in secs": 1.2867767490679398, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.71, "agent_stopped_0": 0.36}, "Total num played games": 76032, "Total num trained steps": 151724, "Timestamp in ms": 1699685541681, "logtype": "played_game"}
{"Total num played games": 76035, "Total num trained steps": 151728, "Timestamp in ms": 1699685552401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.05859375}
{"Ratio train steps to played games": 1.9952946124627051, "Avg loss": 2.584313659463078, "Avg value loss": 2.1820988996187225, "Avg policy loss": 0.4022147445939481, "Total num played games": 76083, "Total num trained steps": 151808, "Timestamp in ms": 1699685586403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956785582934902, "Avg loss": 0.9003656981512904, "Avg value loss": 0.5020523248240352, "Avg policy loss": 0.3983133644796908, "Total num played games": 76132, "Total num trained steps": 151936, "Timestamp in ms": 1699685638540, "logtype": "training_step"}
{"Avg objective": 21.9296875, "Games time in secs": 128.00801834091544, "Avg game time in secs": 1.2926551819982706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.67, "agent_stopped_0": 0.41}, "Total num played games": 76160, "Total num trained steps": 152013, "Timestamp in ms": 1699685669689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960096608211697, "Avg loss": 1.2694092569872737, "Avg value loss": 0.8679421796696261, "Avg policy loss": 0.4014670788310468, "Total num played games": 76184, "Total num trained steps": 152064, "Timestamp in ms": 1699685690486, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9964319445901983, "Avg loss": 1.0811118194833398, "Avg value loss": 0.6974273741943762, "Avg policy loss": 0.38368443259969354, "Total num played games": 76232, "Total num trained steps": 152192, "Timestamp in ms": 1699685742049, "logtype": "training_step"}
{"Avg objective": 23.5625, "Games time in secs": 122.21106211654842, "Avg game time in secs": 1.3715831117297057, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 76288, "Total num trained steps": 152318, "Timestamp in ms": 1699685791900, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960948249878783, "Avg loss": 1.0601352031808347, "Avg value loss": 0.6778889939887449, "Avg policy loss": 0.38224618788808584, "Total num played games": 76307, "Total num trained steps": 152320, "Timestamp in ms": 1699685792544, "logtype": "training_step"}
{"Total num played games": 76335, "Total num trained steps": 152330, "Timestamp in ms": 1699685806385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1875}
{"Ratio train steps to played games": 1.9958236780435437, "Avg loss": 2.8456994977314025, "Avg value loss": 2.4595363829284906, "Avg policy loss": 0.3861631106119603, "Total num played games": 76383, "Total num trained steps": 152448, "Timestamp in ms": 1699685855789, "logtype": "training_step"}
{"Avg objective": 25.109375, "Games time in secs": 90.58510212041438, "Avg game time in secs": 1.1658823972102255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.57}, "Total num played games": 76416, "Total num trained steps": 152515, "Timestamp in ms": 1699685882485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9962449791315042, "Avg loss": 1.2542524330783635, "Avg value loss": 0.8825037134229206, "Avg policy loss": 0.3717487249523401, "Total num played games": 76431, "Total num trained steps": 152576, "Timestamp in ms": 1699685907817, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9966135380029026, "Avg loss": 1.9330390125978738, "Avg value loss": 1.5603149549569935, "Avg policy loss": 0.3727240258594975, "Total num played games": 76481, "Total num trained steps": 152704, "Timestamp in ms": 1699685960554, "logtype": "training_step"}
{"Avg objective": 25.0390625, "Games time in secs": 118.41161525063217, "Avg game time in secs": 1.3714073229493806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 76544, "Total num trained steps": 152805, "Timestamp in ms": 1699686000897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957168973622357, "Avg loss": 1.8347707246430218, "Avg value loss": 1.4494518038118258, "Avg policy loss": 0.3853189121000469, "Total num played games": 76580, "Total num trained steps": 152832, "Timestamp in ms": 1699686011751, "logtype": "training_step"}
{"Total num played games": 76628, "Total num trained steps": 152933, "Timestamp in ms": 1699686063410, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5703125}
{"Avg objective": 24.2109375, "Games time in secs": 65.84482563473284, "Avg game time in secs": 1.308117902604863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 76672, "Total num trained steps": 152941, "Timestamp in ms": 1699686066742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.994887578903438, "Avg loss": 2.324247625656426, "Avg value loss": 1.9228864654432982, "Avg policy loss": 0.4013611350674182, "Total num played games": 76676, "Total num trained steps": 152960, "Timestamp in ms": 1699686074390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965438990035995, "Avg loss": 1.045343593461439, "Avg value loss": 0.6475629670312628, "Avg policy loss": 0.39778064214624465, "Total num played games": 76676, "Total num trained steps": 153088, "Timestamp in ms": 1699686128273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99566259410738, "Avg loss": 1.4585087222512811, "Avg value loss": 1.0656391693046317, "Avg policy loss": 0.3928695563226938, "Total num played games": 76774, "Total num trained steps": 153216, "Timestamp in ms": 1699686178457, "logtype": "training_step"}
{"Avg objective": 22.46875, "Games time in secs": 145.09388266317546, "Avg game time in secs": 1.2915147292078473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 76800, "Total num trained steps": 153297, "Timestamp in ms": 1699686211836, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960818515529406, "Avg loss": 1.5284868830349296, "Avg value loss": 1.1359168423805386, "Avg policy loss": 0.3925700141116977, "Total num played games": 76822, "Total num trained steps": 153344, "Timestamp in ms": 1699686232125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.996474613313213, "Avg loss": 1.5840099167544395, "Avg value loss": 1.189733876963146, "Avg policy loss": 0.3942760128993541, "Total num played games": 76871, "Total num trained steps": 153472, "Timestamp in ms": 1699686286948, "logtype": "training_step"}
{"Total num played games": 76920, "Total num trained steps": 153537, "Timestamp in ms": 1699686322993, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8046875}
{"Avg objective": 24.828125, "Games time in secs": 112.64149134978652, "Avg game time in secs": 1.4477054540329846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 76928, "Total num trained steps": 153541, "Timestamp in ms": 1699686324478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956215570107056, "Avg loss": 2.059759641997516, "Avg value loss": 1.657921542180702, "Avg policy loss": 0.40183807141147554, "Total num played games": 76968, "Total num trained steps": 153600, "Timestamp in ms": 1699686348641, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960138670683096, "Avg loss": 1.0152010719757527, "Avg value loss": 0.6271441462449729, "Avg policy loss": 0.3880569380708039, "Total num played games": 77017, "Total num trained steps": 153728, "Timestamp in ms": 1699686399130, "logtype": "training_step"}
{"Avg objective": 24.234375, "Games time in secs": 97.69156596437097, "Avg game time in secs": 1.3681894766486948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.71}, "Total num played games": 77056, "Total num trained steps": 153784, "Timestamp in ms": 1699686422169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9964445597871927, "Avg loss": 1.420456749619916, "Avg value loss": 1.0185106981080025, "Avg policy loss": 0.40194606105796993, "Total num played games": 77065, "Total num trained steps": 153856, "Timestamp in ms": 1699686451901, "logtype": "training_step"}
{"Ratio train steps to played games": 1.995503142616471, "Avg loss": 1.1128835852723569, "Avg value loss": 0.714336437988095, "Avg policy loss": 0.39854714553803205, "Total num played games": 77165, "Total num trained steps": 153984, "Timestamp in ms": 1699686503616, "logtype": "training_step"}
{"Avg objective": 23.625, "Games time in secs": 118.46511775068939, "Avg game time in secs": 1.401158857930568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 77184, "Total num trained steps": 154078, "Timestamp in ms": 1699686540635, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959333272894462, "Avg loss": 1.3809489835985005, "Avg value loss": 0.990473048761487, "Avg policy loss": 0.390475933207199, "Total num played games": 77213, "Total num trained steps": 154112, "Timestamp in ms": 1699686554206, "logtype": "training_step"}
{"Total num played games": 77213, "Total num trained steps": 154139, "Timestamp in ms": 1699686574516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8359375}
{"Ratio train steps to played games": 1.9963370911585405, "Avg loss": 2.7879872624762356, "Avg value loss": 2.3968481448246166, "Avg policy loss": 0.3911391203291714, "Total num played games": 77261, "Total num trained steps": 154240, "Timestamp in ms": 1699686616092, "logtype": "training_step"}
{"Avg objective": 25.390625, "Games time in secs": 126.78133444674313, "Avg game time in secs": 1.511600555415498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.81, "agent_stopped_0": 0.28}, "Total num played games": 77312, "Total num trained steps": 154365, "Timestamp in ms": 1699686667416, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995927127914043, "Avg loss": 1.304883774369955, "Avg value loss": 0.91032428026665, "Avg policy loss": 0.3945594762917608, "Total num played games": 77339, "Total num trained steps": 154368, "Timestamp in ms": 1699686668440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9958015760237695, "Avg loss": 2.927627047523856, "Avg value loss": 2.5243947410490364, "Avg policy loss": 0.40323230833746493, "Total num played games": 77410, "Total num trained steps": 154496, "Timestamp in ms": 1699686718495, "logtype": "training_step"}
{"Avg objective": 25.171875, "Games time in secs": 80.24896256253123, "Avg game time in secs": 1.2731442251097178, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 77440, "Total num trained steps": 154568, "Timestamp in ms": 1699686747666, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961529027510618, "Avg loss": 2.1901578730903566, "Avg value loss": 1.7840956444852054, "Avg policy loss": 0.40606222837232053, "Total num played games": 77461, "Total num trained steps": 154624, "Timestamp in ms": 1699686771218, "logtype": "training_step"}
{"Total num played games": 77509, "Total num trained steps": 154739, "Timestamp in ms": 1699686827766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.296875}
{"Ratio train steps to played games": 1.9953195714119938, "Avg loss": 1.4335783598944545, "Avg value loss": 1.0317017391789705, "Avg policy loss": 0.401876634452492, "Total num played games": 77557, "Total num trained steps": 154752, "Timestamp in ms": 1699686833646, "logtype": "training_step"}
{"Avg objective": 24.5625, "Games time in secs": 131.00305084697902, "Avg game time in secs": 1.3537950607860694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.66, "agent_stopped_0": 0.42}, "Total num played games": 77568, "Total num trained steps": 154860, "Timestamp in ms": 1699686878669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9956962645122218, "Avg loss": 1.9878744264133275, "Avg value loss": 1.5880353873362765, "Avg policy loss": 0.3998390231281519, "Total num played games": 77607, "Total num trained steps": 154880, "Timestamp in ms": 1699686886529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9960852992685691, "Avg loss": 1.757892093155533, "Avg value loss": 1.3619850227842107, "Avg policy loss": 0.39590707630850375, "Total num played games": 77656, "Total num trained steps": 155008, "Timestamp in ms": 1699686939245, "logtype": "training_step"}
{"Avg objective": 24.84375, "Games time in secs": 83.84308005310595, "Avg game time in secs": 1.141195079209865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 77696, "Total num trained steps": 155061, "Timestamp in ms": 1699686962512, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9964609741972845, "Avg loss": 1.3794163740240037, "Avg value loss": 0.983150188694708, "Avg policy loss": 0.39626620314083993, "Total num played games": 77705, "Total num trained steps": 155136, "Timestamp in ms": 1699686996336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956170792524615, "Avg loss": 3.4458777522668242, "Avg value loss": 3.04478487954475, "Avg policy loss": 0.4010928520001471, "Total num played games": 77802, "Total num trained steps": 155264, "Timestamp in ms": 1699687052489, "logtype": "training_step"}
{"Total num played games": 77802, "Total num trained steps": 155342, "Timestamp in ms": 1699687097124, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.47265625}
{"Avg objective": 26.0390625, "Games time in secs": 136.89976340532303, "Avg game time in secs": 1.3248379278520588, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 77824, "Total num trained steps": 155346, "Timestamp in ms": 1699687099412, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960308285163777, "Avg loss": 1.934010569471866, "Avg value loss": 1.5212794514372945, "Avg policy loss": 0.4127311350312084, "Total num played games": 77850, "Total num trained steps": 155392, "Timestamp in ms": 1699687120671, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9964440678836428, "Avg loss": 1.5416362429969013, "Avg value loss": 1.1513728129211813, "Avg policy loss": 0.3902634484693408, "Total num played games": 77898, "Total num trained steps": 155520, "Timestamp in ms": 1699687177413, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 130.1490630991757, "Avg game time in secs": 1.388785916409688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 77952, "Total num trained steps": 155638, "Timestamp in ms": 1699687229561, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9954999423069526, "Avg loss": 1.3123778952285647, "Avg value loss": 0.9301477585686371, "Avg policy loss": 0.3822301449254155, "Total num played games": 77999, "Total num trained steps": 155648, "Timestamp in ms": 1699687233356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9959127192589081, "Avg loss": 2.366554015316069, "Avg value loss": 1.9803098500706255, "Avg policy loss": 0.3862441631499678, "Total num played games": 78047, "Total num trained steps": 155776, "Timestamp in ms": 1699687291548, "logtype": "training_step"}
{"Avg objective": 25.2421875, "Games time in secs": 92.76002485305071, "Avg game time in secs": 1.2342414351733169, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.65}, "Total num played games": 78080, "Total num trained steps": 155842, "Timestamp in ms": 1699687322321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9963249887956975, "Avg loss": 2.338167777750641, "Avg value loss": 1.946990488213487, "Avg policy loss": 0.39117729058489203, "Total num played games": 78095, "Total num trained steps": 155904, "Timestamp in ms": 1699687348653, "logtype": "training_step"}
{"Total num played games": 78145, "Total num trained steps": 155944, "Timestamp in ms": 1699687375365, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8828125}
{"Ratio train steps to played games": 1.9954599516580769, "Avg loss": 3.2003352902829647, "Avg value loss": 2.803301379084587, "Avg policy loss": 0.3970338897779584, "Total num played games": 78193, "Total num trained steps": 156032, "Timestamp in ms": 1699687414105, "logtype": "training_step"}
{"Avg objective": 26.625, "Games time in secs": 135.15642930381, "Avg game time in secs": 1.352521660795901, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 78208, "Total num trained steps": 156132, "Timestamp in ms": 1699687457478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.995871729655807, "Avg loss": 1.2240828406065702, "Avg value loss": 0.8508377270773053, "Avg policy loss": 0.37324512703344226, "Total num played games": 78241, "Total num trained steps": 156160, "Timestamp in ms": 1699687470060, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9962320062331558, "Avg loss": 1.48523431411013, "Avg value loss": 1.0982679578009993, "Avg policy loss": 0.38696634909138083, "Total num played games": 78291, "Total num trained steps": 156288, "Timestamp in ms": 1699687525776, "logtype": "training_step"}
{"Avg objective": 22.78125, "Games time in secs": 88.46951203234494, "Avg game time in secs": 1.3658387200557627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.73}, "Total num played games": 78336, "Total num trained steps": 156335, "Timestamp in ms": 1699687545947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9965918229279687, "Avg loss": 2.104444576893002, "Avg value loss": 1.7172432362567633, "Avg policy loss": 0.3872013876680285, "Total num played games": 78341, "Total num trained steps": 156416, "Timestamp in ms": 1699687581361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9957546087355618, "Avg loss": 1.6708979401737452, "Avg value loss": 1.2779448978835717, "Avg policy loss": 0.3929530684836209, "Total num played games": 78438, "Total num trained steps": 156544, "Timestamp in ms": 1699687638692, "logtype": "training_step"}
{"Total num played games": 78438, "Total num trained steps": 156546, "Timestamp in ms": 1699687648938, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.125}
{"Avg objective": 25.3359375, "Games time in secs": 105.16602709144354, "Avg game time in secs": 1.3946723207918694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.67, "agent_stopped_0": 0.4}, "Total num played games": 78464, "Total num trained steps": 156550, "Timestamp in ms": 1699687651114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9961649211324313, "Avg loss": 2.2927374495193362, "Avg value loss": 1.898336611688137, "Avg policy loss": 0.3944008194375783, "Total num played games": 78486, "Total num trained steps": 156672, "Timestamp in ms": 1699687705238, "logtype": "training_step"}
{"Ratio train steps to played games": 1.996574731963226, "Avg loss": 1.624624275835231, "Avg value loss": 1.2443207227624953, "Avg policy loss": 0.38030352629721165, "Total num played games": 78534, "Total num trained steps": 156800, "Timestamp in ms": 1699687762265, "logtype": "training_step"}
{"Avg objective": 24.8984375, "Games time in secs": 159.61141885444522, "Avg game time in secs": 1.4205729241948575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 78592, "Total num trained steps": 156912, "Timestamp in ms": 1699687810725, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9957395937988833, "Avg loss": 1.5480227479711175, "Avg value loss": 1.1833351409295574, "Avg policy loss": 0.3646875915583223, "Total num played games": 78631, "Total num trained steps": 156928, "Timestamp in ms": 1699687817927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9961362480935434, "Avg loss": 1.8430475993081927, "Avg value loss": 1.4831088854698464, "Avg policy loss": 0.35993871302343905, "Total num played games": 78680, "Total num trained steps": 157056, "Timestamp in ms": 1699687872976, "logtype": "training_step"}
{"Avg objective": 24.859375, "Games time in secs": 85.39383781887591, "Avg game time in secs": 1.2130617313669063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 78720, "Total num trained steps": 157110, "Timestamp in ms": 1699687896119, "logtype": "played_game"}
{"Total num played games": 78729, "Total num trained steps": 157150, "Timestamp in ms": 1699687922601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.796875}
{"Ratio train steps to played games": 1.9952905035733781, "Avg loss": 2.285141395404935, "Avg value loss": 1.9262147226836532, "Avg policy loss": 0.3589266568887979, "Total num played games": 78777, "Total num trained steps": 157184, "Timestamp in ms": 1699687938416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9956233825544223, "Avg loss": 1.9514180794358253, "Avg value loss": 1.5852310007903725, "Avg policy loss": 0.3661871231161058, "Total num played games": 78828, "Total num trained steps": 157312, "Timestamp in ms": 1699687996183, "logtype": "training_step"}
{"Avg objective": 23.5625, "Games time in secs": 147.62187885306776, "Avg game time in secs": 1.3156176700867945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 78848, "Total num trained steps": 157403, "Timestamp in ms": 1699688043741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996031746031746, "Avg loss": 2.1943863318301737, "Avg value loss": 1.8227526559494436, "Avg policy loss": 0.37163369613699615, "Total num played games": 78876, "Total num trained steps": 157440, "Timestamp in ms": 1699688060940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9964396127920532, "Avg loss": 0.9579257825389504, "Avg value loss": 0.6039015086134896, "Avg policy loss": 0.35402427590452135, "Total num played games": 78924, "Total num trained steps": 157568, "Timestamp in ms": 1699688117917, "logtype": "training_step"}
{"Avg objective": 24.109375, "Games time in secs": 90.111322382465, "Avg game time in secs": 1.4324781455070479, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.73}, "Total num played games": 78976, "Total num trained steps": 157600, "Timestamp in ms": 1699688133853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9967458468395463, "Avg loss": 2.8653843575157225, "Avg value loss": 2.4952259231358767, "Avg policy loss": 0.37015844881534576, "Total num played games": 78976, "Total num trained steps": 157696, "Timestamp in ms": 1699688181477, "logtype": "training_step"}
{"Total num played games": 79024, "Total num trained steps": 157753, "Timestamp in ms": 1699688217123, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.328125}
{"Ratio train steps to played games": 1.9959404087414003, "Avg loss": 1.973390829283744, "Avg value loss": 1.6007341288495809, "Avg policy loss": 0.372656695661135, "Total num played games": 79072, "Total num trained steps": 157824, "Timestamp in ms": 1699688248769, "logtype": "training_step"}
{"Avg objective": 23.4296875, "Games time in secs": 146.2932209596038, "Avg game time in secs": 1.2617331247165566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 79104, "Total num trained steps": 157892, "Timestamp in ms": 1699688280146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996322088952364, "Avg loss": 1.6307572682853788, "Avg value loss": 1.2646029421593994, "Avg policy loss": 0.36615430819801986, "Total num played games": 79121, "Total num trained steps": 157952, "Timestamp in ms": 1699688305622, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9967285174752745, "Avg loss": 1.5505384081043303, "Avg value loss": 1.176070310990326, "Avg policy loss": 0.3744680914096534, "Total num played games": 79169, "Total num trained steps": 158080, "Timestamp in ms": 1699688362156, "logtype": "training_step"}
{"Avg objective": 24.7578125, "Games time in secs": 127.77241220884025, "Avg game time in secs": 1.2802615557448007, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 79232, "Total num trained steps": 158180, "Timestamp in ms": 1699688407919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9959250615025548, "Avg loss": 1.915497520705685, "Avg value loss": 1.541618085699156, "Avg policy loss": 0.37387940543703735, "Total num played games": 79265, "Total num trained steps": 158208, "Timestamp in ms": 1699688420787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9961548159354514, "Avg loss": 1.7157709011808038, "Avg value loss": 1.3453792525688186, "Avg policy loss": 0.37039166898466647, "Total num played games": 79320, "Total num trained steps": 158336, "Timestamp in ms": 1699688476592, "logtype": "training_step"}
{"Total num played games": 79320, "Total num trained steps": 158353, "Timestamp in ms": 1699688493621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.890625}
{"Avg objective": 24.6875, "Games time in secs": 88.668173937127, "Avg game time in secs": 1.3465530686225975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 79360, "Total num trained steps": 158360, "Timestamp in ms": 1699688496587, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996572926116319, "Avg loss": 1.9651845670305192, "Avg value loss": 1.593236823217012, "Avg policy loss": 0.37194777093827724, "Total num played games": 79368, "Total num trained steps": 158464, "Timestamp in ms": 1699688545901, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9957590858753649, "Avg loss": 1.4152289214543998, "Avg value loss": 1.03792867239099, "Avg policy loss": 0.3773002519737929, "Total num played games": 79464, "Total num trained steps": 158592, "Timestamp in ms": 1699688602765, "logtype": "training_step"}
{"Avg objective": 24.75, "Games time in secs": 143.02163032069802, "Avg game time in secs": 1.2408273090113653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 79488, "Total num trained steps": 158676, "Timestamp in ms": 1699688639609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9960134812243768, "Avg loss": 2.079002252779901, "Avg value loss": 1.685370160616003, "Avg policy loss": 0.3936321255750954, "Total num played games": 79518, "Total num trained steps": 158720, "Timestamp in ms": 1699688658693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9964180680190031, "Avg loss": 0.8593708511907607, "Avg value loss": 0.4690396392252296, "Avg policy loss": 0.3903312140610069, "Total num played games": 79566, "Total num trained steps": 158848, "Timestamp in ms": 1699688714291, "logtype": "training_step"}
{"Total num played games": 79615, "Total num trained steps": 158954, "Timestamp in ms": 1699688772893, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.140625}
{"Avg objective": 23.296875, "Games time in secs": 134.25772827118635, "Avg game time in secs": 1.5466725376609247, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.82, "agent_stopped_0": 0.27}, "Total num played games": 79616, "Total num trained steps": 158955, "Timestamp in ms": 1699688773867, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9955939394700175, "Avg loss": 1.7821157346479595, "Avg value loss": 1.4010940501466393, "Avg policy loss": 0.38102164142765105, "Total num played games": 79663, "Total num trained steps": 158976, "Timestamp in ms": 1699688782876, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9959354693027573, "Avg loss": 1.9461385537870228, "Avg value loss": 1.5553289130330086, "Avg policy loss": 0.39080962212756276, "Total num played games": 79714, "Total num trained steps": 159104, "Timestamp in ms": 1699688838472, "logtype": "training_step"}
{"Avg objective": 24.4140625, "Games time in secs": 96.09999822080135, "Avg game time in secs": 1.2200740833213786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 79744, "Total num trained steps": 159177, "Timestamp in ms": 1699688869967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.996289052705481, "Avg loss": 1.8061546147800982, "Avg value loss": 1.409440335468389, "Avg policy loss": 0.39671427151188254, "Total num played games": 79764, "Total num trained steps": 159232, "Timestamp in ms": 1699688895191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9966922267328222, "Avg loss": 2.232278350740671, "Avg value loss": 1.8278577998280525, "Avg policy loss": 0.40442055417224765, "Total num played games": 79812, "Total num trained steps": 159360, "Timestamp in ms": 1699688954046, "logtype": "training_step"}
{"Avg objective": 27.078125, "Games time in secs": 135.49179615080357, "Avg game time in secs": 1.3833132111176383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 79872, "Total num trained steps": 159466, "Timestamp in ms": 1699689005459, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9958952795715073, "Avg loss": 2.115123053546995, "Avg value loss": 1.720981256570667, "Avg policy loss": 0.39414178393781185, "Total num played games": 79908, "Total num trained steps": 159488, "Timestamp in ms": 1699689016610, "logtype": "training_step"}
{"Total num played games": 79908, "Total num trained steps": 159556, "Timestamp in ms": 1699689064753, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7265625}
{"Ratio train steps to played games": 1.9962979638801341, "Avg loss": 1.9720979020930827, "Avg value loss": 1.5644795175176114, "Avg policy loss": 0.4076183692086488, "Total num played games": 79956, "Total num trained steps": 159616, "Timestamp in ms": 1699689096316, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 112.80551932379603, "Avg game time in secs": 1.3060606568324147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.68}, "Total num played games": 80000, "Total num trained steps": 159663, "Timestamp in ms": 1699689118265, "logtype": "played_game"}
{"Total num played games": 80004, "Total num trained steps": 159667, "Timestamp in ms": 1699689129473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.80859375}
{"Total num played games": 80016, "Total num trained steps": 159668, "Timestamp in ms": 1699689141401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.98828125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1699701191888, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.671875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1699701456678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.1640625}
