{"Avg objective": 14.606953125, "Games time in secs": 291.65603799931705, "Avg game time in secs": 84.0159723222896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.11, "agent_stopped_more": 0.45, "played_steps": 11.69, "reached_maximum_moves": 0.45}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1700497852587, "logtype": "played_game"}
{"Avg objective": 12.899375000000001, "Games time in secs": 296.9515289850533, "Avg game time in secs": 108.38422608260589, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 15.12, "agent_stopped_0": 0.04, "reached_maximum_moves": 0.59}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1700498149539, "logtype": "played_game"}
{"Ratio train steps to played games": 0.44755244755244755, "Avg loss": 52.557061433792114, "Avg value loss": 52.012299343943596, "Avg policy loss": 0.5447623229119927, "Total num played games": 286, "Total num trained steps": 128, "Timestamp in ms": 1700498232297, "logtype": "training_step"}
{"Ratio train steps to played games": 0.7950310559006211, "Avg loss": 13.430830910801888, "Avg value loss": 12.908839609473944, "Avg policy loss": 0.5219913022592664, "Total num played games": 322, "Total num trained steps": 256, "Timestamp in ms": 1700498305483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.0726256983240223, "Avg loss": 7.260125886648893, "Avg value loss": 6.747066434472799, "Avg policy loss": 0.5130594281945378, "Total num played games": 358, "Total num trained steps": 384, "Timestamp in ms": 1700498376459, "logtype": "training_step"}
{"Avg objective": 13.567265625000003, "Games time in secs": 276.8356721829623, "Avg game time in secs": 103.12262120599917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 14.02, "reached_maximum_moves": 0.55, "agent_stopped_0": 0.13}, "Total num played games": 384, "Total num trained steps": 507, "Timestamp in ms": 1700498426374, "logtype": "played_game"}
{"Ratio train steps to played games": 1.3298701298701299, "Avg loss": 4.721354894340038, "Avg value loss": 4.199520135298371, "Avg policy loss": 0.5218347380869091, "Total num played games": 385, "Total num trained steps": 512, "Timestamp in ms": 1700498427977, "logtype": "training_step"}
{"Total num played games": 450, "Total num trained steps": 605, "Timestamp in ms": 1700498891742, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4570703125}
{"Ratio train steps to played games": 1.3801295896328294, "Avg loss": 3.904278554022312, "Avg value loss": 3.407176235690713, "Avg policy loss": 0.49710230017080903, "Total num played games": 463, "Total num trained steps": 640, "Timestamp in ms": 1700498907138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.606694560669456, "Avg loss": 3.4093390610069036, "Avg value loss": 2.9192357640713453, "Avg policy loss": 0.4901032936759293, "Total num played games": 478, "Total num trained steps": 768, "Timestamp in ms": 1700498960500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.839835728952772, "Avg loss": 2.659804836846888, "Avg value loss": 2.1757111148908734, "Avg policy loss": 0.484093698207289, "Total num played games": 487, "Total num trained steps": 896, "Timestamp in ms": 1700499013965, "logtype": "training_step"}
{"Avg objective": 14.077812499999995, "Games time in secs": 639.216497387737, "Avg game time in secs": 101.11780850261857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 13.73, "reached_maximum_moves": 0.55, "agent_stopped_0": 0.14}, "Total num played games": 512, "Total num trained steps": 1021, "Timestamp in ms": 1700499065591, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0, "Avg loss": 2.7573331501334906, "Avg value loss": 2.2798008704558015, "Avg policy loss": 0.47753231041133404, "Total num played games": 512, "Total num trained steps": 1024, "Timestamp in ms": 1700499069380, "logtype": "training_step"}
{"Ratio train steps to played games": 2.1003649635036497, "Avg loss": 2.8649277659133077, "Avg value loss": 2.391226756386459, "Avg policy loss": 0.4737009971868247, "Total num played games": 548, "Total num trained steps": 1152, "Timestamp in ms": 1700499121579, "logtype": "training_step"}
{"Total num played games": 604, "Total num trained steps": 1205, "Timestamp in ms": 1700499485725, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.41703125}
{"Ratio train steps to played games": 2.038216560509554, "Avg loss": 3.323159863241017, "Avg value loss": 2.8602046919986606, "Avg policy loss": 0.46295516518875957, "Total num played games": 628, "Total num trained steps": 1280, "Timestamp in ms": 1700499517030, "logtype": "training_step"}
{"Avg objective": 16.048437499999995, "Games time in secs": 481.2576029803604, "Avg game time in secs": 95.150155457246, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3828125, "Avg reasons for ending game": {"reached_maximum_moves": 0.49, "played_steps": 12.23, "agent_stopped_more": 0.24, "agent_stopped_0": 0.27}, "Total num played games": 640, "Total num trained steps": 1352, "Timestamp in ms": 1700499546849, "logtype": "played_game"}
{"Ratio train steps to played games": 2.1931464174454827, "Avg loss": 2.1448448356240988, "Avg value loss": 1.6914618825539947, "Avg policy loss": 0.4533829444553703, "Total num played games": 642, "Total num trained steps": 1408, "Timestamp in ms": 1700499571500, "logtype": "training_step"}
{"Ratio train steps to played games": 2.292537313432836, "Avg loss": 1.9422888942062855, "Avg value loss": 1.494387709069997, "Avg policy loss": 0.4479011748917401, "Total num played games": 670, "Total num trained steps": 1536, "Timestamp in ms": 1700499625911, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3502824858757063, "Avg loss": 2.1560948165133595, "Avg value loss": 1.7156865033321083, "Avg policy loss": 0.4404083287809044, "Total num played games": 708, "Total num trained steps": 1664, "Timestamp in ms": 1700499685908, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4601648351648353, "Avg loss": 2.1845351960510015, "Avg value loss": 1.7483832039870322, "Avg policy loss": 0.43615198601037264, "Total num played games": 728, "Total num trained steps": 1792, "Timestamp in ms": 1700499739596, "logtype": "training_step"}
{"Avg objective": 13.066875, "Games time in secs": 304.509224191308, "Avg game time in secs": 98.82609414892795, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.19, "agent_stopped_more": 0.26, "played_steps": 13.5, "reached_maximum_moves": 0.55}, "Total num played games": 768, "Total num trained steps": 1809, "Timestamp in ms": 1700499851361, "logtype": "played_game"}
{"Total num played games": 783, "Total num trained steps": 1809, "Timestamp in ms": 1700500054237, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.6328515625}
{"Ratio train steps to played games": 2.3443223443223444, "Avg loss": 2.702872342430055, "Avg value loss": 2.2821518243290484, "Avg policy loss": 0.4207205187994987, "Total num played games": 819, "Total num trained steps": 1920, "Timestamp in ms": 1700500102390, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4615384615384617, "Avg loss": 1.855129661038518, "Avg value loss": 1.4394708201289177, "Avg policy loss": 0.41565882856957614, "Total num played games": 832, "Total num trained steps": 2048, "Timestamp in ms": 1700500156047, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5202780996523755, "Avg loss": 1.5622444283217192, "Avg value loss": 1.1482008025050163, "Avg policy loss": 0.41404361999593675, "Total num played games": 863, "Total num trained steps": 2176, "Timestamp in ms": 1700500208763, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5743016759776536, "Avg loss": 1.6464437963441014, "Avg value loss": 1.240130893420428, "Avg policy loss": 0.4063128924462944, "Total num played games": 895, "Total num trained steps": 2304, "Timestamp in ms": 1700500261772, "logtype": "training_step"}
{"Avg objective": 16.354375, "Games time in secs": 411.240340417251, "Avg game time in secs": 75.96856213177671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"reached_maximum_moves": 0.38, "played_steps": 9.97, "agent_stopped_more": 0.26, "agent_stopped_0": 0.37}, "Total num played games": 896, "Total num trained steps": 2306, "Timestamp in ms": 1700500262602, "logtype": "played_game"}
{"Total num played games": 955, "Total num trained steps": 2413, "Timestamp in ms": 1700500607781, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.384296875}
{"Ratio train steps to played games": 2.512396694214876, "Avg loss": 1.6668862951919436, "Avg value loss": 1.2592143802903593, "Avg policy loss": 0.40767190931364894, "Total num played games": 968, "Total num trained steps": 2432, "Timestamp in ms": 1700500616736, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5625625625625625, "Avg loss": 1.9834619499742985, "Avg value loss": 1.5814972915686667, "Avg policy loss": 0.40196464746259153, "Total num played games": 999, "Total num trained steps": 2560, "Timestamp in ms": 1700500670818, "logtype": "training_step"}
{"Ratio train steps to played games": 2.669314796425025, "Avg loss": 1.451402708888054, "Avg value loss": 1.0489782886579633, "Avg policy loss": 0.40242440439760685, "Total num played games": 1007, "Total num trained steps": 2688, "Timestamp in ms": 1700500724462, "logtype": "training_step"}
{"Avg objective": 14.290781249999997, "Games time in secs": 480.4681929126382, "Avg game time in secs": 85.98758271268161, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"reached_maximum_moves": 0.48, "played_steps": 11.77, "agent_stopped_0": 0.27, "agent_stopped_more": 0.25}, "Total num played games": 1024, "Total num trained steps": 2733, "Timestamp in ms": 1700500743074, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6844613918017157, "Avg loss": 1.4355397960171103, "Avg value loss": 1.0397310801781714, "Avg policy loss": 0.39580871374346316, "Total num played games": 1049, "Total num trained steps": 2816, "Timestamp in ms": 1700500777618, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6910420475319925, "Avg loss": 1.754907038062811, "Avg value loss": 1.3572817705571651, "Avg policy loss": 0.3976252421271056, "Total num played games": 1094, "Total num trained steps": 2944, "Timestamp in ms": 1700500831122, "logtype": "training_step"}
{"Avg objective": 15.391875000000004, "Games time in secs": 244.3026461545378, "Avg game time in secs": 94.59642756573157, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.19, "played_steps": 12.23, "reached_maximum_moves": 0.49}, "Total num played games": 1152, "Total num trained steps": 3016, "Timestamp in ms": 1700500987377, "logtype": "played_game"}
{"Total num played games": 1158, "Total num trained steps": 3016, "Timestamp in ms": 1700501128879, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2532421875}
{"Ratio train steps to played games": 2.507755102040816, "Avg loss": 2.3420431688427925, "Avg value loss": 1.9416847550310194, "Avg policy loss": 0.40035843732766807, "Total num played games": 1225, "Total num trained steps": 3072, "Timestamp in ms": 1700501158695, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5806451612903225, "Avg loss": 1.763215895742178, "Avg value loss": 1.36526601575315, "Avg policy loss": 0.39794987440109253, "Total num played games": 1240, "Total num trained steps": 3200, "Timestamp in ms": 1700501223009, "logtype": "training_step"}
{"Avg objective": 19.864843750000006, "Games time in secs": 286.5123359411955, "Avg game time in secs": 30.64537119002489, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2734375, "Avg reasons for ending game": {"reached_maximum_moves": 0.15, "played_steps": 3.87, "agent_stopped_more": 0.12, "agent_stopped_0": 0.73}, "Total num played games": 1280, "Total num trained steps": 3302, "Timestamp in ms": 1700501273889, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5898832684824904, "Avg loss": 1.67065944429487, "Avg value loss": 1.2828652835451066, "Avg policy loss": 0.3877941770479083, "Total num played games": 1285, "Total num trained steps": 3328, "Timestamp in ms": 1700501284461, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6043707611152977, "Avg loss": 1.478236235678196, "Avg value loss": 1.0969280381686985, "Avg policy loss": 0.38130820728838444, "Total num played games": 1327, "Total num trained steps": 3456, "Timestamp in ms": 1700501337897, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6469719350073855, "Avg loss": 1.4669328164309263, "Avg value loss": 1.089426706545055, "Avg policy loss": 0.3775061301421374, "Total num played games": 1354, "Total num trained steps": 3584, "Timestamp in ms": 1700501390428, "logtype": "training_step"}
{"Avg objective": 15.409687500000002, "Games time in secs": 287.60867858864367, "Avg game time in secs": 101.64208187715849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"reached_maximum_moves": 0.52, "played_steps": 13.09, "agent_stopped_0": 0.31, "agent_stopped_more": 0.16}, "Total num played games": 1408, "Total num trained steps": 3619, "Timestamp in ms": 1700501561498, "logtype": "played_game"}
{"Total num played games": 1410, "Total num trained steps": 3619, "Timestamp in ms": 1700501658897, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.117734375}
{"Ratio train steps to played games": 2.522773623385452, "Avg loss": 1.922012117691338, "Avg value loss": 1.541184422094375, "Avg policy loss": 0.38082771049812436, "Total num played games": 1471, "Total num trained steps": 3712, "Timestamp in ms": 1700501700650, "logtype": "training_step"}
{"Ratio train steps to played games": 2.577181208053691, "Avg loss": 1.4204864213243127, "Avg value loss": 1.0424593701027334, "Avg policy loss": 0.37802705517970026, "Total num played games": 1490, "Total num trained steps": 3840, "Timestamp in ms": 1700501754218, "logtype": "training_step"}
{"Avg objective": 19.264375, "Games time in secs": 239.44000778347254, "Avg game time in secs": 28.579594699229347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.16, "played_steps": 3.58, "reached_maximum_moves": 0.12, "agent_stopped_0": 0.73}, "Total num played games": 1536, "Total num trained steps": 3954, "Timestamp in ms": 1700501800938, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5782975958414553, "Avg loss": 1.4764012787491083, "Avg value loss": 1.1052490095607936, "Avg policy loss": 0.37115226360037923, "Total num played games": 1539, "Total num trained steps": 3968, "Timestamp in ms": 1700501806368, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5891276864728194, "Avg loss": 1.4803739013150334, "Avg value loss": 1.1209555063396692, "Avg policy loss": 0.3594183998648077, "Total num played games": 1582, "Total num trained steps": 4096, "Timestamp in ms": 1700501859566, "logtype": "training_step"}
{"Avg objective": 16.45921875, "Games time in secs": 195.5437164157629, "Avg game time in secs": 71.08001073736523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.2, "played_steps": 9.1, "reached_maximum_moves": 0.34}, "Total num played games": 1664, "Total num trained steps": 4220, "Timestamp in ms": 1700501996482, "logtype": "played_game"}
{"Total num played games": 1681, "Total num trained steps": 4220, "Timestamp in ms": 1700502157933, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2024609375}
{"Ratio train steps to played games": 2.5121951219512195, "Avg loss": 1.6793064717203379, "Avg value loss": 1.3227843628264964, "Avg policy loss": 0.3565221026074141, "Total num played games": 1681, "Total num trained steps": 4224, "Timestamp in ms": 1700502160568, "logtype": "training_step"}
{"Avg objective": 20.703359374999994, "Games time in secs": 214.3595801834017, "Avg game time in secs": 26.998897505516652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.390625, "Avg reasons for ending game": {"reached_maximum_moves": 0.13, "played_steps": 3.09, "agent_stopped_0": 0.8, "agent_stopped_more": 0.06}, "Total num played games": 1792, "Total num trained steps": 4339, "Timestamp in ms": 1700502210842, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4245125348189416, "Avg loss": 2.502525898627937, "Avg value loss": 2.1620526434853673, "Avg policy loss": 0.3404732742346823, "Total num played games": 1795, "Total num trained steps": 4352, "Timestamp in ms": 1700502216340, "logtype": "training_step"}
{"Ratio train steps to played games": 2.460186710598572, "Avg loss": 1.5100784292444587, "Avg value loss": 1.1809838600456715, "Avg policy loss": 0.3290945738554001, "Total num played games": 1821, "Total num trained steps": 4480, "Timestamp in ms": 1700502270468, "logtype": "training_step"}
{"Ratio train steps to played games": 2.465489566613162, "Avg loss": 1.4206524826586246, "Avg value loss": 1.0936364834196866, "Avg policy loss": 0.3270159976091236, "Total num played games": 1869, "Total num trained steps": 4608, "Timestamp in ms": 1700502328365, "logtype": "training_step"}
{"Avg objective": 17.20078125, "Games time in secs": 156.51897834055126, "Avg game time in secs": 47.94786229568126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.2, "played_steps": 6.05, "reached_maximum_moves": 0.21}, "Total num played games": 1920, "Total num trained steps": 4703, "Timestamp in ms": 1700502367361, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4399793920659456, "Avg loss": 1.4776315838098526, "Avg value loss": 1.1526302234269679, "Avg policy loss": 0.32500136084854603, "Total num played games": 1941, "Total num trained steps": 4736, "Timestamp in ms": 1700502381269, "logtype": "training_step"}
{"Total num played games": 2039, "Total num trained steps": 4821, "Timestamp in ms": 1700502662637, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2066796875}
{"Avg objective": 17.239843749999995, "Games time in secs": 301.14976177737117, "Avg game time in secs": 70.06065790371213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "reached_maximum_moves": 0.4, "played_steps": 9.14, "agent_stopped_more": 0.09}, "Total num played games": 2048, "Total num trained steps": 4828, "Timestamp in ms": 1700502668511, "logtype": "played_game"}
{"Ratio train steps to played games": 2.295422369042001, "Avg loss": 1.968333856202662, "Avg value loss": 1.6454678839072585, "Avg policy loss": 0.322865956928581, "Total num played games": 2119, "Total num trained steps": 4864, "Timestamp in ms": 1700502687227, "logtype": "training_step"}
{"Avg objective": 21.486328125, "Games time in secs": 56.531987845897675, "Avg game time in secs": 7.167874940612819, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.12, "played_steps": 0.37}, "Total num played games": 2176, "Total num trained steps": 4953, "Timestamp in ms": 1700502725043, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2815356489945153, "Avg loss": 2.0111224418506026, "Avg value loss": 1.6914917146787047, "Avg policy loss": 0.31963072065263987, "Total num played games": 2187, "Total num trained steps": 4992, "Timestamp in ms": 1700502741179, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3073456511942316, "Avg loss": 1.3892918080091476, "Avg value loss": 1.0759527087211609, "Avg policy loss": 0.31333911302499473, "Total num played games": 2219, "Total num trained steps": 5120, "Timestamp in ms": 1700502795515, "logtype": "training_step"}
{"Avg objective": 19.039687500000003, "Games time in secs": 117.74989518523216, "Avg game time in secs": 32.282635469324305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.11, "played_steps": 4.23, "reached_maximum_moves": 0.16}, "Total num played games": 2304, "Total num trained steps": 5233, "Timestamp in ms": 1700502842793, "logtype": "played_game"}
{"Ratio train steps to played games": 2.264997842037117, "Avg loss": 1.7666194150224328, "Avg value loss": 1.4575201799161732, "Avg policy loss": 0.30909923324361444, "Total num played games": 2317, "Total num trained steps": 5248, "Timestamp in ms": 1700502848687, "logtype": "training_step"}
{"Ratio train steps to played games": 2.221487603305785, "Avg loss": 1.7658036639913917, "Avg value loss": 1.462697679642588, "Avg policy loss": 0.30310599505901337, "Total num played games": 2420, "Total num trained steps": 5376, "Timestamp in ms": 1700502902076, "logtype": "training_step"}
{"Avg objective": 19.098046874999998, "Games time in secs": 70.9517560955137, "Avg game time in secs": 30.77227508071519, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"reached_maximum_moves": 0.12, "played_steps": 3.64, "agent_stopped_0": 0.74, "agent_stopped_more": 0.13}, "Total num played games": 2432, "Total num trained steps": 5402, "Timestamp in ms": 1700502913745, "logtype": "played_game"}
{"Total num played games": 2486, "Total num trained steps": 5421, "Timestamp in ms": 1700503135763, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3252734375}
{"Avg objective": 17.932890625, "Games time in secs": 237.78728500194848, "Avg game time in secs": 50.17250575727667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"reached_maximum_moves": 0.28, "played_steps": 6.62, "agent_stopped_more": 0.12, "agent_stopped_0": 0.6}, "Total num played games": 2560, "Total num trained steps": 5448, "Timestamp in ms": 1700503151533, "logtype": "played_game"}
{"Ratio train steps to played games": 2.1136712749615976, "Avg loss": 2.5268296152353287, "Avg value loss": 2.2305331719107926, "Avg policy loss": 0.29629643354564905, "Total num played games": 2604, "Total num trained steps": 5504, "Timestamp in ms": 1700503175225, "logtype": "training_step"}
{"Ratio train steps to played games": 2.1309118426031026, "Avg loss": 1.5281774261966348, "Avg value loss": 1.2362135518342257, "Avg policy loss": 0.29196388937998563, "Total num played games": 2643, "Total num trained steps": 5632, "Timestamp in ms": 1700503228169, "logtype": "training_step"}
{"Ratio train steps to played games": 2.1468505404398064, "Avg loss": 1.3317895932123065, "Avg value loss": 1.040358116850257, "Avg policy loss": 0.2914314662339166, "Total num played games": 2683, "Total num trained steps": 5760, "Timestamp in ms": 1700503279541, "logtype": "training_step"}
{"Avg objective": 20.525859374999996, "Games time in secs": 129.87621195614338, "Avg game time in secs": 21.434576324696536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.23, "played_steps": 2.75, "reached_maximum_moves": 0.09}, "Total num played games": 2688, "Total num trained steps": 5764, "Timestamp in ms": 1700503281409, "logtype": "played_game"}
{"Ratio train steps to played games": 2.10024973242954, "Avg loss": 1.6587754706852138, "Avg value loss": 1.3736731517128646, "Avg policy loss": 0.28510231466498226, "Total num played games": 2803, "Total num trained steps": 5888, "Timestamp in ms": 1700503333780, "logtype": "training_step"}
{"Avg objective": 19.117421874999994, "Games time in secs": 57.29278304241598, "Avg game time in secs": 32.27172294414777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"reached_maximum_moves": 0.16, "played_steps": 3.99, "agent_stopped_0": 0.73, "agent_stopped_more": 0.1}, "Total num played games": 2816, "Total num trained steps": 5900, "Timestamp in ms": 1700503338702, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0701995870612526, "Avg loss": 1.7304548155516386, "Avg value loss": 1.4347302136011422, "Avg policy loss": 0.2957246005535126, "Total num played games": 2906, "Total num trained steps": 6016, "Timestamp in ms": 1700503387026, "logtype": "training_step"}
{"Avg objective": 19.102578125000004, "Games time in secs": 121.03140854462981, "Avg game time in secs": 42.01878906779166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "reached_maximum_moves": 0.22, "played_steps": 5.63, "agent_stopped_more": 0.16}, "Total num played games": 2944, "Total num trained steps": 6021, "Timestamp in ms": 1700503459734, "logtype": "played_game"}
{"Total num played games": 2959, "Total num trained steps": 6021, "Timestamp in ms": 1700503543990, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.123632812500002}
{"Avg objective": 19.514374999999998, "Games time in secs": 108.81022152677178, "Avg game time in secs": 21.14407427838887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"reached_maximum_moves": 0.11, "played_steps": 2.54, "agent_stopped_more": 0.08, "agent_stopped_0": 0.81}, "Total num played games": 3072, "Total num trained steps": 6077, "Timestamp in ms": 1700503568544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968279397628965, "Avg loss": 2.0243036625906825, "Avg value loss": 1.7343905461020768, "Avg policy loss": 0.2899131141602993, "Total num played games": 3121, "Total num trained steps": 6144, "Timestamp in ms": 1700503596201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 1.4419716354459524, "Avg value loss": 1.1564964787103236, "Avg policy loss": 0.2854751554550603, "Total num played games": 3171, "Total num trained steps": 6272, "Timestamp in ms": 1700503649644, "logtype": "training_step"}
{"Avg objective": 19.998984375000003, "Games time in secs": 100.6412159241736, "Avg game time in secs": 14.017781459493563, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.2, "played_steps": 1.75, "reached_maximum_moves": 0.04}, "Total num played games": 3200, "Total num trained steps": 6321, "Timestamp in ms": 1700503669186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.95032002438281, "Avg loss": 1.44993010815233, "Avg value loss": 1.1480047460645437, "Avg policy loss": 0.30192536127287894, "Total num played games": 3281, "Total num trained steps": 6400, "Timestamp in ms": 1700503701197, "logtype": "training_step"}
{"Avg objective": 19.251171875000004, "Games time in secs": 51.93554142490029, "Avg game time in secs": 25.836145792418392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"reached_maximum_moves": 0.13, "played_steps": 3.4, "agent_stopped_0": 0.73, "agent_stopped_more": 0.14}, "Total num played games": 3328, "Total num trained steps": 6449, "Timestamp in ms": 1700503721121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9126867858189276, "Avg loss": 1.7780128903687, "Avg value loss": 1.4821164240129292, "Avg policy loss": 0.29589646810200065, "Total num played games": 3413, "Total num trained steps": 6528, "Timestamp in ms": 1700503753101, "logtype": "training_step"}
{"Avg objective": 20.025703125, "Games time in secs": 54.192033091560006, "Avg game time in secs": 20.729112602668465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.18, "played_steps": 2.45, "reached_maximum_moves": 0.08, "agent_stopped_0": 0.74}, "Total num played games": 3456, "Total num trained steps": 6579, "Timestamp in ms": 1700503775314, "logtype": "played_game"}
{"Total num played games": 3545, "Total num trained steps": 6625, "Timestamp in ms": 1700503925618, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.029726562500002}
{"Avg objective": 18.180624999999996, "Games time in secs": 156.13227396085858, "Avg game time in secs": 45.66357839286502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.2, "played_steps": 6.2, "reached_maximum_moves": 0.22}, "Total num played games": 3584, "Total num trained steps": 6634, "Timestamp in ms": 1700503931446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8414499169894853, "Avg loss": 1.998814961872995, "Avg value loss": 1.6951517621055245, "Avg policy loss": 0.3036631779978052, "Total num played games": 3614, "Total num trained steps": 6656, "Timestamp in ms": 1700503942705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8558139534883722, "Avg loss": 1.5967669524252415, "Avg value loss": 1.2915289858356118, "Avg policy loss": 0.3052379726432264, "Total num played games": 3655, "Total num trained steps": 6784, "Timestamp in ms": 1700504009269, "logtype": "training_step"}
{"Avg objective": 21.213749999999997, "Games time in secs": 130.99681930616498, "Avg game time in secs": 8.005530495429412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.87, "agent_stopped_more": 0.11, "played_steps": 0.8, "reached_maximum_moves": 0.02}, "Total num played games": 3712, "Total num trained steps": 6882, "Timestamp in ms": 1700504062443, "logtype": "played_game"}
{"Ratio train steps to played games": 1.854077253218884, "Avg loss": 1.2507523149251938, "Avg value loss": 0.9494433575309813, "Avg policy loss": 0.30130895785987377, "Total num played games": 3728, "Total num trained steps": 6912, "Timestamp in ms": 1700504078407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8641419491525424, "Avg loss": 1.1900222678668797, "Avg value loss": 0.8866396932862699, "Avg policy loss": 0.30338257655967027, "Total num played games": 3776, "Total num trained steps": 7040, "Timestamp in ms": 1700504147160, "logtype": "training_step"}
{"Avg objective": 21.25789062499999, "Games time in secs": 133.95750500820577, "Avg game time in secs": 18.103693477605702, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.2, "played_steps": 2.25, "reached_maximum_moves": 0.06}, "Total num played games": 3840, "Total num trained steps": 7137, "Timestamp in ms": 1700504196401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8562548562548562, "Avg loss": 1.3673514751717448, "Avg value loss": 1.0691497903317213, "Avg policy loss": 0.298201686469838, "Total num played games": 3861, "Total num trained steps": 7168, "Timestamp in ms": 1700504212887, "logtype": "training_step"}
{"Total num played games": 3915, "Total num trained steps": 7226, "Timestamp in ms": 1700504358163, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4426953125}
{"Ratio train steps to played games": 1.8424242424242425, "Avg loss": 1.4062240556813776, "Avg value loss": 1.0998927531763911, "Avg policy loss": 0.306331301224418, "Total num played games": 3960, "Total num trained steps": 7296, "Timestamp in ms": 1700504395989, "logtype": "training_step"}
{"Avg objective": 20.831171874999992, "Games time in secs": 264.52662545256317, "Avg game time in secs": 17.465851352346363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.21, "played_steps": 2.28, "reached_maximum_moves": 0.07}, "Total num played games": 3968, "Total num trained steps": 7418, "Timestamp in ms": 1700504460928, "logtype": "played_game"}
{"Ratio train steps to played games": 1.854822588705647, "Avg loss": 0.9139954904094338, "Avg value loss": 0.6084027644246817, "Avg policy loss": 0.30559273215476424, "Total num played games": 4002, "Total num trained steps": 7424, "Timestamp in ms": 1700504463715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8605567873860558, "Avg loss": 1.211684468202293, "Avg value loss": 0.8955104439519346, "Avg policy loss": 0.31617402436677366, "Total num played games": 4059, "Total num trained steps": 7552, "Timestamp in ms": 1700504529712, "logtype": "training_step"}
{"Avg objective": 20.373671874999996, "Games time in secs": 105.46823676861823, "Avg game time in secs": 6.495205642844667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.17, "played_steps": 0.65, "reached_maximum_moves": 0.02}, "Total num played games": 4096, "Total num trained steps": 7621, "Timestamp in ms": 1700504566396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.871345029239766, "Avg loss": 1.2281658998690546, "Avg value loss": 0.907992537599057, "Avg policy loss": 0.32017336308490485, "Total num played games": 4104, "Total num trained steps": 7680, "Timestamp in ms": 1700504597304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8625954198473282, "Avg loss": 1.2070291442796588, "Avg value loss": 0.895968813681975, "Avg policy loss": 0.3110603344393894, "Total num played games": 4192, "Total num trained steps": 7808, "Timestamp in ms": 1700504662289, "logtype": "training_step"}
{"Total num played games": 4198, "Total num trained steps": 7827, "Timestamp in ms": 1700504762862, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.7862109375}
{"Avg objective": 21.244374999999998, "Games time in secs": 201.2490094937384, "Avg game time in secs": 14.428151378873736, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 1.83, "agent_stopped_0": 0.75, "reached_maximum_moves": 0.05}, "Total num played games": 4224, "Total num trained steps": 7836, "Timestamp in ms": 1700504767645, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8701390525571528, "Avg loss": 1.2736954912543297, "Avg value loss": 0.9564721120987087, "Avg policy loss": 0.31722337659448385, "Total num played games": 4243, "Total num trained steps": 7936, "Timestamp in ms": 1700504821576, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8794871794871795, "Avg loss": 0.9927496910095215, "Avg value loss": 0.6869072238914669, "Avg policy loss": 0.3058424674673006, "Total num played games": 4290, "Total num trained steps": 8064, "Timestamp in ms": 1700504888296, "logtype": "training_step"}
{"Avg objective": 21.294843749999988, "Games time in secs": 168.75895505212247, "Avg game time in secs": 12.765569447379676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.25, "played_steps": 1.58, "reached_maximum_moves": 0.05}, "Total num played games": 4352, "Total num trained steps": 8163, "Timestamp in ms": 1700504936404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8733135147495998, "Avg loss": 1.153096724767238, "Avg value loss": 0.845459190197289, "Avg policy loss": 0.30763753806240857, "Total num played games": 4373, "Total num trained steps": 8192, "Timestamp in ms": 1700504950852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8823529411764706, "Avg loss": 1.2035949993878603, "Avg value loss": 0.8928118073381484, "Avg policy loss": 0.31078319787047803, "Total num played games": 4420, "Total num trained steps": 8320, "Timestamp in ms": 1700505015159, "logtype": "training_step"}
{"Avg objective": 21.381953124999995, "Games time in secs": 132.92464992776513, "Avg game time in secs": 14.230409273543046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.34, "played_steps": 1.91, "reached_maximum_moves": 0.04}, "Total num played games": 4480, "Total num trained steps": 8431, "Timestamp in ms": 1700505069329, "logtype": "played_game"}
{"Total num played games": 4518, "Total num trained steps": 8431, "Timestamp in ms": 1700505175065, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.926171875}
{"Ratio train steps to played games": 1.853225098727512, "Avg loss": 1.076684056315571, "Avg value loss": 0.7561231073923409, "Avg policy loss": 0.32056094938889146, "Total num played games": 4558, "Total num trained steps": 8448, "Timestamp in ms": 1700505186799, "logtype": "training_step"}
{"Ratio train steps to played games": 1.87842278203724, "Avg loss": 1.0246015153825283, "Avg value loss": 0.7042474376503378, "Avg policy loss": 0.3203540720278397, "Total num played games": 4565, "Total num trained steps": 8576, "Timestamp in ms": 1700505274481, "logtype": "training_step"}
{"Avg objective": 21.786249999999992, "Games time in secs": 242.69539261609316, "Avg game time in secs": 11.153949046783964, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 1.39, "agent_stopped_0": 0.76, "reached_maximum_moves": 0.05}, "Total num played games": 4608, "Total num trained steps": 8633, "Timestamp in ms": 1700505312025, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8866247561239975, "Avg loss": 0.9712121286429465, "Avg value loss": 0.6579801139887422, "Avg policy loss": 0.3132320059230551, "Total num played games": 4613, "Total num trained steps": 8704, "Timestamp in ms": 1700505357197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8777376142887519, "Avg loss": 1.1491044056601822, "Avg value loss": 0.83406000607647, "Avg policy loss": 0.3150444064522162, "Total num played games": 4703, "Total num trained steps": 8832, "Timestamp in ms": 1700505425509, "logtype": "training_step"}
{"Avg objective": 22.125546875, "Games time in secs": 155.48895735666156, "Avg game time in secs": 8.671018533990718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 1.01, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.78}, "Total num played games": 4736, "Total num trained steps": 8910, "Timestamp in ms": 1700505467514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.885708271942749, "Avg loss": 0.9718285114504397, "Avg value loss": 0.6592902620323002, "Avg policy loss": 0.3125382517464459, "Total num played games": 4751, "Total num trained steps": 8960, "Timestamp in ms": 1700505493798, "logtype": "training_step"}
{"Total num played games": 4802, "Total num trained steps": 9031, "Timestamp in ms": 1700505613092, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.678242187500004}
{"Ratio train steps to played games": 1.874381188118812, "Avg loss": 1.1578284073621035, "Avg value loss": 0.8311654790304601, "Avg policy loss": 0.32666292414069176, "Total num played games": 4848, "Total num trained steps": 9088, "Timestamp in ms": 1700505651976, "logtype": "training_step"}
{"Avg objective": 21.003749999999993, "Games time in secs": 254.72698495350778, "Avg game time in secs": 10.952754370620823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.3, "played_steps": 1.51, "reached_maximum_moves": 0.04}, "Total num played games": 4864, "Total num trained steps": 9190, "Timestamp in ms": 1700505722241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8831221904372701, "Avg loss": 0.912684503942728, "Avg value loss": 0.590662335511297, "Avg policy loss": 0.32202217436861247, "Total num played games": 4894, "Total num trained steps": 9216, "Timestamp in ms": 1700505740000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8901476835929598, "Avg loss": 0.9971126466989517, "Avg value loss": 0.6731965476647019, "Avg policy loss": 0.32391608762554824, "Total num played games": 4943, "Total num trained steps": 9344, "Timestamp in ms": 1700505833457, "logtype": "training_step"}
{"Avg objective": 20.50515624999999, "Games time in secs": 198.6360475309193, "Avg game time in secs": 9.834777114636381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.25, "played_steps": 1.28, "reached_maximum_moves": 0.04}, "Total num played games": 4992, "Total num trained steps": 9469, "Timestamp in ms": 1700505920877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8921294446664003, "Avg loss": 0.9427273725159466, "Avg value loss": 0.6055907567497343, "Avg policy loss": 0.337136612739414, "Total num played games": 5003, "Total num trained steps": 9472, "Timestamp in ms": 1700505922329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8884517017509346, "Avg loss": 1.2987007200717926, "Avg value loss": 0.9690579967573285, "Avg policy loss": 0.32964272832032293, "Total num played games": 5083, "Total num trained steps": 9600, "Timestamp in ms": 1700506013022, "logtype": "training_step"}
{"Total num played games": 5085, "Total num trained steps": 9633, "Timestamp in ms": 1700506126972, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9775390625}
{"Avg objective": 21.940624999999997, "Games time in secs": 212.67264779098332, "Avg game time in secs": 8.74125029341667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.27, "played_steps": 1.02, "reached_maximum_moves": 0.02}, "Total num played games": 5120, "Total num trained steps": 9639, "Timestamp in ms": 1700506133550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8964710469877168, "Avg loss": 1.1533889258280396, "Avg value loss": 0.8186180375050753, "Avg policy loss": 0.3347708801738918, "Total num played games": 5129, "Total num trained steps": 9728, "Timestamp in ms": 1700506194982, "logtype": "training_step"}
{"Ratio train steps to played games": 1.891020721412126, "Avg loss": 0.8895767265930772, "Avg value loss": 0.5511049990309402, "Avg policy loss": 0.33847173070535064, "Total num played games": 5212, "Total num trained steps": 9856, "Timestamp in ms": 1700506277820, "logtype": "training_step"}
{"Avg objective": 20.186796874999995, "Games time in secs": 203.41491691209376, "Avg game time in secs": 9.949287250186899, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 1.45, "agent_stopped_0": 0.63, "reached_maximum_moves": 0.04}, "Total num played games": 5248, "Total num trained steps": 9952, "Timestamp in ms": 1700506336965, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8934193058979707, "Avg loss": 1.097207948565483, "Avg value loss": 0.7565668066963553, "Avg policy loss": 0.34064113278873265, "Total num played games": 5273, "Total num trained steps": 9984, "Timestamp in ms": 1700506355125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8996806312229946, "Avg loss": 0.884494733531028, "Avg value loss": 0.546948631061241, "Avg policy loss": 0.33754610549658537, "Total num played games": 5323, "Total num trained steps": 10112, "Timestamp in ms": 1700506427743, "logtype": "training_step"}
{"Total num played games": 5375, "Total num trained steps": 10236, "Timestamp in ms": 1700506616923, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.401992187500003}
{"Avg objective": 19.44421874999999, "Games time in secs": 282.86999217420816, "Avg game time in secs": 9.844109004043275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.3, "played_steps": 1.3, "reached_maximum_moves": 0.03}, "Total num played games": 5376, "Total num trained steps": 10238, "Timestamp in ms": 1700506619835, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9022849712056473, "Avg loss": 0.843194377142936, "Avg value loss": 0.519680350786075, "Avg policy loss": 0.3235140243778005, "Total num played games": 5383, "Total num trained steps": 10240, "Timestamp in ms": 1700506620837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8969807868252515, "Avg loss": 0.9637931771576405, "Avg value loss": 0.6227233717218041, "Avg policy loss": 0.3410698107909411, "Total num played games": 5465, "Total num trained steps": 10368, "Timestamp in ms": 1700506691755, "logtype": "training_step"}
{"Avg objective": 20.898906249999992, "Games time in secs": 109.72119394689798, "Avg game time in secs": 5.641748535359511, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.62}, "Total num played games": 5504, "Total num trained steps": 10437, "Timestamp in ms": 1700506729557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9045545273090183, "Avg loss": 1.013777384068817, "Avg value loss": 0.6632257094606757, "Avg policy loss": 0.3505516729783267, "Total num played games": 5511, "Total num trained steps": 10496, "Timestamp in ms": 1700506761706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.895788722341185, "Avg loss": 1.027344943024218, "Avg value loss": 0.6797342812642455, "Avg policy loss": 0.347610654309392, "Total num played games": 5604, "Total num trained steps": 10624, "Timestamp in ms": 1700506831926, "logtype": "training_step"}
{"Avg objective": 21.504765625, "Games time in secs": 149.41489870473742, "Avg game time in secs": 9.410729395021917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.23, "played_steps": 1.17, "agent_stopped_0": 0.74, "reached_maximum_moves": 0.03}, "Total num played games": 5632, "Total num trained steps": 10706, "Timestamp in ms": 1700506878972, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9024951336046718, "Avg loss": 0.9175518853589892, "Avg value loss": 0.5810072758467868, "Avg policy loss": 0.33654460147954524, "Total num played games": 5651, "Total num trained steps": 10752, "Timestamp in ms": 1700506904884, "logtype": "training_step"}
{"Total num played games": 5700, "Total num trained steps": 10836, "Timestamp in ms": 1700507044426, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.485078125000005}
{"Ratio train steps to played games": 1.892987645728206, "Avg loss": 0.9387610866688192, "Avg value loss": 0.5931913945823908, "Avg policy loss": 0.3455696925520897, "Total num played games": 5747, "Total num trained steps": 10880, "Timestamp in ms": 1700507069102, "logtype": "training_step"}
{"Avg objective": 21.31281249999999, "Games time in secs": 249.5616806577891, "Avg game time in secs": 9.263240080865216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.31, "played_steps": 1.26, "reached_maximum_moves": 0.02}, "Total num played games": 5760, "Total num trained steps": 10986, "Timestamp in ms": 1700507128539, "logtype": "played_game"}
{"Ratio train steps to played games": 1.902194574045274, "Avg loss": 0.8341759173199534, "Avg value loss": 0.4866031481651589, "Avg policy loss": 0.34757277136668563, "Total num played games": 5787, "Total num trained steps": 11008, "Timestamp in ms": 1700507139819, "logtype": "training_step"}
{"Ratio train steps to played games": 1.907331277834875, "Avg loss": 0.9510757173411548, "Avg value loss": 0.6004823078401387, "Avg policy loss": 0.3505934134591371, "Total num played games": 5838, "Total num trained steps": 11136, "Timestamp in ms": 1700507208306, "logtype": "training_step"}
{"Avg objective": 22.131796874999992, "Games time in secs": 143.68363624066114, "Avg game time in secs": 6.017210738908034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.67}, "Total num played games": 5888, "Total num trained steps": 11255, "Timestamp in ms": 1700507272223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9030241594863997, "Avg loss": 0.8659359747543931, "Avg value loss": 0.5061505089979619, "Avg policy loss": 0.3597854662220925, "Total num played games": 5918, "Total num trained steps": 11264, "Timestamp in ms": 1700507276675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9046982110015047, "Avg loss": 1.03286950616166, "Avg value loss": 0.6814741312991828, "Avg policy loss": 0.35139538277871907, "Total num played games": 5981, "Total num trained steps": 11392, "Timestamp in ms": 1700507345997, "logtype": "training_step"}
{"Total num played games": 5982, "Total num trained steps": 11436, "Timestamp in ms": 1700507460262, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.529218750000005}
{"Avg objective": 20.590312499999996, "Games time in secs": 193.57470704428852, "Avg game time in secs": 11.179554342423216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.24, "played_steps": 1.48, "reached_maximum_moves": 0.05}, "Total num played games": 6016, "Total num trained steps": 11444, "Timestamp in ms": 1700507465798, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9123505976095618, "Avg loss": 0.9026637859642506, "Avg value loss": 0.5478937528096139, "Avg policy loss": 0.3547700318740681, "Total num played games": 6024, "Total num trained steps": 11520, "Timestamp in ms": 1700507505756, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9063829787234043, "Avg loss": 0.8043052311986685, "Avg value loss": 0.45939714403357357, "Avg policy loss": 0.34490808355621994, "Total num played games": 6110, "Total num trained steps": 11648, "Timestamp in ms": 1700507574260, "logtype": "training_step"}
{"Avg objective": 21.272656249999997, "Games time in secs": 151.7614623364061, "Avg game time in secs": 8.535323115764186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 1.11, "agent_stopped_0": 0.65, "reached_maximum_moves": 0.02}, "Total num played games": 6144, "Total num trained steps": 11727, "Timestamp in ms": 1700507617560, "logtype": "played_game"}
{"Ratio train steps to played games": 1.910757747850073, "Avg loss": 0.8430262748152018, "Avg value loss": 0.5036379339871928, "Avg policy loss": 0.339388340478763, "Total num played games": 6163, "Total num trained steps": 11776, "Timestamp in ms": 1700507642829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9164385767187249, "Avg loss": 0.7821401259861887, "Avg value loss": 0.44904499512631446, "Avg policy loss": 0.33309512969572097, "Total num played games": 6211, "Total num trained steps": 11904, "Timestamp in ms": 1700507714429, "logtype": "training_step"}
{"Avg objective": 19.694531249999997, "Games time in secs": 157.14993556588888, "Avg game time in secs": 8.938269332356867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.31, "played_steps": 1.21, "reached_maximum_moves": 0.02}, "Total num played games": 6272, "Total num trained steps": 12015, "Timestamp in ms": 1700507774710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9084708121827412, "Avg loss": 0.8683906574733555, "Avg value loss": 0.545204543042928, "Avg policy loss": 0.32318612036760896, "Total num played games": 6304, "Total num trained steps": 12032, "Timestamp in ms": 1700507783182, "logtype": "training_step"}
{"Total num played games": 6310, "Total num trained steps": 12037, "Timestamp in ms": 1700507879435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.69421875}
{"Ratio train steps to played games": 1.9128519742016674, "Avg loss": 0.8816502569243312, "Avg value loss": 0.5519838884938508, "Avg policy loss": 0.32966636470519006, "Total num played games": 6357, "Total num trained steps": 12160, "Timestamp in ms": 1700507947790, "logtype": "training_step"}
{"Avg objective": 21.88437499999999, "Games time in secs": 206.87595434114337, "Avg game time in secs": 5.478595337699517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.67}, "Total num played games": 6400, "Total num trained steps": 12222, "Timestamp in ms": 1700507981586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9179022943655377, "Avg loss": 0.7774491899181157, "Avg value loss": 0.46918236277997494, "Avg policy loss": 0.30826683109626174, "Total num played games": 6407, "Total num trained steps": 12288, "Timestamp in ms": 1700508019659, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9104477611940298, "Avg loss": 0.7644672919996083, "Avg value loss": 0.4494081868324429, "Avg policy loss": 0.31505910714622587, "Total num played games": 6499, "Total num trained steps": 12416, "Timestamp in ms": 1700508087964, "logtype": "training_step"}
{"Avg objective": 21.3053125, "Games time in secs": 153.97029696777463, "Avg game time in secs": 5.122368978118175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.62, "agent_stopped_0": 0.7}, "Total num played games": 6528, "Total num trained steps": 12499, "Timestamp in ms": 1700508135557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9156994502138058, "Avg loss": 0.8583494150079787, "Avg value loss": 0.5407874804222956, "Avg policy loss": 0.3175619358662516, "Total num played games": 6548, "Total num trained steps": 12544, "Timestamp in ms": 1700508159185, "logtype": "training_step"}
{"Total num played games": 6599, "Total num trained steps": 12637, "Timestamp in ms": 1700508285971, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.059140625000005}
{"Ratio train steps to played games": 1.9068472535741159, "Avg loss": 0.8443355527706444, "Avg value loss": 0.5361073871608824, "Avg policy loss": 0.3082281691022217, "Total num played games": 6645, "Total num trained steps": 12672, "Timestamp in ms": 1700508305414, "logtype": "training_step"}
{"Avg objective": 21.81906249999999, "Games time in secs": 230.42864845879376, "Avg game time in secs": 8.778539092600113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.37, "played_steps": 1.23, "reached_maximum_moves": 0.02}, "Total num played games": 6656, "Total num trained steps": 12785, "Timestamp in ms": 1700508365985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9134399760801315, "Avg loss": 0.6613225422333926, "Avg value loss": 0.35636288044042885, "Avg policy loss": 0.3049596647033468, "Total num played games": 6689, "Total num trained steps": 12800, "Timestamp in ms": 1700508373707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.917531889646989, "Avg loss": 0.810547795612365, "Avg value loss": 0.5125129726948217, "Avg policy loss": 0.29803482443094254, "Total num played games": 6742, "Total num trained steps": 12928, "Timestamp in ms": 1700508441517, "logtype": "training_step"}
{"Avg objective": 20.474999999999994, "Games time in secs": 106.15978460386395, "Avg game time in secs": 5.407338008924853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.62}, "Total num played games": 6784, "Total num trained steps": 12985, "Timestamp in ms": 1700508472145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.923394225103123, "Avg loss": 0.7004358328413218, "Avg value loss": 0.4053363107377663, "Avg policy loss": 0.2950995247811079, "Total num played games": 6788, "Total num trained steps": 13056, "Timestamp in ms": 1700508509744, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9157221737866899, "Avg loss": 0.666300539392978, "Avg value loss": 0.37514896725770086, "Avg policy loss": 0.2911515706218779, "Total num played games": 6882, "Total num trained steps": 13184, "Timestamp in ms": 1700508578047, "logtype": "training_step"}
{"Total num played games": 6886, "Total num trained steps": 13238, "Timestamp in ms": 1700508705369, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6392578125}
{"Avg objective": 19.994374999999998, "Games time in secs": 238.0240090545267, "Avg game time in secs": 7.025097112782532, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.91, "agent_stopped_0": 0.71, "reached_maximum_moves": 0.02}, "Total num played games": 6912, "Total num trained steps": 13246, "Timestamp in ms": 1700508710170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.920923520923521, "Avg loss": 0.7937405700795352, "Avg value loss": 0.5017946071457118, "Avg policy loss": 0.29194596281740814, "Total num played games": 6930, "Total num trained steps": 13312, "Timestamp in ms": 1700508744178, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9257773319959879, "Avg loss": 0.6838085348717868, "Avg value loss": 0.39631274703424424, "Avg policy loss": 0.2874957851599902, "Total num played games": 6979, "Total num trained steps": 13440, "Timestamp in ms": 1700508812895, "logtype": "training_step"}
{"Avg objective": 20.51257812499999, "Games time in secs": 163.2655944004655, "Avg game time in secs": 8.050313868719968, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.4, "played_steps": 1.18, "reached_maximum_moves": 0.02}, "Total num played games": 7040, "Total num trained steps": 13550, "Timestamp in ms": 1700508873435, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9184106334841629, "Avg loss": 0.9879173035733402, "Avg value loss": 0.6910712934331968, "Avg policy loss": 0.2968460050178692, "Total num played games": 7072, "Total num trained steps": 13568, "Timestamp in ms": 1700508882780, "logtype": "training_step"}
{"Ratio train steps to played games": 1.923865711476331, "Avg loss": 0.8056578729301691, "Avg value loss": 0.5033366457791999, "Avg policy loss": 0.30232122412417084, "Total num played games": 7119, "Total num trained steps": 13696, "Timestamp in ms": 1700508951941, "logtype": "training_step"}
{"Avg objective": 20.17593749999999, "Games time in secs": 147.51365911960602, "Avg game time in secs": 7.522596887021791, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.97, "reached_maximum_moves": 0.01}, "Total num played games": 7168, "Total num trained steps": 13823, "Timestamp in ms": 1700509020949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9280334728033472, "Avg loss": 0.7363423744682223, "Avg value loss": 0.43969897530041635, "Avg policy loss": 0.2966433991678059, "Total num played games": 7169, "Total num trained steps": 13824, "Timestamp in ms": 1700509021216, "logtype": "training_step"}
{"Total num played games": 7214, "Total num trained steps": 13839, "Timestamp in ms": 1700509118546, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.910898437500002}
{"Ratio train steps to played games": 1.921763085399449, "Avg loss": 1.0217979354783893, "Avg value loss": 0.721157168969512, "Avg policy loss": 0.30064076569397, "Total num played games": 7260, "Total num trained steps": 13952, "Timestamp in ms": 1700509178452, "logtype": "training_step"}
{"Avg objective": 21.145859374999993, "Games time in secs": 198.24453125149012, "Avg game time in secs": 8.03334799433651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.31, "played_steps": 1.09, "reached_maximum_moves": 0.02}, "Total num played games": 7296, "Total num trained steps": 14024, "Timestamp in ms": 1700509219194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.926919392363487, "Avg loss": 0.6793137267231941, "Avg value loss": 0.3861984856193885, "Avg policy loss": 0.29311523982323706, "Total num played games": 7307, "Total num trained steps": 14080, "Timestamp in ms": 1700509248337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9262472885032538, "Avg loss": 0.8095467514358461, "Avg value loss": 0.5110436019022018, "Avg policy loss": 0.29850314650684595, "Total num played games": 7376, "Total num trained steps": 14208, "Timestamp in ms": 1700509315164, "logtype": "training_step"}
{"Avg objective": 21.612968749999993, "Games time in secs": 145.26595246046782, "Avg game time in secs": 7.688443296268815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 1.1, "agent_stopped_0": 0.55, "reached_maximum_moves": 0.01}, "Total num played games": 7424, "Total num trained steps": 14300, "Timestamp in ms": 1700509364460, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9253290357238786, "Avg loss": 0.8800381643231958, "Avg value loss": 0.5815511809196323, "Avg policy loss": 0.298486971645616, "Total num played games": 7446, "Total num trained steps": 14336, "Timestamp in ms": 1700509383236, "logtype": "training_step"}
{"Total num played games": 7497, "Total num trained steps": 14440, "Timestamp in ms": 1700509530413, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.8733203125}
{"Ratio train steps to played games": 1.918678694613956, "Avg loss": 0.8752574126701802, "Avg value loss": 0.5719514242373407, "Avg policy loss": 0.3033059947192669, "Total num played games": 7538, "Total num trained steps": 14464, "Timestamp in ms": 1700509544637, "logtype": "training_step"}
{"Avg objective": 20.815546874999995, "Games time in secs": 245.7698779590428, "Avg game time in secs": 10.694028432902996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.4, "played_steps": 1.59, "reached_maximum_moves": 0.03}, "Total num played games": 7552, "Total num trained steps": 14580, "Timestamp in ms": 1700509610230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9240506329113924, "Avg loss": 0.8174853748641908, "Avg value loss": 0.5104096051072702, "Avg policy loss": 0.3070757775567472, "Total num played games": 7584, "Total num trained steps": 14592, "Timestamp in ms": 1700509616622, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9282158763426775, "Avg loss": 1.313379602972418, "Avg value loss": 0.9905943168560043, "Avg policy loss": 0.32278529228642583, "Total num played games": 7634, "Total num trained steps": 14720, "Timestamp in ms": 1700509685344, "logtype": "training_step"}
{"Avg objective": 22.21460937499999, "Games time in secs": 106.71686086058617, "Avg game time in secs": 6.765847133443458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.95}, "Total num played games": 7680, "Total num trained steps": 14778, "Timestamp in ms": 1700509716947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.932448262397501, "Avg loss": 0.9193202354945242, "Avg value loss": 0.5991566544398665, "Avg policy loss": 0.3201635858276859, "Total num played games": 7683, "Total num trained steps": 14848, "Timestamp in ms": 1700509757169, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9250546342717574, "Avg loss": 0.9622991317883134, "Avg value loss": 0.6443380062701181, "Avg policy loss": 0.31796112447045743, "Total num played games": 7779, "Total num trained steps": 14976, "Timestamp in ms": 1700509827468, "logtype": "training_step"}
{"Total num played games": 7782, "Total num trained steps": 15042, "Timestamp in ms": 1700509936029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.574609375}
{"Avg objective": 20.494921874999996, "Games time in secs": 223.69194349087775, "Avg game time in secs": 7.226545017198077, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"reached_maximum_moves": 0.02, "played_steps": 1.03, "agent_stopped_more": 0.35, "agent_stopped_0": 0.63}, "Total num played games": 7808, "Total num trained steps": 15050, "Timestamp in ms": 1700509940639, "logtype": "played_game"}
{"Ratio train steps to played games": 1.929109720270788, "Avg loss": 0.8049454889260232, "Avg value loss": 0.4862542866030708, "Avg policy loss": 0.31869119335897267, "Total num played games": 7829, "Total num trained steps": 15104, "Timestamp in ms": 1700509969684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9328680203045685, "Avg loss": 0.7691381887998432, "Avg value loss": 0.45798916346393526, "Avg policy loss": 0.31114902440458536, "Total num played games": 7880, "Total num trained steps": 15232, "Timestamp in ms": 1700510038053, "logtype": "training_step"}
{"Avg objective": 21.090859374999994, "Games time in secs": 159.53860170021653, "Avg game time in secs": 6.536239748224034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.91, "reached_maximum_moves": 0.01}, "Total num played games": 7936, "Total num trained steps": 15353, "Timestamp in ms": 1700510100178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.92782728756119, "Avg loss": 0.8158117001876235, "Avg value loss": 0.49972581781912595, "Avg policy loss": 0.31608588714152575, "Total num played games": 7967, "Total num trained steps": 15360, "Timestamp in ms": 1700510103349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9285269580376043, "Avg loss": 0.7777502264361829, "Avg value loss": 0.4685213409829885, "Avg policy loss": 0.30922888149507344, "Total num played games": 8031, "Total num trained steps": 15488, "Timestamp in ms": 1700510174927, "logtype": "training_step"}
{"Avg objective": 20.79828124999999, "Games time in secs": 111.32732125930488, "Avg game time in secs": 3.9247247760213213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.48}, "Total num played games": 8064, "Total num trained steps": 15557, "Timestamp in ms": 1700510211505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9329124891694516, "Avg loss": 0.6912028365768492, "Avg value loss": 0.37914303387515247, "Avg policy loss": 0.31205980386584997, "Total num played games": 8079, "Total num trained steps": 15616, "Timestamp in ms": 1700510244353, "logtype": "training_step"}
{"Total num played games": 8080, "Total num trained steps": 15644, "Timestamp in ms": 1700510299225, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.85421875}
{"Ratio train steps to played games": 1.936884842519685, "Avg loss": 0.681162704480812, "Avg value loss": 0.3706408181460574, "Avg policy loss": 0.31052189029287547, "Total num played games": 8128, "Total num trained steps": 15744, "Timestamp in ms": 1700510353037, "logtype": "training_step"}
{"Avg objective": 20.93304687499999, "Games time in secs": 198.34933299198747, "Avg game time in secs": 5.484996844097623, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.76}, "Total num played games": 8192, "Total num trained steps": 15847, "Timestamp in ms": 1700510409855, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9294918550936055, "Avg loss": 0.807149899424985, "Avg value loss": 0.49788798368535936, "Avg policy loss": 0.3092619217932224, "Total num played games": 8226, "Total num trained steps": 15872, "Timestamp in ms": 1700510422582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.933534743202417, "Avg loss": 0.8009493839927018, "Avg value loss": 0.47942936164326966, "Avg policy loss": 0.32152001827489585, "Total num played games": 8275, "Total num trained steps": 16000, "Timestamp in ms": 1700510486595, "logtype": "training_step"}
{"Avg objective": 20.45976562499999, "Games time in secs": 103.56563081778586, "Avg game time in secs": 4.185817886303994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.59}, "Total num played games": 8320, "Total num trained steps": 16056, "Timestamp in ms": 1700510513421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9370646168628394, "Avg loss": 0.7070851547177881, "Avg value loss": 0.3819109472678974, "Avg policy loss": 0.32517421257216483, "Total num played games": 8326, "Total num trained steps": 16128, "Timestamp in ms": 1700510550542, "logtype": "training_step"}
{"Total num played games": 8424, "Total num trained steps": 16244, "Timestamp in ms": 1700510689119, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.422734375}
{"Avg objective": 21.37328124999999, "Games time in secs": 179.7919724714011, "Avg game time in secs": 5.977523070425377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.89, "agent_stopped_0": 0.65}, "Total num played games": 8448, "Total num trained steps": 16253, "Timestamp in ms": 1700510693213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9218491369117994, "Avg loss": 0.8060165857896209, "Avg value loss": 0.48115881881676614, "Avg policy loss": 0.32485776324756444, "Total num played games": 8458, "Total num trained steps": 16256, "Timestamp in ms": 1700510694470, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9343565525383708, "Avg loss": 0.8665138387586921, "Avg value loss": 0.5329311789246276, "Avg policy loss": 0.3335826627444476, "Total num played games": 8470, "Total num trained steps": 16384, "Timestamp in ms": 1700510759836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9379107981220658, "Avg loss": 0.821465581888333, "Avg value loss": 0.5025567681295797, "Avg policy loss": 0.31890881271101534, "Total num played games": 8520, "Total num trained steps": 16512, "Timestamp in ms": 1700510824327, "logtype": "training_step"}
{"Avg objective": 21.49906249999999, "Games time in secs": 191.2330694962293, "Avg game time in secs": 6.823242420417955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.45, "played_steps": 1.07, "reached_maximum_moves": 0.01}, "Total num played games": 8576, "Total num trained steps": 16633, "Timestamp in ms": 1700510884446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.93420899686156, "Avg loss": 0.703766216756776, "Avg value loss": 0.3861940399510786, "Avg policy loss": 0.31757217925041914, "Total num played games": 8602, "Total num trained steps": 16640, "Timestamp in ms": 1700510887549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9345794392523366, "Avg loss": 0.7937889061868191, "Avg value loss": 0.4739244767697528, "Avg policy loss": 0.3198644338408485, "Total num played games": 8667, "Total num trained steps": 16768, "Timestamp in ms": 1700510950828, "logtype": "training_step"}
{"Avg objective": 20.49226562499999, "Games time in secs": 100.41092271916568, "Avg game time in secs": 4.058795057135285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.55}, "Total num played games": 8704, "Total num trained steps": 16838, "Timestamp in ms": 1700510984857, "logtype": "played_game"}
{"Total num played games": 8716, "Total num trained steps": 16847, "Timestamp in ms": 1700511080533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2395703125}
{"Ratio train steps to played games": 1.9279926965651033, "Avg loss": 0.8582273812498897, "Avg value loss": 0.5228565245633945, "Avg policy loss": 0.33537085040006787, "Total num played games": 8763, "Total num trained steps": 16896, "Timestamp in ms": 1700511103937, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9383967205647916, "Avg loss": 0.5845812945626676, "Avg value loss": 0.2573186957743019, "Avg policy loss": 0.32726259785704315, "Total num played games": 8782, "Total num trained steps": 17024, "Timestamp in ms": 1700511168882, "logtype": "training_step"}
{"Avg objective": 21.531718749999985, "Games time in secs": 233.17713599093258, "Avg game time in secs": 6.981244596783654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.1, "reached_maximum_moves": 0.01, "agent_stopped_0": 0.53}, "Total num played games": 8832, "Total num trained steps": 17125, "Timestamp in ms": 1700511218035, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9355603205055862, "Avg loss": 0.8499747940804809, "Avg value loss": 0.5210564832668751, "Avg policy loss": 0.3289182996377349, "Total num played games": 8861, "Total num trained steps": 17152, "Timestamp in ms": 1700511230217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9379766711529833, "Avg loss": 0.6894241923000664, "Avg value loss": 0.36925518477801234, "Avg policy loss": 0.32016900868620723, "Total num played games": 8916, "Total num trained steps": 17280, "Timestamp in ms": 1700511291624, "logtype": "training_step"}
{"Avg objective": 20.231015624999994, "Games time in secs": 101.3071829546243, "Avg game time in secs": 4.572459563569282, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.62}, "Total num played games": 8960, "Total num trained steps": 17333, "Timestamp in ms": 1700511319342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9416620189626324, "Avg loss": 0.6998837655410171, "Avg value loss": 0.3789327652193606, "Avg policy loss": 0.32095100078731775, "Total num played games": 8965, "Total num trained steps": 17408, "Timestamp in ms": 1700511357731, "logtype": "training_step"}
{"Total num played games": 9016, "Total num trained steps": 17447, "Timestamp in ms": 1700511446619, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.6829296875}
{"Ratio train steps to played games": 1.934576345984113, "Avg loss": 0.724243906326592, "Avg value loss": 0.39643136283848435, "Avg policy loss": 0.32781254313886166, "Total num played games": 9064, "Total num trained steps": 17536, "Timestamp in ms": 1700511489509, "logtype": "training_step"}
{"Avg objective": 20.655390624999992, "Games time in secs": 213.50168077088892, "Avg game time in secs": 4.022917686321307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.59, "agent_stopped_0": 0.63}, "Total num played games": 9088, "Total num trained steps": 17625, "Timestamp in ms": 1700511532844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9382201250960167, "Avg loss": 0.6743591376580298, "Avg value loss": 0.3542800573632121, "Avg policy loss": 0.3200790814589709, "Total num played games": 9113, "Total num trained steps": 17664, "Timestamp in ms": 1700511550660, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9409775256382282, "Avg loss": 0.8019745526835322, "Avg value loss": 0.4695777689339593, "Avg policy loss": 0.3323967873584479, "Total num played games": 9166, "Total num trained steps": 17792, "Timestamp in ms": 1700511613421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9445469343461748, "Avg loss": 0.6400424318853766, "Avg value loss": 0.3180512173566967, "Avg policy loss": 0.32199121278245, "Total num played games": 9215, "Total num trained steps": 17920, "Timestamp in ms": 1700511672529, "logtype": "training_step"}
{"Avg objective": 22.544687499999988, "Games time in secs": 139.92509525455534, "Avg game time in secs": 5.089468468780979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.88, "agent_stopped_0": 0.48}, "Total num played games": 9216, "Total num trained steps": 17920, "Timestamp in ms": 1700511672769, "logtype": "played_game"}
{"Total num played games": 9315, "Total num trained steps": 18046, "Timestamp in ms": 1700511814635, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.6465625}
{"Ratio train steps to played games": 1.9375201288244766, "Avg loss": 0.7760073107201606, "Avg value loss": 0.45009364769794047, "Avg policy loss": 0.32591365836560726, "Total num played games": 9315, "Total num trained steps": 18048, "Timestamp in ms": 1700511816343, "logtype": "training_step"}
{"Avg objective": 19.888828124999993, "Games time in secs": 146.4396726321429, "Avg game time in secs": 4.630206757399719, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.62}, "Total num played games": 9344, "Total num trained steps": 18055, "Timestamp in ms": 1700511819209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9411513403823561, "Avg loss": 0.8923703660257161, "Avg value loss": 0.5636326246894896, "Avg policy loss": 0.32873774180188775, "Total num played games": 9363, "Total num trained steps": 18176, "Timestamp in ms": 1700511878148, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9446451338716533, "Avg loss": 0.7951993814203888, "Avg value loss": 0.47091889183502644, "Avg policy loss": 0.3242804831825197, "Total num played games": 9412, "Total num trained steps": 18304, "Timestamp in ms": 1700511939222, "logtype": "training_step"}
{"Avg objective": 20.37781249999999, "Games time in secs": 172.71964889205992, "Avg game time in secs": 4.331746077456046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.77, "agent_stopped_0": 0.49}, "Total num played games": 9472, "Total num trained steps": 18419, "Timestamp in ms": 1700511991929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.940823417921449, "Avg loss": 0.7100531267933547, "Avg value loss": 0.3920415733009577, "Avg policy loss": 0.3180115567520261, "Total num played games": 9497, "Total num trained steps": 18432, "Timestamp in ms": 1700511997057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9414225941422594, "Avg loss": 0.7002409603446722, "Avg value loss": 0.3798130345530808, "Avg policy loss": 0.3204279232304543, "Total num played games": 9560, "Total num trained steps": 18560, "Timestamp in ms": 1700512056451, "logtype": "training_step"}
{"Avg objective": 20.72179687499999, "Games time in secs": 93.54148077778518, "Avg game time in secs": 4.736711341902264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.78}, "Total num played games": 9600, "Total num trained steps": 18623, "Timestamp in ms": 1700512085470, "logtype": "played_game"}
{"Total num played games": 9611, "Total num trained steps": 18649, "Timestamp in ms": 1700512185581, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.583906250000002}
{"Ratio train steps to played games": 1.9346723263277772, "Avg loss": 0.8932663316372782, "Avg value loss": 0.5620222247671336, "Avg policy loss": 0.3312441031448543, "Total num played games": 9659, "Total num trained steps": 18688, "Timestamp in ms": 1700512202975, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9417956656346749, "Avg loss": 0.5713454026263207, "Avg value loss": 0.2485886422218755, "Avg policy loss": 0.3227567586582154, "Total num played games": 9690, "Total num trained steps": 18816, "Timestamp in ms": 1700512264887, "logtype": "training_step"}
{"Avg objective": 21.460859374999988, "Games time in secs": 224.78259397111833, "Avg game time in secs": 3.6338274420704693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.59, "agent_stopped_0": 0.58}, "Total num played games": 9728, "Total num trained steps": 18913, "Timestamp in ms": 1700512310253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9410800286914642, "Avg loss": 0.868134951684624, "Avg value loss": 0.5326928277499974, "Avg policy loss": 0.33544212381821126, "Total num played games": 9759, "Total num trained steps": 18944, "Timestamp in ms": 1700512324003, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9440366972477063, "Avg loss": 0.9006674331612885, "Avg value loss": 0.5604436523281038, "Avg policy loss": 0.34022378153167665, "Total num played games": 9810, "Total num trained steps": 19072, "Timestamp in ms": 1700512385721, "logtype": "training_step"}
{"Avg objective": 20.02265624999999, "Games time in secs": 102.6119914073497, "Avg game time in secs": 4.430924401196535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.77}, "Total num played games": 9856, "Total num trained steps": 19126, "Timestamp in ms": 1700512412865, "logtype": "played_game"}
{"Ratio train steps to played games": 1.947261663286004, "Avg loss": 0.6957984988112003, "Avg value loss": 0.3669383549131453, "Avg policy loss": 0.32886015344411135, "Total num played games": 9860, "Total num trained steps": 19200, "Timestamp in ms": 1700512448858, "logtype": "training_step"}
{"Total num played games": 9910, "Total num trained steps": 19250, "Timestamp in ms": 1700512518057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.800976562500004}
{"Ratio train steps to played games": 1.9408515766218115, "Avg loss": 1.4077222347259521, "Avg value loss": 1.0526908476604149, "Avg policy loss": 0.35503138205967844, "Total num played games": 9958, "Total num trained steps": 19328, "Timestamp in ms": 1700512555473, "logtype": "training_step"}
{"Avg objective": 22.709531249999987, "Games time in secs": 183.92966688796878, "Avg game time in secs": 3.769133126246743, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.66, "agent_stopped_0": 0.55}, "Total num played games": 9984, "Total num trained steps": 19409, "Timestamp in ms": 1700512596795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.944239032677126, "Avg loss": 0.6883410832379013, "Avg value loss": 0.3526882454752922, "Avg policy loss": 0.3356528398580849, "Total num played games": 10007, "Total num trained steps": 19456, "Timestamp in ms": 1700512619922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9475882645450024, "Avg loss": 0.8145877986680716, "Avg value loss": 0.4817092348821461, "Avg policy loss": 0.3328785659978166, "Total num played games": 10055, "Total num trained steps": 19584, "Timestamp in ms": 1700512684698, "logtype": "training_step"}
{"Avg objective": 21.68687499999999, "Games time in secs": 143.85845877416432, "Avg game time in secs": 3.246254522659001, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.53}, "Total num played games": 10112, "Total num trained steps": 19697, "Timestamp in ms": 1700512740653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9423531730390224, "Avg loss": 0.7647792680654675, "Avg value loss": 0.43732395861297846, "Avg policy loss": 0.32745530479587615, "Total num played games": 10148, "Total num trained steps": 19712, "Timestamp in ms": 1700512748313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9442375539004313, "Avg loss": 0.8039257798809558, "Avg value loss": 0.4701606126036495, "Avg policy loss": 0.3337651623878628, "Total num played games": 10204, "Total num trained steps": 19840, "Timestamp in ms": 1700512814428, "logtype": "training_step"}
{"Total num played games": 10204, "Total num trained steps": 19853, "Timestamp in ms": 1700512909058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.510859375000003}
{"Avg objective": 21.468515624999995, "Games time in secs": 173.6583551503718, "Avg game time in secs": 3.263315448843059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.54}, "Total num played games": 10240, "Total num trained steps": 19862, "Timestamp in ms": 1700512914312, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9477175185329691, "Avg loss": 0.7176481063943356, "Avg value loss": 0.3806741709122434, "Avg policy loss": 0.33697393420152366, "Total num played games": 10252, "Total num trained steps": 19968, "Timestamp in ms": 1700512968602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.94521343529184, "Avg loss": 0.5693848591763526, "Avg value loss": 0.24824096279917285, "Avg policy loss": 0.3211438925936818, "Total num played games": 10331, "Total num trained steps": 20096, "Timestamp in ms": 1700513034673, "logtype": "training_step"}
{"Avg objective": 20.546953124999987, "Games time in secs": 167.24912238307297, "Avg game time in secs": 3.6043455379549414, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.64, "agent_stopped_0": 0.59}, "Total num played games": 10368, "Total num trained steps": 20190, "Timestamp in ms": 1700513081561, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9449894210425083, "Avg loss": 0.7780382335186005, "Avg value loss": 0.45493940520100296, "Avg policy loss": 0.32309882703702897, "Total num played games": 10398, "Total num trained steps": 20224, "Timestamp in ms": 1700513097905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948305571510626, "Avg loss": 0.8431476324331015, "Avg value loss": 0.5137347488198429, "Avg policy loss": 0.32941288233269006, "Total num played games": 10446, "Total num trained steps": 20352, "Timestamp in ms": 1700513161977, "logtype": "training_step"}
{"Total num played games": 10495, "Total num trained steps": 20453, "Timestamp in ms": 1700513297530, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.52515625}
{"Avg objective": 21.980234374999988, "Games time in secs": 217.12751476839185, "Avg game time in secs": 3.9669169797125505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.79}, "Total num played games": 10496, "Total num trained steps": 20453, "Timestamp in ms": 1700513298689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9425211040500807, "Avg loss": 0.8275411003269255, "Avg value loss": 0.5023984418949112, "Avg policy loss": 0.32514265226200223, "Total num played games": 10543, "Total num trained steps": 20480, "Timestamp in ms": 1700513312216, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9458030403172506, "Avg loss": 0.6883381525985897, "Avg value loss": 0.3743493772344664, "Avg policy loss": 0.31398877676110715, "Total num played games": 10591, "Total num trained steps": 20608, "Timestamp in ms": 1700513377153, "logtype": "training_step"}
{"Avg objective": 22.021718749999994, "Games time in secs": 112.77867997251451, "Avg game time in secs": 2.668659670598572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.45}, "Total num played games": 10624, "Total num trained steps": 20680, "Timestamp in ms": 1700513411468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9485950568555588, "Avg loss": 0.7890393049456179, "Avg value loss": 0.473125719698146, "Avg policy loss": 0.3159135876921937, "Total num played games": 10641, "Total num trained steps": 20736, "Timestamp in ms": 1700513438633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.951454494434571, "Avg loss": 0.6638019371312112, "Avg value loss": 0.35396162257529795, "Avg policy loss": 0.30984031839761883, "Total num played games": 10691, "Total num trained steps": 20864, "Timestamp in ms": 1700513496689, "logtype": "training_step"}
{"Avg objective": 20.15281249999999, "Games time in secs": 137.13767877221107, "Avg game time in secs": 3.841191762883682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.7}, "Total num played games": 10752, "Total num trained steps": 20978, "Timestamp in ms": 1700513548606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9452321378926885, "Avg loss": 0.7322270299773663, "Avg value loss": 0.4163403328275308, "Avg policy loss": 0.31588670215569437, "Total num played games": 10791, "Total num trained steps": 20992, "Timestamp in ms": 1700513553973, "logtype": "training_step"}
{"Total num played games": 10793, "Total num trained steps": 21054, "Timestamp in ms": 1700513674357, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.448710937500003}
{"Ratio train steps to played games": 1.9481597638594226, "Avg loss": 0.7937758441548795, "Avg value loss": 0.4795767298201099, "Avg policy loss": 0.31419911968987435, "Total num played games": 10841, "Total num trained steps": 21120, "Timestamp in ms": 1700513704692, "logtype": "training_step"}
{"Avg objective": 21.438281249999992, "Games time in secs": 185.49480333179235, "Avg game time in secs": 3.078523166186642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.55}, "Total num played games": 10880, "Total num trained steps": 21183, "Timestamp in ms": 1700513734102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.951147842056933, "Avg loss": 0.6529278897214681, "Avg value loss": 0.33678520377725363, "Avg policy loss": 0.3161426918813959, "Total num played games": 10890, "Total num trained steps": 21248, "Timestamp in ms": 1700513763264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9476082004555808, "Avg loss": 0.8748628788162023, "Avg value loss": 0.5494989731814712, "Avg policy loss": 0.3253639080794528, "Total num played games": 10975, "Total num trained steps": 21376, "Timestamp in ms": 1700513821449, "logtype": "training_step"}
{"Avg objective": 22.44578124999999, "Games time in secs": 133.00932581909, "Avg game time in secs": 3.414311718326644, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.64, "agent_stopped_0": 0.59}, "Total num played games": 11008, "Total num trained steps": 21475, "Timestamp in ms": 1700513867111, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9480884218155463, "Avg loss": 0.9187031178735197, "Avg value loss": 0.5977164038922638, "Avg policy loss": 0.32098670746199787, "Total num played games": 11038, "Total num trained steps": 21504, "Timestamp in ms": 1700513880371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.951023721475602, "Avg loss": 0.7174075359944254, "Avg value loss": 0.39144467178266495, "Avg policy loss": 0.3259628595551476, "Total num played games": 11087, "Total num trained steps": 21632, "Timestamp in ms": 1700513938843, "logtype": "training_step"}
{"Total num played games": 11087, "Total num trained steps": 21656, "Timestamp in ms": 1700514040021, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.517695312500003}
{"Ratio train steps to played games": 1.9541984732824427, "Avg loss": 0.6801416343078017, "Avg value loss": 0.3614670533570461, "Avg policy loss": 0.31867458194028586, "Total num played games": 11135, "Total num trained steps": 21760, "Timestamp in ms": 1700514087537, "logtype": "training_step"}
{"Avg objective": 21.776328124999992, "Games time in secs": 220.62934644147754, "Avg game time in secs": 3.9738648878847016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.84, "agent_stopped_0": 0.44}, "Total num played games": 11136, "Total num trained steps": 21760, "Timestamp in ms": 1700514087740, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9481085892300845, "Avg loss": 0.9698127789888531, "Avg value loss": 0.6506587699986994, "Avg policy loss": 0.3191540129482746, "Total num played games": 11235, "Total num trained steps": 21888, "Timestamp in ms": 1700514148113, "logtype": "training_step"}
{"Avg objective": 23.096484374999996, "Games time in secs": 97.34929930046201, "Avg game time in secs": 2.6010680896724807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.34}, "Total num played games": 11264, "Total num trained steps": 21968, "Timestamp in ms": 1700514185090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9508196721311475, "Avg loss": 0.7743328446522355, "Avg value loss": 0.4643790596164763, "Avg policy loss": 0.30995378305669874, "Total num played games": 11285, "Total num trained steps": 22016, "Timestamp in ms": 1700514207868, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9536791953414505, "Avg loss": 0.764089462114498, "Avg value loss": 0.4580877487314865, "Avg policy loss": 0.306001715012826, "Total num played games": 11334, "Total num trained steps": 22144, "Timestamp in ms": 1700514268467, "logtype": "training_step"}
{"Avg objective": 21.717265624999982, "Games time in secs": 140.1915123667568, "Avg game time in secs": 3.7942952362791402, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.78, "agent_stopped_0": 0.51}, "Total num played games": 11392, "Total num trained steps": 22255, "Timestamp in ms": 1700514325282, "logtype": "played_game"}
{"Total num played games": 11431, "Total num trained steps": 22255, "Timestamp in ms": 1700514417612, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2133984375}
{"Ratio train steps to played games": 1.9412533774949883, "Avg loss": 0.9223463556263596, "Avg value loss": 0.6090364109841175, "Avg policy loss": 0.31330993329174817, "Total num played games": 11473, "Total num trained steps": 22272, "Timestamp in ms": 1700514426391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95138949385835, "Avg loss": 0.7509160377085209, "Avg value loss": 0.42127167258877307, "Avg policy loss": 0.32964437478221953, "Total num played games": 11479, "Total num trained steps": 22400, "Timestamp in ms": 1700514487704, "logtype": "training_step"}
{"Avg objective": 21.766953124999997, "Games time in secs": 189.22395724616945, "Avg game time in secs": 3.0597595625877148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.51}, "Total num played games": 11520, "Total num trained steps": 22454, "Timestamp in ms": 1700514514506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9539422326307572, "Avg loss": 0.632945419754833, "Avg value loss": 0.3231084290309809, "Avg policy loss": 0.3098369942745194, "Total num played games": 11529, "Total num trained steps": 22528, "Timestamp in ms": 1700514551052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9501592493759146, "Avg loss": 0.7075653155334294, "Avg value loss": 0.3961648785043508, "Avg policy loss": 0.31140043935738504, "Total num played games": 11617, "Total num trained steps": 22656, "Timestamp in ms": 1700514608764, "logtype": "training_step"}
{"Avg objective": 21.284218749999987, "Games time in secs": 136.6798995975405, "Avg game time in secs": 3.1962902604282135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.59, "agent_stopped_0": 0.62}, "Total num played games": 11648, "Total num trained steps": 22749, "Timestamp in ms": 1700514651186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9515203426124197, "Avg loss": 0.8123763813637197, "Avg value loss": 0.5068844527704641, "Avg policy loss": 0.3054919251007959, "Total num played games": 11675, "Total num trained steps": 22784, "Timestamp in ms": 1700514666908, "logtype": "training_step"}
{"Total num played games": 11725, "Total num trained steps": 22856, "Timestamp in ms": 1700514794862, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.975234375000003}
{"Ratio train steps to played games": 1.9460630255669753, "Avg loss": 0.9382215170189738, "Avg value loss": 0.6177744563901797, "Avg policy loss": 0.32044706179294735, "Total num played games": 11773, "Total num trained steps": 22912, "Timestamp in ms": 1700514820019, "logtype": "training_step"}
{"Avg objective": 20.818593749999984, "Games time in secs": 226.84407002851367, "Avg game time in secs": 4.27155490363657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.9}, "Total num played games": 11776, "Total num trained steps": 23037, "Timestamp in ms": 1700514878030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.953782225237449, "Avg loss": 0.6181927560828626, "Avg value loss": 0.29692144982982427, "Avg policy loss": 0.3212713012471795, "Total num played games": 11792, "Total num trained steps": 23040, "Timestamp in ms": 1700514878910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9513982479784366, "Avg loss": 0.7679047097917646, "Avg value loss": 0.4347786548314616, "Avg policy loss": 0.33312605938408524, "Total num played games": 11872, "Total num trained steps": 23168, "Timestamp in ms": 1700514937786, "logtype": "training_step"}
{"Avg objective": 19.945078124999995, "Games time in secs": 93.9479552526027, "Avg game time in secs": 2.7580990287533496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.49}, "Total num played games": 11904, "Total num trained steps": 23241, "Timestamp in ms": 1700514971978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9541984732824427, "Avg loss": 0.7605044548399746, "Avg value loss": 0.4353165979264304, "Avg policy loss": 0.32518785900902003, "Total num played games": 11921, "Total num trained steps": 23296, "Timestamp in ms": 1700514997180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9570557272955134, "Avg loss": 0.7897893802728504, "Avg value loss": 0.45198624883778393, "Avg policy loss": 0.33780312933959067, "Total num played games": 11969, "Total num trained steps": 23424, "Timestamp in ms": 1700515055353, "logtype": "training_step"}
{"Total num played games": 12018, "Total num trained steps": 23459, "Timestamp in ms": 1700515165718, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9922265625}
{"Avg objective": 20.591874999999987, "Games time in secs": 195.7953326497227, "Avg game time in secs": 3.9523413607821567, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.9, "agent_stopped_0": 0.5}, "Total num played games": 12032, "Total num trained steps": 23461, "Timestamp in ms": 1700515167773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9518481684070943, "Avg loss": 0.8056632571388036, "Avg value loss": 0.46321663982234895, "Avg policy loss": 0.34244661405682564, "Total num played games": 12066, "Total num trained steps": 23552, "Timestamp in ms": 1700515208773, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9546017333883616, "Avg loss": 0.6772160949185491, "Avg value loss": 0.34410371840931475, "Avg policy loss": 0.333112376392819, "Total num played games": 12115, "Total num trained steps": 23680, "Timestamp in ms": 1700515267543, "logtype": "training_step"}
{"Avg objective": 20.404374999999984, "Games time in secs": 123.44186803512275, "Avg game time in secs": 3.357695303464425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.69, "agent_stopped_0": 0.51}, "Total num played games": 12160, "Total num trained steps": 23734, "Timestamp in ms": 1700515291215, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9570078092889438, "Avg loss": 0.7026435688603669, "Avg value loss": 0.3689893784467131, "Avg policy loss": 0.3336541884345934, "Total num played games": 12165, "Total num trained steps": 23808, "Timestamp in ms": 1700515325285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9525246757484298, "Avg loss": 1.0117752698715776, "Avg value loss": 0.6684408321743831, "Avg policy loss": 0.34333444107323885, "Total num played games": 12259, "Total num trained steps": 23936, "Timestamp in ms": 1700515382453, "logtype": "training_step"}
{"Avg objective": 22.054062499999993, "Games time in secs": 133.32648351415992, "Avg game time in secs": 3.591450390260434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.76, "agent_stopped_0": 0.52}, "Total num played games": 12288, "Total num trained steps": 24019, "Timestamp in ms": 1700515424542, "logtype": "played_game"}
{"Total num played games": 12311, "Total num trained steps": 24061, "Timestamp in ms": 1700515529412, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.505312500000002}
{"Ratio train steps to played games": 1.951581508515815, "Avg loss": 0.9078642858657986, "Avg value loss": 0.5719397694338113, "Avg policy loss": 0.33592450991272926, "Total num played games": 12330, "Total num trained steps": 24064, "Timestamp in ms": 1700515531988, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9574399223238126, "Avg loss": 0.6449265400879085, "Avg value loss": 0.31229330331552774, "Avg policy loss": 0.3326332395663485, "Total num played games": 12359, "Total num trained steps": 24192, "Timestamp in ms": 1700515594834, "logtype": "training_step"}
{"Avg objective": 22.27781249999999, "Games time in secs": 225.8959542810917, "Avg game time in secs": 3.233557447922067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.66}, "Total num played games": 12416, "Total num trained steps": 24304, "Timestamp in ms": 1700515650438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9520025684244322, "Avg loss": 0.8485442064702511, "Avg value loss": 0.5208306808490306, "Avg policy loss": 0.3277135160751641, "Total num played games": 12459, "Total num trained steps": 24320, "Timestamp in ms": 1700515657864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9538842710997442, "Avg loss": 0.8235477665439248, "Avg value loss": 0.4970764088211581, "Avg policy loss": 0.32647135329898447, "Total num played games": 12512, "Total num trained steps": 24448, "Timestamp in ms": 1700515721990, "logtype": "training_step"}
{"Avg objective": 21.24507812499999, "Games time in secs": 108.24085654132068, "Avg game time in secs": 2.856069696441409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.58}, "Total num played games": 12544, "Total num trained steps": 24518, "Timestamp in ms": 1700515758679, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956608280254777, "Avg loss": 0.701860221568495, "Avg value loss": 0.37015029648318887, "Avg policy loss": 0.33170992915984243, "Total num played games": 12560, "Total num trained steps": 24576, "Timestamp in ms": 1700515787293, "logtype": "training_step"}
{"Total num played games": 12608, "Total num trained steps": 24664, "Timestamp in ms": 1700515922007, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.305820312500003}
{"Ratio train steps to played games": 1.9519595448798988, "Avg loss": 0.7702015123795718, "Avg value loss": 0.4368234818102792, "Avg policy loss": 0.33337802719324827, "Total num played games": 12656, "Total num trained steps": 24704, "Timestamp in ms": 1700515943655, "logtype": "training_step"}
{"Avg objective": 21.536406249999988, "Games time in secs": 238.99133440852165, "Avg game time in secs": 4.1352079211355885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.89, "agent_stopped_0": 0.51}, "Total num played games": 12672, "Total num trained steps": 24803, "Timestamp in ms": 1700515997670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9546599496221662, "Avg loss": 0.692123246146366, "Avg value loss": 0.354583284817636, "Avg policy loss": 0.3375399641226977, "Total num played games": 12704, "Total num trained steps": 24832, "Timestamp in ms": 1700516012642, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9570330876587738, "Avg loss": 0.7499549859203398, "Avg value loss": 0.41410121868830174, "Avg policy loss": 0.3358537689782679, "Total num played games": 12754, "Total num trained steps": 24960, "Timestamp in ms": 1700516078999, "logtype": "training_step"}
{"Avg objective": 21.837265624999986, "Games time in secs": 106.5824617985636, "Avg game time in secs": 3.171569026017096, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.7}, "Total num played games": 12800, "Total num trained steps": 25010, "Timestamp in ms": 1700516104253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9594626259470436, "Avg loss": 0.7792481235228479, "Avg value loss": 0.44129372551105917, "Avg policy loss": 0.33795439219102263, "Total num played games": 12803, "Total num trained steps": 25088, "Timestamp in ms": 1700516143921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9547286821705427, "Avg loss": 0.7850175453349948, "Avg value loss": 0.4463496912503615, "Avg policy loss": 0.3386678551323712, "Total num played games": 12900, "Total num trained steps": 25216, "Timestamp in ms": 1700516207724, "logtype": "training_step"}
{"Total num played games": 12900, "Total num trained steps": 25265, "Timestamp in ms": 1700516310119, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.7627734375}
{"Avg objective": 21.419374999999995, "Games time in secs": 210.05960574187338, "Avg game time in secs": 3.1882773520046612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.62, "agent_stopped_0": 0.6}, "Total num played games": 12928, "Total num trained steps": 25272, "Timestamp in ms": 1700516314313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957290701266605, "Avg loss": 0.8957430359441787, "Avg value loss": 0.5523280322086066, "Avg policy loss": 0.34341500559821725, "Total num played games": 12948, "Total num trained steps": 25344, "Timestamp in ms": 1700516352153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9599876885195444, "Avg loss": 0.819106916198507, "Avg value loss": 0.4806295383023098, "Avg policy loss": 0.33847737626638263, "Total num played games": 12996, "Total num trained steps": 25472, "Timestamp in ms": 1700516418522, "logtype": "training_step"}
{"Avg objective": 20.578281249999982, "Games time in secs": 159.06979406438768, "Avg game time in secs": 3.56084970626398, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.78, "agent_stopped_0": 0.5}, "Total num played games": 13056, "Total num trained steps": 25581, "Timestamp in ms": 1700516473383, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9555419754029486, "Avg loss": 0.8068489606957883, "Avg value loss": 0.4636331652291119, "Avg policy loss": 0.34321579337120056, "Total num played games": 13091, "Total num trained steps": 25600, "Timestamp in ms": 1700516482559, "logtype": "training_step"}
{"Ratio train steps to played games": 1.957692893014762, "Avg loss": 0.7481382926926017, "Avg value loss": 0.4060256283264607, "Avg policy loss": 0.3421126629691571, "Total num played games": 13142, "Total num trained steps": 25728, "Timestamp in ms": 1700516547426, "logtype": "training_step"}
{"Avg objective": 20.808984374999987, "Games time in secs": 104.33437936194241, "Avg game time in secs": 3.031649652199121, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 13184, "Total num trained steps": 25786, "Timestamp in ms": 1700516577717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960048517928891, "Avg loss": 0.6687484853900969, "Avg value loss": 0.32375208265148103, "Avg policy loss": 0.344996404601261, "Total num played games": 13191, "Total num trained steps": 25856, "Timestamp in ms": 1700516615985, "logtype": "training_step"}
{"Total num played games": 13191, "Total num trained steps": 25868, "Timestamp in ms": 1700516708283, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.05703125}
{"Ratio train steps to played games": 1.9555956950402649, "Avg loss": 0.7092423993162811, "Avg value loss": 0.36462624557316303, "Avg policy loss": 0.34461615164764225, "Total num played games": 13287, "Total num trained steps": 25984, "Timestamp in ms": 1700516770913, "logtype": "training_step"}
{"Avg objective": 19.81617187499999, "Games time in secs": 235.17253992334008, "Avg game time in secs": 2.8193456284498097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.54, "agent_stopped_0": 0.58}, "Total num played games": 13312, "Total num trained steps": 26067, "Timestamp in ms": 1700516812890, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9581552305961756, "Avg loss": 0.7897374231833965, "Avg value loss": 0.44985140895005316, "Avg policy loss": 0.339886020636186, "Total num played games": 13335, "Total num trained steps": 26112, "Timestamp in ms": 1700516836577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960696405888067, "Avg loss": 0.7532448614947498, "Avg value loss": 0.41431582905352116, "Avg policy loss": 0.33892903523519635, "Total num played games": 13383, "Total num trained steps": 26240, "Timestamp in ms": 1700516903808, "logtype": "training_step"}
{"Avg objective": 21.13960937499998, "Games time in secs": 150.05154645256698, "Avg game time in secs": 3.3021848737844266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.7}, "Total num played games": 13440, "Total num trained steps": 26355, "Timestamp in ms": 1700516962941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956518513022186, "Avg loss": 0.7288607063237578, "Avg value loss": 0.3980312357307412, "Avg policy loss": 0.33082946960348636, "Total num played games": 13477, "Total num trained steps": 26368, "Timestamp in ms": 1700516968883, "logtype": "training_step"}
{"Total num played games": 13529, "Total num trained steps": 26469, "Timestamp in ms": 1700517097334, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.925585937500003}
{"Avg objective": 21.368437499999995, "Games time in secs": 139.27022540010512, "Avg game time in secs": 2.587312711359118, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.52}, "Total num played games": 13568, "Total num trained steps": 26477, "Timestamp in ms": 1700517102212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9516794342958161, "Avg loss": 0.8814785496797413, "Avg value loss": 0.5518910015234724, "Avg policy loss": 0.32958754641003907, "Total num played games": 13576, "Total num trained steps": 26496, "Timestamp in ms": 1700517111037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960963393975105, "Avg loss": 0.5447327874135226, "Avg value loss": 0.22135584760690108, "Avg policy loss": 0.3233769453363493, "Total num played games": 13577, "Total num trained steps": 26624, "Timestamp in ms": 1700517175971, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9569129480614484, "Avg loss": 0.623901738319546, "Avg value loss": 0.31287310156039894, "Avg policy loss": 0.31102863559499383, "Total num played games": 13670, "Total num trained steps": 26752, "Timestamp in ms": 1700517241383, "logtype": "training_step"}
{"Avg objective": 20.763671874999996, "Games time in secs": 183.12992633879185, "Avg game time in secs": 3.1092130551842274, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.64, "agent_stopped_0": 0.55}, "Total num played games": 13696, "Total num trained steps": 26838, "Timestamp in ms": 1700517285342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.958968005247431, "Avg loss": 0.9098654559347779, "Avg value loss": 0.5990224310662597, "Avg policy loss": 0.310843015788123, "Total num played games": 13721, "Total num trained steps": 26880, "Timestamp in ms": 1700517305603, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9614351078509695, "Avg loss": 0.6380188616458327, "Avg value loss": 0.32553125149570405, "Avg policy loss": 0.31248760945163667, "Total num played games": 13769, "Total num trained steps": 27008, "Timestamp in ms": 1700517369441, "logtype": "training_step"}
{"Total num played games": 13817, "Total num trained steps": 27071, "Timestamp in ms": 1700517474358, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.878671875000002}
{"Avg objective": 21.51460937499998, "Games time in secs": 191.14230444468558, "Avg game time in secs": 2.9414263319340535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.61}, "Total num played games": 13824, "Total num trained steps": 27072, "Timestamp in ms": 1700517476484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9571583122971512, "Avg loss": 1.038675463758409, "Avg value loss": 0.7205194071866572, "Avg policy loss": 0.3181560650700703, "Total num played games": 13865, "Total num trained steps": 27136, "Timestamp in ms": 1700517512745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9595342485445266, "Avg loss": 0.6193531558383256, "Avg value loss": 0.3035654394188896, "Avg policy loss": 0.3157877130433917, "Total num played games": 13913, "Total num trained steps": 27264, "Timestamp in ms": 1700517578517, "logtype": "training_step"}
{"Avg objective": 20.412890624999992, "Games time in secs": 131.8651005513966, "Avg game time in secs": 3.6377277232677443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.84}, "Total num played games": 13952, "Total num trained steps": 27323, "Timestamp in ms": 1700517608349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.961965475252489, "Avg loss": 0.5756535003893077, "Avg value loss": 0.2674831700278446, "Avg policy loss": 0.30817033094353974, "Total num played games": 13961, "Total num trained steps": 27392, "Timestamp in ms": 1700517643861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9585794605366167, "Avg loss": 0.7384130714926869, "Avg value loss": 0.4459877848858014, "Avg policy loss": 0.2924252827651799, "Total num played games": 14051, "Total num trained steps": 27520, "Timestamp in ms": 1700517709456, "logtype": "training_step"}
{"Avg objective": 21.233203124999992, "Games time in secs": 148.11664201319218, "Avg game time in secs": 2.819757270772243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.63, "agent_stopped_0": 0.6}, "Total num played games": 14080, "Total num trained steps": 27608, "Timestamp in ms": 1700517756466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.959946122217496, "Avg loss": 0.769735342822969, "Avg value loss": 0.4711164708714932, "Avg policy loss": 0.2986188706709072, "Total num played games": 14106, "Total num trained steps": 27648, "Timestamp in ms": 1700517778874, "logtype": "training_step"}
{"Total num played games": 14106, "Total num trained steps": 27674, "Timestamp in ms": 1700517881947, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.194375}
{"Ratio train steps to played games": 1.9623428006217323, "Avg loss": 0.8416685245465487, "Avg value loss": 0.5354945382568985, "Avg policy loss": 0.3061739900149405, "Total num played games": 14154, "Total num trained steps": 27776, "Timestamp in ms": 1700517939185, "logtype": "training_step"}
{"Avg objective": 21.225781249999986, "Games time in secs": 240.43892328441143, "Avg game time in secs": 3.3035685006470885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.77}, "Total num played games": 14208, "Total num trained steps": 27894, "Timestamp in ms": 1700517996905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9592051678135094, "Avg loss": 0.7088381666690111, "Avg value loss": 0.41919513419270515, "Avg policy loss": 0.28964303445536643, "Total num played games": 14242, "Total num trained steps": 27904, "Timestamp in ms": 1700518001549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9606910540672868, "Avg loss": 0.8279164363630116, "Avg value loss": 0.5206339840660803, "Avg policy loss": 0.30728245293721557, "Total num played games": 14297, "Total num trained steps": 28032, "Timestamp in ms": 1700518064316, "logtype": "training_step"}
{"Avg objective": 21.121171874999987, "Games time in secs": 99.72361204773188, "Avg game time in secs": 2.908230221932172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.59}, "Total num played games": 14336, "Total num trained steps": 28092, "Timestamp in ms": 1700518096629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9630533286859533, "Avg loss": 0.63251135754399, "Avg value loss": 0.33837881742510945, "Avg policy loss": 0.29413254256360233, "Total num played games": 14345, "Total num trained steps": 28160, "Timestamp in ms": 1700518131421, "logtype": "training_step"}
{"Total num played games": 14393, "Total num trained steps": 28274, "Timestamp in ms": 1700518301821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.3898828125}
{"Ratio train steps to played games": 1.9591384444906157, "Avg loss": 0.7817980591207743, "Avg value loss": 0.495913278311491, "Avg policy loss": 0.2858847862808034, "Total num played games": 14439, "Total num trained steps": 28288, "Timestamp in ms": 1700518309469, "logtype": "training_step"}
{"Avg objective": 22.568359374999982, "Games time in secs": 256.1589887402952, "Avg game time in secs": 3.4875540684442967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.77, "agent_stopped_0": 0.49}, "Total num played games": 14464, "Total num trained steps": 28374, "Timestamp in ms": 1700518352788, "logtype": "played_game"}
{"Ratio train steps to played games": 1.961211953896059, "Avg loss": 0.9244513628073037, "Avg value loss": 0.6348316997755319, "Avg policy loss": 0.2896196631481871, "Total num played games": 14489, "Total num trained steps": 28416, "Timestamp in ms": 1700518372679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9635413083854991, "Avg loss": 0.7026258602272719, "Avg value loss": 0.402641866938211, "Avg policy loss": 0.2999839980620891, "Total num played games": 14537, "Total num trained steps": 28544, "Timestamp in ms": 1700518435041, "logtype": "training_step"}
{"Avg objective": 21.249218749999983, "Games time in secs": 140.02361607179046, "Avg game time in secs": 3.4204779580031754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.8}, "Total num played games": 14592, "Total num trained steps": 28660, "Timestamp in ms": 1700518492812, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9599425798072323, "Avg loss": 0.7495960423257202, "Avg value loss": 0.4461009541992098, "Avg policy loss": 0.303495085448958, "Total num played games": 14629, "Total num trained steps": 28672, "Timestamp in ms": 1700518498365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9615856150388231, "Avg loss": 0.7774773924611509, "Avg value loss": 0.4761544461362064, "Avg policy loss": 0.3013229405041784, "Total num played games": 14682, "Total num trained steps": 28800, "Timestamp in ms": 1700518560120, "logtype": "training_step"}
{"Avg objective": 21.45828124999999, "Games time in secs": 96.18053603731096, "Avg game time in secs": 2.8022723689646227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.49}, "Total num played games": 14720, "Total num trained steps": 28860, "Timestamp in ms": 1700518588993, "logtype": "played_game"}
{"Total num played games": 14731, "Total num trained steps": 28874, "Timestamp in ms": 1700518671647, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.245000000000005}
{"Ratio train steps to played games": 1.957304283104405, "Avg loss": 0.7931377498898655, "Avg value loss": 0.49152270646300167, "Avg policy loss": 0.3016150443581864, "Total num played games": 14779, "Total num trained steps": 28928, "Timestamp in ms": 1700518699178, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9608584154406803, "Avg loss": 0.4798727857414633, "Avg value loss": 0.19337098847609013, "Avg policy loss": 0.286501799011603, "Total num played games": 14817, "Total num trained steps": 29056, "Timestamp in ms": 1700518762213, "logtype": "training_step"}
{"Avg objective": 20.19007812499999, "Games time in secs": 219.3280173074454, "Avg game time in secs": 2.891491113201482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.64, "agent_stopped_0": 0.56}, "Total num played games": 14848, "Total num trained steps": 29146, "Timestamp in ms": 1700518808321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9618176929282065, "Avg loss": 0.8209491947200149, "Avg value loss": 0.5198200420709327, "Avg policy loss": 0.3011291546281427, "Total num played games": 14876, "Total num trained steps": 29184, "Timestamp in ms": 1700518825953, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9640846957920128, "Avg loss": 0.601218351861462, "Avg value loss": 0.3057020122651011, "Avg policy loss": 0.29551633808296174, "Total num played games": 14924, "Total num trained steps": 29312, "Timestamp in ms": 1700518889811, "logtype": "training_step"}
{"Avg objective": 21.99843749999999, "Games time in secs": 142.46604049950838, "Avg game time in secs": 2.881519210000988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.63}, "Total num played games": 14976, "Total num trained steps": 29433, "Timestamp in ms": 1700518950787, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9617511827813687, "Avg loss": 0.6750634543132037, "Avg value loss": 0.39220374933211133, "Avg policy loss": 0.2828597108600661, "Total num played games": 15006, "Total num trained steps": 29440, "Timestamp in ms": 1700518954031, "logtype": "training_step"}
{"Total num played games": 15021, "Total num trained steps": 29474, "Timestamp in ms": 1700519056755, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.965117187500002}
{"Ratio train steps to played games": 1.9621739996018315, "Avg loss": 0.7148954088333994, "Avg value loss": 0.4209710197756067, "Avg policy loss": 0.2939243856817484, "Total num played games": 15069, "Total num trained steps": 29568, "Timestamp in ms": 1700519103252, "logtype": "training_step"}
{"Avg objective": 21.000156249999996, "Games time in secs": 183.81334680132568, "Avg game time in secs": 2.639901701666531, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.54}, "Total num played games": 15104, "Total num trained steps": 29631, "Timestamp in ms": 1700519134600, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964344777402924, "Avg loss": 0.6659217851702124, "Avg value loss": 0.38433590583736077, "Avg policy loss": 0.28158588404767215, "Total num played games": 15117, "Total num trained steps": 29696, "Timestamp in ms": 1700519165776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9628800842437804, "Avg loss": 0.5156342410482466, "Avg value loss": 0.2303349653375335, "Avg policy loss": 0.2852992796106264, "Total num played games": 15194, "Total num trained steps": 29824, "Timestamp in ms": 1700519229453, "logtype": "training_step"}
{"Avg objective": 20.368359374999983, "Games time in secs": 148.0851015392691, "Avg game time in secs": 2.9826736523391446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.6, "agent_stopped_0": 0.57}, "Total num played games": 15232, "Total num trained steps": 29917, "Timestamp in ms": 1700519282686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9624557725068799, "Avg loss": 0.7699588376563042, "Avg value loss": 0.4704179905820638, "Avg policy loss": 0.29954085021745414, "Total num played games": 15262, "Total num trained steps": 29952, "Timestamp in ms": 1700519300558, "logtype": "training_step"}
{"Total num played games": 15310, "Total num trained steps": 30074, "Timestamp in ms": 1700519454888, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.329375}
{"Ratio train steps to played games": 1.962549748809291, "Avg loss": 0.6422970441635698, "Avg value loss": 0.3490979161579162, "Avg policy loss": 0.29319912719074637, "Total num played games": 15327, "Total num trained steps": 30080, "Timestamp in ms": 1700519458518, "logtype": "training_step"}
{"Avg objective": 20.103124999999988, "Games time in secs": 240.3318987302482, "Avg game time in secs": 3.423948955751257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.76}, "Total num played games": 15360, "Total num trained steps": 30205, "Timestamp in ms": 1700519523018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9637261912500812, "Avg loss": 0.7867538852151483, "Avg value loss": 0.4812762589426711, "Avg policy loss": 0.30547762592323124, "Total num played games": 15382, "Total num trained steps": 30208, "Timestamp in ms": 1700519524632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962922220784263, "Avg loss": 0.7393318731337786, "Avg value loss": 0.4384645437821746, "Avg policy loss": 0.3008673205040395, "Total num played games": 15454, "Total num trained steps": 30336, "Timestamp in ms": 1700519588430, "logtype": "training_step"}
{"Avg objective": 21.793749999999992, "Games time in secs": 99.31624962948263, "Avg game time in secs": 2.7579835512151476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.57}, "Total num played games": 15488, "Total num trained steps": 30405, "Timestamp in ms": 1700519622334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9651657850599922, "Avg loss": 0.7032265313901007, "Avg value loss": 0.3913894410361536, "Avg policy loss": 0.31183709285687655, "Total num played games": 15502, "Total num trained steps": 30464, "Timestamp in ms": 1700519651055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648041104688503, "Avg loss": 0.7258751355111599, "Avg value loss": 0.40677002677693963, "Avg policy loss": 0.3191051100147888, "Total num played games": 15570, "Total num trained steps": 30592, "Timestamp in ms": 1700519713631, "logtype": "training_step"}
{"Total num played games": 15598, "Total num trained steps": 30676, "Timestamp in ms": 1700519836070, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.987148437500004}
{"Avg objective": 21.399375, "Games time in secs": 216.05964801087976, "Avg game time in secs": 3.334374715690501, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.73, "agent_stopped_0": 0.56}, "Total num played games": 15616, "Total num trained steps": 30680, "Timestamp in ms": 1700519838394, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9633772210149558, "Avg loss": 0.8888825373724103, "Avg value loss": 0.5787069060606882, "Avg policy loss": 0.3101756253745407, "Total num played games": 15646, "Total num trained steps": 30720, "Timestamp in ms": 1700519858127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9655919459666114, "Avg loss": 0.7754913105163723, "Avg value loss": 0.4622847130522132, "Avg policy loss": 0.31320659909397364, "Total num played games": 15694, "Total num trained steps": 30848, "Timestamp in ms": 1700519922217, "logtype": "training_step"}
{"Avg objective": 22.334296874999986, "Games time in secs": 145.26613584533334, "Avg game time in secs": 3.427266813290771, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.91}, "Total num played games": 15744, "Total num trained steps": 30974, "Timestamp in ms": 1700519983660, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9653575280756297, "Avg loss": 0.5920788494404405, "Avg value loss": 0.2817053362959996, "Avg policy loss": 0.3103735150070861, "Total num played games": 15760, "Total num trained steps": 30976, "Timestamp in ms": 1700519984695, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9637603384052023, "Avg loss": 0.7952581522986293, "Avg value loss": 0.4781280637253076, "Avg policy loss": 0.3171300911344588, "Total num played games": 15839, "Total num trained steps": 31104, "Timestamp in ms": 1700520048729, "logtype": "training_step"}
{"Avg objective": 21.900078124999993, "Games time in secs": 99.60571593232453, "Avg game time in secs": 3.6918300995457685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.8}, "Total num played games": 15872, "Total num trained steps": 31173, "Timestamp in ms": 1700520083266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.965884056146535, "Avg loss": 0.6190467271953821, "Avg value loss": 0.3021508288802579, "Avg policy loss": 0.31689589307643473, "Total num played games": 15887, "Total num trained steps": 31232, "Timestamp in ms": 1700520118521, "logtype": "training_step"}
{"Total num played games": 15938, "Total num trained steps": 31278, "Timestamp in ms": 1700520233101, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.186132812500006}
{"Ratio train steps to played games": 1.9617165019391969, "Avg loss": 0.9030616392847151, "Avg value loss": 0.5754677018267103, "Avg policy loss": 0.32759393309243023, "Total num played games": 15986, "Total num trained steps": 31360, "Timestamp in ms": 1700520275936, "logtype": "training_step"}
{"Avg objective": 21.398828124999984, "Games time in secs": 243.21839328482747, "Avg game time in secs": 3.564580330843455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.84, "agent_stopped_0": 0.47}, "Total num played games": 16000, "Total num trained steps": 31462, "Timestamp in ms": 1700520326485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9638268679057005, "Avg loss": 0.819611354265362, "Avg value loss": 0.4978805986465886, "Avg policy loss": 0.3217307501472533, "Total num played games": 16034, "Total num trained steps": 31488, "Timestamp in ms": 1700520338689, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9659246362392737, "Avg loss": 0.8868109141476452, "Avg value loss": 0.5553516725776717, "Avg policy loss": 0.33145923691336066, "Total num played games": 16082, "Total num trained steps": 31616, "Timestamp in ms": 1700520400265, "logtype": "training_step"}
{"Avg objective": 22.20601562499999, "Games time in secs": 101.57650566659868, "Avg game time in secs": 2.7530455154774245, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.66}, "Total num played games": 16128, "Total num trained steps": 31670, "Timestamp in ms": 1700520428062, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9678879176740438, "Avg loss": 0.6824899238999933, "Avg value loss": 0.35097780055366457, "Avg policy loss": 0.3315121231134981, "Total num played games": 16131, "Total num trained steps": 31744, "Timestamp in ms": 1700520465263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9641338509890922, "Avg loss": 0.7751330235041678, "Avg value loss": 0.44126759248320013, "Avg policy loss": 0.3338654324179515, "Total num played games": 16227, "Total num trained steps": 31872, "Timestamp in ms": 1700520527005, "logtype": "training_step"}
{"Total num played games": 16227, "Total num trained steps": 31878, "Timestamp in ms": 1700520647312, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.390625000000004}
{"Avg objective": 21.15843749999999, "Games time in secs": 222.85043382272124, "Avg game time in secs": 3.0067810317123076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.7, "agent_stopped_0": 0.59}, "Total num played games": 16256, "Total num trained steps": 31883, "Timestamp in ms": 1700520650912, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9661443932411675, "Avg loss": 0.7900423207320273, "Avg value loss": 0.44007824291475117, "Avg policy loss": 0.34996407199651003, "Total num played games": 16275, "Total num trained steps": 32000, "Timestamp in ms": 1700520711919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9676629103380696, "Avg loss": 0.719798693433404, "Avg value loss": 0.38654272974235937, "Avg policy loss": 0.33325596689246595, "Total num played games": 16328, "Total num trained steps": 32128, "Timestamp in ms": 1700520778916, "logtype": "training_step"}
{"Avg objective": 21.21890624999999, "Games time in secs": 183.61928790807724, "Avg game time in secs": 3.4085648866166594, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.78, "agent_stopped_0": 0.52}, "Total num played games": 16384, "Total num trained steps": 32243, "Timestamp in ms": 1700520834532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9640747731839494, "Avg loss": 0.6991088497452438, "Avg value loss": 0.3725544298067689, "Avg policy loss": 0.3265544258756563, "Total num played games": 16423, "Total num trained steps": 32256, "Timestamp in ms": 1700520840895, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965345633307034, "Avg loss": 0.702368798898533, "Avg value loss": 0.3638285008491948, "Avg policy loss": 0.3385402940912172, "Total num played games": 16477, "Total num trained steps": 32384, "Timestamp in ms": 1700520907364, "logtype": "training_step"}
{"Avg objective": 20.575781249999988, "Games time in secs": 105.83786087110639, "Avg game time in secs": 2.7275212008535163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 16512, "Total num trained steps": 32449, "Timestamp in ms": 1700520940370, "logtype": "played_game"}
{"Total num played games": 16525, "Total num trained steps": 32480, "Timestamp in ms": 1700521041187, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.496992187500002}
{"Ratio train steps to played games": 1.9617450069389972, "Avg loss": 0.7791711774189025, "Avg value loss": 0.4352581416023895, "Avg policy loss": 0.34391303081065416, "Total num played games": 16573, "Total num trained steps": 32512, "Timestamp in ms": 1700521057606, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966265060240964, "Avg loss": 0.5776091129519045, "Avg value loss": 0.23861486127134413, "Avg policy loss": 0.33899425342679024, "Total num played games": 16599, "Total num trained steps": 32640, "Timestamp in ms": 1700521121518, "logtype": "training_step"}
{"Avg objective": 21.949062499999982, "Games time in secs": 225.67655412480235, "Avg game time in secs": 3.011420969312894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.7, "agent_stopped_0": 0.47}, "Total num played games": 16640, "Total num trained steps": 32733, "Timestamp in ms": 1700521166046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9656868626274746, "Avg loss": 0.8508387033361942, "Avg value loss": 0.5198611314408481, "Avg policy loss": 0.33097757038194686, "Total num played games": 16670, "Total num trained steps": 32768, "Timestamp in ms": 1700521185026, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9676994855844, "Avg loss": 0.6170836116652936, "Avg value loss": 0.28175180370453745, "Avg policy loss": 0.3353318069130182, "Total num played games": 16718, "Total num trained steps": 32896, "Timestamp in ms": 1700521248102, "logtype": "training_step"}
{"Avg objective": 20.545156249999984, "Games time in secs": 104.70645312592387, "Avg game time in secs": 3.292872818376054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.85, "agent_stopped_0": 0.41}, "Total num played games": 16768, "Total num trained steps": 32945, "Timestamp in ms": 1700521270753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9691711389385809, "Avg loss": 0.7650109657552093, "Avg value loss": 0.4230775550240651, "Avg policy loss": 0.34193341084755957, "Total num played games": 16770, "Total num trained steps": 33024, "Timestamp in ms": 1700521308080, "logtype": "training_step"}
{"Total num played games": 16819, "Total num trained steps": 33081, "Timestamp in ms": 1700521420558, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.611953125000003}
{"Ratio train steps to played games": 1.9654947530681213, "Avg loss": 0.8838528140913695, "Avg value loss": 0.5310805280460045, "Avg policy loss": 0.3527722868602723, "Total num played games": 16867, "Total num trained steps": 33152, "Timestamp in ms": 1700521455568, "logtype": "training_step"}
{"Avg objective": 21.912031249999995, "Games time in secs": 221.1685287449509, "Avg game time in secs": 2.4445090115623316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.55, "agent_stopped_0": 0.59}, "Total num played games": 16896, "Total num trained steps": 33229, "Timestamp in ms": 1700521491921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967484481229678, "Avg loss": 0.7710314909927547, "Avg value loss": 0.42606002115644515, "Avg policy loss": 0.3449714605230838, "Total num played games": 16915, "Total num trained steps": 33280, "Timestamp in ms": 1700521514333, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692879037962745, "Avg loss": 0.6796723706647754, "Avg value loss": 0.33812439802568406, "Avg policy loss": 0.3415479746181518, "Total num played games": 16964, "Total num trained steps": 33408, "Timestamp in ms": 1700521573556, "logtype": "training_step"}
{"Avg objective": 21.416953124999985, "Games time in secs": 137.30799053423107, "Avg game time in secs": 3.1031515694776317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.73, "agent_stopped_0": 0.49}, "Total num played games": 17024, "Total num trained steps": 33517, "Timestamp in ms": 1700521629229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9656526581091378, "Avg loss": 0.7611924528609961, "Avg value loss": 0.4283364209695719, "Avg policy loss": 0.3328560335794464, "Total num played games": 17061, "Total num trained steps": 33536, "Timestamp in ms": 1700521637883, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967330956694524, "Avg loss": 0.7476789008360356, "Avg value loss": 0.4149444806971587, "Avg policy loss": 0.33273442776408046, "Total num played games": 17111, "Total num trained steps": 33664, "Timestamp in ms": 1700521698737, "logtype": "training_step"}
{"Total num played games": 17111, "Total num trained steps": 33682, "Timestamp in ms": 1700521793380, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.761640625000002}
{"Avg objective": 22.50476562499999, "Games time in secs": 169.90331732481718, "Avg game time in secs": 2.746710379520664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.7}, "Total num played games": 17152, "Total num trained steps": 33693, "Timestamp in ms": 1700521799133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969345532956466, "Avg loss": 0.864493174245581, "Avg value loss": 0.511506098555401, "Avg policy loss": 0.3529870710335672, "Total num played games": 17159, "Total num trained steps": 33792, "Timestamp in ms": 1700521850717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9657490582439872, "Avg loss": 0.8193146919365972, "Avg value loss": 0.4780507074901834, "Avg policy loss": 0.3412639833986759, "Total num played games": 17255, "Total num trained steps": 33920, "Timestamp in ms": 1700521917323, "logtype": "training_step"}
{"Avg objective": 21.17999999999999, "Games time in secs": 163.45990659669042, "Avg game time in secs": 2.870857777481433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.72, "agent_stopped_0": 0.5}, "Total num played games": 17280, "Total num trained steps": 34008, "Timestamp in ms": 1700521962593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9674101467699063, "Avg loss": 0.9169953134842217, "Avg value loss": 0.565550351049751, "Avg policy loss": 0.3514449598733336, "Total num played games": 17306, "Total num trained steps": 34048, "Timestamp in ms": 1700521982150, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.7995250090025365, "Avg value loss": 0.4503373698098585, "Avg policy loss": 0.34918764396570623, "Total num played games": 17355, "Total num trained steps": 34176, "Timestamp in ms": 1700522044903, "logtype": "training_step"}
{"Total num played games": 17404, "Total num trained steps": 34285, "Timestamp in ms": 1700522179533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.131757812500002}
{"Avg objective": 20.787656249999987, "Games time in secs": 218.36907821707428, "Avg game time in secs": 3.55762275577581, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.95}, "Total num played games": 17408, "Total num trained steps": 34288, "Timestamp in ms": 1700522180962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9656199862479944, "Avg loss": 0.7878487666603178, "Avg value loss": 0.4362365297274664, "Avg policy loss": 0.35161223635077477, "Total num played games": 17452, "Total num trained steps": 34304, "Timestamp in ms": 1700522187807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674857142857143, "Avg loss": 0.8565252216067165, "Avg value loss": 0.5143924916046672, "Avg policy loss": 0.3421327299438417, "Total num played games": 17500, "Total num trained steps": 34432, "Timestamp in ms": 1700522247456, "logtype": "training_step"}
{"Avg objective": 21.793437499999992, "Games time in secs": 96.18873914889991, "Avg game time in secs": 2.545478002881282, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.6}, "Total num played games": 17536, "Total num trained steps": 34498, "Timestamp in ms": 1700522277151, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.7185092810541391, "Avg value loss": 0.3703812090680003, "Avg policy loss": 0.34812807012349367, "Total num played games": 17550, "Total num trained steps": 34560, "Timestamp in ms": 1700522305313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971021080743224, "Avg loss": 0.6721993323881179, "Avg value loss": 0.32676020404323936, "Avg policy loss": 0.3454391248524189, "Total num played games": 17599, "Total num trained steps": 34688, "Timestamp in ms": 1700522363690, "logtype": "training_step"}
{"Avg objective": 21.198437499999976, "Games time in secs": 140.10455092415214, "Avg game time in secs": 2.925671639779466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.72, "agent_stopped_0": 0.47}, "Total num played games": 17664, "Total num trained steps": 34799, "Timestamp in ms": 1700522417256, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9667834143034686, "Avg loss": 0.8622451031114906, "Avg value loss": 0.5133614774094895, "Avg policy loss": 0.3488836250035092, "Total num played games": 17702, "Total num trained steps": 34816, "Timestamp in ms": 1700522424745, "logtype": "training_step"}
{"Total num played games": 17703, "Total num trained steps": 34885, "Timestamp in ms": 1700522541599, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.383125000000003}
{"Ratio train steps to played games": 1.9685088164047095, "Avg loss": 0.7274641348049045, "Avg value loss": 0.3789781351806596, "Avg policy loss": 0.3484859950840473, "Total num played games": 17751, "Total num trained steps": 34944, "Timestamp in ms": 1700522570002, "logtype": "training_step"}
{"Avg objective": 21.85359374999999, "Games time in secs": 179.16555396094918, "Avg game time in secs": 2.5159201811620733, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.74}, "Total num played games": 17792, "Total num trained steps": 34998, "Timestamp in ms": 1700522596421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970226391775743, "Avg loss": 0.7258591337595135, "Avg value loss": 0.37845461518736556, "Avg policy loss": 0.3474045128095895, "Total num played games": 17801, "Total num trained steps": 35072, "Timestamp in ms": 1700522630905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9676337414053329, "Avg loss": 0.8116894555278122, "Avg value loss": 0.45289614697685465, "Avg policy loss": 0.358793311053887, "Total num played games": 17889, "Total num trained steps": 35200, "Timestamp in ms": 1700522690492, "logtype": "training_step"}
{"Avg objective": 22.792812499999982, "Games time in secs": 138.63087501190603, "Avg game time in secs": 2.859457350918092, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.7, "agent_stopped_0": 0.52}, "Total num played games": 17920, "Total num trained steps": 35292, "Timestamp in ms": 1700522735053, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9682973033207043, "Avg loss": 0.9950814126059413, "Avg value loss": 0.6412981236353517, "Avg policy loss": 0.3537832945585251, "Total num played games": 17948, "Total num trained steps": 35328, "Timestamp in ms": 1700522752357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970050563982886, "Avg loss": 0.7636485435068607, "Avg value loss": 0.4074778654612601, "Avg policy loss": 0.35617067851126194, "Total num played games": 17997, "Total num trained steps": 35456, "Timestamp in ms": 1700522810489, "logtype": "training_step"}
{"Total num played games": 18046, "Total num trained steps": 35488, "Timestamp in ms": 1700522919978, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.249218750000004}
{"Avg objective": 20.964843749999982, "Games time in secs": 186.0644939970225, "Avg game time in secs": 2.90205084651825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.73}, "Total num played games": 18048, "Total num trained steps": 35488, "Timestamp in ms": 1700522921117, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9665635017132752, "Avg loss": 0.8985690036788583, "Avg value loss": 0.5434665122884326, "Avg policy loss": 0.3551024978514761, "Total num played games": 18094, "Total num trained steps": 35584, "Timestamp in ms": 1700522965047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9678734777098144, "Avg loss": 0.5651294095441699, "Avg value loss": 0.23415034759091213, "Avg policy loss": 0.3309790641069412, "Total num played games": 18147, "Total num trained steps": 35712, "Timestamp in ms": 1700523026365, "logtype": "training_step"}
{"Avg objective": 20.954921874999993, "Games time in secs": 139.80363492667675, "Avg game time in secs": 2.218865096423542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.54}, "Total num played games": 18176, "Total num trained steps": 35788, "Timestamp in ms": 1700523060921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696087052099363, "Avg loss": 0.612173672998324, "Avg value loss": 0.28809587366413325, "Avg policy loss": 0.3240777915343642, "Total num played games": 18196, "Total num trained steps": 35840, "Timestamp in ms": 1700523084001, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712813767401074, "Avg loss": 0.6279676575213671, "Avg value loss": 0.3078930012998171, "Avg policy loss": 0.3200746508082375, "Total num played games": 18246, "Total num trained steps": 35968, "Timestamp in ms": 1700523144561, "logtype": "training_step"}
{"Avg objective": 22.27289062499999, "Games time in secs": 137.12280399352312, "Avg game time in secs": 3.0892099000921007, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.88}, "Total num played games": 18304, "Total num trained steps": 36082, "Timestamp in ms": 1700523198044, "logtype": "played_game"}
{"Total num played games": 18345, "Total num trained steps": 36091, "Timestamp in ms": 1700523284485, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.1525390625}
{"Ratio train steps to played games": 1.9653707938582163, "Avg loss": 1.0934843763243407, "Avg value loss": 0.7572404039674439, "Avg policy loss": 0.33624398126266897, "Total num played games": 18364, "Total num trained steps": 36096, "Timestamp in ms": 1700523286737, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9694448975153591, "Avg loss": 0.836980429245159, "Avg value loss": 0.48361298290546983, "Avg policy loss": 0.35336743865627795, "Total num played games": 18393, "Total num trained steps": 36224, "Timestamp in ms": 1700523344929, "logtype": "training_step"}
{"Avg objective": 21.886718749999993, "Games time in secs": 175.06425209529698, "Avg game time in secs": 2.4270761825464433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.7}, "Total num played games": 18432, "Total num trained steps": 36283, "Timestamp in ms": 1700523373108, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710985793297906, "Avg loss": 0.6543013071641326, "Avg value loss": 0.320935724361334, "Avg policy loss": 0.33336558914743364, "Total num played games": 18442, "Total num trained steps": 36352, "Timestamp in ms": 1700523403811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9688056559987048, "Avg loss": 0.671484901336953, "Avg value loss": 0.3363642573240213, "Avg policy loss": 0.3351206441875547, "Total num played games": 18529, "Total num trained steps": 36480, "Timestamp in ms": 1700523461618, "logtype": "training_step"}
{"Avg objective": 22.19578124999999, "Games time in secs": 130.77661837264895, "Avg game time in secs": 2.724310699835769, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.73, "agent_stopped_0": 0.51}, "Total num played games": 18560, "Total num trained steps": 36572, "Timestamp in ms": 1700523503885, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688592481041252, "Avg loss": 0.8024689389858395, "Avg value loss": 0.4662884850986302, "Avg policy loss": 0.3361804516753182, "Total num played games": 18593, "Total num trained steps": 36608, "Timestamp in ms": 1700523520444, "logtype": "training_step"}
{"Total num played games": 18642, "Total num trained steps": 36693, "Timestamp in ms": 1700523643488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.51921875}
{"Avg objective": 20.211953124999983, "Games time in secs": 145.5805208273232, "Avg game time in secs": 2.463833519301261, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.69}, "Total num played games": 18688, "Total num trained steps": 36702, "Timestamp in ms": 1700523649466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9655430711610486, "Avg loss": 0.9632021693978459, "Avg value loss": 0.6275410061352886, "Avg policy loss": 0.33566117426380515, "Total num played games": 18690, "Total num trained steps": 36736, "Timestamp in ms": 1700523667258, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972338148742643, "Avg loss": 0.4990769000723958, "Avg value loss": 0.18002135341521353, "Avg policy loss": 0.31905554747208953, "Total num played games": 18690, "Total num trained steps": 36864, "Timestamp in ms": 1700523732793, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9690727137229853, "Avg loss": 0.6533419014886022, "Avg value loss": 0.3313238341361284, "Avg policy loss": 0.32201806688681245, "Total num played games": 18786, "Total num trained steps": 36992, "Timestamp in ms": 1700523796840, "logtype": "training_step"}
{"Avg objective": 22.239531249999988, "Games time in secs": 184.90990456938744, "Avg game time in secs": 2.32836578944989, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.59, "agent_stopped_0": 0.54}, "Total num played games": 18816, "Total num trained steps": 37065, "Timestamp in ms": 1700523834376, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707459516856916, "Avg loss": 0.7172440674621612, "Avg value loss": 0.40320774813881144, "Avg policy loss": 0.3140363125130534, "Total num played games": 18835, "Total num trained steps": 37120, "Timestamp in ms": 1700523862826, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972410506248676, "Avg loss": 0.6227163863368332, "Avg value loss": 0.2971255096490495, "Avg policy loss": 0.3255908729042858, "Total num played games": 18884, "Total num trained steps": 37248, "Timestamp in ms": 1700523926504, "logtype": "training_step"}
{"Total num played games": 18933, "Total num trained steps": 37293, "Timestamp in ms": 1700524028254, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.401250000000005}
{"Avg objective": 20.92257812499998, "Games time in secs": 195.58535043150187, "Avg game time in secs": 3.2139256006339565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.92, "agent_stopped_0": 0.39}, "Total num played games": 18944, "Total num trained steps": 37295, "Timestamp in ms": 1700524029961, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9691270217586008, "Avg loss": 1.0026609788183123, "Avg value loss": 0.6679037834983319, "Avg policy loss": 0.33475719450507313, "Total num played games": 18981, "Total num trained steps": 37376, "Timestamp in ms": 1700524074702, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9708865415944086, "Avg loss": 0.636054772650823, "Avg value loss": 0.3173703693319112, "Avg policy loss": 0.31868440948892385, "Total num played games": 19029, "Total num trained steps": 37504, "Timestamp in ms": 1700524137428, "logtype": "training_step"}
{"Avg objective": 20.718359374999977, "Games time in secs": 134.23607639223337, "Avg game time in secs": 2.604652212365181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.71, "agent_stopped_0": 0.44}, "Total num played games": 19072, "Total num trained steps": 37558, "Timestamp in ms": 1700524164198, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9723270440251572, "Avg loss": 0.6467534720432013, "Avg value loss": 0.32628313172608614, "Avg policy loss": 0.32047034287825227, "Total num played games": 19080, "Total num trained steps": 37632, "Timestamp in ms": 1700524200838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9694361863036562, "Avg loss": 0.6597109516151249, "Avg value loss": 0.33889963320689276, "Avg policy loss": 0.3208113176515326, "Total num played games": 19173, "Total num trained steps": 37760, "Timestamp in ms": 1700524262937, "logtype": "training_step"}
{"Avg objective": 22.010703124999985, "Games time in secs": 140.21602615341544, "Avg game time in secs": 2.5053354492702056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.6, "agent_stopped_0": 0.53}, "Total num played games": 19200, "Total num trained steps": 37846, "Timestamp in ms": 1700524304414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707672301690506, "Avg loss": 0.7263861102983356, "Avg value loss": 0.4051947834668681, "Avg policy loss": 0.3211913239210844, "Total num played games": 19225, "Total num trained steps": 37888, "Timestamp in ms": 1700524324537, "logtype": "training_step"}
{"Total num played games": 19225, "Total num trained steps": 37896, "Timestamp in ms": 1700524413577, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.790234375}
{"Ratio train steps to played games": 1.9725003891454367, "Avg loss": 0.5814319022465497, "Avg value loss": 0.2585966811166145, "Avg policy loss": 0.3228352207224816, "Total num played games": 19273, "Total num trained steps": 38016, "Timestamp in ms": 1700524473876, "logtype": "training_step"}
{"Avg objective": 20.670312499999984, "Games time in secs": 232.29550635628402, "Avg game time in secs": 2.614406049498939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.7}, "Total num played games": 19328, "Total num trained steps": 38133, "Timestamp in ms": 1700524536709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694841741106006, "Avg loss": 0.6347433063201606, "Avg value loss": 0.32055885094450787, "Avg policy loss": 0.31418445461895317, "Total num played games": 19367, "Total num trained steps": 38144, "Timestamp in ms": 1700524541334, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9708017920593233, "Avg loss": 0.7484108211938292, "Avg value loss": 0.43699284229660407, "Avg policy loss": 0.31141797185409814, "Total num played games": 19419, "Total num trained steps": 38272, "Timestamp in ms": 1700524599908, "logtype": "training_step"}
{"Avg objective": 21.92257812499999, "Games time in secs": 91.18306759931147, "Avg game time in secs": 1.898304959948291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.43}, "Total num played games": 19456, "Total num trained steps": 38332, "Timestamp in ms": 1700524627893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9724162728580235, "Avg loss": 0.7429377175867558, "Avg value loss": 0.4296154423500411, "Avg policy loss": 0.31332227762322873, "Total num played games": 19468, "Total num trained steps": 38400, "Timestamp in ms": 1700524659797, "logtype": "training_step"}
{"Total num played games": 19519, "Total num trained steps": 38497, "Timestamp in ms": 1700524782749, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.757578125000002}
{"Ratio train steps to played games": 1.9689783819696427, "Avg loss": 0.7934903153218329, "Avg value loss": 0.4883098000427708, "Avg policy loss": 0.3051805223803967, "Total num played games": 19567, "Total num trained steps": 38528, "Timestamp in ms": 1700524796129, "logtype": "training_step"}
{"Avg objective": 21.900390624999986, "Games time in secs": 212.78142100386322, "Avg game time in secs": 2.3361801412975183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.62, "agent_stopped_0": 0.52}, "Total num played games": 19584, "Total num trained steps": 38625, "Timestamp in ms": 1700524840674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970484783606056, "Avg loss": 0.6948426249437034, "Avg value loss": 0.3895285848993808, "Avg policy loss": 0.3053140366682783, "Total num played games": 19617, "Total num trained steps": 38656, "Timestamp in ms": 1700524854165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972134648632157, "Avg loss": 1.0228822981007397, "Avg value loss": 0.7068731973995455, "Avg policy loss": 0.31600910890847445, "Total num played games": 19666, "Total num trained steps": 38784, "Timestamp in ms": 1700524914517, "logtype": "training_step"}
{"Avg objective": 22.439921874999985, "Games time in secs": 96.87685086019337, "Avg game time in secs": 2.4915073322481476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.73}, "Total num played games": 19712, "Total num trained steps": 38833, "Timestamp in ms": 1700524937551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737255896525487, "Avg loss": 0.648175397189334, "Avg value loss": 0.32596576143987477, "Avg policy loss": 0.32220963411964476, "Total num played games": 19715, "Total num trained steps": 38912, "Timestamp in ms": 1700524974391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9703729874324938, "Avg loss": 0.7676138686947525, "Avg value loss": 0.44892578246071935, "Avg policy loss": 0.3186880847206339, "Total num played games": 19813, "Total num trained steps": 39040, "Timestamp in ms": 1700525031614, "logtype": "training_step"}
{"Total num played games": 19813, "Total num trained steps": 39098, "Timestamp in ms": 1700525141186, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.24125}
{"Avg objective": 21.439843749999987, "Games time in secs": 206.9406370036304, "Avg game time in secs": 2.3834604861331172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.59, "agent_stopped_0": 0.56}, "Total num played games": 19840, "Total num trained steps": 39106, "Timestamp in ms": 1700525144496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9720557877246865, "Avg loss": 0.715915922774002, "Avg value loss": 0.39297371631255373, "Avg policy loss": 0.32294220430776477, "Total num played games": 19861, "Total num trained steps": 39168, "Timestamp in ms": 1700525173373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973631341034656, "Avg loss": 0.7631593965925276, "Avg value loss": 0.43624996597645804, "Avg policy loss": 0.32690943113993853, "Total num played games": 19910, "Total num trained steps": 39296, "Timestamp in ms": 1700525230748, "logtype": "training_step"}
{"Avg objective": 22.13820312499999, "Games time in secs": 137.34511039964855, "Avg game time in secs": 2.0883263317955425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.63, "agent_stopped_0": 0.53}, "Total num played games": 19968, "Total num trained steps": 39409, "Timestamp in ms": 1700525281841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706573356660835, "Avg loss": 0.6652398228179663, "Avg value loss": 0.3533727722824551, "Avg policy loss": 0.31186704826541245, "Total num played games": 20005, "Total num trained steps": 39424, "Timestamp in ms": 1700525287762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9717832394436412, "Avg loss": 0.8915343028493226, "Avg value loss": 0.5719444719143212, "Avg policy loss": 0.31958982918877155, "Total num played games": 20059, "Total num trained steps": 39552, "Timestamp in ms": 1700525348064, "logtype": "training_step"}
{"Avg objective": 21.885156249999994, "Games time in secs": 95.19662719219923, "Avg game time in secs": 2.425914270672365, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.69}, "Total num played games": 20096, "Total num trained steps": 39614, "Timestamp in ms": 1700525377038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732942112592002, "Avg loss": 0.8146315754856914, "Avg value loss": 0.49840713338926435, "Avg policy loss": 0.3162244400009513, "Total num played games": 20108, "Total num trained steps": 39680, "Timestamp in ms": 1700525406643, "logtype": "training_step"}
{"Total num played games": 20108, "Total num trained steps": 39700, "Timestamp in ms": 1700525490579, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.3498828125}
{"Ratio train steps to played games": 1.9707411257983067, "Avg loss": 0.6873159892857075, "Avg value loss": 0.36776539467973635, "Avg policy loss": 0.31955059221945703, "Total num played games": 20199, "Total num trained steps": 39808, "Timestamp in ms": 1700525543769, "logtype": "training_step"}
{"Avg objective": 22.788437499999986, "Games time in secs": 215.76658201031387, "Avg game time in secs": 2.2264372303470736, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.66, "agent_stopped_0": 0.53}, "Total num played games": 20224, "Total num trained steps": 39905, "Timestamp in ms": 1700525592805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9716119476672427, "Avg loss": 0.7200879885349423, "Avg value loss": 0.404707578883972, "Avg policy loss": 0.3153804097091779, "Total num played games": 20255, "Total num trained steps": 39936, "Timestamp in ms": 1700525608449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973255183962961, "Avg loss": 0.8047225507907569, "Avg value loss": 0.4952267610351555, "Avg policy loss": 0.3094957940047607, "Total num played games": 20303, "Total num trained steps": 40064, "Timestamp in ms": 1700525670410, "logtype": "training_step"}
{"Avg objective": 20.926015624999984, "Games time in secs": 100.25971861928701, "Avg game time in secs": 2.576960336024058, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.8}, "Total num played games": 20352, "Total num trained steps": 40110, "Timestamp in ms": 1700525693065, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9747936320754718, "Avg loss": 0.6133562952745706, "Avg value loss": 0.3092496204772033, "Avg policy loss": 0.3041066755540669, "Total num played games": 20352, "Total num trained steps": 40192, "Timestamp in ms": 1700525731515, "logtype": "training_step"}
{"Total num played games": 20452, "Total num trained steps": 40303, "Timestamp in ms": 1700525867912, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.766210937500002}
{"Avg objective": 21.408437499999987, "Games time in secs": 177.852779539302, "Avg game time in secs": 2.0962731298204744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.51}, "Total num played games": 20480, "Total num trained steps": 40310, "Timestamp in ms": 1700525870918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9670683514660683, "Avg loss": 0.7944979683961719, "Avg value loss": 0.4909507532720454, "Avg policy loss": 0.3035472157644108, "Total num played games": 20497, "Total num trained steps": 40320, "Timestamp in ms": 1700525875229, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9730243902439024, "Avg loss": 0.5747801305260509, "Avg value loss": 0.2679673275561072, "Avg policy loss": 0.30681280698627234, "Total num played games": 20500, "Total num trained steps": 40448, "Timestamp in ms": 1700525936000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9745486398364884, "Avg loss": 0.5422772236634046, "Avg value loss": 0.25424057856434956, "Avg policy loss": 0.2880366448080167, "Total num played games": 20549, "Total num trained steps": 40576, "Timestamp in ms": 1700525995361, "logtype": "training_step"}
{"Avg objective": 20.64867187499998, "Games time in secs": 176.09667292796075, "Avg game time in secs": 2.4819818065298023, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.66}, "Total num played games": 20608, "Total num trained steps": 40685, "Timestamp in ms": 1700526047015, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9714714714714714, "Avg loss": 0.714198119007051, "Avg value loss": 0.415114029427059, "Avg policy loss": 0.29908408992923796, "Total num played games": 20646, "Total num trained steps": 40704, "Timestamp in ms": 1700526055838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727026765871098, "Avg loss": 0.6108230298850685, "Avg value loss": 0.3117534962366335, "Avg policy loss": 0.29906953766476363, "Total num played games": 20698, "Total num trained steps": 40832, "Timestamp in ms": 1700526116009, "logtype": "training_step"}
{"Avg objective": 21.284843749999986, "Games time in secs": 97.33652423135936, "Avg game time in secs": 2.226140696700895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.58}, "Total num played games": 20736, "Total num trained steps": 40892, "Timestamp in ms": 1700526144351, "logtype": "played_game"}
{"Total num played games": 20748, "Total num trained steps": 40904, "Timestamp in ms": 1700526222306, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.348828125}
{"Ratio train steps to played games": 1.9696095402962108, "Avg loss": 0.8223770214244723, "Avg value loss": 0.5093314528930932, "Avg policy loss": 0.3130455600330606, "Total num played games": 20796, "Total num trained steps": 40960, "Timestamp in ms": 1700526250552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726343079360507, "Avg loss": 0.45684008998796344, "Avg value loss": 0.15979979856638238, "Avg policy loss": 0.29704029276035726, "Total num played games": 20829, "Total num trained steps": 41088, "Timestamp in ms": 1700526310924, "logtype": "training_step"}
{"Avg objective": 20.983828124999985, "Games time in secs": 208.64634222351015, "Avg game time in secs": 2.421674246317707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.63, "agent_stopped_0": 0.55}, "Total num played games": 20864, "Total num trained steps": 41182, "Timestamp in ms": 1700526352998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726702723400182, "Avg loss": 0.7896235033404082, "Avg value loss": 0.492119996168185, "Avg policy loss": 0.29750350839458406, "Total num played games": 20893, "Total num trained steps": 41216, "Timestamp in ms": 1700526368896, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9740724824523708, "Avg loss": 0.5695911650545895, "Avg value loss": 0.2681284549762495, "Avg policy loss": 0.30146271362900734, "Total num played games": 20943, "Total num trained steps": 41344, "Timestamp in ms": 1700526427961, "logtype": "training_step"}
{"Avg objective": 20.531406249999986, "Games time in secs": 93.22350653260946, "Avg game time in secs": 2.251273990550544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.67, "agent_stopped_0": 0.53}, "Total num played games": 20992, "Total num trained steps": 41386, "Timestamp in ms": 1700526446221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753739163570545, "Avg loss": 0.6143600610084832, "Avg value loss": 0.3133004951523617, "Avg policy loss": 0.30105956830084324, "Total num played games": 20994, "Total num trained steps": 41472, "Timestamp in ms": 1700526486234, "logtype": "training_step"}
{"Total num played games": 21043, "Total num trained steps": 41507, "Timestamp in ms": 1700526585196, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.388046875}
{"Ratio train steps to played games": 1.9724052913565027, "Avg loss": 0.8754909161943942, "Avg value loss": 0.554723255278077, "Avg policy loss": 0.32076766004320234, "Total num played games": 21091, "Total num trained steps": 41600, "Timestamp in ms": 1700526629225, "logtype": "training_step"}
{"Avg objective": 22.062656249999993, "Games time in secs": 219.66016300022602, "Avg game time in secs": 1.8783522611192893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 21120, "Total num trained steps": 41675, "Timestamp in ms": 1700526665882, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9736082864304971, "Avg loss": 0.6175247996579856, "Avg value loss": 0.314535875688307, "Avg policy loss": 0.30298892059363425, "Total num played games": 21143, "Total num trained steps": 41728, "Timestamp in ms": 1700526692449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9751309518191684, "Avg loss": 0.6339061963371933, "Avg value loss": 0.32524109474616125, "Avg policy loss": 0.30866510700434446, "Total num played games": 21191, "Total num trained steps": 41856, "Timestamp in ms": 1700526755670, "logtype": "training_step"}
{"Avg objective": 22.405937499999983, "Games time in secs": 143.94663172215223, "Avg game time in secs": 2.3524544461251935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.77, "agent_stopped_0": 0.42}, "Total num played games": 21248, "Total num trained steps": 41968, "Timestamp in ms": 1700526809828, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9722365763141823, "Avg loss": 0.8037653644569218, "Avg value loss": 0.49226677778642625, "Avg policy loss": 0.31149858818389475, "Total num played games": 21287, "Total num trained steps": 41984, "Timestamp in ms": 1700526818458, "logtype": "training_step"}
{"Total num played games": 21335, "Total num trained steps": 42110, "Timestamp in ms": 1700526960233, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5712890625}
{"Ratio train steps to played games": 1.973198388154812, "Avg loss": 0.662272114539519, "Avg value loss": 0.3548541683703661, "Avg policy loss": 0.30741795082576573, "Total num played games": 21341, "Total num trained steps": 42112, "Timestamp in ms": 1700526961894, "logtype": "training_step"}
{"Avg objective": 21.854453124999992, "Games time in secs": 155.38919905014336, "Avg game time in secs": 1.7880141019704752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.52}, "Total num played games": 21376, "Total num trained steps": 42119, "Timestamp in ms": 1700526965218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975401019501473, "Avg loss": 0.7316421752329916, "Avg value loss": 0.42367600376019254, "Avg policy loss": 0.3079661732772365, "Total num played games": 21383, "Total num trained steps": 42240, "Timestamp in ms": 1700527023329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726684360013038, "Avg loss": 0.7566150943748653, "Avg value loss": 0.4595205154037103, "Avg policy loss": 0.29709458188153803, "Total num played games": 21477, "Total num trained steps": 42368, "Timestamp in ms": 1700527088020, "logtype": "training_step"}
{"Avg objective": 22.611796874999985, "Games time in secs": 166.99740619398654, "Avg game time in secs": 2.3089578482758952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.66, "agent_stopped_0": 0.55}, "Total num played games": 21504, "Total num trained steps": 42452, "Timestamp in ms": 1700527132217, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739409141583055, "Avg loss": 0.8125265738926828, "Avg value loss": 0.49658073839964345, "Avg policy loss": 0.31594583531841636, "Total num played games": 21528, "Total num trained steps": 42496, "Timestamp in ms": 1700527154684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755283648498332, "Avg loss": 0.6688217618502676, "Avg value loss": 0.36770905274897814, "Avg policy loss": 0.3011127100326121, "Total num played games": 21576, "Total num trained steps": 42624, "Timestamp in ms": 1700527216203, "logtype": "training_step"}
{"Total num played games": 21624, "Total num trained steps": 42710, "Timestamp in ms": 1700527343297, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.821093750000003}
{"Avg objective": 21.740312499999987, "Games time in secs": 212.78475824929774, "Avg game time in secs": 2.196637710338109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.66, "agent_stopped_0": 0.47}, "Total num played games": 21632, "Total num trained steps": 42712, "Timestamp in ms": 1700527345002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726836471022517, "Avg loss": 0.7717552059330046, "Avg value loss": 0.46394774998771027, "Avg policy loss": 0.30780745344236493, "Total num played games": 21672, "Total num trained steps": 42752, "Timestamp in ms": 1700527366526, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974171270718232, "Avg loss": 0.5805603666231036, "Avg value loss": 0.2792310639633797, "Avg policy loss": 0.30132930679246783, "Total num played games": 21720, "Total num trained steps": 42880, "Timestamp in ms": 1700527430772, "logtype": "training_step"}
{"Avg objective": 20.53851562499999, "Games time in secs": 112.26438677310944, "Avg game time in secs": 2.15440894573112, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.59}, "Total num played games": 21760, "Total num trained steps": 42934, "Timestamp in ms": 1700527457266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756075152740136, "Avg loss": 0.6688782176934183, "Avg value loss": 0.36256691557355225, "Avg policy loss": 0.3063112961826846, "Total num played games": 21769, "Total num trained steps": 43008, "Timestamp in ms": 1700527491679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764032073310425, "Avg loss": 0.5814906917512417, "Avg value loss": 0.28007787343813106, "Avg policy loss": 0.30141281289979815, "Total num played games": 21825, "Total num trained steps": 43136, "Timestamp in ms": 1700527550242, "logtype": "training_step"}
{"Avg objective": 20.49007812499999, "Games time in secs": 141.33513835072517, "Avg game time in secs": 2.2036084251012653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.66, "agent_stopped_0": 0.52}, "Total num played games": 21888, "Total num trained steps": 43240, "Timestamp in ms": 1700527598601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731369150779896, "Avg loss": 0.6990572107024491, "Avg value loss": 0.4058025093981996, "Avg policy loss": 0.29325469653122127, "Total num played games": 21926, "Total num trained steps": 43264, "Timestamp in ms": 1700527609304, "logtype": "training_step"}
{"Total num played games": 21926, "Total num trained steps": 43311, "Timestamp in ms": 1700527711004, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.332968750000003}
{"Ratio train steps to played games": 1.9746973696186403, "Avg loss": 0.6347387540154159, "Avg value loss": 0.34182098461315036, "Avg policy loss": 0.29291776835452765, "Total num played games": 21974, "Total num trained steps": 43392, "Timestamp in ms": 1700527748710, "logtype": "training_step"}
{"Avg objective": 21.81070312499999, "Games time in secs": 175.5194152649492, "Avg game time in secs": 2.103348130331142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 22016, "Total num trained steps": 43446, "Timestamp in ms": 1700527774121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761158788539255, "Avg loss": 0.6332363176625222, "Avg value loss": 0.3442653145175427, "Avg policy loss": 0.2889710017479956, "Total num played games": 22023, "Total num trained steps": 43520, "Timestamp in ms": 1700527808078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9729241061338878, "Avg loss": 0.7288053506053984, "Avg value loss": 0.4461808379855938, "Avg policy loss": 0.28262451803311706, "Total num played games": 22123, "Total num trained steps": 43648, "Timestamp in ms": 1700527875046, "logtype": "training_step"}
{"Avg objective": 21.527265624999988, "Games time in secs": 147.7442533876747, "Avg game time in secs": 2.1564397900219774, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.66, "agent_stopped_0": 0.51}, "Total num played games": 22144, "Total num trained steps": 43736, "Timestamp in ms": 1700527921865, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9744711560146138, "Avg loss": 0.6607118574902415, "Avg value loss": 0.3752427030703984, "Avg policy loss": 0.2854691563406959, "Total num played games": 22171, "Total num trained steps": 43776, "Timestamp in ms": 1700527941325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975966515144696, "Avg loss": 0.6630437816493213, "Avg value loss": 0.3711000315961428, "Avg policy loss": 0.29194374987855554, "Total num played games": 22219, "Total num trained steps": 43904, "Timestamp in ms": 1700528006713, "logtype": "training_step"}
{"Total num played games": 22219, "Total num trained steps": 43914, "Timestamp in ms": 1700528078370, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.983867187500003}
{"Avg objective": 21.796484374999995, "Games time in secs": 209.90035469271243, "Avg game time in secs": 1.7966993847221602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.52}, "Total num played games": 22272, "Total num trained steps": 44024, "Timestamp in ms": 1700528131766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741750358680057, "Avg loss": 0.5956479925662279, "Avg value loss": 0.30323903437238187, "Avg policy loss": 0.2924089562147856, "Total num played games": 22304, "Total num trained steps": 44032, "Timestamp in ms": 1700528134514, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744254672270412, "Avg loss": 0.7429388116579503, "Avg value loss": 0.43484885175712407, "Avg policy loss": 0.30808996327687055, "Total num played games": 22366, "Total num trained steps": 44160, "Timestamp in ms": 1700528194231, "logtype": "training_step"}
{"Avg objective": 21.26093749999999, "Games time in secs": 93.61172778718174, "Avg game time in secs": 2.0970296304294607, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.7}, "Total num played games": 22400, "Total num trained steps": 44226, "Timestamp in ms": 1700528225378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755107502899456, "Avg loss": 0.6836400253232569, "Avg value loss": 0.3797698076814413, "Avg policy loss": 0.30387021065689623, "Total num played games": 22418, "Total num trained steps": 44288, "Timestamp in ms": 1700528255451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9768994525303778, "Avg loss": 0.5401617253664881, "Avg value loss": 0.24608179304050282, "Avg policy loss": 0.29407992982305586, "Total num played games": 22467, "Total num trained steps": 44416, "Timestamp in ms": 1700528316101, "logtype": "training_step"}
{"Total num played games": 22517, "Total num trained steps": 44517, "Timestamp in ms": 1700528456301, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.874921875000005}
{"Avg objective": 21.71609374999998, "Games time in secs": 232.415840504691, "Avg game time in secs": 2.2629427491192473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.73, "agent_stopped_0": 0.45}, "Total num played games": 22528, "Total num trained steps": 44518, "Timestamp in ms": 1700528457794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974030578329271, "Avg loss": 0.7443804244976491, "Avg value loss": 0.44404941867105663, "Avg policy loss": 0.3003310003550723, "Total num played games": 22565, "Total num trained steps": 44544, "Timestamp in ms": 1700528469224, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975326110988282, "Avg loss": 0.6104851560667157, "Avg value loss": 0.30793785775313154, "Avg policy loss": 0.3025473025627434, "Total num played games": 22615, "Total num trained steps": 44672, "Timestamp in ms": 1700528526725, "logtype": "training_step"}
{"Avg objective": 20.41515624999999, "Games time in secs": 92.95731504820287, "Avg game time in secs": 2.060313861758914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.56}, "Total num played games": 22656, "Total num trained steps": 44726, "Timestamp in ms": 1700528550751, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767031415460643, "Avg loss": 0.5671677081845701, "Avg value loss": 0.27468905539717525, "Avg policy loss": 0.2924786544172093, "Total num played games": 22664, "Total num trained steps": 44800, "Timestamp in ms": 1700528585614, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973816009138037, "Avg loss": 0.6138750892132521, "Avg value loss": 0.33145310793770477, "Avg policy loss": 0.2824219779577106, "Total num played games": 22762, "Total num trained steps": 44928, "Timestamp in ms": 1700528644383, "logtype": "training_step"}
{"Avg objective": 20.957968749999992, "Games time in secs": 137.74230176769197, "Avg game time in secs": 1.9841862422326813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.52, "agent_stopped_0": 0.6}, "Total num played games": 22784, "Total num trained steps": 45022, "Timestamp in ms": 1700528688496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9749276759884282, "Avg loss": 0.6303677607793361, "Avg value loss": 0.3472554816980846, "Avg policy loss": 0.2831122766947374, "Total num played games": 22814, "Total num trained steps": 45056, "Timestamp in ms": 1700528703953, "logtype": "training_step"}
{"Total num played games": 22863, "Total num trained steps": 45121, "Timestamp in ms": 1700528805923, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.651835937500003}
{"Ratio train steps to played games": 1.9721094670682204, "Avg loss": 0.8940844282042235, "Avg value loss": 0.5982131924829446, "Avg policy loss": 0.29587123822420835, "Total num played games": 22911, "Total num trained steps": 45184, "Timestamp in ms": 1700528835504, "logtype": "training_step"}
{"Avg objective": 21.888749999999984, "Games time in secs": 207.32423398457468, "Avg game time in secs": 1.8219699844921706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 22912, "Total num trained steps": 45311, "Timestamp in ms": 1700528895820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761011774967292, "Avg loss": 0.42430173815228045, "Avg value loss": 0.14308678486850113, "Avg policy loss": 0.2812149543315172, "Total num played games": 22927, "Total num trained steps": 45312, "Timestamp in ms": 1700528896552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748359337650485, "Avg loss": 0.6429849499836564, "Avg value loss": 0.3648065633024089, "Avg policy loss": 0.27817838767077774, "Total num played games": 23009, "Total num trained steps": 45440, "Timestamp in ms": 1700528956534, "logtype": "training_step"}
{"Avg objective": 21.074765624999994, "Games time in secs": 95.09007629007101, "Avg game time in secs": 1.7624377913889475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.52}, "Total num played games": 23040, "Total num trained steps": 45511, "Timestamp in ms": 1700528990910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9762338450863042, "Avg loss": 0.5436259538400918, "Avg value loss": 0.25555086153326556, "Avg policy loss": 0.2880750969052315, "Total num played games": 23058, "Total num trained steps": 45568, "Timestamp in ms": 1700529017204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9775392738131303, "Avg loss": 0.6645398552063853, "Avg value loss": 0.3698005100013688, "Avg policy loss": 0.29473934799898416, "Total num played games": 23107, "Total num trained steps": 45696, "Timestamp in ms": 1700529078157, "logtype": "training_step"}
{"Total num played games": 23156, "Total num trained steps": 45724, "Timestamp in ms": 1700529170687, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4134765625}
{"Avg objective": 22.32820312499999, "Games time in secs": 181.4746768437326, "Avg game time in secs": 2.058814385338337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.64, "agent_stopped_0": 0.52}, "Total num played games": 23168, "Total num trained steps": 45727, "Timestamp in ms": 1700529172386, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9747888295121532, "Avg loss": 0.7498861625790596, "Avg value loss": 0.446169916074723, "Avg policy loss": 0.303716242313385, "Total num played games": 23204, "Total num trained steps": 45824, "Timestamp in ms": 1700529219204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9761321119855502, "Avg loss": 0.7822333220392466, "Avg value loss": 0.4954967248486355, "Avg policy loss": 0.2867365926504135, "Total num played games": 23253, "Total num trained steps": 45952, "Timestamp in ms": 1700529283474, "logtype": "training_step"}
{"Avg objective": 22.70578124999999, "Games time in secs": 135.75840049050748, "Avg game time in secs": 1.8211700012907386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 23296, "Total num trained steps": 46002, "Timestamp in ms": 1700529308149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774277989958375, "Avg loss": 0.7601859311107546, "Avg value loss": 0.46480180346406996, "Avg policy loss": 0.29538413893897086, "Total num played games": 23303, "Total num trained steps": 46080, "Timestamp in ms": 1700529347545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9746581196581197, "Avg loss": 0.5781180809717625, "Avg value loss": 0.29526971571613103, "Avg policy loss": 0.2828483618795872, "Total num played games": 23400, "Total num trained steps": 46208, "Timestamp in ms": 1700529412814, "logtype": "training_step"}
{"Avg objective": 20.857968749999984, "Games time in secs": 147.184142915532, "Avg game time in secs": 1.8628940574708395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.54, "agent_stopped_0": 0.57}, "Total num played games": 23424, "Total num trained steps": 46292, "Timestamp in ms": 1700529455333, "logtype": "played_game"}
{"Total num played games": 23448, "Total num trained steps": 46324, "Timestamp in ms": 1700529544684, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.4090234375}
{"Ratio train steps to played games": 1.972037793667007, "Avg loss": 0.7235291136894375, "Avg value loss": 0.4350127831567079, "Avg policy loss": 0.2885163326282054, "Total num played games": 23496, "Total num trained steps": 46336, "Timestamp in ms": 1700529550915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774855294518217, "Avg loss": 0.6586846229620278, "Avg value loss": 0.36220057494938374, "Avg policy loss": 0.29648405173793435, "Total num played games": 23496, "Total num trained steps": 46464, "Timestamp in ms": 1700529615850, "logtype": "training_step"}
{"Avg objective": 21.62695312499999, "Games time in secs": 221.11251972429454, "Avg game time in secs": 1.8421777584881056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 23552, "Total num trained steps": 46578, "Timestamp in ms": 1700529676446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9747806552791083, "Avg loss": 0.6730181931052357, "Avg value loss": 0.39517987449653447, "Avg policy loss": 0.2778383071999997, "Total num played games": 23593, "Total num trained steps": 46592, "Timestamp in ms": 1700529683196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9760182717929198, "Avg loss": 0.7181577915325761, "Avg value loss": 0.4313148828805424, "Avg policy loss": 0.2868429074296728, "Total num played games": 23643, "Total num trained steps": 46720, "Timestamp in ms": 1700529748254, "logtype": "training_step"}
{"Avg objective": 22.306640624999993, "Games time in secs": 101.32246597111225, "Avg game time in secs": 1.866661288207979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.58}, "Total num played games": 23680, "Total num trained steps": 46782, "Timestamp in ms": 1700529777768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773341212223536, "Avg loss": 0.6516984011977911, "Avg value loss": 0.3496861801831983, "Avg policy loss": 0.3020122265443206, "Total num played games": 23692, "Total num trained steps": 46848, "Timestamp in ms": 1700529808954, "logtype": "training_step"}
{"Total num played games": 23740, "Total num trained steps": 46926, "Timestamp in ms": 1700529920291, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5175}
{"Ratio train steps to played games": 1.974735160585169, "Avg loss": 1.004993891576305, "Avg value loss": 0.6981769348494709, "Avg policy loss": 0.3068169568432495, "Total num played games": 23788, "Total num trained steps": 46976, "Timestamp in ms": 1700529944628, "logtype": "training_step"}
{"Avg objective": 23.336562499999985, "Games time in secs": 210.2197125609964, "Avg game time in secs": 1.9029181030200562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.64, "agent_stopped_0": 0.51}, "Total num played games": 23808, "Total num trained steps": 47067, "Timestamp in ms": 1700529987988, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9760456433276, "Avg loss": 0.6663455232046545, "Avg value loss": 0.37100389308761805, "Avg policy loss": 0.2953416280215606, "Total num played games": 23837, "Total num trained steps": 47104, "Timestamp in ms": 1700530005640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774335356918569, "Avg loss": 0.7551228736992925, "Avg value loss": 0.46635905635776, "Avg policy loss": 0.2887638215906918, "Total num played games": 23885, "Total num trained steps": 47232, "Timestamp in ms": 1700530065830, "logtype": "training_step"}
{"Avg objective": 22.24867187499999, "Games time in secs": 136.04616090655327, "Avg game time in secs": 1.7956116185814608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 23936, "Total num trained steps": 47358, "Timestamp in ms": 1700530124034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9770810720547716, "Avg loss": 0.5420653086621314, "Avg value loss": 0.26111011987086385, "Avg policy loss": 0.2809551879763603, "Total num played games": 23954, "Total num trained steps": 47360, "Timestamp in ms": 1700530124518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9759081263263014, "Avg loss": 1.0441596296150237, "Avg value loss": 0.7509118365123868, "Avg policy loss": 0.2932477965950966, "Total num played games": 24033, "Total num trained steps": 47488, "Timestamp in ms": 1700530184522, "logtype": "training_step"}
{"Total num played games": 24034, "Total num trained steps": 47527, "Timestamp in ms": 1700530272570, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.975625}
{"Avg objective": 21.865390624999993, "Games time in secs": 151.20294564403594, "Avg game time in secs": 1.7905297947872896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.55}, "Total num played games": 24064, "Total num trained steps": 47532, "Timestamp in ms": 1700530275237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9772444149157047, "Avg loss": 0.7005257681012154, "Avg value loss": 0.40233095648000017, "Avg policy loss": 0.2981948103988543, "Total num played games": 24082, "Total num trained steps": 47616, "Timestamp in ms": 1700530315469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9784104094148849, "Avg loss": 0.5437204244080931, "Avg value loss": 0.25450973585247993, "Avg policy loss": 0.2892106892541051, "Total num played games": 24132, "Total num trained steps": 47744, "Timestamp in ms": 1700530374628, "logtype": "training_step"}
{"Avg objective": 20.496953124999987, "Games time in secs": 149.56604483909905, "Avg game time in secs": 2.2716402876540087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.82, "agent_stopped_0": 0.46}, "Total num played games": 24192, "Total num trained steps": 47853, "Timestamp in ms": 1700530424803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756912917870408, "Avg loss": 0.7494163976516575, "Avg value loss": 0.45317749900277704, "Avg policy loss": 0.296238893060945, "Total num played games": 24230, "Total num trained steps": 47872, "Timestamp in ms": 1700530433141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976813146081298, "Avg loss": 0.6365008244756609, "Avg value loss": 0.3358128957916051, "Avg policy loss": 0.3006879260065034, "Total num played games": 24281, "Total num trained steps": 48000, "Timestamp in ms": 1700530493300, "logtype": "training_step"}
{"Avg objective": 21.098281249999992, "Games time in secs": 94.2824584133923, "Avg game time in secs": 1.805166264573927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 24320, "Total num trained steps": 48057, "Timestamp in ms": 1700530519086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780928894369092, "Avg loss": 0.6111268003005534, "Avg value loss": 0.3135017008171417, "Avg policy loss": 0.29762510291766375, "Total num played games": 24330, "Total num trained steps": 48128, "Timestamp in ms": 1700530553821, "logtype": "training_step"}
{"Total num played games": 24330, "Total num trained steps": 48129, "Timestamp in ms": 1700530624894, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.674257812500002}
{"Ratio train steps to played games": 1.9753970853119371, "Avg loss": 0.5583881456404924, "Avg value loss": 0.26831086713355035, "Avg policy loss": 0.2900772801367566, "Total num played games": 24428, "Total num trained steps": 48256, "Timestamp in ms": 1700530683565, "logtype": "training_step"}
{"Avg objective": 21.076328124999986, "Games time in secs": 210.7359331920743, "Avg game time in secs": 1.6726319168083137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.47, "agent_stopped_0": 0.61}, "Total num played games": 24448, "Total num trained steps": 48350, "Timestamp in ms": 1700530729822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976671977775054, "Avg loss": 0.5983773397747427, "Avg value loss": 0.30772497737780213, "Avg policy loss": 0.29065236321184784, "Total num played games": 24477, "Total num trained steps": 48384, "Timestamp in ms": 1700530745600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9778212654924983, "Avg loss": 0.6547077929135412, "Avg value loss": 0.3526792625198141, "Avg policy loss": 0.30202853318769485, "Total num played games": 24528, "Total num trained steps": 48512, "Timestamp in ms": 1700530805192, "logtype": "training_step"}
{"Avg objective": 21.223515624999994, "Games time in secs": 97.62325359135866, "Avg game time in secs": 1.9346454774495214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.69}, "Total num played games": 24576, "Total num trained steps": 48561, "Timestamp in ms": 1700530827445, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9790861374455793, "Avg loss": 0.5713423048146069, "Avg value loss": 0.27541638776892796, "Avg policy loss": 0.29592591838445514, "Total num played games": 24577, "Total num trained steps": 48640, "Timestamp in ms": 1700530864197, "logtype": "training_step"}
{"Total num played games": 24626, "Total num trained steps": 48729, "Timestamp in ms": 1700530975909, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0095703125}
{"Ratio train steps to played games": 1.9764529464213343, "Avg loss": 0.7486351737752557, "Avg value loss": 0.4429459677194245, "Avg policy loss": 0.3056892086751759, "Total num played games": 24674, "Total num trained steps": 48768, "Timestamp in ms": 1700530994807, "logtype": "training_step"}
{"Avg objective": 22.295156249999994, "Games time in secs": 201.51581109687686, "Avg game time in secs": 1.6046559405949665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.49, "agent_stopped_0": 0.61}, "Total num played games": 24704, "Total num trained steps": 48841, "Timestamp in ms": 1700531028967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775530839231548, "Avg loss": 0.5742763939779252, "Avg value loss": 0.27293093118350953, "Avg policy loss": 0.3013454604661092, "Total num played games": 24725, "Total num trained steps": 48896, "Timestamp in ms": 1700531054513, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788084281908453, "Avg loss": 0.6638453968334943, "Avg value loss": 0.35546230972977355, "Avg policy loss": 0.30838307726662606, "Total num played games": 24774, "Total num trained steps": 49024, "Timestamp in ms": 1700531113362, "logtype": "training_step"}
{"Avg objective": 22.069687499999983, "Games time in secs": 137.81530801206827, "Avg game time in secs": 2.0525434929149924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.72}, "Total num played games": 24832, "Total num trained steps": 49137, "Timestamp in ms": 1700531166782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9759990351370909, "Avg loss": 0.6309791950043291, "Avg value loss": 0.31793833180563524, "Avg policy loss": 0.31304086628369987, "Total num played games": 24874, "Total num trained steps": 49152, "Timestamp in ms": 1700531173385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9772107205905953, "Avg loss": 0.6305717786308378, "Avg value loss": 0.3217133909347467, "Avg policy loss": 0.3088583822827786, "Total num played games": 24924, "Total num trained steps": 49280, "Timestamp in ms": 1700531232787, "logtype": "training_step"}
{"Total num played games": 24924, "Total num trained steps": 49332, "Timestamp in ms": 1700531330399, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.000156250000003}
{"Avg objective": 21.440390624999992, "Games time in secs": 166.71496120281518, "Avg game time in secs": 1.7394772287661908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 24960, "Total num trained steps": 49338, "Timestamp in ms": 1700531333497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785359602755086, "Avg loss": 0.5500665823929012, "Avg value loss": 0.2390441809548065, "Avg policy loss": 0.3110224064439535, "Total num played games": 24972, "Total num trained steps": 49408, "Timestamp in ms": 1700531366940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9765771517497306, "Avg loss": 0.7346779264044017, "Avg value loss": 0.4211753116105683, "Avg policy loss": 0.3135026164818555, "Total num played games": 25060, "Total num trained steps": 49536, "Timestamp in ms": 1700531425607, "logtype": "training_step"}
{"Avg objective": 23.241640624999985, "Games time in secs": 141.8092357851565, "Avg game time in secs": 1.8760778970317915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 25088, "Total num trained steps": 49629, "Timestamp in ms": 1700531475307, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977266393279452, "Avg loss": 0.8908507127780467, "Avg value loss": 0.5622754304204136, "Avg policy loss": 0.3285752790980041, "Total num played games": 25117, "Total num trained steps": 49664, "Timestamp in ms": 1700531491179, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785813630041724, "Avg loss": 0.6693473046179861, "Avg value loss": 0.3444997083279304, "Avg policy loss": 0.3248475936707109, "Total num played games": 25165, "Total num trained steps": 49792, "Timestamp in ms": 1700531553137, "logtype": "training_step"}
{"Avg objective": 22.433593749999986, "Games time in secs": 143.9362319521606, "Avg game time in secs": 2.041579623022699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.72, "agent_stopped_0": 0.43}, "Total num played games": 25216, "Total num trained steps": 49918, "Timestamp in ms": 1700531619243, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783616692426584, "Avg loss": 0.5911031360737979, "Avg value loss": 0.26078762795077637, "Avg policy loss": 0.3303155117901042, "Total num played games": 25233, "Total num trained steps": 49920, "Timestamp in ms": 1700531619981, "logtype": "training_step"}
{"Total num played games": 25262, "Total num trained steps": 49934, "Timestamp in ms": 1700531726601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6206640625}
{"Ratio train steps to played games": 1.9773607269853812, "Avg loss": 0.8760692607611418, "Avg value loss": 0.528307442786172, "Avg policy loss": 0.3477618066826835, "Total num played games": 25310, "Total num trained steps": 50048, "Timestamp in ms": 1700531783481, "logtype": "training_step"}
{"Avg objective": 22.061562499999994, "Games time in secs": 195.2267627939582, "Avg game time in secs": 1.6280383085395442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 25344, "Total num trained steps": 50112, "Timestamp in ms": 1700531814470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9782754406024523, "Avg loss": 0.5774724667426199, "Avg value loss": 0.2426068044733256, "Avg policy loss": 0.33486566017381847, "Total num played games": 25363, "Total num trained steps": 50176, "Timestamp in ms": 1700531847542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794978750196757, "Avg loss": 0.6401281652506441, "Avg value loss": 0.3081442406401038, "Avg policy loss": 0.33198392123449594, "Total num played games": 25412, "Total num trained steps": 50304, "Timestamp in ms": 1700531912451, "logtype": "training_step"}
{"Avg objective": 20.16085937499999, "Games time in secs": 151.57118326425552, "Avg game time in secs": 1.9475194071710575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.68, "agent_stopped_0": 0.52}, "Total num played games": 25472, "Total num trained steps": 50415, "Timestamp in ms": 1700531966044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976678556030259, "Avg loss": 0.801452019251883, "Avg value loss": 0.4718354687211104, "Avg policy loss": 0.32961655501276255, "Total num played games": 25513, "Total num trained steps": 50432, "Timestamp in ms": 1700531974727, "logtype": "training_step"}
{"Total num played games": 25564, "Total num trained steps": 50536, "Timestamp in ms": 1700532091643, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8122265625}
{"Avg objective": 21.236718749999987, "Games time in secs": 128.67753256298602, "Avg game time in secs": 1.651415619184263, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 25600, "Total num trained steps": 50541, "Timestamp in ms": 1700532094722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741126859552536, "Avg loss": 0.7946447611320764, "Avg value loss": 0.4670664677978493, "Avg policy loss": 0.3275782912969589, "Total num played games": 25611, "Total num trained steps": 50560, "Timestamp in ms": 1700532104533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790332656567233, "Avg loss": 0.5763331961352378, "Avg value loss": 0.2351505133556202, "Avg policy loss": 0.3411826773080975, "Total num played games": 25612, "Total num trained steps": 50688, "Timestamp in ms": 1700532170608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978662097967448, "Avg loss": 0.682786684948951, "Avg value loss": 0.35740904056001455, "Avg policy loss": 0.3253776472993195, "Total num played games": 25681, "Total num trained steps": 50816, "Timestamp in ms": 1700532235971, "logtype": "training_step"}
{"Avg objective": 21.43882812499998, "Games time in secs": 195.88391998410225, "Avg game time in secs": 2.1950214190001134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.85, "agent_stopped_0": 0.41}, "Total num played games": 25728, "Total num trained steps": 50917, "Timestamp in ms": 1700532290606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774474031519291, "Avg loss": 0.9220222029834986, "Avg value loss": 0.5946580059826374, "Avg policy loss": 0.32736419793218374, "Total num played games": 25762, "Total num trained steps": 50944, "Timestamp in ms": 1700532304693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783459229130351, "Avg loss": 0.6072101378813386, "Avg value loss": 0.283489418332465, "Avg policy loss": 0.3237207215279341, "Total num played games": 25815, "Total num trained steps": 51072, "Timestamp in ms": 1700532367411, "logtype": "training_step"}
{"Avg objective": 22.31757812499999, "Games time in secs": 102.27813924103975, "Avg game time in secs": 1.712015879995306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.64}, "Total num played games": 25856, "Total num trained steps": 51124, "Timestamp in ms": 1700532392884, "logtype": "played_game"}
{"Total num played games": 25864, "Total num trained steps": 51140, "Timestamp in ms": 1700532454941, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.824765625000005}
{"Ratio train steps to played games": 1.9758799012040753, "Avg loss": 0.6753548791166395, "Avg value loss": 0.35132010735105723, "Avg policy loss": 0.32403477479238063, "Total num played games": 25912, "Total num trained steps": 51200, "Timestamp in ms": 1700532485969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771571648690294, "Avg loss": 0.5521296034567058, "Avg value loss": 0.2398050794727169, "Avg policy loss": 0.31232451961841434, "Total num played games": 25960, "Total num trained steps": 51328, "Timestamp in ms": 1700532550856, "logtype": "training_step"}
{"Avg objective": 20.965546874999987, "Games time in secs": 197.65733075141907, "Avg game time in secs": 1.6585034590534633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 25984, "Total num trained steps": 51410, "Timestamp in ms": 1700532590542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978429713934174, "Avg loss": 0.8278412092477083, "Avg value loss": 0.49253611196763813, "Avg policy loss": 0.3353051112499088, "Total num played games": 26008, "Total num trained steps": 51456, "Timestamp in ms": 1700532616774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97969757445502, "Avg loss": 0.6542840031906962, "Avg value loss": 0.31830069387797266, "Avg policy loss": 0.33598330593667924, "Total num played games": 26056, "Total num trained steps": 51584, "Timestamp in ms": 1700532681637, "logtype": "training_step"}
{"Avg objective": 21.950546874999983, "Games time in secs": 148.8637774810195, "Avg game time in secs": 1.8827389708312694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 26112, "Total num trained steps": 51697, "Timestamp in ms": 1700532739406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773248699908228, "Avg loss": 0.7335792004596442, "Avg value loss": 0.40121331316186115, "Avg policy loss": 0.3323658991139382, "Total num played games": 26152, "Total num trained steps": 51712, "Timestamp in ms": 1700532746422, "logtype": "training_step"}
{"Total num played games": 26152, "Total num trained steps": 51743, "Timestamp in ms": 1700532829061, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.355000000000004}
{"Ratio train steps to played games": 1.9786259541984732, "Avg loss": 0.6849219403229654, "Avg value loss": 0.3339481594739482, "Avg policy loss": 0.3509737830609083, "Total num played games": 26200, "Total num trained steps": 51840, "Timestamp in ms": 1700532878127, "logtype": "training_step"}
{"Avg objective": 22.156874999999996, "Games time in secs": 163.8155097141862, "Avg game time in secs": 1.5333917943644337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 26240, "Total num trained steps": 51892, "Timestamp in ms": 1700532903221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9798460835111247, "Avg loss": 0.6536151731852442, "Avg value loss": 0.32559140893863514, "Avg policy loss": 0.3280237694270909, "Total num played games": 26248, "Total num trained steps": 51968, "Timestamp in ms": 1700532938593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774901305800183, "Avg loss": 0.6807764796540141, "Avg value loss": 0.3634481712942943, "Avg policy loss": 0.3173283152282238, "Total num played games": 26344, "Total num trained steps": 52096, "Timestamp in ms": 1700532999574, "logtype": "training_step"}
{"Avg objective": 20.68226562499999, "Games time in secs": 138.1236410960555, "Avg game time in secs": 1.6175867613928858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 26368, "Total num trained steps": 52179, "Timestamp in ms": 1700533041345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787814489239164, "Avg loss": 0.7581065457779914, "Avg value loss": 0.43686461419565603, "Avg policy loss": 0.32124191988259554, "Total num played games": 26392, "Total num trained steps": 52224, "Timestamp in ms": 1700533063713, "logtype": "training_step"}
{"Total num played games": 26440, "Total num trained steps": 52344, "Timestamp in ms": 1700533201766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1016015625}
{"Ratio train steps to played games": 1.9764044095439444, "Avg loss": 0.6732212270144373, "Avg value loss": 0.3494477420463227, "Avg policy loss": 0.32377348153386265, "Total num played games": 26488, "Total num trained steps": 52352, "Timestamp in ms": 1700533206976, "logtype": "training_step"}
{"Avg objective": 21.306015624999983, "Games time in secs": 227.2414783090353, "Avg game time in secs": 1.7203021388850175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.61, "agent_stopped_0": 0.49}, "Total num played games": 26496, "Total num trained steps": 52466, "Timestamp in ms": 1700533268587, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775784753363228, "Avg loss": 0.6379918667953461, "Avg value loss": 0.31799151288578287, "Avg policy loss": 0.3200003581587225, "Total num played games": 26537, "Total num trained steps": 52480, "Timestamp in ms": 1700533274591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786369790883105, "Avg loss": 0.7242677102331072, "Avg value loss": 0.413381869031582, "Avg policy loss": 0.31088584440294653, "Total num played games": 26588, "Total num trained steps": 52608, "Timestamp in ms": 1700533338128, "logtype": "training_step"}
{"Avg objective": 21.068437499999987, "Games time in secs": 99.8895635548979, "Avg game time in secs": 1.4471125872514676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.5}, "Total num played games": 26624, "Total num trained steps": 52668, "Timestamp in ms": 1700533368476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979876858387145, "Avg loss": 0.5805587493814528, "Avg value loss": 0.2632944182259962, "Avg policy loss": 0.31726433348376304, "Total num played games": 26636, "Total num trained steps": 52736, "Timestamp in ms": 1700533403592, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9805552433404519, "Avg loss": 0.7719085675198585, "Avg value loss": 0.454615680326242, "Avg policy loss": 0.31729288795031607, "Total num played games": 26691, "Total num trained steps": 52864, "Timestamp in ms": 1700533471402, "logtype": "training_step"}
{"Total num played games": 26739, "Total num trained steps": 52947, "Timestamp in ms": 1700533622455, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.570468750000003}
{"Avg objective": 22.569765624999988, "Games time in secs": 255.6207653451711, "Avg game time in secs": 1.5645880068623228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.59, "agent_stopped_0": 0.54}, "Total num played games": 26752, "Total num trained steps": 52949, "Timestamp in ms": 1700533624097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9782357113525217, "Avg loss": 0.8708495886530727, "Avg value loss": 0.5458723443443887, "Avg policy loss": 0.32497725263237953, "Total num played games": 26787, "Total num trained steps": 52992, "Timestamp in ms": 1700533645506, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979430615590997, "Avg loss": 0.7805546321906149, "Avg value loss": 0.4578869753750041, "Avg policy loss": 0.32266765367239714, "Total num played games": 26836, "Total num trained steps": 53120, "Timestamp in ms": 1700533710932, "logtype": "training_step"}
{"Avg objective": 21.79406249999999, "Games time in secs": 112.43775945156813, "Avg game time in secs": 1.5221651191968704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 26880, "Total num trained steps": 53166, "Timestamp in ms": 1700533736535, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805467732936581, "Avg loss": 0.606557433726266, "Avg value loss": 0.283919884939678, "Avg policy loss": 0.3226375513477251, "Total num played games": 26885, "Total num trained steps": 53248, "Timestamp in ms": 1700533782629, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776946163251694, "Avg loss": 0.7450820549856871, "Avg value loss": 0.42004112829454243, "Avg policy loss": 0.3250409214524552, "Total num played games": 26989, "Total num trained steps": 53376, "Timestamp in ms": 1700533848918, "logtype": "training_step"}
{"Avg objective": 20.493984374999982, "Games time in secs": 160.18597088754177, "Avg game time in secs": 1.578350037598284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 27008, "Total num trained steps": 53469, "Timestamp in ms": 1700533896721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788445890968267, "Avg loss": 0.681244119303301, "Avg value loss": 0.3582196882343851, "Avg policy loss": 0.3230244282167405, "Total num played games": 27038, "Total num trained steps": 53504, "Timestamp in ms": 1700533914886, "logtype": "training_step"}
{"Total num played games": 27038, "Total num trained steps": 53548, "Timestamp in ms": 1700534035329, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.96328125}
{"Ratio train steps to played games": 1.9800265819980802, "Avg loss": 0.6346276844851673, "Avg value loss": 0.31287310260813683, "Avg policy loss": 0.32175458362326026, "Total num played games": 27086, "Total num trained steps": 53632, "Timestamp in ms": 1700534078267, "logtype": "training_step"}
{"Avg objective": 21.672265624999994, "Games time in secs": 246.5757899377495, "Avg game time in secs": 1.6499580764357233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 27136, "Total num trained steps": 53759, "Timestamp in ms": 1700534143297, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802563724767939, "Avg loss": 0.5172016825526953, "Avg value loss": 0.21402446390129626, "Avg policy loss": 0.3031772155081853, "Total num played games": 27138, "Total num trained steps": 53760, "Timestamp in ms": 1700534143550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789210825896955, "Avg loss": 0.7132850068155676, "Avg value loss": 0.4123795219929889, "Avg policy loss": 0.3009054873837158, "Total num played games": 27231, "Total num trained steps": 53888, "Timestamp in ms": 1700534208277, "logtype": "training_step"}
{"Avg objective": 22.31546874999999, "Games time in secs": 98.33884559571743, "Avg game time in secs": 1.4475430261954898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.46}, "Total num played games": 27264, "Total num trained steps": 53953, "Timestamp in ms": 1700534241636, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801312364822758, "Avg loss": 0.7472550901584327, "Avg value loss": 0.45521180890500546, "Avg policy loss": 0.29204327589832246, "Total num played games": 27279, "Total num trained steps": 54016, "Timestamp in ms": 1700534274283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812280444964872, "Avg loss": 0.5517938195262104, "Avg value loss": 0.2609230624511838, "Avg policy loss": 0.2908707547467202, "Total num played games": 27328, "Total num trained steps": 54144, "Timestamp in ms": 1700534339192, "logtype": "training_step"}
{"Total num played games": 27379, "Total num trained steps": 54152, "Timestamp in ms": 1700534403620, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.252187499999998}
{"Avg objective": 20.968281249999986, "Games time in secs": 163.6455422323197, "Avg game time in secs": 1.755256217715214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.65, "agent_stopped_0": 0.5}, "Total num played games": 27392, "Total num trained steps": 54153, "Timestamp in ms": 1700534405282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787800342727968, "Avg loss": 0.8148959048558027, "Avg value loss": 0.5019243652350269, "Avg policy loss": 0.31297154212370515, "Total num played games": 27427, "Total num trained steps": 54272, "Timestamp in ms": 1700534472413, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798733440093172, "Avg loss": 0.5802145558409393, "Avg value loss": 0.28499639860820025, "Avg policy loss": 0.2952181560685858, "Total num played games": 27476, "Total num trained steps": 54400, "Timestamp in ms": 1700534547179, "logtype": "training_step"}
{"Avg objective": 22.23015624999999, "Games time in secs": 165.77545448206365, "Avg game time in secs": 1.6545124234544346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 27520, "Total num trained steps": 54447, "Timestamp in ms": 1700534571057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9809634527355955, "Avg loss": 0.6149364241864532, "Avg value loss": 0.31689843197818846, "Avg policy loss": 0.29803799313958734, "Total num played games": 27526, "Total num trained steps": 54528, "Timestamp in ms": 1700534615475, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783545082708944, "Avg loss": 0.6776234025601298, "Avg value loss": 0.3849006770760752, "Avg policy loss": 0.2927227218169719, "Total num played games": 27627, "Total num trained steps": 54656, "Timestamp in ms": 1700534676781, "logtype": "training_step"}
{"Avg objective": 21.576406249999984, "Games time in secs": 149.6118910200894, "Avg game time in secs": 1.5711011371313361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 27648, "Total num trained steps": 54744, "Timestamp in ms": 1700534720670, "logtype": "played_game"}
{"Total num played games": 27675, "Total num trained steps": 54755, "Timestamp in ms": 1700534827265, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.582187500000003}
{"Ratio train steps to played games": 1.9760848393031056, "Avg loss": 0.8341055153869092, "Avg value loss": 0.5332075454643928, "Avg policy loss": 0.3008979697478935, "Total num played games": 27723, "Total num trained steps": 54784, "Timestamp in ms": 1700534841421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807019442340295, "Avg loss": 0.4495779734570533, "Avg value loss": 0.15689776703948155, "Avg policy loss": 0.2926802064757794, "Total num played games": 27723, "Total num trained steps": 54912, "Timestamp in ms": 1700534904338, "logtype": "training_step"}
{"Avg objective": 21.815312499999987, "Games time in secs": 246.23145486414433, "Avg game time in secs": 1.6402336344035575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.57, "agent_stopped_0": 0.53}, "Total num played games": 27776, "Total num trained steps": 55032, "Timestamp in ms": 1700534966901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786102023942194, "Avg loss": 0.6166374105960131, "Avg value loss": 0.34262364445021376, "Avg policy loss": 0.2740137542132288, "Total num played games": 27817, "Total num trained steps": 55040, "Timestamp in ms": 1700534970389, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796533534287868, "Avg loss": 0.5500937793403864, "Avg value loss": 0.274234002456069, "Avg policy loss": 0.2758597795618698, "Total num played games": 27867, "Total num trained steps": 55168, "Timestamp in ms": 1700535031941, "logtype": "training_step"}
{"Avg objective": 20.43890624999999, "Games time in secs": 94.58538539893925, "Avg game time in secs": 1.3939440661051776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 27904, "Total num trained steps": 55227, "Timestamp in ms": 1700535061487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980621821047353, "Avg loss": 0.5794695178046823, "Avg value loss": 0.2912425518152304, "Avg policy loss": 0.2882269687252119, "Total num played games": 27918, "Total num trained steps": 55296, "Timestamp in ms": 1700535098249, "logtype": "training_step"}
{"Total num played games": 27968, "Total num trained steps": 55357, "Timestamp in ms": 1700535220454, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.285273437500003}
{"Ratio train steps to played games": 1.9782624214734437, "Avg loss": 0.7853009374812245, "Avg value loss": 0.48564593883929774, "Avg policy loss": 0.29965499916579574, "Total num played games": 28016, "Total num trained steps": 55424, "Timestamp in ms": 1700535253477, "logtype": "training_step"}
{"Avg objective": 21.621953124999987, "Games time in secs": 246.682777101174, "Avg game time in secs": 1.537289372718078, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 28032, "Total num trained steps": 55522, "Timestamp in ms": 1700535308170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9794398517673888, "Avg loss": 0.614555777516216, "Avg value loss": 0.32550946989795193, "Avg policy loss": 0.28904630430042744, "Total num played games": 28064, "Total num trained steps": 55552, "Timestamp in ms": 1700535323300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9805783801088463, "Avg loss": 0.6067343491595238, "Avg value loss": 0.3196310556959361, "Avg policy loss": 0.28710329066962004, "Total num played games": 28113, "Total num trained steps": 55680, "Timestamp in ms": 1700535384696, "logtype": "training_step"}
{"Avg objective": 22.416640624999992, "Games time in secs": 97.11742126569152, "Avg game time in secs": 1.7149296232964844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.7}, "Total num played games": 28160, "Total num trained steps": 55723, "Timestamp in ms": 1700535405287, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816419288402811, "Avg loss": 0.5521682538092136, "Avg value loss": 0.25978361355373636, "Avg policy loss": 0.29238463833462447, "Total num played games": 28162, "Total num trained steps": 55808, "Timestamp in ms": 1700535447759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794394507750017, "Avg loss": 0.8514585103839636, "Avg value loss": 0.5588295353809372, "Avg policy loss": 0.29262896918226033, "Total num played games": 28258, "Total num trained steps": 55936, "Timestamp in ms": 1700535511345, "logtype": "training_step"}
{"Total num played games": 28258, "Total num trained steps": 55957, "Timestamp in ms": 1700535629797, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2601171875}
{"Avg objective": 22.798203124999986, "Games time in secs": 226.894717393443, "Avg game time in secs": 1.399579347576946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 28288, "Total num trained steps": 55961, "Timestamp in ms": 1700535632182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806048187663392, "Avg loss": 0.5332350060343742, "Avg value loss": 0.2338403484900482, "Avg policy loss": 0.29939465573988855, "Total num played games": 28306, "Total num trained steps": 56064, "Timestamp in ms": 1700535683306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817316169987655, "Avg loss": 0.6111980876885355, "Avg value loss": 0.3282059273333289, "Avg policy loss": 0.28299217228777707, "Total num played games": 28355, "Total num trained steps": 56192, "Timestamp in ms": 1700535748867, "logtype": "training_step"}
{"Avg objective": 21.849687499999984, "Games time in secs": 170.43488548323512, "Avg game time in secs": 1.4637114090437535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 28416, "Total num trained steps": 56298, "Timestamp in ms": 1700535802617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979404632200471, "Avg loss": 0.719753626268357, "Avg value loss": 0.42825625865953043, "Avg policy loss": 0.29149736755061895, "Total num played games": 28453, "Total num trained steps": 56320, "Timestamp in ms": 1700535813861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980388029330246, "Avg loss": 0.596169906668365, "Avg value loss": 0.3074312079115771, "Avg policy loss": 0.288738698232919, "Total num played games": 28503, "Total num trained steps": 56448, "Timestamp in ms": 1700535877127, "logtype": "training_step"}
{"Avg objective": 21.801171874999994, "Games time in secs": 99.46848089993, "Avg game time in secs": 1.4813957537116949, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 28544, "Total num trained steps": 56499, "Timestamp in ms": 1700535902086, "logtype": "played_game"}
{"Total num played games": 28555, "Total num trained steps": 56557, "Timestamp in ms": 1700536034094, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.601953125}
{"Ratio train steps to played games": 1.9779743383561166, "Avg loss": 0.7375956000760198, "Avg value loss": 0.45751674921484664, "Avg policy loss": 0.28007885185070336, "Total num played games": 28603, "Total num trained steps": 56576, "Timestamp in ms": 1700536043601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789209185454038, "Avg loss": 0.47811451298184693, "Avg value loss": 0.21023561886977404, "Avg policy loss": 0.26787889061961323, "Total num played games": 28654, "Total num trained steps": 56704, "Timestamp in ms": 1700536108864, "logtype": "training_step"}
{"Avg objective": 20.89296874999999, "Games time in secs": 253.54315230436623, "Avg game time in secs": 1.3956897293537622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.44, "agent_stopped_0": 0.62}, "Total num played games": 28672, "Total num trained steps": 56799, "Timestamp in ms": 1700536155629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9797603288511112, "Avg loss": 0.6314821012783796, "Avg value loss": 0.3657388422288932, "Avg policy loss": 0.2657432503765449, "Total num played games": 28706, "Total num trained steps": 56832, "Timestamp in ms": 1700536171449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808381151104155, "Avg loss": 0.621087426552549, "Avg value loss": 0.3467982230358757, "Avg policy loss": 0.27428921626415104, "Total num played games": 28755, "Total num trained steps": 56960, "Timestamp in ms": 1700536233801, "logtype": "training_step"}
{"Avg objective": 21.253984374999987, "Games time in secs": 99.62226934544742, "Avg game time in secs": 1.560315317401546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.65}, "Total num played games": 28800, "Total num trained steps": 57005, "Timestamp in ms": 1700536255252, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819810436412875, "Avg loss": 0.5467440104112029, "Avg value loss": 0.2639036236796528, "Avg policy loss": 0.2828403915045783, "Total num played games": 28803, "Total num trained steps": 57088, "Timestamp in ms": 1700536299304, "logtype": "training_step"}
{"Total num played games": 28851, "Total num trained steps": 57157, "Timestamp in ms": 1700536430957, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.189531250000005}
{"Ratio train steps to played games": 1.9798262915671823, "Avg loss": 0.7294170907698572, "Avg value loss": 0.44748117949347943, "Avg policy loss": 0.2819359127897769, "Total num played games": 28899, "Total num trained steps": 57216, "Timestamp in ms": 1700536460459, "logtype": "training_step"}
{"Avg objective": 21.12531249999999, "Games time in secs": 243.70226516388357, "Avg game time in secs": 1.6017330154427327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.62, "agent_stopped_0": 0.52}, "Total num played games": 28928, "Total num trained steps": 57290, "Timestamp in ms": 1700536498954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807599309153714, "Avg loss": 0.570372212678194, "Avg value loss": 0.28117194381775334, "Avg policy loss": 0.28920026880223304, "Total num played games": 28950, "Total num trained steps": 57344, "Timestamp in ms": 1700536526299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817586206896551, "Avg loss": 0.6362329802941531, "Avg value loss": 0.34663866501068696, "Avg policy loss": 0.28959430987015367, "Total num played games": 29000, "Total num trained steps": 57472, "Timestamp in ms": 1700536589061, "logtype": "training_step"}
{"Avg objective": 21.60960937499999, "Games time in secs": 148.1850732192397, "Avg game time in secs": 1.6873123007098911, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.63}, "Total num played games": 29056, "Total num trained steps": 57590, "Timestamp in ms": 1700536647140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795511564766126, "Avg loss": 0.6355632415506989, "Avg value loss": 0.35109138733241707, "Avg policy loss": 0.28447186190169305, "Total num played games": 29097, "Total num trained steps": 57600, "Timestamp in ms": 1700536651628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804789350898861, "Avg loss": 1.1763994432985783, "Avg value loss": 0.8874650639481843, "Avg policy loss": 0.2889343900606036, "Total num played games": 29148, "Total num trained steps": 57728, "Timestamp in ms": 1700536716600, "logtype": "training_step"}
{"Total num played games": 29148, "Total num trained steps": 57758, "Timestamp in ms": 1700536786777, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.872695312500003}
{"Avg objective": 22.26843749999999, "Games time in secs": 142.89441602490842, "Avg game time in secs": 1.5758834387088427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.53}, "Total num played games": 29184, "Total num trained steps": 57766, "Timestamp in ms": 1700536790035, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816070694615702, "Avg loss": 0.7134694384876639, "Avg value loss": 0.4088824433856644, "Avg policy loss": 0.30458699236623943, "Total num played games": 29196, "Total num trained steps": 57856, "Timestamp in ms": 1700536835374, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798203981288627, "Avg loss": 0.5976229982916266, "Avg value loss": 0.30019681656267494, "Avg policy loss": 0.2974261804483831, "Total num played games": 29287, "Total num trained steps": 57984, "Timestamp in ms": 1700536899507, "logtype": "training_step"}
{"Avg objective": 20.578515624999987, "Games time in secs": 153.4158620648086, "Avg game time in secs": 1.7346758109051734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.73, "agent_stopped_0": 0.45}, "Total num played games": 29312, "Total num trained steps": 58076, "Timestamp in ms": 1700536943451, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9804382646627816, "Avg loss": 0.6905610517133027, "Avg value loss": 0.38497046870179474, "Avg policy loss": 0.3055905778892338, "Total num played games": 29343, "Total num trained steps": 58112, "Timestamp in ms": 1700536961121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814241486068112, "Avg loss": 0.5423396560363472, "Avg value loss": 0.24331213254481554, "Avg policy loss": 0.2990275213960558, "Total num played games": 29393, "Total num trained steps": 58240, "Timestamp in ms": 1700537023431, "logtype": "training_step"}
{"Avg objective": 21.354999999999983, "Games time in secs": 99.59869734942913, "Avg game time in secs": 1.6026436478132382, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 29440, "Total num trained steps": 58280, "Timestamp in ms": 1700537043050, "logtype": "played_game"}
{"Total num played games": 29441, "Total num trained steps": 58359, "Timestamp in ms": 1700537171705, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.388789062500003}
{"Ratio train steps to played games": 1.979750356149515, "Avg loss": 0.6794603266753256, "Avg value loss": 0.38999334251275286, "Avg policy loss": 0.2894669871311635, "Total num played games": 29482, "Total num trained steps": 58368, "Timestamp in ms": 1700537176104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803304218295077, "Avg loss": 0.8753342307172716, "Avg value loss": 0.5683947505312972, "Avg policy loss": 0.3069394811755046, "Total num played games": 29538, "Total num trained steps": 58496, "Timestamp in ms": 1700537238093, "logtype": "training_step"}
{"Avg objective": 21.841874999999995, "Games time in secs": 231.28934047184885, "Avg game time in secs": 1.459741590268095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.55, "agent_stopped_0": 0.59}, "Total num played games": 29568, "Total num trained steps": 58568, "Timestamp in ms": 1700537274339, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812430295042076, "Avg loss": 0.6144983975682408, "Avg value loss": 0.32263215869897977, "Avg policy loss": 0.2918662374140695, "Total num played games": 29589, "Total num trained steps": 58624, "Timestamp in ms": 1700537301529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823868812632857, "Avg loss": 0.6044018308166414, "Avg value loss": 0.32588237582240254, "Avg policy loss": 0.27851944346912205, "Total num played games": 29637, "Total num trained steps": 58752, "Timestamp in ms": 1700537367314, "logtype": "training_step"}
{"Avg objective": 22.645781249999985, "Games time in secs": 150.40316403843462, "Avg game time in secs": 1.5458441106165992, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 29696, "Total num trained steps": 58866, "Timestamp in ms": 1700537424742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800248848236204, "Avg loss": 0.6811831388622522, "Avg value loss": 0.39984486025059596, "Avg policy loss": 0.281338284839876, "Total num played games": 29737, "Total num trained steps": 58880, "Timestamp in ms": 1700537430838, "logtype": "training_step"}
{"Total num played games": 29753, "Total num trained steps": 58963, "Timestamp in ms": 1700537548268, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.425234375000002}
{"Ratio train steps to played games": 1.9800677829603033, "Avg loss": 0.8063791159074754, "Avg value loss": 0.5137824988923967, "Avg policy loss": 0.29259661328978837, "Total num played games": 29801, "Total num trained steps": 59008, "Timestamp in ms": 1700537572084, "logtype": "training_step"}
{"Avg objective": 22.22234374999999, "Games time in secs": 189.01058939099312, "Avg game time in secs": 1.5288695948111126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 29824, "Total num trained steps": 59093, "Timestamp in ms": 1700537613753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811383965962008, "Avg loss": 0.617222287459299, "Avg value loss": 0.332836473477073, "Avg policy loss": 0.2843858164269477, "Total num played games": 29849, "Total num trained steps": 59136, "Timestamp in ms": 1700537635013, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821064249640457, "Avg loss": 0.7536814054474235, "Avg value loss": 0.4541848215740174, "Avg policy loss": 0.2994965848047286, "Total num played games": 29899, "Total num trained steps": 59264, "Timestamp in ms": 1700537698769, "logtype": "training_step"}
{"Avg objective": 22.404453124999986, "Games time in secs": 146.40649665519595, "Avg game time in secs": 1.6504181015188806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 29952, "Total num trained steps": 59384, "Timestamp in ms": 1700537760163, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800300050008335, "Avg loss": 0.6303777333814651, "Avg value loss": 0.3237140260753222, "Avg policy loss": 0.3066637066658586, "Total num played games": 29995, "Total num trained steps": 59392, "Timestamp in ms": 1700537764629, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809625241296678, "Avg loss": 0.7776290606707335, "Avg value loss": 0.4820754607208073, "Avg policy loss": 0.29555359843652695, "Total num played games": 30046, "Total num trained steps": 59520, "Timestamp in ms": 1700537831766, "logtype": "training_step"}
{"Total num played games": 30046, "Total num trained steps": 59563, "Timestamp in ms": 1700537918009, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.524687500000002}
{"Avg objective": 21.457656249999985, "Games time in secs": 160.15728501044214, "Avg game time in secs": 1.3789320998912444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 30080, "Total num trained steps": 59568, "Timestamp in ms": 1700537920321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982022994616867, "Avg loss": 0.6219243374653161, "Avg value loss": 0.3218706678599119, "Avg policy loss": 0.30005367135163397, "Total num played games": 30094, "Total num trained steps": 59648, "Timestamp in ms": 1700537956865, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814698180130605, "Avg loss": 0.575559233315289, "Avg value loss": 0.282055861025583, "Avg policy loss": 0.2935033756075427, "Total num played games": 30166, "Total num trained steps": 59776, "Timestamp in ms": 1700538019858, "logtype": "training_step"}
{"Avg objective": 21.815390624999985, "Games time in secs": 152.66377526707947, "Avg game time in secs": 1.478344750139513, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 30208, "Total num trained steps": 59878, "Timestamp in ms": 1700538072985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805594128149178, "Avg loss": 0.7025303195696324, "Avg value loss": 0.3969114383799024, "Avg policy loss": 0.3056188845075667, "Total num played games": 30246, "Total num trained steps": 59904, "Timestamp in ms": 1700538085195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815157116451017, "Avg loss": 0.6290373727679253, "Avg value loss": 0.3224921177024953, "Avg policy loss": 0.30654525221325457, "Total num played games": 30296, "Total num trained steps": 60032, "Timestamp in ms": 1700538144075, "logtype": "training_step"}
{"Avg objective": 22.632265624999988, "Games time in secs": 95.43662993423641, "Avg game time in secs": 1.4864313116122503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.58}, "Total num played games": 30336, "Total num trained steps": 60085, "Timestamp in ms": 1700538168421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982599525441603, "Avg loss": 0.7028505872003734, "Avg value loss": 0.3987427013926208, "Avg policy loss": 0.30410787742584944, "Total num played games": 30344, "Total num trained steps": 60160, "Timestamp in ms": 1700538203615, "logtype": "training_step"}
{"Total num played games": 30344, "Total num trained steps": 60164, "Timestamp in ms": 1700538283518, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.622812500000002}
{"Ratio train steps to played games": 1.9802916830902642, "Avg loss": 0.7675435394048691, "Avg value loss": 0.45918426726711914, "Avg policy loss": 0.3083592674229294, "Total num played games": 30444, "Total num trained steps": 60288, "Timestamp in ms": 1700538342902, "logtype": "training_step"}
{"Avg objective": 21.474453124999986, "Games time in secs": 218.3602112159133, "Avg game time in secs": 1.5217988929798594, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.51, "agent_stopped_0": 0.6}, "Total num played games": 30464, "Total num trained steps": 60380, "Timestamp in ms": 1700538386782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812422115826065, "Avg loss": 0.7020039500202984, "Avg value loss": 0.3930989491054788, "Avg policy loss": 0.30890499940142035, "Total num played games": 30494, "Total num trained steps": 60416, "Timestamp in ms": 1700538405212, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821247339990178, "Avg loss": 0.5884154089726508, "Avg value loss": 0.2824858769890852, "Avg policy loss": 0.3059295325074345, "Total num played games": 30545, "Total num trained steps": 60544, "Timestamp in ms": 1700538464308, "logtype": "training_step"}
{"Avg objective": 20.78890624999999, "Games time in secs": 96.24442956410348, "Avg game time in secs": 1.7897630369116087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 30592, "Total num trained steps": 60585, "Timestamp in ms": 1700538483026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829068209301566, "Avg loss": 0.5400614733807743, "Avg value loss": 0.23313815577421337, "Avg policy loss": 0.30692331632599235, "Total num played games": 30597, "Total num trained steps": 60672, "Timestamp in ms": 1700538522464, "logtype": "training_step"}
{"Total num played games": 30645, "Total num trained steps": 60767, "Timestamp in ms": 1700538689499, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8815234375}
{"Ratio train steps to played games": 1.980907698823836, "Avg loss": 0.6791671216487885, "Avg value loss": 0.38668091187719256, "Avg policy loss": 0.2924861984793097, "Total num played games": 30693, "Total num trained steps": 60800, "Timestamp in ms": 1700538704413, "logtype": "training_step"}
{"Avg objective": 20.72859374999999, "Games time in secs": 257.3895696885884, "Avg game time in secs": 1.6034097152296454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.64, "agent_stopped_0": 0.52}, "Total num played games": 30720, "Total num trained steps": 60878, "Timestamp in ms": 1700538740416, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981785063752277, "Avg loss": 0.6892469874583185, "Avg value loss": 0.39843602501787245, "Avg policy loss": 0.29081095720175654, "Total num played games": 30744, "Total num trained steps": 60928, "Timestamp in ms": 1700538763274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828202130423487, "Avg loss": 0.563010833458975, "Avg value loss": 0.27951679221587256, "Avg policy loss": 0.28349404758773744, "Total num played games": 30792, "Total num trained steps": 61056, "Timestamp in ms": 1700538822409, "logtype": "training_step"}
{"Avg objective": 22.197187499999988, "Games time in secs": 139.58198158442974, "Avg game time in secs": 1.641394309772295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.61, "agent_stopped_0": 0.51}, "Total num played games": 30848, "Total num trained steps": 61180, "Timestamp in ms": 1700538879998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808339808339808, "Avg loss": 0.5981441710609943, "Avg value loss": 0.30879435513634235, "Avg policy loss": 0.28934981185011566, "Total num played games": 30887, "Total num trained steps": 61184, "Timestamp in ms": 1700538881870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813216997899499, "Avg loss": 1.0503976242616773, "Avg value loss": 0.7573921834700741, "Avg policy loss": 0.29300542711280286, "Total num played games": 30945, "Total num trained steps": 61312, "Timestamp in ms": 1700538941756, "logtype": "training_step"}
{"Total num played games": 30945, "Total num trained steps": 61368, "Timestamp in ms": 1700539036085, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.080546875000003}
{"Avg objective": 21.920312499999994, "Games time in secs": 158.68728033453226, "Avg game time in secs": 1.4354158358328277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 30976, "Total num trained steps": 61371, "Timestamp in ms": 1700539038686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823831187687542, "Avg loss": 0.5573121514171362, "Avg value loss": 0.26741326675983146, "Avg policy loss": 0.28989888296928257, "Total num played games": 30993, "Total num trained steps": 61440, "Timestamp in ms": 1700539070789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833451452870305, "Avg loss": 0.6197051422204822, "Avg value loss": 0.3366963610169478, "Avg policy loss": 0.28300878091249615, "Total num played games": 31042, "Total num trained steps": 61568, "Timestamp in ms": 1700539130946, "logtype": "training_step"}
{"Avg objective": 21.07546874999998, "Games time in secs": 142.246497053653, "Avg game time in secs": 1.624006692552939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 31104, "Total num trained steps": 61676, "Timestamp in ms": 1700539180932, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9809279178038208, "Avg loss": 0.8156367165502161, "Avg value loss": 0.5217380403773859, "Avg policy loss": 0.29389867407735437, "Total num played games": 31145, "Total num trained steps": 61696, "Timestamp in ms": 1700539189555, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981919599923062, "Avg loss": 0.7659683541860431, "Avg value loss": 0.4667788908118382, "Avg policy loss": 0.2991894556907937, "Total num played games": 31194, "Total num trained steps": 61824, "Timestamp in ms": 1700539251528, "logtype": "training_step"}
{"Avg objective": 22.349531249999984, "Games time in secs": 96.80932321026921, "Avg game time in secs": 1.4966686925909016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.58}, "Total num played games": 31232, "Total num trained steps": 61880, "Timestamp in ms": 1700539277742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828127000384075, "Avg loss": 0.6998852870892733, "Avg value loss": 0.4004708912107162, "Avg policy loss": 0.29941439523827285, "Total num played games": 31244, "Total num trained steps": 61952, "Timestamp in ms": 1700539310538, "logtype": "training_step"}
{"Total num played games": 31244, "Total num trained steps": 61972, "Timestamp in ms": 1700539378477, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.040859375000004}
{"Ratio train steps to played games": 1.981297673379504, "Avg loss": 0.6690737041644752, "Avg value loss": 0.36627187189878896, "Avg policy loss": 0.3028018338372931, "Total num played games": 31332, "Total num trained steps": 62080, "Timestamp in ms": 1700539430017, "logtype": "training_step"}
{"Avg objective": 22.439531249999984, "Games time in secs": 196.09534005448222, "Avg game time in secs": 1.564090637199115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.67}, "Total num played games": 31360, "Total num trained steps": 62170, "Timestamp in ms": 1700539473837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818720530138907, "Avg loss": 0.8532736198976636, "Avg value loss": 0.5382341233780608, "Avg policy loss": 0.3150394909316674, "Total num played games": 31388, "Total num trained steps": 62208, "Timestamp in ms": 1700539491821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828233348177364, "Avg loss": 0.5838638029526919, "Avg value loss": 0.27623070328263566, "Avg policy loss": 0.307633098680526, "Total num played games": 31438, "Total num trained steps": 62336, "Timestamp in ms": 1700539553692, "logtype": "training_step"}
{"Avg objective": 21.604140624999985, "Games time in secs": 137.167829150334, "Avg game time in secs": 1.491340609427425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.61}, "Total num played games": 31488, "Total num trained steps": 62463, "Timestamp in ms": 1700539611005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983676839531265, "Avg loss": 0.5904576205648482, "Avg value loss": 0.2889836634276435, "Avg policy loss": 0.30147395422682166, "Total num played games": 31488, "Total num trained steps": 62464, "Timestamp in ms": 1700539611069, "logtype": "training_step"}
{"Total num played games": 31584, "Total num trained steps": 62575, "Timestamp in ms": 1700539727463, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.180390625}
{"Avg objective": 22.60828124999999, "Games time in secs": 118.89864354208112, "Avg game time in secs": 1.4849173718685051, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 31616, "Total num trained steps": 62580, "Timestamp in ms": 1700539729904, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787240768841678, "Avg loss": 0.871965243248269, "Avg value loss": 0.5651908227009699, "Avg policy loss": 0.30677442357409745, "Total num played games": 31632, "Total num trained steps": 62592, "Timestamp in ms": 1700539735198, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982770612038442, "Avg loss": 0.5731930711772293, "Avg value loss": 0.25889775581890717, "Avg policy loss": 0.3142953156493604, "Total num played games": 31632, "Total num trained steps": 62720, "Timestamp in ms": 1700539795485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98355636914531, "Avg loss": 0.6133052131626755, "Avg value loss": 0.3112053196527995, "Avg policy loss": 0.3020998905412853, "Total num played games": 31684, "Total num trained steps": 62848, "Timestamp in ms": 1700539858315, "logtype": "training_step"}
{"Avg objective": 21.09749999999998, "Games time in secs": 176.5874605756253, "Avg game time in secs": 1.6436187763756607, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 31744, "Total num trained steps": 62955, "Timestamp in ms": 1700539906492, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814989616764207, "Avg loss": 0.6704740393906832, "Avg value loss": 0.3653968166327104, "Avg policy loss": 0.3050772288115695, "Total num played games": 31782, "Total num trained steps": 62976, "Timestamp in ms": 1700539915683, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825007854225574, "Avg loss": 0.5307945827953517, "Avg value loss": 0.23421230574604124, "Avg policy loss": 0.29658227623440325, "Total num played games": 31830, "Total num trained steps": 63104, "Timestamp in ms": 1700539975516, "logtype": "training_step"}
{"Avg objective": 20.15734374999999, "Games time in secs": 92.14534059353173, "Avg game time in secs": 1.6868824166886043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 31872, "Total num trained steps": 63155, "Timestamp in ms": 1700539998637, "logtype": "played_game"}
{"Total num played games": 31879, "Total num trained steps": 63175, "Timestamp in ms": 1700540108940, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.835507812499998}
{"Ratio train steps to played games": 1.9805180568171141, "Avg loss": 0.6368475572671741, "Avg value loss": 0.34907772531732917, "Avg policy loss": 0.28776983183342963, "Total num played games": 31927, "Total num trained steps": 63232, "Timestamp in ms": 1700540136341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814861145859395, "Avg loss": 0.5093415006995201, "Avg value loss": 0.2284263467299752, "Avg policy loss": 0.2809151547262445, "Total num played games": 31976, "Total num trained steps": 63360, "Timestamp in ms": 1700540194635, "logtype": "training_step"}
{"Avg objective": 20.908515624999993, "Games time in secs": 233.52763724699616, "Avg game time in secs": 1.5724920587235829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.57, "agent_stopped_0": 0.57}, "Total num played games": 32000, "Total num trained steps": 63444, "Timestamp in ms": 1700540232165, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825131151636273, "Avg loss": 0.5479655172675848, "Avg value loss": 0.2615647861966863, "Avg policy loss": 0.28640073037240654, "Total num played games": 32024, "Total num trained steps": 63488, "Timestamp in ms": 1700540253361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834751972063729, "Avg loss": 0.7280477765016258, "Avg value loss": 0.445874854165595, "Avg policy loss": 0.2821729227434844, "Total num played games": 32073, "Total num trained steps": 63616, "Timestamp in ms": 1700540313690, "logtype": "training_step"}
{"Avg objective": 21.449140624999984, "Games time in secs": 134.70834486559033, "Avg game time in secs": 1.595473184104776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.63, "agent_stopped_0": 0.46}, "Total num played games": 32128, "Total num trained steps": 63732, "Timestamp in ms": 1700540366873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815039323572383, "Avg loss": 0.8468254534527659, "Avg value loss": 0.5634937037830241, "Avg policy loss": 0.28333173936698586, "Total num played games": 32169, "Total num trained steps": 63744, "Timestamp in ms": 1700540372314, "logtype": "training_step"}
{"Total num played games": 32169, "Total num trained steps": 63775, "Timestamp in ms": 1700540452605, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.12359375}
{"Ratio train steps to played games": 1.9825247540118571, "Avg loss": 0.7422955522779375, "Avg value loss": 0.44618082937086, "Avg policy loss": 0.29611472075339407, "Total num played games": 32217, "Total num trained steps": 63872, "Timestamp in ms": 1700540498712, "logtype": "training_step"}
{"Avg objective": 20.863046874999988, "Games time in secs": 158.44404491968453, "Avg game time in secs": 1.4935893492220202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.58}, "Total num played games": 32256, "Total num trained steps": 63927, "Timestamp in ms": 1700540525318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834505841881798, "Avg loss": 0.4988063359633088, "Avg value loss": 0.2163954151328653, "Avg policy loss": 0.28241092327516526, "Total num played games": 32267, "Total num trained steps": 64000, "Timestamp in ms": 1700540562341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824409546185235, "Avg loss": 0.6143384468741715, "Avg value loss": 0.3276495755999349, "Avg policy loss": 0.28668887028470635, "Total num played games": 32347, "Total num trained steps": 64128, "Timestamp in ms": 1700540625237, "logtype": "training_step"}
{"Avg objective": 20.934921874999983, "Games time in secs": 146.3800660762936, "Avg game time in secs": 1.6179933353851084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.62}, "Total num played games": 32384, "Total num trained steps": 64222, "Timestamp in ms": 1700540671698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982292148696591, "Avg loss": 0.6777594874147326, "Avg value loss": 0.37689727381803095, "Avg policy loss": 0.3008622134802863, "Total num played games": 32415, "Total num trained steps": 64256, "Timestamp in ms": 1700540689785, "logtype": "training_step"}
{"Total num played games": 32463, "Total num trained steps": 64375, "Timestamp in ms": 1700540842423, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.498515625000003}
{"Ratio train steps to played games": 1.980649726204393, "Avg loss": 0.5266746848355979, "Avg value loss": 0.2377241143840365, "Avg policy loss": 0.28895057225599885, "Total num played games": 32506, "Total num trained steps": 64384, "Timestamp in ms": 1700540846125, "logtype": "training_step"}
{"Avg objective": 20.507265624999985, "Games time in secs": 237.67241697572172, "Avg game time in secs": 1.464824215581757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 32512, "Total num trained steps": 64511, "Timestamp in ms": 1700540909370, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837940896091515, "Avg loss": 0.5566006547305733, "Avg value loss": 0.26869225449627265, "Avg policy loss": 0.2879083992447704, "Total num played games": 32518, "Total num trained steps": 64512, "Timestamp in ms": 1700540909586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818795032960295, "Avg loss": 0.5804951696190983, "Avg value loss": 0.2919612340629101, "Avg policy loss": 0.2885339396307245, "Total num played games": 32615, "Total num trained steps": 64640, "Timestamp in ms": 1700540973223, "logtype": "training_step"}
{"Avg objective": 21.795312499999987, "Games time in secs": 104.78671368584037, "Avg game time in secs": 1.4070034007309005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 32640, "Total num trained steps": 64721, "Timestamp in ms": 1700541014157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982825128581925, "Avg loss": 0.6733330846764147, "Avg value loss": 0.3843867027317174, "Avg policy loss": 0.28894638689234853, "Total num played games": 32664, "Total num trained steps": 64768, "Timestamp in ms": 1700541036482, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835860129600196, "Avg loss": 0.5627030376344919, "Avg value loss": 0.27008737984579057, "Avg policy loss": 0.2926156553439796, "Total num played games": 32716, "Total num trained steps": 64896, "Timestamp in ms": 1700541098440, "logtype": "training_step"}
{"Total num played games": 32764, "Total num trained steps": 64976, "Timestamp in ms": 1700541214478, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.704531250000002}
{"Avg objective": 20.496953124999983, "Games time in secs": 201.54697160050273, "Avg game time in secs": 1.7029314295359654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.68, "agent_stopped_0": 0.43}, "Total num played games": 32768, "Total num trained steps": 64976, "Timestamp in ms": 1700541215704, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9817140070705839, "Avg loss": 0.7250264286994934, "Avg value loss": 0.4355065154377371, "Avg policy loss": 0.28951990604400635, "Total num played games": 32812, "Total num trained steps": 65024, "Timestamp in ms": 1700541239838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826237789476888, "Avg loss": 0.605999629246071, "Avg value loss": 0.31693433289183304, "Avg policy loss": 0.28906529617961496, "Total num played games": 32861, "Total num trained steps": 65152, "Timestamp in ms": 1700541305052, "logtype": "training_step"}
{"Avg objective": 22.161796874999993, "Games time in secs": 118.72819463163614, "Avg game time in secs": 1.5095013932441361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 32896, "Total num trained steps": 65214, "Timestamp in ms": 1700541334433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835313421044636, "Avg loss": 0.6479190282989293, "Avg value loss": 0.3480882865842432, "Avg policy loss": 0.299830743460916, "Total num played games": 32911, "Total num trained steps": 65280, "Timestamp in ms": 1700541368009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841650235097832, "Avg loss": 0.7029361412860453, "Avg value loss": 0.4089195933775045, "Avg policy loss": 0.2940165523905307, "Total num played games": 32965, "Total num trained steps": 65408, "Timestamp in ms": 1700541432364, "logtype": "training_step"}
{"Avg objective": 22.142187499999984, "Games time in secs": 153.08053677529097, "Avg game time in secs": 1.645056680572452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.66, "agent_stopped_0": 0.53}, "Total num played games": 33024, "Total num trained steps": 65517, "Timestamp in ms": 1700541487514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821250340259504, "Avg loss": 0.7488067150115967, "Avg value loss": 0.4540426110033877, "Avg policy loss": 0.29476410686038435, "Total num played games": 33063, "Total num trained steps": 65536, "Timestamp in ms": 1700541496408, "logtype": "training_step"}
{"Total num played games": 33063, "Total num trained steps": 65576, "Timestamp in ms": 1700541557121, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.777460937500003}
{"Ratio train steps to played games": 1.983117393011386, "Avg loss": 0.8008024094160646, "Avg value loss": 0.5024167075753212, "Avg policy loss": 0.2983856942737475, "Total num played games": 33111, "Total num trained steps": 65664, "Timestamp in ms": 1700541601365, "logtype": "training_step"}
{"Avg objective": 22.78960937499999, "Games time in secs": 140.29919689707458, "Avg game time in secs": 1.5554941703449003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 33152, "Total num trained steps": 65715, "Timestamp in ms": 1700541627813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838977173355847, "Avg loss": 0.8147740573622286, "Avg value loss": 0.5161611005896702, "Avg policy loss": 0.2986129518831149, "Total num played games": 33163, "Total num trained steps": 65792, "Timestamp in ms": 1700541666651, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820199043867825, "Avg loss": 0.6277798211667687, "Avg value loss": 0.33818175381748006, "Avg policy loss": 0.2895980690373108, "Total num played games": 33259, "Total num trained steps": 65920, "Timestamp in ms": 1700541729321, "logtype": "training_step"}
{"Avg objective": 21.837109374999986, "Games time in secs": 144.8012445550412, "Avg game time in secs": 1.6310884838312631, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 33280, "Total num trained steps": 66008, "Timestamp in ms": 1700541772614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830065751944035, "Avg loss": 0.8906883753370494, "Avg value loss": 0.5955904725124128, "Avg policy loss": 0.2950979018351063, "Total num played games": 33307, "Total num trained steps": 66048, "Timestamp in ms": 1700541791766, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983900947355798, "Avg loss": 0.6273266882635653, "Avg value loss": 0.3313259450951591, "Avg policy loss": 0.29600074340123683, "Total num played games": 33356, "Total num trained steps": 66176, "Timestamp in ms": 1700541859115, "logtype": "training_step"}
{"Total num played games": 33356, "Total num trained steps": 66176, "Timestamp in ms": 1700541915689, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7903125}
{"Avg objective": 21.65437499999999, "Games time in secs": 205.53973043896258, "Avg game time in secs": 1.4306550433248049, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 33408, "Total num trained steps": 66297, "Timestamp in ms": 1700541978154, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820046034735301, "Avg loss": 0.5408452714327723, "Avg value loss": 0.2495344744529575, "Avg policy loss": 0.2913108004722744, "Total num played games": 33453, "Total num trained steps": 66304, "Timestamp in ms": 1700541981596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828080229226361, "Avg loss": 0.9968701829202473, "Avg value loss": 0.6990731463301927, "Avg policy loss": 0.2977970418287441, "Total num played games": 33504, "Total num trained steps": 66432, "Timestamp in ms": 1700542047021, "logtype": "training_step"}
{"Avg objective": 22.510234374999985, "Games time in secs": 104.38696035556495, "Avg game time in secs": 1.4508284123294288, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.54}, "Total num played games": 33536, "Total num trained steps": 66501, "Timestamp in ms": 1700542082541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836383143589438, "Avg loss": 0.5809813591185957, "Avg value loss": 0.2923610717407428, "Avg policy loss": 0.2886202859226614, "Total num played games": 33554, "Total num trained steps": 66560, "Timestamp in ms": 1700542113204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846140110707695, "Avg loss": 0.5472404435276985, "Avg value loss": 0.25671195914037526, "Avg policy loss": 0.29052848229184747, "Total num played games": 33602, "Total num trained steps": 66688, "Timestamp in ms": 1700542177831, "logtype": "training_step"}
{"Total num played games": 33651, "Total num trained steps": 66778, "Timestamp in ms": 1700542265623, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3625}
{"Avg objective": 20.519531249999982, "Games time in secs": 184.96345972269773, "Avg game time in secs": 1.4895764336251887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.58}, "Total num played games": 33664, "Total num trained steps": 66781, "Timestamp in ms": 1700542267505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826997833763613, "Avg loss": 0.6577118344139308, "Avg value loss": 0.3650148903252557, "Avg policy loss": 0.2926969452528283, "Total num played games": 33699, "Total num trained steps": 66816, "Timestamp in ms": 1700542286325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983672622751652, "Avg loss": 0.5806283853016794, "Avg value loss": 0.29348522197688, "Avg policy loss": 0.28714316023979336, "Total num played games": 33747, "Total num trained steps": 66944, "Timestamp in ms": 1700542352017, "logtype": "training_step"}
{"Avg objective": 21.62031249999999, "Games time in secs": 105.71245171502233, "Avg game time in secs": 1.411323615539004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 33792, "Total num trained steps": 66987, "Timestamp in ms": 1700542373217, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842317022661382, "Avg loss": 0.5998347601853311, "Avg value loss": 0.31428602524101734, "Avg policy loss": 0.2855487414635718, "Total num played games": 33802, "Total num trained steps": 67072, "Timestamp in ms": 1700542416409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827392895078484, "Avg loss": 0.5755469787400216, "Avg value loss": 0.29515043465653434, "Avg policy loss": 0.28039654914755374, "Total num played games": 33891, "Total num trained steps": 67200, "Timestamp in ms": 1700542482490, "logtype": "training_step"}
{"Avg objective": 21.931328124999993, "Games time in secs": 158.66640865802765, "Avg game time in secs": 1.462247977455263, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 33920, "Total num trained steps": 67295, "Timestamp in ms": 1700542531884, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831516936671576, "Avg loss": 0.7020795401185751, "Avg value loss": 0.41281479340977967, "Avg policy loss": 0.28926474938634783, "Total num played games": 33950, "Total num trained steps": 67328, "Timestamp in ms": 1700542548595, "logtype": "training_step"}
{"Total num played games": 33950, "Total num trained steps": 67381, "Timestamp in ms": 1700542637310, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1562109375}
{"Ratio train steps to played games": 1.9840872992528973, "Avg loss": 0.7894012562464923, "Avg value loss": 0.5024584452039562, "Avg policy loss": 0.2869428114499897, "Total num played games": 33998, "Total num trained steps": 67456, "Timestamp in ms": 1700542676198, "logtype": "training_step"}
{"Avg objective": 22.55921874999999, "Games time in secs": 162.51211909763515, "Avg game time in secs": 1.4068609091918916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.61}, "Total num played games": 34048, "Total num trained steps": 67494, "Timestamp in ms": 1700542694396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848164464023494, "Avg loss": 0.5862091784365475, "Avg value loss": 0.2915537324734032, "Avg policy loss": 0.29465544468257576, "Total num played games": 34050, "Total num trained steps": 67584, "Timestamp in ms": 1700542739714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828686892350944, "Avg loss": 0.6207986252848059, "Avg value loss": 0.3371322106104344, "Avg policy loss": 0.2836664173519239, "Total num played games": 34148, "Total num trained steps": 67712, "Timestamp in ms": 1700542804356, "logtype": "training_step"}
{"Avg objective": 21.304374999999993, "Games time in secs": 150.49280154332519, "Avg game time in secs": 1.388711210602196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 34176, "Total num trained steps": 67788, "Timestamp in ms": 1700542844889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834225067976494, "Avg loss": 0.6365489873569459, "Avg value loss": 0.35062247898895293, "Avg policy loss": 0.28592651488725096, "Total num played games": 34203, "Total num trained steps": 67840, "Timestamp in ms": 1700542871987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844092143295087, "Avg loss": 0.5609433748759329, "Avg value loss": 0.2830196783761494, "Avg policy loss": 0.2779236932983622, "Total num played games": 34251, "Total num trained steps": 67968, "Timestamp in ms": 1700542939113, "logtype": "training_step"}
{"Total num played games": 34251, "Total num trained steps": 67980, "Timestamp in ms": 1700542994387, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.052226562500003}
{"Avg objective": 20.964140624999985, "Games time in secs": 207.3664382956922, "Avg game time in secs": 1.4826825911004562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.56}, "Total num played games": 34304, "Total num trained steps": 68088, "Timestamp in ms": 1700543052256, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982848989575447, "Avg loss": 0.6060612860601395, "Avg value loss": 0.32028687495039776, "Avg policy loss": 0.2857744093053043, "Total num played games": 34342, "Total num trained steps": 68096, "Timestamp in ms": 1700543055565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833997150914324, "Avg loss": 0.6620534495450556, "Avg value loss": 0.37477763171773404, "Avg policy loss": 0.28727580909617245, "Total num played games": 34397, "Total num trained steps": 68224, "Timestamp in ms": 1700543120549, "logtype": "training_step"}
{"Avg objective": 20.217656249999987, "Games time in secs": 100.87115226686001, "Avg game time in secs": 1.373734447726747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 34432, "Total num trained steps": 68287, "Timestamp in ms": 1700543153127, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842366534095857, "Avg loss": 0.5108847904484719, "Avg value loss": 0.22317849070532247, "Avg policy loss": 0.2877063020132482, "Total num played games": 34447, "Total num trained steps": 68352, "Timestamp in ms": 1700543186383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851287105751392, "Avg loss": 0.5359314850065857, "Avg value loss": 0.25703720055753365, "Avg policy loss": 0.2788942860206589, "Total num played games": 34496, "Total num trained steps": 68480, "Timestamp in ms": 1700543252520, "logtype": "training_step"}
{"Avg objective": 20.630468749999988, "Games time in secs": 149.03525646403432, "Avg game time in secs": 1.5831095617613755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.58, "agent_stopped_0": 0.57}, "Total num played games": 34560, "Total num trained steps": 68578, "Timestamp in ms": 1700543302163, "logtype": "played_game"}
{"Total num played games": 34593, "Total num trained steps": 68582, "Timestamp in ms": 1700543380311, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1718359375}
{"Ratio train steps to played games": 1.980514419329696, "Avg loss": 0.9297288083471358, "Avg value loss": 0.6416949981648941, "Avg policy loss": 0.2880337879760191, "Total num played games": 34641, "Total num trained steps": 68608, "Timestamp in ms": 1700543393728, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984209462775324, "Avg loss": 0.5117934492882341, "Avg value loss": 0.22709862241754308, "Avg policy loss": 0.284694823785685, "Total num played games": 34641, "Total num trained steps": 68736, "Timestamp in ms": 1700543458650, "logtype": "training_step"}
{"Avg objective": 21.61226562499999, "Games time in secs": 177.29387798532844, "Avg game time in secs": 1.7035737162659643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.63}, "Total num played games": 34688, "Total num trained steps": 68777, "Timestamp in ms": 1700543479457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851537951512006, "Avg loss": 0.46319654816761613, "Avg value loss": 0.18978006188990548, "Avg policy loss": 0.2734164821449667, "Total num played games": 34689, "Total num trained steps": 68864, "Timestamp in ms": 1700543524669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830698476573727, "Avg loss": 0.6241664292756468, "Avg value loss": 0.3408005695673637, "Avg policy loss": 0.283365857321769, "Total num played games": 34790, "Total num trained steps": 68992, "Timestamp in ms": 1700543585561, "logtype": "training_step"}
{"Avg objective": 21.8296875, "Games time in secs": 143.58810521662235, "Avg game time in secs": 1.3864908898976864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.53, "agent_stopped_0": 0.59}, "Total num played games": 34816, "Total num trained steps": 69072, "Timestamp in ms": 1700543623045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838978185993112, "Avg loss": 0.5184435499832034, "Avg value loss": 0.2360962653765455, "Avg policy loss": 0.28234728693496436, "Total num played games": 34840, "Total num trained steps": 69120, "Timestamp in ms": 1700543645365, "logtype": "training_step"}
{"Total num played games": 34889, "Total num trained steps": 69184, "Timestamp in ms": 1700543711473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8825}
{"Ratio train steps to played games": 1.9820820333743596, "Avg loss": 0.7043479445856065, "Avg value loss": 0.4162122941634152, "Avg policy loss": 0.2881356467260048, "Total num played games": 34937, "Total num trained steps": 69248, "Timestamp in ms": 1700543741937, "logtype": "training_step"}
{"Avg objective": 21.429765624999984, "Games time in secs": 174.01212780363858, "Avg game time in secs": 1.453802219213685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 34944, "Total num trained steps": 69364, "Timestamp in ms": 1700543797057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829360315554794, "Avg loss": 0.504830876365304, "Avg value loss": 0.22578810513368808, "Avg policy loss": 0.27904277201741934, "Total num played games": 34986, "Total num trained steps": 69376, "Timestamp in ms": 1700543801846, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838728092709939, "Avg loss": 0.7803982216864824, "Avg value loss": 0.4900851982529275, "Avg policy loss": 0.2903130134800449, "Total num played games": 35034, "Total num trained steps": 69504, "Timestamp in ms": 1700543861491, "logtype": "training_step"}
{"Avg objective": 22.33812499999999, "Games time in secs": 90.1123350057751, "Avg game time in secs": 1.225225672853412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 35072, "Total num trained steps": 69560, "Timestamp in ms": 1700543887170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845526833300082, "Avg loss": 0.6418466994073242, "Avg value loss": 0.3554932939587161, "Avg policy loss": 0.2863534006755799, "Total num played games": 35087, "Total num trained steps": 69632, "Timestamp in ms": 1700543920904, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854280510018214, "Avg loss": 0.5158246955834329, "Avg value loss": 0.23371501895599067, "Avg policy loss": 0.28210967767518014, "Total num played games": 35136, "Total num trained steps": 69760, "Timestamp in ms": 1700543979822, "logtype": "training_step"}
{"Total num played games": 35188, "Total num trained steps": 69785, "Timestamp in ms": 1700544062069, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.927890625}
{"Avg objective": 20.65789062499999, "Games time in secs": 176.50734170526266, "Avg game time in secs": 1.539529559770017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.56}, "Total num played games": 35200, "Total num trained steps": 69787, "Timestamp in ms": 1700544063677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834260415484164, "Avg loss": 0.6505189626477659, "Avg value loss": 0.3657560016727075, "Avg policy loss": 0.2847629700554535, "Total num played games": 35236, "Total num trained steps": 69888, "Timestamp in ms": 1700544110899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842709366586369, "Avg loss": 0.7365361489355564, "Avg value loss": 0.4593782588490285, "Avg policy loss": 0.27715789631474763, "Total num played games": 35285, "Total num trained steps": 70016, "Timestamp in ms": 1700544169885, "logtype": "training_step"}
{"Avg objective": 21.158281249999987, "Games time in secs": 127.79863914474845, "Avg game time in secs": 1.3100567499786848, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 35328, "Total num trained steps": 70064, "Timestamp in ms": 1700544191476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851417897775514, "Avg loss": 0.9329628688283265, "Avg value loss": 0.6493933510500938, "Avg policy loss": 0.28356951160822064, "Total num played games": 35334, "Total num trained steps": 70144, "Timestamp in ms": 1700544229496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833196917953204, "Avg loss": 0.7348949918523431, "Avg value loss": 0.4537068079225719, "Avg policy loss": 0.28118819498922676, "Total num played games": 35431, "Total num trained steps": 70272, "Timestamp in ms": 1700544288791, "logtype": "training_step"}
{"Avg objective": 21.938437499999992, "Games time in secs": 136.78709579445422, "Avg game time in secs": 1.2898403535218677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.41, "agent_stopped_0": 0.66}, "Total num played games": 35456, "Total num trained steps": 70353, "Timestamp in ms": 1700544328263, "logtype": "played_game"}
{"Total num played games": 35479, "Total num trained steps": 70386, "Timestamp in ms": 1700544387154, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.991015625000003}
{"Ratio train steps to played games": 1.981647244271801, "Avg loss": 0.8476966759189963, "Avg value loss": 0.5603364426642656, "Avg policy loss": 0.28736024093814194, "Total num played games": 35526, "Total num trained steps": 70400, "Timestamp in ms": 1700544393289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851662116137023, "Avg loss": 0.5034665933344513, "Avg value loss": 0.21118374163052067, "Avg policy loss": 0.29228285083081573, "Total num played games": 35527, "Total num trained steps": 70528, "Timestamp in ms": 1700544453029, "logtype": "training_step"}
{"Avg objective": 21.423124999999985, "Games time in secs": 176.22769930958748, "Avg game time in secs": 1.5802173654810758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.7}, "Total num played games": 35584, "Total num trained steps": 70640, "Timestamp in ms": 1700544504491, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98335391870649, "Avg loss": 0.826005803886801, "Avg value loss": 0.5345828458666801, "Avg policy loss": 0.29142296325881034, "Total num played games": 35624, "Total num trained steps": 70656, "Timestamp in ms": 1700544511685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838565022421524, "Avg loss": 0.8732259562239051, "Avg value loss": 0.5833837339305319, "Avg policy loss": 0.2898422240978107, "Total num played games": 35680, "Total num trained steps": 70784, "Timestamp in ms": 1700544572547, "logtype": "training_step"}
{"Avg objective": 21.342343749999994, "Games time in secs": 99.49857044778764, "Avg game time in secs": 1.2001429908996215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.44}, "Total num played games": 35712, "Total num trained steps": 70852, "Timestamp in ms": 1700544603990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845516623754618, "Avg loss": 0.6489603391382843, "Avg value loss": 0.36854038771707565, "Avg policy loss": 0.28041994909290224, "Total num played games": 35732, "Total num trained steps": 70912, "Timestamp in ms": 1700544632049, "logtype": "training_step"}
{"Total num played games": 35780, "Total num trained steps": 70988, "Timestamp in ms": 1700544726081, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.139882812500005}
{"Ratio train steps to played games": 1.9828067433292398, "Avg loss": 0.8398969417903572, "Avg value loss": 0.5450381767586805, "Avg policy loss": 0.2948587649734691, "Total num played games": 35828, "Total num trained steps": 71040, "Timestamp in ms": 1700544750575, "logtype": "training_step"}
{"Avg objective": 20.95804687499999, "Games time in secs": 195.67083366401494, "Avg game time in secs": 1.451813116305857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.56}, "Total num played games": 35840, "Total num trained steps": 71146, "Timestamp in ms": 1700544799661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836938343182071, "Avg loss": 0.5851432746276259, "Avg value loss": 0.2972126730310265, "Avg policy loss": 0.2879305926617235, "Total num played games": 35876, "Total num trained steps": 71168, "Timestamp in ms": 1700544809738, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845789839944328, "Avg loss": 0.5397751312702894, "Avg value loss": 0.25361428962787613, "Avg policy loss": 0.28616083785891533, "Total num played games": 35925, "Total num trained steps": 71296, "Timestamp in ms": 1700544868638, "logtype": "training_step"}
{"Avg objective": 21.310312499999988, "Games time in secs": 91.13578873313963, "Avg game time in secs": 1.2243172624148428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 35968, "Total num trained steps": 71344, "Timestamp in ms": 1700544890797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853235490326884, "Avg loss": 0.8626762048806995, "Avg value loss": 0.5629896123427898, "Avg policy loss": 0.29968659626320004, "Total num played games": 35976, "Total num trained steps": 71424, "Timestamp in ms": 1700544928517, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983478405499806, "Avg loss": 0.5156341185793281, "Avg value loss": 0.2248675324372016, "Avg policy loss": 0.29076658748090267, "Total num played games": 36074, "Total num trained steps": 71552, "Timestamp in ms": 1700544987342, "logtype": "training_step"}
{"Total num played games": 36077, "Total num trained steps": 71589, "Timestamp in ms": 1700545027728, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.062578125}
{"Avg objective": 21.024609374999986, "Games time in secs": 138.7993183489889, "Avg game time in secs": 1.5570590818679193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 36096, "Total num trained steps": 71592, "Timestamp in ms": 1700545029596, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841937716262976, "Avg loss": 0.6557751512154937, "Avg value loss": 0.3484322558506392, "Avg policy loss": 0.3073428972857073, "Total num played games": 36125, "Total num trained steps": 71680, "Timestamp in ms": 1700545069713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850993835180937, "Avg loss": 0.4907513181678951, "Avg value loss": 0.20613740308908746, "Avg policy loss": 0.2846139185130596, "Total num played games": 36173, "Total num trained steps": 71808, "Timestamp in ms": 1700545127837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858657243816253, "Avg loss": 0.46561185573227704, "Avg value loss": 0.18445269879885018, "Avg policy loss": 0.28115915798116475, "Total num played games": 36223, "Total num trained steps": 71936, "Timestamp in ms": 1700545187244, "logtype": "training_step"}
{"Avg objective": 19.354921874999988, "Games time in secs": 157.6489668842405, "Avg game time in secs": 1.7517523263086332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 36224, "Total num trained steps": 71936, "Timestamp in ms": 1700545187245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840041847915864, "Avg loss": 0.6671349545940757, "Avg value loss": 0.38976502080913633, "Avg policy loss": 0.2773699344834313, "Total num played games": 36322, "Total num trained steps": 72064, "Timestamp in ms": 1700545247417, "logtype": "training_step"}
{"Avg objective": 21.31929687499999, "Games time in secs": 93.81934897042811, "Avg game time in secs": 1.2625234693987295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.46}, "Total num played games": 36352, "Total num trained steps": 72137, "Timestamp in ms": 1700545281065, "logtype": "played_game"}
{"Total num played games": 36370, "Total num trained steps": 72189, "Timestamp in ms": 1700545364058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4736328125}
{"Ratio train steps to played games": 1.9838962323779163, "Avg loss": 0.6067709056660533, "Avg value loss": 0.3205002681934275, "Avg policy loss": 0.286270635901019, "Total num played games": 36387, "Total num trained steps": 72192, "Timestamp in ms": 1700545365676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985803723433467, "Avg loss": 0.7049166958313435, "Avg value loss": 0.4086634541163221, "Avg policy loss": 0.2962532400852069, "Total num played games": 36418, "Total num trained steps": 72320, "Timestamp in ms": 1700545425008, "logtype": "training_step"}
{"Avg objective": 22.01249999999999, "Games time in secs": 190.36457165703177, "Avg game time in secs": 1.4202655177068664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 36480, "Total num trained steps": 72423, "Timestamp in ms": 1700545471429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838166433911115, "Avg loss": 0.7020337807480246, "Avg value loss": 0.41674657474504784, "Avg policy loss": 0.2852872038492933, "Total num played games": 36519, "Total num trained steps": 72448, "Timestamp in ms": 1700545482394, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984658718004813, "Avg loss": 0.5710251852869987, "Avg value loss": 0.2887816757429391, "Avg policy loss": 0.28224351489916444, "Total num played games": 36568, "Total num trained steps": 72576, "Timestamp in ms": 1700545540649, "logtype": "training_step"}
{"Avg objective": 21.95031249999999, "Games time in secs": 93.99662272632122, "Avg game time in secs": 1.4073767108056927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.68}, "Total num played games": 36608, "Total num trained steps": 72629, "Timestamp in ms": 1700545565426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852816689877393, "Avg loss": 0.7286952761933208, "Avg value loss": 0.44432641071034595, "Avg policy loss": 0.28436887671705335, "Total num played games": 36621, "Total num trained steps": 72704, "Timestamp in ms": 1700545600241, "logtype": "training_step"}
{"Total num played games": 36674, "Total num trained steps": 72790, "Timestamp in ms": 1700545718138, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.973671875}
{"Ratio train steps to played games": 1.9833342410544088, "Avg loss": 0.6463629694189876, "Avg value loss": 0.3525126439053565, "Avg policy loss": 0.29385032842401415, "Total num played games": 36722, "Total num trained steps": 72832, "Timestamp in ms": 1700545738618, "logtype": "training_step"}
{"Avg objective": 21.438515624999987, "Games time in secs": 223.9419105388224, "Avg game time in secs": 1.4718272648897255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 36736, "Total num trained steps": 72935, "Timestamp in ms": 1700545789368, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984199075333152, "Avg loss": 0.5746169572230428, "Avg value loss": 0.2749881703639403, "Avg policy loss": 0.29962878103833646, "Total num played games": 36770, "Total num trained steps": 72960, "Timestamp in ms": 1700545800955, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848731736461898, "Avg loss": 0.6068512261845171, "Avg value loss": 0.2965445484733209, "Avg policy loss": 0.31030668050516397, "Total num played games": 36822, "Total num trained steps": 73088, "Timestamp in ms": 1700545862299, "logtype": "training_step"}
{"Avg objective": 20.976171874999988, "Games time in secs": 95.46587837673724, "Avg game time in secs": 1.5280041440419154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.67, "agent_stopped_0": 0.48}, "Total num played games": 36864, "Total num trained steps": 73139, "Timestamp in ms": 1700545884834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852761734320346, "Avg loss": 0.5219828840345144, "Avg value loss": 0.212380355107598, "Avg policy loss": 0.30960252950899303, "Total num played games": 36879, "Total num trained steps": 73216, "Timestamp in ms": 1700545918927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986108102253033, "Avg loss": 0.5499978219158947, "Avg value loss": 0.2430734207155183, "Avg policy loss": 0.30692439910490066, "Total num played games": 36928, "Total num trained steps": 73344, "Timestamp in ms": 1700545978537, "logtype": "training_step"}
{"Total num played games": 36980, "Total num trained steps": 73391, "Timestamp in ms": 1700546073425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.524843750000002}
{"Avg objective": 22.44843749999999, "Games time in secs": 189.95618384703994, "Avg game time in secs": 1.629529023906798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.7, "agent_stopped_0": 0.48}, "Total num played games": 36992, "Total num trained steps": 73393, "Timestamp in ms": 1700546074791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842011450793993, "Avg loss": 0.9768670855555683, "Avg value loss": 0.6546485531143844, "Avg policy loss": 0.32221853267401457, "Total num played games": 37028, "Total num trained steps": 73472, "Timestamp in ms": 1700546110781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846564556142812, "Avg loss": 0.6471648165024817, "Avg value loss": 0.33686886113719083, "Avg policy loss": 0.3102959521347657, "Total num played games": 37084, "Total num trained steps": 73600, "Timestamp in ms": 1700546169934, "logtype": "training_step"}
{"Avg objective": 21.214843749999993, "Games time in secs": 122.05868369713426, "Avg game time in secs": 1.2856042778148549, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 37120, "Total num trained steps": 73660, "Timestamp in ms": 1700546196850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985351141749246, "Avg loss": 0.5483108181506395, "Avg value loss": 0.24261392655898817, "Avg policy loss": 0.3056968851014972, "Total num played games": 37136, "Total num trained steps": 73728, "Timestamp in ms": 1700546227335, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861503294339116, "Avg loss": 0.5282162784133106, "Avg value loss": 0.22049370396416634, "Avg policy loss": 0.3077225786400959, "Total num played games": 37185, "Total num trained steps": 73856, "Timestamp in ms": 1700546284985, "logtype": "training_step"}
{"Avg objective": 21.01421874999999, "Games time in secs": 135.45962618291378, "Avg game time in secs": 1.4854399813775672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.6}, "Total num played games": 37248, "Total num trained steps": 73959, "Timestamp in ms": 1700546332309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984362846337473, "Avg loss": 0.7392411734908819, "Avg value loss": 0.41853446885943413, "Avg policy loss": 0.3207066983450204, "Total num played games": 37283, "Total num trained steps": 73984, "Timestamp in ms": 1700546343793, "logtype": "training_step"}
{"Total num played games": 37283, "Total num trained steps": 73994, "Timestamp in ms": 1700546413943, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.387890625}
{"Ratio train steps to played games": 1.9852669363263775, "Avg loss": 0.5761606895830482, "Avg value loss": 0.2637349750730209, "Avg policy loss": 0.3124257118906826, "Total num played games": 37331, "Total num trained steps": 74112, "Timestamp in ms": 1700546469549, "logtype": "training_step"}
{"Avg objective": 22.147968749999986, "Games time in secs": 155.90677237138152, "Avg game time in secs": 1.2919105916516855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 37376, "Total num trained steps": 74155, "Timestamp in ms": 1700546488216, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856902131757028, "Avg loss": 0.604544606525451, "Avg value loss": 0.30406564721488394, "Avg policy loss": 0.30047895666211843, "Total num played games": 37387, "Total num trained steps": 74240, "Timestamp in ms": 1700546526767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841519703316346, "Avg loss": 0.6169248493388295, "Avg value loss": 0.3202013886766508, "Avg policy loss": 0.29672345728613436, "Total num played games": 37481, "Total num trained steps": 74368, "Timestamp in ms": 1700546583717, "logtype": "training_step"}
{"Avg objective": 21.65289062499999, "Games time in secs": 136.88053400814533, "Avg game time in secs": 1.4407214209350059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.56, "agent_stopped_0": 0.55}, "Total num played games": 37504, "Total num trained steps": 74456, "Timestamp in ms": 1700546625097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849191335162932, "Avg loss": 0.6738251608330756, "Avg value loss": 0.36683765321504325, "Avg policy loss": 0.30698750843293965, "Total num played games": 37531, "Total num trained steps": 74496, "Timestamp in ms": 1700546643625, "logtype": "training_step"}
{"Total num played games": 37579, "Total num trained steps": 74595, "Timestamp in ms": 1700546726465, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.852656250000003}
{"Ratio train steps to played games": 1.9832567039625801, "Avg loss": 0.8458642112091184, "Avg value loss": 0.5367722907103598, "Avg policy loss": 0.30909191991668195, "Total num played games": 37627, "Total num trained steps": 74624, "Timestamp in ms": 1700546739881, "logtype": "training_step"}
{"Avg objective": 23.65640624999999, "Games time in secs": 170.37663824297488, "Avg game time in secs": 1.4534920109435916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.66}, "Total num played games": 37632, "Total num trained steps": 74744, "Timestamp in ms": 1700546795474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839694251287223, "Avg loss": 0.4508861976210028, "Avg value loss": 0.1517106209648773, "Avg policy loss": 0.2991755772382021, "Total num played games": 37678, "Total num trained steps": 74752, "Timestamp in ms": 1700546798933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984653714649209, "Avg loss": 0.7091937265358865, "Avg value loss": 0.4074589785304852, "Avg policy loss": 0.3017347534187138, "Total num played games": 37729, "Total num trained steps": 74880, "Timestamp in ms": 1700546857245, "logtype": "training_step"}
{"Avg objective": 21.664609374999987, "Games time in secs": 93.75084012188017, "Avg game time in secs": 1.3976472196227405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 37760, "Total num trained steps": 74951, "Timestamp in ms": 1700546889225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854942029752767, "Avg loss": 0.6624103407375515, "Avg value loss": 0.34435266483342275, "Avg policy loss": 0.3180576750310138, "Total num played games": 37778, "Total num trained steps": 75008, "Timestamp in ms": 1700546915943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860960587877667, "Avg loss": 0.5075995966326445, "Avg value loss": 0.19929431108175777, "Avg policy loss": 0.30830527970101684, "Total num played games": 37831, "Total num trained steps": 75136, "Timestamp in ms": 1700546977372, "logtype": "training_step"}
{"Total num played games": 37883, "Total num trained steps": 75197, "Timestamp in ms": 1700547069246, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8065234375}
{"Avg objective": 20.72164062499999, "Games time in secs": 181.2530362419784, "Avg game time in secs": 1.5123495128937066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 37888, "Total num trained steps": 75198, "Timestamp in ms": 1700547070478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984234531122301, "Avg loss": 0.626954851904884, "Avg value loss": 0.32535665860632434, "Avg policy loss": 0.30159819533582777, "Total num played games": 37931, "Total num trained steps": 75264, "Timestamp in ms": 1700547101181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847834671580886, "Avg loss": 0.5025357119739056, "Avg value loss": 0.2107177806319669, "Avg policy loss": 0.2918179330881685, "Total num played games": 37985, "Total num trained steps": 75392, "Timestamp in ms": 1700547159695, "logtype": "training_step"}
{"Avg objective": 21.696874999999988, "Games time in secs": 122.25531840510666, "Avg game time in secs": 1.379400067962706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 38016, "Total num trained steps": 75461, "Timestamp in ms": 1700547192733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856177530039703, "Avg loss": 0.7218296339269727, "Avg value loss": 0.4272773426200729, "Avg policy loss": 0.29455228650476784, "Total num played games": 38033, "Total num trained steps": 75520, "Timestamp in ms": 1700547219888, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864761954780599, "Avg loss": 0.7020341076422483, "Avg value loss": 0.3973256433964707, "Avg policy loss": 0.3047084591817111, "Total num played games": 38081, "Total num trained steps": 75648, "Timestamp in ms": 1700547278467, "logtype": "training_step"}
{"Avg objective": 20.775234374999986, "Games time in secs": 132.58053122460842, "Avg game time in secs": 1.588045522410539, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.58, "agent_stopped_0": 0.54}, "Total num played games": 38144, "Total num trained steps": 75750, "Timestamp in ms": 1700547325314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844699350513304, "Avg loss": 0.6494231126271188, "Avg value loss": 0.34562475577695295, "Avg policy loss": 0.3037983599351719, "Total num played games": 38184, "Total num trained steps": 75776, "Timestamp in ms": 1700547337087, "logtype": "training_step"}
{"Total num played games": 38184, "Total num trained steps": 75797, "Timestamp in ms": 1700547414025, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.822109375}
{"Ratio train steps to played games": 1.9853264281230383, "Avg loss": 0.5693003821652383, "Avg value loss": 0.279990685521625, "Avg policy loss": 0.2893096957122907, "Total num played games": 38232, "Total num trained steps": 75904, "Timestamp in ms": 1700547464523, "logtype": "training_step"}
{"Avg objective": 21.540937499999984, "Games time in secs": 163.11235986463726, "Avg game time in secs": 1.3154451611917466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 38272, "Total num trained steps": 75958, "Timestamp in ms": 1700547488427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860251286471802, "Avg loss": 0.7037575482390821, "Avg value loss": 0.41387981330626644, "Avg policy loss": 0.2898777259979397, "Total num played games": 38283, "Total num trained steps": 76032, "Timestamp in ms": 1700547523791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866183222036728, "Avg loss": 0.6580039234831929, "Avg value loss": 0.3708499696222134, "Avg policy loss": 0.28715395752806216, "Total num played games": 38336, "Total num trained steps": 76160, "Timestamp in ms": 1700547584784, "logtype": "training_step"}
{"Avg objective": 21.086171874999984, "Games time in secs": 144.5315580945462, "Avg game time in secs": 1.5335311481176177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.62, "agent_stopped_0": 0.52}, "Total num played games": 38400, "Total num trained steps": 76264, "Timestamp in ms": 1700547632958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984805911124987, "Avg loss": 0.6389228089246899, "Avg value loss": 0.3464985034079291, "Avg policy loss": 0.2924243056913838, "Total num played games": 38436, "Total num trained steps": 76288, "Timestamp in ms": 1700547644368, "logtype": "training_step"}
{"Total num played games": 38484, "Total num trained steps": 76400, "Timestamp in ms": 1700547748431, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1783203125}
{"Avg objective": 21.033906249999987, "Games time in secs": 118.70882084965706, "Avg game time in secs": 1.3513818264618749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.49}, "Total num played games": 38528, "Total num trained steps": 76405, "Timestamp in ms": 1700547751667, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831828090937402, "Avg loss": 0.7343627996742725, "Avg value loss": 0.44512650062097237, "Avg policy loss": 0.28923629806376994, "Total num played games": 38532, "Total num trained steps": 76416, "Timestamp in ms": 1700547756732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865047233468287, "Avg loss": 0.4610426789149642, "Avg value loss": 0.17154999927151948, "Avg policy loss": 0.28949267987627536, "Total num played games": 38532, "Total num trained steps": 76544, "Timestamp in ms": 1700547817500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98480416267571, "Avg loss": 0.7985175773501396, "Avg value loss": 0.5076299723586999, "Avg policy loss": 0.2908876108704135, "Total num played games": 38629, "Total num trained steps": 76672, "Timestamp in ms": 1700547877791, "logtype": "training_step"}
{"Avg objective": 22.90531249999999, "Games time in secs": 164.27260826714337, "Avg game time in secs": 1.3919081444619223, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.52, "agent_stopped_0": 0.62}, "Total num played games": 38656, "Total num trained steps": 76749, "Timestamp in ms": 1700547915940, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985624903045659, "Avg loss": 0.6776083572767675, "Avg value loss": 0.3796376624959521, "Avg policy loss": 0.29797070112545043, "Total num played games": 38678, "Total num trained steps": 76800, "Timestamp in ms": 1700547941331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863406321008057, "Avg loss": 0.5845441338606179, "Avg value loss": 0.2885744872619398, "Avg policy loss": 0.2959696447942406, "Total num played games": 38728, "Total num trained steps": 76928, "Timestamp in ms": 1700548003040, "logtype": "training_step"}
{"Total num played games": 38783, "Total num trained steps": 77002, "Timestamp in ms": 1700548100438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.691796875}
{"Avg objective": 21.616406249999986, "Games time in secs": 185.4209672305733, "Avg game time in secs": 1.6669290110294241, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.69}, "Total num played games": 38784, "Total num trained steps": 77002, "Timestamp in ms": 1700548101361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843939120805543, "Avg loss": 0.9605813121888787, "Avg value loss": 0.6444488795823418, "Avg policy loss": 0.316132424864918, "Total num played games": 38831, "Total num trained steps": 77056, "Timestamp in ms": 1700548125925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851084077055632, "Avg loss": 0.522830359172076, "Avg value loss": 0.2286882009357214, "Avg policy loss": 0.2941421562572941, "Total num played games": 38881, "Total num trained steps": 77184, "Timestamp in ms": 1700548184289, "logtype": "training_step"}
{"Avg objective": 21.644531249999993, "Games time in secs": 115.26802194491029, "Avg game time in secs": 1.2035313132219017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 38912, "Total num trained steps": 77254, "Timestamp in ms": 1700548216630, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859487785455574, "Avg loss": 0.5634171499405056, "Avg value loss": 0.26620863075368106, "Avg policy loss": 0.2972085187211633, "Total num played games": 38929, "Total num trained steps": 77312, "Timestamp in ms": 1700548242417, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986812735715935, "Avg loss": 0.6169886596035212, "Avg value loss": 0.31322801543865353, "Avg policy loss": 0.3037606463767588, "Total num played games": 38977, "Total num trained steps": 77440, "Timestamp in ms": 1700548300769, "logtype": "training_step"}
{"Avg objective": 22.30265624999999, "Games time in secs": 133.3659118898213, "Avg game time in secs": 1.446564257988939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 39040, "Total num trained steps": 77547, "Timestamp in ms": 1700548349996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848515864892529, "Avg loss": 0.630887754028663, "Avg value loss": 0.33306744135916233, "Avg policy loss": 0.2978203148813918, "Total num played games": 39080, "Total num trained steps": 77568, "Timestamp in ms": 1700548359241, "logtype": "training_step"}
{"Total num played games": 39080, "Total num trained steps": 77604, "Timestamp in ms": 1700548442575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8000390625}
{"Ratio train steps to played games": 1.9856624412185646, "Avg loss": 0.678703089710325, "Avg value loss": 0.3688024683506228, "Avg policy loss": 0.30990061932243407, "Total num played games": 39128, "Total num trained steps": 77696, "Timestamp in ms": 1700548485218, "logtype": "training_step"}
{"Avg objective": 21.07054687499999, "Games time in secs": 159.4629392400384, "Avg game time in secs": 1.3198213777941419, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 39168, "Total num trained steps": 77749, "Timestamp in ms": 1700548509459, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864968347968144, "Avg loss": 0.5307879748288542, "Avg value loss": 0.23252429551212117, "Avg policy loss": 0.2982636773958802, "Total num played games": 39176, "Total num trained steps": 77824, "Timestamp in ms": 1700548543860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984774029280713, "Avg loss": 0.5786426505073905, "Avg value loss": 0.27952071360778064, "Avg policy loss": 0.29912193573545665, "Total num played games": 39275, "Total num trained steps": 77952, "Timestamp in ms": 1700548603505, "logtype": "training_step"}
{"Avg objective": 20.93734374999999, "Games time in secs": 134.64638948254287, "Avg game time in secs": 1.3495250862761168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.57, "agent_stopped_0": 0.55}, "Total num played games": 39296, "Total num trained steps": 78042, "Timestamp in ms": 1700548644105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852780391060032, "Avg loss": 0.6071535032242537, "Avg value loss": 0.30024650873383507, "Avg policy loss": 0.30690699303522706, "Total num played games": 39329, "Total num trained steps": 78080, "Timestamp in ms": 1700548662379, "logtype": "training_step"}
{"Total num played games": 39377, "Total num trained steps": 78204, "Timestamp in ms": 1700548752773, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.878164062499998}
{"Ratio train steps to played games": 1.984722750919934, "Avg loss": 0.5331197318155318, "Avg value loss": 0.22503417206462473, "Avg policy loss": 0.3080855655716732, "Total num played games": 39403, "Total num trained steps": 78208, "Timestamp in ms": 1700548754771, "logtype": "training_step"}
{"Avg objective": 21.106718749999985, "Games time in secs": 113.47927452251315, "Avg game time in secs": 1.5617536996869603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.7, "agent_stopped_0": 0.43}, "Total num played games": 39424, "Total num trained steps": 78214, "Timestamp in ms": 1700548757585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869372225745086, "Avg loss": 0.70804722327739, "Avg value loss": 0.39785144085180946, "Avg policy loss": 0.31019578326959163, "Total num played games": 39425, "Total num trained steps": 78336, "Timestamp in ms": 1700548813777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98534956099289, "Avg loss": 0.8101075277663767, "Avg value loss": 0.5000775700318627, "Avg policy loss": 0.3100299519719556, "Total num played games": 39521, "Total num trained steps": 78464, "Timestamp in ms": 1700548871933, "logtype": "training_step"}
{"Avg objective": 22.499609374999988, "Games time in secs": 146.92065201699734, "Avg game time in secs": 1.1193677149276482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 39552, "Total num trained steps": 78533, "Timestamp in ms": 1700548904506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861511245893353, "Avg loss": 0.760780188953504, "Avg value loss": 0.45604787970660254, "Avg policy loss": 0.304732310352847, "Total num played games": 39570, "Total num trained steps": 78592, "Timestamp in ms": 1700548931877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869756171437225, "Avg loss": 0.6137414055410773, "Avg value loss": 0.31699652172392234, "Avg policy loss": 0.296744889463298, "Total num played games": 39618, "Total num trained steps": 78720, "Timestamp in ms": 1700548990357, "logtype": "training_step"}
{"Total num played games": 39666, "Total num trained steps": 78807, "Timestamp in ms": 1700549063213, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.969375}
{"Avg objective": 21.547499999999992, "Games time in secs": 160.30324800685048, "Avg game time in secs": 1.3812932959990576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 39680, "Total num trained steps": 78809, "Timestamp in ms": 1700549064809, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853703983481896, "Avg loss": 0.7908294480293989, "Avg value loss": 0.4888027667766437, "Avg policy loss": 0.30202668416313827, "Total num played games": 39714, "Total num trained steps": 78848, "Timestamp in ms": 1700549082168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862179970826417, "Avg loss": 0.5406566837336868, "Avg value loss": 0.24145736379432492, "Avg policy loss": 0.2991993210744113, "Total num played games": 39762, "Total num trained steps": 78976, "Timestamp in ms": 1700549142570, "logtype": "training_step"}
{"Avg objective": 21.332343749999982, "Games time in secs": 98.96873955242336, "Avg game time in secs": 1.5668862082529813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.7}, "Total num played games": 39808, "Total num trained steps": 79023, "Timestamp in ms": 1700549163778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869634020748035, "Avg loss": 0.6478015766479075, "Avg value loss": 0.3370429009664804, "Avg policy loss": 0.3107586750993505, "Total num played games": 39811, "Total num trained steps": 79104, "Timestamp in ms": 1700549200916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853412849553975, "Avg loss": 0.8278506000060588, "Avg value loss": 0.5337469683145173, "Avg policy loss": 0.29410362988710403, "Total num played games": 39908, "Total num trained steps": 79232, "Timestamp in ms": 1700549263704, "logtype": "training_step"}
{"Avg objective": 22.201249999999987, "Games time in secs": 139.8142047803849, "Avg game time in secs": 1.3384727988595841, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 39936, "Total num trained steps": 79308, "Timestamp in ms": 1700549303592, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861100683234476, "Avg loss": 0.8390773520804942, "Avg value loss": 0.532222005771473, "Avg policy loss": 0.30685535387601703, "Total num played games": 39957, "Total num trained steps": 79360, "Timestamp in ms": 1700549329562, "logtype": "training_step"}
{"Total num played games": 40006, "Total num trained steps": 79408, "Timestamp in ms": 1700549403236, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6830859375}
{"Ratio train steps to played games": 1.9844959304938332, "Avg loss": 0.7219474136363715, "Avg value loss": 0.4123817880754359, "Avg policy loss": 0.30956561595667154, "Total num played games": 40054, "Total num trained steps": 79488, "Timestamp in ms": 1700549442635, "logtype": "training_step"}
{"Avg objective": 21.993906249999984, "Games time in secs": 191.4637926314026, "Avg game time in secs": 1.5124056537169963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 40064, "Total num trained steps": 79598, "Timestamp in ms": 1700549495060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850898845588052, "Avg loss": 0.46677938697393984, "Avg value loss": 0.17988185657304712, "Avg policy loss": 0.28689753299113363, "Total num played games": 40107, "Total num trained steps": 79616, "Timestamp in ms": 1700549503002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985410182995145, "Avg loss": 0.6008986628148705, "Avg value loss": 0.30510032805614173, "Avg policy loss": 0.29579833894968033, "Total num played games": 40165, "Total num trained steps": 79744, "Timestamp in ms": 1700549563089, "logtype": "training_step"}
{"Avg objective": 21.97664062499999, "Games time in secs": 104.56896700523794, "Avg game time in secs": 1.3440658204781357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 40192, "Total num trained steps": 79821, "Timestamp in ms": 1700549599629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985951563976329, "Avg loss": 0.5481362733989954, "Avg value loss": 0.24879720975877717, "Avg policy loss": 0.2993390610208735, "Total num played games": 40218, "Total num trained steps": 79872, "Timestamp in ms": 1700549623304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98654118348191, "Avg loss": 0.6972550533246249, "Avg value loss": 0.4070536904036999, "Avg policy loss": 0.2902013595448807, "Total num played games": 40271, "Total num trained steps": 80000, "Timestamp in ms": 1700549682407, "logtype": "training_step"}
{"Total num played games": 40271, "Total num trained steps": 80011, "Timestamp in ms": 1700549738217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.129921875}
{"Avg objective": 21.457578124999987, "Games time in secs": 192.94974794238806, "Avg game time in secs": 1.4675035350082908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 40320, "Total num trained steps": 80127, "Timestamp in ms": 1700549792579, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872523002901714, "Avg loss": 0.5124436605256051, "Avg value loss": 0.23419155151350424, "Avg policy loss": 0.27825210499577224, "Total num played games": 40321, "Total num trained steps": 80128, "Timestamp in ms": 1700549792765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98577260917976, "Avg loss": 0.699749349616468, "Avg value loss": 0.4115897068986669, "Avg policy loss": 0.28815964073874056, "Total num played games": 40415, "Total num trained steps": 80256, "Timestamp in ms": 1700549853140, "logtype": "training_step"}
{"Avg objective": 20.782968749999995, "Games time in secs": 91.0418532397598, "Avg game time in secs": 1.3334357994317543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.45}, "Total num played games": 40448, "Total num trained steps": 80322, "Timestamp in ms": 1700549883621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863348818819808, "Avg loss": 0.5533878887072206, "Avg value loss": 0.2669320364948362, "Avg policy loss": 0.2864558545406908, "Total num played games": 40468, "Total num trained steps": 80384, "Timestamp in ms": 1700549911680, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871408826142758, "Avg loss": 0.4621887819375843, "Avg value loss": 0.18256949220085517, "Avg policy loss": 0.2796192863024771, "Total num played games": 40516, "Total num trained steps": 80512, "Timestamp in ms": 1700549971661, "logtype": "training_step"}
{"Total num played games": 40564, "Total num trained steps": 80613, "Timestamp in ms": 1700550065675, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3660546875}
{"Avg objective": 21.32578124999999, "Games time in secs": 183.74289915524423, "Avg game time in secs": 1.4764113791898126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.63}, "Total num played games": 40576, "Total num trained steps": 80615, "Timestamp in ms": 1700550067364, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985595390524968, "Avg loss": 0.8582337622065097, "Avg value loss": 0.5697479160153307, "Avg policy loss": 0.2884858470642939, "Total num played games": 40612, "Total num trained steps": 80640, "Timestamp in ms": 1700550078708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986350557044834, "Avg loss": 0.6056366369593889, "Avg value loss": 0.304238511598669, "Avg policy loss": 0.301398127572611, "Total num played games": 40661, "Total num trained steps": 80768, "Timestamp in ms": 1700550137727, "logtype": "training_step"}
{"Avg objective": 21.492656249999982, "Games time in secs": 93.19560834020376, "Avg game time in secs": 1.4104024409462, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.62}, "Total num played games": 40704, "Total num trained steps": 80818, "Timestamp in ms": 1700550160559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871039056742814, "Avg loss": 0.5600330885499716, "Avg value loss": 0.2763656247407198, "Avg policy loss": 0.2836674621794373, "Total num played games": 40710, "Total num trained steps": 80896, "Timestamp in ms": 1700550196501, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854930405802784, "Avg loss": 1.0611641679424793, "Avg value loss": 0.7698474067728966, "Avg policy loss": 0.29131675290409476, "Total num played games": 40808, "Total num trained steps": 81024, "Timestamp in ms": 1700550255797, "logtype": "training_step"}
{"Avg objective": 21.57492187499999, "Games time in secs": 134.70968041196465, "Avg game time in secs": 1.3896273882855894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.54, "agent_stopped_0": 0.57}, "Total num played games": 40832, "Total num trained steps": 81107, "Timestamp in ms": 1700550295269, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986268846681026, "Avg loss": 0.7381076575256884, "Avg value loss": 0.44748756557237357, "Avg policy loss": 0.29062008403707296, "Total num played games": 40856, "Total num trained steps": 81152, "Timestamp in ms": 1700550315777, "logtype": "training_step"}
{"Total num played games": 40905, "Total num trained steps": 81215, "Timestamp in ms": 1700550397985, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1802734375}
{"Ratio train steps to played games": 1.9847141845530243, "Avg loss": 0.8733923572581261, "Avg value loss": 0.5715496229822747, "Avg policy loss": 0.30184272991027683, "Total num played games": 40953, "Total num trained steps": 81280, "Timestamp in ms": 1700550429863, "logtype": "training_step"}
{"Avg objective": 22.11671874999999, "Games time in secs": 191.8995781838894, "Avg game time in secs": 1.506980074918829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 40960, "Total num trained steps": 81396, "Timestamp in ms": 1700550487169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855365853658538, "Avg loss": 0.485609122319147, "Avg value loss": 0.20712380969780497, "Avg policy loss": 0.2784853130578995, "Total num played games": 41000, "Total num trained steps": 81408, "Timestamp in ms": 1700550492143, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861879125965263, "Avg loss": 0.6418001998681575, "Avg value loss": 0.35795469442382455, "Avg policy loss": 0.28384551079943776, "Total num played games": 41051, "Total num trained steps": 81536, "Timestamp in ms": 1700550553117, "logtype": "training_step"}
{"Avg objective": 20.969687499999992, "Games time in secs": 95.16359335556626, "Avg game time in secs": 1.5003428013442317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.6}, "Total num played games": 41088, "Total num trained steps": 81594, "Timestamp in ms": 1700550582333, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869826516460254, "Avg loss": 0.5737983996514231, "Avg value loss": 0.292985285166651, "Avg policy loss": 0.2808131087804213, "Total num played games": 41099, "Total num trained steps": 81664, "Timestamp in ms": 1700550618426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856040007768498, "Avg loss": 0.6137807797640562, "Avg value loss": 0.3293814522039611, "Avg policy loss": 0.28439932770561427, "Total num played games": 41192, "Total num trained steps": 81792, "Timestamp in ms": 1700550684184, "logtype": "training_step"}
{"Total num played games": 41197, "Total num trained steps": 81818, "Timestamp in ms": 1700550734845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4655078125}
{"Avg objective": 22.40695312499999, "Games time in secs": 154.3919656071812, "Avg game time in secs": 1.4619825211557327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.69, "agent_stopped_0": 0.44}, "Total num played games": 41216, "Total num trained steps": 81821, "Timestamp in ms": 1700550736725, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861801430476422, "Avg loss": 0.7592728822492063, "Avg value loss": 0.44794876978266984, "Avg policy loss": 0.311324120615609, "Total num played games": 41245, "Total num trained steps": 81920, "Timestamp in ms": 1700550787859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869711573390163, "Avg loss": 0.7966089784167707, "Avg value loss": 0.5076777437061537, "Avg policy loss": 0.2889312254264951, "Total num played games": 41293, "Total num trained steps": 82048, "Timestamp in ms": 1700550853340, "logtype": "training_step"}
{"Avg objective": 21.617031249999986, "Games time in secs": 177.5522690564394, "Avg game time in secs": 1.561258988629561, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.66, "agent_stopped_0": 0.47}, "Total num played games": 41344, "Total num trained steps": 82171, "Timestamp in ms": 1700550914277, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985670790643727, "Avg loss": 0.5310372442472726, "Avg value loss": 0.24716571846511215, "Avg policy loss": 0.2838715309044346, "Total num played games": 41384, "Total num trained steps": 82176, "Timestamp in ms": 1700550916340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861241825333622, "Avg loss": 0.6130377133376896, "Avg value loss": 0.3198626036173664, "Avg policy loss": 0.2931751044234261, "Total num played games": 41439, "Total num trained steps": 82304, "Timestamp in ms": 1700550981576, "logtype": "training_step"}
{"Avg objective": 21.751562499999988, "Games time in secs": 101.66809352859855, "Avg game time in secs": 1.2760873438819544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 41472, "Total num trained steps": 82370, "Timestamp in ms": 1700551015946, "logtype": "played_game"}
{"Total num played games": 41487, "Total num trained steps": 82418, "Timestamp in ms": 1700551097174, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.193828125000003}
{"Ratio train steps to played games": 1.9846153846153847, "Avg loss": 0.6468280674889684, "Avg value loss": 0.3681753898272291, "Avg policy loss": 0.2786526740528643, "Total num played games": 41535, "Total num trained steps": 82432, "Timestamp in ms": 1700551105738, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987553565409986, "Avg loss": 0.45276751508936286, "Avg value loss": 0.17458914604503661, "Avg policy loss": 0.27817837591283023, "Total num played games": 41535, "Total num trained steps": 82560, "Timestamp in ms": 1700551170969, "logtype": "training_step"}
{"Avg objective": 21.72156249999999, "Games time in secs": 207.59501114673913, "Avg game time in secs": 1.2774096768553136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 41600, "Total num trained steps": 82658, "Timestamp in ms": 1700551223541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861644888547272, "Avg loss": 0.7647504198830575, "Avg value loss": 0.4831607714877464, "Avg policy loss": 0.281589655787684, "Total num played games": 41632, "Total num trained steps": 82688, "Timestamp in ms": 1700551238798, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868765144790193, "Avg loss": 0.5676458047237247, "Avg value loss": 0.2820982045959681, "Avg policy loss": 0.2855476000113413, "Total num played games": 41681, "Total num trained steps": 82816, "Timestamp in ms": 1700551303103, "logtype": "training_step"}
{"Avg objective": 21.707812499999985, "Games time in secs": 101.02383672446012, "Avg game time in secs": 1.4133003248134628, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.58}, "Total num played games": 41728, "Total num trained steps": 82860, "Timestamp in ms": 1700551324565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876824270890747, "Avg loss": 0.4806854813359678, "Avg value loss": 0.20904684223933145, "Avg policy loss": 0.2716386413667351, "Total num played games": 41729, "Total num trained steps": 82944, "Timestamp in ms": 1700551367958, "logtype": "training_step"}
{"Total num played games": 41778, "Total num trained steps": 83021, "Timestamp in ms": 1700551496945, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.070429687500003}
{"Ratio train steps to played games": 1.986133027303591, "Avg loss": 0.6786895643454045, "Avg value loss": 0.40275995287811384, "Avg policy loss": 0.2759296125732362, "Total num played games": 41826, "Total num trained steps": 83072, "Timestamp in ms": 1700551525328, "logtype": "training_step"}
{"Avg objective": 20.444609374999995, "Games time in secs": 241.2964586019516, "Avg game time in secs": 1.3193636801006505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 41856, "Total num trained steps": 83143, "Timestamp in ms": 1700551565861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986652021299458, "Avg loss": 0.5674327169544995, "Avg value loss": 0.2955841845832765, "Avg policy loss": 0.2718485308578238, "Total num played games": 41879, "Total num trained steps": 83200, "Timestamp in ms": 1700551594272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874543850025044, "Avg loss": 0.6406231978908181, "Avg value loss": 0.37296542956028134, "Avg policy loss": 0.26765776809770614, "Total num played games": 41927, "Total num trained steps": 83328, "Timestamp in ms": 1700551658262, "logtype": "training_step"}
{"Avg objective": 22.32874999999999, "Games time in secs": 154.7982525229454, "Avg game time in secs": 1.4066985957324505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.58}, "Total num played games": 41984, "Total num trained steps": 83451, "Timestamp in ms": 1700551720660, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985841760856633, "Avg loss": 0.461756591219455, "Avg value loss": 0.20192510253400542, "Avg policy loss": 0.25983148685190827, "Total num played games": 42025, "Total num trained steps": 83456, "Timestamp in ms": 1700551722600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863352265975902, "Avg loss": 0.7501636471133679, "Avg value loss": 0.4722343874746002, "Avg policy loss": 0.2779292636550963, "Total num played games": 42079, "Total num trained steps": 83584, "Timestamp in ms": 1700551789926, "logtype": "training_step"}
{"Total num played games": 42079, "Total num trained steps": 83624, "Timestamp in ms": 1700551865369, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5087109375}
{"Avg objective": 21.99984374999999, "Games time in secs": 146.84737244807184, "Avg game time in secs": 1.2052296650508652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 42112, "Total num trained steps": 83628, "Timestamp in ms": 1700551867507, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987110404253804, "Avg loss": 0.6119931766297668, "Avg value loss": 0.3371413620770909, "Avg policy loss": 0.27485181868541986, "Total num played games": 42127, "Total num trained steps": 83712, "Timestamp in ms": 1700551909000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877424249608802, "Avg loss": 0.4808305990882218, "Avg value loss": 0.21353378391359001, "Avg policy loss": 0.2672968116821721, "Total num played games": 42178, "Total num trained steps": 83840, "Timestamp in ms": 1700551970077, "logtype": "training_step"}
{"Avg objective": 21.34382812499999, "Games time in secs": 156.34354762546718, "Avg game time in secs": 1.405206451061531, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.62, "agent_stopped_0": 0.5}, "Total num played games": 42240, "Total num trained steps": 83956, "Timestamp in ms": 1700552023851, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859511364442657, "Avg loss": 0.6194217910524458, "Avg value loss": 0.34941347170388326, "Avg policy loss": 0.2700083226663992, "Total num played games": 42281, "Total num trained steps": 83968, "Timestamp in ms": 1700552029141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866524923222302, "Avg loss": 0.6908449316397309, "Avg value loss": 0.41633465464110486, "Avg policy loss": 0.2745102768531069, "Total num played games": 42330, "Total num trained steps": 84096, "Timestamp in ms": 1700552089272, "logtype": "training_step"}
{"Avg objective": 21.90703124999999, "Games time in secs": 92.80982755683362, "Avg game time in secs": 1.2970905783295166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 42368, "Total num trained steps": 84152, "Timestamp in ms": 1700552116661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873056322408627, "Avg loss": 0.7493087095208466, "Avg value loss": 0.45974379224935547, "Avg policy loss": 0.28956490638665855, "Total num played games": 42381, "Total num trained steps": 84224, "Timestamp in ms": 1700552151209, "logtype": "training_step"}
{"Total num played games": 42381, "Total num trained steps": 84225, "Timestamp in ms": 1700552218257, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8858203125}
{"Ratio train steps to played games": 1.9862017000635759, "Avg loss": 0.6429350527469069, "Avg value loss": 0.36050948937190697, "Avg policy loss": 0.2824255683226511, "Total num played games": 42468, "Total num trained steps": 84352, "Timestamp in ms": 1700552277817, "logtype": "training_step"}
{"Avg objective": 21.262031249999982, "Games time in secs": 209.79978321120143, "Avg game time in secs": 1.2935184708912857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 42496, "Total num trained steps": 84447, "Timestamp in ms": 1700552326461, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863857603047332, "Avg loss": 0.7664392867591232, "Avg value loss": 0.47231819335138425, "Avg policy loss": 0.2941211082506925, "Total num played games": 42529, "Total num trained steps": 84480, "Timestamp in ms": 1700552342810, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871761749301267, "Avg loss": 0.54778329632245, "Avg value loss": 0.2656365363509394, "Avg policy loss": 0.28214675665367395, "Total num played games": 42577, "Total num trained steps": 84608, "Timestamp in ms": 1700552403981, "logtype": "training_step"}
{"Avg objective": 20.968593749999986, "Games time in secs": 97.23179669678211, "Avg game time in secs": 1.4477756746928208, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 42624, "Total num trained steps": 84648, "Timestamp in ms": 1700552423693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987941348973607, "Avg loss": 0.5699170886073261, "Avg value loss": 0.28562967013567686, "Avg policy loss": 0.28428741614334285, "Total num played games": 42625, "Total num trained steps": 84736, "Timestamp in ms": 1700552466362, "logtype": "training_step"}
{"Total num played games": 42674, "Total num trained steps": 84826, "Timestamp in ms": 1700552577413, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.569765625000002}
{"Ratio train steps to played games": 1.9864238565610224, "Avg loss": 0.7470403984189034, "Avg value loss": 0.46960582793690264, "Avg policy loss": 0.2774345724610612, "Total num played games": 42722, "Total num trained steps": 84864, "Timestamp in ms": 1700552595456, "logtype": "training_step"}
{"Avg objective": 23.06773437499999, "Games time in secs": 209.09680276550353, "Avg game time in secs": 1.1175408703566063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 42752, "Total num trained steps": 84935, "Timestamp in ms": 1700552632790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871174393865, "Avg loss": 0.7113209671806544, "Avg value loss": 0.43626326794037595, "Avg policy loss": 0.2750576969701797, "Total num played games": 42771, "Total num trained steps": 84992, "Timestamp in ms": 1700552661591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987600700525394, "Avg loss": 0.5826634133700281, "Avg value loss": 0.30171805125428364, "Avg policy loss": 0.280945363920182, "Total num played games": 42825, "Total num trained steps": 85120, "Timestamp in ms": 1700552727688, "logtype": "training_step"}
{"Avg objective": 21.89898437499999, "Games time in secs": 154.94001345522702, "Avg game time in secs": 1.2842210716480622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 42880, "Total num trained steps": 85244, "Timestamp in ms": 1700552787730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986229874880589, "Avg loss": 0.6714714348781854, "Avg value loss": 0.4001982801128179, "Avg policy loss": 0.27127315395046026, "Total num played games": 42919, "Total num trained steps": 85248, "Timestamp in ms": 1700552789280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867358573988319, "Avg loss": 0.7379399137571454, "Avg value loss": 0.4638921840232797, "Avg policy loss": 0.2740477315383032, "Total num played games": 42973, "Total num trained steps": 85376, "Timestamp in ms": 1700552848632, "logtype": "training_step"}
{"Total num played games": 42973, "Total num trained steps": 85427, "Timestamp in ms": 1700552907395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8230859375}
{"Avg objective": 22.020859374999993, "Games time in secs": 121.88328598253429, "Avg game time in secs": 1.186038097468554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 43008, "Total num trained steps": 85432, "Timestamp in ms": 1700552909613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874712349782664, "Avg loss": 0.59363988856785, "Avg value loss": 0.3146739780786447, "Avg policy loss": 0.27896591287571937, "Total num played games": 43021, "Total num trained steps": 85504, "Timestamp in ms": 1700552944009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863833538240274, "Avg loss": 0.5713787730783224, "Avg value loss": 0.29549491085344926, "Avg policy loss": 0.27588387054856867, "Total num played games": 43109, "Total num trained steps": 85632, "Timestamp in ms": 1700553002989, "logtype": "training_step"}
{"Avg objective": 21.242187499999986, "Games time in secs": 136.50051078945398, "Avg game time in secs": 1.2972226948622847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 43136, "Total num trained steps": 85725, "Timestamp in ms": 1700553046114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986679639539463, "Avg loss": 0.947110045934096, "Avg value loss": 0.6558787159156054, "Avg policy loss": 0.2912313317647204, "Total num played games": 43167, "Total num trained steps": 85760, "Timestamp in ms": 1700553061841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874349184311002, "Avg loss": 0.7407028116285801, "Avg value loss": 0.4488758221268654, "Avg policy loss": 0.2918269895017147, "Total num played games": 43215, "Total num trained steps": 85888, "Timestamp in ms": 1700553120779, "logtype": "training_step"}
{"Avg objective": 22.127187499999984, "Games time in secs": 135.2269999459386, "Avg game time in secs": 1.3250365916028386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 43264, "Total num trained steps": 86015, "Timestamp in ms": 1700553181341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988050663338418, "Avg loss": 0.5682351859286427, "Avg value loss": 0.28447281231638044, "Avg policy loss": 0.2837623779196292, "Total num played games": 43266, "Total num trained steps": 86016, "Timestamp in ms": 1700553181501, "logtype": "training_step"}
{"Total num played games": 43311, "Total num trained steps": 86030, "Timestamp in ms": 1700553239568, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.048710937500005}
{"Ratio train steps to played games": 1.9867386240457574, "Avg loss": 0.7598440535366535, "Avg value loss": 0.4655980833922513, "Avg policy loss": 0.2942459591431543, "Total num played games": 43359, "Total num trained steps": 86144, "Timestamp in ms": 1700553293997, "logtype": "training_step"}
{"Avg objective": 21.416406249999987, "Games time in secs": 144.88825510814786, "Avg game time in secs": 1.0975109436840285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 43392, "Total num trained steps": 86211, "Timestamp in ms": 1700553326230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987513534683346, "Avg loss": 0.4841812571976334, "Avg value loss": 0.19502864385140128, "Avg policy loss": 0.28915261302608997, "Total num played games": 43407, "Total num trained steps": 86272, "Timestamp in ms": 1700553355500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988126466933591, "Avg loss": 0.6338097786065191, "Avg value loss": 0.35235717316390947, "Avg policy loss": 0.2814526107395068, "Total num played games": 43456, "Total num trained steps": 86400, "Timestamp in ms": 1700553414457, "logtype": "training_step"}
{"Avg objective": 21.611953124999992, "Games time in secs": 133.1207657624036, "Avg game time in secs": 1.3556811461457983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.52, "agent_stopped_0": 0.61}, "Total num played games": 43520, "Total num trained steps": 86497, "Timestamp in ms": 1700553459351, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986797088470988, "Avg loss": 0.8344357910100371, "Avg value loss": 0.5491267011966556, "Avg policy loss": 0.28530907130334526, "Total num played games": 43551, "Total num trained steps": 86528, "Timestamp in ms": 1700553473071, "logtype": "training_step"}
{"Total num played games": 43600, "Total num trained steps": 86632, "Timestamp in ms": 1700553580943, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.742421875}
{"Avg objective": 21.06437499999998, "Games time in secs": 127.10665315948427, "Avg game time in secs": 1.3429430925752968, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 43648, "Total num trained steps": 86644, "Timestamp in ms": 1700553586457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853372434017595, "Avg loss": 0.6381921342108399, "Avg value loss": 0.35778647841652855, "Avg policy loss": 0.28040565468836576, "Total num played games": 43648, "Total num trained steps": 86656, "Timestamp in ms": 1700553591927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988246884164223, "Avg loss": 0.409460041904822, "Avg value loss": 0.13128104712814093, "Avg policy loss": 0.27817899105139077, "Total num played games": 43648, "Total num trained steps": 86784, "Timestamp in ms": 1700553652310, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867642016230427, "Avg loss": 0.6326673035509884, "Avg value loss": 0.3501679300388787, "Avg policy loss": 0.28249936969950795, "Total num played games": 43745, "Total num trained steps": 86912, "Timestamp in ms": 1700553711648, "logtype": "training_step"}
{"Avg objective": 21.988281249999993, "Games time in secs": 158.39854602888227, "Avg game time in secs": 1.213105972361518, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 43776, "Total num trained steps": 86982, "Timestamp in ms": 1700553744856, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874186550976138, "Avg loss": 0.6111350113060325, "Avg value loss": 0.3251069929683581, "Avg policy loss": 0.286028016009368, "Total num played games": 43795, "Total num trained steps": 87040, "Timestamp in ms": 1700553771752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879355956942164, "Avg loss": 0.5453252918086946, "Avg value loss": 0.25745786662446335, "Avg policy loss": 0.2878674234962091, "Total num played games": 43848, "Total num trained steps": 87168, "Timestamp in ms": 1700553829633, "logtype": "training_step"}
{"Total num played games": 43898, "Total num trained steps": 87236, "Timestamp in ms": 1700553931761, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5814453125}
{"Avg objective": 20.36203124999998, "Games time in secs": 188.08863633871078, "Avg game time in secs": 1.374738512953627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.61}, "Total num played games": 43904, "Total num trained steps": 87238, "Timestamp in ms": 1700553932945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864379010603923, "Avg loss": 0.6314997407607734, "Avg value loss": 0.33377725241007283, "Avg policy loss": 0.29772249213419855, "Total num played games": 43946, "Total num trained steps": 87296, "Timestamp in ms": 1700553959019, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987112171837709, "Avg loss": 0.5906403758563101, "Avg value loss": 0.3112630138057284, "Avg policy loss": 0.2793773632729426, "Total num played games": 43995, "Total num trained steps": 87424, "Timestamp in ms": 1700554017087, "logtype": "training_step"}
{"Avg objective": 21.346874999999994, "Games time in secs": 110.30383561179042, "Avg game time in secs": 1.1431570689892396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 44032, "Total num trained steps": 87482, "Timestamp in ms": 1700554043249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878754853211633, "Avg loss": 0.5837152234744281, "Avg value loss": 0.2899972627055831, "Avg policy loss": 0.29371796280611306, "Total num played games": 44043, "Total num trained steps": 87552, "Timestamp in ms": 1700554076114, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864068871771636, "Avg loss": 0.5397624901961535, "Avg value loss": 0.25438974145799875, "Avg policy loss": 0.28537275141570717, "Total num played games": 44140, "Total num trained steps": 87680, "Timestamp in ms": 1700554133379, "logtype": "training_step"}
{"Avg objective": 22.07421874999999, "Games time in secs": 132.23848734796047, "Avg game time in secs": 1.4031913716898998, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.61, "agent_stopped_0": 0.54}, "Total num played games": 44160, "Total num trained steps": 87773, "Timestamp in ms": 1700554175489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868983775711087, "Avg loss": 0.7863053979817778, "Avg value loss": 0.493546154582873, "Avg policy loss": 0.29275924852117896, "Total num played games": 44193, "Total num trained steps": 87808, "Timestamp in ms": 1700554192041, "logtype": "training_step"}
{"Total num played games": 44193, "Total num trained steps": 87838, "Timestamp in ms": 1700554273682, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.152578124999998}
{"Ratio train steps to played games": 1.9876585068149455, "Avg loss": 0.6025442325044423, "Avg value loss": 0.30958876211661845, "Avg policy loss": 0.2929554706206545, "Total num played games": 44241, "Total num trained steps": 87936, "Timestamp in ms": 1700554318795, "logtype": "training_step"}
{"Avg objective": 21.575312499999995, "Games time in secs": 161.69602416828275, "Avg game time in secs": 1.195419161056634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.5, "agent_stopped_0": 0.58}, "Total num played games": 44288, "Total num trained steps": 87976, "Timestamp in ms": 1700554337185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883495145631067, "Avg loss": 0.6011081882752478, "Avg value loss": 0.32435623128549196, "Avg policy loss": 0.27675195154733956, "Total num played games": 44290, "Total num trained steps": 88064, "Timestamp in ms": 1700554378851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986910287027441, "Avg loss": 0.798976160120219, "Avg value loss": 0.5156422596774064, "Avg policy loss": 0.28333389142062515, "Total num played games": 44386, "Total num trained steps": 88192, "Timestamp in ms": 1700554439225, "logtype": "training_step"}
{"Avg objective": 22.725546874999996, "Games time in secs": 135.09029815718532, "Avg game time in secs": 1.0885791981854709, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.42, "agent_stopped_0": 0.61}, "Total num played games": 44416, "Total num trained steps": 88264, "Timestamp in ms": 1700554472275, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987488185786939, "Avg loss": 0.5553303987253457, "Avg value loss": 0.27680448931641877, "Avg policy loss": 0.27852590498514473, "Total num played games": 44438, "Total num trained steps": 88320, "Timestamp in ms": 1700554497433, "logtype": "training_step"}
{"Total num played games": 44487, "Total num trained steps": 88439, "Timestamp in ms": 1700554607503, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.443359375}
{"Ratio train steps to played games": 1.9860334568317053, "Avg loss": 0.5702742324210703, "Avg value loss": 0.30152221518801525, "Avg policy loss": 0.26875202264636755, "Total num played games": 44535, "Total num trained steps": 88448, "Timestamp in ms": 1700554612696, "logtype": "training_step"}
{"Avg objective": 21.273671874999984, "Games time in secs": 192.18739244528115, "Avg game time in secs": 1.2849893889942905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.53}, "Total num played games": 44544, "Total num trained steps": 88560, "Timestamp in ms": 1700554664463, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986766256196308, "Avg loss": 0.6428762278519571, "Avg value loss": 0.375567624141695, "Avg policy loss": 0.2673086051363498, "Total num played games": 44583, "Total num trained steps": 88576, "Timestamp in ms": 1700554671393, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874305431080839, "Avg loss": 0.5695722189266235, "Avg value loss": 0.3006316482787952, "Avg policy loss": 0.2689405740238726, "Total num played games": 44632, "Total num trained steps": 88704, "Timestamp in ms": 1700554731301, "logtype": "training_step"}
{"Avg objective": 21.09304687499999, "Games time in secs": 91.3161175083369, "Avg game time in secs": 1.2737790729588596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 44672, "Total num trained steps": 88757, "Timestamp in ms": 1700554755779, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881826320501343, "Avg loss": 0.5089945362415165, "Avg value loss": 0.2464938355551567, "Avg policy loss": 0.2625007047317922, "Total num played games": 44680, "Total num trained steps": 88832, "Timestamp in ms": 1700554792053, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987466487935657, "Avg loss": 0.4499790525296703, "Avg value loss": 0.19653441559057683, "Avg policy loss": 0.25344463461078703, "Total num played games": 44760, "Total num trained steps": 88960, "Timestamp in ms": 1700554850498, "logtype": "training_step"}
{"Total num played games": 44786, "Total num trained steps": 89040, "Timestamp in ms": 1700554950385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0524609375}
{"Avg objective": 20.916093749999987, "Games time in secs": 196.11354146525264, "Avg game time in secs": 1.3085426041361643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 44800, "Total num trained steps": 89043, "Timestamp in ms": 1700554951893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987041084890931, "Avg loss": 0.8376305748242885, "Avg value loss": 0.5683290778542869, "Avg policy loss": 0.26930149691179395, "Total num played games": 44834, "Total num trained steps": 89088, "Timestamp in ms": 1700554972842, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877679247805355, "Avg loss": 0.5745434467680752, "Avg value loss": 0.31010872562183067, "Avg policy loss": 0.264434720040299, "Total num played games": 44882, "Total num trained steps": 89216, "Timestamp in ms": 1700555032766, "logtype": "training_step"}
{"Avg objective": 21.88999999999999, "Games time in secs": 101.22179917804897, "Avg game time in secs": 1.108016428843257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.47}, "Total num played games": 44928, "Total num trained steps": 89259, "Timestamp in ms": 1700555053115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884932116625862, "Avg loss": 0.5560374732594937, "Avg value loss": 0.28779903129907325, "Avg policy loss": 0.2682384457439184, "Total num played games": 44930, "Total num trained steps": 89344, "Timestamp in ms": 1700555092472, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869198312236287, "Avg loss": 0.5313218899536878, "Avg value loss": 0.2669576579355635, "Avg policy loss": 0.26436423079576343, "Total num played games": 45030, "Total num trained steps": 89472, "Timestamp in ms": 1700555150644, "logtype": "training_step"}
{"Avg objective": 20.03109374999999, "Games time in secs": 133.82307186350226, "Avg game time in secs": 1.2463755053759087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 45056, "Total num trained steps": 89551, "Timestamp in ms": 1700555186938, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874672818419767, "Avg loss": 0.5237687376793474, "Avg value loss": 0.25379525547032245, "Avg policy loss": 0.2699734802590683, "Total num played games": 45082, "Total num trained steps": 89600, "Timestamp in ms": 1700555209690, "logtype": "training_step"}
{"Total num played games": 45082, "Total num trained steps": 89643, "Timestamp in ms": 1700555294634, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5959765625}
{"Ratio train steps to played games": 1.9882118324839353, "Avg loss": 0.47264013439416885, "Avg value loss": 0.2129876739345491, "Avg policy loss": 0.2596524605760351, "Total num played games": 45130, "Total num trained steps": 89728, "Timestamp in ms": 1700555336622, "logtype": "training_step"}
{"Avg objective": 20.704531249999995, "Games time in secs": 204.6653409563005, "Avg game time in secs": 1.1238034996931674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 45184, "Total num trained steps": 89846, "Timestamp in ms": 1700555391603, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986755699029341, "Avg loss": 0.5976677627768368, "Avg value loss": 0.3464424274279736, "Avg policy loss": 0.25122533889953047, "Total num played games": 45227, "Total num trained steps": 89856, "Timestamp in ms": 1700555396016, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874765323025954, "Avg loss": 0.5880487863905728, "Avg value loss": 0.32182000135071576, "Avg policy loss": 0.2662287795683369, "Total num played games": 45275, "Total num trained steps": 89984, "Timestamp in ms": 1700555456388, "logtype": "training_step"}
{"Avg objective": 22.835156249999994, "Games time in secs": 92.8334992043674, "Avg game time in secs": 1.2338243050326128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.54}, "Total num played games": 45312, "Total num trained steps": 90042, "Timestamp in ms": 1700555484437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881519724649193, "Avg loss": 0.6047920205164701, "Avg value loss": 0.3412761512445286, "Avg policy loss": 0.2635158688062802, "Total num played games": 45324, "Total num trained steps": 90112, "Timestamp in ms": 1700555518369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886726755845472, "Avg loss": 0.6732381337787956, "Avg value loss": 0.41195543340290897, "Avg policy loss": 0.26128270069602877, "Total num played games": 45377, "Total num trained steps": 90240, "Timestamp in ms": 1700555581485, "logtype": "training_step"}
{"Total num played games": 45425, "Total num trained steps": 90245, "Timestamp in ms": 1700555648461, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.150976562500002}
{"Avg objective": 22.235390624999983, "Games time in secs": 165.58976442180574, "Avg game time in secs": 1.3151957915106323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.57, "agent_stopped_0": 0.54}, "Total num played games": 45440, "Total num trained steps": 90248, "Timestamp in ms": 1700555650027, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872671695291713, "Avg loss": 1.0139765958301723, "Avg value loss": 0.7431354084401391, "Avg policy loss": 0.2708411847706884, "Total num played games": 45473, "Total num trained steps": 90368, "Timestamp in ms": 1700555711743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879835680235496, "Avg loss": 0.5884081913391128, "Avg value loss": 0.33314162530587055, "Avg policy loss": 0.25526656629517674, "Total num played games": 45521, "Total num trained steps": 90496, "Timestamp in ms": 1700555781592, "logtype": "training_step"}
{"Avg objective": 22.947109374999986, "Games time in secs": 153.5257566384971, "Avg game time in secs": 1.1688432128430577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 45568, "Total num trained steps": 90537, "Timestamp in ms": 1700555803553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886984572845574, "Avg loss": 0.6077893392648548, "Avg value loss": 0.3443290808936581, "Avg policy loss": 0.26346026454120874, "Total num played games": 45569, "Total num trained steps": 90624, "Timestamp in ms": 1700555847776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987320705135224, "Avg loss": 0.6664647802244872, "Avg value loss": 0.4170822018641047, "Avg policy loss": 0.24938257655594498, "Total num played games": 45665, "Total num trained steps": 90752, "Timestamp in ms": 1700555911161, "logtype": "training_step"}
{"Avg objective": 20.89609374999999, "Games time in secs": 142.0426988657564, "Avg game time in secs": 1.1743706893903436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.37, "agent_stopped_0": 0.67}, "Total num played games": 45696, "Total num trained steps": 90821, "Timestamp in ms": 1700555945596, "logtype": "played_game"}
{"Total num played games": 45714, "Total num trained steps": 90845, "Timestamp in ms": 1700556028693, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.676679687500002}
{"Ratio train steps to played games": 1.9859271884970062, "Avg loss": 0.8236704750452191, "Avg value loss": 0.5669756244169548, "Avg policy loss": 0.25669484096579254, "Total num played games": 45762, "Total num trained steps": 90880, "Timestamp in ms": 1700556047885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887024168524103, "Avg loss": 0.33415131515357643, "Avg value loss": 0.10095506624202244, "Avg policy loss": 0.23319624993018806, "Total num played games": 45762, "Total num trained steps": 91008, "Timestamp in ms": 1700556113071, "logtype": "training_step"}
{"Avg objective": 20.355234374999984, "Games time in secs": 219.4429334681481, "Avg game time in secs": 1.3163311180251185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 45824, "Total num trained steps": 91110, "Timestamp in ms": 1700556165039, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873304548824633, "Avg loss": 0.5745224024867639, "Avg value loss": 0.32867068660561927, "Avg policy loss": 0.24585171358194202, "Total num played games": 45858, "Total num trained steps": 91136, "Timestamp in ms": 1700556178024, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880407789831394, "Avg loss": 0.503283699741587, "Avg value loss": 0.25865567446453497, "Avg policy loss": 0.24462802859488875, "Total num played games": 45906, "Total num trained steps": 91264, "Timestamp in ms": 1700556239898, "logtype": "training_step"}
{"Avg objective": 21.33593749999999, "Games time in secs": 95.17005807161331, "Avg game time in secs": 1.2416478409722913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 45952, "Total num trained steps": 91304, "Timestamp in ms": 1700556260209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988576526393664, "Avg loss": 0.539845674764365, "Avg value loss": 0.2887223938596435, "Avg policy loss": 0.25112328003160655, "Total num played games": 45958, "Total num trained steps": 91392, "Timestamp in ms": 1700556305680, "logtype": "training_step"}
{"Total num played games": 46006, "Total num trained steps": 91448, "Timestamp in ms": 1700556431044, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.770859375}
{"Ratio train steps to played games": 1.987210665740218, "Avg loss": 0.5689039819408208, "Avg value loss": 0.3104682287957985, "Avg policy loss": 0.2584357522428036, "Total num played games": 46054, "Total num trained steps": 91520, "Timestamp in ms": 1700556466165, "logtype": "training_step"}
{"Avg objective": 21.918281249999993, "Games time in secs": 244.32766249589622, "Avg game time in secs": 1.1589163886092138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.38, "agent_stopped_0": 0.7}, "Total num played games": 46080, "Total num trained steps": 91599, "Timestamp in ms": 1700556504537, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879397856925947, "Avg loss": 0.4305969091365114, "Avg value loss": 0.18369480082765222, "Avg policy loss": 0.24690211017150432, "Total num played games": 46102, "Total num trained steps": 91648, "Timestamp in ms": 1700556528631, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885809624926871, "Avg loss": 0.6398814414860681, "Avg value loss": 0.39155681914417073, "Avg policy loss": 0.24832462635822594, "Total num played games": 46151, "Total num trained steps": 91776, "Timestamp in ms": 1700556590211, "logtype": "training_step"}
{"Avg objective": 22.774999999999995, "Games time in secs": 143.2901305090636, "Avg game time in secs": 1.1002968737884657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 46208, "Total num trained steps": 91888, "Timestamp in ms": 1700556647827, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872207927000671, "Avg loss": 0.5886756692780182, "Avg value loss": 0.33831005133106373, "Avg policy loss": 0.2503656193148345, "Total num played games": 46247, "Total num trained steps": 91904, "Timestamp in ms": 1700556656132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879252619073333, "Avg loss": 0.6477310087066144, "Avg value loss": 0.38574669274385087, "Avg policy loss": 0.26198431430384517, "Total num played games": 46295, "Total num trained steps": 92032, "Timestamp in ms": 1700556721991, "logtype": "training_step"}
{"Total num played games": 46295, "Total num trained steps": 92051, "Timestamp in ms": 1700556762946, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.728125000000006}
{"Avg objective": 22.29320312499999, "Games time in secs": 117.8091681972146, "Avg game time in secs": 1.108077624507132, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 46336, "Total num trained steps": 92056, "Timestamp in ms": 1700556765637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886498500312884, "Avg loss": 0.5803348526824266, "Avg value loss": 0.32466359448153526, "Avg policy loss": 0.2556712579680607, "Total num played games": 46343, "Total num trained steps": 92160, "Timestamp in ms": 1700556820592, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987188045046403, "Avg loss": 0.7119863268453628, "Avg value loss": 0.44974159938283265, "Avg policy loss": 0.2622447272296995, "Total num played games": 46441, "Total num trained steps": 92288, "Timestamp in ms": 1700556885630, "logtype": "training_step"}
{"Avg objective": 22.062421874999995, "Games time in secs": 164.78504252806306, "Avg game time in secs": 1.2622230389824836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.51, "agent_stopped_0": 0.62}, "Total num played games": 46464, "Total num trained steps": 92372, "Timestamp in ms": 1700556930422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878896082944353, "Avg loss": 0.6919322265312076, "Avg value loss": 0.4207387625647243, "Avg policy loss": 0.27119345928076655, "Total num played games": 46489, "Total num trained steps": 92416, "Timestamp in ms": 1700556952700, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886112125835358, "Avg loss": 0.6389077648054808, "Avg value loss": 0.3713341670227237, "Avg policy loss": 0.26757360447663814, "Total num played games": 46537, "Total num trained steps": 92544, "Timestamp in ms": 1700557014255, "logtype": "training_step"}
{"Total num played games": 46586, "Total num trained steps": 92654, "Timestamp in ms": 1700557119429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.723359375}
{"Avg objective": 21.97398437499999, "Games time in secs": 190.41158923693, "Avg game time in secs": 1.191565611792612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 46592, "Total num trained steps": 92656, "Timestamp in ms": 1700557120833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871981815842519, "Avg loss": 0.5841264125192538, "Avg value loss": 0.31743067779461853, "Avg policy loss": 0.2666957384208217, "Total num played games": 46634, "Total num trained steps": 92672, "Timestamp in ms": 1700557128812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879182554303585, "Avg loss": 0.49683227576315403, "Avg value loss": 0.2362945987842977, "Avg policy loss": 0.26053767814300954, "Total num played games": 46682, "Total num trained steps": 92800, "Timestamp in ms": 1700557192932, "logtype": "training_step"}
{"Avg objective": 21.701640624999996, "Games time in secs": 100.85339173302054, "Avg game time in secs": 1.1867451769649051, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 46720, "Total num trained steps": 92856, "Timestamp in ms": 1700557221687, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885940509308795, "Avg loss": 0.5988678977591917, "Avg value loss": 0.3384595241805073, "Avg policy loss": 0.260408369358629, "Total num played games": 46730, "Total num trained steps": 92928, "Timestamp in ms": 1700557259249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873144687666844, "Avg loss": 0.7097316789440811, "Avg value loss": 0.4453643971355632, "Avg policy loss": 0.2643672826234251, "Total num played games": 46825, "Total num trained steps": 93056, "Timestamp in ms": 1700557323665, "logtype": "training_step"}
{"Avg objective": 21.646093749999988, "Games time in secs": 145.7302025910467, "Avg game time in secs": 1.183211156996549, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 46848, "Total num trained steps": 93145, "Timestamp in ms": 1700557367418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987904, "Avg loss": 0.7519191906321794, "Avg value loss": 0.47280483308713883, "Avg policy loss": 0.27911435812711716, "Total num played games": 46875, "Total num trained steps": 93184, "Timestamp in ms": 1700557387241, "logtype": "training_step"}
{"Total num played games": 46923, "Total num trained steps": 93255, "Timestamp in ms": 1700557466047, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.011875000000003}
{"Ratio train steps to played games": 1.9865661791318048, "Avg loss": 0.6855787946842611, "Avg value loss": 0.41043751797406003, "Avg policy loss": 0.2751412708312273, "Total num played games": 46971, "Total num trained steps": 93312, "Timestamp in ms": 1700557495599, "logtype": "training_step"}
{"Avg objective": 21.549687499999987, "Games time in secs": 188.10321908816695, "Avg game time in secs": 1.3550768268032698, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 46976, "Total num trained steps": 93432, "Timestamp in ms": 1700557555521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986922406277245, "Avg loss": 0.37970331707037985, "Avg value loss": 0.11902327573625371, "Avg policy loss": 0.2606800398789346, "Total num played games": 47027, "Total num trained steps": 93440, "Timestamp in ms": 1700557558620, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875310661257088, "Avg loss": 0.6019535808591172, "Avg value loss": 0.3447065802756697, "Avg policy loss": 0.2572469983715564, "Total num played games": 47077, "Total num trained steps": 93568, "Timestamp in ms": 1700557617613, "logtype": "training_step"}
{"Avg objective": 21.919609374999993, "Games time in secs": 100.45627515204251, "Avg game time in secs": 1.1242560205137124, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 47104, "Total num trained steps": 93645, "Timestamp in ms": 1700557655977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882440318302388, "Avg loss": 0.5563292524311692, "Avg value loss": 0.2884171335026622, "Avg policy loss": 0.26791212032549083, "Total num played games": 47125, "Total num trained steps": 93696, "Timestamp in ms": 1700557680777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888500264970854, "Avg loss": 0.5919984995853156, "Avg value loss": 0.31952687934972346, "Avg policy loss": 0.27247161767445505, "Total num played games": 47175, "Total num trained steps": 93824, "Timestamp in ms": 1700557743867, "logtype": "training_step"}
{"Total num played games": 47225, "Total num trained steps": 93856, "Timestamp in ms": 1700557814859, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.484375}
{"Avg objective": 21.481953124999986, "Games time in secs": 160.1073032040149, "Avg game time in secs": 1.3244230249692919, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.64}, "Total num played games": 47232, "Total num trained steps": 93858, "Timestamp in ms": 1700557816085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874346878768008, "Avg loss": 0.6914951655780897, "Avg value loss": 0.40575134876416996, "Avg policy loss": 0.2857438225764781, "Total num played games": 47273, "Total num trained steps": 93952, "Timestamp in ms": 1700557864278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987850487036998, "Avg loss": 0.4584669660544023, "Avg value loss": 0.19202018534997478, "Avg policy loss": 0.26644678541924804, "Total num played games": 47327, "Total num trained steps": 94080, "Timestamp in ms": 1700557929229, "logtype": "training_step"}
{"Avg objective": 20.403359374999987, "Games time in secs": 145.17546364478767, "Avg game time in secs": 1.1139729361748323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.52}, "Total num played games": 47360, "Total num trained steps": 94146, "Timestamp in ms": 1700557961261, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884962850388381, "Avg loss": 0.5470407500397414, "Avg value loss": 0.27427807249478064, "Avg policy loss": 0.27276267239358276, "Total num played games": 47376, "Total num trained steps": 94208, "Timestamp in ms": 1700557991942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891826923076923, "Avg loss": 0.5314457786735147, "Avg value loss": 0.25711679286905564, "Avg policy loss": 0.2743289872305468, "Total num played games": 47424, "Total num trained steps": 94336, "Timestamp in ms": 1700558057921, "logtype": "training_step"}
{"Avg objective": 21.22140624999999, "Games time in secs": 148.5443521887064, "Avg game time in secs": 1.2169541182665853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 47488, "Total num trained steps": 94436, "Timestamp in ms": 1700558109805, "logtype": "played_game"}
{"Total num played games": 47522, "Total num trained steps": 94459, "Timestamp in ms": 1700558184641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.427187500000002}
{"Ratio train steps to played games": 1.9864575009462926, "Avg loss": 0.6719116778112948, "Avg value loss": 0.38940536449081264, "Avg policy loss": 0.28250631073024124, "Total num played games": 47553, "Total num trained steps": 94464, "Timestamp in ms": 1700558186778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884591128862728, "Avg loss": 0.6255848577711731, "Avg value loss": 0.32946023394470103, "Avg policy loss": 0.2961246279301122, "Total num played games": 47570, "Total num trained steps": 94592, "Timestamp in ms": 1700558250844, "logtype": "training_step"}
{"Avg objective": 21.969999999999995, "Games time in secs": 162.24500872567296, "Avg game time in secs": 1.1243778568459675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 47616, "Total num trained steps": 94634, "Timestamp in ms": 1700558272050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891637616027553, "Avg loss": 0.5405878564342856, "Avg value loss": 0.2664850305591244, "Avg policy loss": 0.27410282706841826, "Total num played games": 47618, "Total num trained steps": 94720, "Timestamp in ms": 1700558318208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878232803789244, "Avg loss": 0.6879001327324659, "Avg value loss": 0.41003426839597523, "Avg policy loss": 0.2778658699244261, "Total num played games": 47714, "Total num trained steps": 94848, "Timestamp in ms": 1700558384240, "logtype": "training_step"}
{"Avg objective": 22.335703125000002, "Games time in secs": 150.81867328844965, "Avg game time in secs": 1.1574270697019529, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 47744, "Total num trained steps": 94920, "Timestamp in ms": 1700558422869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988484810418106, "Avg loss": 0.5664548331405967, "Avg value loss": 0.27614510848070495, "Avg policy loss": 0.2903097216039896, "Total num played games": 47763, "Total num trained steps": 94976, "Timestamp in ms": 1700558450986, "logtype": "training_step"}
{"Total num played games": 47814, "Total num trained steps": 95062, "Timestamp in ms": 1700558530425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.161601562500003}
{"Ratio train steps to played games": 1.9870460908445113, "Avg loss": 0.7999670014251024, "Avg value loss": 0.5083672062610276, "Avg policy loss": 0.2915997947566211, "Total num played games": 47862, "Total num trained steps": 95104, "Timestamp in ms": 1700558553187, "logtype": "training_step"}
{"Avg objective": 22.35367187499999, "Games time in secs": 187.4488458931446, "Avg game time in secs": 1.2767308294714894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 47872, "Total num trained steps": 95214, "Timestamp in ms": 1700558610318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874572167960598, "Avg loss": 0.5031150465365499, "Avg value loss": 0.21820685791317374, "Avg policy loss": 0.2849081909516826, "Total num played games": 47916, "Total num trained steps": 95232, "Timestamp in ms": 1700558619168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881369360353598, "Avg loss": 0.5107122214976698, "Avg value loss": 0.22810749133350328, "Avg policy loss": 0.28260472987312824, "Total num played games": 47964, "Total num trained steps": 95360, "Timestamp in ms": 1700558685969, "logtype": "training_step"}
{"Avg objective": 20.778124999999996, "Games time in secs": 105.8706238437444, "Avg game time in secs": 1.1784917528566439, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 48000, "Total num trained steps": 95419, "Timestamp in ms": 1700558716189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988815296175956, "Avg loss": 0.5290650245733559, "Avg value loss": 0.2501215028751176, "Avg policy loss": 0.27894352038856596, "Total num played games": 48012, "Total num trained steps": 95488, "Timestamp in ms": 1700558750323, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875899056250779, "Avg loss": 0.6565733081661165, "Avg value loss": 0.3782371954875998, "Avg policy loss": 0.2783361116889864, "Total num played games": 48106, "Total num trained steps": 95616, "Timestamp in ms": 1700558813110, "logtype": "training_step"}
{"Total num played games": 48108, "Total num trained steps": 95662, "Timestamp in ms": 1700558888719, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.418359375}
{"Avg objective": 22.07468749999999, "Games time in secs": 174.27861632220447, "Avg game time in secs": 1.1568621726182755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 48128, "Total num trained steps": 95665, "Timestamp in ms": 1700558890468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881842345709777, "Avg loss": 0.6096373924519867, "Avg value loss": 0.32964259531581774, "Avg policy loss": 0.2799947945168242, "Total num played games": 48156, "Total num trained steps": 95744, "Timestamp in ms": 1700558932091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988859845655962, "Avg loss": 0.5371408271603286, "Avg value loss": 0.2582303085946478, "Avg policy loss": 0.27891051617916673, "Total num played games": 48204, "Total num trained steps": 95872, "Timestamp in ms": 1700558996897, "logtype": "training_step"}
{"Avg objective": 21.85953124999999, "Games time in secs": 170.72897075675428, "Avg game time in secs": 1.1897154628823046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.5}, "Total num played games": 48256, "Total num trained steps": 95999, "Timestamp in ms": 1700559061199, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989307472336193, "Avg loss": 0.5376458412501961, "Avg value loss": 0.2524223468499258, "Avg policy loss": 0.28522350010462105, "Total num played games": 48256, "Total num trained steps": 96000, "Timestamp in ms": 1700559061298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880666776968894, "Avg loss": 0.7608436970040202, "Avg value loss": 0.46964584913803264, "Avg policy loss": 0.2911978466436267, "Total num played games": 48352, "Total num trained steps": 96128, "Timestamp in ms": 1700559125216, "logtype": "training_step"}
{"Avg objective": 22.72945312499999, "Games time in secs": 98.2144182883203, "Avg game time in secs": 1.0880613627814455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 48384, "Total num trained steps": 96195, "Timestamp in ms": 1700559159414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887396694214876, "Avg loss": 0.5193706111749634, "Avg value loss": 0.2319007175974548, "Avg policy loss": 0.28746988938655704, "Total num played games": 48400, "Total num trained steps": 96256, "Timestamp in ms": 1700559190668, "logtype": "training_step"}
{"Total num played games": 48400, "Total num trained steps": 96264, "Timestamp in ms": 1700559251953, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.838125}
{"Ratio train steps to played games": 1.989431968295905, "Avg loss": 0.7192358423490077, "Avg value loss": 0.4226938358042389, "Avg policy loss": 0.2965420160908252, "Total num played games": 48448, "Total num trained steps": 96384, "Timestamp in ms": 1700559311829, "logtype": "training_step"}
{"Avg objective": 22.185624999999987, "Games time in secs": 208.24639917351305, "Avg game time in secs": 1.212672742360155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 48512, "Total num trained steps": 96490, "Timestamp in ms": 1700559367661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987950070033781, "Avg loss": 0.5121544918511063, "Avg value loss": 0.2313281180395279, "Avg policy loss": 0.2808263733750209, "Total num played games": 48548, "Total num trained steps": 96512, "Timestamp in ms": 1700559379241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988600119348931, "Avg loss": 0.8159976725000888, "Avg value loss": 0.526509961229749, "Avg policy loss": 0.2894877053331584, "Total num played games": 48597, "Total num trained steps": 96640, "Timestamp in ms": 1700559450212, "logtype": "training_step"}
{"Avg objective": 20.784296874999985, "Games time in secs": 106.98196502029896, "Avg game time in secs": 1.3006011143297656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.62}, "Total num played games": 48640, "Total num trained steps": 96689, "Timestamp in ms": 1700559474643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892486380923013, "Avg loss": 0.6277791238389909, "Avg value loss": 0.3359192023635842, "Avg policy loss": 0.2918599194381386, "Total num played games": 48645, "Total num trained steps": 96768, "Timestamp in ms": 1700559515485, "logtype": "training_step"}
{"Total num played games": 48695, "Total num trained steps": 96867, "Timestamp in ms": 1700559631943, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.980859375}
{"Ratio train steps to played games": 1.9878751820774265, "Avg loss": 0.5782250582706183, "Avg value loss": 0.29638083040481433, "Avg policy loss": 0.2818442205898464, "Total num played games": 48743, "Total num trained steps": 96896, "Timestamp in ms": 1700559645761, "logtype": "training_step"}
{"Avg objective": 20.868515624999993, "Games time in secs": 211.9904419258237, "Avg game time in secs": 1.228836362453876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.5, "agent_stopped_0": 0.6}, "Total num played games": 48768, "Total num trained steps": 96977, "Timestamp in ms": 1700559686633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884207074640325, "Avg loss": 0.5428970464272425, "Avg value loss": 0.27435151929967105, "Avg policy loss": 0.2685455254977569, "Total num played games": 48794, "Total num trained steps": 97024, "Timestamp in ms": 1700559710235, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890872609639245, "Avg loss": 0.43445454631000757, "Avg value loss": 0.17658057220978662, "Avg policy loss": 0.2578739724121988, "Total num played games": 48842, "Total num trained steps": 97152, "Timestamp in ms": 1700559776424, "logtype": "training_step"}
{"Avg objective": 21.931406249999988, "Games time in secs": 147.91567099280655, "Avg game time in secs": 1.2499990391079336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 48896, "Total num trained steps": 97272, "Timestamp in ms": 1700559834549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876790421119306, "Avg loss": 0.510451422072947, "Avg value loss": 0.25346771522890776, "Avg policy loss": 0.25698370777536184, "Total num played games": 48941, "Total num trained steps": 97280, "Timestamp in ms": 1700559838127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883443221947785, "Avg loss": 0.5334598682820797, "Avg value loss": 0.2632879031880293, "Avg policy loss": 0.2701719638425857, "Total num played games": 48989, "Total num trained steps": 97408, "Timestamp in ms": 1700559902715, "logtype": "training_step"}
{"Avg objective": 20.84109374999999, "Games time in secs": 97.38929169252515, "Avg game time in secs": 1.0329720666341018, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.35}, "Total num played games": 49024, "Total num trained steps": 97470, "Timestamp in ms": 1700559931939, "logtype": "played_game"}
{"Total num played games": 49037, "Total num trained steps": 97471, "Timestamp in ms": 1700560003812, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6707421875}
{"Ratio train steps to played games": 1.9870632576143425, "Avg loss": 0.743668076931499, "Avg value loss": 0.48072255769511685, "Avg policy loss": 0.2629455113783479, "Total num played games": 49085, "Total num trained steps": 97536, "Timestamp in ms": 1700560036853, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879093814244133, "Avg loss": 0.34406127338297665, "Avg value loss": 0.09541550430003554, "Avg policy loss": 0.2486457700142637, "Total num played games": 49129, "Total num trained steps": 97664, "Timestamp in ms": 1700560102748, "logtype": "training_step"}
{"Avg objective": 21.15781249999999, "Games time in secs": 215.01893147453666, "Avg game time in secs": 1.074759335431736, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.42, "agent_stopped_0": 0.61}, "Total num played games": 49152, "Total num trained steps": 97757, "Timestamp in ms": 1700560146958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883697287625555, "Avg loss": 0.602100623305887, "Avg value loss": 0.3480293753091246, "Avg policy loss": 0.2540712490445003, "Total num played games": 49182, "Total num trained steps": 97792, "Timestamp in ms": 1700560163517, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890107657932155, "Avg loss": 0.5672492980957031, "Avg value loss": 0.3055355313408654, "Avg policy loss": 0.26171376020647585, "Total num played games": 49230, "Total num trained steps": 97920, "Timestamp in ms": 1700560227916, "logtype": "training_step"}
{"Avg objective": 21.126718749999988, "Games time in secs": 146.86149666644633, "Avg game time in secs": 1.2089317061909242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.5, "agent_stopped_0": 0.56}, "Total num played games": 49280, "Total num trained steps": 98046, "Timestamp in ms": 1700560293820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882789528116318, "Avg loss": 0.43976752017624676, "Avg value loss": 0.19465817636228167, "Avg policy loss": 0.24510934040881693, "Total num played games": 49312, "Total num trained steps": 98048, "Timestamp in ms": 1700560294724, "logtype": "training_step"}
{"Total num played games": 49326, "Total num trained steps": 98073, "Timestamp in ms": 1700560360821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.260859375}
{"Ratio train steps to played games": 1.9883947016648438, "Avg loss": 0.8861388911027461, "Avg value loss": 0.6169213874964043, "Avg policy loss": 0.2692175079137087, "Total num played games": 49374, "Total num trained steps": 98176, "Timestamp in ms": 1700560409450, "logtype": "training_step"}
{"Avg objective": 21.485312499999992, "Games time in secs": 145.71405734494328, "Avg game time in secs": 1.1458697997586569, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.45}, "Total num played games": 49408, "Total num trained steps": 98239, "Timestamp in ms": 1700560439534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989013212471926, "Avg loss": 0.4966447870247066, "Avg value loss": 0.25552047506789677, "Avg policy loss": 0.24112431367393583, "Total num played games": 49423, "Total num trained steps": 98304, "Timestamp in ms": 1700560469443, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895702793386425, "Avg loss": 0.4987474981462583, "Avg value loss": 0.24841998404008336, "Avg policy loss": 0.25032752100378275, "Total num played games": 49471, "Total num trained steps": 98432, "Timestamp in ms": 1700560529145, "logtype": "training_step"}
{"Avg objective": 22.27296874999999, "Games time in secs": 136.52083082683384, "Avg game time in secs": 1.0471787286660401, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 49536, "Total num trained steps": 98530, "Timestamp in ms": 1700560576055, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882592644893184, "Avg loss": 0.7500225601252168, "Avg value loss": 0.49956026740255766, "Avg policy loss": 0.25046228675637394, "Total num played games": 49571, "Total num trained steps": 98560, "Timestamp in ms": 1700560589528, "logtype": "training_step"}
{"Total num played games": 49619, "Total num trained steps": 98677, "Timestamp in ms": 1700560703576, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.838789062500002}
{"Avg objective": 20.72265624999999, "Games time in secs": 131.08992176875472, "Avg game time in secs": 1.1249002515833126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 49664, "Total num trained steps": 98684, "Timestamp in ms": 1700560707145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870132484999798, "Avg loss": 0.5565209349151701, "Avg value loss": 0.2996162122581154, "Avg policy loss": 0.2569047217257321, "Total num played games": 49666, "Total num trained steps": 98688, "Timestamp in ms": 1700560708632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989570539795035, "Avg loss": 0.4713367371587083, "Avg value loss": 0.21848900016630068, "Avg policy loss": 0.2528477405430749, "Total num played games": 49667, "Total num trained steps": 98816, "Timestamp in ms": 1700560765495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882246558826484, "Avg loss": 0.5573440814623609, "Avg value loss": 0.29729565963498317, "Avg policy loss": 0.2600484226131812, "Total num played games": 49765, "Total num trained steps": 98944, "Timestamp in ms": 1700560823977, "logtype": "training_step"}
{"Avg objective": 21.115234374999993, "Games time in secs": 152.7603247575462, "Avg game time in secs": 1.0608708696527174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.41, "agent_stopped_0": 0.66}, "Total num played games": 49792, "Total num trained steps": 99021, "Timestamp in ms": 1700560859905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988878405235581, "Avg loss": 0.4849062745925039, "Avg value loss": 0.22184884836315177, "Avg policy loss": 0.2630574263166636, "Total num played games": 49813, "Total num trained steps": 99072, "Timestamp in ms": 1700560882656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989510840135577, "Avg loss": 0.5451556383632123, "Avg value loss": 0.27926329887122847, "Avg policy loss": 0.26589233672712, "Total num played games": 49861, "Total num trained steps": 99200, "Timestamp in ms": 1700560942459, "logtype": "training_step"}
{"Total num played games": 49909, "Total num trained steps": 99281, "Timestamp in ms": 1700561047121, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1812109375}
{"Avg objective": 22.263281249999984, "Games time in secs": 188.70026664994657, "Avg game time in secs": 1.1258061093685683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 49920, "Total num trained steps": 99283, "Timestamp in ms": 1700561048608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882498949096223, "Avg loss": 0.5942308374214917, "Avg value loss": 0.3308791990566533, "Avg policy loss": 0.2633516404312104, "Total num played games": 49957, "Total num trained steps": 99328, "Timestamp in ms": 1700561069184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988901109889011, "Avg loss": 0.5046274296473712, "Avg value loss": 0.24631146376486868, "Avg policy loss": 0.25831597053911537, "Total num played games": 50005, "Total num trained steps": 99456, "Timestamp in ms": 1700561131446, "logtype": "training_step"}
{"Avg objective": 21.21953124999999, "Games time in secs": 106.14236434362829, "Avg game time in secs": 1.0968282165122218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 50048, "Total num trained steps": 99502, "Timestamp in ms": 1700561154751, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989551075859589, "Avg loss": 0.6262414176017046, "Avg value loss": 0.36228910108911805, "Avg policy loss": 0.2639523168327287, "Total num played games": 50053, "Total num trained steps": 99584, "Timestamp in ms": 1700561194857, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882552342971087, "Avg loss": 0.8631199195515364, "Avg value loss": 0.6071959125983994, "Avg policy loss": 0.2559240056434646, "Total num played games": 50150, "Total num trained steps": 99712, "Timestamp in ms": 1700561259722, "logtype": "training_step"}
{"Avg objective": 21.89296874999999, "Games time in secs": 143.6932855732739, "Avg game time in secs": 1.0995482416328741, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.43, "agent_stopped_0": 0.62}, "Total num played games": 50176, "Total num trained steps": 99790, "Timestamp in ms": 1700561298444, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889238615084266, "Avg loss": 0.662195451091975, "Avg value loss": 0.3889520489028655, "Avg policy loss": 0.27324340061750263, "Total num played games": 50198, "Total num trained steps": 99840, "Timestamp in ms": 1700561321433, "logtype": "training_step"}
{"Total num played games": 50199, "Total num trained steps": 99885, "Timestamp in ms": 1700561437460, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.370078125}
{"Ratio train steps to played games": 1.9895118116504469, "Avg loss": 0.5325973564758897, "Avg value loss": 0.26959712750976905, "Avg policy loss": 0.26300023356452584, "Total num played games": 50247, "Total num trained steps": 99968, "Timestamp in ms": 1700561477565, "logtype": "training_step"}
{"Avg objective": 21.525937499999994, "Games time in secs": 231.06876952759922, "Avg game time in secs": 1.0902275589178316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.51, "agent_stopped_0": 0.59}, "Total num played games": 50304, "Total num trained steps": 100080, "Timestamp in ms": 1700561529513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882605327453668, "Avg loss": 0.8574423629324883, "Avg value loss": 0.5815058002190199, "Avg policy loss": 0.27593655441887677, "Total num played games": 50343, "Total num trained steps": 100096, "Timestamp in ms": 1700561536292, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988906749221091, "Avg loss": 0.5660769492387772, "Avg value loss": 0.30405157650238834, "Avg policy loss": 0.2620253722416237, "Total num played games": 50391, "Total num trained steps": 100224, "Timestamp in ms": 1700561595833, "logtype": "training_step"}
{"Avg objective": 21.59218749999999, "Games time in secs": 89.18001864105463, "Avg game time in secs": 1.0398222807125421, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 50432, "Total num trained steps": 100274, "Timestamp in ms": 1700561618693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989571561688376, "Avg loss": 0.5206795365083963, "Avg value loss": 0.25252440123585984, "Avg policy loss": 0.2681551253190264, "Total num played games": 50439, "Total num trained steps": 100352, "Timestamp in ms": 1700561654295, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883051350549124, "Avg loss": 0.5920563226100057, "Avg value loss": 0.32031483424361795, "Avg policy loss": 0.2717414799844846, "Total num played games": 50535, "Total num trained steps": 100480, "Timestamp in ms": 1700561711750, "logtype": "training_step"}
{"Total num played games": 50535, "Total num trained steps": 100488, "Timestamp in ms": 1700561782695, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3834765625}
{"Avg objective": 21.55281249999999, "Games time in secs": 165.68258836120367, "Avg game time in secs": 1.0695308086578734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.43, "agent_stopped_0": 0.63}, "Total num played games": 50560, "Total num trained steps": 100490, "Timestamp in ms": 1700561784376, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889488563351323, "Avg loss": 0.6602239378262311, "Avg value loss": 0.3853394645266235, "Avg policy loss": 0.27488447772338986, "Total num played games": 50583, "Total num trained steps": 100608, "Timestamp in ms": 1700561840467, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895127683526554, "Avg loss": 0.44945699092932045, "Avg value loss": 0.19057375538977794, "Avg policy loss": 0.25888323376420885, "Total num played games": 50633, "Total num trained steps": 100736, "Timestamp in ms": 1700561899269, "logtype": "training_step"}
{"Avg objective": 21.476328124999988, "Games time in secs": 167.42490238510072, "Avg game time in secs": 1.05806942115305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.42}, "Total num played games": 50688, "Total num trained steps": 100852, "Timestamp in ms": 1700561951801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882710086932525, "Avg loss": 0.6370018777670339, "Avg value loss": 0.3784074134018738, "Avg policy loss": 0.25859446497634053, "Total num played games": 50729, "Total num trained steps": 100864, "Timestamp in ms": 1700561957121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888731340344243, "Avg loss": 0.6743035197723657, "Avg value loss": 0.407686852326151, "Avg policy loss": 0.26661665993742645, "Total num played games": 50778, "Total num trained steps": 100992, "Timestamp in ms": 1700562016789, "logtype": "training_step"}
{"Avg objective": 21.54999999999999, "Games time in secs": 91.19285967759788, "Avg game time in secs": 1.040614224912133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 50816, "Total num trained steps": 101047, "Timestamp in ms": 1700562042994, "logtype": "played_game"}
{"Total num played games": 50826, "Total num trained steps": 101091, "Timestamp in ms": 1700562140330, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.696328125}
{"Ratio train steps to played games": 1.98765577701773, "Avg loss": 0.8494552165502682, "Avg value loss": 0.5885331235767808, "Avg policy loss": 0.2609221017919481, "Total num played games": 50874, "Total num trained steps": 101120, "Timestamp in ms": 1700562155117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880225411847867, "Avg loss": 0.47127193165943027, "Avg value loss": 0.21420709288213402, "Avg policy loss": 0.2570648373803124, "Total num played games": 50929, "Total num trained steps": 101248, "Timestamp in ms": 1700562214768, "logtype": "training_step"}
{"Avg objective": 21.835703124999988, "Games time in secs": 219.40769427642226, "Avg game time in secs": 1.0729513485421194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.46, "agent_stopped_0": 0.61}, "Total num played games": 50944, "Total num trained steps": 101348, "Timestamp in ms": 1700562262402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885249117300903, "Avg loss": 0.7330709926318377, "Avg value loss": 0.47943231277167797, "Avg policy loss": 0.253638674155809, "Total num played games": 50980, "Total num trained steps": 101376, "Timestamp in ms": 1700562275791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989162812573489, "Avg loss": 0.5299030061578378, "Avg value loss": 0.2667823183001019, "Avg policy loss": 0.2631206886144355, "Total num played games": 51028, "Total num trained steps": 101504, "Timestamp in ms": 1700562334535, "logtype": "training_step"}
{"Avg objective": 21.905781249999993, "Games time in secs": 94.01776649989188, "Avg game time in secs": 1.077870885419543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.52}, "Total num played games": 51072, "Total num trained steps": 101549, "Timestamp in ms": 1700562356420, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897995144490563, "Avg loss": 0.5497608688892797, "Avg value loss": 0.295275250216946, "Avg policy loss": 0.25448561389930546, "Total num played games": 51076, "Total num trained steps": 101632, "Timestamp in ms": 1700562396734, "logtype": "training_step"}
{"Total num played games": 51124, "Total num trained steps": 101694, "Timestamp in ms": 1700562507473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.771796875}
{"Ratio train steps to played games": 1.9885679668568748, "Avg loss": 0.7567829668987542, "Avg value loss": 0.49502123045385815, "Avg policy loss": 0.26176173717249185, "Total num played games": 51172, "Total num trained steps": 101760, "Timestamp in ms": 1700562536581, "logtype": "training_step"}
{"Avg objective": 21.778671874999993, "Games time in secs": 216.47746035084128, "Avg game time in secs": 1.0116603950446006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.41, "agent_stopped_0": 0.65}, "Total num played games": 51200, "Total num trained steps": 101835, "Timestamp in ms": 1700562572897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892034361577509, "Avg loss": 0.4643719602609053, "Avg value loss": 0.21457334121805616, "Avg policy loss": 0.24979861988686025, "Total num played games": 51220, "Total num trained steps": 101888, "Timestamp in ms": 1700562598057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897989038210224, "Avg loss": 0.4557616766542196, "Avg value loss": 0.20834034663857892, "Avg policy loss": 0.24742133100517094, "Total num played games": 51269, "Total num trained steps": 102016, "Timestamp in ms": 1700562657893, "logtype": "training_step"}
{"Avg objective": 21.97499999999999, "Games time in secs": 135.26818906515837, "Avg game time in secs": 1.139768240172998, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 51328, "Total num trained steps": 102126, "Timestamp in ms": 1700562708166, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885332710353152, "Avg loss": 0.7044320446439087, "Avg value loss": 0.45214021622086875, "Avg policy loss": 0.25229182303883135, "Total num played games": 51366, "Total num trained steps": 102144, "Timestamp in ms": 1700562716159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891663749173376, "Avg loss": 0.4785857571987435, "Avg value loss": 0.23795918209361844, "Avg policy loss": 0.24062657984904945, "Total num played games": 51414, "Total num trained steps": 102272, "Timestamp in ms": 1700562773944, "logtype": "training_step"}
{"Total num played games": 51414, "Total num trained steps": 102297, "Timestamp in ms": 1700562825071, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2780078125}
{"Avg objective": 20.686328124999985, "Games time in secs": 119.2119481805712, "Avg game time in secs": 1.0536201831273502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 51456, "Total num trained steps": 102299, "Timestamp in ms": 1700562827378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898177295868797, "Avg loss": 0.4792241679970175, "Avg value loss": 0.2283467411471065, "Avg policy loss": 0.25087742845062166, "Total num played games": 51462, "Total num trained steps": 102400, "Timestamp in ms": 1700562874539, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881517966220017, "Avg loss": 0.5333250657422468, "Avg value loss": 0.27805907104630023, "Avg policy loss": 0.2552659997018054, "Total num played games": 51569, "Total num trained steps": 102528, "Timestamp in ms": 1700562932003, "logtype": "training_step"}
{"Avg objective": 20.970312499999988, "Games time in secs": 151.04413977265358, "Avg game time in secs": 1.0091078131226823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 51584, "Total num trained steps": 102628, "Timestamp in ms": 1700562978422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988744236506645, "Avg loss": 0.6847023075679317, "Avg value loss": 0.4257114472857211, "Avg policy loss": 0.2589908574009314, "Total num played games": 51618, "Total num trained steps": 102656, "Timestamp in ms": 1700562990651, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989374056439438, "Avg loss": 0.4791335118934512, "Avg value loss": 0.22407171683153138, "Avg policy loss": 0.2550617960514501, "Total num played games": 51666, "Total num trained steps": 102784, "Timestamp in ms": 1700563049493, "logtype": "training_step"}
{"Avg objective": 21.48093749999999, "Games time in secs": 90.49756849743426, "Avg game time in secs": 0.9787217707635136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 51712, "Total num trained steps": 102825, "Timestamp in ms": 1700563068920, "logtype": "played_game"}
{"Total num played games": 51714, "Total num trained steps": 102899, "Timestamp in ms": 1700563120631, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.000195312500004}
{"Ratio train steps to played games": 1.9881573354970827, "Avg loss": 0.5822694378439337, "Avg value loss": 0.3329068627790548, "Avg policy loss": 0.2493625800125301, "Total num played games": 51762, "Total num trained steps": 102912, "Timestamp in ms": 1700563126705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887859486585602, "Avg loss": 0.49840878846589476, "Avg value loss": 0.24551872757729143, "Avg policy loss": 0.25289006414823234, "Total num played games": 51810, "Total num trained steps": 103040, "Timestamp in ms": 1700563191782, "logtype": "training_step"}
{"Avg objective": 21.52468749999999, "Games time in secs": 157.78494872897863, "Avg game time in secs": 0.9921074130688794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.42, "agent_stopped_0": 0.65}, "Total num played games": 51840, "Total num trained steps": 103111, "Timestamp in ms": 1700563226705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894133981256508, "Avg loss": 0.5099253327352926, "Avg value loss": 0.26075257326010615, "Avg policy loss": 0.24917275633197278, "Total num played games": 51858, "Total num trained steps": 103168, "Timestamp in ms": 1700563253201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900589527222285, "Avg loss": 0.5363410722929984, "Avg value loss": 0.2898138032469433, "Avg policy loss": 0.2465272662229836, "Total num played games": 51906, "Total num trained steps": 103296, "Timestamp in ms": 1700563312118, "logtype": "training_step"}
{"Avg objective": 21.834453124999982, "Games time in secs": 132.7239939570427, "Avg game time in secs": 1.0614774459827458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 51968, "Total num trained steps": 103400, "Timestamp in ms": 1700563359429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988789108320674, "Avg loss": 0.5540634356439114, "Avg value loss": 0.3106254003942013, "Avg policy loss": 0.24343803094234318, "Total num played games": 52003, "Total num trained steps": 103424, "Timestamp in ms": 1700563370125, "logtype": "training_step"}
{"Total num played games": 52051, "Total num trained steps": 103499, "Timestamp in ms": 1700563432394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.121484375}
{"Avg objective": 20.896249999999995, "Games time in secs": 75.93261447548866, "Avg game time in secs": 1.039998333362746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 52096, "Total num trained steps": 103505, "Timestamp in ms": 1700563435362, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987600529760648, "Avg loss": 0.627814305247739, "Avg value loss": 0.376007012440823, "Avg policy loss": 0.25180729350540787, "Total num played games": 52099, "Total num trained steps": 103552, "Timestamp in ms": 1700563456999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900381965104896, "Avg loss": 0.32592417241539806, "Avg value loss": 0.08016185546875931, "Avg policy loss": 0.24576231604442, "Total num played games": 52099, "Total num trained steps": 103680, "Timestamp in ms": 1700563519310, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888303477344573, "Avg loss": 0.622777920216322, "Avg value loss": 0.36002405994804576, "Avg policy loss": 0.2627538637025282, "Total num played games": 52195, "Total num trained steps": 103808, "Timestamp in ms": 1700563578070, "logtype": "training_step"}
{"Avg objective": 19.97632812499999, "Games time in secs": 175.3755258526653, "Avg game time in secs": 0.9262181940866867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.39, "agent_stopped_0": 0.66}, "Total num played games": 52224, "Total num trained steps": 103881, "Timestamp in ms": 1700563610737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894531324770783, "Avg loss": 0.48392236593645066, "Avg value loss": 0.23606339399702847, "Avg policy loss": 0.2478589693782851, "Total num played games": 52243, "Total num trained steps": 103936, "Timestamp in ms": 1700563634870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900747738616589, "Avg loss": 0.5251112747937441, "Avg value loss": 0.2733097413147334, "Avg policy loss": 0.25180153269320726, "Total num played games": 52291, "Total num trained steps": 104064, "Timestamp in ms": 1700563693093, "logtype": "training_step"}
{"Total num played games": 52339, "Total num trained steps": 104103, "Timestamp in ms": 1700563777187, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.107343750000002}
{"Avg objective": 22.27265624999999, "Games time in secs": 167.7057111095637, "Avg game time in secs": 1.0633882003021426, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 52352, "Total num trained steps": 104103, "Timestamp in ms": 1700563778443, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988871284860748, "Avg loss": 0.8748720730654895, "Avg value loss": 0.6091900120372884, "Avg policy loss": 0.26568206469528377, "Total num played games": 52387, "Total num trained steps": 104192, "Timestamp in ms": 1700563819396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894917516925719, "Avg loss": 0.4341018971754238, "Avg value loss": 0.19362513688975014, "Avg policy loss": 0.24047675973270088, "Total num played games": 52435, "Total num trained steps": 104320, "Timestamp in ms": 1700563878212, "logtype": "training_step"}
{"Avg objective": 21.41023437499999, "Games time in secs": 120.38853831961751, "Avg game time in secs": 0.9946221997379325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 52480, "Total num trained steps": 104362, "Timestamp in ms": 1700563898832, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901110835889717, "Avg loss": 0.7533418734092265, "Avg value loss": 0.509616397350328, "Avg policy loss": 0.2437254685210064, "Total num played games": 52483, "Total num trained steps": 104448, "Timestamp in ms": 1700563936854, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988911923011088, "Avg loss": 0.648016186314635, "Avg value loss": 0.39902378161787055, "Avg policy loss": 0.24899240350350738, "Total num played games": 52579, "Total num trained steps": 104576, "Timestamp in ms": 1700563998570, "logtype": "training_step"}
{"Avg objective": 21.78968749999999, "Games time in secs": 133.58938403055072, "Avg game time in secs": 1.049187911223271, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.44, "agent_stopped_0": 0.63}, "Total num played games": 52608, "Total num trained steps": 104649, "Timestamp in ms": 1700564032422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895300891177532, "Avg loss": 0.721990832593292, "Avg value loss": 0.45901738142129034, "Avg policy loss": 0.26297345175407827, "Total num played games": 52627, "Total num trained steps": 104704, "Timestamp in ms": 1700564059927, "logtype": "training_step"}
{"Total num played games": 52627, "Total num trained steps": 104704, "Timestamp in ms": 1700564088168, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9266796875}
{"Ratio train steps to played games": 1.9901471286188894, "Avg loss": 0.4921651578042656, "Avg value loss": 0.23705621616682038, "Avg policy loss": 0.2551089443732053, "Total num played games": 52675, "Total num trained steps": 104832, "Timestamp in ms": 1700564148337, "logtype": "training_step"}
{"Avg objective": 23.199218749999996, "Games time in secs": 162.32792065665126, "Avg game time in secs": 0.9575348977232352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.41, "agent_stopped_0": 0.6}, "Total num played games": 52736, "Total num trained steps": 104936, "Timestamp in ms": 1700564194750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988952265448826, "Avg loss": 0.7541927713900805, "Avg value loss": 0.4991208079154603, "Avg policy loss": 0.25507196865510195, "Total num played games": 52771, "Total num trained steps": 104960, "Timestamp in ms": 1700564205969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895870804066718, "Avg loss": 0.484455511206761, "Avg value loss": 0.24392633064417168, "Avg policy loss": 0.24052917736116797, "Total num played games": 52819, "Total num trained steps": 105088, "Timestamp in ms": 1700564265624, "logtype": "training_step"}
{"Avg objective": 21.385937499999986, "Games time in secs": 90.95892681181431, "Avg game time in secs": 0.980489109075279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 52864, "Total num trained steps": 105131, "Timestamp in ms": 1700564285709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901829118353604, "Avg loss": 0.4439535610144958, "Avg value loss": 0.2009743312955834, "Avg policy loss": 0.24297923024278134, "Total num played games": 52867, "Total num trained steps": 105216, "Timestamp in ms": 1700564324173, "logtype": "training_step"}
{"Total num played games": 52915, "Total num trained steps": 105304, "Timestamp in ms": 1700564462257, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.235234375}
{"Ratio train steps to played games": 1.9890111964956667, "Avg loss": 0.5985271922545508, "Avg value loss": 0.3440261856885627, "Avg policy loss": 0.2545010120375082, "Total num played games": 52963, "Total num trained steps": 105344, "Timestamp in ms": 1700564479849, "logtype": "training_step"}
{"Avg objective": 21.36546874999999, "Games time in secs": 227.0014855377376, "Avg game time in secs": 0.9999103137088241, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 52992, "Total num trained steps": 105416, "Timestamp in ms": 1700564512710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896247948538983, "Avg loss": 0.43977705377619714, "Avg value loss": 0.18448741154861636, "Avg policy loss": 0.2552896470297128, "Total num played games": 53011, "Total num trained steps": 105472, "Timestamp in ms": 1700564538703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901809272521673, "Avg loss": 0.4720551064237952, "Avg value loss": 0.22684958481113426, "Avg policy loss": 0.24520552693866193, "Total num played games": 53060, "Total num trained steps": 105600, "Timestamp in ms": 1700564595878, "logtype": "training_step"}
{"Avg objective": 21.86929687499999, "Games time in secs": 139.00697355531156, "Avg game time in secs": 0.9726858466747217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 53120, "Total num trained steps": 105712, "Timestamp in ms": 1700564651718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888824093756468, "Avg loss": 0.5959225274855271, "Avg value loss": 0.35056008168612607, "Avg policy loss": 0.24536244466435164, "Total num played games": 53159, "Total num trained steps": 105728, "Timestamp in ms": 1700564659397, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894938635893773, "Avg loss": 0.6109541004989296, "Avg value loss": 0.35790296539198607, "Avg policy loss": 0.2530511332442984, "Total num played games": 53207, "Total num trained steps": 105856, "Timestamp in ms": 1700564716830, "logtype": "training_step"}
{"Avg objective": 21.266406249999992, "Games time in secs": 86.95532011799514, "Avg game time in secs": 0.9425234048685525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 53248, "Total num trained steps": 105906, "Timestamp in ms": 1700564738673, "logtype": "played_game"}
{"Total num played games": 53255, "Total num trained steps": 105907, "Timestamp in ms": 1700564789479, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.076992187500004}
{"Ratio train steps to played games": 1.9883121025083017, "Avg loss": 0.6255477212835103, "Avg value loss": 0.3770969770557713, "Avg policy loss": 0.24845074978657067, "Total num played games": 53303, "Total num trained steps": 105984, "Timestamp in ms": 1700564825847, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886987649230654, "Avg loss": 0.41392503038514405, "Avg value loss": 0.17564458725973964, "Avg policy loss": 0.23828044207766652, "Total num played games": 53357, "Total num trained steps": 106112, "Timestamp in ms": 1700564886289, "logtype": "training_step"}
{"Avg objective": 20.77890624999999, "Games time in secs": 189.37471670471132, "Avg game time in secs": 0.9273088013578672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.37, "agent_stopped_0": 0.66}, "Total num played games": 53376, "Total num trained steps": 106204, "Timestamp in ms": 1700564928048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892895929296335, "Avg loss": 0.41818480601068586, "Avg value loss": 0.17506863476592116, "Avg policy loss": 0.24311617435887456, "Total num played games": 53406, "Total num trained steps": 106240, "Timestamp in ms": 1700564944727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898978561005725, "Avg loss": 0.542652317439206, "Avg value loss": 0.3063868935278151, "Avg policy loss": 0.23626542650163174, "Total num played games": 53454, "Total num trained steps": 106368, "Timestamp in ms": 1700565003372, "logtype": "training_step"}
{"Avg objective": 21.259999999999987, "Games time in secs": 133.98535939492285, "Avg game time in secs": 1.0363282442558557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 53504, "Total num trained steps": 106495, "Timestamp in ms": 1700565062033, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902446317441926, "Avg loss": 0.5835793029982597, "Avg value loss": 0.33910588893922977, "Avg policy loss": 0.24447341298218817, "Total num played games": 53504, "Total num trained steps": 106496, "Timestamp in ms": 1700565062110, "logtype": "training_step"}
{"Total num played games": 53551, "Total num trained steps": 106507, "Timestamp in ms": 1700565128402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4484765625}
{"Ratio train steps to played games": 1.989290844978451, "Avg loss": 0.6103709321469069, "Avg value loss": 0.3612635408062488, "Avg policy loss": 0.2491073909914121, "Total num played games": 53599, "Total num trained steps": 106624, "Timestamp in ms": 1700565182441, "logtype": "training_step"}
{"Avg objective": 21.02859374999999, "Games time in secs": 150.03646032325923, "Avg game time in secs": 0.8634235892241122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.31}, "Total num played games": 53632, "Total num trained steps": 106690, "Timestamp in ms": 1700565212070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896557508433825, "Avg loss": 0.4942174553871155, "Avg value loss": 0.25151509686838835, "Avg policy loss": 0.24270235444419086, "Total num played games": 53653, "Total num trained steps": 106752, "Timestamp in ms": 1700565242166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897978180735003, "Avg loss": 0.4886247518006712, "Avg value loss": 0.2369588839064818, "Avg policy loss": 0.2516658684471622, "Total num played games": 53714, "Total num trained steps": 106880, "Timestamp in ms": 1700565300289, "logtype": "training_step"}
{"Avg objective": 20.455156249999987, "Games time in secs": 106.5477871671319, "Avg game time in secs": 1.0521133517613634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 53760, "Total num trained steps": 106920, "Timestamp in ms": 1700565318618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990383542278933, "Avg loss": 0.40847537526860833, "Avg value loss": 0.16470871702767909, "Avg policy loss": 0.24376665684394538, "Total num played games": 53762, "Total num trained steps": 107008, "Timestamp in ms": 1700565359573, "logtype": "training_step"}
{"Total num played games": 53810, "Total num trained steps": 107107, "Timestamp in ms": 1700565478064, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.87140625}
{"Ratio train steps to played games": 1.9892309406216346, "Avg loss": 0.6380558565724641, "Avg value loss": 0.3907458074972965, "Avg policy loss": 0.24731004028581083, "Total num played games": 53858, "Total num trained steps": 107136, "Timestamp in ms": 1700565491400, "logtype": "training_step"}
{"Avg objective": 21.777109374999995, "Games time in secs": 205.49697220511734, "Avg game time in secs": 0.8697782394883689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.37, "agent_stopped_0": 0.66}, "Total num played games": 53888, "Total num trained steps": 107206, "Timestamp in ms": 1700565524115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897786929341272, "Avg loss": 0.5546655410435051, "Avg value loss": 0.30092715242062695, "Avg policy loss": 0.2537383856251836, "Total num played games": 53907, "Total num trained steps": 107264, "Timestamp in ms": 1700565550151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990362517606939, "Avg loss": 0.44361991656478494, "Avg value loss": 0.20558551547583193, "Avg policy loss": 0.238034397829324, "Total num played games": 53956, "Total num trained steps": 107392, "Timestamp in ms": 1700565608715, "logtype": "training_step"}
{"Avg objective": 21.10937499999999, "Games time in secs": 133.31052548065782, "Avg game time in secs": 0.9280158206092892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.44, "agent_stopped_0": 0.59}, "Total num played games": 54016, "Total num trained steps": 107498, "Timestamp in ms": 1700565657426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891770887293718, "Avg loss": 0.5154445269145072, "Avg value loss": 0.28090040184906684, "Avg policy loss": 0.23454413609579206, "Total num played games": 54052, "Total num trained steps": 107520, "Timestamp in ms": 1700565667242, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897781885397412, "Avg loss": 0.48192884982563555, "Avg value loss": 0.23895749368239194, "Avg policy loss": 0.24297135486267507, "Total num played games": 54100, "Total num trained steps": 107648, "Timestamp in ms": 1700565725938, "logtype": "training_step"}
{"Avg objective": 21.034374999999994, "Games time in secs": 88.51472276821733, "Avg game time in secs": 0.9345542355440557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.4}, "Total num played games": 54144, "Total num trained steps": 107692, "Timestamp in ms": 1700565745941, "logtype": "played_game"}
{"Total num played games": 54148, "Total num trained steps": 107707, "Timestamp in ms": 1700565816191, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.020234375}
{"Ratio train steps to played games": 1.9886153959701822, "Avg loss": 0.7580607093404979, "Avg value loss": 0.5163150260341354, "Avg policy loss": 0.2417456831317395, "Total num played games": 54196, "Total num trained steps": 107776, "Timestamp in ms": 1700565849144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891787261498757, "Avg loss": 0.3746917996322736, "Avg value loss": 0.1441956706403289, "Avg policy loss": 0.23049612797331065, "Total num played games": 54245, "Total num trained steps": 107904, "Timestamp in ms": 1700565906851, "logtype": "training_step"}
{"Avg objective": 22.579687499999988, "Games time in secs": 196.08845739625394, "Avg game time in secs": 0.931317362759728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.33, "agent_stopped_0": 0.72}, "Total num played games": 54272, "Total num trained steps": 107980, "Timestamp in ms": 1700565942029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897961063120475, "Avg loss": 0.44941385521087795, "Avg value loss": 0.21669627996743657, "Avg policy loss": 0.2327175724785775, "Total num played games": 54293, "Total num trained steps": 108032, "Timestamp in ms": 1700565966412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903755911742516, "Avg loss": 0.4124239827506244, "Avg value loss": 0.18085118680028245, "Avg policy loss": 0.23157279437873513, "Total num played games": 54341, "Total num trained steps": 108160, "Timestamp in ms": 1700566026258, "logtype": "training_step"}
{"Avg objective": 20.78773437499998, "Games time in secs": 135.68350497819483, "Avg game time in secs": 0.9587540949432878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 54400, "Total num trained steps": 108268, "Timestamp in ms": 1700566077713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989180351960028, "Avg loss": 0.6575200469233096, "Avg value loss": 0.4169668185641058, "Avg policy loss": 0.2405532323755324, "Total num played games": 54438, "Total num trained steps": 108288, "Timestamp in ms": 1700566086816, "logtype": "training_step"}
{"Total num played games": 54438, "Total num trained steps": 108308, "Timestamp in ms": 1700566171750, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.713359375000003}
{"Ratio train steps to played games": 1.9897771904709467, "Avg loss": 0.9901797864586115, "Avg value loss": 0.73766787617933, "Avg policy loss": 0.25251191668212414, "Total num played games": 54486, "Total num trained steps": 108416, "Timestamp in ms": 1700566222054, "logtype": "training_step"}
{"Avg objective": 23.80781249999999, "Games time in secs": 166.32411247864366, "Avg game time in secs": 0.8515913157898467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 54528, "Total num trained steps": 108464, "Timestamp in ms": 1700566244037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903729783254482, "Avg loss": 0.5382905321894214, "Avg value loss": 0.30633021070389077, "Avg policy loss": 0.2319603303913027, "Total num played games": 54534, "Total num trained steps": 108544, "Timestamp in ms": 1700566281192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891819662828796, "Avg loss": 0.9136162691283971, "Avg value loss": 0.6703118860314135, "Avg policy loss": 0.2433043784694746, "Total num played games": 54631, "Total num trained steps": 108672, "Timestamp in ms": 1700566337600, "logtype": "training_step"}
{"Avg objective": 21.293984374999987, "Games time in secs": 131.02543044649065, "Avg game time in secs": 0.9204577658092603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 54656, "Total num trained steps": 108753, "Timestamp in ms": 1700566375063, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887946477534457, "Avg loss": 0.6535022736061364, "Avg value loss": 0.4160761962411925, "Avg policy loss": 0.23742606909945607, "Total num played games": 54706, "Total num trained steps": 108800, "Timestamp in ms": 1700566396551, "logtype": "training_step"}
{"Total num played games": 54758, "Total num trained steps": 108912, "Timestamp in ms": 1700566507919, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.316835937500002}
{"Avg objective": 21.46812499999999, "Games time in secs": 134.7311084792018, "Avg game time in secs": 0.9713652678037761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 54784, "Total num trained steps": 108916, "Timestamp in ms": 1700566509794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987501368463307, "Avg loss": 0.5702211712487042, "Avg value loss": 0.3461764352105092, "Avg policy loss": 0.2240447330987081, "Total num played games": 54806, "Total num trained steps": 108928, "Timestamp in ms": 1700566515058, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898551253512389, "Avg loss": 0.4318315911805257, "Avg value loss": 0.1955376132100355, "Avg policy loss": 0.2362939779413864, "Total num played games": 54806, "Total num trained steps": 109056, "Timestamp in ms": 1700566572984, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904291391694315, "Avg loss": 0.49244145723059773, "Avg value loss": 0.269137409835821, "Avg policy loss": 0.22330404934473336, "Total num played games": 54854, "Total num trained steps": 109184, "Timestamp in ms": 1700566630752, "logtype": "training_step"}
{"Avg objective": 21.627109374999986, "Games time in secs": 170.38366404920816, "Avg game time in secs": 0.9742776399943978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 54912, "Total num trained steps": 109294, "Timestamp in ms": 1700566680178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892811646951774, "Avg loss": 0.5908166753361002, "Avg value loss": 0.3525837632769253, "Avg policy loss": 0.2382329124957323, "Total num played games": 54950, "Total num trained steps": 109312, "Timestamp in ms": 1700566688029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898905414742354, "Avg loss": 0.5311942540574819, "Avg value loss": 0.2900830250000581, "Avg policy loss": 0.24111122591421008, "Total num played games": 54998, "Total num trained steps": 109440, "Timestamp in ms": 1700566747856, "logtype": "training_step"}
{"Avg objective": 21.67109374999999, "Games time in secs": 89.48318816162646, "Avg game time in secs": 0.9071156996651553, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.4}, "Total num played games": 55040, "Total num trained steps": 109488, "Timestamp in ms": 1700566769661, "logtype": "played_game"}
{"Total num played games": 55046, "Total num trained steps": 109513, "Timestamp in ms": 1700566846821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.96125}
{"Ratio train steps to played games": 1.988728355174792, "Avg loss": 0.6131683452986181, "Avg value loss": 0.3744151107093785, "Avg policy loss": 0.2387532329885289, "Total num played games": 55094, "Total num trained steps": 109568, "Timestamp in ms": 1700566872123, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893184868158573, "Avg loss": 0.44811436370946467, "Avg value loss": 0.2160511352994945, "Avg policy loss": 0.2320632232585922, "Total num played games": 55142, "Total num trained steps": 109696, "Timestamp in ms": 1700566931630, "logtype": "training_step"}
{"Avg objective": 21.14734374999999, "Games time in secs": 198.65142342075706, "Avg game time in secs": 0.8978578573151026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.36, "agent_stopped_0": 0.67}, "Total num played games": 55168, "Total num trained steps": 109774, "Timestamp in ms": 1700566968313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899257111795614, "Avg loss": 0.5856953328475356, "Avg value loss": 0.340469416230917, "Avg policy loss": 0.24522591556888074, "Total num played games": 55190, "Total num trained steps": 109824, "Timestamp in ms": 1700566991406, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904777421749127, "Avg loss": 0.49896404321771115, "Avg value loss": 0.2603391829470638, "Avg policy loss": 0.23862486041616648, "Total num played games": 55239, "Total num trained steps": 109952, "Timestamp in ms": 1700567051285, "logtype": "training_step"}
{"Avg objective": 22.28664062499999, "Games time in secs": 135.2460745126009, "Avg game time in secs": 0.9262161094520707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 55296, "Total num trained steps": 110066, "Timestamp in ms": 1700567103559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989283648980772, "Avg loss": 0.6181877206545323, "Avg value loss": 0.37672757636755705, "Avg policy loss": 0.24146014510188252, "Total num played games": 55336, "Total num trained steps": 110080, "Timestamp in ms": 1700567110114, "logtype": "training_step"}
{"Total num played games": 55336, "Total num trained steps": 110116, "Timestamp in ms": 1700567176108, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.231914062500003}
{"Ratio train steps to played games": 1.9898887765419615, "Avg loss": 0.7713291798718274, "Avg value loss": 0.5113548486842774, "Avg policy loss": 0.25997433019801974, "Total num played games": 55384, "Total num trained steps": 110208, "Timestamp in ms": 1700567221621, "logtype": "training_step"}
{"Avg objective": 21.73828124999999, "Games time in secs": 144.8976348247379, "Avg game time in secs": 0.9345211144245695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 55424, "Total num trained steps": 110259, "Timestamp in ms": 1700567248457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904748159907635, "Avg loss": 0.5473452227888629, "Avg value loss": 0.292319488391513, "Avg policy loss": 0.25502573139965534, "Total num played games": 55432, "Total num trained steps": 110336, "Timestamp in ms": 1700567285944, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892670628489104, "Avg loss": 0.5055503080366179, "Avg value loss": 0.2600651136308443, "Avg policy loss": 0.24548519786912948, "Total num played games": 55530, "Total num trained steps": 110464, "Timestamp in ms": 1700567351301, "logtype": "training_step"}
{"Avg objective": 21.274687499999995, "Games time in secs": 144.45643158629537, "Avg game time in secs": 0.9282871720934054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.3, "agent_stopped_0": 0.73}, "Total num played games": 55552, "Total num trained steps": 110550, "Timestamp in ms": 1700567392913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898341070207637, "Avg loss": 0.6133975172415376, "Avg value loss": 0.36497192695969716, "Avg policy loss": 0.24842558917589486, "Total num played games": 55578, "Total num trained steps": 110592, "Timestamp in ms": 1700567412348, "logtype": "training_step"}
{"Total num played games": 55627, "Total num trained steps": 110718, "Timestamp in ms": 1700567536517, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0133203125}
{"Ratio train steps to played games": 1.9894525003144485, "Avg loss": 0.5618588486686349, "Avg value loss": 0.31270440088701434, "Avg policy loss": 0.24915444618090987, "Total num played games": 55652, "Total num trained steps": 110720, "Timestamp in ms": 1700567538310, "logtype": "training_step"}
{"Avg objective": 21.664296874999987, "Games time in secs": 200.45880669541657, "Avg game time in secs": 0.9911579874606105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.5}, "Total num played games": 55680, "Total num trained steps": 110840, "Timestamp in ms": 1700567593373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892503992965203, "Avg loss": 0.5086963031208143, "Avg value loss": 0.26332608569646254, "Avg policy loss": 0.24537021829746664, "Total num played games": 55723, "Total num trained steps": 110848, "Timestamp in ms": 1700567596882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898513564397267, "Avg loss": 0.7228188042063266, "Avg value loss": 0.46705988043686375, "Avg policy loss": 0.25575892138294876, "Total num played games": 55771, "Total num trained steps": 110976, "Timestamp in ms": 1700567656497, "logtype": "training_step"}
{"Avg objective": 21.569296874999992, "Games time in secs": 89.50414927303791, "Avg game time in secs": 0.9140515610779403, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 55808, "Total num trained steps": 111033, "Timestamp in ms": 1700567682877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904154499364015, "Avg loss": 0.5502358046360314, "Avg value loss": 0.29864991435897537, "Avg policy loss": 0.2515858847182244, "Total num played games": 55819, "Total num trained steps": 111104, "Timestamp in ms": 1700567716387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989269618713785, "Avg loss": 0.4261896775569767, "Avg value loss": 0.17433099739719182, "Avg policy loss": 0.2518586771329865, "Total num played games": 55916, "Total num trained steps": 111232, "Timestamp in ms": 1700567776444, "logtype": "training_step"}
{"Total num played games": 55916, "Total num trained steps": 111319, "Timestamp in ms": 1700567842692, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.637539062500004}
{"Avg objective": 21.430468749999985, "Games time in secs": 161.38372113741934, "Avg game time in secs": 1.0195356901822379, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 55936, "Total num trained steps": 111320, "Timestamp in ms": 1700567844261, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898327496247588, "Avg loss": 0.613180301617831, "Avg value loss": 0.3501893169886898, "Avg policy loss": 0.2629909869283438, "Total num played games": 55964, "Total num trained steps": 111360, "Timestamp in ms": 1700567862341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.5406641298905015, "Avg value loss": 0.2774135041399859, "Avg policy loss": 0.2632506259251386, "Total num played games": 56012, "Total num trained steps": 111488, "Timestamp in ms": 1700567927310, "logtype": "training_step"}
{"Avg objective": 22.33242187499999, "Games time in secs": 139.77822739630938, "Avg game time in secs": 0.8525464315753197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.39}, "Total num played games": 56064, "Total num trained steps": 111612, "Timestamp in ms": 1700567984039, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892885150067727, "Avg loss": 0.5009240882936865, "Avg value loss": 0.24691112979780883, "Avg policy loss": 0.25401295779738575, "Total num played games": 56108, "Total num trained steps": 111616, "Timestamp in ms": 1700567985815, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898144520816268, "Avg loss": 0.611675831140019, "Avg value loss": 0.3526292768365238, "Avg policy loss": 0.25904655910562724, "Total num played games": 56158, "Total num trained steps": 111744, "Timestamp in ms": 1700568045095, "logtype": "training_step"}
{"Avg objective": 21.650781249999987, "Games time in secs": 89.75437641143799, "Avg game time in secs": 0.8729871202813229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 56192, "Total num trained steps": 111808, "Timestamp in ms": 1700568073794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990392484788101, "Avg loss": 0.5450523581821471, "Avg value loss": 0.27813570058788173, "Avg policy loss": 0.26691666012629867, "Total num played games": 56206, "Total num trained steps": 111872, "Timestamp in ms": 1700568104133, "logtype": "training_step"}
{"Total num played games": 56254, "Total num trained steps": 111920, "Timestamp in ms": 1700568182837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.001210937499998}
{"Ratio train steps to played games": 1.9892543781748429, "Avg loss": 1.0035523858387023, "Avg value loss": 0.7243717969977297, "Avg policy loss": 0.27918058377690613, "Total num played games": 56302, "Total num trained steps": 112000, "Timestamp in ms": 1700568220239, "logtype": "training_step"}
{"Avg objective": 21.75960937499999, "Games time in secs": 189.7683956436813, "Avg game time in secs": 0.9219469483214198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.45}, "Total num played games": 56320, "Total num trained steps": 112094, "Timestamp in ms": 1700568263562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989849157054126, "Avg loss": 0.4190810858272016, "Avg value loss": 0.15149645894416608, "Avg policy loss": 0.267584623885341, "Total num played games": 56350, "Total num trained steps": 112128, "Timestamp in ms": 1700568279400, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904251923827085, "Avg loss": 0.48330862261354923, "Avg value loss": 0.22254428308224306, "Avg policy loss": 0.26076434121932834, "Total num played games": 56398, "Total num trained steps": 112256, "Timestamp in ms": 1700568337238, "logtype": "training_step"}
{"Avg objective": 20.99374999999999, "Games time in secs": 132.87284079566598, "Avg game time in secs": 0.9551933800830739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.39}, "Total num played games": 56448, "Total num trained steps": 112381, "Timestamp in ms": 1700568396435, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989379027118884, "Avg loss": 0.4241380263119936, "Avg value loss": 0.16353048229939304, "Avg policy loss": 0.26060754305217415, "Total num played games": 56490, "Total num trained steps": 112384, "Timestamp in ms": 1700568397666, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898307482800701, "Avg loss": 0.6945622258353978, "Avg value loss": 0.4298176351294387, "Avg policy loss": 0.2647445807233453, "Total num played games": 56543, "Total num trained steps": 112512, "Timestamp in ms": 1700568456747, "logtype": "training_step"}
{"Total num played games": 56543, "Total num trained steps": 112523, "Timestamp in ms": 1700568527274, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5676953125}
{"Avg objective": 21.43179687499999, "Games time in secs": 132.76630297489464, "Avg game time in secs": 0.837563442211831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 56576, "Total num trained steps": 112525, "Timestamp in ms": 1700568529202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904048346910286, "Avg loss": 0.494088982231915, "Avg value loss": 0.23988795973127708, "Avg policy loss": 0.25420102605130523, "Total num played games": 56591, "Total num trained steps": 112640, "Timestamp in ms": 1700568582787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908198573547067, "Avg loss": 0.3887486037565395, "Avg value loss": 0.14125303394393995, "Avg policy loss": 0.24749557115137577, "Total num played games": 56644, "Total num trained steps": 112768, "Timestamp in ms": 1700568641222, "logtype": "training_step"}
{"Avg objective": 20.842421874999996, "Games time in secs": 155.7715957723558, "Avg game time in secs": 0.8761519737890922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.37}, "Total num played games": 56704, "Total num trained steps": 112864, "Timestamp in ms": 1700568684973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898651625980435, "Avg loss": 0.7641020193696022, "Avg value loss": 0.5087978066585492, "Avg policy loss": 0.25530421105213463, "Total num played games": 56735, "Total num trained steps": 112896, "Timestamp in ms": 1700568699184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99043727876301, "Avg loss": 0.4552481754217297, "Avg value loss": 0.19670273846713826, "Avg policy loss": 0.25854543840978295, "Total num played games": 56783, "Total num trained steps": 113024, "Timestamp in ms": 1700568758991, "logtype": "training_step"}
{"Total num played games": 56831, "Total num trained steps": 113123, "Timestamp in ms": 1700568867003, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9610546875}
{"Avg objective": 20.13593749999999, "Games time in secs": 182.85727389156818, "Avg game time in secs": 1.0112296457664343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 56832, "Total num trained steps": 113124, "Timestamp in ms": 1700568867831, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893282230700258, "Avg loss": 0.5214148564264178, "Avg value loss": 0.2675313981017098, "Avg policy loss": 0.2538834564620629, "Total num played games": 56879, "Total num trained steps": 113152, "Timestamp in ms": 1700568879597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898993447748872, "Avg loss": 0.5282559671904892, "Avg value loss": 0.28318909218069166, "Avg policy loss": 0.2450668786186725, "Total num played games": 56927, "Total num trained steps": 113280, "Timestamp in ms": 1700568937683, "logtype": "training_step"}
{"Avg objective": 20.596874999999994, "Games time in secs": 99.08765873499215, "Avg game time in secs": 0.7738892316265265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.27}, "Total num played games": 56960, "Total num trained steps": 113345, "Timestamp in ms": 1700568966919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990469504168495, "Avg loss": 0.5395105013158172, "Avg value loss": 0.2990084180200938, "Avg policy loss": 0.24050208262633532, "Total num played games": 56975, "Total num trained steps": 113408, "Timestamp in ms": 1700568995243, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908118534104857, "Avg loss": 0.4507985630771145, "Avg value loss": 0.2173351061937865, "Avg policy loss": 0.23346345603931695, "Total num played games": 57027, "Total num trained steps": 113536, "Timestamp in ms": 1700569052691, "logtype": "training_step"}
{"Avg objective": 22.726562499999993, "Games time in secs": 128.54648993723094, "Avg game time in secs": 0.9378868032363243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.42, "agent_stopped_0": 0.63}, "Total num played games": 57088, "Total num trained steps": 113632, "Timestamp in ms": 1700569095465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899508044608625, "Avg loss": 0.6569562279619277, "Avg value loss": 0.41341179874143563, "Avg policy loss": 0.24354442465119064, "Total num played games": 57119, "Total num trained steps": 113664, "Timestamp in ms": 1700569110228, "logtype": "training_step"}
{"Total num played games": 57119, "Total num trained steps": 113725, "Timestamp in ms": 1700569200604, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.964140625}
{"Ratio train steps to played games": 1.9905015131107107, "Avg loss": 0.6147461942164227, "Avg value loss": 0.37621848576236516, "Avg policy loss": 0.23852770740631968, "Total num played games": 57167, "Total num trained steps": 113792, "Timestamp in ms": 1700569232053, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991086253604824, "Avg loss": 0.5424663887824863, "Avg value loss": 0.3006291184865404, "Avg policy loss": 0.2418372689280659, "Total num played games": 57215, "Total num trained steps": 113920, "Timestamp in ms": 1700569291935, "logtype": "training_step"}
{"Avg objective": 22.039765624999987, "Games time in secs": 196.53485758788884, "Avg game time in secs": 0.9090926177304937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 57216, "Total num trained steps": 113920, "Timestamp in ms": 1700569292000, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.5753059716662392, "Avg value loss": 0.33183836020180024, "Avg policy loss": 0.2434676123666577, "Total num played games": 57321, "Total num trained steps": 114048, "Timestamp in ms": 1700569349432, "logtype": "training_step"}
{"Avg objective": 22.167187499999994, "Games time in secs": 95.34208211675286, "Avg game time in secs": 0.9042663307191106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 57344, "Total num trained steps": 114132, "Timestamp in ms": 1700569387343, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901863375690705, "Avg loss": 0.5412016189657152, "Avg value loss": 0.2974974038952496, "Avg policy loss": 0.24370421562343836, "Total num played games": 57369, "Total num trained steps": 114176, "Timestamp in ms": 1700569407163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907692843582911, "Avg loss": 0.4054580917581916, "Avg value loss": 0.17051401891512796, "Avg policy loss": 0.23494407220277935, "Total num played games": 57417, "Total num trained steps": 114304, "Timestamp in ms": 1700569464222, "logtype": "training_step"}
{"Total num played games": 57465, "Total num trained steps": 114327, "Timestamp in ms": 1700569537602, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.660703125}
{"Avg objective": 20.175312499999986, "Games time in secs": 151.4878481440246, "Avg game time in secs": 0.948892254542443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 57472, "Total num trained steps": 114327, "Timestamp in ms": 1700569538833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896545128927372, "Avg loss": 0.5396424037171528, "Avg value loss": 0.29450885401456617, "Avg policy loss": 0.245133554097265, "Total num played games": 57513, "Total num trained steps": 114432, "Timestamp in ms": 1700569585975, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902364448150658, "Avg loss": 0.41613284894265234, "Avg value loss": 0.1814687707228586, "Avg policy loss": 0.23466407880187035, "Total num played games": 57561, "Total num trained steps": 114560, "Timestamp in ms": 1700569643162, "logtype": "training_step"}
{"Avg objective": 20.11718749999999, "Games time in secs": 129.16443968378007, "Avg game time in secs": 0.8187986508419272, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.39}, "Total num played games": 57600, "Total num trained steps": 114613, "Timestamp in ms": 1700569667998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907826902046555, "Avg loss": 0.423699326813221, "Avg value loss": 0.18508081091567874, "Avg policy loss": 0.23861851275432855, "Total num played games": 57609, "Total num trained steps": 114688, "Timestamp in ms": 1700569702958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896544553425988, "Avg loss": 0.6610586669994518, "Avg value loss": 0.4105509572545998, "Avg policy loss": 0.2505077092209831, "Total num played games": 57706, "Total num trained steps": 114816, "Timestamp in ms": 1700569761711, "logtype": "training_step"}
{"Avg objective": 20.81640624999999, "Games time in secs": 133.9196053724736, "Avg game time in secs": 0.8608343433443224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.39, "agent_stopped_0": 0.64}, "Total num played games": 57728, "Total num trained steps": 114902, "Timestamp in ms": 1700569801917, "logtype": "played_game"}
{"Total num played games": 57754, "Total num trained steps": 114928, "Timestamp in ms": 1700569874257, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.773398437500003}
{"Ratio train steps to played games": 1.9885644095360022, "Avg loss": 0.7161350821843371, "Avg value loss": 0.46578176342882216, "Avg policy loss": 0.2503533224808052, "Total num played games": 57802, "Total num trained steps": 114944, "Timestamp in ms": 1700569881838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907788657831909, "Avg loss": 0.4334614905528724, "Avg value loss": 0.18226966669317335, "Avg policy loss": 0.25119182805065066, "Total num played games": 57802, "Total num trained steps": 115072, "Timestamp in ms": 1700569940889, "logtype": "training_step"}
{"Avg objective": 21.352343749999992, "Games time in secs": 192.50120437517762, "Avg game time in secs": 0.9008314651146065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 57856, "Total num trained steps": 115190, "Timestamp in ms": 1700569994419, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896887629969948, "Avg loss": 0.5069339782930911, "Avg value loss": 0.25924269630922936, "Avg policy loss": 0.24769128253683448, "Total num played games": 57898, "Total num trained steps": 115200, "Timestamp in ms": 1700569998616, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902495426776654, "Avg loss": 0.5297613977454603, "Avg value loss": 0.28163037085323595, "Avg policy loss": 0.2481310253497213, "Total num played games": 57946, "Total num trained steps": 115328, "Timestamp in ms": 1700570056908, "logtype": "training_step"}
{"Avg objective": 21.613046874999995, "Games time in secs": 88.76198495179415, "Avg game time in secs": 0.8355664178816369, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 57984, "Total num trained steps": 115383, "Timestamp in ms": 1700570083181, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908093940752492, "Avg loss": 0.543476538034156, "Avg value loss": 0.3016966753639281, "Avg policy loss": 0.24177986662834883, "Total num played games": 57994, "Total num trained steps": 115456, "Timestamp in ms": 1700570117219, "logtype": "training_step"}
{"Total num played games": 58043, "Total num trained steps": 115530, "Timestamp in ms": 1700570229376, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9580078125}
{"Ratio train steps to played games": 1.9896885920366323, "Avg loss": 0.7918922950048, "Avg value loss": 0.5360153403598815, "Avg policy loss": 0.2558769512688741, "Total num played games": 58091, "Total num trained steps": 115584, "Timestamp in ms": 1700570253102, "logtype": "training_step"}
{"Avg objective": 21.45156249999999, "Games time in secs": 209.95184772461653, "Avg game time in secs": 0.8662088834244059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.37, "agent_stopped_0": 0.68}, "Total num played games": 58112, "Total num trained steps": 115672, "Timestamp in ms": 1700570293133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902475102770945, "Avg loss": 0.6721717759501189, "Avg value loss": 0.41738534957403317, "Avg policy loss": 0.2547864258522168, "Total num played games": 58139, "Total num trained steps": 115712, "Timestamp in ms": 1700570312228, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907712930501134, "Avg loss": 0.6214829739183187, "Avg value loss": 0.3526106346398592, "Avg policy loss": 0.268872331478633, "Total num played games": 58188, "Total num trained steps": 115840, "Timestamp in ms": 1700570371177, "logtype": "training_step"}
{"Avg objective": 22.21539062499998, "Games time in secs": 135.8992179427296, "Avg game time in secs": 0.9909658369142562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 58240, "Total num trained steps": 115962, "Timestamp in ms": 1700570429032, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989739718271194, "Avg loss": 0.521551794372499, "Avg value loss": 0.26005124344374053, "Avg policy loss": 0.2615005549741909, "Total num played games": 58283, "Total num trained steps": 115968, "Timestamp in ms": 1700570431729, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902626345745045, "Avg loss": 0.7149920655647293, "Avg value loss": 0.4555223887437023, "Avg policy loss": 0.2594696810701862, "Total num played games": 58332, "Total num trained steps": 116096, "Timestamp in ms": 1700570490820, "logtype": "training_step"}
{"Total num played games": 58332, "Total num trained steps": 116134, "Timestamp in ms": 1700570598491, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2240234375}
{"Avg objective": 21.736406249999987, "Games time in secs": 171.44370240718126, "Avg game time in secs": 0.8787558380572591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 58368, "Total num trained steps": 116136, "Timestamp in ms": 1700570600476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908187735525864, "Avg loss": 0.5885885416064411, "Avg value loss": 0.31718499929411337, "Avg policy loss": 0.2714035405078903, "Total num played games": 58380, "Total num trained steps": 116224, "Timestamp in ms": 1700570640860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897222792256652, "Avg loss": 0.5756962469313294, "Avg value loss": 0.30601191814639606, "Avg policy loss": 0.26968433300498873, "Total num played games": 58476, "Total num trained steps": 116352, "Timestamp in ms": 1700570700469, "logtype": "training_step"}
{"Avg objective": 20.632968749999993, "Games time in secs": 141.4652569424361, "Avg game time in secs": 0.8662819537566975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 58496, "Total num trained steps": 116442, "Timestamp in ms": 1700570741942, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902605724049551, "Avg loss": 0.662314657587558, "Avg value loss": 0.388048011547653, "Avg policy loss": 0.2742666465928778, "Total num played games": 58525, "Total num trained steps": 116480, "Timestamp in ms": 1700570759656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907978078636914, "Avg loss": 0.5278696077875793, "Avg value loss": 0.2512334431230556, "Avg policy loss": 0.27663616614881903, "Total num played games": 58573, "Total num trained steps": 116608, "Timestamp in ms": 1700570818303, "logtype": "training_step"}
{"Avg objective": 21.869999999999994, "Games time in secs": 136.0950239598751, "Avg game time in secs": 0.8983455702400533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 58624, "Total num trained steps": 116732, "Timestamp in ms": 1700570878037, "logtype": "played_game"}
{"Total num played games": 58669, "Total num trained steps": 116733, "Timestamp in ms": 1700570945521, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3483203125}
{"Ratio train steps to played games": 1.9889932016833927, "Avg loss": 0.6189826726913452, "Avg value loss": 0.34630342287709936, "Avg policy loss": 0.2726792567409575, "Total num played games": 58688, "Total num trained steps": 116736, "Timestamp in ms": 1700570947254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902753887289881, "Avg loss": 0.7949598303530365, "Avg value loss": 0.5202618997718673, "Avg policy loss": 0.27469794533681124, "Total num played games": 58717, "Total num trained steps": 116864, "Timestamp in ms": 1700571005889, "logtype": "training_step"}
{"Avg objective": 21.010468749999987, "Games time in secs": 154.97040981799364, "Avg game time in secs": 0.8776749738754006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 58752, "Total num trained steps": 116925, "Timestamp in ms": 1700571033007, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990793996528605, "Avg loss": 0.5940173352137208, "Avg value loss": 0.32405120410840027, "Avg policy loss": 0.26996612700168043, "Total num played games": 58766, "Total num trained steps": 116992, "Timestamp in ms": 1700571063861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901612601743446, "Avg loss": 0.6665164604783058, "Avg value loss": 0.40106137123075314, "Avg policy loss": 0.26545509533025324, "Total num played games": 58848, "Total num trained steps": 117120, "Timestamp in ms": 1700571121898, "logtype": "training_step"}
{"Avg objective": 22.56507812499999, "Games time in secs": 134.61976102925837, "Avg game time in secs": 0.9743536488967948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 58880, "Total num trained steps": 117218, "Timestamp in ms": 1700571167627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901213612832047, "Avg loss": 0.6826689740410075, "Avg value loss": 0.4065551317180507, "Avg policy loss": 0.27611384366173297, "Total num played games": 58915, "Total num trained steps": 117248, "Timestamp in ms": 1700571181854, "logtype": "training_step"}
{"Total num played games": 58963, "Total num trained steps": 117337, "Timestamp in ms": 1700571289188, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.705546875000003}
{"Avg objective": 22.27265624999999, "Games time in secs": 124.30196560174227, "Avg game time in secs": 0.9295312059548451, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 59008, "Total num trained steps": 117341, "Timestamp in ms": 1700571291929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890359424514075, "Avg loss": 0.6264828376006335, "Avg value loss": 0.3537383991351817, "Avg policy loss": 0.27274443255737424, "Total num played games": 59011, "Total num trained steps": 117376, "Timestamp in ms": 1700571307983, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991205029570758, "Avg loss": 0.35814269457478076, "Avg value loss": 0.09579214197583497, "Avg policy loss": 0.26235054968856275, "Total num played games": 59011, "Total num trained steps": 117504, "Timestamp in ms": 1700571369084, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901365320520412, "Avg loss": 0.4836721792817116, "Avg value loss": 0.2202158914587926, "Avg policy loss": 0.2634562919847667, "Total num played games": 59107, "Total num trained steps": 117632, "Timestamp in ms": 1700571427973, "logtype": "training_step"}
{"Avg objective": 21.23359374999999, "Games time in secs": 170.20316463150084, "Avg game time in secs": 0.9926439411792671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 59136, "Total num trained steps": 117705, "Timestamp in ms": 1700571462133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907023920209619, "Avg loss": 0.6596020003780723, "Avg value loss": 0.3917937411169987, "Avg policy loss": 0.2678082616766915, "Total num played games": 59155, "Total num trained steps": 117760, "Timestamp in ms": 1700571487185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912335523537659, "Avg loss": 0.5278957639820874, "Avg value loss": 0.27066007477696985, "Avg policy loss": 0.2572356821037829, "Total num played games": 59203, "Total num trained steps": 117888, "Timestamp in ms": 1700571545332, "logtype": "training_step"}
{"Total num played games": 59251, "Total num trained steps": 117939, "Timestamp in ms": 1700571644460, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8998828125}
{"Avg objective": 21.13164062499999, "Games time in secs": 183.62669236399233, "Avg game time in secs": 0.9886165383068146, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 59264, "Total num trained steps": 117940, "Timestamp in ms": 1700571645760, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990185331961753, "Avg loss": 0.8161688528489321, "Avg value loss": 0.5356165076955222, "Avg policy loss": 0.28055233624763787, "Total num played games": 59299, "Total num trained steps": 118016, "Timestamp in ms": 1700571679710, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990715621682646, "Avg loss": 0.4284980653319508, "Avg value loss": 0.16312225893489085, "Avg policy loss": 0.2653758099768311, "Total num played games": 59347, "Total num trained steps": 118144, "Timestamp in ms": 1700571738548, "logtype": "training_step"}
{"Avg objective": 21.98312499999999, "Games time in secs": 112.78944257646799, "Avg game time in secs": 0.8043182353139855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 59392, "Total num trained steps": 118186, "Timestamp in ms": 1700571758549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912787271655863, "Avg loss": 0.626232314389199, "Avg value loss": 0.36238887973013334, "Avg policy loss": 0.26384344475809485, "Total num played games": 59395, "Total num trained steps": 118272, "Timestamp in ms": 1700571799809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990217007614597, "Avg loss": 0.5631438125856221, "Avg value loss": 0.29972085426561534, "Avg policy loss": 0.26342296006623656, "Total num played games": 59491, "Total num trained steps": 118400, "Timestamp in ms": 1700571859162, "logtype": "training_step"}
{"Avg objective": 21.465390624999987, "Games time in secs": 136.6680678576231, "Avg game time in secs": 0.8723233881319175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.39, "agent_stopped_0": 0.62}, "Total num played games": 59520, "Total num trained steps": 118473, "Timestamp in ms": 1700571895217, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907455617326457, "Avg loss": 0.4960496190469712, "Avg value loss": 0.22847565068514086, "Avg policy loss": 0.26757397095207125, "Total num played games": 59539, "Total num trained steps": 118528, "Timestamp in ms": 1700571921751, "logtype": "training_step"}
{"Total num played games": 59539, "Total num trained steps": 118540, "Timestamp in ms": 1700572009760, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5873046875}
{"Ratio train steps to played games": 1.9912900464866499, "Avg loss": 0.5683434503152966, "Avg value loss": 0.2940286766679492, "Avg policy loss": 0.2743147775763646, "Total num played games": 59587, "Total num trained steps": 118656, "Timestamp in ms": 1700572065461, "logtype": "training_step"}
{"Avg objective": 21.18773437499998, "Games time in secs": 220.39473973028362, "Avg game time in secs": 0.9851081635133596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.57, "agent_stopped_0": 0.51}, "Total num played games": 59648, "Total num trained steps": 118760, "Timestamp in ms": 1700572115613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902484794665147, "Avg loss": 0.7132953442633152, "Avg value loss": 0.44869040421326645, "Avg policy loss": 0.2646049403119832, "Total num played games": 59683, "Total num trained steps": 118784, "Timestamp in ms": 1700572126991, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907753093033769, "Avg loss": 0.5325895473361015, "Avg value loss": 0.27226352898287587, "Avg policy loss": 0.26032600994221866, "Total num played games": 59731, "Total num trained steps": 118912, "Timestamp in ms": 1700572188597, "logtype": "training_step"}
{"Avg objective": 22.063828124999993, "Games time in secs": 93.39250794425607, "Avg game time in secs": 0.8544678683247184, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 59776, "Total num trained steps": 118955, "Timestamp in ms": 1700572209005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912847106055538, "Avg loss": 0.593364015687257, "Avg value loss": 0.3275704916450195, "Avg policy loss": 0.26579351793043315, "Total num played games": 59780, "Total num trained steps": 119040, "Timestamp in ms": 1700572249397, "logtype": "training_step"}
{"Total num played games": 59828, "Total num trained steps": 119142, "Timestamp in ms": 1700572378326, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5591796875}
{"Ratio train steps to played games": 1.9902465094528692, "Avg loss": 0.645328821381554, "Avg value loss": 0.39171982335392386, "Avg policy loss": 0.25360899313818663, "Total num played games": 59876, "Total num trained steps": 119168, "Timestamp in ms": 1700572391469, "logtype": "training_step"}
{"Avg objective": 22.21039062499999, "Games time in secs": 217.84366270527244, "Avg game time in secs": 0.8588297278038226, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.41, "agent_stopped_0": 0.65}, "Total num played games": 59904, "Total num trained steps": 119243, "Timestamp in ms": 1700572426849, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907716440825045, "Avg loss": 0.6108150507789105, "Avg value loss": 0.3613242022402119, "Avg policy loss": 0.2494908571243286, "Total num played games": 59924, "Total num trained steps": 119296, "Timestamp in ms": 1700572451739, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913126125525245, "Avg loss": 0.5445373478578404, "Avg value loss": 0.2923611059959512, "Avg policy loss": 0.252176234847866, "Total num played games": 59972, "Total num trained steps": 119424, "Timestamp in ms": 1700572510636, "logtype": "training_step"}
{"Avg objective": 21.661484374999986, "Games time in secs": 131.52399581298232, "Avg game time in secs": 1.0339123139419826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 60032, "Total num trained steps": 119530, "Timestamp in ms": 1700572558373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902445520984202, "Avg loss": 0.5806518397293985, "Avg value loss": 0.32478709873976186, "Avg policy loss": 0.2558647431433201, "Total num played games": 60069, "Total num trained steps": 119552, "Timestamp in ms": 1700572568170, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907680023953291, "Avg loss": 0.7335097125032917, "Avg value loss": 0.48375925252912566, "Avg policy loss": 0.24975046957843006, "Total num played games": 60117, "Total num trained steps": 119680, "Timestamp in ms": 1700572625246, "logtype": "training_step"}
{"Avg objective": 22.329218749999992, "Games time in secs": 87.64808132313192, "Avg game time in secs": 0.9437542923114961, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 60160, "Total num trained steps": 119726, "Timestamp in ms": 1700572646021, "logtype": "played_game"}
{"Total num played games": 60165, "Total num trained steps": 119744, "Timestamp in ms": 1700572715381, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.408398437500004}
{"Ratio train steps to played games": 1.9897364356534304, "Avg loss": 0.6248697862029076, "Avg value loss": 0.35817197203869, "Avg policy loss": 0.2666978141060099, "Total num played games": 60213, "Total num trained steps": 119808, "Timestamp in ms": 1700572747121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902756343240238, "Avg loss": 0.4137579638045281, "Avg value loss": 0.16570483826217242, "Avg policy loss": 0.24805312720127404, "Total num played games": 60261, "Total num trained steps": 119936, "Timestamp in ms": 1700572807801, "logtype": "training_step"}
{"Avg objective": 22.047031249999993, "Games time in secs": 197.02005602791905, "Avg game time in secs": 0.9034594312252011, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.43, "agent_stopped_0": 0.64}, "Total num played games": 60288, "Total num trained steps": 120013, "Timestamp in ms": 1700572843042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907973934238672, "Avg loss": 0.6319131862837821, "Avg value loss": 0.3651091267238371, "Avg policy loss": 0.26680405670776963, "Total num played games": 60309, "Total num trained steps": 120064, "Timestamp in ms": 1700572866029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991351458820021, "Avg loss": 0.49704210250638425, "Avg value loss": 0.23023436634684913, "Avg policy loss": 0.2668077383423224, "Total num played games": 60357, "Total num trained steps": 120192, "Timestamp in ms": 1700572924547, "logtype": "training_step"}
{"Avg objective": 20.982031249999984, "Games time in secs": 132.25957611948252, "Avg game time in secs": 0.9413644278392894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.44, "agent_stopped_0": 0.62}, "Total num played games": 60416, "Total num trained steps": 120302, "Timestamp in ms": 1700572975301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902570549508718, "Avg loss": 0.5857373393373564, "Avg value loss": 0.31763637566473335, "Avg policy loss": 0.26810096541885287, "Total num played games": 60454, "Total num trained steps": 120320, "Timestamp in ms": 1700572983050, "logtype": "training_step"}
{"Total num played games": 60454, "Total num trained steps": 120346, "Timestamp in ms": 1700573063992, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5329296875}
{"Ratio train steps to played games": 1.990810221149714, "Avg loss": 0.5905006844550371, "Avg value loss": 0.3144295996753499, "Avg policy loss": 0.27607108443044126, "Total num played games": 60502, "Total num trained steps": 120448, "Timestamp in ms": 1700573110521, "logtype": "training_step"}
{"Avg objective": 21.54898437499999, "Games time in secs": 157.0801391173154, "Avg game time in secs": 0.8805867575865705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 60544, "Total num trained steps": 120496, "Timestamp in ms": 1700573132382, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991345995045417, "Avg loss": 0.4477372723631561, "Avg value loss": 0.1910796647425741, "Avg policy loss": 0.2566576109966263, "Total num played games": 60550, "Total num trained steps": 120576, "Timestamp in ms": 1700573168921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902550826916419, "Avg loss": 0.6315875359578058, "Avg value loss": 0.368348953925306, "Avg policy loss": 0.2632385912584141, "Total num played games": 60647, "Total num trained steps": 120704, "Timestamp in ms": 1700573228320, "logtype": "training_step"}
{"Avg objective": 21.43515624999999, "Games time in secs": 135.12589330598712, "Avg game time in secs": 0.8986572512367275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 60672, "Total num trained steps": 120785, "Timestamp in ms": 1700573267508, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905113336847655, "Avg loss": 0.6159913544543087, "Avg value loss": 0.34836929239099845, "Avg policy loss": 0.26762206002604216, "Total num played games": 60704, "Total num trained steps": 120832, "Timestamp in ms": 1700573289146, "logtype": "training_step"}
{"Total num played games": 60752, "Total num trained steps": 120949, "Timestamp in ms": 1700573411413, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5845703125}
{"Ratio train steps to played games": 1.9894899587164263, "Avg loss": 0.6711685105692595, "Avg value loss": 0.3944714789977297, "Avg policy loss": 0.2766970278462395, "Total num played games": 60799, "Total num trained steps": 120960, "Timestamp in ms": 1700573416442, "logtype": "training_step"}
{"Avg objective": 22.256171874999986, "Games time in secs": 151.88066233880818, "Avg game time in secs": 1.1363465492468094, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.61}, "Total num played games": 60800, "Total num trained steps": 120966, "Timestamp in ms": 1700573419389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915625, "Avg loss": 0.5401010098867118, "Avg value loss": 0.24751568789361045, "Avg policy loss": 0.2925853240303695, "Total num played games": 60800, "Total num trained steps": 121088, "Timestamp in ms": 1700573475604, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905248292170257, "Avg loss": 0.7130880795884877, "Avg value loss": 0.4326145322411321, "Avg policy loss": 0.2804735549725592, "Total num played games": 60896, "Total num trained steps": 121216, "Timestamp in ms": 1700573534213, "logtype": "training_step"}
{"Avg objective": 21.63648437499999, "Games time in secs": 144.99754125997424, "Avg game time in secs": 0.894991948880488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.34}, "Total num played games": 60928, "Total num trained steps": 121283, "Timestamp in ms": 1700573564386, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910573641375688, "Avg loss": 0.7475743531249464, "Avg value loss": 0.4607914451917168, "Avg policy loss": 0.28678291698452085, "Total num played games": 60944, "Total num trained steps": 121344, "Timestamp in ms": 1700573592770, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916054564533054, "Avg loss": 0.7231647127773613, "Avg value loss": 0.44119609671179205, "Avg policy loss": 0.2819686094298959, "Total num played games": 60992, "Total num trained steps": 121472, "Timestamp in ms": 1700573651998, "logtype": "training_step"}
{"Total num played games": 61050, "Total num trained steps": 121551, "Timestamp in ms": 1700573773832, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.642148437499998}
{"Avg objective": 21.525234374999986, "Games time in secs": 210.4771852903068, "Avg game time in secs": 0.998040120350197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 61056, "Total num trained steps": 121552, "Timestamp in ms": 1700573774864, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990245179874955, "Avg loss": 0.6189479972235858, "Avg value loss": 0.3388785236165859, "Avg policy loss": 0.28006946796085685, "Total num played games": 61098, "Total num trained steps": 121600, "Timestamp in ms": 1700573796359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907761750564223, "Avg loss": 0.4774462338536978, "Avg value loss": 0.20167789512197487, "Avg policy loss": 0.27576834126375616, "Total num played games": 61146, "Total num trained steps": 121728, "Timestamp in ms": 1700573855334, "logtype": "training_step"}
{"Avg objective": 20.86617187499999, "Games time in secs": 106.43825794942677, "Avg game time in secs": 0.8454617378156399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 61184, "Total num trained steps": 121783, "Timestamp in ms": 1700573881302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912737968788299, "Avg loss": 0.569243197562173, "Avg value loss": 0.28720049117691815, "Avg policy loss": 0.2820427054539323, "Total num played games": 61195, "Total num trained steps": 121856, "Timestamp in ms": 1700573916096, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901133860836937, "Avg loss": 0.6025155346142128, "Avg value loss": 0.31728082161862403, "Avg policy loss": 0.2852347095031291, "Total num played games": 61295, "Total num trained steps": 121984, "Timestamp in ms": 1700573974971, "logtype": "training_step"}
{"Avg objective": 20.863984374999983, "Games time in secs": 137.24575028009713, "Avg game time in secs": 0.9442567291553132, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 61312, "Total num trained steps": 122080, "Timestamp in ms": 1700574018548, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99039934800326, "Avg loss": 0.7392009436152875, "Avg value loss": 0.45081088691949844, "Avg policy loss": 0.2883900547167286, "Total num played games": 61350, "Total num trained steps": 122112, "Timestamp in ms": 1700574032966, "logtype": "training_step"}
{"Total num played games": 61350, "Total num trained steps": 122152, "Timestamp in ms": 1700574147689, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7668359375}
{"Ratio train steps to played games": 1.990944330434216, "Avg loss": 0.5270018808078021, "Avg value loss": 0.2320104023674503, "Avg policy loss": 0.29499148263130337, "Total num played games": 61398, "Total num trained steps": 122240, "Timestamp in ms": 1700574188082, "logtype": "training_step"}
{"Avg objective": 21.065937499999986, "Games time in secs": 191.57287331297994, "Avg game time in secs": 0.930997720657615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 61440, "Total num trained steps": 122287, "Timestamp in ms": 1700574210121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991455912508544, "Avg loss": 0.5333835908677429, "Avg value loss": 0.2446733615361154, "Avg policy loss": 0.2887102314271033, "Total num played games": 61446, "Total num trained steps": 122368, "Timestamp in ms": 1700574248716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904455493809106, "Avg loss": 0.653365284204483, "Avg value loss": 0.3637295030639507, "Avg policy loss": 0.2896357785211876, "Total num played games": 61542, "Total num trained steps": 122496, "Timestamp in ms": 1700574306220, "logtype": "training_step"}
{"Avg objective": 21.93187499999999, "Games time in secs": 134.2319289445877, "Avg game time in secs": 0.9674387199047487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.44, "agent_stopped_0": 0.61}, "Total num played games": 61568, "Total num trained steps": 122575, "Timestamp in ms": 1700574344353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909563240785841, "Avg loss": 0.5911271134391427, "Avg value loss": 0.29742067187908106, "Avg policy loss": 0.2937064360594377, "Total num played games": 61590, "Total num trained steps": 122624, "Timestamp in ms": 1700574367342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914825270125571, "Avg loss": 0.49449243675917387, "Avg value loss": 0.2108562017674558, "Avg policy loss": 0.2836362331872806, "Total num played games": 61638, "Total num trained steps": 122752, "Timestamp in ms": 1700574426401, "logtype": "training_step"}
{"Total num played games": 61638, "Total num trained steps": 122755, "Timestamp in ms": 1700574494057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.166640625000003}
{"Avg objective": 22.987968749999983, "Games time in secs": 198.47174791060388, "Avg game time in secs": 1.0041023654775927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 61696, "Total num trained steps": 122862, "Timestamp in ms": 1700574542825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904268243297967, "Avg loss": 0.8994813496246934, "Avg value loss": 0.6119464045041241, "Avg policy loss": 0.2875349640380591, "Total num played games": 61735, "Total num trained steps": 122880, "Timestamp in ms": 1700574551319, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909683893627697, "Avg loss": 0.7688471172004938, "Avg value loss": 0.46899567131185904, "Avg policy loss": 0.2998514388455078, "Total num played games": 61783, "Total num trained steps": 123008, "Timestamp in ms": 1700574609457, "logtype": "training_step"}
{"Avg objective": 22.33249999999999, "Games time in secs": 90.01348548941314, "Avg game time in secs": 0.95651027536951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 61824, "Total num trained steps": 123058, "Timestamp in ms": 1700574632839, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991476767317365, "Avg loss": 0.6265111155807972, "Avg value loss": 0.33978257118724287, "Avg policy loss": 0.28672854334581643, "Total num played games": 61831, "Total num trained steps": 123136, "Timestamp in ms": 1700574669554, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904243637772898, "Avg loss": 0.6781812143744901, "Avg value loss": 0.38849959115032107, "Avg policy loss": 0.28968161589000374, "Total num played games": 61928, "Total num trained steps": 123264, "Timestamp in ms": 1700574727476, "logtype": "training_step"}
{"Avg objective": 20.892421874999986, "Games time in secs": 132.56866982020438, "Avg game time in secs": 1.036821080633672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 61952, "Total num trained steps": 123347, "Timestamp in ms": 1700574765412, "logtype": "played_game"}
{"Total num played games": 61977, "Total num trained steps": 123357, "Timestamp in ms": 1700574844366, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.265859375}
{"Ratio train steps to played games": 1.989391374445788, "Avg loss": 0.8893161350861192, "Avg value loss": 0.5959838084527291, "Avg policy loss": 0.2933323383331299, "Total num played games": 62025, "Total num trained steps": 123392, "Timestamp in ms": 1700574860402, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914550584441757, "Avg loss": 0.4126364653930068, "Avg value loss": 0.12765500918612815, "Avg policy loss": 0.28498145437333733, "Total num played games": 62025, "Total num trained steps": 123520, "Timestamp in ms": 1700574920821, "logtype": "training_step"}
{"Avg objective": 21.029374999999984, "Games time in secs": 211.57114256732166, "Avg game time in secs": 1.1041882276913384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 62080, "Total num trained steps": 123640, "Timestamp in ms": 1700574976984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903258000128774, "Avg loss": 0.5318597422447056, "Avg value loss": 0.25258919899351895, "Avg policy loss": 0.27927054511383176, "Total num played games": 62124, "Total num trained steps": 123648, "Timestamp in ms": 1700574980697, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908159490454056, "Avg loss": 0.6617583406623453, "Avg value loss": 0.37420803573331796, "Avg policy loss": 0.2875503022223711, "Total num played games": 62173, "Total num trained steps": 123776, "Timestamp in ms": 1700575039038, "logtype": "training_step"}
{"Avg objective": 21.993749999999988, "Games time in secs": 89.00111534819007, "Avg game time in secs": 0.8839472428080626, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 62208, "Total num trained steps": 123836, "Timestamp in ms": 1700575065985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913373298404076, "Avg loss": 0.5819880194030702, "Avg value loss": 0.278883594146464, "Avg policy loss": 0.3031044318340719, "Total num played games": 62221, "Total num trained steps": 123904, "Timestamp in ms": 1700575097018, "logtype": "training_step"}
{"Total num played games": 62269, "Total num trained steps": 123958, "Timestamp in ms": 1700575200459, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.271171875}
{"Ratio train steps to played games": 1.9903397146845965, "Avg loss": 0.8082782619167119, "Avg value loss": 0.5169683040585369, "Avg policy loss": 0.2913099607685581, "Total num played games": 62317, "Total num trained steps": 124032, "Timestamp in ms": 1700575235043, "logtype": "training_step"}
{"Avg objective": 21.157812499999984, "Games time in secs": 210.76440498046577, "Avg game time in secs": 0.9446808921784395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 62336, "Total num trained steps": 124124, "Timestamp in ms": 1700575276750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908283359522816, "Avg loss": 0.4895991268567741, "Avg value loss": 0.20506014497368596, "Avg policy loss": 0.2845389802241698, "Total num played games": 62366, "Total num trained steps": 124160, "Timestamp in ms": 1700575292462, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913001682287912, "Avg loss": 0.5875685813371092, "Avg value loss": 0.3082499464508146, "Avg policy loss": 0.2793186317430809, "Total num played games": 62415, "Total num trained steps": 124288, "Timestamp in ms": 1700575351759, "logtype": "training_step"}
{"Avg objective": 20.93249999999998, "Games time in secs": 133.98967663571239, "Avg game time in secs": 1.065085188674857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 62464, "Total num trained steps": 124415, "Timestamp in ms": 1700575410739, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914844575343342, "Avg loss": 0.8806309023639187, "Avg value loss": 0.5896814661100507, "Avg policy loss": 0.29094942880328745, "Total num played games": 62467, "Total num trained steps": 124416, "Timestamp in ms": 1700575410942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908086766092807, "Avg loss": 0.6982285510748625, "Avg value loss": 0.4130446130875498, "Avg policy loss": 0.285183941363357, "Total num played games": 62559, "Total num trained steps": 124544, "Timestamp in ms": 1700575471595, "logtype": "training_step"}
{"Total num played games": 62559, "Total num trained steps": 124559, "Timestamp in ms": 1700575577394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8258984375}
{"Avg objective": 22.114843749999984, "Games time in secs": 168.69309838488698, "Avg game time in secs": 0.9287400233006338, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 62592, "Total num trained steps": 124563, "Timestamp in ms": 1700575579433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913268484354785, "Avg loss": 0.639665822731331, "Avg value loss": 0.34602018230361864, "Avg policy loss": 0.2936456357128918, "Total num played games": 62607, "Total num trained steps": 124672, "Timestamp in ms": 1700575628701, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916058918340966, "Avg loss": 0.687433733837679, "Avg value loss": 0.40880235872464254, "Avg policy loss": 0.27863137633539736, "Total num played games": 62659, "Total num trained steps": 124800, "Timestamp in ms": 1700575686121, "logtype": "training_step"}
{"Avg objective": 22.44820312499999, "Games time in secs": 150.65060138329864, "Avg game time in secs": 0.9990855155483587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 62720, "Total num trained steps": 124896, "Timestamp in ms": 1700575730083, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908210096889343, "Avg loss": 0.734495764831081, "Avg value loss": 0.4434130964218639, "Avg policy loss": 0.29108266765251756, "Total num played games": 62752, "Total num trained steps": 124928, "Timestamp in ms": 1700575744360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913216560509555, "Avg loss": 0.598047083709389, "Avg value loss": 0.314864941930864, "Avg policy loss": 0.2831821362487972, "Total num played games": 62800, "Total num trained steps": 125056, "Timestamp in ms": 1700575803295, "logtype": "training_step"}
{"Avg objective": 21.56539062499998, "Games time in secs": 91.0308832898736, "Avg game time in secs": 1.040917913269368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 62848, "Total num trained steps": 125093, "Timestamp in ms": 1700575821114, "logtype": "played_game"}
{"Total num played games": 62848, "Total num trained steps": 125159, "Timestamp in ms": 1700575944201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9101953125}
{"Ratio train steps to played games": 1.9903332485372678, "Avg loss": 0.6313463028054684, "Avg value loss": 0.35135481995530427, "Avg policy loss": 0.27999147889204323, "Total num played games": 62896, "Total num trained steps": 125184, "Timestamp in ms": 1700575955358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908331215048296, "Avg loss": 0.4925942230038345, "Avg value loss": 0.21008235824410804, "Avg policy loss": 0.2825118647888303, "Total num played games": 62944, "Total num trained steps": 125312, "Timestamp in ms": 1700576013349, "logtype": "training_step"}
{"Avg objective": 20.700781249999984, "Games time in secs": 222.4550599846989, "Avg game time in secs": 0.8173298572801286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 62976, "Total num trained steps": 125379, "Timestamp in ms": 1700576043570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913639827279654, "Avg loss": 0.5374008168000728, "Avg value loss": 0.26083856727927923, "Avg policy loss": 0.2765622570877895, "Total num played games": 62992, "Total num trained steps": 125440, "Timestamp in ms": 1700576072117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918623096446701, "Avg loss": 0.6538213420426473, "Avg value loss": 0.37123590416740626, "Avg policy loss": 0.28258544160053134, "Total num played games": 63040, "Total num trained steps": 125568, "Timestamp in ms": 1700576133876, "logtype": "training_step"}
{"Avg objective": 22.442499999999985, "Games time in secs": 135.471127435565, "Avg game time in secs": 1.0921436341159279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 63104, "Total num trained steps": 125666, "Timestamp in ms": 1700576179041, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990860998479473, "Avg loss": 0.6819316993933171, "Avg value loss": 0.3944012545980513, "Avg policy loss": 0.2875304442131892, "Total num played games": 63136, "Total num trained steps": 125696, "Timestamp in ms": 1700576196198, "logtype": "training_step"}
{"Total num played games": 63184, "Total num trained steps": 125762, "Timestamp in ms": 1700576288536, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0930859375}
{"Avg objective": 22.068593749999987, "Games time in secs": 119.15989186055958, "Avg game time in secs": 1.0453603956411825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.58, "agent_stopped_0": 0.47}, "Total num played games": 63232, "Total num trained steps": 125783, "Timestamp in ms": 1700576298201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898627277327936, "Avg loss": 0.7189908111467957, "Avg value loss": 0.42214497542590834, "Avg policy loss": 0.2968458329560235, "Total num played games": 63232, "Total num trained steps": 125824, "Timestamp in ms": 1700576318566, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918870192307692, "Avg loss": 0.3645171767566353, "Avg value loss": 0.09020973311271518, "Avg policy loss": 0.2743074393365532, "Total num played games": 63232, "Total num trained steps": 125952, "Timestamp in ms": 1700576391835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908572691815756, "Avg loss": 0.8239116845652461, "Avg value loss": 0.532817137776874, "Avg policy loss": 0.2910945435287431, "Total num played games": 63329, "Total num trained steps": 126080, "Timestamp in ms": 1700576454235, "logtype": "training_step"}
{"Avg objective": 21.58249999999998, "Games time in secs": 189.14460884965956, "Avg game time in secs": 0.9940773976268247, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 63360, "Total num trained steps": 126148, "Timestamp in ms": 1700576487346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913848872619404, "Avg loss": 0.7216269262135029, "Avg value loss": 0.42886759465909563, "Avg policy loss": 0.292759338975884, "Total num played games": 63377, "Total num trained steps": 126208, "Timestamp in ms": 1700576515233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918801734331888, "Avg loss": 0.5757851274684072, "Avg value loss": 0.29951512144180015, "Avg policy loss": 0.27627000445500016, "Total num played games": 63425, "Total num trained steps": 126336, "Timestamp in ms": 1700576579176, "logtype": "training_step"}
{"Total num played games": 63474, "Total num trained steps": 126365, "Timestamp in ms": 1700576697773, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.636523437500003}
{"Avg objective": 21.888281249999988, "Games time in secs": 211.88623717427254, "Avg game time in secs": 1.0516806329105748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 63488, "Total num trained steps": 126365, "Timestamp in ms": 1700576699232, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99085356254526, "Avg loss": 0.7030844998080283, "Avg value loss": 0.41100519557949156, "Avg policy loss": 0.2920792846707627, "Total num played games": 63522, "Total num trained steps": 126464, "Timestamp in ms": 1700576747168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913638508730533, "Avg loss": 0.4700298130046576, "Avg value loss": 0.18969645991455764, "Avg policy loss": 0.28033334971405566, "Total num played games": 63570, "Total num trained steps": 126592, "Timestamp in ms": 1700576806626, "logtype": "training_step"}
{"Avg objective": 20.569062499999987, "Games time in secs": 126.74845398776233, "Avg game time in secs": 0.9854804446804337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.58}, "Total num played games": 63616, "Total num trained steps": 126633, "Timestamp in ms": 1700576825981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918733691722468, "Avg loss": 0.437661875737831, "Avg value loss": 0.1654289964644704, "Avg policy loss": 0.27223287941887975, "Total num played games": 63618, "Total num trained steps": 126720, "Timestamp in ms": 1700576868198, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908811250274665, "Avg loss": 0.6337653547525406, "Avg value loss": 0.3599640793981962, "Avg policy loss": 0.27380128065124154, "Total num played games": 63714, "Total num trained steps": 126848, "Timestamp in ms": 1700576927823, "logtype": "training_step"}
{"Avg objective": 20.26796874999999, "Games time in secs": 135.3516431748867, "Avg game time in secs": 0.9445791944890516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 63744, "Total num trained steps": 126918, "Timestamp in ms": 1700576961333, "logtype": "played_game"}
{"Total num played games": 63765, "Total num trained steps": 126966, "Timestamp in ms": 1700577056923, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5431640625}
{"Ratio train steps to played games": 1.9897983169573599, "Avg loss": 0.640039294026792, "Avg value loss": 0.35806339979171753, "Avg policy loss": 0.2819758950499818, "Total num played games": 63813, "Total num trained steps": 126976, "Timestamp in ms": 1700577061693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991819848620187, "Avg loss": 0.5237452099099755, "Avg value loss": 0.24145623607910238, "Avg policy loss": 0.28228897566441447, "Total num played games": 63813, "Total num trained steps": 127104, "Timestamp in ms": 1700577119220, "logtype": "training_step"}
{"Avg objective": 21.26414062499999, "Games time in secs": 205.16507259197533, "Avg game time in secs": 1.0498842560482444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 63872, "Total num trained steps": 127212, "Timestamp in ms": 1700577166498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908150651707897, "Avg loss": 0.7434967588633299, "Avg value loss": 0.45403263077605516, "Avg policy loss": 0.28946413181256503, "Total num played games": 63909, "Total num trained steps": 127232, "Timestamp in ms": 1700577175331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913222946667293, "Avg loss": 0.5277304209303111, "Avg value loss": 0.23201503106974997, "Avg policy loss": 0.2957153827883303, "Total num played games": 63957, "Total num trained steps": 127360, "Timestamp in ms": 1700577234316, "logtype": "training_step"}
{"Avg objective": 21.115078124999982, "Games time in secs": 88.83165926486254, "Avg game time in secs": 0.990101664850954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 64000, "Total num trained steps": 127407, "Timestamp in ms": 1700577255330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991828763377861, "Avg loss": 0.5514424503780901, "Avg value loss": 0.2623533518926706, "Avg policy loss": 0.2890890978742391, "Total num played games": 64005, "Total num trained steps": 127488, "Timestamp in ms": 1700577293549, "logtype": "training_step"}
{"Total num played games": 64053, "Total num trained steps": 127568, "Timestamp in ms": 1700577397564, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.50328125}
{"Ratio train steps to played games": 1.990842576558868, "Avg loss": 0.6479572108946741, "Avg value loss": 0.3613789998635184, "Avg policy loss": 0.2865782101871446, "Total num played games": 64101, "Total num trained steps": 127616, "Timestamp in ms": 1700577420897, "logtype": "training_step"}
{"Avg objective": 21.04085937499999, "Games time in secs": 202.4111756850034, "Avg game time in secs": 0.9147541674756212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.44, "agent_stopped_0": 0.59}, "Total num played games": 64128, "Total num trained steps": 127693, "Timestamp in ms": 1700577457741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913172252533125, "Avg loss": 0.49934322014451027, "Avg value loss": 0.21901589422486722, "Avg policy loss": 0.2803273219615221, "Total num played games": 64150, "Total num trained steps": 127744, "Timestamp in ms": 1700577482929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918067259614636, "Avg loss": 0.5511148045770824, "Avg value loss": 0.2596670061466284, "Avg policy loss": 0.2914477940648794, "Total num played games": 64199, "Total num trained steps": 127872, "Timestamp in ms": 1700577544325, "logtype": "training_step"}
{"Avg objective": 21.459843749999987, "Games time in secs": 136.57631384022534, "Avg game time in secs": 0.938361594977323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 64256, "Total num trained steps": 127984, "Timestamp in ms": 1700577594317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908079944008088, "Avg loss": 0.5169738214462996, "Avg value loss": 0.2403688694757875, "Avg policy loss": 0.27660495648160577, "Total num played games": 64295, "Total num trained steps": 128000, "Timestamp in ms": 1700577601466, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913277279579753, "Avg loss": 0.6972068420145661, "Avg value loss": 0.4096621877979487, "Avg policy loss": 0.28754465258680284, "Total num played games": 64343, "Total num trained steps": 128128, "Timestamp in ms": 1700577660951, "logtype": "training_step"}
{"Total num played games": 64343, "Total num trained steps": 128169, "Timestamp in ms": 1700577736754, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.422656250000003}
{"Avg objective": 21.914062499999986, "Games time in secs": 144.55123842693865, "Avg game time in secs": 0.9544079027255066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 64384, "Total num trained steps": 128173, "Timestamp in ms": 1700577738869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918156264074172, "Avg loss": 0.5566971998196095, "Avg value loss": 0.2697076382464729, "Avg policy loss": 0.2869895586045459, "Total num played games": 64391, "Total num trained steps": 128256, "Timestamp in ms": 1700577776153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990835362166018, "Avg loss": 0.5304237983655185, "Avg value loss": 0.2524252106086351, "Avg policy loss": 0.2779985865345225, "Total num played games": 64487, "Total num trained steps": 128384, "Timestamp in ms": 1700577834307, "logtype": "training_step"}
{"Avg objective": 20.798749999999988, "Games time in secs": 132.34952419996262, "Avg game time in secs": 1.0504298407031456, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 64512, "Total num trained steps": 128465, "Timestamp in ms": 1700577871218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991322672616834, "Avg loss": 0.6180226670112461, "Avg value loss": 0.3331514061719645, "Avg policy loss": 0.28487125621177256, "Total num played games": 64536, "Total num trained steps": 128512, "Timestamp in ms": 1700577896265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918091168091168, "Avg loss": 0.4821223688777536, "Avg value loss": 0.19497436843812466, "Avg policy loss": 0.28714799613226205, "Total num played games": 64584, "Total num trained steps": 128640, "Timestamp in ms": 1700577962612, "logtype": "training_step"}
{"Avg objective": 21.32007812499998, "Games time in secs": 147.43493347987533, "Avg game time in secs": 1.0000646028638585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 64640, "Total num trained steps": 128754, "Timestamp in ms": 1700578018654, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908317872603587, "Avg loss": 0.5941541392821819, "Avg value loss": 0.3025320911256131, "Avg policy loss": 0.2916220434708521, "Total num played games": 64680, "Total num trained steps": 128768, "Timestamp in ms": 1700578025124, "logtype": "training_step"}
{"Total num played games": 64680, "Total num trained steps": 128772, "Timestamp in ms": 1700578084890, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.701328125000003}
{"Ratio train steps to played games": 1.9913484118155975, "Avg loss": 0.6109606402460486, "Avg value loss": 0.31414981989655644, "Avg policy loss": 0.29681082256138325, "Total num played games": 64728, "Total num trained steps": 128896, "Timestamp in ms": 1700578147194, "logtype": "training_step"}
{"Avg objective": 20.283359374999982, "Games time in secs": 154.259302649647, "Avg game time in secs": 0.8792977643606719, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 64768, "Total num trained steps": 128947, "Timestamp in ms": 1700578172913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918333950845992, "Avg loss": 0.4954523639753461, "Avg value loss": 0.21470942106680013, "Avg policy loss": 0.28074294375255704, "Total num played games": 64776, "Total num trained steps": 129024, "Timestamp in ms": 1700578210314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908129605080618, "Avg loss": 0.6002432277891785, "Avg value loss": 0.3143324965785723, "Avg policy loss": 0.285910738282837, "Total num played games": 64874, "Total num trained steps": 129152, "Timestamp in ms": 1700578271816, "logtype": "training_step"}
{"Avg objective": 21.829453124999986, "Games time in secs": 140.99458167888224, "Avg game time in secs": 0.9383240341994679, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 64896, "Total num trained steps": 129238, "Timestamp in ms": 1700578313908, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912972490065002, "Avg loss": 0.617253583855927, "Avg value loss": 0.30717457114951685, "Avg policy loss": 0.3100790084572509, "Total num played games": 64922, "Total num trained steps": 129280, "Timestamp in ms": 1700578334291, "logtype": "training_step"}
{"Total num played games": 64970, "Total num trained steps": 129372, "Timestamp in ms": 1700578408277, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5578515625}
{"Ratio train steps to played games": 1.9903257559445078, "Avg loss": 0.7813163723330945, "Avg value loss": 0.47530073730740696, "Avg policy loss": 0.30601563781965524, "Total num played games": 65018, "Total num trained steps": 129408, "Timestamp in ms": 1700578427696, "logtype": "training_step"}
{"Avg objective": 22.08859374999998, "Games time in secs": 172.9489626251161, "Avg game time in secs": 0.9838159639184596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.67}, "Total num played games": 65024, "Total num trained steps": 129526, "Timestamp in ms": 1700578486857, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908247010727569, "Avg loss": 0.4627188553567976, "Avg value loss": 0.16035975882550701, "Avg policy loss": 0.3023590949596837, "Total num played games": 65066, "Total num trained steps": 129536, "Timestamp in ms": 1700578491508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913382682679608, "Avg loss": 0.6767443201970309, "Avg value loss": 0.3794432143040467, "Avg policy loss": 0.2973011090653017, "Total num played games": 65114, "Total num trained steps": 129664, "Timestamp in ms": 1700578554553, "logtype": "training_step"}
{"Avg objective": 21.384374999999988, "Games time in secs": 94.73635363206267, "Avg game time in secs": 0.9492618109943578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 65152, "Total num trained steps": 129719, "Timestamp in ms": 1700578581593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918203861146067, "Avg loss": 0.56266898161266, "Avg value loss": 0.26761996280401945, "Avg policy loss": 0.2950490174116567, "Total num played games": 65162, "Total num trained steps": 129792, "Timestamp in ms": 1700578617373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908670201354624, "Avg loss": 0.5325349099002779, "Avg value loss": 0.24689874990144745, "Avg policy loss": 0.28563616157043725, "Total num played games": 65258, "Total num trained steps": 129920, "Timestamp in ms": 1700578680177, "logtype": "training_step"}
{"Total num played games": 65258, "Total num trained steps": 129973, "Timestamp in ms": 1700578782236, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.811953125000002}
{"Avg objective": 21.594531249999985, "Games time in secs": 202.19956325925887, "Avg game time in secs": 0.9120170557871461, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.52, "agent_stopped_0": 0.5}, "Total num played games": 65280, "Total num trained steps": 129976, "Timestamp in ms": 1700578783793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99134842127829, "Avg loss": 0.587513861944899, "Avg value loss": 0.28967613220447674, "Avg policy loss": 0.29783772584050894, "Total num played games": 65306, "Total num trained steps": 130048, "Timestamp in ms": 1700578819088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918444165621079, "Avg loss": 0.6337960362434387, "Avg value loss": 0.3462727273872588, "Avg policy loss": 0.2875233131926507, "Total num played games": 65354, "Total num trained steps": 130176, "Timestamp in ms": 1700578884788, "logtype": "training_step"}
{"Avg objective": 21.287890624999985, "Games time in secs": 159.7598184850067, "Avg game time in secs": 1.0042365763656562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.64, "agent_stopped_0": 0.44}, "Total num played games": 65408, "Total num trained steps": 130294, "Timestamp in ms": 1700578943553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908785332314745, "Avg loss": 0.6061969120055437, "Avg value loss": 0.32852056456613354, "Avg policy loss": 0.27767634647898376, "Total num played games": 65450, "Total num trained steps": 130304, "Timestamp in ms": 1700578948460, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913890500473297, "Avg loss": 0.6169843729585409, "Avg value loss": 0.3325706609466579, "Avg policy loss": 0.28441371745429933, "Total num played games": 65498, "Total num trained steps": 130432, "Timestamp in ms": 1700579013314, "logtype": "training_step"}
{"Avg objective": 21.12499999999999, "Games time in secs": 97.08602010086179, "Avg game time in secs": 0.91032328120491, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 65536, "Total num trained steps": 130488, "Timestamp in ms": 1700579040639, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918683062276874, "Avg loss": 0.4358137028757483, "Avg value loss": 0.1548114096513018, "Avg policy loss": 0.28100229625124484, "Total num played games": 65546, "Total num trained steps": 130560, "Timestamp in ms": 1700579076439, "logtype": "training_step"}
{"Total num played games": 65546, "Total num trained steps": 130574, "Timestamp in ms": 1700579163298, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.250429687500002}
{"Ratio train steps to played games": 1.9909355433341966, "Avg loss": 0.510460591642186, "Avg value loss": 0.22329423652263358, "Avg policy loss": 0.28716635366436094, "Total num played games": 65641, "Total num trained steps": 130688, "Timestamp in ms": 1700579219223, "logtype": "training_step"}
{"Avg objective": 21.245468749999993, "Games time in secs": 222.48971305973828, "Avg game time in secs": 1.0827445337636163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 65664, "Total num trained steps": 130774, "Timestamp in ms": 1700579263129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914142182980668, "Avg loss": 0.616649717791006, "Avg value loss": 0.3260328336909879, "Avg policy loss": 0.2906168858753517, "Total num played games": 65690, "Total num trained steps": 130816, "Timestamp in ms": 1700579284078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918920563448843, "Avg loss": 0.5631736661307514, "Avg value loss": 0.26690693738055415, "Avg policy loss": 0.29626672284211963, "Total num played games": 65738, "Total num trained steps": 130944, "Timestamp in ms": 1700579348792, "logtype": "training_step"}
{"Avg objective": 21.655156249999983, "Games time in secs": 146.1246385164559, "Avg game time in secs": 1.0843605175468838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 65792, "Total num trained steps": 131062, "Timestamp in ms": 1700579409254, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909469271197253, "Avg loss": 0.6342246369458735, "Avg value loss": 0.3430423552345019, "Avg policy loss": 0.291182282846421, "Total num played games": 65834, "Total num trained steps": 131072, "Timestamp in ms": 1700579414359, "logtype": "training_step"}
{"Total num played games": 65882, "Total num trained steps": 131176, "Timestamp in ms": 1700579525566, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.036640625}
{"Avg objective": 20.684999999999988, "Games time in secs": 118.45547642372549, "Avg game time in secs": 0.9330808439699467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 65920, "Total num trained steps": 131178, "Timestamp in ms": 1700579527709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899893826785986, "Avg loss": 1.0055010081268847, "Avg value loss": 0.7062971187697258, "Avg policy loss": 0.29920388746540993, "Total num played games": 65930, "Total num trained steps": 131200, "Timestamp in ms": 1700579538101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919308357348704, "Avg loss": 0.5752851562574506, "Avg value loss": 0.2729409016028512, "Avg policy loss": 0.30234425351954997, "Total num played games": 65930, "Total num trained steps": 131328, "Timestamp in ms": 1700579603453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909581074122316, "Avg loss": 0.4965158945415169, "Avg value loss": 0.21450614125933498, "Avg policy loss": 0.2820097504882142, "Total num played games": 66026, "Total num trained steps": 131456, "Timestamp in ms": 1700579664970, "logtype": "training_step"}
{"Avg objective": 20.059218749999985, "Games time in secs": 179.26791130006313, "Avg game time in secs": 0.9769575748214265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 66048, "Total num trained steps": 131541, "Timestamp in ms": 1700579706977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914641159911615, "Avg loss": 0.5667267444077879, "Avg value loss": 0.27858937822747976, "Avg policy loss": 0.2881373619893566, "Total num played games": 66074, "Total num trained steps": 131584, "Timestamp in ms": 1700579727821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919391427966486, "Avg loss": 0.5286723726894706, "Avg value loss": 0.24081063197809272, "Avg policy loss": 0.2878617395181209, "Total num played games": 66122, "Total num trained steps": 131712, "Timestamp in ms": 1700579790281, "logtype": "training_step"}
{"Total num played games": 66170, "Total num trained steps": 131777, "Timestamp in ms": 1700579874622, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.150859375}
{"Avg objective": 21.27093749999998, "Games time in secs": 168.83948466554284, "Avg game time in secs": 0.9340879435476381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 66176, "Total num trained steps": 131778, "Timestamp in ms": 1700579875817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990999426137908, "Avg loss": 0.7194229607703164, "Avg value loss": 0.43511716526700184, "Avg policy loss": 0.28430578927509487, "Total num played games": 66218, "Total num trained steps": 131840, "Timestamp in ms": 1700579905531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914888479763377, "Avg loss": 0.4953130728099495, "Avg value loss": 0.2158376258739736, "Avg policy loss": 0.27947544772177935, "Total num played games": 66266, "Total num trained steps": 131968, "Timestamp in ms": 1700579968809, "logtype": "training_step"}
{"Avg objective": 21.93804687499999, "Games time in secs": 120.47508068569005, "Avg game time in secs": 0.8825188291521044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 66304, "Total num trained steps": 132023, "Timestamp in ms": 1700579996292, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919775612992732, "Avg loss": 0.5170226003974676, "Avg value loss": 0.23430119425756857, "Avg policy loss": 0.28272140957415104, "Total num played games": 66314, "Total num trained steps": 132096, "Timestamp in ms": 1700580031658, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910103900015057, "Avg loss": 0.5764337589498609, "Avg value loss": 0.292694258474512, "Avg policy loss": 0.28373950719833374, "Total num played games": 66410, "Total num trained steps": 132224, "Timestamp in ms": 1700580094485, "logtype": "training_step"}
{"Avg objective": 21.55257812499999, "Games time in secs": 140.14420070499182, "Avg game time in secs": 1.0471907788596582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 66432, "Total num trained steps": 132310, "Timestamp in ms": 1700580136437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915134370579914, "Avg loss": 0.5953908048104495, "Avg value loss": 0.29512610429082997, "Avg policy loss": 0.3002647057874128, "Total num played games": 66458, "Total num trained steps": 132352, "Timestamp in ms": 1700580156981, "logtype": "training_step"}
{"Total num played games": 66458, "Total num trained steps": 132379, "Timestamp in ms": 1700580238096, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.820859375}
{"Ratio train steps to played games": 1.99198568550206, "Avg loss": 0.49511063378304243, "Avg value loss": 0.19670366987702437, "Avg policy loss": 0.298406966147013, "Total num played games": 66506, "Total num trained steps": 132480, "Timestamp in ms": 1700580289821, "logtype": "training_step"}
{"Avg objective": 21.757031249999983, "Games time in secs": 212.38031412102282, "Avg game time in secs": 0.9952870088018244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 66560, "Total num trained steps": 132599, "Timestamp in ms": 1700580348817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991006411122622, "Avg loss": 0.7162865709979087, "Avg value loss": 0.4152281174319796, "Avg policy loss": 0.3010584570001811, "Total num played games": 66603, "Total num trained steps": 132608, "Timestamp in ms": 1700580352929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914781251875413, "Avg loss": 0.8114308107178658, "Avg value loss": 0.4993385632697027, "Avg policy loss": 0.3120922524249181, "Total num played games": 66652, "Total num trained steps": 132736, "Timestamp in ms": 1700580417410, "logtype": "training_step"}
{"Avg objective": 22.133906249999985, "Games time in secs": 99.40206572785974, "Avg game time in secs": 0.9064038496871945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 66688, "Total num trained steps": 132794, "Timestamp in ms": 1700580448220, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919640179910045, "Avg loss": 0.6914945875760168, "Avg value loss": 0.38747170093120076, "Avg policy loss": 0.3040228955214843, "Total num played games": 66700, "Total num trained steps": 132864, "Timestamp in ms": 1700580484244, "logtype": "training_step"}
{"Total num played games": 66749, "Total num trained steps": 132980, "Timestamp in ms": 1700580606579, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.2689453125}
{"Ratio train steps to played games": 1.9909726484722368, "Avg loss": 0.6770286404062063, "Avg value loss": 0.3701696017815266, "Avg policy loss": 0.306859043543227, "Total num played games": 66797, "Total num trained steps": 132992, "Timestamp in ms": 1700580612904, "logtype": "training_step"}
{"Avg objective": 22.71609374999999, "Games time in secs": 209.55575606785715, "Avg game time in secs": 0.9409880808379967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 66816, "Total num trained steps": 133083, "Timestamp in ms": 1700580657775, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914578502505798, "Avg loss": 0.7677123050671071, "Avg value loss": 0.4612152792396955, "Avg policy loss": 0.30649702122900635, "Total num played games": 66845, "Total num trained steps": 133120, "Timestamp in ms": 1700580674807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919125781086495, "Avg loss": 0.5053394881542772, "Avg value loss": 0.21140740215196274, "Avg policy loss": 0.2939320858567953, "Total num played games": 66894, "Total num trained steps": 133248, "Timestamp in ms": 1700580737261, "logtype": "training_step"}
{"Avg objective": 21.293437499999982, "Games time in secs": 138.60962712205946, "Avg game time in secs": 0.9497733339812839, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 66944, "Total num trained steps": 133373, "Timestamp in ms": 1700580796385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909688013136289, "Avg loss": 0.5628875829279423, "Avg value loss": 0.27670006404514425, "Avg policy loss": 0.28618751955218613, "Total num played games": 66990, "Total num trained steps": 133376, "Timestamp in ms": 1700580797748, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914378197765479, "Avg loss": 0.7609272010158747, "Avg value loss": 0.47111268670414574, "Avg policy loss": 0.2898145163198933, "Total num played games": 67039, "Total num trained steps": 133504, "Timestamp in ms": 1700580863285, "logtype": "training_step"}
{"Avg objective": 22.264843749999994, "Games time in secs": 98.27160919643939, "Avg game time in secs": 0.820946444539004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.41}, "Total num played games": 67072, "Total num trained steps": 133568, "Timestamp in ms": 1700580894657, "logtype": "played_game"}
{"Total num played games": 67087, "Total num trained steps": 133580, "Timestamp in ms": 1700580957511, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8546484375}
{"Ratio train steps to played games": 1.9904967602591792, "Avg loss": 0.7177622381132096, "Avg value loss": 0.4289136734441854, "Avg policy loss": 0.28884856798686087, "Total num played games": 67135, "Total num trained steps": 133632, "Timestamp in ms": 1700580984518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917506737942434, "Avg loss": 0.3598960533272475, "Avg value loss": 0.07730634656036273, "Avg policy loss": 0.28258970577735454, "Total num played games": 67155, "Total num trained steps": 133760, "Timestamp in ms": 1700581048220, "logtype": "training_step"}
{"Avg objective": 21.442890624999983, "Games time in secs": 199.37161313928664, "Avg game time in secs": 1.0432071706891293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 67200, "Total num trained steps": 133855, "Timestamp in ms": 1700581094029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914622718686321, "Avg loss": 0.6846502227708697, "Avg value loss": 0.4092175197729375, "Avg policy loss": 0.27543270017486066, "Total num played games": 67231, "Total num trained steps": 133888, "Timestamp in ms": 1700581109113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918995243757431, "Avg loss": 0.4643342688214034, "Avg value loss": 0.1912569420528598, "Avg policy loss": 0.273077325662598, "Total num played games": 67280, "Total num trained steps": 134016, "Timestamp in ms": 1700581169777, "logtype": "training_step"}
{"Avg objective": 21.013281249999988, "Games time in secs": 93.04029373265803, "Avg game time in secs": 0.939894507304416, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 67328, "Total num trained steps": 134053, "Timestamp in ms": 1700581187069, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923362542700134, "Avg loss": 0.57831209897995, "Avg value loss": 0.30398144404171035, "Avg policy loss": 0.27433065057266504, "Total num played games": 67330, "Total num trained steps": 134144, "Timestamp in ms": 1700581232160, "logtype": "training_step"}
{"Total num played games": 67378, "Total num trained steps": 134180, "Timestamp in ms": 1700581312528, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6619921875}
{"Ratio train steps to played games": 1.9913979770414973, "Avg loss": 0.7094140045810491, "Avg value loss": 0.4173294933862053, "Avg policy loss": 0.2920845135813579, "Total num played games": 67426, "Total num trained steps": 134272, "Timestamp in ms": 1700581356273, "logtype": "training_step"}
{"Avg objective": 22.238046874999988, "Games time in secs": 202.1004323847592, "Avg game time in secs": 0.9359116459963843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 67456, "Total num trained steps": 134342, "Timestamp in ms": 1700581389170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991878353143433, "Avg loss": 0.6527853949228302, "Avg value loss": 0.3756434091483243, "Avg policy loss": 0.27714199444744736, "Total num played games": 67474, "Total num trained steps": 134400, "Timestamp in ms": 1700581417055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923580462664021, "Avg loss": 0.6232759242411703, "Avg value loss": 0.346385996817844, "Avg policy loss": 0.27688992489129305, "Total num played games": 67522, "Total num trained steps": 134528, "Timestamp in ms": 1700581479896, "logtype": "training_step"}
{"Avg objective": 20.775546874999982, "Games time in secs": 140.967485005036, "Avg game time in secs": 0.9982437499566004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 67584, "Total num trained steps": 134629, "Timestamp in ms": 1700581530137, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991422402318909, "Avg loss": 0.6028060591779649, "Avg value loss": 0.32471091489424, "Avg policy loss": 0.2780951450113207, "Total num played games": 67618, "Total num trained steps": 134656, "Timestamp in ms": 1700581543594, "logtype": "training_step"}
{"Total num played games": 67668, "Total num trained steps": 134782, "Timestamp in ms": 1700581666395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.838398437499997}
{"Ratio train steps to played games": 1.991724790164322, "Avg loss": 0.5535947824828327, "Avg value loss": 0.2783089517906774, "Avg policy loss": 0.2752858316525817, "Total num played games": 67671, "Total num trained steps": 134784, "Timestamp in ms": 1700581667621, "logtype": "training_step"}
{"Avg objective": 20.55210937499999, "Games time in secs": 138.35949698649347, "Avg game time in secs": 0.9144960100384196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 67712, "Total num trained steps": 134785, "Timestamp in ms": 1700581668497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992320869513852, "Avg loss": 0.4479747505392879, "Avg value loss": 0.17210978010552935, "Avg policy loss": 0.27586497203446925, "Total num played games": 67716, "Total num trained steps": 134912, "Timestamp in ms": 1700581728915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913585890610945, "Avg loss": 0.6626215032301843, "Avg value loss": 0.3868775638693478, "Avg policy loss": 0.2757439393317327, "Total num played games": 67813, "Total num trained steps": 135040, "Timestamp in ms": 1700581789160, "logtype": "training_step"}
{"Avg objective": 21.15281249999999, "Games time in secs": 156.53865240514278, "Avg game time in secs": 0.8898760270385537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.49, "agent_stopped_0": 0.52}, "Total num played games": 67840, "Total num trained steps": 135116, "Timestamp in ms": 1700581825036, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917628162621752, "Avg loss": 0.4731562128290534, "Avg value loss": 0.19835665114806034, "Avg policy loss": 0.2747995628742501, "Total num played games": 67863, "Total num trained steps": 135168, "Timestamp in ms": 1700581850519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922252326540228, "Avg loss": 0.4913013319019228, "Avg value loss": 0.2329586437845137, "Avg policy loss": 0.2583426858764142, "Total num played games": 67912, "Total num trained steps": 135296, "Timestamp in ms": 1700581912108, "logtype": "training_step"}
{"Total num played games": 67962, "Total num trained steps": 135385, "Timestamp in ms": 1700581972610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.364101562500004}
{"Avg objective": 20.979453124999985, "Games time in secs": 148.79232470318675, "Avg game time in secs": 1.0272754993638955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 67968, "Total num trained steps": 135386, "Timestamp in ms": 1700581973829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912365828554623, "Avg loss": 0.696853123838082, "Avg value loss": 0.4209639309265185, "Avg policy loss": 0.2758891909616068, "Total num played games": 68010, "Total num trained steps": 135424, "Timestamp in ms": 1700581993111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917129507185047, "Avg loss": 0.5750804755371064, "Avg value loss": 0.2995119870174676, "Avg policy loss": 0.27556848991662264, "Total num played games": 68058, "Total num trained steps": 135552, "Timestamp in ms": 1700582063344, "logtype": "training_step"}
{"Avg objective": 22.096484374999985, "Games time in secs": 119.31928251497447, "Avg game time in secs": 0.8952349353930913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 68096, "Total num trained steps": 135606, "Timestamp in ms": 1700582093148, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921886471089185, "Avg loss": 0.5117730498313904, "Avg value loss": 0.23153887171065435, "Avg policy loss": 0.28023417410440743, "Total num played games": 68106, "Total num trained steps": 135680, "Timestamp in ms": 1700582132815, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912465910090613, "Avg loss": 0.6149252993054688, "Avg value loss": 0.3375419447256718, "Avg policy loss": 0.2773833549581468, "Total num played games": 68202, "Total num trained steps": 135808, "Timestamp in ms": 1700582200277, "logtype": "training_step"}
{"Avg objective": 21.342812499999987, "Games time in secs": 153.03789104148746, "Avg game time in secs": 1.0151653033681214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 68224, "Total num trained steps": 135893, "Timestamp in ms": 1700582246186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917362637362637, "Avg loss": 0.7402096455916762, "Avg value loss": 0.4572745020268485, "Avg policy loss": 0.2829351578839123, "Total num played games": 68250, "Total num trained steps": 135936, "Timestamp in ms": 1700582270022, "logtype": "training_step"}
{"Total num played games": 68250, "Total num trained steps": 135987, "Timestamp in ms": 1700582362834, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.239296875}
{"Ratio train steps to played games": 1.9922106064599256, "Avg loss": 0.5231103275436908, "Avg value loss": 0.22917534440057352, "Avg policy loss": 0.2939349856460467, "Total num played games": 68298, "Total num trained steps": 136064, "Timestamp in ms": 1700582402475, "logtype": "training_step"}
{"Avg objective": 22.564843749999987, "Games time in secs": 215.12056844122708, "Avg game time in secs": 0.9839222889131634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 68352, "Total num trained steps": 136181, "Timestamp in ms": 1700582461307, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912857853028043, "Avg loss": 0.591992829926312, "Avg value loss": 0.3026227547088638, "Avg policy loss": 0.289370070095174, "Total num played games": 68394, "Total num trained steps": 136192, "Timestamp in ms": 1700582467059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917303449585786, "Avg loss": 0.6243791689630598, "Avg value loss": 0.3343539031338878, "Avg policy loss": 0.2900252687977627, "Total num played games": 68443, "Total num trained steps": 136320, "Timestamp in ms": 1700582535167, "logtype": "training_step"}
{"Avg objective": 21.540624999999988, "Games time in secs": 106.71227109245956, "Avg game time in secs": 1.0144797524699243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.63}, "Total num played games": 68480, "Total num trained steps": 136376, "Timestamp in ms": 1700582568019, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922033551853529, "Avg loss": 0.5156200677156448, "Avg value loss": 0.2332092643773649, "Avg policy loss": 0.28241080429870635, "Total num played games": 68491, "Total num trained steps": 136448, "Timestamp in ms": 1700582609524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912811465729656, "Avg loss": 0.46730801183730364, "Avg value loss": 0.19346128340112045, "Avg policy loss": 0.2738467310555279, "Total num played games": 68587, "Total num trained steps": 136576, "Timestamp in ms": 1700582681284, "logtype": "training_step"}
{"Total num played games": 68587, "Total num trained steps": 136590, "Timestamp in ms": 1700582750766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.670234375}
{"Avg objective": 20.208593749999988, "Games time in secs": 184.2274097111076, "Avg game time in secs": 0.9378616221802076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 68608, "Total num trained steps": 136592, "Timestamp in ms": 1700582752247, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917534785459314, "Avg loss": 0.5788031594129279, "Avg value loss": 0.3003055836597923, "Avg policy loss": 0.2784975765971467, "Total num played games": 68635, "Total num trained steps": 136704, "Timestamp in ms": 1700582816768, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99221059068474, "Avg loss": 0.47705085447523743, "Avg value loss": 0.20733863970963284, "Avg policy loss": 0.26971221319399774, "Total num played games": 68683, "Total num trained steps": 136832, "Timestamp in ms": 1700582883958, "logtype": "training_step"}
{"Avg objective": 20.712109374999983, "Games time in secs": 190.10706279985607, "Avg game time in secs": 0.9910441010579234, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 68736, "Total num trained steps": 136951, "Timestamp in ms": 1700582942361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991305485686038, "Avg loss": 0.5176820285851136, "Avg value loss": 0.24284366521169432, "Avg policy loss": 0.27483836258761585, "Total num played games": 68779, "Total num trained steps": 136960, "Timestamp in ms": 1700582946439, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917764830662386, "Avg loss": 0.5979651962406933, "Avg value loss": 0.31030560325598344, "Avg policy loss": 0.28765959246084094, "Total num played games": 68827, "Total num trained steps": 137088, "Timestamp in ms": 1700583008839, "logtype": "training_step"}
{"Avg objective": 20.97343749999998, "Games time in secs": 93.70108990557492, "Avg game time in secs": 0.8620717764715664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 68864, "Total num trained steps": 137144, "Timestamp in ms": 1700583036062, "logtype": "played_game"}
{"Total num played games": 68875, "Total num trained steps": 137191, "Timestamp in ms": 1700583071185, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2291015625}
{"Ratio train steps to played games": 1.9908593647983983, "Avg loss": 0.8787592421285808, "Avg value loss": 0.5926346008491237, "Avg policy loss": 0.2861246506217867, "Total num played games": 68923, "Total num trained steps": 137216, "Timestamp in ms": 1700583084360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913296892897014, "Avg loss": 0.43455967819318175, "Avg value loss": 0.1567229786887765, "Avg policy loss": 0.2778366992715746, "Total num played games": 68971, "Total num trained steps": 137344, "Timestamp in ms": 1700583147177, "logtype": "training_step"}
{"Avg objective": 22.726406249999982, "Games time in secs": 153.71509442292154, "Avg game time in secs": 0.9691721665731166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 68992, "Total num trained steps": 137431, "Timestamp in ms": 1700583189777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917993595966328, "Avg loss": 0.52183275250718, "Avg value loss": 0.24515646605868824, "Avg policy loss": 0.27667628426570445, "Total num played games": 69019, "Total num trained steps": 137472, "Timestamp in ms": 1700583209236, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922395320553656, "Avg loss": 0.4705350298900157, "Avg value loss": 0.19465157322701998, "Avg policy loss": 0.2758834612322971, "Total num played games": 69068, "Total num trained steps": 137600, "Timestamp in ms": 1700583271008, "logtype": "training_step"}
{"Avg objective": 22.03203124999998, "Games time in secs": 140.0155220553279, "Avg game time in secs": 0.9424940579629038, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 69120, "Total num trained steps": 137721, "Timestamp in ms": 1700583329793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912961758114653, "Avg loss": 0.48639252327848226, "Avg value loss": 0.2140914709016215, "Avg policy loss": 0.27230105036869645, "Total num played games": 69165, "Total num trained steps": 137728, "Timestamp in ms": 1700583333012, "logtype": "training_step"}
{"Total num played games": 69165, "Total num trained steps": 137794, "Timestamp in ms": 1700583381654, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.421445312500005}
{"Ratio train steps to played games": 1.9917645529019115, "Avg loss": 0.47310430742800236, "Avg value loss": 0.203492804459529, "Avg policy loss": 0.26961150171700865, "Total num played games": 69213, "Total num trained steps": 137856, "Timestamp in ms": 1700583411659, "logtype": "training_step"}
{"Avg objective": 20.90531249999999, "Games time in secs": 110.94327626749873, "Avg game time in secs": 0.8192115998390364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 69248, "Total num trained steps": 137916, "Timestamp in ms": 1700583440737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922322807929427, "Avg loss": 0.4658788525266573, "Avg value loss": 0.19835467089433223, "Avg policy loss": 0.2675241781398654, "Total num played games": 69261, "Total num trained steps": 137984, "Timestamp in ms": 1700583474554, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913202704845943, "Avg loss": 0.4950432365294546, "Avg value loss": 0.22273060560110025, "Avg policy loss": 0.2723126329947263, "Total num played games": 69357, "Total num trained steps": 138112, "Timestamp in ms": 1700583536007, "logtype": "training_step"}
{"Avg objective": 21.290468749999988, "Games time in secs": 141.964977664873, "Avg game time in secs": 1.0329151442856528, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 69376, "Total num trained steps": 138208, "Timestamp in ms": 1700583582702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991715533015402, "Avg loss": 0.60747259715572, "Avg value loss": 0.3153805176843889, "Avg policy loss": 0.2920920802280307, "Total num played games": 69407, "Total num trained steps": 138240, "Timestamp in ms": 1700583598017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921963861493053, "Avg loss": 0.48637225199490786, "Avg value loss": 0.20204586203908548, "Avg policy loss": 0.2843263896647841, "Total num played games": 69455, "Total num trained steps": 138368, "Timestamp in ms": 1700583660536, "logtype": "training_step"}
{"Total num played games": 69455, "Total num trained steps": 138398, "Timestamp in ms": 1700583685173, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.787851562500002}
{"Avg objective": 20.735468749999978, "Games time in secs": 149.02055274508893, "Avg game time in secs": 0.9435479896346806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 69504, "Total num trained steps": 138495, "Timestamp in ms": 1700583731723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918883934992089, "Avg loss": 0.4761605537496507, "Avg value loss": 0.20042578430729918, "Avg policy loss": 0.2757347677834332, "Total num played games": 69529, "Total num trained steps": 138496, "Timestamp in ms": 1700583732240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916955216160688, "Avg loss": 0.6692418416496366, "Avg value loss": 0.38572986860526726, "Avg policy loss": 0.2835119627416134, "Total num played games": 69601, "Total num trained steps": 138624, "Timestamp in ms": 1700583793622, "logtype": "training_step"}
{"Avg objective": 20.599843749999984, "Games time in secs": 95.0460227560252, "Avg game time in secs": 0.9316629319364438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 69632, "Total num trained steps": 138692, "Timestamp in ms": 1700583826769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992160691467214, "Avg loss": 0.5694099313113838, "Avg value loss": 0.2859971171419602, "Avg policy loss": 0.28341281320899725, "Total num played games": 69649, "Total num trained steps": 138752, "Timestamp in ms": 1700583855317, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926252205977302, "Avg loss": 0.69529162440449, "Avg value loss": 0.4071003296703566, "Avg policy loss": 0.2881912977900356, "Total num played games": 69697, "Total num trained steps": 138880, "Timestamp in ms": 1700583921468, "logtype": "training_step"}
{"Avg objective": 22.294999999999987, "Games time in secs": 142.37830777466297, "Avg game time in secs": 0.8988692193233874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 69760, "Total num trained steps": 138979, "Timestamp in ms": 1700583969147, "logtype": "played_game"}
{"Total num played games": 69793, "Total num trained steps": 139000, "Timestamp in ms": 1700584042829, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0426953125}
{"Ratio train steps to played games": 1.9903780068728523, "Avg loss": 0.6053535377141088, "Avg value loss": 0.33042593506979756, "Avg policy loss": 0.27492759737651795, "Total num played games": 69840, "Total num trained steps": 139008, "Timestamp in ms": 1700584046885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992167924285162, "Avg loss": 0.499756105709821, "Avg value loss": 0.22162874165223911, "Avg policy loss": 0.2781273671425879, "Total num played games": 69841, "Total num trained steps": 139136, "Timestamp in ms": 1700584110848, "logtype": "training_step"}
{"Avg objective": 21.49820312499998, "Games time in secs": 160.53623788803816, "Avg game time in secs": 1.0855473867268302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 69888, "Total num trained steps": 139174, "Timestamp in ms": 1700584129684, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926454806908098, "Avg loss": 0.5638730162754655, "Avg value loss": 0.2909428707207553, "Avg policy loss": 0.27293013397138566, "Total num played games": 69889, "Total num trained steps": 139264, "Timestamp in ms": 1700584172307, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917126282399338, "Avg loss": 0.7592388698831201, "Avg value loss": 0.48129862506175414, "Avg policy loss": 0.2779402416199446, "Total num played games": 69986, "Total num trained steps": 139392, "Timestamp in ms": 1700584235137, "logtype": "training_step"}
{"Avg objective": 22.119531249999987, "Games time in secs": 138.68891792744398, "Avg game time in secs": 0.9242538804828655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 70016, "Total num trained steps": 139462, "Timestamp in ms": 1700584268373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992175229174401, "Avg loss": 0.5092502140905708, "Avg value loss": 0.22389044633018784, "Avg policy loss": 0.28535976784769446, "Total num played games": 70034, "Total num trained steps": 139520, "Timestamp in ms": 1700584296408, "logtype": "training_step"}
{"Total num played games": 70083, "Total num trained steps": 139604, "Timestamp in ms": 1700584350437, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.286015625}
{"Ratio train steps to played games": 1.9912306968387732, "Avg loss": 0.664181413827464, "Avg value loss": 0.37249624909600243, "Avg policy loss": 0.2916851664194837, "Total num played games": 70131, "Total num trained steps": 139648, "Timestamp in ms": 1700584371909, "logtype": "training_step"}
{"Avg objective": 21.390624999999986, "Games time in secs": 153.05659028701484, "Avg game time in secs": 0.9907544069137657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 70144, "Total num trained steps": 139751, "Timestamp in ms": 1700584421429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917069208737657, "Avg loss": 0.5575924140866846, "Avg value loss": 0.2665669917187188, "Avg policy loss": 0.2910254173912108, "Total num played games": 70179, "Total num trained steps": 139776, "Timestamp in ms": 1700584433132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992154014837598, "Avg loss": 0.49633286404423416, "Avg value loss": 0.20359275935334153, "Avg policy loss": 0.2927401016931981, "Total num played games": 70227, "Total num trained steps": 139904, "Timestamp in ms": 1700584496864, "logtype": "training_step"}
{"Avg objective": 21.347265624999974, "Games time in secs": 96.74539032019675, "Avg game time in secs": 1.0578066702437354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.82}, "Total num played games": 70272, "Total num trained steps": 139944, "Timestamp in ms": 1700584518175, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992628957666311, "Avg loss": 0.5322736385278404, "Avg value loss": 0.24128360967733897, "Avg policy loss": 0.2909900314407423, "Total num played games": 70275, "Total num trained steps": 140032, "Timestamp in ms": 1700584560078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917295476829944, "Avg loss": 0.717562282923609, "Avg value loss": 0.4279687041125726, "Avg policy loss": 0.28959358180873096, "Total num played games": 70371, "Total num trained steps": 140160, "Timestamp in ms": 1700584621581, "logtype": "training_step"}
{"Total num played games": 70371, "Total num trained steps": 140205, "Timestamp in ms": 1700584662893, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83515625}
{"Avg objective": 22.985624999999985, "Games time in secs": 146.6016720943153, "Avg game time in secs": 0.930504213552922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 70400, "Total num trained steps": 140207, "Timestamp in ms": 1700584664777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921754072054416, "Avg loss": 0.7348925003316253, "Avg value loss": 0.4346422464295756, "Avg policy loss": 0.30025024933274835, "Total num played games": 70419, "Total num trained steps": 140288, "Timestamp in ms": 1700584705293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926348503554856, "Avg loss": 0.5883071080315858, "Avg value loss": 0.29299698263639584, "Avg policy loss": 0.29531012556981295, "Total num played games": 70467, "Total num trained steps": 140416, "Timestamp in ms": 1700584771147, "logtype": "training_step"}
{"Avg objective": 21.624062499999983, "Games time in secs": 159.95282186940312, "Avg game time in secs": 0.9693379179225303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 70528, "Total num trained steps": 140519, "Timestamp in ms": 1700584824730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917520513583606, "Avg loss": 0.8193398679140955, "Avg value loss": 0.5142071705195121, "Avg policy loss": 0.3051326934946701, "Total num played games": 70563, "Total num trained steps": 140544, "Timestamp in ms": 1700584837415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992196683236323, "Avg loss": 0.535801611142233, "Avg value loss": 0.22665710080764256, "Avg policy loss": 0.3091445134487003, "Total num played games": 70611, "Total num trained steps": 140672, "Timestamp in ms": 1700584900761, "logtype": "training_step"}
{"Avg objective": 20.97632812499998, "Games time in secs": 95.59771358035505, "Avg game time in secs": 1.031761859107064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.73}, "Total num played games": 70656, "Total num trained steps": 140713, "Timestamp in ms": 1700584920328, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926690159781486, "Avg loss": 0.654010861646384, "Avg value loss": 0.34363136044703424, "Avg policy loss": 0.31037951074540615, "Total num played games": 70659, "Total num trained steps": 140800, "Timestamp in ms": 1700584961460, "logtype": "training_step"}
{"Total num played games": 70659, "Total num trained steps": 140805, "Timestamp in ms": 1700584974377, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9933984375}
{"Ratio train steps to played games": 1.9917602996254682, "Avg loss": 0.786609944421798, "Avg value loss": 0.4818251859396696, "Avg policy loss": 0.30478476034477353, "Total num played games": 70755, "Total num trained steps": 140928, "Timestamp in ms": 1700585034598, "logtype": "training_step"}
{"Avg objective": 21.392187499999984, "Games time in secs": 149.4297305084765, "Avg game time in secs": 0.8572368243039818, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 70784, "Total num trained steps": 141000, "Timestamp in ms": 1700585069758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922319675719955, "Avg loss": 0.7591971170622855, "Avg value loss": 0.4447753981221467, "Avg policy loss": 0.31442171707749367, "Total num played games": 70803, "Total num trained steps": 141056, "Timestamp in ms": 1700585096905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925903971547125, "Avg loss": 0.6664415830746293, "Avg value loss": 0.3574052832555026, "Avg policy loss": 0.3090362980728969, "Total num played games": 70854, "Total num trained steps": 141184, "Timestamp in ms": 1700585160140, "logtype": "training_step"}
{"Avg objective": 22.41499999999998, "Games time in secs": 144.96769332699478, "Avg game time in secs": 1.02156358519278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.69, "agent_stopped_0": 0.43}, "Total num played games": 70912, "Total num trained steps": 141293, "Timestamp in ms": 1700585214726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916983791402396, "Avg loss": 0.8068440733477473, "Avg value loss": 0.4941765710536856, "Avg policy loss": 0.31266749871429056, "Total num played games": 70950, "Total num trained steps": 141312, "Timestamp in ms": 1700585223522, "logtype": "training_step"}
{"Total num played games": 70998, "Total num trained steps": 141406, "Timestamp in ms": 1700585280966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.214140625}
{"Avg objective": 21.35281249999998, "Games time in secs": 68.39907933026552, "Avg game time in secs": 0.8889083027752349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 71040, "Total num trained steps": 141409, "Timestamp in ms": 1700585283125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908228471694396, "Avg loss": 0.8016982276458293, "Avg value loss": 0.49213513839640655, "Avg policy loss": 0.30956308625172824, "Total num played games": 71046, "Total num trained steps": 141440, "Timestamp in ms": 1700585298286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992624496804887, "Avg loss": 0.4158245068974793, "Avg value loss": 0.1171788310748525, "Avg policy loss": 0.2986456770449877, "Total num played games": 71046, "Total num trained steps": 141568, "Timestamp in ms": 1700585358737, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917348401787973, "Avg loss": 0.6376517296303064, "Avg value loss": 0.3407692028558813, "Avg policy loss": 0.2968825262505561, "Total num played games": 71142, "Total num trained steps": 141696, "Timestamp in ms": 1700585420084, "logtype": "training_step"}
{"Avg objective": 20.696718749999977, "Games time in secs": 178.099843993783, "Avg game time in secs": 0.9483905304805376, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 71168, "Total num trained steps": 141774, "Timestamp in ms": 1700585461225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921758673971064, "Avg loss": 0.5228968525771052, "Avg value loss": 0.22557346124085598, "Avg policy loss": 0.29732339014299214, "Total num played games": 71190, "Total num trained steps": 141824, "Timestamp in ms": 1700585487233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926303377410932, "Avg loss": 0.564313457114622, "Avg value loss": 0.2717979135341011, "Avg policy loss": 0.29251554678194225, "Total num played games": 71238, "Total num trained steps": 141952, "Timestamp in ms": 1700585550681, "logtype": "training_step"}
{"Total num played games": 71286, "Total num trained steps": 142008, "Timestamp in ms": 1700585587586, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4891015625}
{"Avg objective": 22.241015624999985, "Games time in secs": 127.68367952108383, "Avg game time in secs": 0.9804941800102824, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 71296, "Total num trained steps": 142009, "Timestamp in ms": 1700585588916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917570863823704, "Avg loss": 0.7853184973355383, "Avg value loss": 0.48500410321867093, "Avg policy loss": 0.30031439173035324, "Total num played games": 71334, "Total num trained steps": 142080, "Timestamp in ms": 1700585623216, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922109215208317, "Avg loss": 0.6010649190284312, "Avg value loss": 0.30024534757831134, "Avg policy loss": 0.3008195696165785, "Total num played games": 71382, "Total num trained steps": 142208, "Timestamp in ms": 1700585689853, "logtype": "training_step"}
{"Avg objective": 21.35781249999998, "Games time in secs": 123.8162386957556, "Avg game time in secs": 0.9328988934576046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.61}, "Total num played games": 71424, "Total num trained steps": 142255, "Timestamp in ms": 1700585712745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926641467170656, "Avg loss": 0.5204524535220116, "Avg value loss": 0.2230066359625198, "Avg policy loss": 0.2974458171520382, "Total num played games": 71430, "Total num trained steps": 142336, "Timestamp in ms": 1700585751644, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991779213153259, "Avg loss": 0.5625705011188984, "Avg value loss": 0.27557762266951613, "Avg policy loss": 0.286992879351601, "Total num played games": 71526, "Total num trained steps": 142464, "Timestamp in ms": 1700585812552, "logtype": "training_step"}
{"Avg objective": 20.977890624999986, "Games time in secs": 137.61309104412794, "Avg game time in secs": 0.9592544551560422, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.52, "agent_stopped_0": 0.5}, "Total num played games": 71552, "Total num trained steps": 142542, "Timestamp in ms": 1700585850358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922039818372337, "Avg loss": 0.58253752021119, "Avg value loss": 0.2894294332654681, "Avg policy loss": 0.2931080862181261, "Total num played games": 71575, "Total num trained steps": 142592, "Timestamp in ms": 1700585875203, "logtype": "training_step"}
{"Total num played games": 71575, "Total num trained steps": 142608, "Timestamp in ms": 1700585891856, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.046054687500003}
{"Ratio train steps to played games": 1.9926420283986988, "Avg loss": 0.6124276604969054, "Avg value loss": 0.32516431336989626, "Avg policy loss": 0.28726333274971694, "Total num played games": 71623, "Total num trained steps": 142720, "Timestamp in ms": 1700585946705, "logtype": "training_step"}
{"Avg objective": 21.724999999999984, "Games time in secs": 152.96943627297878, "Avg game time in secs": 0.9615520130028017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.56, "agent_stopped_0": 0.45}, "Total num played games": 71680, "Total num trained steps": 142831, "Timestamp in ms": 1700586003327, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917039639715006, "Avg loss": 0.555053374147974, "Avg value loss": 0.2816868429654278, "Avg policy loss": 0.27336652809754014, "Total num played games": 71721, "Total num trained steps": 142848, "Timestamp in ms": 1700586010881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921553874235394, "Avg loss": 0.6147220018319786, "Avg value loss": 0.33242176769999787, "Avg policy loss": 0.282300234423019, "Total num played games": 71769, "Total num trained steps": 142976, "Timestamp in ms": 1700586073375, "logtype": "training_step"}
{"Avg objective": 20.77164062499998, "Games time in secs": 97.38540458679199, "Avg game time in secs": 0.9632790390023729, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 71808, "Total num trained steps": 143029, "Timestamp in ms": 1700586100713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99260620744392, "Avg loss": 0.5124834578018636, "Avg value loss": 0.23209426406538114, "Avg policy loss": 0.2803891928633675, "Total num played games": 71817, "Total num trained steps": 143104, "Timestamp in ms": 1700586138492, "logtype": "training_step"}
{"Total num played games": 71865, "Total num trained steps": 143209, "Timestamp in ms": 1700586206698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.660312500000003}
{"Ratio train steps to played games": 1.9917400191898544, "Avg loss": 0.6053837295621634, "Avg value loss": 0.3314648578816559, "Avg policy loss": 0.2739188706036657, "Total num played games": 71913, "Total num trained steps": 143232, "Timestamp in ms": 1700586218647, "logtype": "training_step"}
{"Avg objective": 20.81374999999998, "Games time in secs": 159.1916746739298, "Avg game time in secs": 0.9564129679201869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 71936, "Total num trained steps": 143316, "Timestamp in ms": 1700586259905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921348470741909, "Avg loss": 0.5856663938611746, "Avg value loss": 0.31598053747438826, "Avg policy loss": 0.2696858576964587, "Total num played games": 71963, "Total num trained steps": 143360, "Timestamp in ms": 1700586281814, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925705794947994, "Avg loss": 0.5340293983463198, "Avg value loss": 0.2601721591781825, "Avg policy loss": 0.273857242311351, "Total num played games": 72011, "Total num trained steps": 143488, "Timestamp in ms": 1700586345514, "logtype": "training_step"}
{"Avg objective": 22.63335937499998, "Games time in secs": 147.23419370129704, "Avg game time in secs": 1.0268839230702724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 72064, "Total num trained steps": 143610, "Timestamp in ms": 1700586407139, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916652798579908, "Avg loss": 0.6410633426858112, "Avg value loss": 0.3639647225209046, "Avg policy loss": 0.2770986258983612, "Total num played games": 72108, "Total num trained steps": 143616, "Timestamp in ms": 1700586409993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992086699835082, "Avg loss": 0.6063992734998465, "Avg value loss": 0.33319332826067694, "Avg policy loss": 0.27320594305638224, "Total num played games": 72157, "Total num trained steps": 143744, "Timestamp in ms": 1700586473373, "logtype": "training_step"}
{"Avg objective": 21.705937499999987, "Games time in secs": 97.36780996248126, "Avg game time in secs": 0.9319113386591198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 72192, "Total num trained steps": 143805, "Timestamp in ms": 1700586504507, "logtype": "played_game"}
{"Total num played games": 72205, "Total num trained steps": 143811, "Timestamp in ms": 1700586526712, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1640234375}
{"Ratio train steps to played games": 1.9912114375873666, "Avg loss": 0.8345910403877497, "Avg value loss": 0.5479234124941286, "Avg policy loss": 0.28666762029752135, "Total num played games": 72253, "Total num trained steps": 143872, "Timestamp in ms": 1700586558388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916047743523781, "Avg loss": 0.38357618846930563, "Avg value loss": 0.1065306170785334, "Avg policy loss": 0.27704557008109987, "Total num played games": 72303, "Total num trained steps": 144000, "Timestamp in ms": 1700586622888, "logtype": "training_step"}
{"Avg objective": 21.966874999999987, "Games time in secs": 167.9003856945783, "Avg game time in secs": 0.9621788979420671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 72320, "Total num trained steps": 144096, "Timestamp in ms": 1700586672408, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920664538154276, "Avg loss": 0.8385629600379616, "Avg value loss": 0.5567790672648698, "Avg policy loss": 0.2817838928895071, "Total num played games": 72351, "Total num trained steps": 144128, "Timestamp in ms": 1700586688065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992499896407409, "Avg loss": 0.5303564448840916, "Avg value loss": 0.2619529479125049, "Avg policy loss": 0.2684034949634224, "Total num played games": 72399, "Total num trained steps": 144256, "Timestamp in ms": 1700586752232, "logtype": "training_step"}
{"Avg objective": 20.758124999999975, "Games time in secs": 144.24200190417469, "Avg game time in secs": 0.9504044285422424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.63}, "Total num played games": 72448, "Total num trained steps": 144383, "Timestamp in ms": 1700586816650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992864044168392, "Avg loss": 0.5966778039000928, "Avg value loss": 0.33841279256739654, "Avg policy loss": 0.2582650142721832, "Total num played games": 72449, "Total num trained steps": 144384, "Timestamp in ms": 1700586816801, "logtype": "training_step"}
{"Total num played games": 72495, "Total num trained steps": 144415, "Timestamp in ms": 1700586847323, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3753125}
{"Ratio train steps to played games": 1.9920736666528818, "Avg loss": 0.780274128774181, "Avg value loss": 0.49884492909768596, "Avg policy loss": 0.2814291997347027, "Total num played games": 72543, "Total num trained steps": 144512, "Timestamp in ms": 1700586897449, "logtype": "training_step"}
{"Avg objective": 20.58359374999998, "Games time in secs": 114.10712027177215, "Avg game time in secs": 0.9119381737691583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 72576, "Total num trained steps": 144576, "Timestamp in ms": 1700586930757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925335096637324, "Avg loss": 0.4881094798911363, "Avg value loss": 0.22554801689693704, "Avg policy loss": 0.2625614651478827, "Total num played games": 72591, "Total num trained steps": 144640, "Timestamp in ms": 1700586962621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929515418502202, "Avg loss": 0.5268499242374673, "Avg value loss": 0.26486722318804823, "Avg policy loss": 0.26198270765598863, "Total num played games": 72640, "Total num trained steps": 144768, "Timestamp in ms": 1700587024868, "logtype": "training_step"}
{"Avg objective": 21.057031249999984, "Games time in secs": 144.14321414753795, "Avg game time in secs": 0.9401080322277267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 72704, "Total num trained steps": 144865, "Timestamp in ms": 1700587074900, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920809502859658, "Avg loss": 0.7345778271555901, "Avg value loss": 0.4657757358509116, "Avg policy loss": 0.26880211278330535, "Total num played games": 72736, "Total num trained steps": 144896, "Timestamp in ms": 1700587091052, "logtype": "training_step"}
{"Total num played games": 72784, "Total num trained steps": 145015, "Timestamp in ms": 1700587164607, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.295351562500002}
{"Avg objective": 21.767031249999985, "Games time in secs": 92.97201181948185, "Avg game time in secs": 0.9441412392043276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 72832, "Total num trained steps": 145020, "Timestamp in ms": 1700587167873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912126537785588, "Avg loss": 0.7259407342644408, "Avg value loss": 0.4652580216352362, "Avg policy loss": 0.26068271801341325, "Total num played games": 72832, "Total num trained steps": 145024, "Timestamp in ms": 1700587169752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929701230228472, "Avg loss": 0.5605930746532977, "Avg value loss": 0.30860141236917116, "Avg policy loss": 0.2519916632445529, "Total num played games": 72832, "Total num trained steps": 145152, "Timestamp in ms": 1700587237633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921017990346643, "Avg loss": 0.5886522335931659, "Avg value loss": 0.3375391663867049, "Avg policy loss": 0.25111306668259203, "Total num played games": 72928, "Total num trained steps": 145280, "Timestamp in ms": 1700587299063, "logtype": "training_step"}
{"Avg objective": 22.252343749999987, "Games time in secs": 162.8217178247869, "Avg game time in secs": 0.8264116021891823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 72960, "Total num trained steps": 145346, "Timestamp in ms": 1700587330694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925181906628116, "Avg loss": 0.5295091123552993, "Avg value loss": 0.2675666247669142, "Avg policy loss": 0.2619424876756966, "Total num played games": 72977, "Total num trained steps": 145408, "Timestamp in ms": 1700587359852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929613146182814, "Avg loss": 0.45094705163501203, "Avg value loss": 0.1832762983685825, "Avg policy loss": 0.2676707517821342, "Total num played games": 73025, "Total num trained steps": 145536, "Timestamp in ms": 1700587422608, "logtype": "training_step"}
{"Total num played games": 73073, "Total num trained steps": 145617, "Timestamp in ms": 1700587478422, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.762304687500002}
{"Avg objective": 21.585703124999988, "Games time in secs": 149.1588145662099, "Avg game time in secs": 1.0650079070474021, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.74, "agent_stopped_0": 0.33}, "Total num played games": 73088, "Total num trained steps": 145618, "Timestamp in ms": 1700587479853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920952941015577, "Avg loss": 0.5839831524062902, "Avg value loss": 0.30728708778042346, "Avg policy loss": 0.27669606800191104, "Total num played games": 73121, "Total num trained steps": 145664, "Timestamp in ms": 1700587502009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925378233951536, "Avg loss": 0.5809243560070172, "Avg value loss": 0.3148362970096059, "Avg policy loss": 0.266088061616756, "Total num played games": 73169, "Total num trained steps": 145792, "Timestamp in ms": 1700587564074, "logtype": "training_step"}
{"Avg objective": 21.58593749999998, "Games time in secs": 102.57929123751819, "Avg game time in secs": 0.9471897874464048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 73216, "Total num trained steps": 145830, "Timestamp in ms": 1700587582433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929661144269772, "Avg loss": 0.4786178113427013, "Avg value loss": 0.20720824858290143, "Avg policy loss": 0.2714095659321174, "Total num played games": 73217, "Total num trained steps": 145920, "Timestamp in ms": 1700587625364, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920888234170826, "Avg loss": 0.6945694710593671, "Avg value loss": 0.40290477973758243, "Avg policy loss": 0.291664692456834, "Total num played games": 73314, "Total num trained steps": 146048, "Timestamp in ms": 1700587693878, "logtype": "training_step"}
{"Avg objective": 21.63765624999999, "Games time in secs": 149.03196649625897, "Avg game time in secs": 0.9703011140372837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 73344, "Total num trained steps": 146118, "Timestamp in ms": 1700587731465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992516561707696, "Avg loss": 0.5503975347382948, "Avg value loss": 0.25819314731052145, "Avg policy loss": 0.2922043832950294, "Total num played games": 73362, "Total num trained steps": 146176, "Timestamp in ms": 1700587758837, "logtype": "training_step"}
{"Total num played games": 73410, "Total num trained steps": 146220, "Timestamp in ms": 1700587800753, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.754023437500003}
{"Ratio train steps to played games": 1.9916550954286802, "Avg loss": 0.7364901178516448, "Avg value loss": 0.42919816754874773, "Avg policy loss": 0.3072919494006783, "Total num played games": 73458, "Total num trained steps": 146304, "Timestamp in ms": 1700587842153, "logtype": "training_step"}
{"Avg objective": 21.348046874999987, "Games time in secs": 162.43590266630054, "Avg game time in secs": 0.9870642458699876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 73472, "Total num trained steps": 146405, "Timestamp in ms": 1700587893901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921094876608711, "Avg loss": 0.536176604218781, "Avg value loss": 0.2397876995964907, "Avg policy loss": 0.29638890840578824, "Total num played games": 73506, "Total num trained steps": 146432, "Timestamp in ms": 1700587906560, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925496913832015, "Avg loss": 0.5020615190733224, "Avg value loss": 0.201392451999709, "Avg policy loss": 0.30066906614229083, "Total num played games": 73554, "Total num trained steps": 146560, "Timestamp in ms": 1700587969522, "logtype": "training_step"}
{"Avg objective": 22.511093749999986, "Games time in secs": 93.8898475561291, "Avg game time in secs": 0.9461399884312414, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 73600, "Total num trained steps": 146601, "Timestamp in ms": 1700587987791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929757343550447, "Avg loss": 0.5588492855895311, "Avg value loss": 0.2630548648885451, "Avg policy loss": 0.29579442378599197, "Total num played games": 73602, "Total num trained steps": 146688, "Timestamp in ms": 1700588029065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921164753453282, "Avg loss": 0.7719088275916874, "Avg value loss": 0.46244878383004107, "Avg policy loss": 0.30946004786528647, "Total num played games": 73698, "Total num trained steps": 146816, "Timestamp in ms": 1700588086740, "logtype": "training_step"}
{"Total num played games": 73698, "Total num trained steps": 146820, "Timestamp in ms": 1700588100492, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.851796875}
{"Avg objective": 20.789296874999984, "Games time in secs": 114.42576079815626, "Avg game time in secs": 0.945640949808876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.6, "agent_stopped_0": 0.44}, "Total num played games": 73728, "Total num trained steps": 146824, "Timestamp in ms": 1700588102217, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925690884929352, "Avg loss": 0.5738476968836039, "Avg value loss": 0.25710602529579774, "Avg policy loss": 0.31674167211167514, "Total num played games": 73746, "Total num trained steps": 146944, "Timestamp in ms": 1700588157743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929940103531452, "Avg loss": 0.6349325175397098, "Avg value loss": 0.33564773603575304, "Avg policy loss": 0.29928477213252336, "Total num played games": 73794, "Total num trained steps": 147072, "Timestamp in ms": 1700588219958, "logtype": "training_step"}
{"Avg objective": 21.372890624999982, "Games time in secs": 173.68824017979205, "Avg game time in secs": 0.9408103989699157, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 73856, "Total num trained steps": 147187, "Timestamp in ms": 1700588275905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919617846461968, "Avg loss": 0.6584845338948071, "Avg value loss": 0.35048379155341536, "Avg policy loss": 0.3080007378011942, "Total num played games": 73897, "Total num trained steps": 147200, "Timestamp in ms": 1700588281873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923997565758333, "Avg loss": 0.5996098252944648, "Avg value loss": 0.29061586788157, "Avg policy loss": 0.3089939638739452, "Total num played games": 73945, "Total num trained steps": 147328, "Timestamp in ms": 1700588343520, "logtype": "training_step"}
{"Avg objective": 21.716640624999982, "Games time in secs": 94.73919538967311, "Avg game time in secs": 0.9110832871228922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 73984, "Total num trained steps": 147381, "Timestamp in ms": 1700588370645, "logtype": "played_game"}
{"Total num played games": 73993, "Total num trained steps": 147420, "Timestamp in ms": 1700588458866, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.216289062500003}
{"Ratio train steps to played games": 1.9915317189124944, "Avg loss": 0.7722490574233234, "Avg value loss": 0.4680899035301991, "Avg policy loss": 0.3041591471992433, "Total num played games": 74041, "Total num trained steps": 147456, "Timestamp in ms": 1700588476552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919691182226782, "Avg loss": 0.5394352200673893, "Avg value loss": 0.2301719358365517, "Avg policy loss": 0.30926328152418137, "Total num played games": 74089, "Total num trained steps": 147584, "Timestamp in ms": 1700588540133, "logtype": "training_step"}
{"Avg objective": 22.723203124999987, "Games time in secs": 212.29612993821502, "Avg game time in secs": 0.9304495614633197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.55, "agent_stopped_0": 0.47}, "Total num played games": 74112, "Total num trained steps": 147669, "Timestamp in ms": 1700588582941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924059511445027, "Avg loss": 0.680196879664436, "Avg value loss": 0.3560191990400199, "Avg policy loss": 0.32417767483275384, "Total num played games": 74137, "Total num trained steps": 147712, "Timestamp in ms": 1700588604993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927482510884362, "Avg loss": 0.4726545228622854, "Avg value loss": 0.1618917477026116, "Avg policy loss": 0.31076277839019895, "Total num played games": 74189, "Total num trained steps": 147840, "Timestamp in ms": 1700588670461, "logtype": "training_step"}
{"Avg objective": 21.28601562499998, "Games time in secs": 155.5065441057086, "Avg game time in secs": 1.0477389220468467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.72, "agent_stopped_0": 0.32}, "Total num played games": 74240, "Total num trained steps": 147964, "Timestamp in ms": 1700588738448, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918826142559063, "Avg loss": 0.5159950866363943, "Avg value loss": 0.19691777243860997, "Avg policy loss": 0.31907731376122683, "Total num played games": 74285, "Total num trained steps": 147968, "Timestamp in ms": 1700588740490, "logtype": "training_step"}
{"Total num played games": 74285, "Total num trained steps": 148022, "Timestamp in ms": 1700588783806, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9657421875}
{"Ratio train steps to played games": 1.992331804178494, "Avg loss": 0.7004677865188569, "Avg value loss": 0.37516100361244753, "Avg policy loss": 0.3253067892510444, "Total num played games": 74333, "Total num trained steps": 148096, "Timestamp in ms": 1700588819986, "logtype": "training_step"}
{"Avg objective": 21.113281249999986, "Games time in secs": 111.74875041283667, "Avg game time in secs": 0.8654376783815678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.55}, "Total num played games": 74368, "Total num trained steps": 148157, "Timestamp in ms": 1700588850197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927535257659885, "Avg loss": 0.5209200812969357, "Avg value loss": 0.19473946947255172, "Avg policy loss": 0.3261806060327217, "Total num played games": 74381, "Total num trained steps": 148224, "Timestamp in ms": 1700588884274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931212381771282, "Avg loss": 0.5298118316568434, "Avg value loss": 0.2110976789263077, "Avg policy loss": 0.318714153021574, "Total num played games": 74432, "Total num trained steps": 148352, "Timestamp in ms": 1700588946902, "logtype": "training_step"}
{"Avg objective": 21.53492187499999, "Games time in secs": 144.9590747114271, "Avg game time in secs": 0.9612101028469624, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 74496, "Total num trained steps": 148450, "Timestamp in ms": 1700588995156, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922713610991842, "Avg loss": 0.8498647618107498, "Avg value loss": 0.524318381852936, "Avg policy loss": 0.32554637792054564, "Total num played games": 74528, "Total num trained steps": 148480, "Timestamp in ms": 1700589009085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926920188800687, "Avg loss": 0.6618862173054367, "Avg value loss": 0.33250216901069507, "Avg policy loss": 0.3293840519618243, "Total num played games": 74576, "Total num trained steps": 148608, "Timestamp in ms": 1700589073209, "logtype": "training_step"}
{"Total num played games": 74576, "Total num trained steps": 148623, "Timestamp in ms": 1700589135104, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8418359375}
{"Avg objective": 20.99374999999998, "Games time in secs": 144.26525497436523, "Avg game time in secs": 0.946367961310898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 74624, "Total num trained steps": 148631, "Timestamp in ms": 1700589139421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931255360205833, "Avg loss": 0.6428107200190425, "Avg value loss": 0.3116580873611383, "Avg policy loss": 0.33115262840874493, "Total num played games": 74624, "Total num trained steps": 148736, "Timestamp in ms": 1700589193016, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922778372591006, "Avg loss": 0.8887323038652539, "Avg value loss": 0.5616164857929107, "Avg policy loss": 0.32711582665797323, "Total num played games": 74720, "Total num trained steps": 148864, "Timestamp in ms": 1700589259798, "logtype": "training_step"}
{"Avg objective": 20.96695312499998, "Games time in secs": 153.1032008547336, "Avg game time in secs": 0.9034187048237072, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 74752, "Total num trained steps": 148931, "Timestamp in ms": 1700589292525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925775346716061, "Avg loss": 0.6809835175517946, "Avg value loss": 0.34840696604806, "Avg policy loss": 0.3325765560148284, "Total num played games": 74773, "Total num trained steps": 148992, "Timestamp in ms": 1700589321823, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930099838280697, "Avg loss": 0.5107341057155281, "Avg value loss": 0.1775002324138768, "Avg policy loss": 0.33323387359268963, "Total num played games": 74821, "Total num trained steps": 149120, "Timestamp in ms": 1700589385767, "logtype": "training_step"}
{"Total num played games": 74869, "Total num trained steps": 149225, "Timestamp in ms": 1700589459095, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9476171875}
{"Avg objective": 21.452343749999983, "Games time in secs": 167.84572326019406, "Avg game time in secs": 0.9938368404109497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 74880, "Total num trained steps": 149227, "Timestamp in ms": 1700589460371, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921514188846472, "Avg loss": 0.6571101697627455, "Avg value loss": 0.33295063793775626, "Avg policy loss": 0.3241595297586173, "Total num played games": 74918, "Total num trained steps": 149248, "Timestamp in ms": 1700589470648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925301461957101, "Avg loss": 0.5831737038679421, "Avg value loss": 0.2637424446293153, "Avg policy loss": 0.3194312568521127, "Total num played games": 74968, "Total num trained steps": 149376, "Timestamp in ms": 1700589531868, "logtype": "training_step"}
{"Avg objective": 20.446874999999984, "Games time in secs": 94.2849180791527, "Avg game time in secs": 0.9012179530691355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 75008, "Total num trained steps": 149427, "Timestamp in ms": 1700589554656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929481710568413, "Avg loss": 0.5264369961805642, "Avg value loss": 0.22555905795888975, "Avg policy loss": 0.30087793176062405, "Total num played games": 75016, "Total num trained steps": 149504, "Timestamp in ms": 1700589590316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992038873726952, "Avg loss": 0.7554400959052145, "Avg value loss": 0.4481294239812996, "Avg policy loss": 0.30731066409498453, "Total num played games": 75115, "Total num trained steps": 149632, "Timestamp in ms": 1700589649648, "logtype": "training_step"}
{"Avg objective": 21.975078124999982, "Games time in secs": 135.3891292847693, "Avg game time in secs": 0.922064154263353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 75136, "Total num trained steps": 149720, "Timestamp in ms": 1700589690045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924696991871, "Avg loss": 0.5883668137248605, "Avg value loss": 0.2759044356062077, "Avg policy loss": 0.3124623813200742, "Total num played games": 75163, "Total num trained steps": 149760, "Timestamp in ms": 1700589709630, "logtype": "training_step"}
{"Total num played games": 75211, "Total num trained steps": 149828, "Timestamp in ms": 1700589755606, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8065234375}
{"Ratio train steps to played games": 1.9916156207231028, "Avg loss": 0.8283437141217291, "Avg value loss": 0.5028752481448464, "Avg policy loss": 0.3254684713901952, "Total num played games": 75259, "Total num trained steps": 149888, "Timestamp in ms": 1700589784253, "logtype": "training_step"}
{"Avg objective": 21.389609374999974, "Games time in secs": 151.41638668440282, "Avg game time in secs": 1.0148458697804017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.71, "agent_stopped_0": 0.34}, "Total num played games": 75264, "Total num trained steps": 150008, "Timestamp in ms": 1700589841461, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920458921481403, "Avg loss": 0.432646946515888, "Avg value loss": 0.12623131429427303, "Avg policy loss": 0.3064156286418438, "Total num played games": 75307, "Total num trained steps": 150016, "Timestamp in ms": 1700589845384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924756154203438, "Avg loss": 0.6412179830949754, "Avg value loss": 0.3267267973278649, "Avg policy loss": 0.31449118501041085, "Total num played games": 75355, "Total num trained steps": 150144, "Timestamp in ms": 1700589905071, "logtype": "training_step"}
{"Avg objective": 20.881249999999977, "Games time in secs": 89.77518153004348, "Avg game time in secs": 0.9377468043385306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.59}, "Total num played games": 75392, "Total num trained steps": 150201, "Timestamp in ms": 1700589931237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928916237865366, "Avg loss": 0.5261199974920601, "Avg value loss": 0.21502894334844314, "Avg policy loss": 0.3110910542309284, "Total num played games": 75404, "Total num trained steps": 150272, "Timestamp in ms": 1700589964313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920397350993377, "Avg loss": 0.5675195625517517, "Avg value loss": 0.2582365481357556, "Avg policy loss": 0.3092830089153722, "Total num played games": 75500, "Total num trained steps": 150400, "Timestamp in ms": 1700590023342, "logtype": "training_step"}
{"Total num played games": 75500, "Total num trained steps": 150433, "Timestamp in ms": 1700590095125, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.285898437500002}
{"Avg objective": 22.515859374999987, "Games time in secs": 165.32284818403423, "Avg game time in secs": 0.9625709453539457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 75520, "Total num trained steps": 150436, "Timestamp in ms": 1700590096560, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924816011012867, "Avg loss": 0.8441404574550688, "Avg value loss": 0.5273975128948223, "Avg policy loss": 0.31674294965341687, "Total num played games": 75548, "Total num trained steps": 150528, "Timestamp in ms": 1700590139306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928964495475952, "Avg loss": 0.5099842180497944, "Avg value loss": 0.19583083092584275, "Avg policy loss": 0.3141533808084205, "Total num played games": 75596, "Total num trained steps": 150656, "Timestamp in ms": 1700590198028, "logtype": "training_step"}
{"Avg objective": 21.58062499999998, "Games time in secs": 157.37381686083972, "Avg game time in secs": 0.891695205544238, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 75648, "Total num trained steps": 150778, "Timestamp in ms": 1700590253934, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920731385086932, "Avg loss": 0.7772236675955355, "Avg value loss": 0.46376197805511765, "Avg policy loss": 0.3134616910247132, "Total num played games": 75692, "Total num trained steps": 150784, "Timestamp in ms": 1700590256811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924874570900448, "Avg loss": 0.8181732245720923, "Avg value loss": 0.511471904348582, "Avg policy loss": 0.30670131754595786, "Total num played games": 75740, "Total num trained steps": 150912, "Timestamp in ms": 1700590317358, "logtype": "training_step"}
{"Avg objective": 20.527343749999982, "Games time in secs": 92.07713933102787, "Avg game time in secs": 0.8986137700558174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 75776, "Total num trained steps": 150971, "Timestamp in ms": 1700590346011, "logtype": "played_game"}
{"Total num played games": 75788, "Total num trained steps": 151035, "Timestamp in ms": 1700590441235, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.23}
{"Ratio train steps to played games": 1.9916662271216836, "Avg loss": 0.6020532839465886, "Avg value loss": 0.30508184773498215, "Avg policy loss": 0.29697144345846027, "Total num played games": 75835, "Total num trained steps": 151040, "Timestamp in ms": 1700590444282, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992080016867851, "Avg loss": 0.6113137684296817, "Avg value loss": 0.3167871257173829, "Avg policy loss": 0.2945266410242766, "Total num played games": 75884, "Total num trained steps": 151168, "Timestamp in ms": 1700590509884, "logtype": "training_step"}
{"Avg objective": 21.632812499999986, "Games time in secs": 207.3700030427426, "Avg game time in secs": 0.9134333276451798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 75904, "Total num trained steps": 151257, "Timestamp in ms": 1700590553381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925064531422851, "Avg loss": 0.49218126107007265, "Avg value loss": 0.21263200778048486, "Avg policy loss": 0.2795492553850636, "Total num played games": 75932, "Total num trained steps": 151296, "Timestamp in ms": 1700590571531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992919282452192, "Avg loss": 0.5570056573487818, "Avg value loss": 0.26968342493637465, "Avg policy loss": 0.28732222807593644, "Total num played games": 75981, "Total num trained steps": 151424, "Timestamp in ms": 1700590639210, "logtype": "training_step"}
{"Avg objective": 20.45039062499998, "Games time in secs": 152.22707479260862, "Avg game time in secs": 1.0462408972816775, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.8, "agent_stopped_0": 0.32}, "Total num played games": 76032, "Total num trained steps": 151549, "Timestamp in ms": 1700590705609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992086964522786, "Avg loss": 0.6055982736870646, "Avg value loss": 0.3148274082923308, "Avg policy loss": 0.2907708656275645, "Total num played games": 76077, "Total num trained steps": 151552, "Timestamp in ms": 1700590706925, "logtype": "training_step"}
{"Total num played games": 76078, "Total num trained steps": 151635, "Timestamp in ms": 1700590771066, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.811484375000003}
{"Ratio train steps to played games": 1.9924861413971573, "Avg loss": 0.7166052805259824, "Avg value loss": 0.415169248561142, "Avg policy loss": 0.3014360296074301, "Total num played games": 76126, "Total num trained steps": 151680, "Timestamp in ms": 1700590796161, "logtype": "training_step"}
{"Avg objective": 21.44187499999998, "Games time in secs": 120.62653686664999, "Avg game time in secs": 0.9075632884341758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 76160, "Total num trained steps": 151742, "Timestamp in ms": 1700590826235, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99288480472596, "Avg loss": 0.5141807445324957, "Avg value loss": 0.21643197047524154, "Avg policy loss": 0.2977487739408389, "Total num played games": 76175, "Total num trained steps": 151808, "Timestamp in ms": 1700590857813, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927339497671979, "Avg loss": 0.4936362176667899, "Avg value loss": 0.20832487248117104, "Avg policy loss": 0.2853113482706249, "Total num played games": 76243, "Total num trained steps": 151936, "Timestamp in ms": 1700590920048, "logtype": "training_step"}
{"Avg objective": 22.114296874999987, "Games time in secs": 145.72333105653524, "Avg game time in secs": 0.9456163967697648, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 76288, "Total num trained steps": 152033, "Timestamp in ms": 1700590971959, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924397274633123, "Avg loss": 0.6294290006626397, "Avg value loss": 0.3448934872285463, "Avg policy loss": 0.28453551221173257, "Total num played games": 76320, "Total num trained steps": 152064, "Timestamp in ms": 1700590988637, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992824407489852, "Avg loss": 0.5584372512530535, "Avg value loss": 0.2779442385362927, "Avg policy loss": 0.2804930127458647, "Total num played games": 76370, "Total num trained steps": 152192, "Timestamp in ms": 1700591052083, "logtype": "training_step"}
{"Avg objective": 21.239843749999984, "Games time in secs": 100.00593355856836, "Avg game time in secs": 0.9707078619831009, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.67}, "Total num played games": 76416, "Total num trained steps": 152231, "Timestamp in ms": 1700591071965, "logtype": "played_game"}
{"Total num played games": 76418, "Total num trained steps": 152238, "Timestamp in ms": 1700591137181, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.611484375000003}
{"Ratio train steps to played games": 1.9919964428634949, "Avg loss": 0.7820711797103286, "Avg value loss": 0.4852598733850755, "Avg policy loss": 0.2968113061506301, "Total num played games": 76466, "Total num trained steps": 152320, "Timestamp in ms": 1700591179108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924196879002536, "Avg loss": 0.4099339544773102, "Avg value loss": 0.12966805277392268, "Avg policy loss": 0.2802659001899883, "Total num played games": 76514, "Total num trained steps": 152448, "Timestamp in ms": 1700591240626, "logtype": "training_step"}
{"Avg objective": 20.419531249999977, "Games time in secs": 206.5599714126438, "Avg game time in secs": 0.9555069557973184, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 76544, "Total num trained steps": 152518, "Timestamp in ms": 1700591278525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928424022360962, "Avg loss": 0.5164975104853511, "Avg value loss": 0.2192276994464919, "Avg policy loss": 0.2972698137164116, "Total num played games": 76562, "Total num trained steps": 152576, "Timestamp in ms": 1700591307440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932385688739216, "Avg loss": 0.4953678669407964, "Avg value loss": 0.19796567992307246, "Avg policy loss": 0.29740218294318765, "Total num played games": 76611, "Total num trained steps": 152704, "Timestamp in ms": 1700591369810, "logtype": "training_step"}
{"Avg objective": 22.293749999999985, "Games time in secs": 141.03053222224116, "Avg game time in secs": 1.040388768989942, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 76672, "Total num trained steps": 152807, "Timestamp in ms": 1700591419556, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923996506185877, "Avg loss": 0.7196209419053048, "Avg value loss": 0.4309343220666051, "Avg policy loss": 0.2886866215849295, "Total num played games": 76707, "Total num trained steps": 152832, "Timestamp in ms": 1700591430808, "logtype": "training_step"}
{"Total num played games": 76707, "Total num trained steps": 152838, "Timestamp in ms": 1700591494219, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.895664062500003}
{"Ratio train steps to played games": 1.9928343430395414, "Avg loss": 0.5295901959761977, "Avg value loss": 0.23199303197907284, "Avg policy loss": 0.2975971590494737, "Total num played games": 76755, "Total num trained steps": 152960, "Timestamp in ms": 1700591553014, "logtype": "training_step"}
{"Avg objective": 20.024765624999983, "Games time in secs": 152.90508560836315, "Avg game time in secs": 0.9548378892213805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.63}, "Total num played games": 76800, "Total num trained steps": 153001, "Timestamp in ms": 1700591572461, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932424514667395, "Avg loss": 0.47991810960229486, "Avg value loss": 0.19085743109462783, "Avg policy loss": 0.28906068194191903, "Total num played games": 76803, "Total num trained steps": 153088, "Timestamp in ms": 1700591614386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924316311005346, "Avg loss": 0.702009514789097, "Avg value loss": 0.4192045192758087, "Avg policy loss": 0.28280499193351716, "Total num played games": 76899, "Total num trained steps": 153216, "Timestamp in ms": 1700591676828, "logtype": "training_step"}
{"Avg objective": 21.449218749999982, "Games time in secs": 140.00412820093334, "Avg game time in secs": 0.9126772818126483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.59, "agent_stopped_0": 0.42}, "Total num played games": 76928, "Total num trained steps": 153288, "Timestamp in ms": 1700591712465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928522229586598, "Avg loss": 0.5658177299192175, "Avg value loss": 0.2854242822213564, "Avg policy loss": 0.2803934516850859, "Total num played games": 76947, "Total num trained steps": 153344, "Timestamp in ms": 1700591739406, "logtype": "training_step"}
{"Total num played games": 76995, "Total num trained steps": 153438, "Timestamp in ms": 1700591843960, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.367890625}
{"Ratio train steps to played games": 1.9920304245680984, "Avg loss": 0.6313642719760537, "Avg value loss": 0.3474005803000182, "Avg policy loss": 0.28396369493566453, "Total num played games": 77043, "Total num trained steps": 153472, "Timestamp in ms": 1700591860856, "logtype": "training_step"}
{"Avg objective": 20.70828124999998, "Games time in secs": 198.5576067045331, "Avg game time in secs": 1.023248691475601, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.74, "agent_stopped_0": 0.36}, "Total num played games": 77056, "Total num trained steps": 153575, "Timestamp in ms": 1700591911026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924504806008483, "Avg loss": 0.4468897987389937, "Avg value loss": 0.15663013205630705, "Avg policy loss": 0.29025966755580157, "Total num played games": 77091, "Total num trained steps": 153600, "Timestamp in ms": 1700591923696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992870013871064, "Avg loss": 0.5201277303276584, "Avg value loss": 0.23802889056969434, "Avg policy loss": 0.28209884522948414, "Total num played games": 77139, "Total num trained steps": 153728, "Timestamp in ms": 1700591984088, "logtype": "training_step"}
{"Avg objective": 21.39921874999998, "Games time in secs": 92.47794522345066, "Avg game time in secs": 0.9310336830094457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 77184, "Total num trained steps": 153769, "Timestamp in ms": 1700592003504, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932632015339171, "Avg loss": 0.4593095376621932, "Avg value loss": 0.17497088509844616, "Avg policy loss": 0.2843386536696926, "Total num played games": 77188, "Total num trained steps": 153856, "Timestamp in ms": 1700592045611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992391895039205, "Avg loss": 0.6422244382556528, "Avg value loss": 0.35630207450594753, "Avg policy loss": 0.2859223613049835, "Total num played games": 77286, "Total num trained steps": 153984, "Timestamp in ms": 1700592106801, "logtype": "training_step"}
{"Total num played games": 77286, "Total num trained steps": 154038, "Timestamp in ms": 1700592186386, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.043242187500002}
{"Avg objective": 21.69898437499998, "Games time in secs": 184.57297590002418, "Avg game time in secs": 1.0334541186166462, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 77312, "Total num trained steps": 154040, "Timestamp in ms": 1700592188077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992810406806838, "Avg loss": 0.6594246807508171, "Avg value loss": 0.3618178150791209, "Avg policy loss": 0.2976068693678826, "Total num played games": 77334, "Total num trained steps": 154112, "Timestamp in ms": 1700592222706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932154764673955, "Avg loss": 0.48366653313860297, "Avg value loss": 0.19817008182872087, "Avg policy loss": 0.28549645305611193, "Total num played games": 77382, "Total num trained steps": 154240, "Timestamp in ms": 1700592292691, "logtype": "training_step"}
{"Avg objective": 21.63804687499998, "Games time in secs": 160.70421322062612, "Avg game time in secs": 0.9736119644076098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 77440, "Total num trained steps": 154350, "Timestamp in ms": 1700592348782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923978419680426, "Avg loss": 0.5211272719316185, "Avg value loss": 0.22794725093990564, "Avg policy loss": 0.2931800205260515, "Total num played games": 77478, "Total num trained steps": 154368, "Timestamp in ms": 1700592358015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926867962492423, "Avg loss": 0.552686742390506, "Avg value loss": 0.2687925337231718, "Avg policy loss": 0.2838942089583725, "Total num played games": 77531, "Total num trained steps": 154496, "Timestamp in ms": 1700592421996, "logtype": "training_step"}
{"Avg objective": 21.61531249999998, "Games time in secs": 100.71886529028416, "Avg game time in secs": 0.9137321896705544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 77568, "Total num trained steps": 154553, "Timestamp in ms": 1700592449501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9930910028357824, "Avg loss": 0.5665556946769357, "Avg value loss": 0.2796800122014247, "Avg policy loss": 0.2868756843963638, "Total num played games": 77580, "Total num trained steps": 154624, "Timestamp in ms": 1700592483562, "logtype": "training_step"}
{"Total num played games": 77580, "Total num trained steps": 154640, "Timestamp in ms": 1700592553394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.67140625}
{"Ratio train steps to played games": 1.9921344987834864, "Avg loss": 0.5427753992844373, "Avg value loss": 0.2591560122091323, "Avg policy loss": 0.2836193897528574, "Total num played games": 77681, "Total num trained steps": 154752, "Timestamp in ms": 1700592607757, "logtype": "training_step"}
{"Avg objective": 21.165624999999988, "Games time in secs": 210.74812545254827, "Avg game time in secs": 0.9329219571227441, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 77696, "Total num trained steps": 154852, "Timestamp in ms": 1700592660249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925510427253663, "Avg loss": 0.7115995548665524, "Avg value loss": 0.41545914846938103, "Avg policy loss": 0.2961404094239697, "Total num played games": 77729, "Total num trained steps": 154880, "Timestamp in ms": 1700592674090, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992967072527868, "Avg loss": 0.5909606914501637, "Avg value loss": 0.3012051581754349, "Avg policy loss": 0.28975554078351706, "Total num played games": 77777, "Total num trained steps": 155008, "Timestamp in ms": 1700592739610, "logtype": "training_step"}
{"Avg objective": 21.87890624999998, "Games time in secs": 98.48821136541665, "Avg game time in secs": 0.9834969592484413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 77824, "Total num trained steps": 155046, "Timestamp in ms": 1700592758737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933825891423065, "Avg loss": 0.4925498249940574, "Avg value loss": 0.20516525232233107, "Avg policy loss": 0.2873845733702183, "Total num played games": 77825, "Total num trained steps": 155136, "Timestamp in ms": 1700592806153, "logtype": "training_step"}
{"Total num played games": 77922, "Total num trained steps": 155242, "Timestamp in ms": 1700592956855, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.320937500000003}
{"Avg objective": 21.578359374999984, "Games time in secs": 199.8718621712178, "Avg game time in secs": 0.851217705552699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 77952, "Total num trained steps": 155244, "Timestamp in ms": 1700592958609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913171732717712, "Avg loss": 0.8442339668981731, "Avg value loss": 0.5465763278480154, "Avg policy loss": 0.29765763913746923, "Total num played games": 77970, "Total num trained steps": 155264, "Timestamp in ms": 1700592969248, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929716557650379, "Avg loss": 0.47428734973073006, "Avg value loss": 0.17704229382798076, "Avg policy loss": 0.2972450531087816, "Total num played games": 77970, "Total num trained steps": 155392, "Timestamp in ms": 1700593030365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933477742601162, "Avg loss": 0.5647035422734916, "Avg value loss": 0.2738565820036456, "Avg policy loss": 0.29084696469362825, "Total num played games": 78019, "Total num trained steps": 155520, "Timestamp in ms": 1700593097667, "logtype": "training_step"}
{"Avg objective": 21.00624999999998, "Games time in secs": 195.3115709554404, "Avg game time in secs": 0.9092448145092931, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.59, "agent_stopped_0": 0.42}, "Total num played games": 78080, "Total num trained steps": 155624, "Timestamp in ms": 1700593153921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925366446905204, "Avg loss": 0.7230412079952657, "Avg value loss": 0.4418368943443056, "Avg policy loss": 0.2812043078010902, "Total num played games": 78115, "Total num trained steps": 155648, "Timestamp in ms": 1700593166154, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929634225912516, "Avg loss": 0.5827192896977067, "Avg value loss": 0.298696190235205, "Avg policy loss": 0.2840230929432437, "Total num played games": 78163, "Total num trained steps": 155776, "Timestamp in ms": 1700593231908, "logtype": "training_step"}
{"Avg objective": 21.52859374999998, "Games time in secs": 100.20009076409042, "Avg game time in secs": 0.9836172850918956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 78208, "Total num trained steps": 155818, "Timestamp in ms": 1700593254121, "logtype": "played_game"}
{"Total num played games": 78217, "Total num trained steps": 155844, "Timestamp in ms": 1700593340716, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.203593750000003}
{"Ratio train steps to played games": 1.991988756148981, "Avg loss": 0.7772667603567243, "Avg value loss": 0.47521659708581865, "Avg policy loss": 0.3020501750288531, "Total num played games": 78265, "Total num trained steps": 155904, "Timestamp in ms": 1700593371384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924150524178617, "Avg loss": 0.48396781808696687, "Avg value loss": 0.18465336711960845, "Avg policy loss": 0.29931444476824254, "Total num played games": 78313, "Total num trained steps": 156032, "Timestamp in ms": 1700593435493, "logtype": "training_step"}
{"Avg objective": 22.28257812499998, "Games time in secs": 222.46811533160508, "Avg game time in secs": 0.9146209463069681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 78336, "Total num trained steps": 156117, "Timestamp in ms": 1700593476589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928153035310934, "Avg loss": 0.7200624253600836, "Avg value loss": 0.41610664350446314, "Avg policy loss": 0.30395578721072525, "Total num played games": 78361, "Total num trained steps": 156160, "Timestamp in ms": 1700593498241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932405718731268, "Avg loss": 0.5706727474462241, "Avg value loss": 0.27006483226432465, "Avg policy loss": 0.30060791363939643, "Total num played games": 78409, "Total num trained steps": 156288, "Timestamp in ms": 1700593562925, "logtype": "training_step"}
{"Avg objective": 21.62085937499998, "Games time in secs": 142.89926377497613, "Avg game time in secs": 0.9258278050547233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.57, "agent_stopped_0": 0.46}, "Total num played games": 78464, "Total num trained steps": 156406, "Timestamp in ms": 1700593619489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923701071242055, "Avg loss": 0.6120793549343944, "Avg value loss": 0.3106340945523698, "Avg policy loss": 0.30144525435753167, "Total num played games": 78507, "Total num trained steps": 156416, "Timestamp in ms": 1700593624541, "logtype": "training_step"}
{"Total num played games": 78507, "Total num trained steps": 156448, "Timestamp in ms": 1700593737919, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.645273437500002}
{"Ratio train steps to played games": 1.9927821271720452, "Avg loss": 0.6365143032744527, "Avg value loss": 0.3311189801315777, "Avg policy loss": 0.30539533379487693, "Total num played games": 78555, "Total num trained steps": 156544, "Timestamp in ms": 1700593788847, "logtype": "training_step"}
{"Avg objective": 21.727343749999985, "Games time in secs": 197.9371577128768, "Avg game time in secs": 0.8774830896581989, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 78592, "Total num trained steps": 156601, "Timestamp in ms": 1700593817426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99320636616923, "Avg loss": 0.5457715482916683, "Avg value loss": 0.25001963795511983, "Avg policy loss": 0.29575191088952124, "Total num played games": 78603, "Total num trained steps": 156672, "Timestamp in ms": 1700593853395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924267452794227, "Avg loss": 0.6882213375065476, "Avg value loss": 0.38526636955793947, "Avg policy loss": 0.3029549738857895, "Total num played games": 78698, "Total num trained steps": 156800, "Timestamp in ms": 1700593916201, "logtype": "training_step"}
{"Avg objective": 23.478515624999982, "Games time in secs": 145.82259960100055, "Avg game time in secs": 1.0231138763338095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 78720, "Total num trained steps": 156895, "Timestamp in ms": 1700593963249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927238095238096, "Avg loss": 0.6424170497339219, "Avg value loss": 0.34162993941572495, "Avg policy loss": 0.30078710929956287, "Total num played games": 78750, "Total num trained steps": 156928, "Timestamp in ms": 1700593978889, "logtype": "training_step"}
{"Total num played games": 78798, "Total num trained steps": 157050, "Timestamp in ms": 1700594148253, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.350625}
{"Ratio train steps to played games": 1.9919209598457752, "Avg loss": 0.7265565103152767, "Avg value loss": 0.43288567164563574, "Avg policy loss": 0.29367084498517215, "Total num played games": 78846, "Total num trained steps": 157056, "Timestamp in ms": 1700594152011, "logtype": "training_step"}
{"Avg objective": 21.17343749999998, "Games time in secs": 252.73038667999208, "Avg game time in secs": 1.0292658710823162, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 78848, "Total num trained steps": 157181, "Timestamp in ms": 1700594215979, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924072454399107, "Avg loss": 0.49669358553364873, "Avg value loss": 0.2082789812120609, "Avg policy loss": 0.2884146050782874, "Total num played games": 78891, "Total num trained steps": 157184, "Timestamp in ms": 1700594216879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927415064224367, "Avg loss": 0.514086531708017, "Avg value loss": 0.22571858851006255, "Avg policy loss": 0.28836794081144035, "Total num played games": 78942, "Total num trained steps": 157312, "Timestamp in ms": 1700594281349, "logtype": "training_step"}
{"Avg objective": 21.275781249999987, "Games time in secs": 97.66597471944988, "Avg game time in secs": 0.8556519899138948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 78976, "Total num trained steps": 157375, "Timestamp in ms": 1700594313646, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931636916065325, "Avg loss": 0.4599503449862823, "Avg value loss": 0.176269576739287, "Avg policy loss": 0.2836807656567544, "Total num played games": 78990, "Total num trained steps": 157440, "Timestamp in ms": 1700594348390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926020537204714, "Avg loss": 0.5228295627748594, "Avg value loss": 0.22359429716016166, "Avg policy loss": 0.2992352711735293, "Total num played games": 79075, "Total num trained steps": 157568, "Timestamp in ms": 1700594414044, "logtype": "training_step"}
{"Total num played games": 79094, "Total num trained steps": 157652, "Timestamp in ms": 1700594537737, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3502734375}
{"Avg objective": 21.532109374999987, "Games time in secs": 225.55588281154633, "Avg game time in secs": 1.006391975141014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 79104, "Total num trained steps": 157653, "Timestamp in ms": 1700594539202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925703166460287, "Avg loss": 0.8631296358071268, "Avg value loss": 0.5507728392840363, "Avg policy loss": 0.31235680263489485, "Total num played games": 79142, "Total num trained steps": 157696, "Timestamp in ms": 1700594561278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929662836216695, "Avg loss": 0.8116659186780453, "Avg value loss": 0.4989657033002004, "Avg policy loss": 0.3127002235269174, "Total num played games": 79190, "Total num trained steps": 157824, "Timestamp in ms": 1700594621689, "logtype": "training_step"}
{"Avg objective": 21.86015624999998, "Games time in secs": 104.44816405139863, "Avg game time in secs": 0.9890649276640033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.63}, "Total num played games": 79232, "Total num trained steps": 157872, "Timestamp in ms": 1700594643650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933870112824654, "Avg loss": 0.5413394731003791, "Avg value loss": 0.2164354659325909, "Avg policy loss": 0.3249040066730231, "Total num played games": 79238, "Total num trained steps": 157952, "Timestamp in ms": 1700594680596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925756926412383, "Avg loss": 0.6199764900375158, "Avg value loss": 0.28196763852611184, "Avg policy loss": 0.33800885104574263, "Total num played games": 79334, "Total num trained steps": 158080, "Timestamp in ms": 1700594738064, "logtype": "training_step"}
{"Avg objective": 20.925546874999988, "Games time in secs": 130.25321723148227, "Avg game time in secs": 0.9692769823741401, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 79360, "Total num trained steps": 158159, "Timestamp in ms": 1700594773903, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992983295961301, "Avg loss": 0.6100974669679999, "Avg value loss": 0.2810694064828567, "Avg policy loss": 0.329028066014871, "Total num played games": 79382, "Total num trained steps": 158208, "Timestamp in ms": 1700594796143, "logtype": "training_step"}
{"Total num played games": 79382, "Total num trained steps": 158252, "Timestamp in ms": 1700594826429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.105664062500004}
{"Ratio train steps to played games": 1.9933779003159975, "Avg loss": 0.46602284349501133, "Avg value loss": 0.1372098980937153, "Avg policy loss": 0.32881294493563473, "Total num played games": 79431, "Total num trained steps": 158336, "Timestamp in ms": 1700594866646, "logtype": "training_step"}
{"Avg objective": 21.14999999999998, "Games time in secs": 143.3540602568537, "Avg game time in secs": 0.9907295240991516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.73}, "Total num played games": 79488, "Total num trained steps": 158448, "Timestamp in ms": 1700594917258, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925811359664014, "Avg loss": 0.730896835681051, "Avg value loss": 0.4035551337292418, "Avg policy loss": 0.3273417119635269, "Total num played games": 79527, "Total num trained steps": 158464, "Timestamp in ms": 1700594924075, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929877474081055, "Avg loss": 0.5862042850349098, "Avg value loss": 0.24780826989444904, "Avg policy loss": 0.33839601289946586, "Total num played games": 79575, "Total num trained steps": 158592, "Timestamp in ms": 1700594985106, "logtype": "training_step"}
{"Avg objective": 21.319296874999974, "Games time in secs": 89.68378657661378, "Avg game time in secs": 0.9534957751457114, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.71}, "Total num played games": 79616, "Total num trained steps": 158641, "Timestamp in ms": 1700595006941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933813094206447, "Avg loss": 0.5140362083911896, "Avg value loss": 0.18046720096026547, "Avg policy loss": 0.33356900908984244, "Total num played games": 79623, "Total num trained steps": 158720, "Timestamp in ms": 1700595043597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925990040015555, "Avg loss": 0.7977714848238975, "Avg value loss": 0.4600351639383007, "Avg policy loss": 0.3377363345352933, "Total num played games": 79716, "Total num trained steps": 158848, "Timestamp in ms": 1700595102211, "logtype": "training_step"}
{"Total num played games": 79726, "Total num trained steps": 158853, "Timestamp in ms": 1700595124125, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5975390625}
{"Avg objective": 21.916718749999983, "Games time in secs": 118.74217686615884, "Avg game time in secs": 1.0129875721468125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 79744, "Total num trained steps": 158855, "Timestamp in ms": 1700595125684, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928297440268758, "Avg loss": 0.8315419820137322, "Avg value loss": 0.49040896259248257, "Avg policy loss": 0.34113302477635443, "Total num played games": 79774, "Total num trained steps": 158976, "Timestamp in ms": 1700595181594, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932349477587632, "Avg loss": 0.5711369225755334, "Avg value loss": 0.24278479593340307, "Avg policy loss": 0.3283521174453199, "Total num played games": 79822, "Total num trained steps": 159104, "Timestamp in ms": 1700595240660, "logtype": "training_step"}
{"Avg objective": 23.308593749999986, "Games time in secs": 172.11751030385494, "Avg game time in secs": 1.0274662476149388, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.77, "agent_stopped_0": 0.33}, "Total num played games": 79872, "Total num trained steps": 159231, "Timestamp in ms": 1700595297801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9935772235576923, "Avg loss": 0.578923273133114, "Avg value loss": 0.24981867251335643, "Avg policy loss": 0.329104601056315, "Total num played games": 79872, "Total num trained steps": 159232, "Timestamp in ms": 1700595298021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927846138455383, "Avg loss": 0.7974480094853789, "Avg value loss": 0.4597936294740066, "Avg policy loss": 0.33765437721740454, "Total num played games": 79968, "Total num trained steps": 159360, "Timestamp in ms": 1700595356358, "logtype": "training_step"}
{"Avg objective": 22.251562499999984, "Games time in secs": 89.25871974788606, "Avg game time in secs": 0.9097951331059448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 80000, "Total num trained steps": 159427, "Timestamp in ms": 1700595387060, "logtype": "played_game"}
{"Total num played games": 80016, "Total num trained steps": 159430, "Timestamp in ms": 1700595472325, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.038125}
{"Total num played games": 80026, "Total num trained steps": 159430, "Timestamp in ms": 1700595495704, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0784765625}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700598411804, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.47265625}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700598752207, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.22265625}
