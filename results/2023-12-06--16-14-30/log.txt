{"Avg objective": 15.9921875, "Games time in secs": 367.343715865165, "Avg game time in secs": 165.66551281172724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 14.8, "reached_maximum_moves": 0.57, "agent_stopped_0": 0.06}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1701879644398, "logtype": "played_game"}
{"Avg objective": 14.9140625, "Games time in secs": 298.81986643746495, "Avg game time in secs": 174.4272206621099, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"reached_maximum_moves": 0.59, "played_steps": 15.89, "agent_stopped_more": 0.39, "agent_stopped_0": 0.02}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1701879943218, "logtype": "played_game"}
{"Ratio train steps to played games": 0.43537414965986393, "Avg loss": 55.95631876587868, "Avg value loss": 55.54060120135546, "Avg policy loss": 0.41571817733347416, "Total num played games": 294, "Total num trained steps": 128, "Timestamp in ms": 1701880015003, "logtype": "training_step"}
{"Ratio train steps to played games": 0.8205128205128205, "Avg loss": 12.114143401384354, "Avg value loss": 11.765548054128885, "Avg policy loss": 0.3485952753107995, "Total num played games": 312, "Total num trained steps": 256, "Timestamp in ms": 1701880073455, "logtype": "training_step"}
{"Ratio train steps to played games": 1.1497005988023952, "Avg loss": 6.151375148445368, "Avg value loss": 5.81872939132154, "Avg policy loss": 0.33264572685584426, "Total num played games": 334, "Total num trained steps": 384, "Timestamp in ms": 1701880133786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3689839572192513, "Avg loss": 4.189804192632437, "Avg value loss": 3.859027210623026, "Avg policy loss": 0.3307769778184593, "Total num played games": 374, "Total num trained steps": 512, "Timestamp in ms": 1701880206872, "logtype": "training_step"}
{"Avg objective": 15.8125, "Games time in secs": 286.6998034399003, "Avg game time in secs": 182.6964912627882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"reached_maximum_moves": 0.61, "played_steps": 15.71, "agent_stopped_0": 0.08, "agent_stopped_more": 0.31}, "Total num played games": 384, "Total num trained steps": 559, "Timestamp in ms": 1701880229917, "logtype": "played_game"}
{"Total num played games": 490, "Total num trained steps": 603, "Timestamp in ms": 1701880595678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5859375}
{"Ratio train steps to played games": 1.3008130081300813, "Avg loss": 4.945983085781336, "Avg value loss": 4.628716578707099, "Avg policy loss": 0.3172665105666965, "Total num played games": 492, "Total num trained steps": 640, "Timestamp in ms": 1701880615431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5118110236220472, "Avg loss": 4.230442937463522, "Avg value loss": 3.9013337660580873, "Avg policy loss": 0.32910917047411203, "Total num played games": 508, "Total num trained steps": 768, "Timestamp in ms": 1701880676728, "logtype": "training_step"}
{"Avg objective": 14.90625, "Games time in secs": 463.8038132339716, "Avg game time in secs": 192.08005058017443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 15.21, "reached_maximum_moves": 0.63, "agent_stopped_0": 0.06}, "Total num played games": 512, "Total num trained steps": 803, "Timestamp in ms": 1701880693721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7099236641221374, "Avg loss": 3.614861471578479, "Avg value loss": 3.277688605710864, "Avg policy loss": 0.33717287285253406, "Total num played games": 524, "Total num trained steps": 896, "Timestamp in ms": 1701880737248, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8686131386861313, "Avg loss": 3.1935439705848694, "Avg value loss": 2.8504311898723245, "Avg policy loss": 0.3431127700023353, "Total num played games": 548, "Total num trained steps": 1024, "Timestamp in ms": 1701880797629, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930795847750864, "Avg loss": 3.626997299492359, "Avg value loss": 3.286248719319701, "Avg policy loss": 0.3407485887873918, "Total num played games": 578, "Total num trained steps": 1152, "Timestamp in ms": 1701880857005, "logtype": "training_step"}
{"Avg objective": 14.390625, "Games time in secs": 279.1519611403346, "Avg game time in secs": 162.02357635206135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 14.41, "reached_maximum_moves": 0.6, "agent_stopped_0": 0.06}, "Total num played games": 640, "Total num trained steps": 1203, "Timestamp in ms": 1701880972873, "logtype": "played_game"}
{"Total num played games": 682, "Total num trained steps": 1203, "Timestamp in ms": 1701881139669, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.70703125}
{"Ratio train steps to played games": 1.871345029239766, "Avg loss": 3.6810683086514473, "Avg value loss": 3.3401784440502524, "Avg policy loss": 0.3408898862544447, "Total num played games": 684, "Total num trained steps": 1280, "Timestamp in ms": 1701881176595, "logtype": "training_step"}
{"Ratio train steps to played games": 2.0391304347826087, "Avg loss": 2.3782990453764796, "Avg value loss": 2.04244480188936, "Avg policy loss": 0.3358542376663536, "Total num played games": 690, "Total num trained steps": 1408, "Timestamp in ms": 1701881235434, "logtype": "training_step"}
{"Ratio train steps to played games": 2.169491525423729, "Avg loss": 2.119109041057527, "Avg value loss": 1.781545015051961, "Avg policy loss": 0.3375640294980258, "Total num played games": 708, "Total num trained steps": 1536, "Timestamp in ms": 1701881295720, "logtype": "training_step"}
{"Ratio train steps to played games": 2.271857923497268, "Avg loss": 2.1892360653728247, "Avg value loss": 1.8382121548056602, "Avg policy loss": 0.3510239126626402, "Total num played games": 732, "Total num trained steps": 1664, "Timestamp in ms": 1701881358522, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3753315649867375, "Avg loss": 1.978926650248468, "Avg value loss": 1.6385921314358711, "Avg policy loss": 0.3403345267288387, "Total num played games": 754, "Total num trained steps": 1792, "Timestamp in ms": 1701881421065, "logtype": "training_step"}
{"Avg objective": 14.625, "Games time in secs": 476.400537410751, "Avg game time in secs": 164.74982456820726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 14.88, "reached_maximum_moves": 0.6, "agent_stopped_0": 0.06}, "Total num played games": 768, "Total num trained steps": 1805, "Timestamp in ms": 1701881449274, "logtype": "played_game"}
{"Total num played games": 844, "Total num trained steps": 1805, "Timestamp in ms": 1701881700463, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.79296875}
{"Ratio train steps to played games": 2.2313953488372094, "Avg loss": 3.287733733654022, "Avg value loss": 2.9541076831519604, "Avg policy loss": 0.3336260167416185, "Total num played games": 860, "Total num trained steps": 1920, "Timestamp in ms": 1701881755462, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3758700696055683, "Avg loss": 2.067395049147308, "Avg value loss": 1.7381562609225512, "Avg policy loss": 0.3292387940455228, "Total num played games": 862, "Total num trained steps": 2048, "Timestamp in ms": 1701881816235, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4394618834080717, "Avg loss": 1.7191543150693178, "Avg value loss": 1.38927598670125, "Avg policy loss": 0.32987832510843873, "Total num played games": 892, "Total num trained steps": 2176, "Timestamp in ms": 1701881876166, "logtype": "training_step"}
{"Avg objective": 15.5859375, "Games time in secs": 431.2995568886399, "Avg game time in secs": 179.74257016052434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"reached_maximum_moves": 0.63, "played_steps": 14.66, "agent_stopped_more": 0.28, "agent_stopped_0": 0.09}, "Total num played games": 896, "Total num trained steps": 2185, "Timestamp in ms": 1701881880574, "logtype": "played_game"}
{"Ratio train steps to played games": 2.51528384279476, "Avg loss": 1.768667628057301, "Avg value loss": 1.428906370420009, "Avg policy loss": 0.3397612601984292, "Total num played games": 916, "Total num trained steps": 2304, "Timestamp in ms": 1701881935224, "logtype": "training_step"}
{"Total num played games": 1006, "Total num trained steps": 2408, "Timestamp in ms": 1701882180801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.43359375}
{"Ratio train steps to played games": 2.393700787401575, "Avg loss": 2.704636030830443, "Avg value loss": 2.3721863166429102, "Avg policy loss": 0.33244973979890347, "Total num played games": 1016, "Total num trained steps": 2432, "Timestamp in ms": 1701882192907, "logtype": "training_step"}
{"Avg objective": 15.953125, "Games time in secs": 357.66365017928183, "Avg game time in secs": 198.29611743369605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 15.77, "reached_maximum_moves": 0.61, "agent_stopped_0": 0.05}, "Total num played games": 1024, "Total num trained steps": 2528, "Timestamp in ms": 1701882238238, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4854368932038833, "Avg loss": 2.388592779636383, "Avg value loss": 2.054390786215663, "Avg policy loss": 0.33420198201201856, "Total num played games": 1030, "Total num trained steps": 2560, "Timestamp in ms": 1701882253311, "logtype": "training_step"}
{"Ratio train steps to played games": 2.559047619047619, "Avg loss": 1.714142344892025, "Avg value loss": 1.3816590271890163, "Avg policy loss": 0.33248332189396024, "Total num played games": 1050, "Total num trained steps": 2688, "Timestamp in ms": 1701882316624, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6074074074074076, "Avg loss": 1.9565649321302772, "Avg value loss": 1.6223041927441955, "Avg policy loss": 0.3342607442755252, "Total num played games": 1080, "Total num trained steps": 2816, "Timestamp in ms": 1701882379246, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6570397111913358, "Avg loss": 1.7327014496549964, "Avg value loss": 1.3913200683891773, "Avg policy loss": 0.3413813915103674, "Total num played games": 1108, "Total num trained steps": 2944, "Timestamp in ms": 1701882441384, "logtype": "training_step"}
{"Avg objective": 16.171875, "Games time in secs": 291.03573470935225, "Avg game time in secs": 143.78625424107304, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"reached_maximum_moves": 0.52, "played_steps": 13.23, "agent_stopped_more": 0.34, "agent_stopped_0": 0.14}, "Total num played games": 1152, "Total num trained steps": 3010, "Timestamp in ms": 1701882529274, "logtype": "played_game"}
{"Total num played games": 1210, "Total num trained steps": 3010, "Timestamp in ms": 1701882717230, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.28515625}
{"Ratio train steps to played games": 2.5213464696223316, "Avg loss": 1.9505472732707858, "Avg value loss": 1.6053584893234074, "Avg policy loss": 0.34518877998925745, "Total num played games": 1218, "Total num trained steps": 3072, "Timestamp in ms": 1701882748175, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6058631921824102, "Avg loss": 1.5505245067179203, "Avg value loss": 1.2030699183233082, "Avg policy loss": 0.34745456743985415, "Total num played games": 1228, "Total num trained steps": 3200, "Timestamp in ms": 1701882812441, "logtype": "training_step"}
{"Ratio train steps to played games": 2.653907496012759, "Avg loss": 1.607183264568448, "Avg value loss": 1.2577231228351593, "Avg policy loss": 0.34946014010347426, "Total num played games": 1254, "Total num trained steps": 3328, "Timestamp in ms": 1701882874928, "logtype": "training_step"}
{"Avg objective": 15.5703125, "Games time in secs": 397.65164523757994, "Avg game time in secs": 158.33540531471954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"reached_maximum_moves": 0.55, "played_steps": 13.77, "agent_stopped_0": 0.12, "agent_stopped_more": 0.33}, "Total num played games": 1280, "Total num trained steps": 3442, "Timestamp in ms": 1701882926925, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6957878315132606, "Avg loss": 1.3368254136294127, "Avg value loss": 0.9818992707878351, "Avg policy loss": 0.3549261372536421, "Total num played games": 1282, "Total num trained steps": 3456, "Timestamp in ms": 1701882933313, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7400611620795106, "Avg loss": 1.3376448904164135, "Avg value loss": 0.9877569605596364, "Avg policy loss": 0.3498879272956401, "Total num played games": 1308, "Total num trained steps": 3584, "Timestamp in ms": 1701882991664, "logtype": "training_step"}
{"Total num played games": 1392, "Total num trained steps": 3612, "Timestamp in ms": 1701883206033, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.671875}
{"Ratio train steps to played games": 2.6401137980085347, "Avg loss": 1.9048374146223068, "Avg value loss": 1.5482413368299603, "Avg policy loss": 0.35659608501009643, "Total num played games": 1406, "Total num trained steps": 3712, "Timestamp in ms": 1701883252654, "logtype": "training_step"}
{"Avg objective": 15.625, "Games time in secs": 331.20080597884953, "Avg game time in secs": 174.61703566247888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"reached_maximum_moves": 0.56, "played_steps": 14.45, "agent_stopped_more": 0.35, "agent_stopped_0": 0.09}, "Total num played games": 1408, "Total num trained steps": 3724, "Timestamp in ms": 1701883258127, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7195467422096318, "Avg loss": 1.3863223865628242, "Avg value loss": 1.038171582389623, "Avg policy loss": 0.3481507943943143, "Total num played games": 1412, "Total num trained steps": 3840, "Timestamp in ms": 1701883309910, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7663877266387726, "Avg loss": 1.466051715426147, "Avg value loss": 1.1138069950975478, "Avg policy loss": 0.35224471613764763, "Total num played games": 1434, "Total num trained steps": 3968, "Timestamp in ms": 1701883368816, "logtype": "training_step"}
{"Ratio train steps to played games": 2.786394557823129, "Avg loss": 1.375196830369532, "Avg value loss": 1.0182544332928956, "Avg policy loss": 0.3569423882290721, "Total num played games": 1470, "Total num trained steps": 4096, "Timestamp in ms": 1701883428475, "logtype": "training_step"}
{"Avg objective": 15.3125, "Games time in secs": 301.0307399779558, "Avg game time in secs": 153.99288772455475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"reached_maximum_moves": 0.58, "played_steps": 14.07, "agent_stopped_0": 0.15, "agent_stopped_more": 0.27}, "Total num played games": 1536, "Total num trained steps": 4212, "Timestamp in ms": 1701883559158, "logtype": "played_game"}
{"Total num played games": 1582, "Total num trained steps": 4212, "Timestamp in ms": 1701883755738, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.6640625}
{"Ratio train steps to played games": 2.6666666666666665, "Avg loss": 1.3764519859105349, "Avg value loss": 1.0221493132412434, "Avg policy loss": 0.35430267616175115, "Total num played games": 1584, "Total num trained steps": 4224, "Timestamp in ms": 1701883761488, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7166042446941323, "Avg loss": 1.5316893244162202, "Avg value loss": 1.1783611387945712, "Avg policy loss": 0.35332819912582636, "Total num played games": 1602, "Total num trained steps": 4352, "Timestamp in ms": 1701883820852, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7860696517412937, "Avg loss": 1.2011470249854028, "Avg value loss": 0.8506647516041994, "Avg policy loss": 0.3504822817631066, "Total num played games": 1608, "Total num trained steps": 4480, "Timestamp in ms": 1701883879660, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8131868131868134, "Avg loss": 1.21562740765512, "Avg value loss": 0.8632283830083907, "Avg policy loss": 0.35239903279580176, "Total num played games": 1638, "Total num trained steps": 4608, "Timestamp in ms": 1701883939119, "logtype": "training_step"}
{"Ratio train steps to played games": 2.859903381642512, "Avg loss": 1.2696932111866772, "Avg value loss": 0.9122759737074375, "Avg policy loss": 0.35741724516265094, "Total num played games": 1656, "Total num trained steps": 4736, "Timestamp in ms": 1701883998528, "logtype": "training_step"}
{"Avg objective": 15.8125, "Games time in secs": 448.32259169593453, "Avg game time in secs": 148.46275605887058, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"reached_maximum_moves": 0.5, "played_steps": 13.21, "agent_stopped_more": 0.35, "agent_stopped_0": 0.15}, "Total num played games": 1664, "Total num trained steps": 4755, "Timestamp in ms": 1701884007481, "logtype": "played_game"}
{"Total num played games": 1758, "Total num trained steps": 4813, "Timestamp in ms": 1701884258667, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.00390625}
{"Ratio train steps to played games": 2.7480225988700564, "Avg loss": 1.5534997205249965, "Avg value loss": 1.194892925210297, "Avg policy loss": 0.3586068160366267, "Total num played games": 1770, "Total num trained steps": 4864, "Timestamp in ms": 1701884286554, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8013468013468015, "Avg loss": 1.4943009726703167, "Avg value loss": 1.1380976936779916, "Avg policy loss": 0.3562032990157604, "Total num played games": 1782, "Total num trained steps": 4992, "Timestamp in ms": 1701884347083, "logtype": "training_step"}
{"Avg objective": 15.46875, "Games time in secs": 381.9233081508428, "Avg game time in secs": 172.77700876085146, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 14.23, "reached_maximum_moves": 0.57, "agent_stopped_0": 0.12}, "Total num played games": 1792, "Total num trained steps": 5084, "Timestamp in ms": 1701884389404, "logtype": "played_game"}
{"Ratio train steps to played games": 2.841287458379578, "Avg loss": 1.200000355951488, "Avg value loss": 0.8459203797392547, "Avg policy loss": 0.3540799729526043, "Total num played games": 1802, "Total num trained steps": 5120, "Timestamp in ms": 1701884405559, "logtype": "training_step"}
{"Ratio train steps to played games": 2.83982683982684, "Avg loss": 1.2460302556864917, "Avg value loss": 0.8830637242645025, "Avg policy loss": 0.36296652909368277, "Total num played games": 1848, "Total num trained steps": 5248, "Timestamp in ms": 1701884464836, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8595744680851065, "Avg loss": 1.2226226404309273, "Avg value loss": 0.857481352519244, "Avg policy loss": 0.3651412813924253, "Total num played games": 1880, "Total num trained steps": 5376, "Timestamp in ms": 1701884523445, "logtype": "training_step"}
{"Avg objective": 16.546875, "Games time in secs": 203.1735453400761, "Avg game time in secs": 102.18507247681555, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 10.13, "reached_maximum_moves": 0.41, "agent_stopped_0": 0.23}, "Total num played games": 1920, "Total num trained steps": 5417, "Timestamp in ms": 1701884592578, "logtype": "played_game"}
{"Total num played games": 1970, "Total num trained steps": 5417, "Timestamp in ms": 1701884741971, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.34765625}
{"Ratio train steps to played games": 2.754754754754755, "Avg loss": 1.8893059906549752, "Avg value loss": 1.5138353537768126, "Avg policy loss": 0.37547064456157386, "Total num played games": 1998, "Total num trained steps": 5504, "Timestamp in ms": 1701884782479, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7798617966436328, "Avg loss": 1.3287420170381665, "Avg value loss": 0.9552015936933458, "Avg policy loss": 0.3735404242761433, "Total num played games": 2026, "Total num trained steps": 5632, "Timestamp in ms": 1701884841262, "logtype": "training_step"}
{"Avg objective": 17.96875, "Games time in secs": 294.8179553654045, "Avg game time in secs": 136.33280091828783, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 11.23, "reached_maximum_moves": 0.44, "agent_stopped_0": 0.22}, "Total num played games": 2048, "Total num trained steps": 5732, "Timestamp in ms": 1701884887396, "logtype": "played_game"}
{"Ratio train steps to played games": 2.806530214424951, "Avg loss": 1.1816941993311048, "Avg value loss": 0.8060819683596492, "Avg policy loss": 0.3756122374907136, "Total num played games": 2052, "Total num trained steps": 5760, "Timestamp in ms": 1701884900323, "logtype": "training_step"}
{"Ratio train steps to played games": 2.801141769743102, "Avg loss": 1.1865159813314676, "Avg value loss": 0.8097754567861557, "Avg policy loss": 0.37674051779322326, "Total num played games": 2102, "Total num trained steps": 5888, "Timestamp in ms": 1701884959938, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8297271872060206, "Avg loss": 1.1600218024104834, "Avg value loss": 0.7812605930957943, "Avg policy loss": 0.3787612160667777, "Total num played games": 2126, "Total num trained steps": 6016, "Timestamp in ms": 1701885018330, "logtype": "training_step"}
{"Avg objective": 16.4453125, "Games time in secs": 241.91186356917024, "Avg game time in secs": 113.74610897021194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 11.32, "reached_maximum_moves": 0.46, "agent_stopped_0": 0.22}, "Total num played games": 2176, "Total num trained steps": 6021, "Timestamp in ms": 1701885129308, "logtype": "played_game"}
{"Total num played games": 2212, "Total num trained steps": 6021, "Timestamp in ms": 1701885227353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.05078125}
{"Ratio train steps to played games": 2.742857142857143, "Avg loss": 1.7154501960612833, "Avg value loss": 1.3265871265903115, "Avg policy loss": 0.388863074593246, "Total num played games": 2240, "Total num trained steps": 6144, "Timestamp in ms": 1701885285495, "logtype": "training_step"}
{"Ratio train steps to played games": 2.782608695652174, "Avg loss": 1.1801582188345492, "Avg value loss": 0.784955887356773, "Avg policy loss": 0.3952023331075907, "Total num played games": 2254, "Total num trained steps": 6272, "Timestamp in ms": 1701885345063, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7996500437445317, "Avg loss": 1.0955537338741124, "Avg value loss": 0.6902111254166812, "Avg policy loss": 0.4053426068276167, "Total num played games": 2286, "Total num trained steps": 6400, "Timestamp in ms": 1701885404547, "logtype": "training_step"}
{"Avg objective": 17.5390625, "Games time in secs": 292.68565950356424, "Avg game time in secs": 109.45843234223139, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"reached_maximum_moves": 0.41, "played_steps": 10.38, "agent_stopped_more": 0.41, "agent_stopped_0": 0.18}, "Total num played games": 2304, "Total num trained steps": 6439, "Timestamp in ms": 1701885421994, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8137931034482757, "Avg loss": 1.2108509135432541, "Avg value loss": 0.8106376933865249, "Avg policy loss": 0.40021321969106793, "Total num played games": 2320, "Total num trained steps": 6528, "Timestamp in ms": 1701885462363, "logtype": "training_step"}
{"Total num played games": 2426, "Total num trained steps": 6623, "Timestamp in ms": 1701885684616, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2421875}
{"Avg objective": 16.3671875, "Games time in secs": 269.4534648284316, "Avg game time in secs": 149.26790300982248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"reached_maximum_moves": 0.53, "played_steps": 13.31, "agent_stopped_more": 0.3, "agent_stopped_0": 0.17}, "Total num played games": 2432, "Total num trained steps": 6637, "Timestamp in ms": 1701885691448, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7323481116584567, "Avg loss": 1.557751634158194, "Avg value loss": 1.1574087403714657, "Avg policy loss": 0.4003429068252444, "Total num played games": 2436, "Total num trained steps": 6656, "Timestamp in ms": 1701885699958, "logtype": "training_step"}
{"Ratio train steps to played games": 2.739903069466882, "Avg loss": 1.3855384550988674, "Avg value loss": 0.9750537844374776, "Avg policy loss": 0.41048467718064785, "Total num played games": 2476, "Total num trained steps": 6784, "Timestamp in ms": 1701885758131, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7581803671189147, "Avg loss": 1.1946324300952256, "Avg value loss": 0.7887684484012425, "Avg policy loss": 0.40586398052982986, "Total num played games": 2506, "Total num trained steps": 6912, "Timestamp in ms": 1701885816952, "logtype": "training_step"}
{"Ratio train steps to played games": 2.77602523659306, "Avg loss": 1.180692923720926, "Avg value loss": 0.7740465344395489, "Avg policy loss": 0.406646394636482, "Total num played games": 2536, "Total num trained steps": 7040, "Timestamp in ms": 1701885875780, "logtype": "training_step"}
{"Avg objective": 17.5, "Games time in secs": 209.33757174387574, "Avg game time in secs": 73.80135560546478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.38, "played_steps": 7.68, "reached_maximum_moves": 0.29}, "Total num played games": 2560, "Total num trained steps": 7094, "Timestamp in ms": 1701885900786, "logtype": "played_game"}
{"Ratio train steps to played games": 2.767181467181467, "Avg loss": 1.1245453469455242, "Avg value loss": 0.7148144778329879, "Avg policy loss": 0.40973086515441537, "Total num played games": 2590, "Total num trained steps": 7168, "Timestamp in ms": 1701885934761, "logtype": "training_step"}
{"Avg objective": 16.5234375, "Games time in secs": 228.00505747646093, "Avg game time in secs": 126.4948105277872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.22, "agent_stopped_more": 0.31, "played_steps": 11.65, "reached_maximum_moves": 0.47}, "Total num played games": 2688, "Total num trained steps": 7224, "Timestamp in ms": 1701886128791, "logtype": "played_game"}
{"Total num played games": 2694, "Total num trained steps": 7224, "Timestamp in ms": 1701886135693, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.06640625}
{"Ratio train steps to played games": 2.6725274725274724, "Avg loss": 1.9743367698974907, "Avg value loss": 1.5536958216689527, "Avg policy loss": 0.4206409598700702, "Total num played games": 2730, "Total num trained steps": 7296, "Timestamp in ms": 1701886168424, "logtype": "training_step"}
{"Ratio train steps to played games": 2.683658712942878, "Avg loss": 1.3475333000533283, "Avg value loss": 0.9270296809263527, "Avg policy loss": 0.4205036184284836, "Total num played games": 2766, "Total num trained steps": 7424, "Timestamp in ms": 1701886229037, "logtype": "training_step"}
{"Ratio train steps to played games": 2.691375623663578, "Avg loss": 1.1893329536542296, "Avg value loss": 0.7661434235051274, "Avg policy loss": 0.4231895301491022, "Total num played games": 2806, "Total num trained steps": 7552, "Timestamp in ms": 1701886287760, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 183.9310489781201, "Avg game time in secs": 46.817960003143526, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"reached_maximum_moves": 0.16, "played_steps": 4.98, "agent_stopped_0": 0.43, "agent_stopped_more": 0.41}, "Total num played games": 2816, "Total num trained steps": 7605, "Timestamp in ms": 1701886312723, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6740947075208914, "Avg loss": 1.3863263744860888, "Avg value loss": 0.9638501168228686, "Avg policy loss": 0.4224762499798089, "Total num played games": 2872, "Total num trained steps": 7680, "Timestamp in ms": 1701886346171, "logtype": "training_step"}
{"Avg objective": 19.75, "Games time in secs": 87.5043766964227, "Avg game time in secs": 63.05534346074273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "reached_maximum_moves": 0.23, "played_steps": 6.5, "agent_stopped_more": 0.38}, "Total num played games": 2944, "Total num trained steps": 7797, "Timestamp in ms": 1701886400227, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6503733876442634, "Avg loss": 1.4638874740339816, "Avg value loss": 1.0288016037084162, "Avg policy loss": 0.43508586240932345, "Total num played games": 2946, "Total num trained steps": 7808, "Timestamp in ms": 1701886405252, "logtype": "training_step"}
{"Total num played games": 3036, "Total num trained steps": 7827, "Timestamp in ms": 1701886595375, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.29296875}
{"Avg objective": 17.53125, "Games time in secs": 218.0233040433377, "Avg game time in secs": 80.2833889395697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 8.56, "agent_stopped_0": 0.29, "reached_maximum_moves": 0.34}, "Total num played games": 3072, "Total num trained steps": 7875, "Timestamp in ms": 1701886618250, "logtype": "played_game"}
{"Ratio train steps to played games": 2.568284789644013, "Avg loss": 1.8017855547368526, "Avg value loss": 1.3575089522637427, "Avg policy loss": 0.44427660945802927, "Total num played games": 3090, "Total num trained steps": 7936, "Timestamp in ms": 1701886645810, "logtype": "training_step"}
{"Ratio train steps to played games": 2.585952533675433, "Avg loss": 1.1747628501616418, "Avg value loss": 0.7302516391500831, "Avg policy loss": 0.44451120868325233, "Total num played games": 3118, "Total num trained steps": 8064, "Timestamp in ms": 1701886706013, "logtype": "training_step"}
{"Ratio train steps to played games": 2.577407174323474, "Avg loss": 1.1461807219311595, "Avg value loss": 0.7072781987953931, "Avg policy loss": 0.4389025252312422, "Total num played games": 3178, "Total num trained steps": 8192, "Timestamp in ms": 1701886764532, "logtype": "training_step"}
{"Avg objective": 19.21875, "Games time in secs": 157.41531064920127, "Avg game time in secs": 45.89829036986339, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 5.45, "agent_stopped_0": 0.47, "reached_maximum_moves": 0.19}, "Total num played games": 3200, "Total num trained steps": 8216, "Timestamp in ms": 1701886775666, "logtype": "played_game"}
{"Ratio train steps to played games": 2.54278728606357, "Avg loss": 1.4717082232236862, "Avg value loss": 1.0110382405109704, "Avg policy loss": 0.46066997572779655, "Total num played games": 3272, "Total num trained steps": 8320, "Timestamp in ms": 1701886822796, "logtype": "training_step"}
{"Avg objective": 19.5703125, "Games time in secs": 104.93551827594638, "Avg game time in secs": 40.35147009731736, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.29, "played_steps": 4.35, "reached_maximum_moves": 0.16}, "Total num played games": 3328, "Total num trained steps": 8430, "Timestamp in ms": 1701886880602, "logtype": "played_game"}
{"Total num played games": 3410, "Total num trained steps": 8430, "Timestamp in ms": 1701887088403, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.29296875}
{"Ratio train steps to played games": 2.4698830409356725, "Avg loss": 1.6860737791284919, "Avg value loss": 1.2311752303503454, "Avg policy loss": 0.45489855762571096, "Total num played games": 3420, "Total num trained steps": 8448, "Timestamp in ms": 1701887097217, "logtype": "training_step"}
{"Avg objective": 17.609375, "Games time in secs": 233.9458496104926, "Avg game time in secs": 96.74532019613252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"reached_maximum_moves": 0.37, "played_steps": 9.15, "agent_stopped_more": 0.27, "agent_stopped_0": 0.37}, "Total num played games": 3456, "Total num trained steps": 8485, "Timestamp in ms": 1701887114548, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4488863506567675, "Avg loss": 1.898327604867518, "Avg value loss": 1.4401508765295148, "Avg policy loss": 0.45817671227268875, "Total num played games": 3502, "Total num trained steps": 8576, "Timestamp in ms": 1701887156337, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4532130777903043, "Avg loss": 1.3638447159901261, "Avg value loss": 0.9074751348234713, "Avg policy loss": 0.4563695772085339, "Total num played games": 3548, "Total num trained steps": 8704, "Timestamp in ms": 1701887215938, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 131.40328805707395, "Avg game time in secs": 35.70149020459212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.33, "played_steps": 3.85, "reached_maximum_moves": 0.12}, "Total num played games": 3584, "Total num trained steps": 8768, "Timestamp in ms": 1701887245951, "logtype": "played_game"}
{"Ratio train steps to played games": 2.450610432852386, "Avg loss": 1.1842532232403755, "Avg value loss": 0.735977252246812, "Avg policy loss": 0.4482759677339345, "Total num played games": 3604, "Total num trained steps": 8832, "Timestamp in ms": 1701887274612, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4384866630375615, "Avg loss": 1.5235189250670373, "Avg value loss": 1.0749293095432222, "Avg policy loss": 0.4485896062105894, "Total num played games": 3674, "Total num trained steps": 8960, "Timestamp in ms": 1701887331841, "logtype": "training_step"}
{"Avg objective": 19.96875, "Games time in secs": 112.08961720950902, "Avg game time in secs": 58.77238462034438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"reached_maximum_moves": 0.24, "played_steps": 6.09, "agent_stopped_more": 0.29, "agent_stopped_0": 0.47}, "Total num played games": 3712, "Total num trained steps": 9017, "Timestamp in ms": 1701887358041, "logtype": "played_game"}
{"Total num played games": 3812, "Total num trained steps": 9031, "Timestamp in ms": 1701887592178, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.046875}
{"Avg objective": 17.2890625, "Games time in secs": 244.56865881197155, "Avg game time in secs": 92.71914020142867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.3, "played_steps": 8.44, "reached_maximum_moves": 0.32}, "Total num played games": 3840, "Total num trained steps": 9053, "Timestamp in ms": 1701887602610, "logtype": "played_game"}
{"Ratio train steps to played games": 2.339855818743563, "Avg loss": 2.0485166888684034, "Avg value loss": 1.5917918975465, "Avg policy loss": 0.45672479551285505, "Total num played games": 3884, "Total num trained steps": 9088, "Timestamp in ms": 1701887618591, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 69.77827025391161, "Avg game time in secs": 25.701313632147503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.98, "agent_stopped_0": 0.51, "reached_maximum_moves": 0.03}, "Total num played games": 3968, "Total num trained steps": 9205, "Timestamp in ms": 1701887672388, "logtype": "played_game"}
{"Ratio train steps to played games": 2.316742081447964, "Avg loss": 1.5885394448414445, "Avg value loss": 1.1265632477588952, "Avg policy loss": 0.46197619172744453, "Total num played games": 3978, "Total num trained steps": 9216, "Timestamp in ms": 1701887677607, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3186104218362282, "Avg loss": 1.2688174434006214, "Avg value loss": 0.8149325172416866, "Avg policy loss": 0.4538849217351526, "Total num played games": 4030, "Total num trained steps": 9344, "Timestamp in ms": 1701887736111, "logtype": "training_step"}
{"Avg objective": 19.078125, "Games time in secs": 114.48191156424582, "Avg game time in secs": 33.8680741348071, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.32, "played_steps": 3.99, "reached_maximum_moves": 0.15}, "Total num played games": 4096, "Total num trained steps": 9453, "Timestamp in ms": 1701887786870, "logtype": "played_game"}
{"Ratio train steps to played games": 2.3001457017969886, "Avg loss": 1.4613129226490855, "Avg value loss": 1.0201237245928496, "Avg policy loss": 0.44118920317851007, "Total num played games": 4118, "Total num trained steps": 9472, "Timestamp in ms": 1701887795602, "logtype": "training_step"}
{"Avg objective": 18.8046875, "Games time in secs": 49.45791304111481, "Avg game time in secs": 34.73639980364533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.3, "played_steps": 3.68, "reached_maximum_moves": 0.14}, "Total num played games": 4224, "Total num trained steps": 9559, "Timestamp in ms": 1701887836328, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2620169651272386, "Avg loss": 1.5441738972440362, "Avg value loss": 1.0941667170263827, "Avg policy loss": 0.4500071897637099, "Total num played games": 4244, "Total num trained steps": 9600, "Timestamp in ms": 1701887854658, "logtype": "training_step"}
{"Total num played games": 4348, "Total num trained steps": 9634, "Timestamp in ms": 1701888097270, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.35546875}
{"Avg objective": 18.40625, "Games time in secs": 267.26546762511134, "Avg game time in secs": 76.34917747143481, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 8.87, "agent_stopped_0": 0.34, "reached_maximum_moves": 0.35}, "Total num played games": 4352, "Total num trained steps": 9644, "Timestamp in ms": 1701888103594, "logtype": "played_game"}
{"Ratio train steps to played games": 2.1753130590339893, "Avg loss": 2.116873888298869, "Avg value loss": 1.6762574249878526, "Avg policy loss": 0.4406164507381618, "Total num played games": 4472, "Total num trained steps": 9728, "Timestamp in ms": 1701888141719, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 46.078947216272354, "Avg game time in secs": 9.458343778576818, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.47}, "Total num played games": 4480, "Total num trained steps": 9745, "Timestamp in ms": 1701888149673, "logtype": "played_game"}
{"Ratio train steps to played games": 2.169969176574196, "Avg loss": 1.4172832975164056, "Avg value loss": 0.9730590116232634, "Avg policy loss": 0.4442242805380374, "Total num played games": 4542, "Total num trained steps": 9856, "Timestamp in ms": 1701888199622, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 83.11234267614782, "Avg game time in secs": 24.45119786831492, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 2.73, "agent_stopped_0": 0.54, "reached_maximum_moves": 0.05}, "Total num played games": 4608, "Total num trained steps": 9929, "Timestamp in ms": 1701888232785, "logtype": "played_game"}
{"Ratio train steps to played games": 2.1258517887563886, "Avg loss": 1.8955200901255012, "Avg value loss": 1.4542849701829255, "Avg policy loss": 0.4412351157516241, "Total num played games": 4696, "Total num trained steps": 9984, "Timestamp in ms": 1701888257478, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 39.908791311085224, "Avg game time in secs": 23.912910261089564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 2.63, "reached_maximum_moves": 0.09, "agent_stopped_0": 0.53}, "Total num played games": 4736, "Total num trained steps": 10017, "Timestamp in ms": 1701888272694, "logtype": "played_game"}
{"Ratio train steps to played games": 2.094241922120961, "Avg loss": 1.9800417991355062, "Avg value loss": 1.5348102254793048, "Avg policy loss": 0.4452315878588706, "Total num played games": 4828, "Total num trained steps": 10112, "Timestamp in ms": 1701888315110, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 60.23548221029341, "Avg game time in secs": 28.337461610411992, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 3.19, "agent_stopped_0": 0.54, "reached_maximum_moves": 0.11}, "Total num played games": 4864, "Total num trained steps": 10152, "Timestamp in ms": 1701888332930, "logtype": "played_game"}
{"Avg objective": 18.875, "Games time in secs": 173.07849849574268, "Avg game time in secs": 57.22331371484324, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.32, "played_steps": 7.16, "reached_maximum_moves": 0.26}, "Total num played games": 4992, "Total num trained steps": 10238, "Timestamp in ms": 1701888506008, "logtype": "played_game"}
{"Total num played games": 5002, "Total num trained steps": 10238, "Timestamp in ms": 1701888539898, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9453125}
{"Ratio train steps to played games": 2.0471811275489804, "Avg loss": 1.7018567267805338, "Avg value loss": 1.248390655964613, "Avg policy loss": 0.45346606336534023, "Total num played games": 5002, "Total num trained steps": 10240, "Timestamp in ms": 1701888541412, "logtype": "training_step"}
{"Avg objective": 21.640625, "Games time in secs": 63.933313090354204, "Avg game time in secs": 18.51738230677438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 1.59, "agent_stopped_0": 0.65, "reached_maximum_moves": 0.04}, "Total num played games": 5120, "Total num trained steps": 10303, "Timestamp in ms": 1701888569942, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900191938579654, "Avg loss": 2.5761674661189318, "Avg value loss": 2.11742235487327, "Avg policy loss": 0.45874514267779887, "Total num played games": 5210, "Total num trained steps": 10368, "Timestamp in ms": 1701888599004, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 47.415734346956015, "Avg game time in secs": 14.052943165734177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 1.05}, "Total num played games": 5248, "Total num trained steps": 10408, "Timestamp in ms": 1701888617358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9655430711610486, "Avg loss": 1.8042606739327312, "Avg value loss": 1.3536701267585158, "Avg policy loss": 0.45059053995646536, "Total num played games": 5340, "Total num trained steps": 10496, "Timestamp in ms": 1701888657030, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 59.4997734464705, "Avg game time in secs": 17.719714487495366, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.27, "played_steps": 1.7, "reached_maximum_moves": 0.05}, "Total num played games": 5376, "Total num trained steps": 10540, "Timestamp in ms": 1701888676858, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9465005496518872, "Avg loss": 1.4852622807957232, "Avg value loss": 1.036943738348782, "Avg policy loss": 0.44831854826770723, "Total num played games": 5458, "Total num trained steps": 10624, "Timestamp in ms": 1701888714127, "logtype": "training_step"}
{"Avg objective": 19.40625, "Games time in secs": 54.240492491051555, "Avg game time in secs": 29.076838697103085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 3.41, "agent_stopped_0": 0.56, "reached_maximum_moves": 0.11}, "Total num played games": 5504, "Total num trained steps": 10661, "Timestamp in ms": 1701888731098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9172610556348073, "Avg loss": 1.6174512803554535, "Avg value loss": 1.1720104543492198, "Avg policy loss": 0.4454408229794353, "Total num played games": 5606, "Total num trained steps": 10752, "Timestamp in ms": 1701888772193, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 54.063023107126355, "Avg game time in secs": 26.797797016406548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 2.74, "agent_stopped_0": 0.52, "reached_maximum_moves": 0.07}, "Total num played games": 5632, "Total num trained steps": 10780, "Timestamp in ms": 1701888785161, "logtype": "played_game"}
{"Total num played games": 5750, "Total num trained steps": 10839, "Timestamp in ms": 1701888962707, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.92578125}
{"Avg objective": 18.703125, "Games time in secs": 184.07007702812552, "Avg game time in secs": 49.73451609525364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "reached_maximum_moves": 0.27, "played_steps": 6.29, "agent_stopped_more": 0.3}, "Total num played games": 5760, "Total num trained steps": 10852, "Timestamp in ms": 1701888969232, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8719889883000689, "Avg loss": 1.8257285002619028, "Avg value loss": 1.388733355794102, "Avg policy loss": 0.43699514702893794, "Total num played games": 5812, "Total num trained steps": 10880, "Timestamp in ms": 1701888982451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.89010989010989, "Avg loss": 1.275042722467333, "Avg value loss": 0.8492865059524775, "Avg policy loss": 0.4257562146522105, "Total num played games": 5824, "Total num trained steps": 11008, "Timestamp in ms": 1701889044942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.907502569373073, "Avg loss": 0.9792711543850601, "Avg value loss": 0.56300043547526, "Avg policy loss": 0.416270716348663, "Total num played games": 5838, "Total num trained steps": 11136, "Timestamp in ms": 1701889107344, "logtype": "training_step"}
{"Avg objective": 20.4921875, "Games time in secs": 160.84595128707588, "Avg game time in secs": 16.293730302437325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.23, "played_steps": 1.69, "reached_maximum_moves": 0.05}, "Total num played games": 5888, "Total num trained steps": 11186, "Timestamp in ms": 1701889130078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9001349527665317, "Avg loss": 1.1540971002541482, "Avg value loss": 0.732653264189139, "Avg policy loss": 0.4214438439812511, "Total num played games": 5928, "Total num trained steps": 11264, "Timestamp in ms": 1701889167181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8980339886704432, "Avg loss": 1.0498274168930948, "Avg value loss": 0.6363285125698894, "Avg policy loss": 0.413498904556036, "Total num played games": 6002, "Total num trained steps": 11392, "Timestamp in ms": 1701889227245, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 162.31599459797144, "Avg game time in secs": 18.285637111679534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.42, "played_steps": 1.9, "reached_maximum_moves": 0.05}, "Total num played games": 6016, "Total num trained steps": 11439, "Timestamp in ms": 1701889292394, "logtype": "played_game"}
{"Total num played games": 6028, "Total num trained steps": 11439, "Timestamp in ms": 1701889390373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.94140625}
{"Ratio train steps to played games": 1.8854337152209493, "Avg loss": 1.182396061718464, "Avg value loss": 0.7658776531461626, "Avg policy loss": 0.41651840531267226, "Total num played games": 6110, "Total num trained steps": 11520, "Timestamp in ms": 1701889428226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9049721949623815, "Avg loss": 0.8395102857612073, "Avg value loss": 0.432864329777658, "Avg policy loss": 0.40664595621638, "Total num played games": 6114, "Total num trained steps": 11648, "Timestamp in ms": 1701889489131, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 241.91754262521863, "Avg game time in secs": 16.723070908992668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.23, "played_steps": 1.72, "reached_maximum_moves": 0.05}, "Total num played games": 6144, "Total num trained steps": 11742, "Timestamp in ms": 1701889534312, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8956857694784288, "Avg loss": 1.1798769324086607, "Avg value loss": 0.7850867023225874, "Avg policy loss": 0.3947902275249362, "Total num played games": 6212, "Total num trained steps": 11776, "Timestamp in ms": 1701889551097, "logtype": "training_step"}
{"Ratio train steps to played games": 1.915057915057915, "Avg loss": 0.9059951696544886, "Avg value loss": 0.5096244397573173, "Avg policy loss": 0.39637073199264705, "Total num played games": 6216, "Total num trained steps": 11904, "Timestamp in ms": 1701889612535, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 96.07475187815726, "Avg game time in secs": 8.736522033257643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.23, "played_steps": 0.49, "reached_maximum_moves": 0.01}, "Total num played games": 6272, "Total num trained steps": 11943, "Timestamp in ms": 1701889630386, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9092351634401776, "Avg loss": 1.100333926267922, "Avg value loss": 0.7252607885748148, "Avg policy loss": 0.3750731414183974, "Total num played games": 6302, "Total num trained steps": 12032, "Timestamp in ms": 1701889673306, "logtype": "training_step"}
{"Total num played games": 6318, "Total num trained steps": 12041, "Timestamp in ms": 1701889860304, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.76171875}
{"Avg objective": 20.6328125, "Games time in secs": 249.38145950436592, "Avg game time in secs": 18.494493439487997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.34, "played_steps": 1.98, "reached_maximum_moves": 0.05}, "Total num played games": 6400, "Total num trained steps": 12081, "Timestamp in ms": 1701889879768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8982204183577895, "Avg loss": 1.1852089678868651, "Avg value loss": 0.8012899558525532, "Avg policy loss": 0.383919021114707, "Total num played games": 6406, "Total num trained steps": 12160, "Timestamp in ms": 1701889918112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9170046801872076, "Avg loss": 0.7624167250469327, "Avg value loss": 0.3864887508098036, "Avg policy loss": 0.37592797656543553, "Total num played games": 6410, "Total num trained steps": 12288, "Timestamp in ms": 1701889980967, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9107417666974453, "Avg loss": 1.1259674048051238, "Avg value loss": 0.7489644575398415, "Avg policy loss": 0.37700294121168554, "Total num played games": 6498, "Total num trained steps": 12416, "Timestamp in ms": 1701890040244, "logtype": "training_step"}
{"Avg objective": 22.1796875, "Games time in secs": 199.03750843554735, "Avg game time in secs": 11.322243854490807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.25, "played_steps": 0.83, "reached_maximum_moves": 0.01}, "Total num played games": 6528, "Total num trained steps": 12500, "Timestamp in ms": 1701890078806, "logtype": "played_game"}
{"Ratio train steps to played games": 1.905803707079915, "Avg loss": 1.0042024021968246, "Avg value loss": 0.6351036629639566, "Avg policy loss": 0.3690987329464406, "Total num played games": 6582, "Total num trained steps": 12544, "Timestamp in ms": 1701890098898, "logtype": "training_step"}
{"Total num played games": 6600, "Total num trained steps": 12642, "Timestamp in ms": 1701890300409, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1015625}
{"Avg objective": 20.5234375, "Games time in secs": 230.88386314176023, "Avg game time in secs": 17.58809517849295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.3, "played_steps": 1.88, "reached_maximum_moves": 0.06}, "Total num played games": 6656, "Total num trained steps": 12661, "Timestamp in ms": 1701890309690, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8975741239892183, "Avg loss": 1.0050224149599671, "Avg value loss": 0.6381094572134316, "Avg policy loss": 0.36691294936463237, "Total num played games": 6678, "Total num trained steps": 12672, "Timestamp in ms": 1701890314899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9127316198445905, "Avg loss": 0.9270665072835982, "Avg value loss": 0.5743997078388929, "Avg policy loss": 0.3526667985133827, "Total num played games": 6692, "Total num trained steps": 12800, "Timestamp in ms": 1701890375589, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9067846607669616, "Avg loss": 0.9579489820171148, "Avg value loss": 0.6081931522348896, "Avg policy loss": 0.349755825009197, "Total num played games": 6780, "Total num trained steps": 12928, "Timestamp in ms": 1701890435843, "logtype": "training_step"}
{"Avg objective": 22.9453125, "Games time in secs": 157.74757671914995, "Avg game time in secs": 9.996361440527835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.4, "played_steps": 0.8, "reached_maximum_moves": 0.01}, "Total num played games": 6784, "Total num trained steps": 12995, "Timestamp in ms": 1701890467438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9245283018867925, "Avg loss": 0.6975053902715445, "Avg value loss": 0.3586485928390175, "Avg policy loss": 0.33885680290404707, "Total num played games": 6784, "Total num trained steps": 13056, "Timestamp in ms": 1701890495577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9157221737866899, "Avg loss": 1.0065956767648458, "Avg value loss": 0.6634801516775042, "Avg policy loss": 0.34311552182771266, "Total num played games": 6882, "Total num trained steps": 13184, "Timestamp in ms": 1701890558392, "logtype": "training_step"}
{"Total num played games": 6886, "Total num trained steps": 13245, "Timestamp in ms": 1701890877766, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.07421875}
{"Avg objective": 21.4296875, "Games time in secs": 417.7000009957701, "Avg game time in secs": 13.193948301384808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.28, "played_steps": 1.38, "reached_maximum_moves": 0.03}, "Total num played games": 6912, "Total num trained steps": 13260, "Timestamp in ms": 1701890885138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.908256880733945, "Avg loss": 1.102476756554097, "Avg value loss": 0.7676104011479765, "Avg policy loss": 0.33486635505687445, "Total num played games": 6976, "Total num trained steps": 13312, "Timestamp in ms": 1701890910031, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9260533104041273, "Avg loss": 0.688716490752995, "Avg value loss": 0.3545992053113878, "Avg policy loss": 0.3341172819491476, "Total num played games": 6978, "Total num trained steps": 13440, "Timestamp in ms": 1701890972071, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 96.91152708791196, "Avg game time in secs": 7.88243775824958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.43}, "Total num played games": 7040, "Total num trained steps": 13462, "Timestamp in ms": 1701890982050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.919637804187889, "Avg loss": 1.0181891494430602, "Avg value loss": 0.6797236509155482, "Avg policy loss": 0.3384655015543103, "Total num played games": 7068, "Total num trained steps": 13568, "Timestamp in ms": 1701891031956, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9128491620111732, "Avg loss": 1.0301022890489548, "Avg value loss": 0.6908117614220828, "Avg policy loss": 0.3392905304208398, "Total num played games": 7160, "Total num trained steps": 13696, "Timestamp in ms": 1701891091531, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 171.00690337643027, "Avg game time in secs": 13.046141119542881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.38, "played_steps": 1.35, "reached_maximum_moves": 0.03}, "Total num played games": 7168, "Total num trained steps": 13823, "Timestamp in ms": 1701891153057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9280334728033472, "Avg loss": 0.7097944160923362, "Avg value loss": 0.3742704455507919, "Avg policy loss": 0.3355239671654999, "Total num played games": 7170, "Total num trained steps": 13824, "Timestamp in ms": 1701891153221, "logtype": "training_step"}
{"Total num played games": 7262, "Total num trained steps": 13849, "Timestamp in ms": 1701891301388, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.64453125}
{"Avg objective": 21.0, "Games time in secs": 154.87949136644602, "Avg game time in secs": 10.558514250835287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.21, "played_steps": 0.78, "agent_stopped_0": 0.77, "reached_maximum_moves": 0.02}, "Total num played games": 7296, "Total num trained steps": 13862, "Timestamp in ms": 1701891307937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.897714907508161, "Avg loss": 1.6150663397274911, "Avg value loss": 1.270605324069038, "Avg policy loss": 0.3444610165897757, "Total num played games": 7352, "Total num trained steps": 13952, "Timestamp in ms": 1701891350089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9146042969812347, "Avg loss": 0.6658448739908636, "Avg value loss": 0.34129779727663845, "Avg policy loss": 0.32454707683064044, "Total num played games": 7354, "Total num trained steps": 14080, "Timestamp in ms": 1701891409684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9278154681139756, "Avg loss": 0.6203453270718455, "Avg value loss": 0.3008599770255387, "Avg policy loss": 0.31948534643743187, "Total num played games": 7370, "Total num trained steps": 14208, "Timestamp in ms": 1701891467204, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 164.84072247333825, "Avg game time in secs": 10.0433828473615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.33, "played_steps": 0.8, "reached_maximum_moves": 0.02}, "Total num played games": 7424, "Total num trained steps": 14220, "Timestamp in ms": 1701891472778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9236446591519056, "Avg loss": 0.9023395958356559, "Avg value loss": 0.5766724325949326, "Avg policy loss": 0.3256671620765701, "Total num played games": 7452, "Total num trained steps": 14336, "Timestamp in ms": 1701891526560, "logtype": "training_step"}
{"Total num played games": 7550, "Total num trained steps": 14449, "Timestamp in ms": 1701891827535, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.63671875}
{"Avg objective": 23.234375, "Games time in secs": 357.2973764333874, "Avg game time in secs": 11.299559345847229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.42, "played_steps": 1.11, "reached_maximum_moves": 0.02}, "Total num played games": 7552, "Total num trained steps": 14453, "Timestamp in ms": 1701891830075, "logtype": "played_game"}
{"Ratio train steps to played games": 1.904160084254871, "Avg loss": 1.0993444949854165, "Avg value loss": 0.7767701968550682, "Avg policy loss": 0.3225742932409048, "Total num played games": 7594, "Total num trained steps": 14464, "Timestamp in ms": 1701891834437, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9093169327401205, "Avg loss": 1.0289412857964635, "Avg value loss": 0.688367837225087, "Avg policy loss": 0.3405734512489289, "Total num played games": 7642, "Total num trained steps": 14592, "Timestamp in ms": 1701891894071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.926197330541743, "Avg loss": 0.6165657856035978, "Avg value loss": 0.29830987623427063, "Avg policy loss": 0.31825590960215777, "Total num played games": 7642, "Total num trained steps": 14720, "Timestamp in ms": 1701891953637, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 153.2306820563972, "Avg game time in secs": 7.321496240896522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.18, "played_steps": 0.42, "reached_maximum_moves": 0.01}, "Total num played games": 7680, "Total num trained steps": 14785, "Timestamp in ms": 1701891983313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.919338159255429, "Avg loss": 1.0712405459489673, "Avg value loss": 0.7561950881499797, "Avg policy loss": 0.3150454662973061, "Total num played games": 7736, "Total num trained steps": 14848, "Timestamp in ms": 1701892012411, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9308922124806602, "Avg loss": 0.6136557441204786, "Avg value loss": 0.30601004825439304, "Avg policy loss": 0.30764569574967027, "Total num played games": 7756, "Total num trained steps": 14976, "Timestamp in ms": 1701892071648, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 93.15659832395613, "Avg game time in secs": 6.635510668886127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.43}, "Total num played games": 7808, "Total num trained steps": 14986, "Timestamp in ms": 1701892076469, "logtype": "played_game"}
{"Total num played games": 7836, "Total num trained steps": 15049, "Timestamp in ms": 1701892343145, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.09765625}
{"Ratio train steps to played games": 1.905627050214484, "Avg loss": 1.2911476618610322, "Avg value loss": 0.9889252838911489, "Avg policy loss": 0.3022223792504519, "Total num played games": 7926, "Total num trained steps": 15104, "Timestamp in ms": 1701892367741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9208070617906683, "Avg loss": 0.6512567498721182, "Avg value loss": 0.34746562654618174, "Avg policy loss": 0.30379112425725907, "Total num played games": 7930, "Total num trained steps": 15232, "Timestamp in ms": 1701892427276, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 407.61678638495505, "Avg game time in secs": 8.840748390022782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.82, "agent_stopped_0": 0.61}, "Total num played games": 7936, "Total num trained steps": 15357, "Timestamp in ms": 1701892484086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9324358329139406, "Avg loss": 0.5230853063985705, "Avg value loss": 0.2407123901648447, "Avg policy loss": 0.28237291728146374, "Total num played games": 7948, "Total num trained steps": 15360, "Timestamp in ms": 1701892485112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.929728382756043, "Avg loss": 0.8160860084462911, "Avg value loss": 0.514926505391486, "Avg policy loss": 0.3011595036368817, "Total num played games": 8026, "Total num trained steps": 15488, "Timestamp in ms": 1701892542827, "logtype": "training_step"}
{"Avg objective": 23.390625, "Games time in secs": 88.30390551313758, "Avg game time in secs": 5.8955107856018, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.41, "agent_stopped_0": 0.7}, "Total num played games": 8064, "Total num trained steps": 15555, "Timestamp in ms": 1701892572390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9222058099458394, "Avg loss": 1.0198850960005075, "Avg value loss": 0.7187942981254309, "Avg policy loss": 0.3010907961288467, "Total num played games": 8124, "Total num trained steps": 15616, "Timestamp in ms": 1701892599236, "logtype": "training_step"}
{"Total num played games": 8124, "Total num trained steps": 15650, "Timestamp in ms": 1701892719858, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8359375}
{"Avg objective": 22.7890625, "Games time in secs": 156.53174577467144, "Avg game time in secs": 7.120806900144089, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.33, "played_steps": 0.52, "reached_maximum_moves": 0.01}, "Total num played games": 8192, "Total num trained steps": 15671, "Timestamp in ms": 1701892728922, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9162609542356377, "Avg loss": 1.1405308661051095, "Avg value loss": 0.8171846945770085, "Avg policy loss": 0.3233461774652824, "Total num played games": 8216, "Total num trained steps": 15744, "Timestamp in ms": 1701892761811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.931840311587147, "Avg loss": 0.6112294122576714, "Avg value loss": 0.2960426489589736, "Avg policy loss": 0.3151867630658671, "Total num played games": 8216, "Total num trained steps": 15872, "Timestamp in ms": 1701892820541, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9244647582391148, "Avg loss": 0.910825417842716, "Avg value loss": 0.5989358805818483, "Avg policy loss": 0.3118895416846499, "Total num played games": 8314, "Total num trained steps": 16000, "Timestamp in ms": 1701892877648, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 203.60981167666614, "Avg game time in secs": 7.936625204602024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.74, "reached_maximum_moves": 0.01}, "Total num played games": 8320, "Total num trained steps": 16124, "Timestamp in ms": 1701892932532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.936599423631124, "Avg loss": 0.6115363042335957, "Avg value loss": 0.30478791519999504, "Avg policy loss": 0.3067483881022781, "Total num played games": 8326, "Total num trained steps": 16128, "Timestamp in ms": 1701892933897, "logtype": "training_step"}
{"Total num played games": 8412, "Total num trained steps": 16250, "Timestamp in ms": 1701893162659, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1796875}
{"Ratio train steps to played games": 1.9324774132192106, "Avg loss": 0.9218253793660551, "Avg value loss": 0.6085139870410785, "Avg policy loss": 0.31331139139365405, "Total num played games": 8412, "Total num trained steps": 16256, "Timestamp in ms": 1701893165367, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 235.93523179367185, "Avg game time in secs": 6.279255096742418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.78, "agent_stopped_more": 0.21, "played_steps": 0.44, "reached_maximum_moves": 0.01}, "Total num played games": 8448, "Total num trained steps": 16263, "Timestamp in ms": 1701893168467, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9266227657572907, "Avg loss": 0.9070464698597789, "Avg value loss": 0.5917909804265946, "Avg policy loss": 0.3152554832631722, "Total num played games": 8504, "Total num trained steps": 16384, "Timestamp in ms": 1701893222104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.930776426566885, "Avg loss": 0.5532008337322623, "Avg value loss": 0.2586056248983368, "Avg policy loss": 0.2945952118607238, "Total num played games": 8552, "Total num trained steps": 16512, "Timestamp in ms": 1701893275800, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 109.40261835046113, "Avg game time in secs": 5.975963553690235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.47, "agent_stopped_0": 0.6}, "Total num played games": 8576, "Total num trained steps": 16516, "Timestamp in ms": 1701893277870, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9344338525924203, "Avg loss": 0.819155917968601, "Avg value loss": 0.5138751462800428, "Avg policy loss": 0.3052807628409937, "Total num played games": 8602, "Total num trained steps": 16640, "Timestamp in ms": 1701893331706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9281278748850046, "Avg loss": 0.840524687198922, "Avg value loss": 0.5403570431517437, "Avg policy loss": 0.3001676476560533, "Total num played games": 8696, "Total num trained steps": 16768, "Timestamp in ms": 1701893389033, "logtype": "training_step"}
{"Total num played games": 8698, "Total num trained steps": 16853, "Timestamp in ms": 1701893663210, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.234375}
{"Avg objective": 21.375, "Games time in secs": 388.816870264709, "Avg game time in secs": 7.831499938532943, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.8, "agent_stopped_0": 0.53, "reached_maximum_moves": 0.01}, "Total num played games": 8704, "Total num trained steps": 16859, "Timestamp in ms": 1701893666687, "logtype": "played_game"}
{"Ratio train steps to played games": 1.921747042766151, "Avg loss": 0.9023946940433234, "Avg value loss": 0.6116818669252098, "Avg policy loss": 0.2907128237420693, "Total num played games": 8792, "Total num trained steps": 16896, "Timestamp in ms": 1701893682278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9363057324840764, "Avg loss": 0.6254319110885262, "Avg value loss": 0.32402381976135075, "Avg policy loss": 0.30140809912700206, "Total num played games": 8792, "Total num trained steps": 17024, "Timestamp in ms": 1701893738209, "logtype": "training_step"}
{"Avg objective": 22.6796875, "Games time in secs": 96.95297078043222, "Avg game time in secs": 4.816202148300363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.37}, "Total num played games": 8832, "Total num trained steps": 17084, "Timestamp in ms": 1701893763640, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9297929792979298, "Avg loss": 0.9116625858005136, "Avg value loss": 0.6144149885512888, "Avg policy loss": 0.2972476000431925, "Total num played games": 8888, "Total num trained steps": 17152, "Timestamp in ms": 1701893792835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.931157800625838, "Avg loss": 0.5546895929146558, "Avg value loss": 0.26535201515071094, "Avg policy loss": 0.28933758253697306, "Total num played games": 8948, "Total num trained steps": 17280, "Timestamp in ms": 1701893847010, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 84.9194374717772, "Avg game time in secs": 4.892458572066971, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 8960, "Total num trained steps": 17283, "Timestamp in ms": 1701893848559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.93766696349065, "Avg loss": 0.9273047673050314, "Avg value loss": 0.6213403311558068, "Avg policy loss": 0.30596443673130125, "Total num played games": 8984, "Total num trained steps": 17408, "Timestamp in ms": 1701893902440, "logtype": "training_step"}
{"Total num played games": 8984, "Total num trained steps": 17456, "Timestamp in ms": 1701894065230, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.578125}
{"Ratio train steps to played games": 1.9312775330396477, "Avg loss": 0.8238731718156487, "Avg value loss": 0.5270126996329054, "Avg policy loss": 0.296860474627465, "Total num played games": 9080, "Total num trained steps": 17536, "Timestamp in ms": 1701894098712, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 299.7576389685273, "Avg game time in secs": 5.972416920500109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.67}, "Total num played games": 9088, "Total num trained steps": 17657, "Timestamp in ms": 1701894148317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9326039387308533, "Avg loss": 0.5807392105925828, "Avg value loss": 0.28531719848979264, "Avg policy loss": 0.2954220100073144, "Total num played games": 9140, "Total num trained steps": 17664, "Timestamp in ms": 1701894151089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9384397472216168, "Avg loss": 1.0307728943880647, "Avg value loss": 0.7085900619858876, "Avg policy loss": 0.3221828263485804, "Total num played games": 9178, "Total num trained steps": 17792, "Timestamp in ms": 1701894206495, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 84.17220239713788, "Avg game time in secs": 4.537229536261293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.35}, "Total num played games": 9216, "Total num trained steps": 17854, "Timestamp in ms": 1701894232490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9322838041837396, "Avg loss": 0.7903283901978284, "Avg value loss": 0.47439456288702786, "Avg policy loss": 0.31593382474966347, "Total num played games": 9274, "Total num trained steps": 17920, "Timestamp in ms": 1701894260791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9373121511378273, "Avg loss": 0.536690165521577, "Avg value loss": 0.23386983713135123, "Avg policy loss": 0.30282032629475, "Total num played games": 9314, "Total num trained steps": 18048, "Timestamp in ms": 1701894314292, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 83.73683324456215, "Avg game time in secs": 4.619742400289397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.45}, "Total num played games": 9344, "Total num trained steps": 18053, "Timestamp in ms": 1701894316226, "logtype": "played_game"}
{"Total num played games": 9370, "Total num trained steps": 18059, "Timestamp in ms": 1701894544416, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.24609375}
{"Ratio train steps to played games": 1.9209469456774466, "Avg loss": 1.396483133547008, "Avg value loss": 1.064804736408405, "Avg policy loss": 0.3316784077323973, "Total num played games": 9462, "Total num trained steps": 18176, "Timestamp in ms": 1701894596554, "logtype": "training_step"}
{"Ratio train steps to played games": 1.934065934065934, "Avg loss": 0.5747934835962951, "Avg value loss": 0.26477138057816774, "Avg policy loss": 0.31002210383303463, "Total num played games": 9464, "Total num trained steps": 18304, "Timestamp in ms": 1701894649069, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 382.616919465363, "Avg game time in secs": 6.2785826986364555, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.72, "agent_stopped_0": 0.59}, "Total num played games": 9472, "Total num trained steps": 18423, "Timestamp in ms": 1701894698844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.936541290187014, "Avg loss": 0.5308566060848534, "Avg value loss": 0.24324145092396066, "Avg policy loss": 0.28761515335645527, "Total num played games": 9518, "Total num trained steps": 18432, "Timestamp in ms": 1701894702056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9414225941422594, "Avg loss": 0.7613982420880347, "Avg value loss": 0.4617794557707384, "Avg policy loss": 0.2996187835233286, "Total num played games": 9560, "Total num trained steps": 18560, "Timestamp in ms": 1701894755710, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 80.92992147803307, "Avg game time in secs": 4.336040679219877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.48}, "Total num played games": 9600, "Total num trained steps": 18619, "Timestamp in ms": 1701894779774, "logtype": "played_game"}
{"Total num played games": 9656, "Total num trained steps": 18660, "Timestamp in ms": 1701894918330, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.23828125}
{"Avg objective": 21.578125, "Games time in secs": 145.22838832065463, "Avg game time in secs": 4.464481822942616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.45}, "Total num played games": 9728, "Total num trained steps": 18674, "Timestamp in ms": 1701894925002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9171112022979073, "Avg loss": 0.9085162524133921, "Avg value loss": 0.6176962131867185, "Avg policy loss": 0.2908200464444235, "Total num played games": 9748, "Total num trained steps": 18688, "Timestamp in ms": 1701894930537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9298461538461538, "Avg loss": 0.7250997093506157, "Avg value loss": 0.41118652699515224, "Avg policy loss": 0.31391318002715707, "Total num played games": 9750, "Total num trained steps": 18816, "Timestamp in ms": 1701894984555, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9429743589743589, "Avg loss": 0.4886978198774159, "Avg value loss": 0.20014660467859358, "Avg policy loss": 0.2885512177599594, "Total num played games": 9750, "Total num trained steps": 18944, "Timestamp in ms": 1701895038217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9370302660979077, "Avg loss": 0.8615920899901539, "Avg value loss": 0.5665387731278315, "Avg policy loss": 0.29505331546533853, "Total num played games": 9846, "Total num trained steps": 19072, "Timestamp in ms": 1701895091759, "logtype": "training_step"}
{"Avg objective": 20.2265625, "Games time in secs": 213.23117863200605, "Avg game time in secs": 4.28019422214129, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.53}, "Total num played games": 9856, "Total num trained steps": 19187, "Timestamp in ms": 1701895138233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.933534743202417, "Avg loss": 0.6020744338165969, "Avg value loss": 0.31396367691922933, "Avg policy loss": 0.2881107541033998, "Total num played games": 9930, "Total num trained steps": 19200, "Timestamp in ms": 1701895143195, "logtype": "training_step"}
{"Total num played games": 9944, "Total num trained steps": 19262, "Timestamp in ms": 1701895286246, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.26953125}
{"Avg objective": 21.84375, "Games time in secs": 152.6625466477126, "Avg game time in secs": 3.910555253038183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.35}, "Total num played games": 9984, "Total num trained steps": 19272, "Timestamp in ms": 1701895290896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.925483163976888, "Avg loss": 1.2243031291291118, "Avg value loss": 0.9091245728777722, "Avg policy loss": 0.3151785545051098, "Total num played games": 10038, "Total num trained steps": 19328, "Timestamp in ms": 1701895313021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.938234708109185, "Avg loss": 0.556594600668177, "Avg value loss": 0.2580272639170289, "Avg policy loss": 0.2985673383809626, "Total num played games": 10038, "Total num trained steps": 19456, "Timestamp in ms": 1701895363459, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 123.6599527914077, "Avg game time in secs": 4.303795055457158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.5}, "Total num played games": 10112, "Total num trained steps": 19581, "Timestamp in ms": 1701895414556, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9355603874283456, "Avg loss": 0.6258985782042146, "Avg value loss": 0.3418330796994269, "Avg policy loss": 0.284065498621203, "Total num played games": 10118, "Total num trained steps": 19584, "Timestamp in ms": 1701895415620, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9451351884744426, "Avg loss": 0.8083320995792747, "Avg value loss": 0.48155662731733173, "Avg policy loss": 0.3267754733096808, "Total num played games": 10134, "Total num trained steps": 19712, "Timestamp in ms": 1701895466609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9393939393939394, "Avg loss": 0.8021063774358481, "Avg value loss": 0.49858571391087025, "Avg policy loss": 0.30352067144121975, "Total num played games": 10230, "Total num trained steps": 19840, "Timestamp in ms": 1701895517217, "logtype": "training_step"}
{"Total num played games": 10230, "Total num trained steps": 19864, "Timestamp in ms": 1701895649299, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.609375}
{"Avg objective": 21.5546875, "Games time in secs": 237.58345849625766, "Avg game time in secs": 5.0029503127298085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.65, "agent_stopped_0": 0.59}, "Total num played games": 10240, "Total num trained steps": 19869, "Timestamp in ms": 1701895652140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.934134056567222, "Avg loss": 0.8004941190592945, "Avg value loss": 0.4887884563067928, "Avg policy loss": 0.3117056683404371, "Total num played games": 10324, "Total num trained steps": 19968, "Timestamp in ms": 1701895691686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9465323518016273, "Avg loss": 0.48791484418325126, "Avg value loss": 0.19164939876645803, "Avg policy loss": 0.29626544809434563, "Total num played games": 10324, "Total num trained steps": 20096, "Timestamp in ms": 1701895743143, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 110.78747509419918, "Avg game time in secs": 3.691248979928787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 10368, "Total num trained steps": 20147, "Timestamp in ms": 1701895762927, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9408829174664108, "Avg loss": 0.8865765342488885, "Avg value loss": 0.5837102652294561, "Avg policy loss": 0.30286627204623073, "Total num played games": 10420, "Total num trained steps": 20224, "Timestamp in ms": 1701895793661, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 77.9335020519793, "Avg game time in secs": 3.9208218052372104, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 10496, "Total num trained steps": 20344, "Timestamp in ms": 1701895840861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9356096633060682, "Avg loss": 0.6709090007934719, "Avg value loss": 0.37393239088123664, "Avg policy loss": 0.2969766127644107, "Total num played games": 10514, "Total num trained steps": 20352, "Timestamp in ms": 1701895844082, "logtype": "training_step"}
{"Total num played games": 10516, "Total num trained steps": 20465, "Timestamp in ms": 1701895984918, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.18359375}
{"Ratio train steps to played games": 1.9316166760988494, "Avg loss": 0.7829899948555976, "Avg value loss": 0.4703919213498011, "Avg policy loss": 0.31259807117749006, "Total num played games": 10602, "Total num trained steps": 20480, "Timestamp in ms": 1701895992001, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9423185673892553, "Avg loss": 0.8577814265154302, "Avg value loss": 0.5381674931850284, "Avg policy loss": 0.3196139317005873, "Total num played games": 10610, "Total num trained steps": 20608, "Timestamp in ms": 1701896043391, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 245.83156022801995, "Avg game time in secs": 3.5821580894553335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.48, "agent_stopped_0": 0.63}, "Total num played games": 10624, "Total num trained steps": 20714, "Timestamp in ms": 1701896086693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9375817604186134, "Avg loss": 0.6966023645363748, "Avg value loss": 0.40731382806552574, "Avg policy loss": 0.2892885450273752, "Total num played games": 10702, "Total num trained steps": 20736, "Timestamp in ms": 1701896094930, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9487203437324865, "Avg loss": 0.601258480688557, "Avg value loss": 0.30747457465622574, "Avg policy loss": 0.29378390638157725, "Total num played games": 10706, "Total num trained steps": 20864, "Timestamp in ms": 1701896147520, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 79.7576739732176, "Avg game time in secs": 3.5111559580109315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.48}, "Total num played games": 10752, "Total num trained steps": 20910, "Timestamp in ms": 1701896166451, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9433438252175523, "Avg loss": 0.9660244996193796, "Avg value loss": 0.665352298412472, "Avg policy loss": 0.3006722158752382, "Total num played games": 10802, "Total num trained steps": 20992, "Timestamp in ms": 1701896200654, "logtype": "training_step"}
{"Total num played games": 10802, "Total num trained steps": 21066, "Timestamp in ms": 1701896354556, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.48046875}
{"Avg objective": 21.203125, "Games time in secs": 194.87990605086088, "Avg game time in secs": 3.9324398821918294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.64, "agent_stopped_0": 0.51}, "Total num played games": 10880, "Total num trained steps": 21081, "Timestamp in ms": 1701896361331, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9383259911894273, "Avg loss": 0.7701404050458223, "Avg value loss": 0.47259736189153045, "Avg policy loss": 0.2975430426886305, "Total num played games": 10896, "Total num trained steps": 21120, "Timestamp in ms": 1701896377761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9500734214390603, "Avg loss": 0.5267532300204039, "Avg value loss": 0.2316721057286486, "Avg policy loss": 0.2950811261544004, "Total num played games": 10896, "Total num trained steps": 21248, "Timestamp in ms": 1701896434151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9445960698689957, "Avg loss": 0.8791102604009211, "Avg value loss": 0.584078470536042, "Avg policy loss": 0.2950317950453609, "Total num played games": 10992, "Total num trained steps": 21376, "Timestamp in ms": 1701896488440, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 173.15067215822637, "Avg game time in secs": 3.5149540155834984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.49, "agent_stopped_0": 0.64}, "Total num played games": 11008, "Total num trained steps": 21478, "Timestamp in ms": 1701896534481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9393939393939394, "Avg loss": 0.653187348973006, "Avg value loss": 0.37727062043268234, "Avg policy loss": 0.27591672784183174, "Total num played games": 11088, "Total num trained steps": 21504, "Timestamp in ms": 1701896545081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9504959422903516, "Avg loss": 0.5631775110960007, "Avg value loss": 0.2781022727722302, "Avg policy loss": 0.285075235995464, "Total num played games": 11090, "Total num trained steps": 21632, "Timestamp in ms": 1701896599585, "logtype": "training_step"}
{"Total num played games": 11120, "Total num trained steps": 21669, "Timestamp in ms": 1701896718908, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8671875}
{"Avg objective": 21.453125, "Games time in secs": 187.08814275078475, "Avg game time in secs": 3.6195406522165285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.6}, "Total num played games": 11136, "Total num trained steps": 21673, "Timestamp in ms": 1701896721570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9404316033529516, "Avg loss": 1.0409045298583806, "Avg value loss": 0.7420750554301776, "Avg policy loss": 0.29882946726866066, "Total num played games": 11214, "Total num trained steps": 21760, "Timestamp in ms": 1701896759390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9518459069020866, "Avg loss": 0.48822525423020124, "Avg value loss": 0.2054874372552149, "Avg policy loss": 0.2827378195943311, "Total num played games": 11214, "Total num trained steps": 21888, "Timestamp in ms": 1701896817392, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 113.01327925547957, "Avg game time in secs": 3.2169085774803534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.52}, "Total num played games": 11264, "Total num trained steps": 21921, "Timestamp in ms": 1701896834583, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9469402193137602, "Avg loss": 0.8660006925929338, "Avg value loss": 0.575756989303045, "Avg policy loss": 0.29024370783008635, "Total num played games": 11308, "Total num trained steps": 22016, "Timestamp in ms": 1701896878040, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 89.88069029524922, "Avg game time in secs": 3.9875591041782172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 11392, "Total num trained steps": 22120, "Timestamp in ms": 1701896924468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9417748158540862, "Avg loss": 0.6640006545931101, "Avg value loss": 0.38033765321597457, "Avg policy loss": 0.2836629991652444, "Total num played games": 11404, "Total num trained steps": 22144, "Timestamp in ms": 1701896935156, "logtype": "training_step"}
{"Ratio train steps to played games": 1.952998947737636, "Avg loss": 0.5382886216975749, "Avg value loss": 0.2399545202497393, "Avg policy loss": 0.29833410400897264, "Total num played games": 11404, "Total num trained steps": 22272, "Timestamp in ms": 1701896990892, "logtype": "training_step"}
{"Total num played games": 11404, "Total num trained steps": 22273, "Timestamp in ms": 1701897125711, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8828125}
{"Ratio train steps to played games": 1.9481648982431727, "Avg loss": 0.8432584081310779, "Avg value loss": 0.5430357777513564, "Avg policy loss": 0.3002226405078545, "Total num played games": 11498, "Total num trained steps": 22400, "Timestamp in ms": 1701897182711, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 298.33331624791026, "Avg game time in secs": 3.388873308649636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.58, "agent_stopped_0": 0.54}, "Total num played games": 11520, "Total num trained steps": 22491, "Timestamp in ms": 1701897222802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.942987752285665, "Avg loss": 0.7373716209549457, "Avg value loss": 0.4438880240195431, "Avg policy loss": 0.2934835940832272, "Total num played games": 11594, "Total num trained steps": 22528, "Timestamp in ms": 1701897238507, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9541141969984475, "Avg loss": 0.48878998635336757, "Avg value loss": 0.20911358098965138, "Avg policy loss": 0.279676407109946, "Total num played games": 11594, "Total num trained steps": 22656, "Timestamp in ms": 1701897296561, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 85.90931040421128, "Avg game time in secs": 3.259923959747539, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.47}, "Total num played games": 11648, "Total num trained steps": 22686, "Timestamp in ms": 1701897308711, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9489307100085542, "Avg loss": 0.8572786552831531, "Avg value loss": 0.5718487886479124, "Avg policy loss": 0.28542986419051886, "Total num played games": 11690, "Total num trained steps": 22784, "Timestamp in ms": 1701897352810, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 94.1305379960686, "Avg game time in secs": 3.616243730954011, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 11776, "Total num trained steps": 22876, "Timestamp in ms": 1701897402842, "logtype": "played_game"}
{"Total num played games": 11788, "Total num trained steps": 22876, "Timestamp in ms": 1701897489837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5234375}
{"Ratio train steps to played games": 1.9282107389328396, "Avg loss": 1.144712105160579, "Avg value loss": 0.8598137195804156, "Avg policy loss": 0.2848983987933025, "Total num played games": 11882, "Total num trained steps": 22912, "Timestamp in ms": 1701897507609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9389833361386972, "Avg loss": 0.7248749150894582, "Avg value loss": 0.4072775477543473, "Avg policy loss": 0.31759736384265125, "Total num played games": 11882, "Total num trained steps": 23040, "Timestamp in ms": 1701897566710, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9498400942602256, "Avg loss": 0.4673155646305531, "Avg value loss": 0.1810879050171934, "Avg policy loss": 0.2862276608357206, "Total num played games": 11882, "Total num trained steps": 23168, "Timestamp in ms": 1701897624784, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 265.34353202953935, "Avg game time in secs": 3.6180182628449984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.59, "agent_stopped_0": 0.59}, "Total num played games": 11904, "Total num trained steps": 23258, "Timestamp in ms": 1701897668186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9442497078951761, "Avg loss": 0.8532924067694694, "Avg value loss": 0.5594674404710531, "Avg policy loss": 0.29382496466860175, "Total num played games": 11982, "Total num trained steps": 23296, "Timestamp in ms": 1701897684139, "logtype": "training_step"}
{"Ratio train steps to played games": 1.954848940076782, "Avg loss": 0.5585453417152166, "Avg value loss": 0.2479660470271483, "Avg policy loss": 0.3105792918941006, "Total num played games": 11982, "Total num trained steps": 23424, "Timestamp in ms": 1701897741448, "logtype": "training_step"}
{"Avg objective": 22.65625, "Games time in secs": 88.79363304376602, "Avg game time in secs": 2.9433493411634117, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.49}, "Total num played games": 12032, "Total num trained steps": 23460, "Timestamp in ms": 1701897756980, "logtype": "played_game"}
{"Total num played games": 12078, "Total num trained steps": 23476, "Timestamp in ms": 1701897902494, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.46875}
{"Avg objective": 21.4765625, "Games time in secs": 152.89225569739938, "Avg game time in secs": 3.3524810546514345, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 12160, "Total num trained steps": 23493, "Timestamp in ms": 1701897909872, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9349326322707854, "Avg loss": 1.3383386288769543, "Avg value loss": 1.0199260876979679, "Avg policy loss": 0.3184125345433131, "Total num played games": 12172, "Total num trained steps": 23552, "Timestamp in ms": 1701897935855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9454485704896485, "Avg loss": 0.5693709093611687, "Avg value loss": 0.26067227812018245, "Avg policy loss": 0.30869863484986126, "Total num played games": 12172, "Total num trained steps": 23680, "Timestamp in ms": 1701897993149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9558823529411764, "Avg loss": 0.46061167819425464, "Avg value loss": 0.16273468447616324, "Avg policy loss": 0.29787699691951275, "Total num played games": 12172, "Total num trained steps": 23808, "Timestamp in ms": 1701898050148, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9510922725790676, "Avg loss": 0.759215296478942, "Avg value loss": 0.46035636035958305, "Avg policy loss": 0.29885894269682467, "Total num played games": 12268, "Total num trained steps": 23936, "Timestamp in ms": 1701898104977, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 236.141053667292, "Avg game time in secs": 3.0154926209070254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.49, "agent_stopped_0": 0.6}, "Total num played games": 12288, "Total num trained steps": 24030, "Timestamp in ms": 1701898146013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9462148172112586, "Avg loss": 0.7391495518386364, "Avg value loss": 0.4455788816558197, "Avg policy loss": 0.2935706761199981, "Total num played games": 12364, "Total num trained steps": 24064, "Timestamp in ms": 1701898161203, "logtype": "training_step"}
{"Total num played games": 12364, "Total num trained steps": 24077, "Timestamp in ms": 1701898247629, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.64453125}
{"Avg objective": 21.4765625, "Games time in secs": 105.68442779034376, "Avg game time in secs": 2.9861994323291583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 12416, "Total num trained steps": 24086, "Timestamp in ms": 1701898251698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9418847327018782, "Avg loss": 0.9726494601927698, "Avg value loss": 0.6374167406465858, "Avg policy loss": 0.33523271733429283, "Total num played games": 12458, "Total num trained steps": 24192, "Timestamp in ms": 1701898297942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9520789853909135, "Avg loss": 0.46988477697595954, "Avg value loss": 0.1693589735077694, "Avg policy loss": 0.3005258006742224, "Total num played games": 12458, "Total num trained steps": 24320, "Timestamp in ms": 1701898356721, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 149.91495059244335, "Avg game time in secs": 3.598420316382544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 12544, "Total num trained steps": 24422, "Timestamp in ms": 1701898401613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9474271148637885, "Avg loss": 0.6415741264354438, "Avg value loss": 0.35010619467357174, "Avg policy loss": 0.2914679324021563, "Total num played games": 12554, "Total num trained steps": 24448, "Timestamp in ms": 1701898412464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9575434124581808, "Avg loss": 0.5283779089804739, "Avg value loss": 0.22273471392691135, "Avg policy loss": 0.305643193423748, "Total num played games": 12554, "Total num trained steps": 24576, "Timestamp in ms": 1701898470579, "logtype": "training_step"}
{"Total num played games": 12650, "Total num trained steps": 24678, "Timestamp in ms": 1701898615632, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.25390625}
{"Avg objective": 22.4140625, "Games time in secs": 216.3947118036449, "Avg game time in secs": 3.2685366799414624, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.62, "agent_stopped_0": 0.56}, "Total num played games": 12672, "Total num trained steps": 24678, "Timestamp in ms": 1701898618008, "logtype": "played_game"}
{"Ratio train steps to played games": 1.938480853735091, "Avg loss": 0.9890865499619395, "Avg value loss": 0.6647182155284099, "Avg policy loss": 0.324368336237967, "Total num played games": 12744, "Total num trained steps": 24704, "Timestamp in ms": 1701898628668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948524795982423, "Avg loss": 0.5832313294522464, "Avg value loss": 0.263297033845447, "Avg policy loss": 0.31993429316207767, "Total num played games": 12744, "Total num trained steps": 24832, "Timestamp in ms": 1701898684889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9585687382297552, "Avg loss": 0.43050193320959806, "Avg value loss": 0.14482545264763758, "Avg policy loss": 0.28567648003809154, "Total num played games": 12744, "Total num trained steps": 24960, "Timestamp in ms": 1701898740086, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 132.7689683549106, "Avg game time in secs": 2.652607067619101, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.39}, "Total num played games": 12800, "Total num trained steps": 24985, "Timestamp in ms": 1701898750777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9538940809968848, "Avg loss": 0.7902974544558674, "Avg value loss": 0.48476346634561196, "Avg policy loss": 0.3055339801358059, "Total num played games": 12840, "Total num trained steps": 25088, "Timestamp in ms": 1701898796955, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 87.04303256422281, "Avg game time in secs": 3.2188866374781355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 12928, "Total num trained steps": 25182, "Timestamp in ms": 1701898837820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9492888064316636, "Avg loss": 0.8232817202806473, "Avg value loss": 0.5240315371192992, "Avg policy loss": 0.29925019410438836, "Total num played games": 12936, "Total num trained steps": 25216, "Timestamp in ms": 1701898852957, "logtype": "training_step"}
{"Total num played games": 12936, "Total num trained steps": 25280, "Timestamp in ms": 1701899006133, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.65234375}
{"Ratio train steps to played games": 1.9449731389102072, "Avg loss": 0.7154195148032159, "Avg value loss": 0.4094212435884401, "Avg policy loss": 0.3059982736594975, "Total num played games": 13030, "Total num trained steps": 25344, "Timestamp in ms": 1701899035733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9548733691481197, "Avg loss": 0.46068249247036874, "Avg value loss": 0.16401222703279927, "Avg policy loss": 0.29667026549577713, "Total num played games": 13030, "Total num trained steps": 25472, "Timestamp in ms": 1701899093172, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 291.2527554742992, "Avg game time in secs": 2.7615522594132926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.34}, "Total num played games": 13056, "Total num trained steps": 25554, "Timestamp in ms": 1701899129073, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9502514094164254, "Avg loss": 0.8180674132890999, "Avg value loss": 0.529000899696257, "Avg policy loss": 0.2890665245940909, "Total num played games": 13126, "Total num trained steps": 25600, "Timestamp in ms": 1701899150167, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9600030473868657, "Avg loss": 0.4959101143758744, "Avg value loss": 0.20719732803991064, "Avg policy loss": 0.2887127861613408, "Total num played games": 13126, "Total num trained steps": 25728, "Timestamp in ms": 1701899207470, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 87.14913149550557, "Avg game time in secs": 2.8073369339399505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 13184, "Total num trained steps": 25749, "Timestamp in ms": 1701899216222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9555286643473, "Avg loss": 0.8478421228937805, "Avg value loss": 0.5499942380120046, "Avg policy loss": 0.2978478854056448, "Total num played games": 13222, "Total num trained steps": 25856, "Timestamp in ms": 1701899262202, "logtype": "training_step"}
{"Total num played games": 13222, "Total num trained steps": 25882, "Timestamp in ms": 1701899372416, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9375}
{"Avg objective": 21.0546875, "Games time in secs": 164.42217498272657, "Avg game time in secs": 3.186955773999216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 13312, "Total num trained steps": 25898, "Timestamp in ms": 1701899380644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.951336737759087, "Avg loss": 0.7331640396732837, "Avg value loss": 0.43403550289804116, "Avg policy loss": 0.29912853497080505, "Total num played games": 13316, "Total num trained steps": 25984, "Timestamp in ms": 1701899419709, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9609492340042054, "Avg loss": 0.42859379784204066, "Avg value loss": 0.14570059749530628, "Avg policy loss": 0.28289319993928075, "Total num played games": 13316, "Total num trained steps": 26112, "Timestamp in ms": 1701899479286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9564569042648374, "Avg loss": 0.7414233332965523, "Avg value loss": 0.4552258357871324, "Avg policy loss": 0.28619749704375863, "Total num played games": 13412, "Total num trained steps": 26240, "Timestamp in ms": 1701899535814, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 191.38454546034336, "Avg game time in secs": 2.672940945078153, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 13440, "Total num trained steps": 26318, "Timestamp in ms": 1701899572029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.95202842759846, "Avg loss": 0.9246447212062776, "Avg value loss": 0.6411400504293852, "Avg policy loss": 0.28350467002019286, "Total num played games": 13508, "Total num trained steps": 26368, "Timestamp in ms": 1701899595222, "logtype": "training_step"}
{"Total num played games": 13508, "Total num trained steps": 26484, "Timestamp in ms": 1701899771082, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2421875}
{"Avg objective": 22.2578125, "Games time in secs": 202.5678618364036, "Avg game time in secs": 2.7499719851766713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.55}, "Total num played games": 13568, "Total num trained steps": 26490, "Timestamp in ms": 1701899774597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9488084730803177, "Avg loss": 0.5773860162589699, "Avg value loss": 0.2851907883887179, "Avg policy loss": 0.29219523107167333, "Total num played games": 13596, "Total num trained steps": 26496, "Timestamp in ms": 1701899776883, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9572856932804, "Avg loss": 0.7312595983967185, "Avg value loss": 0.43967934657121077, "Avg policy loss": 0.2915802542120218, "Total num played games": 13602, "Total num trained steps": 26624, "Timestamp in ms": 1701899832094, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 94.58778170123696, "Avg game time in secs": 3.050582810305059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.7}, "Total num played games": 13696, "Total num trained steps": 26710, "Timestamp in ms": 1701899869185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.952985837348518, "Avg loss": 0.8183435201644897, "Avg value loss": 0.5380133814178407, "Avg policy loss": 0.2803301370004192, "Total num played games": 13698, "Total num trained steps": 26752, "Timestamp in ms": 1701899888166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9622572638341365, "Avg loss": 0.4952786120120436, "Avg value loss": 0.20427833893336356, "Avg policy loss": 0.29100027098320425, "Total num played games": 13698, "Total num trained steps": 26880, "Timestamp in ms": 1701899946879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9579527330723503, "Avg loss": 0.8207768395077437, "Avg value loss": 0.5237643742002547, "Avg policy loss": 0.2970124671701342, "Total num played games": 13794, "Total num trained steps": 27008, "Timestamp in ms": 1701900003328, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 168.4766990840435, "Avg game time in secs": 2.5051660643948708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.38}, "Total num played games": 13824, "Total num trained steps": 27082, "Timestamp in ms": 1701900037662, "logtype": "played_game"}
{"Total num played games": 13890, "Total num trained steps": 27086, "Timestamp in ms": 1701900171909, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.15234375}
{"Avg objective": 21.046875, "Games time in secs": 137.7297014966607, "Avg game time in secs": 2.469265293504577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 13952, "Total num trained steps": 27092, "Timestamp in ms": 1701900175391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9405034324942791, "Avg loss": 1.1048337637912482, "Avg value loss": 0.8069175146520138, "Avg policy loss": 0.29791624983772635, "Total num played games": 13984, "Total num trained steps": 27136, "Timestamp in ms": 1701900194921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9496567505720823, "Avg loss": 0.5752173012588173, "Avg value loss": 0.2501061552320607, "Avg policy loss": 0.32511114911176264, "Total num played games": 13984, "Total num trained steps": 27264, "Timestamp in ms": 1701900252128, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9588100686498855, "Avg loss": 0.4387371961493045, "Avg value loss": 0.13448512624017894, "Avg policy loss": 0.304252068628557, "Total num played games": 13984, "Total num trained steps": 27392, "Timestamp in ms": 1701900308984, "logtype": "training_step"}
{"Avg objective": 23.2734375, "Games time in secs": 173.28890340402722, "Avg game time in secs": 2.9233628565852996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.62, "agent_stopped_0": 0.5}, "Total num played games": 14080, "Total num trained steps": 27485, "Timestamp in ms": 1701900348680, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9542678596790228, "Avg loss": 0.9078337426763028, "Avg value loss": 0.6047583790495992, "Avg policy loss": 0.3030753673519939, "Total num played games": 14082, "Total num trained steps": 27520, "Timestamp in ms": 1701900364585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9633574776310183, "Avg loss": 0.488080166047439, "Avg value loss": 0.19221571634989232, "Avg policy loss": 0.29586444899905473, "Total num played games": 14082, "Total num trained steps": 27648, "Timestamp in ms": 1701900423034, "logtype": "training_step"}
{"Total num played games": 14180, "Total num trained steps": 27688, "Timestamp in ms": 1701900540163, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.0625}
{"Avg objective": 21.578125, "Games time in secs": 193.91302855312824, "Avg game time in secs": 2.748784448369406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.51}, "Total num played games": 14208, "Total num trained steps": 27692, "Timestamp in ms": 1701900542595, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9459156508336837, "Avg loss": 1.152399428654462, "Avg value loss": 0.8141542319208384, "Avg policy loss": 0.33824518939945847, "Total num played games": 14274, "Total num trained steps": 27776, "Timestamp in ms": 1701900579738, "logtype": "training_step"}
{"Ratio train steps to played games": 1.954883004063332, "Avg loss": 0.49328409787267447, "Avg value loss": 0.17736592731671408, "Avg policy loss": 0.315918174572289, "Total num played games": 14274, "Total num trained steps": 27904, "Timestamp in ms": 1701900638712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9638503572929802, "Avg loss": 0.430916330544278, "Avg value loss": 0.1352944209938869, "Avg policy loss": 0.29562191176228225, "Total num played games": 14274, "Total num trained steps": 28032, "Timestamp in ms": 1701900698999, "logtype": "training_step"}
{"Avg objective": 23.109375, "Games time in secs": 162.0142847970128, "Avg game time in secs": 2.518927372293547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 14336, "Total num trained steps": 28046, "Timestamp in ms": 1701900704608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9596381350034795, "Avg loss": 0.8783150531817228, "Avg value loss": 0.5635579212103039, "Avg policy loss": 0.3147571354638785, "Total num played games": 14370, "Total num trained steps": 28160, "Timestamp in ms": 1701900756563, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 94.32311592623591, "Avg game time in secs": 2.94212457202957, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.66}, "Total num played games": 14464, "Total num trained steps": 28251, "Timestamp in ms": 1701900798931, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955211501244125, "Avg loss": 0.8490865805651993, "Avg value loss": 0.5433938109199516, "Avg policy loss": 0.3056927741272375, "Total num played games": 14468, "Total num trained steps": 28288, "Timestamp in ms": 1701900814243, "logtype": "training_step"}
{"Total num played games": 14468, "Total num trained steps": 28290, "Timestamp in ms": 1701900887312, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.19921875}
{"Ratio train steps to played games": 1.9513116330174427, "Avg loss": 1.1719502077903599, "Avg value loss": 0.8294973477022722, "Avg policy loss": 0.3424528636969626, "Total num played games": 14562, "Total num trained steps": 28416, "Timestamp in ms": 1701900948503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9601703062766103, "Avg loss": 0.45462113595567644, "Avg value loss": 0.14828665845561773, "Avg policy loss": 0.3063344778493047, "Total num played games": 14562, "Total num trained steps": 28544, "Timestamp in ms": 1701901006758, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 242.49046662449837, "Avg game time in secs": 2.661127639847109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.49, "agent_stopped_0": 0.62}, "Total num played games": 14592, "Total num trained steps": 28619, "Timestamp in ms": 1701901041422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9560649474689589, "Avg loss": 0.736998416017741, "Avg value loss": 0.4289099364541471, "Avg policy loss": 0.308088488294743, "Total num played games": 14658, "Total num trained steps": 28672, "Timestamp in ms": 1701901065624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9647973802701597, "Avg loss": 0.462831872748211, "Avg value loss": 0.16586676758015528, "Avg policy loss": 0.2969651068560779, "Total num played games": 14658, "Total num trained steps": 28800, "Timestamp in ms": 1701901124161, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 87.66785733029246, "Avg game time in secs": 2.7971165378403384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 14720, "Total num trained steps": 28811, "Timestamp in ms": 1701901129090, "logtype": "played_game"}
{"Total num played games": 14756, "Total num trained steps": 28891, "Timestamp in ms": 1701901241998, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.0234375}
{"Avg objective": 21.125, "Games time in secs": 120.43794660270214, "Avg game time in secs": 3.01986620677053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.67}, "Total num played games": 14848, "Total num trained steps": 28907, "Timestamp in ms": 1701901249528, "logtype": "played_game"}
{"Ratio train steps to played games": 1.948013468013468, "Avg loss": 1.180494235130027, "Avg value loss": 0.8579204994020984, "Avg policy loss": 0.32257373351603746, "Total num played games": 14850, "Total num trained steps": 28928, "Timestamp in ms": 1701901257712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9566329966329967, "Avg loss": 0.6373220065142959, "Avg value loss": 0.3125876468839124, "Avg policy loss": 0.32473435846623033, "Total num played games": 14850, "Total num trained steps": 29056, "Timestamp in ms": 1701901315041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9651851851851851, "Avg loss": 0.4322731227148324, "Avg value loss": 0.13654140941798687, "Avg policy loss": 0.2957317135296762, "Total num played games": 14850, "Total num trained steps": 29184, "Timestamp in ms": 1701901375732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9611936304027833, "Avg loss": 1.0024686644319445, "Avg value loss": 0.6887088379007764, "Avg policy loss": 0.31375982461031526, "Total num played games": 14946, "Total num trained steps": 29312, "Timestamp in ms": 1701901435041, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 218.59261544421315, "Avg game time in secs": 2.349803738645278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.48, "agent_stopped_0": 0.62}, "Total num played games": 14976, "Total num trained steps": 29387, "Timestamp in ms": 1701901468121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956926349375166, "Avg loss": 0.8294294455554336, "Avg value loss": 0.5185536635690369, "Avg policy loss": 0.31087577680591494, "Total num played games": 15044, "Total num trained steps": 29440, "Timestamp in ms": 1701901493879, "logtype": "training_step"}
{"Total num played games": 15044, "Total num trained steps": 29491, "Timestamp in ms": 1701901585011, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.22265625}
{"Avg objective": 21.46875, "Games time in secs": 120.71954737603664, "Avg game time in secs": 2.746318693854846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 15104, "Total num trained steps": 29496, "Timestamp in ms": 1701901588840, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9531642224864578, "Avg loss": 0.9113065721467137, "Avg value loss": 0.583702031057328, "Avg policy loss": 0.3276045355014503, "Total num played games": 15138, "Total num trained steps": 29568, "Timestamp in ms": 1701901620807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9616858237547892, "Avg loss": 0.5045605537015945, "Avg value loss": 0.18842117203166708, "Avg policy loss": 0.3161393835907802, "Total num played games": 15138, "Total num trained steps": 29696, "Timestamp in ms": 1701901677326, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 122.60674799978733, "Avg game time in secs": 2.7234027638914995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 15232, "Total num trained steps": 29776, "Timestamp in ms": 1701901711447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9572122325764536, "Avg loss": 0.7828360525891185, "Avg value loss": 0.47354346537031233, "Avg policy loss": 0.30929258500691503, "Total num played games": 15238, "Total num trained steps": 29824, "Timestamp in ms": 1701901731265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965546659666623, "Avg loss": 0.45424804044887424, "Avg value loss": 0.16512250405503437, "Avg policy loss": 0.289125534822233, "Total num played games": 15238, "Total num trained steps": 29952, "Timestamp in ms": 1701901786524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.961909731280981, "Avg loss": 0.964534823782742, "Avg value loss": 0.6627561638015322, "Avg policy loss": 0.30177867296151817, "Total num played games": 15332, "Total num trained steps": 30080, "Timestamp in ms": 1701901840566, "logtype": "training_step"}
{"Total num played games": 15332, "Total num trained steps": 30091, "Timestamp in ms": 1701901931462, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.359375}
{"Avg objective": 21.3828125, "Games time in secs": 222.12879913672805, "Avg game time in secs": 2.2945219319080934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.43, "agent_stopped_0": 0.62}, "Total num played games": 15360, "Total num trained steps": 30092, "Timestamp in ms": 1701901933576, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9582523013094775, "Avg loss": 0.9709583118092269, "Avg value loss": 0.6580504247685894, "Avg policy loss": 0.31290789414197206, "Total num played games": 15426, "Total num trained steps": 30208, "Timestamp in ms": 1701901982595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9665499805523143, "Avg loss": 0.44443656504154205, "Avg value loss": 0.15615468885516748, "Avg policy loss": 0.28828187205363065, "Total num played games": 15426, "Total num trained steps": 30336, "Timestamp in ms": 1701902031121, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 102.42173109203577, "Avg game time in secs": 2.3854360323457513, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.43}, "Total num played games": 15488, "Total num trained steps": 30347, "Timestamp in ms": 1701902035998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9628865979381442, "Avg loss": 0.8431514878757298, "Avg value loss": 0.547940571908839, "Avg policy loss": 0.29521092120558023, "Total num played games": 15520, "Total num trained steps": 30464, "Timestamp in ms": 1701902083170, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 81.35203312709928, "Avg game time in secs": 2.722254337713821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 15616, "Total num trained steps": 30550, "Timestamp in ms": 1701902117350, "logtype": "played_game"}
{"Ratio train steps to played games": 1.958952356557377, "Avg loss": 0.7816626527346671, "Avg value loss": 0.494828374881763, "Avg policy loss": 0.2868342880392447, "Total num played games": 15616, "Total num trained steps": 30592, "Timestamp in ms": 1701902135255, "logtype": "training_step"}
{"Total num played games": 15616, "Total num trained steps": 30694, "Timestamp in ms": 1701902267370, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.93359375}
{"Ratio train steps to played games": 1.9554423933800127, "Avg loss": 0.7536227996461093, "Avg value loss": 0.46639282925752923, "Avg policy loss": 0.28722997452132404, "Total num played games": 15710, "Total num trained steps": 30720, "Timestamp in ms": 1701902277474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.963590070019096, "Avg loss": 0.6989093029405922, "Avg value loss": 0.40507387166144326, "Avg policy loss": 0.2938354288926348, "Total num played games": 15710, "Total num trained steps": 30848, "Timestamp in ms": 1701902328675, "logtype": "training_step"}
{"Avg objective": 22.6953125, "Games time in secs": 237.21143270283937, "Avg game time in secs": 2.505968699726509, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 15744, "Total num trained steps": 30914, "Timestamp in ms": 1701902354562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.959762115652284, "Avg loss": 0.813163821818307, "Avg value loss": 0.5219928163569421, "Avg policy loss": 0.2911709970794618, "Total num played games": 15806, "Total num trained steps": 30976, "Timestamp in ms": 1701902378794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9677970390990762, "Avg loss": 0.46572977770119905, "Avg value loss": 0.1805940776830539, "Avg policy loss": 0.2851356999017298, "Total num played games": 15806, "Total num trained steps": 31104, "Timestamp in ms": 1701902428857, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 76.48692628368735, "Avg game time in secs": 2.4544814551773015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.53, "agent_stopped_0": 0.57}, "Total num played games": 15872, "Total num trained steps": 31110, "Timestamp in ms": 1701902431049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9642767295597485, "Avg loss": 0.7675855499692261, "Avg value loss": 0.4657203401438892, "Avg policy loss": 0.3018651983002201, "Total num played games": 15900, "Total num trained steps": 31232, "Timestamp in ms": 1701902479351, "logtype": "training_step"}
{"Total num played games": 15996, "Total num trained steps": 31296, "Timestamp in ms": 1701902573135, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2109375}
{"Avg objective": 22.453125, "Games time in secs": 144.07485639303923, "Avg game time in secs": 2.6795325882849284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 16000, "Total num trained steps": 31297, "Timestamp in ms": 1701902575124, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9490366687383467, "Avg loss": 1.451532566221431, "Avg value loss": 1.1472000890644267, "Avg policy loss": 0.3043324809987098, "Total num played games": 16090, "Total num trained steps": 31360, "Timestamp in ms": 1701902598986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9569919204474828, "Avg loss": 0.5794962518848479, "Avg value loss": 0.26196982921101153, "Avg policy loss": 0.31752642476931214, "Total num played games": 16090, "Total num trained steps": 31488, "Timestamp in ms": 1701902649725, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964947172156619, "Avg loss": 0.43787045730277896, "Avg value loss": 0.14894785766955465, "Avg policy loss": 0.2889225984690711, "Total num played games": 16090, "Total num trained steps": 31616, "Timestamp in ms": 1701902700500, "logtype": "training_step"}
{"Avg objective": 22.859375, "Games time in secs": 148.95856668427587, "Avg game time in secs": 2.34836180289858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.52}, "Total num played games": 16128, "Total num trained steps": 31675, "Timestamp in ms": 1701902724083, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9614434008897677, "Avg loss": 0.9450219122227281, "Avg value loss": 0.6451214279513806, "Avg policy loss": 0.29990048543550074, "Total num played games": 16184, "Total num trained steps": 31744, "Timestamp in ms": 1701902751198, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 74.6734344959259, "Avg game time in secs": 2.2555196787579916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 16256, "Total num trained steps": 31863, "Timestamp in ms": 1701902798756, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9584613493916676, "Avg loss": 0.570636953227222, "Avg value loss": 0.2768421382061206, "Avg policy loss": 0.29379481775686145, "Total num played games": 16274, "Total num trained steps": 31872, "Timestamp in ms": 1701902801892, "logtype": "training_step"}
{"Total num played games": 16278, "Total num trained steps": 31898, "Timestamp in ms": 1701902925930, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.015625}
{"Ratio train steps to played games": 1.9545565599804544, "Avg loss": 1.1441723459865898, "Avg value loss": 0.8126556687057018, "Avg policy loss": 0.3315166821703315, "Total num played games": 16372, "Total num trained steps": 32000, "Timestamp in ms": 1701902966575, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9623747862203762, "Avg loss": 0.4729324874933809, "Avg value loss": 0.17286267189774662, "Avg policy loss": 0.3000698194373399, "Total num played games": 16372, "Total num trained steps": 32128, "Timestamp in ms": 1701903016555, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 259.3282817415893, "Avg game time in secs": 2.44559453256079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 16384, "Total num trained steps": 32237, "Timestamp in ms": 1701903058085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9589457063038989, "Avg loss": 0.6706883134320378, "Avg value loss": 0.3903563665226102, "Avg policy loss": 0.2803319579688832, "Total num played games": 16466, "Total num trained steps": 32256, "Timestamp in ms": 1701903065294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9664804469273742, "Avg loss": 0.6700062195304781, "Avg value loss": 0.37077459663851187, "Avg policy loss": 0.2992316229501739, "Total num played games": 16468, "Total num trained steps": 32384, "Timestamp in ms": 1701903117211, "logtype": "training_step"}
{"Avg objective": 22.421875, "Games time in secs": 77.50260945037007, "Avg game time in secs": 2.4406484698702116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 16512, "Total num trained steps": 32431, "Timestamp in ms": 1701903135588, "logtype": "played_game"}
{"Total num played games": 16562, "Total num trained steps": 32500, "Timestamp in ms": 1701903258145, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.66796875}
{"Avg objective": 21.1015625, "Games time in secs": 126.95579217746854, "Avg game time in secs": 2.5092743986169808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 16640, "Total num trained steps": 32509, "Timestamp in ms": 1701903262543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9526726726726726, "Avg loss": 0.8682217700406909, "Avg value loss": 0.5712458646157756, "Avg policy loss": 0.2969759071711451, "Total num played games": 16650, "Total num trained steps": 32512, "Timestamp in ms": 1701903263654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9595941402497599, "Avg loss": 0.810627793893218, "Avg value loss": 0.508384108543396, "Avg policy loss": 0.3022436781320721, "Total num played games": 16656, "Total num trained steps": 32640, "Timestamp in ms": 1701903316380, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967339097022094, "Avg loss": 0.4080714387819171, "Avg value loss": 0.13361922529293224, "Avg policy loss": 0.27445221331436187, "Total num played games": 16656, "Total num trained steps": 32768, "Timestamp in ms": 1701903367789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9637058261700095, "Avg loss": 0.9157143081538379, "Avg value loss": 0.6195959084434435, "Avg policy loss": 0.2961184033192694, "Total num played games": 16752, "Total num trained steps": 32896, "Timestamp in ms": 1701903420587, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 198.58211118727922, "Avg game time in secs": 2.5867143197974656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.61, "agent_stopped_0": 0.49}, "Total num played games": 16768, "Total num trained steps": 32996, "Timestamp in ms": 1701903461126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96011396011396, "Avg loss": 0.7991948763374239, "Avg value loss": 0.5028758642147295, "Avg policy loss": 0.2963190237060189, "Total num played games": 16848, "Total num trained steps": 33024, "Timestamp in ms": 1701903472054, "logtype": "training_step"}
{"Total num played games": 16848, "Total num trained steps": 33102, "Timestamp in ms": 1701903582969, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.359375}
{"Avg objective": 21.703125, "Games time in secs": 124.89643443375826, "Avg game time in secs": 2.3739738456206396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 16896, "Total num trained steps": 33109, "Timestamp in ms": 1701903586022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9567937669696611, "Avg loss": 1.1108712805435061, "Avg value loss": 0.7943502709968016, "Avg policy loss": 0.31652102060616016, "Total num played games": 16942, "Total num trained steps": 33152, "Timestamp in ms": 1701903603032, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9643489552591193, "Avg loss": 0.5522165594156832, "Avg value loss": 0.24606577248778194, "Avg policy loss": 0.306150785414502, "Total num played games": 16942, "Total num trained steps": 33280, "Timestamp in ms": 1701903655473, "logtype": "training_step"}
{"Avg objective": 22.5703125, "Games time in secs": 108.16144256293774, "Avg game time in secs": 2.3991904310532846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 17024, "Total num trained steps": 33383, "Timestamp in ms": 1701903694184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96079352036624, "Avg loss": 0.7986831364687532, "Avg value loss": 0.5040771870408207, "Avg policy loss": 0.2946059488458559, "Total num played games": 17038, "Total num trained steps": 33408, "Timestamp in ms": 1701903704004, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9683061392182182, "Avg loss": 0.5682213399559259, "Avg value loss": 0.25558753713266924, "Avg policy loss": 0.3126338020665571, "Total num played games": 17038, "Total num trained steps": 33536, "Timestamp in ms": 1701903754770, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9649778192855476, "Avg loss": 0.8277162909507751, "Avg value loss": 0.5186715921736322, "Avg policy loss": 0.3090446878923103, "Total num played games": 17132, "Total num trained steps": 33664, "Timestamp in ms": 1701903805058, "logtype": "training_step"}
{"Total num played games": 17132, "Total num trained steps": 33705, "Timestamp in ms": 1701903881377, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.90234375}
{"Avg objective": 23.015625, "Games time in secs": 189.17689043283463, "Avg game time in secs": 2.269386887695873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.43, "agent_stopped_0": 0.6}, "Total num played games": 17152, "Total num trained steps": 33707, "Timestamp in ms": 1701903883361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9616858237547892, "Avg loss": 0.8237090932670981, "Avg value loss": 0.5092721648397855, "Avg policy loss": 0.314436933840625, "Total num played games": 17226, "Total num trained steps": 33792, "Timestamp in ms": 1701903917492, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9691164518750726, "Avg loss": 0.43955012364313006, "Avg value loss": 0.14199881750391796, "Avg policy loss": 0.2975513085257262, "Total num played games": 17226, "Total num trained steps": 33920, "Timestamp in ms": 1701903968187, "logtype": "training_step"}
{"Avg objective": 22.6796875, "Games time in secs": 95.71665424108505, "Avg game time in secs": 2.1868837715592235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.53}, "Total num played games": 17280, "Total num trained steps": 33947, "Timestamp in ms": 1701903979078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9658198614318707, "Avg loss": 0.8449970462825149, "Avg value loss": 0.5270148609997705, "Avg policy loss": 0.3179821892408654, "Total num played games": 17320, "Total num trained steps": 34048, "Timestamp in ms": 1701904018459, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 75.81585017219186, "Avg game time in secs": 2.4872883791394997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.63, "agent_stopped_0": 0.49}, "Total num played games": 17408, "Total num trained steps": 34141, "Timestamp in ms": 1701904054894, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9621081639683087, "Avg loss": 0.9940325559582561, "Avg value loss": 0.6816354529582895, "Avg policy loss": 0.31239708804059774, "Total num played games": 17418, "Total num trained steps": 34176, "Timestamp in ms": 1701904068818, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9694568836835458, "Avg loss": 0.525355794467032, "Avg value loss": 0.21215894707711414, "Avg policy loss": 0.3131968448869884, "Total num played games": 17418, "Total num trained steps": 34304, "Timestamp in ms": 1701904121408, "logtype": "training_step"}
{"Total num played games": 17418, "Total num trained steps": 34305, "Timestamp in ms": 1701904228487, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.65234375}
{"Ratio train steps to played games": 1.96619460941069, "Avg loss": 0.783205240033567, "Avg value loss": 0.460455582884606, "Avg policy loss": 0.32274965522810817, "Total num played games": 17512, "Total num trained steps": 34432, "Timestamp in ms": 1701904278670, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 256.46188409253955, "Avg game time in secs": 2.4207500827033073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.53, "agent_stopped_0": 0.59}, "Total num played games": 17536, "Total num trained steps": 34517, "Timestamp in ms": 1701904311356, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9629671702828582, "Avg loss": 0.6427454673685133, "Avg value loss": 0.34118548419792205, "Avg policy loss": 0.30155997816473246, "Total num played games": 17606, "Total num trained steps": 34560, "Timestamp in ms": 1701904328633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9702374190616836, "Avg loss": 0.4581204322166741, "Avg value loss": 0.16272855189163238, "Avg policy loss": 0.29539187951013446, "Total num played games": 17606, "Total num trained steps": 34688, "Timestamp in ms": 1701904380908, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 77.02692312374711, "Avg game time in secs": 2.355745981214568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.55}, "Total num played games": 17664, "Total num trained steps": 34707, "Timestamp in ms": 1701904388383, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9665047446904653, "Avg loss": 1.0142833478748798, "Avg value loss": 0.7076805926044472, "Avg policy loss": 0.306602748692967, "Total num played games": 17704, "Total num trained steps": 34816, "Timestamp in ms": 1701904429857, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 78.15560417249799, "Avg game time in secs": 2.3912366942386143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 17792, "Total num trained steps": 34905, "Timestamp in ms": 1701904466538, "logtype": "played_game"}
{"Total num played games": 17800, "Total num trained steps": 34905, "Timestamp in ms": 1701904541510, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.9609375}
{"Ratio train steps to played games": 1.9528333519615513, "Avg loss": 1.020701478002593, "Avg value loss": 0.7269723736681044, "Avg policy loss": 0.29372909129597247, "Total num played games": 17894, "Total num trained steps": 34944, "Timestamp in ms": 1701904557822, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9599865876830223, "Avg loss": 0.653212126577273, "Avg value loss": 0.3468165205558762, "Avg policy loss": 0.30639560823328793, "Total num played games": 17894, "Total num trained steps": 35072, "Timestamp in ms": 1701904610343, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9671398234044932, "Avg loss": 0.41913122474215925, "Avg value loss": 0.134648546052631, "Avg policy loss": 0.28448267828207463, "Total num played games": 17894, "Total num trained steps": 35200, "Timestamp in ms": 1701904659577, "logtype": "training_step"}
{"Avg objective": 22.4375, "Games time in secs": 226.24764286354184, "Avg game time in secs": 2.228034078172641, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.55, "agent_stopped_0": 0.57}, "Total num played games": 17920, "Total num trained steps": 35281, "Timestamp in ms": 1701904692786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9637020566981656, "Avg loss": 0.7058214405551553, "Avg value loss": 0.42169784632278606, "Avg policy loss": 0.2841235945234075, "Total num played games": 17990, "Total num trained steps": 35328, "Timestamp in ms": 1701904711217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9708727070594776, "Avg loss": 0.44469934212975204, "Avg value loss": 0.15520314883906394, "Avg policy loss": 0.28949619189370424, "Total num played games": 17990, "Total num trained steps": 35456, "Timestamp in ms": 1701904762786, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 78.12985805794597, "Avg game time in secs": 2.212291374366032, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 18048, "Total num trained steps": 35476, "Timestamp in ms": 1701904770916, "logtype": "played_game"}
{"Total num played games": 18084, "Total num trained steps": 35505, "Timestamp in ms": 1701904817432, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.078125}
{"Avg objective": 22.1875, "Games time in secs": 52.6530951410532, "Avg game time in secs": 2.58826635486912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.73, "agent_stopped_0": 0.41}, "Total num played games": 18176, "Total num trained steps": 35519, "Timestamp in ms": 1701904823571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9574760699746947, "Avg loss": 1.3319968890864402, "Avg value loss": 1.0039139291038737, "Avg policy loss": 0.3280829528812319, "Total num played games": 18178, "Total num trained steps": 35584, "Timestamp in ms": 1701904848962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645725602376498, "Avg loss": 0.5003745090216398, "Avg value loss": 0.18631514988373965, "Avg policy loss": 0.31405935739167035, "Total num played games": 18178, "Total num trained steps": 35712, "Timestamp in ms": 1701904899499, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971614038948179, "Avg loss": 0.404224781319499, "Avg value loss": 0.11494794976897538, "Avg policy loss": 0.28927683224901557, "Total num played games": 18178, "Total num trained steps": 35840, "Timestamp in ms": 1701904951736, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9679908076165462, "Avg loss": 0.88339864439331, "Avg value loss": 0.5855214359471574, "Avg policy loss": 0.29787720437161624, "Total num played games": 18276, "Total num trained steps": 35968, "Timestamp in ms": 1701905003883, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 210.81822795048356, "Avg game time in secs": 2.056188038259279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 18304, "Total num trained steps": 36046, "Timestamp in ms": 1701905034390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9649428415895482, "Avg loss": 0.9399205748923123, "Avg value loss": 0.6368034836486913, "Avg policy loss": 0.3031170847825706, "Total num played games": 18370, "Total num trained steps": 36096, "Timestamp in ms": 1701905053972, "logtype": "training_step"}
{"Total num played games": 18370, "Total num trained steps": 36106, "Timestamp in ms": 1701905124794, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9140625}
{"Avg objective": 21.4296875, "Games time in secs": 93.60961689054966, "Avg game time in secs": 2.0476380264153704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 18432, "Total num trained steps": 36112, "Timestamp in ms": 1701905127999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9618717504332757, "Avg loss": 1.0746237416751683, "Avg value loss": 0.7370388132985681, "Avg policy loss": 0.3375849302392453, "Total num played games": 18464, "Total num trained steps": 36224, "Timestamp in ms": 1701905172683, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9688041594454073, "Avg loss": 0.500029080780223, "Avg value loss": 0.19472022529225796, "Avg policy loss": 0.3053088547894731, "Total num played games": 18464, "Total num trained steps": 36352, "Timestamp in ms": 1701905224135, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9656751805151418, "Avg loss": 0.7083995933644474, "Avg value loss": 0.39969216735335067, "Avg policy loss": 0.30870742560364306, "Total num played games": 18558, "Total num trained steps": 36480, "Timestamp in ms": 1701905273985, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9725724754822718, "Avg loss": 0.47253219969570637, "Avg value loss": 0.176289961731527, "Avg policy loss": 0.29624223965220153, "Total num played games": 18558, "Total num trained steps": 36608, "Timestamp in ms": 1701905324190, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 196.26335050165653, "Avg game time in secs": 2.2382493410550524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 18560, "Total num trained steps": 36608, "Timestamp in ms": 1701905324263, "logtype": "played_game"}
{"Total num played games": 18654, "Total num trained steps": 36706, "Timestamp in ms": 1701905430997, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.79296875}
{"Avg objective": 22.171875, "Games time in secs": 109.28450267016888, "Avg game time in secs": 2.009503568173386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 18688, "Total num trained steps": 36711, "Timestamp in ms": 1701905433547, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9594623426498827, "Avg loss": 1.1371359270997345, "Avg value loss": 0.8194783669314347, "Avg policy loss": 0.317657568724826, "Total num played games": 18748, "Total num trained steps": 36736, "Timestamp in ms": 1701905443663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9662897375720076, "Avg loss": 0.5723511041142046, "Avg value loss": 0.26045268028974533, "Avg policy loss": 0.3118984241737053, "Total num played games": 18748, "Total num trained steps": 36864, "Timestamp in ms": 1701905495626, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9664044227089092, "Avg loss": 0.4229711515363306, "Avg value loss": 0.13950038235634565, "Avg policy loss": 0.2834707669680938, "Total num played games": 18812, "Total num trained steps": 36992, "Timestamp in ms": 1701905547484, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 114.00566682592034, "Avg game time in secs": 2.237788722937694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 18816, "Total num trained steps": 36992, "Timestamp in ms": 1701905547553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696487318263822, "Avg loss": 1.0656715799123049, "Avg value loss": 0.772250845679082, "Avg policy loss": 0.2934207330690697, "Total num played games": 18846, "Total num trained steps": 37120, "Timestamp in ms": 1701905599294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9666314677930306, "Avg loss": 0.6876596079673618, "Avg value loss": 0.3983110165572725, "Avg policy loss": 0.2893485826207325, "Total num played games": 18940, "Total num trained steps": 37248, "Timestamp in ms": 1701905650168, "logtype": "training_step"}
{"Total num played games": 18940, "Total num trained steps": 37308, "Timestamp in ms": 1701905755423, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.41796875}
{"Avg objective": 21.421875, "Games time in secs": 209.30099169909954, "Avg game time in secs": 2.1214946249092463, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.51, "agent_stopped_0": 0.58}, "Total num played games": 18944, "Total num trained steps": 37310, "Timestamp in ms": 1701905756854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9636440054639066, "Avg loss": 1.1055862749926746, "Avg value loss": 0.8024512948468328, "Avg policy loss": 0.30313498829491436, "Total num played games": 19034, "Total num trained steps": 37376, "Timestamp in ms": 1701905783654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9703688137017967, "Avg loss": 0.5073896376416087, "Avg value loss": 0.21990767458919436, "Avg policy loss": 0.287481966544874, "Total num played games": 19034, "Total num trained steps": 37504, "Timestamp in ms": 1701905834949, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 101.11520643159747, "Avg game time in secs": 1.8364753451023716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.38}, "Total num played games": 19072, "Total num trained steps": 37562, "Timestamp in ms": 1701905857970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9673776662484317, "Avg loss": 0.8915390111505985, "Avg value loss": 0.5983126292121597, "Avg policy loss": 0.2932263732654974, "Total num played games": 19128, "Total num trained steps": 37632, "Timestamp in ms": 1701905885542, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 77.0635835826397, "Avg game time in secs": 2.05990268921596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 19200, "Total num trained steps": 37753, "Timestamp in ms": 1701905935033, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9644157735927583, "Avg loss": 0.5823616324923933, "Avg value loss": 0.2988952472805977, "Avg policy loss": 0.28346638928633183, "Total num played games": 19222, "Total num trained steps": 37760, "Timestamp in ms": 1701905937980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9710748101134117, "Avg loss": 0.6292550947982818, "Avg value loss": 0.34514880197821185, "Avg policy loss": 0.2841062964871526, "Total num played games": 19222, "Total num trained steps": 37888, "Timestamp in ms": 1701905990316, "logtype": "training_step"}
{"Total num played games": 19222, "Total num trained steps": 37908, "Timestamp in ms": 1701906058270, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.6953125}
{"Ratio train steps to played games": 1.9680575688548354, "Avg loss": 0.8555096699856222, "Avg value loss": 0.5586572311003692, "Avg policy loss": 0.29685244522988796, "Total num played games": 19316, "Total num trained steps": 38016, "Timestamp in ms": 1701906102513, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 211.8121368177235, "Avg game time in secs": 2.126595671463292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 19328, "Total num trained steps": 38124, "Timestamp in ms": 1701906146846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9651725914477074, "Avg loss": 0.6284685772843659, "Avg value loss": 0.3535834872745909, "Avg policy loss": 0.2748850912321359, "Total num played games": 19410, "Total num trained steps": 38144, "Timestamp in ms": 1701906154572, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971767130345183, "Avg loss": 0.6722894040867686, "Avg value loss": 0.3821213010814972, "Avg policy loss": 0.290168103761971, "Total num played games": 19410, "Total num trained steps": 38272, "Timestamp in ms": 1701906207710, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 78.16602582857013, "Avg game time in secs": 1.9909114153997507, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 19456, "Total num trained steps": 38314, "Timestamp in ms": 1701906225012, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968423210990363, "Avg loss": 0.7915666743647307, "Avg value loss": 0.5063193863607012, "Avg policy loss": 0.2852472895756364, "Total num played games": 19508, "Total num trained steps": 38400, "Timestamp in ms": 1701906259389, "logtype": "training_step"}
{"Avg objective": 22.8046875, "Games time in secs": 79.66954758390784, "Avg game time in secs": 1.9448872919892892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 19584, "Total num trained steps": 38508, "Timestamp in ms": 1701906304681, "logtype": "played_game"}
{"Total num played games": 19604, "Total num trained steps": 38508, "Timestamp in ms": 1701906359046, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9375}
{"Ratio train steps to played games": 1.9559346126510306, "Avg loss": 0.9939462402835488, "Avg value loss": 0.7171489369357005, "Avg policy loss": 0.276797297061421, "Total num played games": 19698, "Total num trained steps": 38528, "Timestamp in ms": 1701906367217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962432734287745, "Avg loss": 0.924303179839626, "Avg value loss": 0.6067300966242328, "Avg policy loss": 0.3175730872899294, "Total num played games": 19698, "Total num trained steps": 38656, "Timestamp in ms": 1701906418994, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9689308559244594, "Avg loss": 0.4311225756537169, "Avg value loss": 0.15140714164590463, "Avg policy loss": 0.2797154310392216, "Total num played games": 19698, "Total num trained steps": 38784, "Timestamp in ms": 1701906471793, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 207.10632200539112, "Avg game time in secs": 2.166647178324638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.5, "agent_stopped_0": 0.58}, "Total num played games": 19712, "Total num trained steps": 38888, "Timestamp in ms": 1701906511788, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9657977164797413, "Avg loss": 0.6840688365045935, "Avg value loss": 0.41881889902288094, "Avg policy loss": 0.2652499364921823, "Total num played games": 19794, "Total num trained steps": 38912, "Timestamp in ms": 1701906520824, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9722643225219763, "Avg loss": 0.5909706482198089, "Avg value loss": 0.29747230448992923, "Avg policy loss": 0.2934983450686559, "Total num played games": 19794, "Total num trained steps": 39040, "Timestamp in ms": 1701906572613, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 78.17692875862122, "Avg game time in secs": 1.8401980857888702, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 19840, "Total num trained steps": 39082, "Timestamp in ms": 1701906589965, "logtype": "played_game"}
{"Total num played games": 19890, "Total num trained steps": 39111, "Timestamp in ms": 1701906732333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.48828125}
{"Avg objective": 20.828125, "Games time in secs": 145.79242085665464, "Avg game time in secs": 2.138474936800776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 19968, "Total num trained steps": 39119, "Timestamp in ms": 1701906735757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9599679743795035, "Avg loss": 1.2585327252745628, "Avg value loss": 0.961071815341711, "Avg policy loss": 0.29746091121342033, "Total num played games": 19984, "Total num trained steps": 39168, "Timestamp in ms": 1701906756658, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966373098478783, "Avg loss": 0.537635252578184, "Avg value loss": 0.24433416913961992, "Avg policy loss": 0.29330108570866287, "Total num played games": 19984, "Total num trained steps": 39296, "Timestamp in ms": 1701906808251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727782225780623, "Avg loss": 0.40483048162423074, "Avg value loss": 0.1342127647367306, "Avg policy loss": 0.2706177136860788, "Total num played games": 19984, "Total num trained steps": 39424, "Timestamp in ms": 1701906859368, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9697211155378487, "Avg loss": 0.7838127138093114, "Avg value loss": 0.501243643288035, "Avg policy loss": 0.28256907081231475, "Total num played games": 20080, "Total num trained steps": 39552, "Timestamp in ms": 1701906910501, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 215.09442961215973, "Avg game time in secs": 2.1971754458209034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.51, "agent_stopped_0": 0.54}, "Total num played games": 20096, "Total num trained steps": 39652, "Timestamp in ms": 1701906950852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9668880737583028, "Avg loss": 0.6374185159802437, "Avg value loss": 0.357883338117972, "Avg policy loss": 0.27953517402056605, "Total num played games": 20174, "Total num trained steps": 39680, "Timestamp in ms": 1701906961720, "logtype": "training_step"}
{"Total num played games": 20174, "Total num trained steps": 39713, "Timestamp in ms": 1701907063575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.26953125}
{"Avg objective": 21.1171875, "Games time in secs": 115.35806109383702, "Avg game time in secs": 1.849205359671032, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.39}, "Total num played games": 20224, "Total num trained steps": 39718, "Timestamp in ms": 1701907066211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9640813104401027, "Avg loss": 0.9334706659428775, "Avg value loss": 0.6377079316880554, "Avg policy loss": 0.2957627293653786, "Total num played games": 20268, "Total num trained steps": 39808, "Timestamp in ms": 1701907102200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970396684428656, "Avg loss": 0.41859424323774874, "Avg value loss": 0.14631063817068934, "Avg policy loss": 0.27228360646404326, "Total num played games": 20268, "Total num trained steps": 39936, "Timestamp in ms": 1701907153740, "logtype": "training_step"}
{"Avg objective": 22.0234375, "Games time in secs": 125.94182331487536, "Avg game time in secs": 2.2793698035529815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 20352, "Total num trained steps": 40033, "Timestamp in ms": 1701907192156, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9675866810725862, "Avg loss": 0.7057671649381518, "Avg value loss": 0.43622372980462387, "Avg policy loss": 0.26954342890530825, "Total num played games": 20362, "Total num trained steps": 40064, "Timestamp in ms": 1701907204169, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973872900500933, "Avg loss": 0.4785746061243117, "Avg value loss": 0.20344281871803105, "Avg policy loss": 0.275131786824204, "Total num played games": 20362, "Total num trained steps": 40192, "Timestamp in ms": 1701907256457, "logtype": "training_step"}
{"Total num played games": 20458, "Total num trained steps": 40317, "Timestamp in ms": 1701907398443, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.98828125}
{"Ratio train steps to played games": 1.9690857589372925, "Avg loss": 0.9954036569688469, "Avg value loss": 0.71785909216851, "Avg policy loss": 0.2775445528095588, "Total num played games": 20476, "Total num trained steps": 40320, "Timestamp in ms": 1701907400574, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 208.46906203776598, "Avg game time in secs": 1.9302912820712663, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 20480, "Total num trained steps": 40320, "Timestamp in ms": 1701907400626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9680809653561697, "Avg loss": 0.7708238139748573, "Avg value loss": 0.4905382413417101, "Avg policy loss": 0.2802855719346553, "Total num played games": 20552, "Total num trained steps": 40448, "Timestamp in ms": 1701907452560, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974309069676917, "Avg loss": 0.39173970418050885, "Avg value loss": 0.12629322934662923, "Avg policy loss": 0.2654464755905792, "Total num played games": 20552, "Total num trained steps": 40576, "Timestamp in ms": 1701907503751, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 111.83891123533249, "Avg game time in secs": 2.004150633496465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 20608, "Total num trained steps": 40597, "Timestamp in ms": 1701907512465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9715199070037779, "Avg loss": 0.9853186255786568, "Avg value loss": 0.706236467754934, "Avg policy loss": 0.27908215881325305, "Total num played games": 20646, "Total num trained steps": 40704, "Timestamp in ms": 1701907553851, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 75.48736309632659, "Avg game time in secs": 1.9082947784627322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 20736, "Total num trained steps": 40790, "Timestamp in ms": 1701907587953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9687560270009643, "Avg loss": 0.7615057893563062, "Avg value loss": 0.4925293044070713, "Avg policy loss": 0.26897648989688605, "Total num played games": 20740, "Total num trained steps": 40832, "Timestamp in ms": 1701907604679, "logtype": "training_step"}
{"Total num played games": 20740, "Total num trained steps": 40918, "Timestamp in ms": 1701907710904, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2421875}
{"Ratio train steps to played games": 1.9660170874532015, "Avg loss": 0.7818386016879231, "Avg value loss": 0.5072644943138584, "Avg policy loss": 0.2745740998070687, "Total num played games": 20834, "Total num trained steps": 40960, "Timestamp in ms": 1701907728151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9721608908514927, "Avg loss": 0.45653125271201134, "Avg value loss": 0.20291170675773174, "Avg policy loss": 0.2536195479333401, "Total num played games": 20834, "Total num trained steps": 41088, "Timestamp in ms": 1701907782173, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 223.52826980873942, "Avg game time in secs": 1.874459731800016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.32, "agent_stopped_0": 0.73}, "Total num played games": 20864, "Total num trained steps": 41161, "Timestamp in ms": 1701907811481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.6246068573091179, "Avg value loss": 0.37337982963072136, "Avg policy loss": 0.25122703227680176, "Total num played games": 20930, "Total num trained steps": 41216, "Timestamp in ms": 1701907833099, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975346392737697, "Avg loss": 0.3848418854176998, "Avg value loss": 0.14015843643574044, "Avg policy loss": 0.24468344799242914, "Total num played games": 20930, "Total num trained steps": 41344, "Timestamp in ms": 1701907882963, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 75.46003652736545, "Avg game time in secs": 2.0280194229853805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.51}, "Total num played games": 20992, "Total num trained steps": 41355, "Timestamp in ms": 1701907886941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726027397260273, "Avg loss": 0.8952876736875623, "Avg value loss": 0.6309801747556776, "Avg policy loss": 0.2643075113883242, "Total num played games": 21024, "Total num trained steps": 41472, "Timestamp in ms": 1701907933153, "logtype": "training_step"}
{"Total num played games": 21024, "Total num trained steps": 41521, "Timestamp in ms": 1701908039880, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.58203125}
{"Ratio train steps to played games": 1.9698835116961833, "Avg loss": 0.7087122858501971, "Avg value loss": 0.4465472954325378, "Avg policy loss": 0.2621649898355827, "Total num played games": 21118, "Total num trained steps": 41600, "Timestamp in ms": 1701908071380, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 234.0152040310204, "Avg game time in secs": 2.064861311693676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 21120, "Total num trained steps": 41727, "Timestamp in ms": 1701908120957, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975383450104147, "Avg loss": 0.38905660691671073, "Avg value loss": 0.13560100650647655, "Avg policy loss": 0.2534556012833491, "Total num played games": 21122, "Total num trained steps": 41728, "Timestamp in ms": 1701908121108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973036673894598, "Avg loss": 0.7589166578836739, "Avg value loss": 0.4932867782190442, "Avg policy loss": 0.26562988525256515, "Total num played games": 21214, "Total num trained steps": 41856, "Timestamp in ms": 1701908170901, "logtype": "training_step"}
{"Avg objective": 22.5859375, "Games time in secs": 75.31508889049292, "Avg game time in secs": 1.8986537057789974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 21248, "Total num trained steps": 41921, "Timestamp in ms": 1701908196272, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701548568747067, "Avg loss": 0.697690526721999, "Avg value loss": 0.43331879237666726, "Avg policy loss": 0.26437173783779144, "Total num played games": 21310, "Total num trained steps": 41984, "Timestamp in ms": 1701908221129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9736607770539438, "Avg loss": 0.3932447067927569, "Avg value loss": 0.14136562182102352, "Avg policy loss": 0.2518790817121044, "Total num played games": 21336, "Total num trained steps": 42112, "Timestamp in ms": 1701908273483, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 78.22294646501541, "Avg game time in secs": 2.100707145902561, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.61, "agent_stopped_0": 0.46}, "Total num played games": 21376, "Total num trained steps": 42114, "Timestamp in ms": 1701908274495, "logtype": "played_game"}
{"Total num played games": 21404, "Total num trained steps": 42126, "Timestamp in ms": 1701908356712, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3203125}
{"Ratio train steps to played games": 1.964833938040748, "Avg loss": 1.1989500143099576, "Avg value loss": 0.9073991897748783, "Avg policy loss": 0.29155081568751484, "Total num played games": 21498, "Total num trained steps": 42240, "Timestamp in ms": 1701908402542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970787980277235, "Avg loss": 0.40008808649145067, "Avg value loss": 0.13685650803381577, "Avg policy loss": 0.263231577235274, "Total num played games": 21498, "Total num trained steps": 42368, "Timestamp in ms": 1701908454358, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 227.27148665115237, "Avg game time in secs": 2.166930963139748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 21504, "Total num trained steps": 42488, "Timestamp in ms": 1701908501767, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679540613133277, "Avg loss": 0.4237495921552181, "Avg value loss": 0.18126766249770299, "Avg policy loss": 0.24248192878440022, "Total num played games": 21594, "Total num trained steps": 42496, "Timestamp in ms": 1701908504839, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738353246272113, "Avg loss": 0.5835481432732195, "Avg value loss": 0.3302343843970448, "Avg policy loss": 0.25331376143731177, "Total num played games": 21594, "Total num trained steps": 42624, "Timestamp in ms": 1701908556880, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 78.09272853657603, "Avg game time in secs": 1.7995546977908816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 21632, "Total num trained steps": 42682, "Timestamp in ms": 1701908579859, "logtype": "played_game"}
{"Total num played games": 21688, "Total num trained steps": 42727, "Timestamp in ms": 1701908696399, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.05859375}
{"Avg objective": 21.8984375, "Games time in secs": 119.61177204549313, "Avg game time in secs": 1.9813000132271554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 21760, "Total num trained steps": 42732, "Timestamp in ms": 1701908699471, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9629017447199266, "Avg loss": 1.0411965013481677, "Avg value loss": 0.7898682045633905, "Avg policy loss": 0.2513282966101542, "Total num played games": 21780, "Total num trained steps": 42752, "Timestamp in ms": 1701908707388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9685979248921128, "Avg loss": 0.6550369912292808, "Avg value loss": 0.3743683296488598, "Avg policy loss": 0.28066866321023554, "Total num played games": 21782, "Total num trained steps": 42880, "Timestamp in ms": 1701908760510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744743366082087, "Avg loss": 0.37561079184524715, "Avg value loss": 0.1273663992760703, "Avg policy loss": 0.248244394431822, "Total num played games": 21782, "Total num trained steps": 43008, "Timestamp in ms": 1701908811023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9716153213273608, "Avg loss": 1.3145222165621817, "Avg value loss": 1.0556639609276317, "Avg policy loss": 0.2588582676835358, "Total num played games": 21878, "Total num trained steps": 43136, "Timestamp in ms": 1701908860990, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 206.88070245459676, "Avg game time in secs": 2.1770827093569096, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.63}, "Total num played games": 21888, "Total num trained steps": 43248, "Timestamp in ms": 1701908906352, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688723036315645, "Avg loss": 0.737164568156004, "Avg value loss": 0.4757293933071196, "Avg policy loss": 0.26143517810851336, "Total num played games": 21974, "Total num trained steps": 43264, "Timestamp in ms": 1701908913390, "logtype": "training_step"}
{"Total num played games": 21974, "Total num trained steps": 43329, "Timestamp in ms": 1701909044163, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.82421875}
{"Avg objective": 23.203125, "Games time in secs": 140.0051946118474, "Avg game time in secs": 1.848418686829973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 22016, "Total num trained steps": 43334, "Timestamp in ms": 1701909046357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9662860250135943, "Avg loss": 1.2344002611935139, "Avg value loss": 0.9307244464289397, "Avg policy loss": 0.30367581255268306, "Total num played games": 22068, "Total num trained steps": 43392, "Timestamp in ms": 1701909070043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9720862787746964, "Avg loss": 0.45120336464606225, "Avg value loss": 0.17672600742662326, "Avg policy loss": 0.2744773542508483, "Total num played games": 22068, "Total num trained steps": 43520, "Timestamp in ms": 1701909119794, "logtype": "training_step"}
{"Avg objective": 21.796875, "Games time in secs": 117.3356539644301, "Avg game time in secs": 1.946110702905571, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 22144, "Total num trained steps": 43632, "Timestamp in ms": 1701909163693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694973377853984, "Avg loss": 0.578732795547694, "Avg value loss": 0.31765699351672083, "Avg policy loss": 0.26107579679228365, "Total num played games": 22162, "Total num trained steps": 43648, "Timestamp in ms": 1701909169532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9752729898023644, "Avg loss": 0.5266203039791435, "Avg value loss": 0.2612434573820792, "Avg policy loss": 0.2653768464224413, "Total num played games": 22162, "Total num trained steps": 43776, "Timestamp in ms": 1701909220697, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726815240833933, "Avg loss": 0.7154085503425449, "Avg value loss": 0.4492293115472421, "Avg policy loss": 0.2661792499711737, "Total num played games": 22256, "Total num trained steps": 43904, "Timestamp in ms": 1701909270557, "logtype": "training_step"}
{"Total num played games": 22256, "Total num trained steps": 43931, "Timestamp in ms": 1701909320950, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6015625}
{"Avg objective": 21.2734375, "Games time in secs": 158.9040617570281, "Avg game time in secs": 1.7701869152660947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.38, "agent_stopped_0": 0.67}, "Total num played games": 22272, "Total num trained steps": 43934, "Timestamp in ms": 1701909322597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9700671140939596, "Avg loss": 0.737235049251467, "Avg value loss": 0.4477585512213409, "Avg policy loss": 0.2894765001256019, "Total num played games": 22350, "Total num trained steps": 44032, "Timestamp in ms": 1701909364659, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758389261744966, "Avg loss": 0.39401956205256283, "Avg value loss": 0.1316688254592009, "Avg policy loss": 0.26235073362477124, "Total num played games": 22350, "Total num trained steps": 44160, "Timestamp in ms": 1701909414796, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 104.81239387765527, "Avg game time in secs": 1.9263307056680787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.4}, "Total num played games": 22400, "Total num trained steps": 44194, "Timestamp in ms": 1701909427410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9729151817533856, "Avg loss": 0.6044374899938703, "Avg value loss": 0.33123776165302843, "Avg policy loss": 0.2731997270602733, "Total num played games": 22448, "Total num trained steps": 44288, "Timestamp in ms": 1701909464928, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 77.86725090071559, "Avg game time in secs": 1.8478030902333558, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 22528, "Total num trained steps": 44391, "Timestamp in ms": 1701909505277, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701916252661462, "Avg loss": 0.5992184316273779, "Avg value loss": 0.3397700721397996, "Avg policy loss": 0.25944835552945733, "Total num played games": 22544, "Total num trained steps": 44416, "Timestamp in ms": 1701909514659, "logtype": "training_step"}
{"Total num played games": 22544, "Total num trained steps": 44533, "Timestamp in ms": 1701909604598, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6796875}
{"Ratio train steps to played games": 1.9678388407845908, "Avg loss": 0.5427463741507381, "Avg value loss": 0.2796020773239434, "Avg policy loss": 0.26314429531339556, "Total num played games": 22636, "Total num trained steps": 44544, "Timestamp in ms": 1701909609512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9733191978089937, "Avg loss": 0.6725648208521307, "Avg value loss": 0.4047387349419296, "Avg policy loss": 0.2678260813700035, "Total num played games": 22638, "Total num trained steps": 44672, "Timestamp in ms": 1701909661511, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 195.36672987043858, "Avg game time in secs": 1.8117821738123894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.39, "agent_stopped_0": 0.64}, "Total num played games": 22656, "Total num trained steps": 44768, "Timestamp in ms": 1701909700644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707900756642618, "Avg loss": 0.5943755733314902, "Avg value loss": 0.3467033089254983, "Avg policy loss": 0.2476722652791068, "Total num played games": 22732, "Total num trained steps": 44800, "Timestamp in ms": 1701909712957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9763769136019709, "Avg loss": 0.43254355213139206, "Avg value loss": 0.1818920141668059, "Avg policy loss": 0.250651539885439, "Total num played games": 22732, "Total num trained steps": 44928, "Timestamp in ms": 1701909762815, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 74.20957697182894, "Avg game time in secs": 1.8155430983752012, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 22784, "Total num trained steps": 44958, "Timestamp in ms": 1701909774854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737164885228666, "Avg loss": 0.7325317966751754, "Avg value loss": 0.47093032248085365, "Avg policy loss": 0.2616014799568802, "Total num played games": 22828, "Total num trained steps": 45056, "Timestamp in ms": 1701909815058, "logtype": "training_step"}
{"Total num played games": 22828, "Total num trained steps": 45135, "Timestamp in ms": 1701909909721, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0703125}
{"Avg objective": 20.4140625, "Games time in secs": 138.48038609325886, "Avg game time in secs": 2.0726938117295504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 22912, "Total num trained steps": 45144, "Timestamp in ms": 1701909913334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9712067009859524, "Avg loss": 0.658471935428679, "Avg value loss": 0.40063873410690576, "Avg policy loss": 0.25783319713082165, "Total num played games": 22922, "Total num trained steps": 45184, "Timestamp in ms": 1701909929037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767908559462526, "Avg loss": 0.4128688625060022, "Avg value loss": 0.15097332664299756, "Avg policy loss": 0.2618955357465893, "Total num played games": 22922, "Total num trained steps": 45312, "Timestamp in ms": 1701909979862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742787625999305, "Avg loss": 0.7787446959409863, "Avg value loss": 0.5033412463380955, "Avg policy loss": 0.27540345664601773, "Total num played games": 23016, "Total num trained steps": 45440, "Timestamp in ms": 1701910030380, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 150.46060052141547, "Avg game time in secs": 1.9300482595863286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 23040, "Total num trained steps": 45524, "Timestamp in ms": 1701910063795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9717871051492861, "Avg loss": 0.7401214251294732, "Avg value loss": 0.4766505133593455, "Avg policy loss": 0.26347091514617205, "Total num played games": 23110, "Total num trained steps": 45568, "Timestamp in ms": 1701910081304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977325832972739, "Avg loss": 0.44615996920038015, "Avg value loss": 0.1828625647467561, "Avg policy loss": 0.2632974050939083, "Total num played games": 23110, "Total num trained steps": 45696, "Timestamp in ms": 1701910131249, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 74.61023015901446, "Avg game time in secs": 1.8541691026766784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 23168, "Total num trained steps": 45714, "Timestamp in ms": 1701910138405, "logtype": "played_game"}
{"Total num played games": 23204, "Total num trained steps": 45739, "Timestamp in ms": 1701910215015, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.91796875}
{"Avg objective": 21.7109375, "Games time in secs": 81.30317761003971, "Avg game time in secs": 2.1277639933105092, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.53, "agent_stopped_0": 0.48}, "Total num played games": 23296, "Total num trained steps": 45749, "Timestamp in ms": 1701910219709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966864108507168, "Avg loss": 1.1041391673497856, "Avg value loss": 0.8124651327962056, "Avg policy loss": 0.29167404503095895, "Total num played games": 23298, "Total num trained steps": 45824, "Timestamp in ms": 1701910250086, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9723581423298138, "Avg loss": 0.40757959545589983, "Avg value loss": 0.13287249254062772, "Avg policy loss": 0.2747071048943326, "Total num played games": 23298, "Total num trained steps": 45952, "Timestamp in ms": 1701910300305, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9778521761524595, "Avg loss": 0.3712370996363461, "Avg value loss": 0.11560523475054651, "Avg policy loss": 0.2556318666320294, "Total num played games": 23298, "Total num trained steps": 46080, "Timestamp in ms": 1701910351697, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9752073181157561, "Avg loss": 0.9440910767298192, "Avg value loss": 0.6576640163548291, "Avg policy loss": 0.28642704454250634, "Total num played games": 23394, "Total num trained steps": 46208, "Timestamp in ms": 1701910402603, "logtype": "training_step"}
{"Avg objective": 23.328125, "Games time in secs": 211.34853891655803, "Avg game time in secs": 1.6291569558670744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 23424, "Total num trained steps": 46281, "Timestamp in ms": 1701910431058, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97270946866485, "Avg loss": 0.7797616038005799, "Avg value loss": 0.5002244544448331, "Avg policy loss": 0.279537147609517, "Total num played games": 23488, "Total num trained steps": 46336, "Timestamp in ms": 1701910452491, "logtype": "training_step"}
{"Total num played games": 23488, "Total num trained steps": 46340, "Timestamp in ms": 1701910485382, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.125}
{"Avg objective": 22.4296875, "Games time in secs": 56.924087680876255, "Avg game time in secs": 1.8387241989548784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 23552, "Total num trained steps": 46345, "Timestamp in ms": 1701910487982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9703163429734543, "Avg loss": 1.110945298569277, "Avg value loss": 0.8062057654606178, "Avg policy loss": 0.30473951308522373, "Total num played games": 23582, "Total num trained steps": 46464, "Timestamp in ms": 1701910534999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757442116868797, "Avg loss": 0.39542736462317407, "Avg value loss": 0.13373758824309334, "Avg policy loss": 0.2616897786501795, "Total num played games": 23582, "Total num trained steps": 46592, "Timestamp in ms": 1701910586018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973139623278993, "Avg loss": 0.7648275119718164, "Avg value loss": 0.49520495923934504, "Avg policy loss": 0.2696225579129532, "Total num played games": 23678, "Total num trained steps": 46720, "Timestamp in ms": 1701910636605, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783783783783784, "Avg loss": 0.41487763496115804, "Avg value loss": 0.14860267407493666, "Avg policy loss": 0.2662749596638605, "Total num played games": 23678, "Total num trained steps": 46848, "Timestamp in ms": 1701910687464, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 199.48331857845187, "Avg game time in secs": 2.1322807605029084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.65, "agent_stopped_0": 0.46}, "Total num played games": 23680, "Total num trained steps": 46848, "Timestamp in ms": 1701910687465, "logtype": "played_game"}
{"Total num played games": 23776, "Total num trained steps": 46943, "Timestamp in ms": 1701910801436, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.83203125}
{"Avg objective": 21.265625, "Games time in secs": 116.11955989897251, "Avg game time in secs": 1.8416639587376267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 23808, "Total num trained steps": 46948, "Timestamp in ms": 1701910803585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679932970255551, "Avg loss": 1.2337242821231484, "Avg value loss": 0.938160264689941, "Avg policy loss": 0.29556400584988296, "Total num played games": 23870, "Total num trained steps": 46976, "Timestamp in ms": 1701910815145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973355676581483, "Avg loss": 0.4842094499617815, "Avg value loss": 0.20495995559031144, "Avg policy loss": 0.2792494937311858, "Total num played games": 23870, "Total num trained steps": 47104, "Timestamp in ms": 1701910868098, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783865292787133, "Avg loss": 0.3659922576043755, "Avg value loss": 0.11250144930090755, "Avg policy loss": 0.2534908055095002, "Total num played games": 23872, "Total num trained steps": 47232, "Timestamp in ms": 1701910917153, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 114.69726736471057, "Avg game time in secs": 1.8248163465759717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 23936, "Total num trained steps": 47235, "Timestamp in ms": 1701910918282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761328548777435, "Avg loss": 0.7759071716573089, "Avg value loss": 0.5020398692577146, "Avg policy loss": 0.2738673009444028, "Total num played games": 23966, "Total num trained steps": 47360, "Timestamp in ms": 1701910968916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737323358270988, "Avg loss": 0.9013608301756904, "Avg value loss": 0.6210932136164047, "Avg policy loss": 0.2802676059072837, "Total num played games": 24060, "Total num trained steps": 47488, "Timestamp in ms": 1701911020804, "logtype": "training_step"}
{"Total num played games": 24060, "Total num trained steps": 47545, "Timestamp in ms": 1701911088894, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2421875}
{"Avg objective": 21.6953125, "Games time in secs": 172.2747607268393, "Avg game time in secs": 1.947589052375406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 24064, "Total num trained steps": 47548, "Timestamp in ms": 1701911090557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9713090999420386, "Avg loss": 0.8494558078236878, "Avg value loss": 0.5627543866285123, "Avg policy loss": 0.2867014156654477, "Total num played games": 24154, "Total num trained steps": 47616, "Timestamp in ms": 1701911118091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9766498302558582, "Avg loss": 0.43416136037558317, "Avg value loss": 0.14977434335742146, "Avg policy loss": 0.2843870149226859, "Total num played games": 24154, "Total num trained steps": 47744, "Timestamp in ms": 1701911166192, "logtype": "training_step"}
{"Avg objective": 22.6015625, "Games time in secs": 98.07567993178964, "Avg game time in secs": 1.945443930773763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 24192, "Total num trained steps": 47802, "Timestamp in ms": 1701911188633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974265918838667, "Avg loss": 0.681482128566131, "Avg value loss": 0.3971965566743165, "Avg policy loss": 0.28428556385915726, "Total num played games": 24248, "Total num trained steps": 47872, "Timestamp in ms": 1701911216452, "logtype": "training_step"}
{"Avg objective": 22.65625, "Games time in secs": 76.69471087306738, "Avg game time in secs": 1.9823970480938442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 24320, "Total num trained steps": 47992, "Timestamp in ms": 1701911265328, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972062448644207, "Avg loss": 0.545815393794328, "Avg value loss": 0.27321618306450546, "Avg policy loss": 0.27259920770302415, "Total num played games": 24340, "Total num trained steps": 48000, "Timestamp in ms": 1701911268270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771588201462493, "Avg loss": 0.7418395599815995, "Avg value loss": 0.4401204384630546, "Avg policy loss": 0.30171912093646824, "Total num played games": 24342, "Total num trained steps": 48128, "Timestamp in ms": 1701911319118, "logtype": "training_step"}
{"Total num played games": 24342, "Total num trained steps": 48149, "Timestamp in ms": 1701911406080, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.203125}
{"Ratio train steps to played games": 1.9747503683090522, "Avg loss": 0.985998387215659, "Avg value loss": 0.6941202944726683, "Avg policy loss": 0.29187809850554913, "Total num played games": 24436, "Total num trained steps": 48256, "Timestamp in ms": 1701911447773, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 224.37407019361854, "Avg game time in secs": 2.095453535555862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 24448, "Total num trained steps": 48364, "Timestamp in ms": 1701911489702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9724419078679167, "Avg loss": 0.582774453330785, "Avg value loss": 0.3110294900252484, "Avg policy loss": 0.271744956378825, "Total num played games": 24530, "Total num trained steps": 48384, "Timestamp in ms": 1701911498053, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776600081532818, "Avg loss": 0.5386673689354211, "Avg value loss": 0.26256972999544814, "Avg policy loss": 0.27609764121007174, "Total num played games": 24530, "Total num trained steps": 48512, "Timestamp in ms": 1701911549805, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 77.06787756457925, "Avg game time in secs": 1.8376440980064217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 24576, "Total num trained steps": 48553, "Timestamp in ms": 1701911566770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.8145338883623481, "Avg value loss": 0.5222937339276541, "Avg policy loss": 0.29224015097133815, "Total num played games": 24624, "Total num trained steps": 48640, "Timestamp in ms": 1701911600335, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 75.8515625745058, "Avg game time in secs": 2.0031998328049667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 24704, "Total num trained steps": 48746, "Timestamp in ms": 1701911642622, "logtype": "played_game"}
{"Total num played games": 24718, "Total num trained steps": 48751, "Timestamp in ms": 1701911710597, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.05078125}
{"Ratio train steps to played games": 1.9655005642431083, "Avg loss": 0.8213320137001574, "Avg value loss": 0.5449827770935372, "Avg policy loss": 0.2763492284575477, "Total num played games": 24812, "Total num trained steps": 48768, "Timestamp in ms": 1701911718132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9706593583749799, "Avg loss": 0.7447195381391793, "Avg value loss": 0.43726532405707985, "Avg policy loss": 0.3074542188551277, "Total num played games": 24812, "Total num trained steps": 48896, "Timestamp in ms": 1701911769881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757778494276963, "Avg loss": 0.39587057242169976, "Avg value loss": 0.12826256547123194, "Avg policy loss": 0.26760800706688315, "Total num played games": 24812, "Total num trained steps": 49024, "Timestamp in ms": 1701911820793, "logtype": "training_step"}
{"Avg objective": 21.2578125, "Games time in secs": 213.6155392974615, "Avg game time in secs": 1.828247712168377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 24832, "Total num trained steps": 49117, "Timestamp in ms": 1701911856238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730250481695568, "Avg loss": 0.7038955956231803, "Avg value loss": 0.4350454885570798, "Avg policy loss": 0.2688501151278615, "Total num played games": 24912, "Total num trained steps": 49152, "Timestamp in ms": 1701911869639, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9781631342324983, "Avg loss": 0.46812189603224397, "Avg value loss": 0.1918997799511999, "Avg policy loss": 0.2762221172451973, "Total num played games": 24912, "Total num trained steps": 49280, "Timestamp in ms": 1701911920503, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 79.61529956385493, "Avg game time in secs": 1.778830827854108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 24960, "Total num trained steps": 49318, "Timestamp in ms": 1701911935854, "logtype": "played_game"}
{"Total num played games": 25006, "Total num trained steps": 49352, "Timestamp in ms": 1701912016276, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.265625}
{"Avg objective": 22.96875, "Games time in secs": 83.93883190304041, "Avg game time in secs": 1.9614963585627265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 25088, "Total num trained steps": 49359, "Timestamp in ms": 1701912019794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684462151394422, "Avg loss": 1.386261617532, "Avg value loss": 1.0936920657986775, "Avg policy loss": 0.29256954009179026, "Total num played games": 25100, "Total num trained steps": 49408, "Timestamp in ms": 1701912039168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9735458167330677, "Avg loss": 0.504827490542084, "Avg value loss": 0.21224733907729387, "Avg policy loss": 0.2925801547244191, "Total num played games": 25100, "Total num trained steps": 49536, "Timestamp in ms": 1701912091356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786454183266933, "Avg loss": 0.3806878949981183, "Avg value loss": 0.11307500384282321, "Avg policy loss": 0.26761289092246443, "Total num played games": 25100, "Total num trained steps": 49664, "Timestamp in ms": 1701912143312, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9761470074615017, "Avg loss": 0.6667664962587878, "Avg value loss": 0.38261321280151606, "Avg policy loss": 0.28415328823029995, "Total num played games": 25196, "Total num trained steps": 49792, "Timestamp in ms": 1701912196113, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 213.39990128576756, "Avg game time in secs": 1.8839570256823208, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.41, "agent_stopped_0": 0.7}, "Total num played games": 25216, "Total num trained steps": 49884, "Timestamp in ms": 1701912233194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973746639253519, "Avg loss": 0.7789569047745317, "Avg value loss": 0.49526664859149605, "Avg policy loss": 0.2836902652634308, "Total num played games": 25292, "Total num trained steps": 49920, "Timestamp in ms": 1701912247314, "logtype": "training_step"}
{"Total num played games": 25292, "Total num trained steps": 49955, "Timestamp in ms": 1701912357958, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.48046875}
{"Avg objective": 22.2734375, "Games time in secs": 127.35509943217039, "Avg game time in secs": 1.7041322295553982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.43}, "Total num played games": 25344, "Total num trained steps": 49961, "Timestamp in ms": 1701912360549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9714803434964154, "Avg loss": 0.9223960975650698, "Avg value loss": 0.6088729007169604, "Avg policy loss": 0.3135231955675408, "Total num played games": 25386, "Total num trained steps": 50048, "Timestamp in ms": 1701912396111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9765224927125187, "Avg loss": 0.3989941293839365, "Avg value loss": 0.12560057628434151, "Avg policy loss": 0.27339355333242565, "Total num played games": 25386, "Total num trained steps": 50176, "Timestamp in ms": 1701912446402, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 123.40153877809644, "Avg game time in secs": 1.9327807458175812, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.46}, "Total num played games": 25472, "Total num trained steps": 50269, "Timestamp in ms": 1701912483950, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9740993642571227, "Avg loss": 0.8039906037738547, "Avg value loss": 0.5256043432164006, "Avg policy loss": 0.27838626131415367, "Total num played games": 25482, "Total num trained steps": 50304, "Timestamp in ms": 1701912498011, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791225178557412, "Avg loss": 0.4566660344135016, "Avg value loss": 0.17109584948047996, "Avg policy loss": 0.28557018691208214, "Total num played games": 25482, "Total num trained steps": 50432, "Timestamp in ms": 1701912550682, "logtype": "training_step"}
{"Total num played games": 25576, "Total num trained steps": 50559, "Timestamp in ms": 1701912664002, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9296875}
{"Ratio train steps to played games": 1.9768532999687207, "Avg loss": 0.6618065345101058, "Avg value loss": 0.38105077971704304, "Avg policy loss": 0.28075575770344585, "Total num played games": 25576, "Total num trained steps": 50560, "Timestamp in ms": 1701912664680, "logtype": "training_step"}
{"Avg objective": 22.1796875, "Games time in secs": 182.0274201221764, "Avg game time in secs": 1.7947806196461897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 25600, "Total num trained steps": 50563, "Timestamp in ms": 1701912665978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9746007012076354, "Avg loss": 0.7571524418890476, "Avg value loss": 0.46762644383125007, "Avg policy loss": 0.2895259972428903, "Total num played games": 25670, "Total num trained steps": 50688, "Timestamp in ms": 1701912715986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795870666147253, "Avg loss": 0.3889137259684503, "Avg value loss": 0.12125891412142664, "Avg policy loss": 0.26765481184702367, "Total num played games": 25670, "Total num trained steps": 50816, "Timestamp in ms": 1701912769692, "logtype": "training_step"}
{"Avg objective": 22.90625, "Games time in secs": 110.65584371611476, "Avg game time in secs": 1.8620918851229362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 25728, "Total num trained steps": 50833, "Timestamp in ms": 1701912776634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773327123117528, "Avg loss": 0.8538965010084212, "Avg value loss": 0.5660575040965341, "Avg policy loss": 0.28783899219706655, "Total num played games": 25764, "Total num trained steps": 50944, "Timestamp in ms": 1701912820019, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 76.32987413182855, "Avg game time in secs": 2.028153143968666, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 25856, "Total num trained steps": 51026, "Timestamp in ms": 1701912852964, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750947482403898, "Avg loss": 0.6984108318574727, "Avg value loss": 0.42285681958310306, "Avg policy loss": 0.2755540047073737, "Total num played games": 25858, "Total num trained steps": 51072, "Timestamp in ms": 1701912870745, "logtype": "training_step"}
{"Total num played games": 25858, "Total num trained steps": 51162, "Timestamp in ms": 1701912980623, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.10546875}
{"Ratio train steps to played games": 1.972872996300863, "Avg loss": 0.7028684674296528, "Avg value loss": 0.424577827390749, "Avg policy loss": 0.27829064044635743, "Total num played games": 25952, "Total num trained steps": 51200, "Timestamp in ms": 1701912996315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9778051787916153, "Avg loss": 0.43294147634878755, "Avg value loss": 0.15119992598192766, "Avg policy loss": 0.28174155205488205, "Total num played games": 25952, "Total num trained steps": 51328, "Timestamp in ms": 1701913046489, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 220.02077826857567, "Avg game time in secs": 1.8268606020137668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.46}, "Total num played games": 25984, "Total num trained steps": 51397, "Timestamp in ms": 1701913072985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755432695999386, "Avg loss": 0.8666692329570651, "Avg value loss": 0.5838318724418059, "Avg policy loss": 0.2828373610973358, "Total num played games": 26046, "Total num trained steps": 51456, "Timestamp in ms": 1701913096311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800399201596806, "Avg loss": 0.43196524563245475, "Avg value loss": 0.15552489558467641, "Avg policy loss": 0.2764403544133529, "Total num played games": 26052, "Total num trained steps": 51584, "Timestamp in ms": 1701913146309, "logtype": "training_step"}
{"Avg objective": 22.0859375, "Games time in secs": 74.53786378353834, "Avg game time in secs": 1.8865736946463585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 26112, "Total num trained steps": 51587, "Timestamp in ms": 1701913147523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781195011858312, "Avg loss": 0.707223281962797, "Avg value loss": 0.42010792350629345, "Avg policy loss": 0.28711535735055804, "Total num played games": 26142, "Total num trained steps": 51712, "Timestamp in ms": 1701913197205, "logtype": "training_step"}
{"Total num played games": 26142, "Total num trained steps": 51762, "Timestamp in ms": 1701913314358, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.22265625}
{"Ratio train steps to played games": 1.975910962036896, "Avg loss": 0.6704579920042306, "Avg value loss": 0.3926928377477452, "Avg policy loss": 0.2777651642682031, "Total num played games": 26236, "Total num trained steps": 51840, "Timestamp in ms": 1701913347083, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 251.11080915108323, "Avg game time in secs": 1.9474644043366425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.51, "agent_stopped_0": 0.59}, "Total num played games": 26240, "Total num trained steps": 51963, "Timestamp in ms": 1701913398634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9745801352686374, "Avg loss": 0.39099437929689884, "Avg value loss": 0.1344443461857736, "Avg policy loss": 0.25655003311112523, "Total num played games": 26318, "Total num trained steps": 51968, "Timestamp in ms": 1701913400368, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9784292875588638, "Avg loss": 0.7580652867909521, "Avg value loss": 0.47048426134279, "Avg policy loss": 0.2875810223631561, "Total num played games": 26332, "Total num trained steps": 52096, "Timestamp in ms": 1701913452871, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 79.72362620383501, "Avg game time in secs": 1.7425055082130712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.39}, "Total num played games": 26368, "Total num trained steps": 52156, "Timestamp in ms": 1701913478358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9762355256187087, "Avg loss": 0.740922486409545, "Avg value loss": 0.4611909632803872, "Avg policy loss": 0.2797315262723714, "Total num played games": 26426, "Total num trained steps": 52224, "Timestamp in ms": 1701913505506, "logtype": "training_step"}
{"Avg objective": 23.34375, "Games time in secs": 78.5278797633946, "Avg game time in secs": 1.8214826404000632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 26496, "Total num trained steps": 52346, "Timestamp in ms": 1701913556886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974057315233786, "Avg loss": 0.5254110025707632, "Avg value loss": 0.26258791075088084, "Avg policy loss": 0.26282309263478965, "Total num played games": 26518, "Total num trained steps": 52352, "Timestamp in ms": 1701913559258, "logtype": "training_step"}
{"Total num played games": 26520, "Total num trained steps": 52363, "Timestamp in ms": 1701913631362, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.70703125}
{"Ratio train steps to played games": 1.9718944916209513, "Avg loss": 1.1812983653508127, "Avg value loss": 0.8726750507485121, "Avg policy loss": 0.3086233298527077, "Total num played games": 26614, "Total num trained steps": 52480, "Timestamp in ms": 1701913681943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767039903810024, "Avg loss": 0.4090621671639383, "Avg value loss": 0.13508080336032435, "Avg policy loss": 0.27398136316332966, "Total num played games": 26614, "Total num trained steps": 52608, "Timestamp in ms": 1701913736921, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 228.27732759341598, "Avg game time in secs": 1.7778430919279344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.43, "agent_stopped_0": 0.65}, "Total num played games": 26624, "Total num trained steps": 52720, "Timestamp in ms": 1701913785164, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9745020218661076, "Avg loss": 0.5526105361059308, "Avg value loss": 0.28928549218107946, "Avg policy loss": 0.2633250425569713, "Total num played games": 26708, "Total num trained steps": 52736, "Timestamp in ms": 1701913792263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793320353452148, "Avg loss": 0.5887726517394185, "Avg value loss": 0.31221862172242254, "Avg policy loss": 0.27655402396339923, "Total num played games": 26708, "Total num trained steps": 52864, "Timestamp in ms": 1701913848187, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 83.77641469240189, "Avg game time in secs": 1.769390122499317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.4}, "Total num played games": 26752, "Total num trained steps": 52910, "Timestamp in ms": 1701913868940, "logtype": "played_game"}
{"Total num played games": 26810, "Total num trained steps": 52964, "Timestamp in ms": 1701913969017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55859375}
{"Avg objective": 21.703125, "Games time in secs": 103.04404310509562, "Avg game time in secs": 1.9597202166041825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.54, "agent_stopped_0": 0.58}, "Total num played games": 26880, "Total num trained steps": 52971, "Timestamp in ms": 1701913971984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696699375557538, "Avg loss": 0.9600783183705062, "Avg value loss": 0.675942710833624, "Avg policy loss": 0.2841356066055596, "Total num played games": 26904, "Total num trained steps": 52992, "Timestamp in ms": 1701913980576, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744275944097531, "Avg loss": 0.5262034134939313, "Avg value loss": 0.22848931001499295, "Avg policy loss": 0.2977141049923375, "Total num played games": 26904, "Total num trained steps": 53120, "Timestamp in ms": 1701914037481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791480820695808, "Avg loss": 0.37309268256649375, "Avg value loss": 0.10460864374181256, "Avg policy loss": 0.26848403946496546, "Total num played games": 26904, "Total num trained steps": 53248, "Timestamp in ms": 1701914095936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770353359508113, "Avg loss": 0.9177887648111209, "Avg value loss": 0.6387567109777592, "Avg policy loss": 0.2790320545900613, "Total num played games": 26998, "Total num trained steps": 53376, "Timestamp in ms": 1701914151164, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 227.77037352323532, "Avg game time in secs": 1.9939829666982405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.51, "agent_stopped_0": 0.57}, "Total num played games": 27008, "Total num trained steps": 53487, "Timestamp in ms": 1701914199755, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9749003395836409, "Avg loss": 0.5207870781887323, "Avg value loss": 0.25965941074537113, "Avg policy loss": 0.2611276663374156, "Total num played games": 27092, "Total num trained steps": 53504, "Timestamp in ms": 1701914207153, "logtype": "training_step"}
{"Total num played games": 27092, "Total num trained steps": 53565, "Timestamp in ms": 1701914336284, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1796875}
{"Avg objective": 20.921875, "Games time in secs": 138.6007494740188, "Avg game time in secs": 1.78267675236566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.4}, "Total num played games": 27136, "Total num trained steps": 53567, "Timestamp in ms": 1701914338356, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727433237695873, "Avg loss": 0.7814246432390064, "Avg value loss": 0.4955312532838434, "Avg policy loss": 0.2858933958923444, "Total num played games": 27186, "Total num trained steps": 53632, "Timestamp in ms": 1701914368946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774884131538293, "Avg loss": 0.37329228315502405, "Avg value loss": 0.11752555059501901, "Avg policy loss": 0.2557667325017974, "Total num played games": 27186, "Total num trained steps": 53760, "Timestamp in ms": 1701914424179, "logtype": "training_step"}
{"Avg objective": 22.546875, "Games time in secs": 132.26589184254408, "Avg game time in secs": 1.7917407958011609, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.41}, "Total num played games": 27264, "Total num trained steps": 53866, "Timestamp in ms": 1701914470622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975366568914956, "Avg loss": 0.8109354833140969, "Avg value loss": 0.553341549821198, "Avg policy loss": 0.2575939263915643, "Total num played games": 27280, "Total num trained steps": 53888, "Timestamp in ms": 1701914479710, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980058651026393, "Avg loss": 0.5975208641029894, "Avg value loss": 0.3235004232265055, "Avg policy loss": 0.2740204413421452, "Total num played games": 27280, "Total num trained steps": 54016, "Timestamp in ms": 1701914537885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779352670417185, "Avg loss": 0.7465596129186451, "Avg value loss": 0.466707079554908, "Avg policy loss": 0.2798525320831686, "Total num played games": 27374, "Total num trained steps": 54144, "Timestamp in ms": 1701914592692, "logtype": "training_step"}
{"Total num played games": 27374, "Total num trained steps": 54168, "Timestamp in ms": 1701914701964, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.46484375}
{"Avg objective": 21.8359375, "Games time in secs": 233.03185452148318, "Avg game time in secs": 2.051802153204335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 27392, "Total num trained steps": 54170, "Timestamp in ms": 1701914703654, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758264161933887, "Avg loss": 0.8796029179356992, "Avg value loss": 0.6047686375677586, "Avg policy loss": 0.27483428944833577, "Total num played games": 27468, "Total num trained steps": 54272, "Timestamp in ms": 1701914747249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980486384156109, "Avg loss": 0.35846068209502846, "Avg value loss": 0.10839689488057047, "Avg policy loss": 0.25006378698162735, "Total num played games": 27468, "Total num trained steps": 54400, "Timestamp in ms": 1701914800853, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 109.9273286908865, "Avg game time in secs": 1.8256570470693987, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 27520, "Total num trained steps": 54429, "Timestamp in ms": 1701914813581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978376024961904, "Avg loss": 0.6172153281513602, "Avg value loss": 0.35756884020520374, "Avg policy loss": 0.2596464839298278, "Total num played games": 27562, "Total num trained steps": 54528, "Timestamp in ms": 1701914856147, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 83.6431841365993, "Avg game time in secs": 1.9508131845213939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.43, "agent_stopped_0": 0.59}, "Total num played games": 27648, "Total num trained steps": 54620, "Timestamp in ms": 1701914897224, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976243853051779, "Avg loss": 0.5608195897657424, "Avg value loss": 0.3033943955088034, "Avg policy loss": 0.2574251985643059, "Total num played games": 27656, "Total num trained steps": 54656, "Timestamp in ms": 1701914913074, "logtype": "training_step"}
{"Total num played games": 27656, "Total num trained steps": 54768, "Timestamp in ms": 1701915060529, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.125}
{"Ratio train steps to played games": 1.9741981981981982, "Avg loss": 0.5182471524458379, "Avg value loss": 0.2573007053579204, "Avg policy loss": 0.2609464457491413, "Total num played games": 27750, "Total num trained steps": 54784, "Timestamp in ms": 1701915068663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978810810810811, "Avg loss": 0.5102591591421515, "Avg value loss": 0.25371391244698316, "Avg policy loss": 0.25654524308629334, "Total num played games": 27750, "Total num trained steps": 54912, "Timestamp in ms": 1701915126427, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 262.44341341406107, "Avg game time in secs": 1.8145652609237004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.41, "agent_stopped_0": 0.66}, "Total num played games": 27776, "Total num trained steps": 54992, "Timestamp in ms": 1701915159668, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765855059972708, "Avg loss": 0.4801110866246745, "Avg value loss": 0.23540610523195937, "Avg policy loss": 0.24470497982110828, "Total num played games": 27846, "Total num trained steps": 55040, "Timestamp in ms": 1701915179401, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811822164763342, "Avg loss": 0.34403820615261793, "Avg value loss": 0.10390009492402896, "Avg policy loss": 0.24013811314944178, "Total num played games": 27846, "Total num trained steps": 55168, "Timestamp in ms": 1701915235276, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 82.93405456840992, "Avg game time in secs": 1.8196858599840198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.45}, "Total num played games": 27904, "Total num trained steps": 55185, "Timestamp in ms": 1701915242602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788147724019467, "Avg loss": 0.8657371301669627, "Avg value loss": 0.6076644500717521, "Avg policy loss": 0.25807268207427114, "Total num played games": 27944, "Total num trained steps": 55296, "Timestamp in ms": 1701915292487, "logtype": "training_step"}
{"Total num played games": 27944, "Total num trained steps": 55369, "Timestamp in ms": 1701915414605, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.921875}
{"Avg objective": 21.5, "Games time in secs": 175.66106195375323, "Avg game time in secs": 2.075254229566781, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 28032, "Total num trained steps": 55376, "Timestamp in ms": 1701915418263, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767101790427277, "Avg loss": 0.8768318402580917, "Avg value loss": 0.6162109500728548, "Avg policy loss": 0.26062088226899505, "Total num played games": 28038, "Total num trained steps": 55424, "Timestamp in ms": 1701915438044, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812754119409373, "Avg loss": 0.4101143891457468, "Avg value loss": 0.15404854592634365, "Avg policy loss": 0.25606584269553423, "Total num played games": 28038, "Total num trained steps": 55552, "Timestamp in ms": 1701915497608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792051756007394, "Avg loss": 0.9232986562419683, "Avg value loss": 0.653651159896981, "Avg policy loss": 0.2696475062984973, "Total num played games": 28132, "Total num trained steps": 55680, "Timestamp in ms": 1701915554681, "logtype": "training_step"}
{"Avg objective": 22.265625, "Games time in secs": 169.0037775747478, "Avg game time in secs": 1.8925508478132542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 28160, "Total num trained steps": 55757, "Timestamp in ms": 1701915587267, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771841564514987, "Avg loss": 0.635086634894833, "Avg value loss": 0.3744553471915424, "Avg policy loss": 0.2606312904972583, "Total num played games": 28226, "Total num trained steps": 55808, "Timestamp in ms": 1701915610593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817189824984058, "Avg loss": 0.4020942198112607, "Avg value loss": 0.1455729430890642, "Avg policy loss": 0.2565212768968195, "Total num played games": 28226, "Total num trained steps": 55936, "Timestamp in ms": 1701915669372, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 86.43782347813249, "Avg game time in secs": 1.8057160155440215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.37, "agent_stopped_0": 0.64}, "Total num played games": 28288, "Total num trained steps": 55946, "Timestamp in ms": 1701915673705, "logtype": "played_game"}
{"Total num played games": 28320, "Total num trained steps": 55972, "Timestamp in ms": 1701915757288, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.90234375}
{"Ratio train steps to played games": 1.9730766523544732, "Avg loss": 1.179832214023918, "Avg value loss": 0.8966632210067473, "Avg policy loss": 0.2831689934246242, "Total num played games": 28414, "Total num trained steps": 56064, "Timestamp in ms": 1701915800126, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776166678397973, "Avg loss": 0.3934708572924137, "Avg value loss": 0.13614796882029623, "Avg policy loss": 0.25732288777362555, "Total num played games": 28414, "Total num trained steps": 56192, "Timestamp in ms": 1701915858419, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 242.49669510871172, "Avg game time in secs": 2.214455718465615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.72, "agent_stopped_0": 0.4}, "Total num played games": 28416, "Total num trained steps": 56319, "Timestamp in ms": 1701915916202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808666291502532, "Avg loss": 0.3422643408412114, "Avg value loss": 0.09896043976186775, "Avg policy loss": 0.24330390093382448, "Total num played games": 28426, "Total num trained steps": 56320, "Timestamp in ms": 1701915916440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979936864258155, "Avg loss": 0.7616138188168406, "Avg value loss": 0.5041656962130219, "Avg policy loss": 0.25744812190532684, "Total num played games": 28510, "Total num trained steps": 56448, "Timestamp in ms": 1701915974287, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 88.1315470598638, "Avg game time in secs": 1.7520219947618898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.34}, "Total num played games": 28544, "Total num trained steps": 56512, "Timestamp in ms": 1701916004335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778702279401483, "Avg loss": 0.7492974838241935, "Avg value loss": 0.4914250929723494, "Avg policy loss": 0.2578723765909672, "Total num played games": 28604, "Total num trained steps": 56576, "Timestamp in ms": 1701916033099, "logtype": "training_step"}
{"Total num played games": 28604, "Total num trained steps": 56576, "Timestamp in ms": 1701916124689, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.12109375}
{"Avg objective": 22.328125, "Games time in secs": 123.13874734565616, "Avg game time in secs": 1.8077215251105372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 28672, "Total num trained steps": 56580, "Timestamp in ms": 1701916127474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975886821381281, "Avg loss": 0.8299288533162326, "Avg value loss": 0.5481515640276484, "Avg policy loss": 0.28177729411982, "Total num played games": 28698, "Total num trained steps": 56704, "Timestamp in ms": 1701916184210, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980347062513067, "Avg loss": 0.3795173855032772, "Avg value loss": 0.12330554838990793, "Avg policy loss": 0.25621183740440756, "Total num played games": 28698, "Total num trained steps": 56832, "Timestamp in ms": 1701916240023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783273131425396, "Avg loss": 0.9128442115616053, "Avg value loss": 0.6280348025611602, "Avg policy loss": 0.2848094046348706, "Total num played games": 28792, "Total num trained steps": 56960, "Timestamp in ms": 1701916296934, "logtype": "training_step"}
{"Avg objective": 22.40625, "Games time in secs": 223.53811786696315, "Avg game time in secs": 1.983257527142996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.55, "agent_stopped_0": 0.54}, "Total num played games": 28800, "Total num trained steps": 57075, "Timestamp in ms": 1701916351012, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764575543553524, "Avg loss": 0.5563737292541191, "Avg value loss": 0.28618742304388434, "Avg policy loss": 0.2701863010879606, "Total num played games": 28884, "Total num trained steps": 57088, "Timestamp in ms": 1701916356036, "logtype": "training_step"}
{"Total num played games": 28886, "Total num trained steps": 57179, "Timestamp in ms": 1701916458282, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.875}
{"Avg objective": 21.984375, "Games time in secs": 109.65562482923269, "Avg game time in secs": 1.8764035530621186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.43}, "Total num played games": 28928, "Total num trained steps": 57184, "Timestamp in ms": 1701916460668, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974327122153209, "Avg loss": 1.2494148404803127, "Avg value loss": 0.9447602268191986, "Avg policy loss": 0.30465462419670075, "Total num played games": 28980, "Total num trained steps": 57216, "Timestamp in ms": 1701916474507, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978743961352657, "Avg loss": 0.5276238471269608, "Avg value loss": 0.2359271175810136, "Avg policy loss": 0.29169672541320324, "Total num played games": 28980, "Total num trained steps": 57344, "Timestamp in ms": 1701916532242, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 120.72923835739493, "Avg game time in secs": 2.0252385583589785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 29056, "Total num trained steps": 57455, "Timestamp in ms": 1701916581397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767489853477334, "Avg loss": 0.6697821975685656, "Avg value loss": 0.39713310153456405, "Avg policy loss": 0.2726491040084511, "Total num played games": 29074, "Total num trained steps": 57472, "Timestamp in ms": 1701916589351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811515443351448, "Avg loss": 0.558377624489367, "Avg value loss": 0.28409954329254106, "Avg policy loss": 0.27427807718049735, "Total num played games": 29074, "Total num trained steps": 57600, "Timestamp in ms": 1701916647999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790195406239286, "Avg loss": 0.7013118176255375, "Avg value loss": 0.42014263686724007, "Avg policy loss": 0.2811691854149103, "Total num played games": 29170, "Total num trained steps": 57728, "Timestamp in ms": 1701916705819, "logtype": "training_step"}
{"Total num played games": 29170, "Total num trained steps": 57782, "Timestamp in ms": 1701916804283, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6640625}
{"Avg objective": 22.328125, "Games time in secs": 224.6882723160088, "Avg game time in secs": 1.9901745094684884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.46, "agent_stopped_0": 0.61}, "Total num played games": 29184, "Total num trained steps": 57783, "Timestamp in ms": 1701916806087, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9770366320393657, "Avg loss": 1.0047116235364228, "Avg value loss": 0.6982880968716927, "Avg policy loss": 0.30642353009898216, "Total num played games": 29264, "Total num trained steps": 57856, "Timestamp in ms": 1701916840298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814106068890105, "Avg loss": 0.4418445280753076, "Avg value loss": 0.14135484729195014, "Avg policy loss": 0.3004896811908111, "Total num played games": 29264, "Total num trained steps": 57984, "Timestamp in ms": 1701916895997, "logtype": "training_step"}
{"Avg objective": 21.9296875, "Games time in secs": 106.62420875951648, "Avg game time in secs": 1.886402889387682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 29312, "Total num trained steps": 58022, "Timestamp in ms": 1701916912711, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9794263914435588, "Avg loss": 0.7597535208333284, "Avg value loss": 0.45697918243240565, "Avg policy loss": 0.3027743357233703, "Total num played games": 29358, "Total num trained steps": 58112, "Timestamp in ms": 1701916953345, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 87.7348613590002, "Avg game time in secs": 2.0028239709499758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 29440, "Total num trained steps": 58212, "Timestamp in ms": 1701917000446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771863117870723, "Avg loss": 0.9044897358398885, "Avg value loss": 0.6116600985988043, "Avg policy loss": 0.29282963857986033, "Total num played games": 29456, "Total num trained steps": 58240, "Timestamp in ms": 1701917012673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815317762085822, "Avg loss": 0.5201582980807871, "Avg value loss": 0.2183779469341971, "Avg policy loss": 0.3017803516704589, "Total num played games": 29456, "Total num trained steps": 58368, "Timestamp in ms": 1701917067166, "logtype": "training_step"}
{"Total num played games": 29456, "Total num trained steps": 58382, "Timestamp in ms": 1701917152005, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.953125}
{"Ratio train steps to played games": 1.9795600676818952, "Avg loss": 1.1085945153608918, "Avg value loss": 0.7995350989513099, "Avg policy loss": 0.3090594308450818, "Total num played games": 29550, "Total num trained steps": 58496, "Timestamp in ms": 1701917203633, "logtype": "training_step"}
{"Avg objective": 23.0703125, "Games time in secs": 246.89920852705836, "Avg game time in secs": 1.9925082035770174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 29568, "Total num trained steps": 58592, "Timestamp in ms": 1701917247346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977600863581163, "Avg loss": 0.7223123218864202, "Avg value loss": 0.439858804049436, "Avg policy loss": 0.28245351859368384, "Total num played games": 29644, "Total num trained steps": 58624, "Timestamp in ms": 1701917262583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819187693968425, "Avg loss": 0.49590489570982754, "Avg value loss": 0.20308247703360394, "Avg policy loss": 0.29282242176122963, "Total num played games": 29644, "Total num trained steps": 58752, "Timestamp in ms": 1701917316344, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 82.48725482448936, "Avg game time in secs": 1.867159206274664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 29696, "Total num trained steps": 58783, "Timestamp in ms": 1701917329833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979958302508575, "Avg loss": 0.9002875108271837, "Avg value loss": 0.6060962577466853, "Avg policy loss": 0.29419125290587544, "Total num played games": 29738, "Total num trained steps": 58880, "Timestamp in ms": 1701917371131, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 81.58132018148899, "Avg game time in secs": 2.159619455342181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.61, "agent_stopped_0": 0.49}, "Total num played games": 29824, "Total num trained steps": 58973, "Timestamp in ms": 1701917411415, "logtype": "played_game"}
{"Total num played games": 29832, "Total num trained steps": 58985, "Timestamp in ms": 1701917509068, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.30859375}
{"Ratio train steps to played games": 1.97179709951213, "Avg loss": 0.9498605984263122, "Avg value loss": 0.6532004741020501, "Avg policy loss": 0.2966601315420121, "Total num played games": 29926, "Total num trained steps": 59008, "Timestamp in ms": 1701917519696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976074316647731, "Avg loss": 0.6780119983013719, "Avg value loss": 0.34887203841935843, "Avg policy loss": 0.32913996116258204, "Total num played games": 29926, "Total num trained steps": 59136, "Timestamp in ms": 1701917578393, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803515337833322, "Avg loss": 0.4177740414161235, "Avg value loss": 0.11797765421215445, "Avg policy loss": 0.299796387553215, "Total num played games": 29926, "Total num trained steps": 59264, "Timestamp in ms": 1701917633393, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 254.70706712454557, "Avg game time in secs": 1.967607224098174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.48, "agent_stopped_0": 0.62}, "Total num played games": 29952, "Total num trained steps": 59344, "Timestamp in ms": 1701917666122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9782492838585037, "Avg loss": 0.7059675008058548, "Avg value loss": 0.4187750112032518, "Avg policy loss": 0.28719249297864735, "Total num played games": 30022, "Total num trained steps": 59392, "Timestamp in ms": 1701917685596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825461328359204, "Avg loss": 0.43363766674883664, "Avg value loss": 0.14402457111282274, "Avg policy loss": 0.28961309243459255, "Total num played games": 30022, "Total num trained steps": 59520, "Timestamp in ms": 1701917741927, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 83.44362153857946, "Avg game time in secs": 1.7472794535569847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 30080, "Total num trained steps": 59537, "Timestamp in ms": 1701917749566, "logtype": "played_game"}
{"Total num played games": 30118, "Total num trained steps": 59588, "Timestamp in ms": 1701917875106, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.859375}
{"Avg objective": 22.265625, "Games time in secs": 130.95006186515093, "Avg game time in secs": 2.084225552272983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.52, "agent_stopped_0": 0.59}, "Total num played games": 30208, "Total num trained steps": 59600, "Timestamp in ms": 1701917880516, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9742817423540315, "Avg loss": 1.0616004599723965, "Avg value loss": 0.7636473806924187, "Avg policy loss": 0.29795307654421777, "Total num played games": 30212, "Total num trained steps": 59648, "Timestamp in ms": 1701917899673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785184694823248, "Avg loss": 0.45269345911219716, "Avg value loss": 0.1537808933062479, "Avg policy loss": 0.2989125665044412, "Total num played games": 30212, "Total num trained steps": 59776, "Timestamp in ms": 1701917956952, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827882960413081, "Avg loss": 0.3794491980224848, "Avg value loss": 0.10457422805484384, "Avg policy loss": 0.2748749702004716, "Total num played games": 30212, "Total num trained steps": 59904, "Timestamp in ms": 1701918015336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807311600897453, "Avg loss": 0.8764069955796003, "Avg value loss": 0.5699578682542779, "Avg policy loss": 0.30644912843126804, "Total num played games": 30308, "Total num trained steps": 60032, "Timestamp in ms": 1701918073090, "logtype": "training_step"}
{"Avg objective": 22.453125, "Games time in secs": 226.19069545343518, "Avg game time in secs": 2.0129161575168837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 30336, "Total num trained steps": 60109, "Timestamp in ms": 1701918106707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978687014866465, "Avg loss": 0.680253621423617, "Avg value loss": 0.391558084404096, "Avg policy loss": 0.2886955350404605, "Total num played games": 30404, "Total num trained steps": 60160, "Timestamp in ms": 1701918129061, "logtype": "training_step"}
{"Total num played games": 30404, "Total num trained steps": 60188, "Timestamp in ms": 1701918245339, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6171875}
{"Avg objective": 21.2734375, "Games time in secs": 141.35395180433989, "Avg game time in secs": 1.9939656041678973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 30464, "Total num trained steps": 60193, "Timestamp in ms": 1701918248061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767525739392746, "Avg loss": 0.865230007097125, "Avg value loss": 0.5530569432303309, "Avg policy loss": 0.3121730628190562, "Total num played games": 30498, "Total num trained steps": 60288, "Timestamp in ms": 1701918289933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809823594989835, "Avg loss": 0.40576121117919683, "Avg value loss": 0.11887432844378054, "Avg policy loss": 0.28688688669353724, "Total num played games": 30498, "Total num trained steps": 60416, "Timestamp in ms": 1701918344590, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 131.6164784580469, "Avg game time in secs": 2.1385036022693384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.63}, "Total num played games": 30592, "Total num trained steps": 60495, "Timestamp in ms": 1701918379677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789501209387461, "Avg loss": 0.806083066156134, "Avg value loss": 0.5192343958769925, "Avg policy loss": 0.28684866591356695, "Total num played games": 30594, "Total num trained steps": 60544, "Timestamp in ms": 1701918399943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831339478329084, "Avg loss": 0.4503005603328347, "Avg value loss": 0.1641814650502056, "Avg policy loss": 0.28611909702885896, "Total num played games": 30594, "Total num trained steps": 60672, "Timestamp in ms": 1701918454307, "logtype": "training_step"}
{"Total num played games": 30688, "Total num trained steps": 60791, "Timestamp in ms": 1701918617995, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.79296875}
{"Avg objective": 21.515625, "Games time in secs": 240.644256811589, "Avg game time in secs": 1.7540046963258646, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.39, "agent_stopped_0": 0.66}, "Total num played games": 30720, "Total num trained steps": 60794, "Timestamp in ms": 1701918620322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975950601234969, "Avg loss": 0.8030673118773848, "Avg value loss": 0.5079679462360218, "Avg policy loss": 0.29509937402326614, "Total num played games": 30768, "Total num trained steps": 60800, "Timestamp in ms": 1701918622434, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979338574491586, "Avg loss": 0.7620355859398842, "Avg value loss": 0.4573534493101761, "Avg policy loss": 0.3046821387251839, "Total num played games": 30782, "Total num trained steps": 60928, "Timestamp in ms": 1701918679059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828526890101326, "Avg loss": 0.3946438229177147, "Avg value loss": 0.10971822426654398, "Avg policy loss": 0.28492559562437236, "Total num played games": 30788, "Total num trained steps": 61056, "Timestamp in ms": 1701918734045, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 114.93325964733958, "Avg game time in secs": 2.0852251422184054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 30848, "Total num trained steps": 61059, "Timestamp in ms": 1701918735255, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816038346936131, "Avg loss": 0.8288292197976261, "Avg value loss": 0.5239630191936158, "Avg policy loss": 0.3048661999637261, "Total num played games": 30876, "Total num trained steps": 61184, "Timestamp in ms": 1701918791289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797223119147562, "Avg loss": 0.7154419885482639, "Avg value loss": 0.43160511075984687, "Avg policy loss": 0.2838368806988001, "Total num played games": 30970, "Total num trained steps": 61312, "Timestamp in ms": 1701918850156, "logtype": "training_step"}
{"Total num played games": 30970, "Total num trained steps": 61393, "Timestamp in ms": 1701918969080, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1796875}
{"Avg objective": 21.7109375, "Games time in secs": 235.3865296766162, "Avg game time in secs": 2.1898604920716025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.61, "agent_stopped_0": 0.5}, "Total num played games": 30976, "Total num trained steps": 61396, "Timestamp in ms": 1701918970642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778521761524595, "Avg loss": 0.9036090134177357, "Avg value loss": 0.6081703983945772, "Avg policy loss": 0.2954386109486222, "Total num played games": 31064, "Total num trained steps": 61440, "Timestamp in ms": 1701918989447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819405099150142, "Avg loss": 0.4348926283419132, "Avg value loss": 0.15226469154004008, "Avg policy loss": 0.2826279359869659, "Total num played games": 31064, "Total num trained steps": 61568, "Timestamp in ms": 1701919043097, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 94.78517887368798, "Avg game time in secs": 2.035548290325096, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 31104, "Total num trained steps": 61622, "Timestamp in ms": 1701919065427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801014185762886, "Avg loss": 0.7508692762348801, "Avg value loss": 0.4643531767069362, "Avg policy loss": 0.2865160872461274, "Total num played games": 31158, "Total num trained steps": 61696, "Timestamp in ms": 1701919099381, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 86.30509229749441, "Avg game time in secs": 2.0142975514172576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 31232, "Total num trained steps": 61811, "Timestamp in ms": 1701919151732, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781148013054328, "Avg loss": 0.5684353779070079, "Avg value loss": 0.2946859559742734, "Avg policy loss": 0.2737494327593595, "Total num played games": 31254, "Total num trained steps": 61824, "Timestamp in ms": 1701919157219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822102770845331, "Avg loss": 0.5797014308627695, "Avg value loss": 0.29895257693715394, "Avg policy loss": 0.2807488563703373, "Total num played games": 31254, "Total num trained steps": 61952, "Timestamp in ms": 1701919213743, "logtype": "training_step"}
{"Total num played games": 31254, "Total num trained steps": 61993, "Timestamp in ms": 1701919305907, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.94140625}
{"Ratio train steps to played games": 1.9803177236187317, "Avg loss": 0.7540182168595493, "Avg value loss": 0.4766332729777787, "Avg policy loss": 0.2773849457735196, "Total num played games": 31348, "Total num trained steps": 62080, "Timestamp in ms": 1701919344637, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 241.0451662875712, "Avg game time in secs": 1.935194436868187, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 31360, "Total num trained steps": 62187, "Timestamp in ms": 1701919392778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783742526396133, "Avg loss": 0.6761343150865287, "Avg value loss": 0.4046080603147857, "Avg policy loss": 0.2715262563433498, "Total num played games": 31444, "Total num trained steps": 62208, "Timestamp in ms": 1701919401221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824449815545095, "Avg loss": 0.5422493393998593, "Avg value loss": 0.2612964981235564, "Avg policy loss": 0.28095284022856504, "Total num played games": 31444, "Total num trained steps": 62336, "Timestamp in ms": 1701919458406, "logtype": "training_step"}
{"Avg objective": 21.9296875, "Games time in secs": 86.91804203763604, "Avg game time in secs": 1.7468615369871259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.39}, "Total num played games": 31488, "Total num trained steps": 62382, "Timestamp in ms": 1701919479696, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805948379732385, "Avg loss": 0.9929614493157715, "Avg value loss": 0.7007519730832428, "Avg policy loss": 0.29220948077272624, "Total num played games": 31538, "Total num trained steps": 62464, "Timestamp in ms": 1701919514220, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 83.30688282474875, "Avg game time in secs": 2.133251644030679, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 31616, "Total num trained steps": 62571, "Timestamp in ms": 1701919563003, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786305873427326, "Avg loss": 0.6753609464503825, "Avg value loss": 0.3919532368890941, "Avg policy loss": 0.28340770583599806, "Total num played games": 31634, "Total num trained steps": 62592, "Timestamp in ms": 1701919572207, "logtype": "training_step"}
{"Total num played games": 31634, "Total num trained steps": 62595, "Timestamp in ms": 1701919662427, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8359375}
{"Ratio train steps to played games": 1.9768028240040343, "Avg loss": 0.8496689253952354, "Avg value loss": 0.5393476539175026, "Avg policy loss": 0.31032127025537193, "Total num played games": 31728, "Total num trained steps": 62720, "Timestamp in ms": 1701919717968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808371154815936, "Avg loss": 0.39942838647402823, "Avg value loss": 0.1157892940682359, "Avg policy loss": 0.283639092114754, "Total num played games": 31728, "Total num trained steps": 62848, "Timestamp in ms": 1701919773176, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 255.67500191926956, "Avg game time in secs": 1.9598217789025512, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.47, "agent_stopped_0": 0.61}, "Total num played games": 31744, "Total num trained steps": 62948, "Timestamp in ms": 1701919818678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978976808497266, "Avg loss": 0.6985950386151671, "Avg value loss": 0.4294729402172379, "Avg policy loss": 0.26912210101727396, "Total num played games": 31822, "Total num trained steps": 62976, "Timestamp in ms": 1701919829529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830306077556408, "Avg loss": 0.5150439459830523, "Avg value loss": 0.23035065387375653, "Avg policy loss": 0.28469328791834414, "Total num played games": 31822, "Total num trained steps": 63104, "Timestamp in ms": 1701919884377, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 80.60276345536113, "Avg game time in secs": 1.9541503418877255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 31872, "Total num trained steps": 63137, "Timestamp in ms": 1701919899281, "logtype": "played_game"}
{"Total num played games": 31916, "Total num trained steps": 63195, "Timestamp in ms": 1701919992102, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.40625}
{"Avg objective": 21.1875, "Games time in secs": 96.17170856893063, "Avg game time in secs": 2.09845686974586, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 32000, "Total num trained steps": 63201, "Timestamp in ms": 1701919995452, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753826929084661, "Avg loss": 0.9347350215539336, "Avg value loss": 0.6390933994553052, "Avg policy loss": 0.2956416273955256, "Total num played games": 32010, "Total num trained steps": 63232, "Timestamp in ms": 1701920008464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793502030615433, "Avg loss": 0.47633962356485426, "Avg value loss": 0.1837231833487749, "Avg policy loss": 0.2926164388190955, "Total num played games": 32010, "Total num trained steps": 63360, "Timestamp in ms": 1701920064600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983380193689472, "Avg loss": 0.3660870234016329, "Avg value loss": 0.1007841182872653, "Avg policy loss": 0.2653029046487063, "Total num played games": 32010, "Total num trained steps": 63488, "Timestamp in ms": 1701920121545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981559930226763, "Avg loss": 0.7432833027560264, "Avg value loss": 0.4565587655524723, "Avg policy loss": 0.28672453900799155, "Total num played games": 32104, "Total num trained steps": 63616, "Timestamp in ms": 1701920178396, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 219.308931004256, "Avg game time in secs": 1.9163275251921732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.45, "agent_stopped_0": 0.6}, "Total num played games": 32128, "Total num trained steps": 63699, "Timestamp in ms": 1701920214761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979719237219703, "Avg loss": 0.799866964109242, "Avg value loss": 0.5128848683671094, "Avg policy loss": 0.2869820980122313, "Total num played games": 32198, "Total num trained steps": 63744, "Timestamp in ms": 1701920234201, "logtype": "training_step"}
{"Total num played games": 32198, "Total num trained steps": 63797, "Timestamp in ms": 1701920342357, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.30859375}
{"Avg objective": 22.1953125, "Games time in secs": 130.15406170114875, "Avg game time in secs": 1.8788621945423074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 32256, "Total num trained steps": 63801, "Timestamp in ms": 1701920344916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779511953424997, "Avg loss": 1.034437915077433, "Avg value loss": 0.7240136205218732, "Avg policy loss": 0.31042430514935404, "Total num played games": 32292, "Total num trained steps": 63872, "Timestamp in ms": 1701920377942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819150253932862, "Avg loss": 0.4395161154679954, "Avg value loss": 0.1588866602978669, "Avg policy loss": 0.28062945685815066, "Total num played games": 32292, "Total num trained steps": 64000, "Timestamp in ms": 1701920434596, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 123.54049649089575, "Avg game time in secs": 2.0687953760207165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 32384, "Total num trained steps": 64082, "Timestamp in ms": 1701920468458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801148644476008, "Avg loss": 0.5895593431778252, "Avg value loss": 0.31773206166690215, "Avg policy loss": 0.2718272872734815, "Total num played games": 32386, "Total num trained steps": 64128, "Timestamp in ms": 1701920486383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840671895263386, "Avg loss": 0.3975392454303801, "Avg value loss": 0.1282178083783947, "Avg policy loss": 0.269321437808685, "Total num played games": 32386, "Total num trained steps": 64256, "Timestamp in ms": 1701920541355, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821439566529155, "Avg loss": 0.6541688127908856, "Avg value loss": 0.3620755243464373, "Avg policy loss": 0.29209329723380506, "Total num played games": 32482, "Total num trained steps": 64384, "Timestamp in ms": 1701920598630, "logtype": "training_step"}
{"Total num played games": 32482, "Total num trained steps": 64398, "Timestamp in ms": 1701920721441, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.55078125}
{"Avg objective": 20.84375, "Games time in secs": 254.94432712718844, "Avg game time in secs": 1.7887547552527394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.38, "agent_stopped_0": 0.7}, "Total num played games": 32512, "Total num trained steps": 64401, "Timestamp in ms": 1701920723402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803536345776032, "Avg loss": 0.8361329035833478, "Avg value loss": 0.5455793407163583, "Avg policy loss": 0.2905535636236891, "Total num played games": 32576, "Total num trained steps": 64512, "Timestamp in ms": 1701920773843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98425221021611, "Avg loss": 0.371091732988134, "Avg value loss": 0.10806326533202082, "Avg policy loss": 0.26302846474573016, "Total num played games": 32576, "Total num trained steps": 64640, "Timestamp in ms": 1701920830356, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 109.50165081769228, "Avg game time in secs": 2.002460600953782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 32640, "Total num trained steps": 64647, "Timestamp in ms": 1701920832904, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824915824915825, "Avg loss": 0.6627258723601699, "Avg value loss": 0.38483542494941503, "Avg policy loss": 0.2778904448496178, "Total num played games": 32670, "Total num trained steps": 64768, "Timestamp in ms": 1701920885434, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980710535954096, "Avg loss": 0.6559762414544821, "Avg value loss": 0.38417855475563556, "Avg policy loss": 0.27179768471978605, "Total num played games": 32764, "Total num trained steps": 64896, "Timestamp in ms": 1701920941357, "logtype": "training_step"}
{"Total num played games": 32764, "Total num trained steps": 64998, "Timestamp in ms": 1701921054479, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8671875}
{"Avg objective": 21.2578125, "Games time in secs": 222.92337559908628, "Avg game time in secs": 2.073952191072749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 32768, "Total num trained steps": 65000, "Timestamp in ms": 1701921055827, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789396798344392, "Avg loss": 0.5927289326209575, "Avg value loss": 0.32651692093349993, "Avg policy loss": 0.2662120130844414, "Total num played games": 32858, "Total num trained steps": 65024, "Timestamp in ms": 1701921066351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828047963966158, "Avg loss": 0.486717440886423, "Avg value loss": 0.21216909401118755, "Avg policy loss": 0.2745483433827758, "Total num played games": 32858, "Total num trained steps": 65152, "Timestamp in ms": 1701921119580, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 87.65541206672788, "Avg game time in secs": 1.755415891035227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.44}, "Total num played games": 32896, "Total num trained steps": 65210, "Timestamp in ms": 1701921143483, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810633648943918, "Avg loss": 0.6514925034716725, "Avg value loss": 0.3764981879503466, "Avg policy loss": 0.27499431383330375, "Total num played games": 32952, "Total num trained steps": 65280, "Timestamp in ms": 1701921173475, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 80.12889066711068, "Avg game time in secs": 2.1194663601054344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 33024, "Total num trained steps": 65400, "Timestamp in ms": 1701921223612, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793015796162925, "Avg loss": 0.5123657200019807, "Avg value loss": 0.25338101820671, "Avg policy loss": 0.2589847114868462, "Total num played games": 33046, "Total num trained steps": 65408, "Timestamp in ms": 1701921226668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983174968226109, "Avg loss": 0.6901017187628895, "Avg value loss": 0.4015667231869884, "Avg policy loss": 0.2885349924908951, "Total num played games": 33046, "Total num trained steps": 65536, "Timestamp in ms": 1701921282392, "logtype": "training_step"}
{"Total num played games": 33140, "Total num trained steps": 65599, "Timestamp in ms": 1701921368063, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.015625}
{"Avg objective": 21.984375, "Games time in secs": 146.1857003197074, "Avg game time in secs": 2.092636134388158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 33152, "Total num trained steps": 65601, "Timestamp in ms": 1701921369798, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758079075645423, "Avg loss": 1.256330115487799, "Avg value loss": 0.9530673020635732, "Avg policy loss": 0.3032628009095788, "Total num played games": 33234, "Total num trained steps": 65664, "Timestamp in ms": 1701921397552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796593849672022, "Avg loss": 0.44417456816881895, "Avg value loss": 0.15574553329497576, "Avg policy loss": 0.2884290326619521, "Total num played games": 33234, "Total num trained steps": 65792, "Timestamp in ms": 1701921451287, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983480772702654, "Avg loss": 0.3616883580107242, "Avg value loss": 0.10358267102856189, "Avg policy loss": 0.2581056880299002, "Total num played games": 33234, "Total num trained steps": 65920, "Timestamp in ms": 1701921509453, "logtype": "training_step"}
{"Avg objective": 22.6171875, "Games time in secs": 157.61944824829698, "Avg game time in secs": 1.8866168244567234, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 33280, "Total num trained steps": 65962, "Timestamp in ms": 1701921527417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9817570811329812, "Avg loss": 0.9217182602733374, "Avg value loss": 0.6349983862601221, "Avg policy loss": 0.28671987052075565, "Total num played games": 33328, "Total num trained steps": 66048, "Timestamp in ms": 1701921561626, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 79.84842345118523, "Avg game time in secs": 2.1084886436292436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 33408, "Total num trained steps": 66154, "Timestamp in ms": 1701921607266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98001316498115, "Avg loss": 0.6767588125076145, "Avg value loss": 0.4031371633755043, "Avg policy loss": 0.2736216454068199, "Total num played games": 33422, "Total num trained steps": 66176, "Timestamp in ms": 1701921616552, "logtype": "training_step"}
{"Total num played games": 33422, "Total num trained steps": 66203, "Timestamp in ms": 1701921731728, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.875}
{"Ratio train steps to played games": 1.9782790309106097, "Avg loss": 0.8506148082669824, "Avg value loss": 0.5333618390723132, "Avg policy loss": 0.3172529727453366, "Total num played games": 33516, "Total num trained steps": 66304, "Timestamp in ms": 1701921776976, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820981023988542, "Avg loss": 0.38396874046884477, "Avg value loss": 0.10331237915670499, "Avg policy loss": 0.2806563628837466, "Total num played games": 33516, "Total num trained steps": 66432, "Timestamp in ms": 1701921833926, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 267.62565053626895, "Avg game time in secs": 2.029305753763765, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 33536, "Total num trained steps": 66523, "Timestamp in ms": 1701921874892, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803629872061885, "Avg loss": 0.8110212662722915, "Avg value loss": 0.5342782773077488, "Avg policy loss": 0.2767429747618735, "Total num played games": 33610, "Total num trained steps": 66560, "Timestamp in ms": 1701921890742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841416245165129, "Avg loss": 0.4569024962838739, "Avg value loss": 0.17604993615532294, "Avg policy loss": 0.28085255855694413, "Total num played games": 33610, "Total num trained steps": 66688, "Timestamp in ms": 1701921947360, "logtype": "training_step"}
{"Avg objective": 23.328125, "Games time in secs": 83.14923912659287, "Avg game time in secs": 1.6333597628981806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 33664, "Total num trained steps": 66713, "Timestamp in ms": 1701921958041, "logtype": "played_game"}
{"Total num played games": 33704, "Total num trained steps": 66806, "Timestamp in ms": 1701922078317, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1640625}
{"Avg objective": 22.5390625, "Games time in secs": 124.2322626747191, "Avg game time in secs": 2.0356463029165752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.57}, "Total num played games": 33792, "Total num trained steps": 66813, "Timestamp in ms": 1701922082273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771557081138664, "Avg loss": 1.068870564457029, "Avg value loss": 0.765053786104545, "Avg policy loss": 0.30381677602417767, "Total num played games": 33794, "Total num trained steps": 66816, "Timestamp in ms": 1701922083531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980679330137878, "Avg loss": 0.623258312465623, "Avg value loss": 0.3176599827129394, "Avg policy loss": 0.30559833196457475, "Total num played games": 33798, "Total num trained steps": 66944, "Timestamp in ms": 1701922137796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.3699334050761536, "Avg value loss": 0.09067870493163355, "Avg policy loss": 0.2792547019198537, "Total num played games": 33798, "Total num trained steps": 67072, "Timestamp in ms": 1701922193632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827687949958692, "Avg loss": 0.6683732443489134, "Avg value loss": 0.374500124307815, "Avg policy loss": 0.2938731167232618, "Total num played games": 33892, "Total num trained steps": 67200, "Timestamp in ms": 1701922249089, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 199.998012047261, "Avg game time in secs": 1.906174757052213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.46, "agent_stopped_0": 0.62}, "Total num played games": 33920, "Total num trained steps": 67276, "Timestamp in ms": 1701922282272, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810510210086507, "Avg loss": 0.5827801099512726, "Avg value loss": 0.2932408024207689, "Avg policy loss": 0.2895393040962517, "Total num played games": 33986, "Total num trained steps": 67328, "Timestamp in ms": 1701922304789, "logtype": "training_step"}
{"Total num played games": 33986, "Total num trained steps": 67410, "Timestamp in ms": 1701922445487, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.765625}
{"Avg objective": 21.078125, "Games time in secs": 165.98249209672213, "Avg game time in secs": 1.8876365673204418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 34048, "Total num trained steps": 67416, "Timestamp in ms": 1701922448254, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793133802816902, "Avg loss": 0.9244278101250529, "Avg value loss": 0.6271015653619543, "Avg policy loss": 0.29732624848838896, "Total num played games": 34080, "Total num trained steps": 67456, "Timestamp in ms": 1701922466153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983069248826291, "Avg loss": 0.48455727472901344, "Avg value loss": 0.18296668393304572, "Avg policy loss": 0.30159059073776007, "Total num played games": 34080, "Total num trained steps": 67584, "Timestamp in ms": 1701922525723, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813600983203605, "Avg loss": 0.7564707749988884, "Avg value loss": 0.4575184627319686, "Avg policy loss": 0.2989523175638169, "Total num played games": 34174, "Total num trained steps": 67712, "Timestamp in ms": 1701922583309, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 187.9551216289401, "Avg game time in secs": 2.2863759264873806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 34176, "Total num trained steps": 67838, "Timestamp in ms": 1701922636209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847864248098304, "Avg loss": 0.4186357827857137, "Avg value loss": 0.1250585974776186, "Avg policy loss": 0.29357718932442367, "Total num played games": 34180, "Total num trained steps": 67840, "Timestamp in ms": 1701922636665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983424769464223, "Avg loss": 0.8121295445598662, "Avg value loss": 0.5001444338704459, "Avg policy loss": 0.31198511086404324, "Total num played games": 34268, "Total num trained steps": 67968, "Timestamp in ms": 1701922695077, "logtype": "training_step"}
{"Total num played games": 34268, "Total num trained steps": 68011, "Timestamp in ms": 1701922779200, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.90625}
{"Avg objective": 22.46875, "Games time in secs": 145.12403496727347, "Avg game time in secs": 1.9025825934950262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.46}, "Total num played games": 34304, "Total num trained steps": 68015, "Timestamp in ms": 1701922781334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816948955241256, "Avg loss": 0.7619964182376862, "Avg value loss": 0.4428526127594523, "Avg policy loss": 0.3191438023932278, "Total num played games": 34362, "Total num trained steps": 68096, "Timestamp in ms": 1701922817879, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 92.71600162610412, "Avg game time in secs": 2.020628680707887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 34432, "Total num trained steps": 68219, "Timestamp in ms": 1701922874050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801474429674348, "Avg loss": 0.5092221039813012, "Avg value loss": 0.2130910906707868, "Avg policy loss": 0.29613101889844984, "Total num played games": 34454, "Total num trained steps": 68224, "Timestamp in ms": 1701922876511, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837183654515904, "Avg loss": 0.7427158372011036, "Avg value loss": 0.42990901751909405, "Avg policy loss": 0.31280682678334415, "Total num played games": 34456, "Total num trained steps": 68352, "Timestamp in ms": 1701922931149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818255484169705, "Avg loss": 0.851919749751687, "Avg value loss": 0.5406003147654701, "Avg policy loss": 0.311319419182837, "Total num played games": 34554, "Total num trained steps": 68480, "Timestamp in ms": 1701922985580, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 165.35349965840578, "Avg game time in secs": 1.9464925519714598, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 34560, "Total num trained steps": 68599, "Timestamp in ms": 1701923039403, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801431540060033, "Avg loss": 0.48348622024059296, "Avg value loss": 0.1828440758981742, "Avg policy loss": 0.3006421427708119, "Total num played games": 34648, "Total num trained steps": 68608, "Timestamp in ms": 1701923043197, "logtype": "training_step"}
{"Total num played games": 34648, "Total num trained steps": 68614, "Timestamp in ms": 1701923111371, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.55859375}
{"Avg objective": 22.0546875, "Games time in secs": 74.35188606008887, "Avg game time in secs": 1.762913201120682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 34688, "Total num trained steps": 68619, "Timestamp in ms": 1701923113755, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9784410799608543, "Avg loss": 0.9233771068975329, "Avg value loss": 0.589610668073874, "Avg policy loss": 0.3337664391146973, "Total num played games": 34742, "Total num trained steps": 68736, "Timestamp in ms": 1701923167206, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982154164987623, "Avg loss": 0.4092821173835546, "Avg value loss": 0.11469724558992311, "Avg policy loss": 0.2945848738308996, "Total num played games": 34742, "Total num trained steps": 68864, "Timestamp in ms": 1701923222940, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 159.16185304149985, "Avg game time in secs": 1.8739532608014997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 34816, "Total num trained steps": 68980, "Timestamp in ms": 1701923272917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980223880597015, "Avg loss": 0.7572188831400126, "Avg value loss": 0.4718931448587682, "Avg policy loss": 0.28532572428230196, "Total num played games": 34840, "Total num trained steps": 68992, "Timestamp in ms": 1701923278857, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839265212399542, "Avg loss": 0.6902261502109468, "Avg value loss": 0.38180051487870514, "Avg policy loss": 0.3084256425499916, "Total num played games": 34840, "Total num trained steps": 69120, "Timestamp in ms": 1701923333198, "logtype": "training_step"}
{"Total num played games": 34936, "Total num trained steps": 69216, "Timestamp in ms": 1701923450257, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9765625}
{"Avg objective": 22.6640625, "Games time in secs": 179.11426236853004, "Avg game time in secs": 1.9426172392850276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.56, "agent_stopped_0": 0.53}, "Total num played games": 34944, "Total num trained steps": 69218, "Timestamp in ms": 1701923452034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976819868683985, "Avg loss": 1.0329649900086224, "Avg value loss": 0.7282616317970678, "Avg policy loss": 0.3047033512266353, "Total num played games": 35030, "Total num trained steps": 69248, "Timestamp in ms": 1701923464849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980445332572081, "Avg loss": 0.5131994273979217, "Avg value loss": 0.20551935851108283, "Avg policy loss": 0.3076800676062703, "Total num played games": 35030, "Total num trained steps": 69376, "Timestamp in ms": 1701923519923, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841278903796746, "Avg loss": 0.3808990395627916, "Avg value loss": 0.10387112625176087, "Avg policy loss": 0.27702791430056095, "Total num played games": 35030, "Total num trained steps": 69504, "Timestamp in ms": 1701923575196, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 145.17569606378675, "Avg game time in secs": 1.925587888195878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 35072, "Total num trained steps": 69553, "Timestamp in ms": 1701923597208, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824621341532855, "Avg loss": 0.6395335335982963, "Avg value loss": 0.35490914538968354, "Avg policy loss": 0.28462437773123384, "Total num played games": 35124, "Total num trained steps": 69632, "Timestamp in ms": 1701923632547, "logtype": "training_step"}
{"Avg objective": 22.2578125, "Games time in secs": 84.74525438249111, "Avg game time in secs": 1.9204960411298089, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 35200, "Total num trained steps": 69743, "Timestamp in ms": 1701923681953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808052700323697, "Avg loss": 0.567921687150374, "Avg value loss": 0.28728149557719007, "Avg policy loss": 0.28064019442535937, "Total num played games": 35218, "Total num trained steps": 69760, "Timestamp in ms": 1701923689915, "logtype": "training_step"}
{"Total num played games": 35218, "Total num trained steps": 69820, "Timestamp in ms": 1701923795182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.71875}
{"Ratio train steps to played games": 1.9791572270049842, "Avg loss": 0.937441895250231, "Avg value loss": 0.6250705189304426, "Avg policy loss": 0.3123713684035465, "Total num played games": 35312, "Total num trained steps": 69888, "Timestamp in ms": 1701923827115, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982782057091074, "Avg loss": 0.4220740254968405, "Avg value loss": 0.12807459809118882, "Avg policy loss": 0.2939994253683835, "Total num played games": 35312, "Total num trained steps": 70016, "Timestamp in ms": 1701923884735, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 245.88793244585395, "Avg game time in secs": 2.0751358866109513, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.54, "agent_stopped_0": 0.56}, "Total num played games": 35328, "Total num trained steps": 70116, "Timestamp in ms": 1701923927841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98113314127549, "Avg loss": 0.624310540384613, "Avg value loss": 0.34636696364032105, "Avg policy loss": 0.27794357866514474, "Total num played games": 35406, "Total num trained steps": 70144, "Timestamp in ms": 1701923939522, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847201039371858, "Avg loss": 0.4719908586703241, "Avg value loss": 0.1860388249042444, "Avg policy loss": 0.2859520361525938, "Total num played games": 35406, "Total num trained steps": 70272, "Timestamp in ms": 1701923998961, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 87.44673310220242, "Avg game time in secs": 1.8946419197891373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 35456, "Total num trained steps": 70306, "Timestamp in ms": 1701924015288, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830704225352114, "Avg loss": 0.7303670132532716, "Avg value loss": 0.4336631210753694, "Avg policy loss": 0.2967038970673457, "Total num played games": 35500, "Total num trained steps": 70400, "Timestamp in ms": 1701924055417, "logtype": "training_step"}
{"Total num played games": 35500, "Total num trained steps": 70420, "Timestamp in ms": 1701924150700, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0546875}
{"Avg objective": 21.890625, "Games time in secs": 138.96169601380825, "Avg game time in secs": 2.0441150762781035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 35584, "Total num trained steps": 70428, "Timestamp in ms": 1701924154250, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814575490251165, "Avg loss": 0.8748116111382842, "Avg value loss": 0.569517346273642, "Avg policy loss": 0.3052942688809708, "Total num played games": 35594, "Total num trained steps": 70528, "Timestamp in ms": 1701924200880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850536607293363, "Avg loss": 0.3901664244476706, "Avg value loss": 0.1038654672447592, "Avg policy loss": 0.28630095766857266, "Total num played games": 35594, "Total num trained steps": 70656, "Timestamp in ms": 1701924257432, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983300644438218, "Avg loss": 0.6143755088560283, "Avg value loss": 0.33206299686571583, "Avg policy loss": 0.2823125129798427, "Total num played games": 35690, "Total num trained steps": 70784, "Timestamp in ms": 1701924313743, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 197.29868285357952, "Avg game time in secs": 1.8989858859276865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 35712, "Total num trained steps": 70872, "Timestamp in ms": 1701924351548, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981667784484686, "Avg loss": 0.6458623551297933, "Avg value loss": 0.3660422919492703, "Avg policy loss": 0.2798200638499111, "Total num played games": 35784, "Total num trained steps": 70912, "Timestamp in ms": 1701924369070, "logtype": "training_step"}
{"Total num played games": 35784, "Total num trained steps": 71023, "Timestamp in ms": 1701924508713, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.73828125}
{"Avg objective": 22.765625, "Games time in secs": 159.6323770917952, "Avg game time in secs": 1.8243465293489862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.5}, "Total num played games": 35840, "Total num trained steps": 71027, "Timestamp in ms": 1701924511181, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800434806845422, "Avg loss": 0.6108704151120037, "Avg value loss": 0.33191339863697067, "Avg policy loss": 0.278957013390027, "Total num played games": 35878, "Total num trained steps": 71040, "Timestamp in ms": 1701924516719, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836111265956853, "Avg loss": 0.7170824101194739, "Avg value loss": 0.42384172324091196, "Avg policy loss": 0.293240686529316, "Total num played games": 35878, "Total num trained steps": 71168, "Timestamp in ms": 1701924573453, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 99.66423720866442, "Avg game time in secs": 2.0293511742493138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 35968, "Total num trained steps": 71254, "Timestamp in ms": 1701924610845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819859891026355, "Avg loss": 0.7024630582891405, "Avg value loss": 0.43705168151063845, "Avg policy loss": 0.2654113711323589, "Total num played games": 35972, "Total num trained steps": 71296, "Timestamp in ms": 1701924630240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855443122428555, "Avg loss": 0.4037265775259584, "Avg value loss": 0.1411741284537129, "Avg policy loss": 0.2625524481991306, "Total num played games": 35972, "Total num trained steps": 71424, "Timestamp in ms": 1701924688030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838906449287417, "Avg loss": 0.6447361083701253, "Avg value loss": 0.36226094915764406, "Avg policy loss": 0.2824751652078703, "Total num played games": 36066, "Total num trained steps": 71552, "Timestamp in ms": 1701924745305, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 166.4019422084093, "Avg game time in secs": 1.7448426617193036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 36096, "Total num trained steps": 71625, "Timestamp in ms": 1701924777247, "logtype": "played_game"}
{"Total num played games": 36162, "Total num trained steps": 71625, "Timestamp in ms": 1701924911830, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7734375}
{"Avg objective": 21.2109375, "Games time in secs": 137.38989378884435, "Avg game time in secs": 1.9109912083367817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 36224, "Total num trained steps": 71631, "Timestamp in ms": 1701924914637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9770520741394528, "Avg loss": 0.9530718479072675, "Avg value loss": 0.6635953512159176, "Avg policy loss": 0.2894765060627833, "Total num played games": 36256, "Total num trained steps": 71680, "Timestamp in ms": 1701924937686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9805825242718447, "Avg loss": 0.42585917096585035, "Avg value loss": 0.1489746852312237, "Avg policy loss": 0.276884485851042, "Total num played games": 36256, "Total num trained steps": 71808, "Timestamp in ms": 1701924995891, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840853927625772, "Avg loss": 0.3478086160030216, "Avg value loss": 0.08980067452648655, "Avg policy loss": 0.258007942000404, "Total num played games": 36256, "Total num trained steps": 71936, "Timestamp in ms": 1701925051803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825034387895462, "Avg loss": 0.663386641535908, "Avg value loss": 0.3907921443460509, "Avg policy loss": 0.2725944941630587, "Total num played games": 36350, "Total num trained steps": 72064, "Timestamp in ms": 1701925107077, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 249.42816963419318, "Avg game time in secs": 2.1239126393629704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.61, "agent_stopped_0": 0.46}, "Total num played games": 36352, "Total num trained steps": 72190, "Timestamp in ms": 1701925164066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859154929577465, "Avg loss": 0.38341496186330914, "Avg value loss": 0.11623959237476811, "Avg policy loss": 0.26717536814976484, "Total num played games": 36352, "Total num trained steps": 72192, "Timestamp in ms": 1701925164551, "logtype": "training_step"}
{"Total num played games": 36450, "Total num trained steps": 72228, "Timestamp in ms": 1701925281829, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.58984375}
{"Avg objective": 20.84375, "Games time in secs": 119.77491404116154, "Avg game time in secs": 1.9363600284268614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 36480, "Total num trained steps": 72231, "Timestamp in ms": 1701925283841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978984238178634, "Avg loss": 1.2012415502686054, "Avg value loss": 0.8860785596771166, "Avg policy loss": 0.3151629943167791, "Total num played games": 36544, "Total num trained steps": 72320, "Timestamp in ms": 1701925323063, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824595008756567, "Avg loss": 0.40455875149928033, "Avg value loss": 0.12786340212915093, "Avg policy loss": 0.27669534948654473, "Total num played games": 36544, "Total num trained steps": 72448, "Timestamp in ms": 1701925376448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859621278458843, "Avg loss": 0.3540411542635411, "Avg value loss": 0.09604890845366754, "Avg policy loss": 0.2579922475852072, "Total num played games": 36544, "Total num trained steps": 72576, "Timestamp in ms": 1701925430157, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 149.02420300990343, "Avg game time in secs": 2.0102684907615185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.61}, "Total num played games": 36608, "Total num trained steps": 72583, "Timestamp in ms": 1701925432865, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842521834061135, "Avg loss": 0.746020290767774, "Avg value loss": 0.4580740889068693, "Avg policy loss": 0.2879461969714612, "Total num played games": 36640, "Total num trained steps": 72704, "Timestamp in ms": 1701925485103, "logtype": "training_step"}
{"Total num played games": 36734, "Total num trained steps": 72829, "Timestamp in ms": 1701925623657, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1640625}
{"Avg objective": 21.546875, "Games time in secs": 191.5728439129889, "Avg game time in secs": 2.250872438075021, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.68}, "Total num played games": 36736, "Total num trained steps": 72829, "Timestamp in ms": 1701925624438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981068436513981, "Avg loss": 1.089122181525454, "Avg value loss": 0.8048305418051314, "Avg policy loss": 0.2842916289810091, "Total num played games": 36764, "Total num trained steps": 72832, "Timestamp in ms": 1701925625754, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811013359400456, "Avg loss": 0.8910301455762237, "Avg value loss": 0.5757509605027735, "Avg policy loss": 0.31527918961364776, "Total num played games": 36828, "Total num trained steps": 72960, "Timestamp in ms": 1701925682843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845769523188879, "Avg loss": 0.36988652031868696, "Avg value loss": 0.09794899463304318, "Avg policy loss": 0.27193752548191696, "Total num played games": 36828, "Total num trained steps": 73088, "Timestamp in ms": 1701925740436, "logtype": "training_step"}
{"Avg objective": 23.0859375, "Games time in secs": 143.65371887385845, "Avg game time in secs": 2.009392715874128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 36864, "Total num trained steps": 73149, "Timestamp in ms": 1701925768092, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829911705758085, "Avg loss": 0.7962026312015951, "Avg value loss": 0.5111012918059714, "Avg policy loss": 0.2851013495819643, "Total num played games": 36922, "Total num trained steps": 73216, "Timestamp in ms": 1701925798245, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 83.797347728163, "Avg game time in secs": 2.021306790615199, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.61}, "Total num played games": 36992, "Total num trained steps": 73339, "Timestamp in ms": 1701925851889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814134428355306, "Avg loss": 0.47459486685693264, "Avg value loss": 0.1970877746352926, "Avg policy loss": 0.2775070919888094, "Total num played games": 37016, "Total num trained steps": 73344, "Timestamp in ms": 1701925853650, "logtype": "training_step"}
{"Total num played games": 37018, "Total num trained steps": 73432, "Timestamp in ms": 1701925960669, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.51171875}
{"Ratio train steps to played games": 1.979737012287131, "Avg loss": 0.8900703000836074, "Avg value loss": 0.5952831662143581, "Avg policy loss": 0.29478713404387236, "Total num played games": 37112, "Total num trained steps": 73472, "Timestamp in ms": 1701925978090, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983159086009916, "Avg loss": 0.4306755415163934, "Avg value loss": 0.14504752383800223, "Avg policy loss": 0.28562801622319967, "Total num played games": 37112, "Total num trained steps": 73600, "Timestamp in ms": 1701926033269, "logtype": "training_step"}
{"Avg objective": 22.5234375, "Games time in secs": 232.7309570275247, "Avg game time in secs": 1.901886714185821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 37120, "Total num trained steps": 73716, "Timestamp in ms": 1701926084620, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981482476886691, "Avg loss": 0.554399904794991, "Avg value loss": 0.285420001426246, "Avg policy loss": 0.268979893415235, "Total num played games": 37208, "Total num trained steps": 73728, "Timestamp in ms": 1701926089458, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849494732315631, "Avg loss": 0.7501611763145775, "Avg value loss": 0.45333991444204, "Avg policy loss": 0.29682126361876726, "Total num played games": 37208, "Total num trained steps": 73856, "Timestamp in ms": 1701926143127, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 80.36724952608347, "Avg game time in secs": 1.8816146919270977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 37248, "Total num trained steps": 73909, "Timestamp in ms": 1701926164988, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983378907297196, "Avg loss": 0.6674566564615816, "Avg value loss": 0.3832013499340974, "Avg policy loss": 0.28425529866945, "Total num played games": 37302, "Total num trained steps": 73984, "Timestamp in ms": 1701926198688, "logtype": "training_step"}
{"Total num played games": 37302, "Total num trained steps": 74032, "Timestamp in ms": 1701926315017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.921875}
{"Avg objective": 21.71875, "Games time in secs": 153.29469203576446, "Avg game time in secs": 2.1821800369070843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 37376, "Total num trained steps": 74037, "Timestamp in ms": 1701926318283, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9817894962028024, "Avg loss": 1.0326276596169919, "Avg value loss": 0.7339582295971923, "Avg policy loss": 0.29866942134685814, "Total num played games": 37396, "Total num trained steps": 74112, "Timestamp in ms": 1701926351383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852123221734945, "Avg loss": 0.4089258343447, "Avg value loss": 0.13013511709868908, "Avg policy loss": 0.27879071701318026, "Total num played games": 37396, "Total num trained steps": 74240, "Timestamp in ms": 1701926404294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835698282300225, "Avg loss": 0.823152853641659, "Avg value loss": 0.5391403235844336, "Avg policy loss": 0.2840125351212919, "Total num played games": 37492, "Total num trained steps": 74368, "Timestamp in ms": 1701926459005, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 187.77598616853356, "Avg game time in secs": 2.136468696058728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.58, "agent_stopped_0": 0.53}, "Total num played games": 37504, "Total num trained steps": 74476, "Timestamp in ms": 1701926506059, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98201457989677, "Avg loss": 0.6957523634191602, "Avg value loss": 0.4123560706502758, "Avg policy loss": 0.283396287006326, "Total num played games": 37586, "Total num trained steps": 74496, "Timestamp in ms": 1701926514921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854201032299261, "Avg loss": 0.6417271429672837, "Avg value loss": 0.3506774955894798, "Avg policy loss": 0.2910496382974088, "Total num played games": 37586, "Total num trained steps": 74624, "Timestamp in ms": 1701926570151, "logtype": "training_step"}
{"Total num played games": 37586, "Total num trained steps": 74636, "Timestamp in ms": 1701926642109, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.40625}
{"Avg objective": 22.390625, "Games time in secs": 138.41203482449055, "Avg game time in secs": 1.708724581199931, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 37632, "Total num trained steps": 74641, "Timestamp in ms": 1701926644471, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983864118895966, "Avg loss": 0.8618611504789442, "Avg value loss": 0.5537715084501542, "Avg policy loss": 0.3080896356841549, "Total num played games": 37680, "Total num trained steps": 74752, "Timestamp in ms": 1701926694235, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 93.96226620674133, "Avg game time in secs": 1.8187782233871985, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 37760, "Total num trained steps": 74854, "Timestamp in ms": 1701926738433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822109275730622, "Avg loss": 0.5940722220111638, "Avg value loss": 0.31271849723998457, "Avg policy loss": 0.2813537218607962, "Total num played games": 37776, "Total num trained steps": 74880, "Timestamp in ms": 1701926749283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855993223210504, "Avg loss": 0.4232188034802675, "Avg value loss": 0.13289063289994374, "Avg policy loss": 0.2903281659819186, "Total num played games": 37776, "Total num trained steps": 75008, "Timestamp in ms": 1701926807784, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840506997623448, "Avg loss": 0.7491929731331766, "Avg value loss": 0.4561501166317612, "Avg policy loss": 0.29304285626858473, "Total num played games": 37870, "Total num trained steps": 75136, "Timestamp in ms": 1701926868118, "logtype": "training_step"}
{"Avg objective": 20.109375, "Games time in secs": 173.90674138069153, "Avg game time in secs": 1.9367208778858185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 37888, "Total num trained steps": 75232, "Timestamp in ms": 1701926912340, "logtype": "played_game"}
{"Total num played games": 37964, "Total num trained steps": 75235, "Timestamp in ms": 1701927001362, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.89453125}
{"Avg objective": 22.1796875, "Games time in secs": 91.32088826596737, "Avg game time in secs": 1.7423361192632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 38016, "Total num trained steps": 75239, "Timestamp in ms": 1701927003661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775868411372117, "Avg loss": 1.0638624241109937, "Avg value loss": 0.7718079484766349, "Avg policy loss": 0.29205446713604033, "Total num played games": 38058, "Total num trained steps": 75264, "Timestamp in ms": 1701927014445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809764044353355, "Avg loss": 0.6200188554357737, "Avg value loss": 0.2936835444997996, "Avg policy loss": 0.3263353108195588, "Total num played games": 38058, "Total num trained steps": 75392, "Timestamp in ms": 1701927072983, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984339692048978, "Avg loss": 0.3974232056643814, "Avg value loss": 0.10909829975571483, "Avg policy loss": 0.28832490486092865, "Total num played games": 38058, "Total num trained steps": 75520, "Timestamp in ms": 1701927130969, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 168.2004315033555, "Avg game time in secs": 1.8523901173612103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 38144, "Total num trained steps": 75614, "Timestamp in ms": 1701927171863, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824676345720427, "Avg loss": 0.7513013614807278, "Avg value loss": 0.4571535465947818, "Avg policy loss": 0.2941478155553341, "Total num played games": 38158, "Total num trained steps": 75648, "Timestamp in ms": 1701927187348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858221080769431, "Avg loss": 0.4437647631857544, "Avg value loss": 0.1541523698833771, "Avg policy loss": 0.2896123939426616, "Total num played games": 38158, "Total num trained steps": 75776, "Timestamp in ms": 1701927244331, "logtype": "training_step"}
{"Total num played games": 38254, "Total num trained steps": 75838, "Timestamp in ms": 1701927334093, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.25390625}
{"Avg objective": 21.5859375, "Games time in secs": 163.93095955997705, "Avg game time in secs": 1.7762290840037167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.43}, "Total num played games": 38272, "Total num trained steps": 75841, "Timestamp in ms": 1701927335794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793470324397622, "Avg loss": 1.315316644962877, "Avg value loss": 0.9924946762330364, "Avg policy loss": 0.3228219550801441, "Total num played games": 38348, "Total num trained steps": 75904, "Timestamp in ms": 1701927363995, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982684885782831, "Avg loss": 0.43155583553016186, "Avg value loss": 0.13579374109394848, "Avg policy loss": 0.2957620961824432, "Total num played games": 38348, "Total num trained steps": 76032, "Timestamp in ms": 1701927419431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860227391258995, "Avg loss": 0.3734707999974489, "Avg value loss": 0.10140994042740203, "Avg policy loss": 0.2720608579693362, "Total num played games": 38348, "Total num trained steps": 76160, "Timestamp in ms": 1701927474567, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 151.57210301980376, "Avg game time in secs": 1.8172163972340059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 38400, "Total num trained steps": 76189, "Timestamp in ms": 1701927487366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843668712933098, "Avg loss": 0.8070715279318392, "Avg value loss": 0.5309184493380599, "Avg policy loss": 0.2761530773714185, "Total num played games": 38444, "Total num trained steps": 76288, "Timestamp in ms": 1701927530877, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 85.8712566383183, "Avg game time in secs": 1.9909377869043965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.64}, "Total num played games": 38528, "Total num trained steps": 76384, "Timestamp in ms": 1701927573237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827711468604048, "Avg loss": 0.6920754904858768, "Avg value loss": 0.41694981267210096, "Avg policy loss": 0.2751256745541468, "Total num played games": 38540, "Total num trained steps": 76416, "Timestamp in ms": 1701927587240, "logtype": "training_step"}
{"Total num played games": 38540, "Total num trained steps": 76439, "Timestamp in ms": 1701927678601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.76171875}
{"Ratio train steps to played games": 1.9812600300253662, "Avg loss": 0.830377051141113, "Avg value loss": 0.5227901750477031, "Avg policy loss": 0.3075868843588978, "Total num played games": 38634, "Total num trained steps": 76544, "Timestamp in ms": 1701927725856, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984573173888285, "Avg loss": 0.37666143476963043, "Avg value loss": 0.10525614221114665, "Avg policy loss": 0.2714052948867902, "Total num played games": 38634, "Total num trained steps": 76672, "Timestamp in ms": 1701927780736, "logtype": "training_step"}
{"Avg objective": 22.8515625, "Games time in secs": 247.853842318058, "Avg game time in secs": 2.0561107043467928, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 38656, "Total num trained steps": 76761, "Timestamp in ms": 1701927821091, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830613509605453, "Avg loss": 0.6463766564847901, "Avg value loss": 0.37903093377826735, "Avg policy loss": 0.26734573079738766, "Total num played games": 38728, "Total num trained steps": 76800, "Timestamp in ms": 1701927837950, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863664532121463, "Avg loss": 0.4131414066068828, "Avg value loss": 0.13872933603124693, "Avg policy loss": 0.2744120704010129, "Total num played games": 38728, "Total num trained steps": 76928, "Timestamp in ms": 1701927895071, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 83.02099008113146, "Avg game time in secs": 1.8776929297891911, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 38784, "Total num trained steps": 76950, "Timestamp in ms": 1701927904112, "logtype": "played_game"}
{"Total num played games": 38822, "Total num trained steps": 77043, "Timestamp in ms": 1701928013673, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.53515625}
{"Avg objective": 22.453125, "Games time in secs": 113.25697718188167, "Avg game time in secs": 1.9679235649236944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 38912, "Total num trained steps": 77050, "Timestamp in ms": 1701928017370, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800339192106076, "Avg loss": 1.037244871724397, "Avg value loss": 0.7449717521085404, "Avg policy loss": 0.2922731317812577, "Total num played games": 38916, "Total num trained steps": 77056, "Timestamp in ms": 1701928019421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833230547846643, "Avg loss": 0.6413320002611727, "Avg value loss": 0.3435206004069187, "Avg policy loss": 0.29781139618717134, "Total num played games": 38916, "Total num trained steps": 77184, "Timestamp in ms": 1701928076489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866378867303938, "Avg loss": 0.36132457689382136, "Avg value loss": 0.08857879304559901, "Avg policy loss": 0.27274578250944614, "Total num played games": 38916, "Total num trained steps": 77312, "Timestamp in ms": 1701928132564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850302471034553, "Avg loss": 0.749870530795306, "Avg value loss": 0.46471822168678045, "Avg policy loss": 0.28515230084303766, "Total num played games": 39012, "Total num trained steps": 77440, "Timestamp in ms": 1701928188327, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 204.6045999377966, "Avg game time in secs": 1.8630093407991808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.47, "agent_stopped_0": 0.58}, "Total num played games": 39040, "Total num trained steps": 77517, "Timestamp in ms": 1701928221974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835319388329156, "Avg loss": 0.7497651611920446, "Avg value loss": 0.46879570436431095, "Avg policy loss": 0.2809694577008486, "Total num played games": 39106, "Total num trained steps": 77568, "Timestamp in ms": 1701928243388, "logtype": "training_step"}
{"Total num played games": 39106, "Total num trained steps": 77644, "Timestamp in ms": 1701928372728, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.62890625}
{"Avg objective": 22.0546875, "Games time in secs": 153.4393757097423, "Avg game time in secs": 1.8193361814483069, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.52, "agent_stopped_0": 0.48}, "Total num played games": 39168, "Total num trained steps": 77649, "Timestamp in ms": 1701928375414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820408163265306, "Avg loss": 0.8013148051686585, "Avg value loss": 0.5085705634555779, "Avg policy loss": 0.2927442449145019, "Total num played games": 39200, "Total num trained steps": 77696, "Timestamp in ms": 1701928395981, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853061224489796, "Avg loss": 0.42489008349366486, "Avg value loss": 0.13703680780599825, "Avg policy loss": 0.2878532789181918, "Total num played games": 39200, "Total num trained steps": 77824, "Timestamp in ms": 1701928452942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838143227973737, "Avg loss": 1.0160485487431288, "Avg value loss": 0.7261554796132259, "Avg policy loss": 0.28989306336734444, "Total num played games": 39294, "Total num trained steps": 77952, "Timestamp in ms": 1701928510049, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 188.34386337548494, "Avg game time in secs": 1.9884744430019055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 39296, "Total num trained steps": 78078, "Timestamp in ms": 1701928563758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861619861619861, "Avg loss": 0.395390807883814, "Avg value loss": 0.11520547943655401, "Avg policy loss": 0.2801853271666914, "Total num played games": 39308, "Total num trained steps": 78080, "Timestamp in ms": 1701928564557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854785478547854, "Avg loss": 0.8830565239768475, "Avg value loss": 0.5860987144405954, "Avg policy loss": 0.29695780749898404, "Total num played games": 39390, "Total num trained steps": 78208, "Timestamp in ms": 1701928623185, "logtype": "training_step"}
{"Total num played games": 39390, "Total num trained steps": 78244, "Timestamp in ms": 1701928733614, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.61328125}
{"Avg objective": 21.15625, "Games time in secs": 172.07115050405264, "Avg game time in secs": 1.9302427140064538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 39424, "Total num trained steps": 78248, "Timestamp in ms": 1701928735829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839935163610576, "Avg loss": 0.9718812990467995, "Avg value loss": 0.6746899508289061, "Avg policy loss": 0.2971913608489558, "Total num played games": 39484, "Total num trained steps": 78336, "Timestamp in ms": 1701928775121, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 93.58082650974393, "Avg game time in secs": 1.8714675818919204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.6, "agent_stopped_0": 0.46}, "Total num played games": 39552, "Total num trained steps": 78462, "Timestamp in ms": 1701928829410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827159245969577, "Avg loss": 0.4062263797968626, "Avg value loss": 0.12012468595639803, "Avg policy loss": 0.28610169410239905, "Total num played games": 39574, "Total num trained steps": 78464, "Timestamp in ms": 1701928830022, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854234033953113, "Avg loss": 0.7153879182878882, "Avg value loss": 0.4215228530811146, "Avg policy loss": 0.29386505705770105, "Total num played games": 39584, "Total num trained steps": 78592, "Timestamp in ms": 1701928888198, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 93.02020855620503, "Avg game time in secs": 1.891984823916573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 39680, "Total num trained steps": 78668, "Timestamp in ms": 1701928922430, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838709677419355, "Avg loss": 0.736618718598038, "Avg value loss": 0.4360792626393959, "Avg policy loss": 0.3005394471110776, "Total num played games": 39680, "Total num trained steps": 78720, "Timestamp in ms": 1701928944758, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870715725806452, "Avg loss": 0.40731372800655663, "Avg value loss": 0.11554427453665994, "Avg policy loss": 0.2917694532079622, "Total num played games": 39680, "Total num trained steps": 78848, "Timestamp in ms": 1701929000179, "logtype": "training_step"}
{"Total num played games": 39680, "Total num trained steps": 78848, "Timestamp in ms": 1701929135184, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1015625}
{"Ratio train steps to played games": 1.9856187459144166, "Avg loss": 0.7514837211929262, "Avg value loss": 0.4405492973164655, "Avg policy loss": 0.3109344228869304, "Total num played games": 39774, "Total num trained steps": 78976, "Timestamp in ms": 1701929194744, "logtype": "training_step"}
{"Avg objective": 20.9921875, "Games time in secs": 300.8831147737801, "Avg game time in secs": 1.7333722308976576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 39808, "Total num trained steps": 79041, "Timestamp in ms": 1701929223314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841476873683155, "Avg loss": 0.810342529322952, "Avg value loss": 0.495424128806917, "Avg policy loss": 0.31491840013768524, "Total num played games": 39868, "Total num trained steps": 79104, "Timestamp in ms": 1701929251998, "logtype": "training_step"}
{"Avg objective": 22.1875, "Games time in secs": 85.78527448698878, "Avg game time in secs": 1.9376324503391515, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 39936, "Total num trained steps": 79230, "Timestamp in ms": 1701929309099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982981279407348, "Avg loss": 0.44961755769327283, "Avg value loss": 0.14515869732713327, "Avg policy loss": 0.304458859260194, "Total num played games": 39956, "Total num trained steps": 79232, "Timestamp in ms": 1701929309788, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985787208487639, "Avg loss": 0.826411718968302, "Avg value loss": 0.5130896615446545, "Avg policy loss": 0.31332205329090357, "Total num played games": 39964, "Total num trained steps": 79360, "Timestamp in ms": 1701929366707, "logtype": "training_step"}
{"Total num played games": 40060, "Total num trained steps": 79448, "Timestamp in ms": 1701929485200, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.84765625}
{"Avg objective": 21.9375, "Games time in secs": 177.45869641005993, "Avg game time in secs": 1.909985318139661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 40064, "Total num trained steps": 79448, "Timestamp in ms": 1701929486558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795786223041292, "Avg loss": 1.3397968111094087, "Avg value loss": 1.0263291066512465, "Avg policy loss": 0.31346770317759365, "Total num played games": 40154, "Total num trained steps": 79488, "Timestamp in ms": 1701929504653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982741445435075, "Avg loss": 0.505049966275692, "Avg value loss": 0.18804874923080206, "Avg policy loss": 0.3170012185582891, "Total num played games": 40154, "Total num trained steps": 79616, "Timestamp in ms": 1701929561608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859540768043034, "Avg loss": 0.3890109609346837, "Avg value loss": 0.09523111305315979, "Avg policy loss": 0.2937798493076116, "Total num played games": 40154, "Total num trained steps": 79744, "Timestamp in ms": 1701929617163, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 154.63591311126947, "Avg game time in secs": 1.7453568746277597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.43}, "Total num played games": 40192, "Total num trained steps": 79801, "Timestamp in ms": 1701929641194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.7313433331437409, "Avg value loss": 0.4317475661227945, "Avg policy loss": 0.2995957719394937, "Total num played games": 40248, "Total num trained steps": 79872, "Timestamp in ms": 1701929671938, "logtype": "training_step"}
{"Avg objective": 22.390625, "Games time in secs": 81.95163878425956, "Avg game time in secs": 1.934002033289289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 40320, "Total num trained steps": 79991, "Timestamp in ms": 1701929723146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828235760670203, "Avg loss": 0.49277174076996744, "Avg value loss": 0.20144314612844028, "Avg policy loss": 0.2913285931572318, "Total num played games": 40346, "Total num trained steps": 80000, "Timestamp in ms": 1701929726912, "logtype": "training_step"}
{"Total num played games": 40346, "Total num trained steps": 80051, "Timestamp in ms": 1701929812694, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.87890625}
{"Ratio train steps to played games": 1.981379821958457, "Avg loss": 1.1738266195170581, "Avg value loss": 0.8351261032512411, "Avg policy loss": 0.3387005196418613, "Total num played games": 40440, "Total num trained steps": 80128, "Timestamp in ms": 1701929848392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845450049455984, "Avg loss": 0.4378180780913681, "Avg value loss": 0.11824407067615539, "Avg policy loss": 0.3195740063674748, "Total num played games": 40440, "Total num trained steps": 80256, "Timestamp in ms": 1701929906186, "logtype": "training_step"}
{"Avg objective": 22.7890625, "Games time in secs": 232.81686890870333, "Avg game time in secs": 2.025324229733087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 40448, "Total num trained steps": 80371, "Timestamp in ms": 1701929955963, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831252775447772, "Avg loss": 0.4771738601848483, "Avg value loss": 0.17440636013634503, "Avg policy loss": 0.3027675002813339, "Total num played games": 40534, "Total num trained steps": 80384, "Timestamp in ms": 1701929961644, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862831203434155, "Avg loss": 0.6544578468892723, "Avg value loss": 0.3286993252695538, "Avg policy loss": 0.3257585206301883, "Total num played games": 40534, "Total num trained steps": 80512, "Timestamp in ms": 1701930018805, "logtype": "training_step"}
{"Avg objective": 22.0390625, "Games time in secs": 85.86696856096387, "Avg game time in secs": 1.8631087305257097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 40576, "Total num trained steps": 80561, "Timestamp in ms": 1701930041830, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848380427291523, "Avg loss": 0.7964761559851468, "Avg value loss": 0.4758619706844911, "Avg policy loss": 0.3206141834380105, "Total num played games": 40628, "Total num trained steps": 80640, "Timestamp in ms": 1701930075301, "logtype": "training_step"}
{"Total num played games": 40628, "Total num trained steps": 80651, "Timestamp in ms": 1701930155130, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.13671875}
{"Avg objective": 21.6171875, "Games time in secs": 115.81186504662037, "Avg game time in secs": 1.8095819153822958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 40704, "Total num trained steps": 80656, "Timestamp in ms": 1701930157642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833996365600903, "Avg loss": 0.7393246067222208, "Avg value loss": 0.4078094302676618, "Avg policy loss": 0.33151517692022026, "Total num played games": 40722, "Total num trained steps": 80768, "Timestamp in ms": 1701930205058, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865429006433868, "Avg loss": 0.3969618098344654, "Avg value loss": 0.0940373363555409, "Avg policy loss": 0.3029244728386402, "Total num played games": 40722, "Total num trained steps": 80896, "Timestamp in ms": 1701930260293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851038808310466, "Avg loss": 0.6765405156183988, "Avg value loss": 0.3596858597593382, "Avg policy loss": 0.316854655276984, "Total num played games": 40816, "Total num trained steps": 81024, "Timestamp in ms": 1701930315466, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 201.4092293716967, "Avg game time in secs": 2.100039494864177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 40832, "Total num trained steps": 81124, "Timestamp in ms": 1701930359051, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836714739672452, "Avg loss": 0.7768680925946683, "Avg value loss": 0.4666526615328621, "Avg policy loss": 0.31021542963571846, "Total num played games": 40910, "Total num trained steps": 81152, "Timestamp in ms": 1701930370750, "logtype": "training_step"}
{"Total num played games": 40910, "Total num trained steps": 81253, "Timestamp in ms": 1701930438406, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83203125}
{"Avg objective": 21.2890625, "Games time in secs": 81.62474377080798, "Avg game time in secs": 1.7962127931241412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 40960, "Total num trained steps": 81258, "Timestamp in ms": 1701930440676, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822456345722368, "Avg loss": 0.7653850915376097, "Avg value loss": 0.44749452848918736, "Avg policy loss": 0.3178905645618215, "Total num played games": 41004, "Total num trained steps": 81280, "Timestamp in ms": 1701930450056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985342893376256, "Avg loss": 0.5175817748531699, "Avg value loss": 0.1958816336991731, "Avg policy loss": 0.3217001425800845, "Total num played games": 41004, "Total num trained steps": 81408, "Timestamp in ms": 1701930507147, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 106.37361601367593, "Avg game time in secs": 1.972933964949334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 41088, "Total num trained steps": 81505, "Timestamp in ms": 1701930547050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838442822384428, "Avg loss": 0.6039900067262352, "Avg value loss": 0.29900679594720714, "Avg policy loss": 0.3049832053948194, "Total num played games": 41100, "Total num trained steps": 81536, "Timestamp in ms": 1701930560293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869586374695865, "Avg loss": 0.490804836852476, "Avg value loss": 0.17609622102463618, "Avg policy loss": 0.31470861460547894, "Total num played games": 41100, "Total num trained steps": 81664, "Timestamp in ms": 1701930617962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855318735738214, "Avg loss": 0.7512031062506139, "Avg value loss": 0.4362310542492196, "Avg policy loss": 0.31497203884646297, "Total num played games": 41194, "Total num trained steps": 81792, "Timestamp in ms": 1701930676022, "logtype": "training_step"}
{"Total num played games": 41194, "Total num trained steps": 81855, "Timestamp in ms": 1701930782537, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.58984375}
{"Avg objective": 22.1640625, "Games time in secs": 237.48262282833457, "Avg game time in secs": 1.9782502521993592, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.57, "agent_stopped_0": 0.53}, "Total num played games": 41216, "Total num trained steps": 81859, "Timestamp in ms": 1701930784532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840873861654718, "Avg loss": 0.6437803378794342, "Avg value loss": 0.326329275208991, "Avg policy loss": 0.31745106528978795, "Total num played games": 41288, "Total num trained steps": 81920, "Timestamp in ms": 1701930811557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872117806626624, "Avg loss": 0.39308407390490174, "Avg value loss": 0.10229015635559335, "Avg policy loss": 0.29079391644336283, "Total num played games": 41288, "Total num trained steps": 82048, "Timestamp in ms": 1701930867562, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 93.02135708555579, "Avg game time in secs": 1.7334656221792102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 41344, "Total num trained steps": 82070, "Timestamp in ms": 1701930877554, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856949545718152, "Avg loss": 0.6858874980825931, "Avg value loss": 0.38153025921201333, "Avg policy loss": 0.30435722623951733, "Total num played games": 41384, "Total num trained steps": 82176, "Timestamp in ms": 1701930923821, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 83.06528538092971, "Avg game time in secs": 2.0216074021009263, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 41472, "Total num trained steps": 82263, "Timestamp in ms": 1701930960619, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984280823569121, "Avg loss": 0.8252963717095554, "Avg value loss": 0.5218856688879896, "Avg policy loss": 0.30341069831047207, "Total num played games": 41478, "Total num trained steps": 82304, "Timestamp in ms": 1701930978436, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873667968561648, "Avg loss": 0.4908741977997124, "Avg value loss": 0.17456454719649628, "Avg policy loss": 0.31630965205840766, "Total num played games": 41478, "Total num trained steps": 82432, "Timestamp in ms": 1701931035113, "logtype": "training_step"}
{"Total num played games": 41572, "Total num trained steps": 82459, "Timestamp in ms": 1701931164091, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.05859375}
{"Avg objective": 21.578125, "Games time in secs": 205.43915988877416, "Avg game time in secs": 1.8297145808464848, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 41600, "Total num trained steps": 82463, "Timestamp in ms": 1701931166059, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814717035472567, "Avg loss": 1.3555280382279307, "Avg value loss": 1.003379188652616, "Avg policy loss": 0.3521488719852641, "Total num played games": 41666, "Total num trained steps": 82560, "Timestamp in ms": 1701931208742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845437527000431, "Avg loss": 0.4492168335709721, "Avg value loss": 0.13604194665094838, "Avg policy loss": 0.31317488697823137, "Total num played games": 41666, "Total num trained steps": 82688, "Timestamp in ms": 1701931264503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876158018528296, "Avg loss": 0.39056743681430817, "Avg value loss": 0.09236561227589846, "Avg policy loss": 0.2982018240727484, "Total num played games": 41666, "Total num trained steps": 82816, "Timestamp in ms": 1701931319775, "logtype": "training_step"}
{"Avg objective": 22.84375, "Games time in secs": 158.4221859127283, "Avg game time in secs": 1.8989196222973987, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 41728, "Total num trained steps": 82827, "Timestamp in ms": 1701931324481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854461891995403, "Avg loss": 1.0230859373696148, "Avg value loss": 0.6895146516035311, "Avg policy loss": 0.3335712979314849, "Total num played games": 41776, "Total num trained steps": 82944, "Timestamp in ms": 1701931374699, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 94.04237243905663, "Avg game time in secs": 1.9256456569128204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 41856, "Total num trained steps": 83047, "Timestamp in ms": 1701931418524, "logtype": "played_game"}
{"Total num played games": 41870, "Total num trained steps": 83061, "Timestamp in ms": 1701931495261, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.97265625}
{"Ratio train steps to played games": 1.979695915351985, "Avg loss": 0.8152381414547563, "Avg value loss": 0.5038358264428098, "Avg policy loss": 0.31140231154859066, "Total num played games": 41962, "Total num trained steps": 83072, "Timestamp in ms": 1701931500057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826279668287103, "Avg loss": 0.872145386878401, "Avg value loss": 0.5315569215454161, "Avg policy loss": 0.34058846009429544, "Total num played games": 41964, "Total num trained steps": 83200, "Timestamp in ms": 1701931556716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857020303116957, "Avg loss": 0.3984495827462524, "Avg value loss": 0.099945262336405, "Avg policy loss": 0.29850432090461254, "Total num played games": 41964, "Total num trained steps": 83328, "Timestamp in ms": 1701931610673, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 235.1009007282555, "Avg game time in secs": 1.9377815569459926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 41984, "Total num trained steps": 83420, "Timestamp in ms": 1701931653625, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984307385039707, "Avg loss": 0.671427414054051, "Avg value loss": 0.37678583900560625, "Avg policy loss": 0.2946415804326534, "Total num played games": 42058, "Total num trained steps": 83456, "Timestamp in ms": 1701931669521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873508012744305, "Avg loss": 0.6011772444471717, "Avg value loss": 0.2890690505155362, "Avg policy loss": 0.31210819038096815, "Total num played games": 42058, "Total num trained steps": 83584, "Timestamp in ms": 1701931725428, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 82.96034164726734, "Avg game time in secs": 1.9975320982921403, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 42112, "Total num trained steps": 83611, "Timestamp in ms": 1701931736585, "logtype": "played_game"}
{"Total num played games": 42152, "Total num trained steps": 83666, "Timestamp in ms": 1701931817141, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.31640625}
{"Avg objective": 22.6171875, "Games time in secs": 84.34153079614043, "Avg game time in secs": 2.043530094611924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 42240, "Total num trained steps": 83674, "Timestamp in ms": 1701931820927, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815367135350093, "Avg loss": 1.3831341727636755, "Avg value loss": 1.0524215624900535, "Avg policy loss": 0.33071260701399297, "Total num played games": 42246, "Total num trained steps": 83712, "Timestamp in ms": 1701931837874, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845665861856743, "Avg loss": 0.5563342778477818, "Avg value loss": 0.2315006879507564, "Avg policy loss": 0.3248335922835395, "Total num played games": 42246, "Total num trained steps": 83840, "Timestamp in ms": 1701931894285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875727879562561, "Avg loss": 0.39761886093765497, "Avg value loss": 0.10770289413630962, "Avg policy loss": 0.28991596901323646, "Total num played games": 42246, "Total num trained steps": 83968, "Timestamp in ms": 1701931947562, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986206896551724, "Avg loss": 0.8726583607494831, "Avg value loss": 0.5651188750052825, "Avg policy loss": 0.3075394902843982, "Total num played games": 42340, "Total num trained steps": 84096, "Timestamp in ms": 1701932000761, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 213.81392366811633, "Avg game time in secs": 1.746222240763018, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.42, "agent_stopped_0": 0.63}, "Total num played games": 42368, "Total num trained steps": 84172, "Timestamp in ms": 1701932034741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847063813743049, "Avg loss": 0.7312874062918127, "Avg value loss": 0.4241472571156919, "Avg policy loss": 0.3071401420747861, "Total num played games": 42436, "Total num trained steps": 84224, "Timestamp in ms": 1701932058534, "logtype": "training_step"}
{"Total num played games": 42436, "Total num trained steps": 84266, "Timestamp in ms": 1701932149692, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.07421875}
{"Avg objective": 21.2734375, "Games time in secs": 117.54312412813306, "Avg game time in secs": 1.909641512640519, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.43}, "Total num played games": 42496, "Total num trained steps": 84271, "Timestamp in ms": 1701932152284, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833529273454031, "Avg loss": 0.7625854075886309, "Avg value loss": 0.44679027545498684, "Avg policy loss": 0.315795132657513, "Total num played games": 42530, "Total num trained steps": 84352, "Timestamp in ms": 1701932188910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863625675993417, "Avg loss": 0.4207736689131707, "Avg value loss": 0.12353449198417366, "Avg policy loss": 0.2972391765797511, "Total num played games": 42530, "Total num trained steps": 84480, "Timestamp in ms": 1701932244922, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 125.66288217157125, "Avg game time in secs": 1.9889547027996741, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 42624, "Total num trained steps": 84560, "Timestamp in ms": 1701932277947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848683901843944, "Avg loss": 0.7026922469958663, "Avg value loss": 0.40898706257576123, "Avg policy loss": 0.29370518133509904, "Total num played games": 42626, "Total num trained steps": 84608, "Timestamp in ms": 1701932299321, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878947121475157, "Avg loss": 0.41229790006764233, "Avg value loss": 0.11633198673371226, "Avg policy loss": 0.295965914032422, "Total num played games": 42626, "Total num trained steps": 84736, "Timestamp in ms": 1701932355834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864238565610224, "Avg loss": 0.7875811429694295, "Avg value loss": 0.4646827114629559, "Avg policy loss": 0.322898437269032, "Total num played games": 42722, "Total num trained steps": 84864, "Timestamp in ms": 1701932412181, "logtype": "training_step"}
{"Total num played games": 42722, "Total num trained steps": 84868, "Timestamp in ms": 1701932478721, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.42578125}
{"Avg objective": 20.078125, "Games time in secs": 202.70535227656364, "Avg game time in secs": 1.746674363326747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 42752, "Total num trained steps": 84870, "Timestamp in ms": 1701932480653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985028961136024, "Avg loss": 0.8872784646227956, "Avg value loss": 0.5479090113076381, "Avg policy loss": 0.33936945674940944, "Total num played games": 42816, "Total num trained steps": 84992, "Timestamp in ms": 1701932535358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880184977578474, "Avg loss": 0.4060741188004613, "Avg value loss": 0.09956334249000065, "Avg policy loss": 0.30651077604852617, "Total num played games": 42816, "Total num trained steps": 85120, "Timestamp in ms": 1701932592095, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 114.02460573986173, "Avg game time in secs": 1.8437471055076458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 42880, "Total num trained steps": 85127, "Timestamp in ms": 1701932594677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866697739454673, "Avg loss": 0.8346720887348056, "Avg value loss": 0.5063892346224748, "Avg policy loss": 0.3282828553346917, "Total num played games": 42910, "Total num trained steps": 85248, "Timestamp in ms": 1701932645674, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852804390289276, "Avg loss": 0.7917960803024471, "Avg value loss": 0.47869427199475467, "Avg policy loss": 0.3131018008571118, "Total num played games": 43004, "Total num trained steps": 85376, "Timestamp in ms": 1701932704509, "logtype": "training_step"}
{"Total num played games": 43004, "Total num trained steps": 85472, "Timestamp in ms": 1701932838696, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.16015625}
{"Avg objective": 20.859375, "Games time in secs": 245.59213475883007, "Avg game time in secs": 2.093798238376621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 43008, "Total num trained steps": 85475, "Timestamp in ms": 1701932840270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983943570467307, "Avg loss": 0.6055259886197746, "Avg value loss": 0.3050549916806631, "Avg policy loss": 0.3004709972301498, "Total num played games": 43098, "Total num trained steps": 85504, "Timestamp in ms": 1701932853754, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869135458721983, "Avg loss": 0.4549429942853749, "Avg value loss": 0.15688756247982383, "Avg policy loss": 0.2980554335517809, "Total num played games": 43098, "Total num trained steps": 85632, "Timestamp in ms": 1701932914216, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 99.53538668528199, "Avg game time in secs": 1.877928818226792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 43136, "Total num trained steps": 85689, "Timestamp in ms": 1701932939805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855528801629931, "Avg loss": 0.8051196853630245, "Avg value loss": 0.5056221354170702, "Avg policy loss": 0.2994975580368191, "Total num played games": 43192, "Total num trained steps": 85760, "Timestamp in ms": 1701932972853, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 84.57039958611131, "Avg game time in secs": 1.855933318118332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.48, "agent_stopped_0": 0.54}, "Total num played games": 43264, "Total num trained steps": 85878, "Timestamp in ms": 1701933024376, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841981241047915, "Avg loss": 0.5406004907563329, "Avg value loss": 0.2586313281208277, "Avg policy loss": 0.2819691663607955, "Total num played games": 43286, "Total num trained steps": 85888, "Timestamp in ms": 1701933027934, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870402883016078, "Avg loss": 0.7138495182152838, "Avg value loss": 0.40840064658550546, "Avg policy loss": 0.3054488698253408, "Total num played games": 43288, "Total num trained steps": 86016, "Timestamp in ms": 1701933085288, "logtype": "training_step"}
{"Total num played games": 43384, "Total num trained steps": 86075, "Timestamp in ms": 1701933194993, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.015625}
{"Avg objective": 21.421875, "Games time in secs": 172.17685421928763, "Avg game time in secs": 2.0467287888459396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 43392, "Total num trained steps": 86076, "Timestamp in ms": 1701933196553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813238879433277, "Avg loss": 1.2294939232524484, "Avg value loss": 0.9200856388779357, "Avg policy loss": 0.3094082761090249, "Total num played games": 43478, "Total num trained steps": 86144, "Timestamp in ms": 1701933226475, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842679056074337, "Avg loss": 0.41453790105879307, "Avg value loss": 0.12550312554230914, "Avg policy loss": 0.28903477592393756, "Total num played games": 43478, "Total num trained steps": 86272, "Timestamp in ms": 1701933282478, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872119232715397, "Avg loss": 0.3533181694801897, "Avg value loss": 0.08357571056694724, "Avg policy loss": 0.26974245661403984, "Total num played games": 43478, "Total num trained steps": 86400, "Timestamp in ms": 1701933338914, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 164.95127913728356, "Avg game time in secs": 1.700628739228705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.35}, "Total num played games": 43520, "Total num trained steps": 86449, "Timestamp in ms": 1701933361504, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985497934832492, "Avg loss": 0.9241769569925964, "Avg value loss": 0.6377938704390544, "Avg policy loss": 0.28638309182133526, "Total num played games": 43580, "Total num trained steps": 86528, "Timestamp in ms": 1701933395205, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 91.15484639257193, "Avg game time in secs": 1.8855745879991446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 43648, "Total num trained steps": 86654, "Timestamp in ms": 1701933452659, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984973428623786, "Avg loss": 0.4374271968845278, "Avg value loss": 0.1584435771801509, "Avg policy loss": 0.2789836198789999, "Total num played games": 43654, "Total num trained steps": 86656, "Timestamp in ms": 1701933453225, "logtype": "training_step"}
{"Total num played games": 43676, "Total num trained steps": 86675, "Timestamp in ms": 1701933546263, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.41015625}
{"Ratio train steps to played games": 1.9827050491204021, "Avg loss": 1.2259433537255973, "Avg value loss": 0.898293910198845, "Avg policy loss": 0.3276494281599298, "Total num played games": 43770, "Total num trained steps": 86784, "Timestamp in ms": 1701933597805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856522732465158, "Avg loss": 0.40093727479688823, "Avg value loss": 0.11929499398684129, "Avg policy loss": 0.28164227888919413, "Total num played games": 43770, "Total num trained steps": 86912, "Timestamp in ms": 1701933653973, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 254.80299736186862, "Avg game time in secs": 2.1262936603743583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 43776, "Total num trained steps": 87032, "Timestamp in ms": 1701933707465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984315155936531, "Avg loss": 0.46027533477172256, "Avg value loss": 0.19358242055750452, "Avg policy loss": 0.26669291860889643, "Total num played games": 43864, "Total num trained steps": 87040, "Timestamp in ms": 1701933710354, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871426617425796, "Avg loss": 0.7627504649572074, "Avg value loss": 0.4601363633410074, "Avg policy loss": 0.302614109008573, "Total num played games": 43866, "Total num trained steps": 87168, "Timestamp in ms": 1701933768549, "logtype": "training_step"}
{"Avg objective": 23.2265625, "Games time in secs": 87.22865285724401, "Avg game time in secs": 1.769997620023787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 43904, "Total num trained steps": 87225, "Timestamp in ms": 1701933794694, "logtype": "played_game"}
{"Total num played games": 43960, "Total num trained steps": 87278, "Timestamp in ms": 1701933905251, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.046875}
{"Avg objective": 21.71875, "Games time in secs": 113.70122134312987, "Avg game time in secs": 1.9360284311696887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 44032, "Total num trained steps": 87282, "Timestamp in ms": 1701933908396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815453761292958, "Avg loss": 0.8744089633692056, "Avg value loss": 0.5762493190704845, "Avg policy loss": 0.29815964854788035, "Total num played games": 44054, "Total num trained steps": 87296, "Timestamp in ms": 1701933913949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984473600581105, "Avg loss": 0.6019574494566768, "Avg value loss": 0.287537959695328, "Avg policy loss": 0.31441948446445167, "Total num played games": 44054, "Total num trained steps": 87424, "Timestamp in ms": 1701933967327, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873791256185591, "Avg loss": 0.37625653063878417, "Avg value loss": 0.09115872418624349, "Avg policy loss": 0.28509780764579773, "Total num played games": 44054, "Total num trained steps": 87552, "Timestamp in ms": 1701934023158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860469330433994, "Avg loss": 1.0525018444750458, "Avg value loss": 0.7498871478892397, "Avg policy loss": 0.30261468852404505, "Total num played games": 44148, "Total num trained steps": 87680, "Timestamp in ms": 1701934079606, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 216.30973771214485, "Avg game time in secs": 2.042068296461366, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 44160, "Total num trained steps": 87788, "Timestamp in ms": 1701934124705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846306843865835, "Avg loss": 0.6021087630651891, "Avg value loss": 0.3126855972222984, "Avg policy loss": 0.28942316758912057, "Total num played games": 44244, "Total num trained steps": 87808, "Timestamp in ms": 1701934133205, "logtype": "training_step"}
{"Total num played games": 44244, "Total num trained steps": 87878, "Timestamp in ms": 1701934203488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.65234375}
{"Avg objective": 20.875, "Games time in secs": 81.02092459797859, "Avg game time in secs": 1.8266718134691473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 44288, "Total num trained steps": 87882, "Timestamp in ms": 1701934205726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833100275159006, "Avg loss": 0.927922444883734, "Avg value loss": 0.619382296456024, "Avg policy loss": 0.3085401417920366, "Total num played games": 44338, "Total num trained steps": 87936, "Timestamp in ms": 1701934229160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986174387658442, "Avg loss": 0.43069058284163475, "Avg value loss": 0.13927751989103854, "Avg policy loss": 0.29141306516248733, "Total num played games": 44338, "Total num trained steps": 88064, "Timestamp in ms": 1701934284179, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 124.61788699403405, "Avg game time in secs": 1.922844861401245, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 44416, "Total num trained steps": 88171, "Timestamp in ms": 1701934330345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98487576521426, "Avg loss": 0.6837327021639794, "Avg value loss": 0.4031001229886897, "Avg policy loss": 0.28063258656766266, "Total num played games": 44432, "Total num trained steps": 88192, "Timestamp in ms": 1701934339767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877565718401153, "Avg loss": 0.4851328069344163, "Avg value loss": 0.19681218056939542, "Avg policy loss": 0.2883206227561459, "Total num played games": 44432, "Total num trained steps": 88320, "Timestamp in ms": 1701934399159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863456701401365, "Avg loss": 0.8127977577969432, "Avg value loss": 0.5173223158053588, "Avg policy loss": 0.29547543835360557, "Total num played games": 44528, "Total num trained steps": 88448, "Timestamp in ms": 1701934458210, "logtype": "training_step"}
{"Total num played games": 44528, "Total num trained steps": 88480, "Timestamp in ms": 1701934533797, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.546875}
{"Avg objective": 20.7890625, "Games time in secs": 205.09831869229674, "Avg game time in secs": 1.742780971864704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.47, "agent_stopped_0": 0.6}, "Total num played games": 44544, "Total num trained steps": 88482, "Timestamp in ms": 1701934535443, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850298059253284, "Avg loss": 0.8705291920341551, "Avg value loss": 0.5661014158395119, "Avg policy loss": 0.3044277790468186, "Total num played games": 44622, "Total num trained steps": 88576, "Timestamp in ms": 1701934577396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878983461073014, "Avg loss": 0.3811605875380337, "Avg value loss": 0.09798977474565618, "Avg policy loss": 0.28317081229761243, "Total num played games": 44622, "Total num trained steps": 88704, "Timestamp in ms": 1701934637480, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 117.60215144231915, "Avg game time in secs": 1.6889217564894352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 44672, "Total num trained steps": 88737, "Timestamp in ms": 1701934653046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864931347555794, "Avg loss": 0.6484267592895776, "Avg value loss": 0.35092740622349083, "Avg policy loss": 0.2974993442185223, "Total num played games": 44718, "Total num trained steps": 88832, "Timestamp in ms": 1701934694253, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 85.46086091920733, "Avg game time in secs": 1.8635669445211533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 44800, "Total num trained steps": 88932, "Timestamp in ms": 1701934738507, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851602249397482, "Avg loss": 0.6078799541573972, "Avg value loss": 0.32514973531942815, "Avg policy loss": 0.2827302262885496, "Total num played games": 44812, "Total num trained steps": 88960, "Timestamp in ms": 1701934752098, "logtype": "training_step"}
{"Total num played games": 44812, "Total num trained steps": 89082, "Timestamp in ms": 1701934846908, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.24609375}
{"Ratio train steps to played games": 1.9854248846693856, "Avg loss": 0.4426048237364739, "Avg value loss": 0.16051387836341746, "Avg policy loss": 0.2820909454021603, "Total num played games": 44868, "Total num trained steps": 89088, "Timestamp in ms": 1701934849590, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867055627310382, "Avg loss": 0.8916912775021046, "Avg value loss": 0.5942964428686537, "Avg policy loss": 0.2973948298022151, "Total num played games": 44906, "Total num trained steps": 89216, "Timestamp in ms": 1701934908306, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 208.79390851035714, "Avg game time in secs": 1.8692915229767095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.46, "agent_stopped_0": 0.6}, "Total num played games": 44928, "Total num trained steps": 89304, "Timestamp in ms": 1701934947302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854, "Avg loss": 0.6652397101279348, "Avg value loss": 0.3829089704377111, "Avg policy loss": 0.28233074164018035, "Total num played games": 45000, "Total num trained steps": 89344, "Timestamp in ms": 1701934964715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882666666666666, "Avg loss": 0.42992039979435503, "Avg value loss": 0.13876255211653188, "Avg policy loss": 0.291157845989801, "Total num played games": 45000, "Total num trained steps": 89472, "Timestamp in ms": 1701935022948, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 84.33959782123566, "Avg game time in secs": 1.8744343954022042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 45056, "Total num trained steps": 89493, "Timestamp in ms": 1701935031641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869605712511642, "Avg loss": 0.7682484113611281, "Avg value loss": 0.4712594916927628, "Avg policy loss": 0.29698891658335924, "Total num played games": 45094, "Total num trained steps": 89600, "Timestamp in ms": 1701935079640, "logtype": "training_step"}
{"Avg objective": 23.203125, "Games time in secs": 86.64849536120892, "Avg game time in secs": 1.8878804819833022, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 45184, "Total num trained steps": 89684, "Timestamp in ms": 1701935118290, "logtype": "played_game"}
{"Total num played games": 45188, "Total num trained steps": 89684, "Timestamp in ms": 1701935176762, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.21875}
{"Ratio train steps to played games": 1.9815158341062673, "Avg loss": 1.5686040003784, "Avg value loss": 1.273300272616325, "Avg policy loss": 0.29530369804706424, "Total num played games": 45282, "Total num trained steps": 89728, "Timestamp in ms": 1701935197413, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984342564374365, "Avg loss": 0.561847566626966, "Avg value loss": 0.25055321637773886, "Avg policy loss": 0.3112943524029106, "Total num played games": 45282, "Total num trained steps": 89856, "Timestamp in ms": 1701935255181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871913784726822, "Avg loss": 0.37581095355562866, "Avg value loss": 0.09788461177959107, "Avg policy loss": 0.2779263419797644, "Total num played games": 45282, "Total num trained steps": 89984, "Timestamp in ms": 1701935314772, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 229.26793269068003, "Avg game time in secs": 1.9200267031555995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.51, "agent_stopped_0": 0.59}, "Total num played games": 45312, "Total num trained steps": 90057, "Timestamp in ms": 1701935347558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858956276445698, "Avg loss": 0.7957624939735979, "Avg value loss": 0.499475170916412, "Avg policy loss": 0.29628733335994184, "Total num played games": 45376, "Total num trained steps": 90112, "Timestamp in ms": 1701935372201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886944640338504, "Avg loss": 0.4272266107145697, "Avg value loss": 0.1357018748531118, "Avg policy loss": 0.29152473830617964, "Total num played games": 45376, "Total num trained steps": 90240, "Timestamp in ms": 1701935427273, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 82.40344676747918, "Avg game time in secs": 1.9351911799167283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 45440, "Total num trained steps": 90246, "Timestamp in ms": 1701935429962, "logtype": "played_game"}
{"Total num played games": 45470, "Total num trained steps": 90288, "Timestamp in ms": 1701935505421, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6953125}
{"Ratio train steps to played games": 1.9833201650425776, "Avg loss": 1.1589459266979247, "Avg value loss": 0.8368133578333072, "Avg policy loss": 0.32213255821261555, "Total num played games": 45564, "Total num trained steps": 90368, "Timestamp in ms": 1701935542520, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861294004038277, "Avg loss": 0.4071086149197072, "Avg value loss": 0.12137920409440994, "Avg policy loss": 0.28572940919548273, "Total num played games": 45564, "Total num trained steps": 90496, "Timestamp in ms": 1701935597539, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 222.84700134396553, "Avg game time in secs": 2.240202876884723, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 45568, "Total num trained steps": 90619, "Timestamp in ms": 1701935652809, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854307247392866, "Avg loss": 0.39043484372086823, "Avg value loss": 0.11421395430807024, "Avg policy loss": 0.2762208920903504, "Total num played games": 45644, "Total num trained steps": 90624, "Timestamp in ms": 1701935655040, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876253887599107, "Avg loss": 0.6474522959906608, "Avg value loss": 0.363299613003619, "Avg policy loss": 0.28415269462857395, "Total num played games": 45658, "Total num trained steps": 90752, "Timestamp in ms": 1701935710765, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 82.20083773508668, "Avg game time in secs": 1.6240931804059073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 45696, "Total num trained steps": 90809, "Timestamp in ms": 1701935735010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862744240940682, "Avg loss": 0.7108874062541872, "Avg value loss": 0.4310934418463148, "Avg policy loss": 0.2797939624870196, "Total num played games": 45754, "Total num trained steps": 90880, "Timestamp in ms": 1701935765286, "logtype": "training_step"}
{"Total num played games": 45754, "Total num trained steps": 90889, "Timestamp in ms": 1701935840038, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5078125}
{"Avg objective": 20.90625, "Games time in secs": 107.91228126361966, "Avg game time in secs": 1.8599797019560356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 45824, "Total num trained steps": 90894, "Timestamp in ms": 1701935842922, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849938928633746, "Avg loss": 0.8074432224966586, "Avg value loss": 0.5098539549508132, "Avg policy loss": 0.2975892636459321, "Total num played games": 45848, "Total num trained steps": 91008, "Timestamp in ms": 1701935892055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877857267492585, "Avg loss": 0.3646788315381855, "Avg value loss": 0.09585314310970716, "Avg policy loss": 0.2688256868859753, "Total num played games": 45848, "Total num trained steps": 91136, "Timestamp in ms": 1701935949437, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862235570645077, "Avg loss": 0.9300045489799231, "Avg value loss": 0.6461910669750068, "Avg policy loss": 0.28381348750554025, "Total num played games": 45948, "Total num trained steps": 91264, "Timestamp in ms": 1701936006703, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 218.44848278537393, "Avg game time in secs": 2.032361178746214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 45952, "Total num trained steps": 91386, "Timestamp in ms": 1701936061371, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854014598540146, "Avg loss": 0.42400901135988533, "Avg value loss": 0.1470307785202749, "Avg policy loss": 0.2769782315008342, "Total num played games": 46032, "Total num trained steps": 91392, "Timestamp in ms": 1701936063662, "logtype": "training_step"}
{"Total num played games": 46042, "Total num trained steps": 91493, "Timestamp in ms": 1701936211076, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4296875}
{"Avg objective": 21.1015625, "Games time in secs": 151.72299613058567, "Avg game time in secs": 1.7070630580128636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.36}, "Total num played games": 46080, "Total num trained steps": 91495, "Timestamp in ms": 1701936213094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983700364140801, "Avg loss": 0.9363245682325214, "Avg value loss": 0.6363009624765255, "Avg policy loss": 0.3000236072111875, "Total num played games": 46136, "Total num trained steps": 91520, "Timestamp in ms": 1701936224765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864747702444945, "Avg loss": 0.45002715149894357, "Avg value loss": 0.16102682490600273, "Avg policy loss": 0.2890003251377493, "Total num played games": 46136, "Total num trained steps": 91648, "Timestamp in ms": 1701936281535, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 122.3528360761702, "Avg game time in secs": 1.798092285549501, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 46208, "Total num trained steps": 91766, "Timestamp in ms": 1701936335447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852044127190136, "Avg loss": 0.524826762615703, "Avg value loss": 0.25720799560076557, "Avg policy loss": 0.26761875837109983, "Total num played games": 46230, "Total num trained steps": 91776, "Timestamp in ms": 1701936340547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879731775903093, "Avg loss": 0.6946135594043881, "Avg value loss": 0.39738227071939036, "Avg policy loss": 0.2972312883939594, "Total num played games": 46230, "Total num trained steps": 91904, "Timestamp in ms": 1701936399403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986680770227096, "Avg loss": 0.7743578834924847, "Avg value loss": 0.4759395534929354, "Avg policy loss": 0.29841833491809666, "Total num played games": 46324, "Total num trained steps": 92032, "Timestamp in ms": 1701936453082, "logtype": "training_step"}
{"Total num played games": 46324, "Total num trained steps": 92095, "Timestamp in ms": 1701936555373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.671875}
{"Avg objective": 22.515625, "Games time in secs": 221.6292039528489, "Avg game time in secs": 1.9004012820369098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.58, "agent_stopped_0": 0.55}, "Total num played games": 46336, "Total num trained steps": 92097, "Timestamp in ms": 1701936557076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854366840449826, "Avg loss": 0.6356329908594489, "Avg value loss": 0.334513294917997, "Avg policy loss": 0.3011196939041838, "Total num played games": 46418, "Total num trained steps": 92160, "Timestamp in ms": 1701936583842, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988194234995045, "Avg loss": 0.3908976304810494, "Avg value loss": 0.09373490058351308, "Avg policy loss": 0.29716273106168956, "Total num played games": 46418, "Total num trained steps": 92288, "Timestamp in ms": 1701936638643, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 99.84215469658375, "Avg game time in secs": 1.8148616042744834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.43}, "Total num played games": 46464, "Total num trained steps": 92329, "Timestamp in ms": 1701936656918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869281045751634, "Avg loss": 0.8359309453517199, "Avg value loss": 0.5370494720991701, "Avg policy loss": 0.2988814760465175, "Total num played games": 46512, "Total num trained steps": 92416, "Timestamp in ms": 1701936694119, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 81.07422214373946, "Avg game time in secs": 1.7925646427902393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 46592, "Total num trained steps": 92518, "Timestamp in ms": 1701936737993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855604188122211, "Avg loss": 0.6709452581126243, "Avg value loss": 0.380283049918944, "Avg policy loss": 0.2906622054288164, "Total num played games": 46608, "Total num trained steps": 92544, "Timestamp in ms": 1701936748928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883281840027462, "Avg loss": 0.4785271023865789, "Avg value loss": 0.17510228947503492, "Avg policy loss": 0.3034248132025823, "Total num played games": 46608, "Total num trained steps": 92672, "Timestamp in ms": 1701936809949, "logtype": "training_step"}
{"Total num played games": 46608, "Total num trained steps": 92699, "Timestamp in ms": 1701936926500, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.359375}
{"Ratio train steps to played games": 1.9870669350349022, "Avg loss": 0.8400740909855813, "Avg value loss": 0.5351929889002349, "Avg policy loss": 0.30488111288286746, "Total num played games": 46702, "Total num trained steps": 92800, "Timestamp in ms": 1701936973317, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 279.3562350310385, "Avg game time in secs": 1.7853736549732275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.49, "agent_stopped_0": 0.59}, "Total num played games": 46720, "Total num trained steps": 92894, "Timestamp in ms": 1701937017349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985725885721612, "Avg loss": 0.7749149238225073, "Avg value loss": 0.4804751638439484, "Avg policy loss": 0.29443976120091975, "Total num played games": 46798, "Total num trained steps": 92928, "Timestamp in ms": 1701937031742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988461045343818, "Avg loss": 0.47874036827124655, "Avg value loss": 0.1740019476856105, "Avg policy loss": 0.30473842087667435, "Total num played games": 46798, "Total num trained steps": 93056, "Timestamp in ms": 1701937091501, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 88.32443087175488, "Avg game time in secs": 1.7519293035729788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 46848, "Total num trained steps": 93089, "Timestamp in ms": 1701937105674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870985627159126, "Avg loss": 0.7705581721384078, "Avg value loss": 0.47298010456142947, "Avg policy loss": 0.2975780648412183, "Total num played games": 46894, "Total num trained steps": 93184, "Timestamp in ms": 1701937146186, "logtype": "training_step"}
{"Avg objective": 23.4765625, "Games time in secs": 84.79781479015946, "Avg game time in secs": 1.9752585221722256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.67}, "Total num played games": 46976, "Total num trained steps": 93283, "Timestamp in ms": 1701937190472, "logtype": "played_game"}
{"Total num played games": 46988, "Total num trained steps": 93303, "Timestamp in ms": 1701937281628, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.11328125}
{"Ratio train steps to played games": 1.9819668649107902, "Avg loss": 0.9181312718428671, "Avg value loss": 0.6265483781462535, "Avg policy loss": 0.2915828882250935, "Total num played games": 47080, "Total num trained steps": 93312, "Timestamp in ms": 1701937286378, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846013338430823, "Avg loss": 0.9045637887902558, "Avg value loss": 0.5609711908036843, "Avg policy loss": 0.3435925969388336, "Total num played games": 47082, "Total num trained steps": 93440, "Timestamp in ms": 1701937341806, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873412344420374, "Avg loss": 0.4062627220991999, "Avg value loss": 0.10690935933962464, "Avg policy loss": 0.29935336438938975, "Total num played games": 47082, "Total num trained steps": 93568, "Timestamp in ms": 1701937399275, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 247.2336871214211, "Avg game time in secs": 1.7358386589039583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.43, "agent_stopped_0": 0.67}, "Total num played games": 47104, "Total num trained steps": 93656, "Timestamp in ms": 1701937437705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860946243852806, "Avg loss": 0.6937396952416748, "Avg value loss": 0.41074487727019005, "Avg policy loss": 0.2829948227154091, "Total num played games": 47176, "Total num trained steps": 93696, "Timestamp in ms": 1701937455535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887235575904023, "Avg loss": 0.4542390778660774, "Avg value loss": 0.15664363792166114, "Avg policy loss": 0.2975954393623397, "Total num played games": 47178, "Total num trained steps": 93824, "Timestamp in ms": 1701937514602, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 88.14410466328263, "Avg game time in secs": 2.0078366157831624, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.5}, "Total num played games": 47232, "Total num trained steps": 93850, "Timestamp in ms": 1701937525850, "logtype": "played_game"}
{"Total num played games": 47272, "Total num trained steps": 93907, "Timestamp in ms": 1701937614254, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3828125}
{"Avg objective": 22.1328125, "Games time in secs": 92.07277893647552, "Avg game time in secs": 1.851687172165839, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 47360, "Total num trained steps": 93914, "Timestamp in ms": 1701937617923, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835113794705064, "Avg loss": 1.1145921302959323, "Avg value loss": 0.7958203869930003, "Avg policy loss": 0.31877174507826567, "Total num played games": 47366, "Total num trained steps": 93952, "Timestamp in ms": 1701937633256, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862348520035469, "Avg loss": 0.4415025969501585, "Avg value loss": 0.1390522023430094, "Avg policy loss": 0.3024503914639354, "Total num played games": 47366, "Total num trained steps": 94080, "Timestamp in ms": 1701937689366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889372123464089, "Avg loss": 0.3488323820056394, "Avg value loss": 0.07331505691399798, "Avg policy loss": 0.27551732619758695, "Total num played games": 47366, "Total num trained steps": 94208, "Timestamp in ms": 1701937748448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876111415448148, "Avg loss": 0.8453664598055184, "Avg value loss": 0.5407513490354177, "Avg policy loss": 0.3046151070157066, "Total num played games": 47462, "Total num trained steps": 94336, "Timestamp in ms": 1701937807245, "logtype": "training_step"}
{"Avg objective": 22.515625, "Games time in secs": 224.1780385300517, "Avg game time in secs": 1.6923135923570953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.44, "agent_stopped_0": 0.62}, "Total num played games": 47488, "Total num trained steps": 94415, "Timestamp in ms": 1701937842102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863739591218774, "Avg loss": 0.7171449451707304, "Avg value loss": 0.4143663124414161, "Avg policy loss": 0.30277862632647157, "Total num played games": 47556, "Total num trained steps": 94464, "Timestamp in ms": 1701937863360, "logtype": "training_step"}
{"Total num played games": 47556, "Total num trained steps": 94510, "Timestamp in ms": 1701937944957, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.98046875}
{"Avg objective": 22.28125, "Games time in secs": 105.28796927630901, "Avg game time in secs": 1.671488303662045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 47616, "Total num trained steps": 94515, "Timestamp in ms": 1701937947390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851416579223504, "Avg loss": 0.763780212495476, "Avg value loss": 0.4426974555826746, "Avg policy loss": 0.32108275534119457, "Total num played games": 47650, "Total num trained steps": 94592, "Timestamp in ms": 1701937979642, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878279118572928, "Avg loss": 0.38627849961631, "Avg value loss": 0.09222996805328876, "Avg policy loss": 0.2940485312137753, "Total num played games": 47650, "Total num trained steps": 94720, "Timestamp in ms": 1701938030189, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 113.86927537620068, "Avg game time in secs": 1.8869516175473109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 47744, "Total num trained steps": 94798, "Timestamp in ms": 1701938061260, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865119591169942, "Avg loss": 0.6571485798340291, "Avg value loss": 0.37007098420872353, "Avg policy loss": 0.2870775953633711, "Total num played games": 47746, "Total num trained steps": 94848, "Timestamp in ms": 1701938081103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891928119633058, "Avg loss": 0.38553400337696075, "Avg value loss": 0.10099215264199302, "Avg policy loss": 0.28454184881411493, "Total num played games": 47746, "Total num trained steps": 94976, "Timestamp in ms": 1701938132699, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879598662207358, "Avg loss": 0.7198807045351714, "Avg value loss": 0.4154235152818728, "Avg policy loss": 0.30445718741975725, "Total num played games": 47840, "Total num trained steps": 95104, "Timestamp in ms": 1701938184287, "logtype": "training_step"}
{"Total num played games": 47840, "Total num trained steps": 95113, "Timestamp in ms": 1701938298121, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.63671875}
{"Avg objective": 21.6484375, "Games time in secs": 238.86287765577435, "Avg game time in secs": 1.8520463681197725, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.43, "agent_stopped_0": 0.61}, "Total num played games": 47872, "Total num trained steps": 95118, "Timestamp in ms": 1701938300123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867317561647264, "Avg loss": 0.6784087475389242, "Avg value loss": 0.37327061651740223, "Avg policy loss": 0.30513813195284456, "Total num played games": 47934, "Total num trained steps": 95232, "Timestamp in ms": 1701938345103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893190921228305, "Avg loss": 0.3642834252677858, "Avg value loss": 0.08047715155407786, "Avg policy loss": 0.28380627604201436, "Total num played games": 47936, "Total num trained steps": 95360, "Timestamp in ms": 1701938396518, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 97.60006763413548, "Avg game time in secs": 1.8384276684955694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 48000, "Total num trained steps": 95363, "Timestamp in ms": 1701938397723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880079946702198, "Avg loss": 0.6835190334822983, "Avg value loss": 0.36928601504769176, "Avg policy loss": 0.3142330222763121, "Total num played games": 48032, "Total num trained steps": 95488, "Timestamp in ms": 1701938447927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867846901882558, "Avg loss": 0.747078642481938, "Avg value loss": 0.4416981123504229, "Avg policy loss": 0.3053805340314284, "Total num played games": 48126, "Total num trained steps": 95616, "Timestamp in ms": 1701938497583, "logtype": "training_step"}
{"Total num played games": 48126, "Total num trained steps": 95715, "Timestamp in ms": 1701938627492, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0625}
{"Avg objective": 21.3203125, "Games time in secs": 230.5397973842919, "Avg game time in secs": 2.0514738041965757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 48128, "Total num trained steps": 95716, "Timestamp in ms": 1701938628263, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855454168394857, "Avg loss": 0.6892969664186239, "Avg value loss": 0.3849370303796604, "Avg policy loss": 0.3043599381344393, "Total num played games": 48220, "Total num trained steps": 95744, "Timestamp in ms": 1701938638945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881999170468685, "Avg loss": 0.4865953382104635, "Avg value loss": 0.1795074497931637, "Avg policy loss": 0.30708788812626153, "Total num played games": 48220, "Total num trained steps": 95872, "Timestamp in ms": 1701938691433, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 87.55968459323049, "Avg game time in secs": 1.6844088858051691, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 48256, "Total num trained steps": 95933, "Timestamp in ms": 1701938715823, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870016972306164, "Avg loss": 0.6363455613609403, "Avg value loss": 0.3342812685004901, "Avg policy loss": 0.3020642977207899, "Total num played games": 48314, "Total num trained steps": 96000, "Timestamp in ms": 1701938742414, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 76.0664101690054, "Avg game time in secs": 1.914252978778677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 48384, "Total num trained steps": 96123, "Timestamp in ms": 1701938791889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857874731449348, "Avg loss": 0.48762369924224913, "Avg value loss": 0.18894504057243466, "Avg policy loss": 0.29867865808773786, "Total num played games": 48408, "Total num trained steps": 96128, "Timestamp in ms": 1701938793727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884316641877375, "Avg loss": 0.708265133202076, "Avg value loss": 0.3973786885617301, "Avg policy loss": 0.3108864459209144, "Total num played games": 48408, "Total num trained steps": 96256, "Timestamp in ms": 1701938846093, "logtype": "training_step"}
{"Total num played games": 48504, "Total num trained steps": 96318, "Timestamp in ms": 1701938941897, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.19921875}
{"Avg objective": 22.0390625, "Games time in secs": 151.6536367163062, "Avg game time in secs": 1.8871487948927097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.61}, "Total num played games": 48512, "Total num trained steps": 96321, "Timestamp in ms": 1701938943543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832914934770978, "Avg loss": 1.1303333622636274, "Avg value loss": 0.8163015817990527, "Avg policy loss": 0.3140317896613851, "Total num played games": 48598, "Total num trained steps": 96384, "Timestamp in ms": 1701938967834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859253467220874, "Avg loss": 0.4343879499938339, "Avg value loss": 0.13052440452156588, "Avg policy loss": 0.30386354902293533, "Total num played games": 48598, "Total num trained steps": 96512, "Timestamp in ms": 1701939017916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885591999670769, "Avg loss": 0.3566946731880307, "Avg value loss": 0.07748681629891507, "Avg policy loss": 0.27920785814058036, "Total num played games": 48598, "Total num trained steps": 96640, "Timestamp in ms": 1701939068539, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 143.92497595772147, "Avg game time in secs": 1.7175195299787447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 48640, "Total num trained steps": 96690, "Timestamp in ms": 1701939087468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873285139242587, "Avg loss": 0.7852534013800323, "Avg value loss": 0.4822467442427296, "Avg policy loss": 0.30300665087997913, "Total num played games": 48692, "Total num trained steps": 96768, "Timestamp in ms": 1701939118360, "logtype": "training_step"}
{"Avg objective": 22.7265625, "Games time in secs": 73.3006609454751, "Avg game time in secs": 2.054403171670856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.61}, "Total num played games": 48768, "Total num trained steps": 96880, "Timestamp in ms": 1701939160769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98606214642945, "Avg loss": 0.6465786860790104, "Avg value loss": 0.34137222295976244, "Avg policy loss": 0.3052064647199586, "Total num played games": 48788, "Total num trained steps": 96896, "Timestamp in ms": 1701939167144, "logtype": "training_step"}
{"Total num played games": 48788, "Total num trained steps": 96920, "Timestamp in ms": 1701939282132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.66796875}
{"Ratio train steps to played games": 1.9848615032118162, "Avg loss": 1.0247147136833519, "Avg value loss": 0.6636092766420916, "Avg policy loss": 0.3611054257489741, "Total num played games": 48882, "Total num trained steps": 97024, "Timestamp in ms": 1701939323473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98748005400761, "Avg loss": 0.41644825716502964, "Avg value loss": 0.09598469387856312, "Avg policy loss": 0.3204635645961389, "Total num played games": 48882, "Total num trained steps": 97152, "Timestamp in ms": 1701939373446, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 253.51637378707528, "Avg game time in secs": 2.124088327109348, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 48896, "Total num trained steps": 97256, "Timestamp in ms": 1701939414285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862789937928782, "Avg loss": 0.6524389912374318, "Avg value loss": 0.34820368071086705, "Avg policy loss": 0.30423531343694776, "Total num played games": 48976, "Total num trained steps": 97280, "Timestamp in ms": 1701939423805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888721006207122, "Avg loss": 0.6356880655512214, "Avg value loss": 0.32046579601592384, "Avg policy loss": 0.31522227253299206, "Total num played games": 48976, "Total num trained steps": 97408, "Timestamp in ms": 1701939473263, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 73.69955795630813, "Avg game time in secs": 1.8270191187330056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 49024, "Total num trained steps": 97446, "Timestamp in ms": 1701939487985, "logtype": "played_game"}
{"Total num played games": 49070, "Total num trained steps": 97521, "Timestamp in ms": 1701939576710, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3359375}
{"Avg objective": 22.6328125, "Games time in secs": 92.20889105275273, "Avg game time in secs": 1.96866115796729, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 49152, "Total num trained steps": 97528, "Timestamp in ms": 1701939580194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839510190797771, "Avg loss": 0.966366728534922, "Avg value loss": 0.6510541108145844, "Avg policy loss": 0.31531261396594346, "Total num played games": 49162, "Total num trained steps": 97536, "Timestamp in ms": 1701939583041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864941827353348, "Avg loss": 0.706247630994767, "Avg value loss": 0.373599135724362, "Avg policy loss": 0.33264850184787065, "Total num played games": 49164, "Total num trained steps": 97664, "Timestamp in ms": 1701939635703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890773736880645, "Avg loss": 0.3854439731221646, "Avg value loss": 0.08612648144480772, "Avg policy loss": 0.29931749182287604, "Total num played games": 49164, "Total num trained steps": 97792, "Timestamp in ms": 1701939686274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879004425677047, "Avg loss": 0.7036071587353945, "Avg value loss": 0.3890944294689689, "Avg policy loss": 0.3145127303432673, "Total num played games": 49258, "Total num trained steps": 97920, "Timestamp in ms": 1701939736912, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 190.91317339986563, "Avg game time in secs": 2.1174410674429964, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.61, "agent_stopped_0": 0.49}, "Total num played games": 49280, "Total num trained steps": 98009, "Timestamp in ms": 1701939771108, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986687469606095, "Avg loss": 0.6438927017152309, "Avg value loss": 0.3282971321605146, "Avg policy loss": 0.3155955709517002, "Total num played games": 49352, "Total num trained steps": 98048, "Timestamp in ms": 1701939787026, "logtype": "training_step"}
{"Total num played games": 49352, "Total num trained steps": 98123, "Timestamp in ms": 1701939895089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.11328125}
{"Avg objective": 21.4140625, "Games time in secs": 126.4926594235003, "Avg game time in secs": 1.8467491523188073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 49408, "Total num trained steps": 98128, "Timestamp in ms": 1701939897601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985519556688104, "Avg loss": 0.7702660309150815, "Avg value loss": 0.45178084581857547, "Avg policy loss": 0.3184851830592379, "Total num played games": 49446, "Total num trained steps": 98176, "Timestamp in ms": 1701939916643, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988108239291348, "Avg loss": 0.41970596788451076, "Avg value loss": 0.10809986837557517, "Avg policy loss": 0.31160609843209386, "Total num played games": 49446, "Total num trained steps": 98304, "Timestamp in ms": 1701939967143, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 102.79405995458364, "Avg game time in secs": 1.936162452911958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 49536, "Total num trained steps": 98389, "Timestamp in ms": 1701940000395, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868994751715785, "Avg loss": 0.6232089262921363, "Avg value loss": 0.31900201286771335, "Avg policy loss": 0.3042069122893736, "Total num played games": 49540, "Total num trained steps": 98432, "Timestamp in ms": 1701940017540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989503431570448, "Avg loss": 0.39349179877899587, "Avg value loss": 0.09502721644821577, "Avg policy loss": 0.2984645807882771, "Total num played games": 49540, "Total num trained steps": 98560, "Timestamp in ms": 1701940066460, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883144618608213, "Avg loss": 0.8788367116358131, "Avg value loss": 0.5650759873678908, "Avg policy loss": 0.3137607276439667, "Total num played games": 49634, "Total num trained steps": 98688, "Timestamp in ms": 1701940117696, "logtype": "training_step"}
{"Total num played games": 49634, "Total num trained steps": 98728, "Timestamp in ms": 1701940206687, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66015625}
{"Avg objective": 21.84375, "Games time in secs": 208.25142174586654, "Avg game time in secs": 1.7285443758883048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 49664, "Total num trained steps": 98730, "Timestamp in ms": 1701940208647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871299871299872, "Avg loss": 0.799515507882461, "Avg value loss": 0.4898236097651534, "Avg policy loss": 0.30969190155155957, "Total num played games": 49728, "Total num trained steps": 98816, "Timestamp in ms": 1701940243794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896838803088803, "Avg loss": 0.3759051710367203, "Avg value loss": 0.0925999155442696, "Avg policy loss": 0.2833052558125928, "Total num played games": 49728, "Total num trained steps": 98944, "Timestamp in ms": 1701940294761, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 88.47137505933642, "Avg game time in secs": 1.9000458111113403, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 49792, "Total num trained steps": 98950, "Timestamp in ms": 1701940297119, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988519128096022, "Avg loss": 0.5841754509601742, "Avg value loss": 0.2881474882888142, "Avg policy loss": 0.2960279651451856, "Total num played games": 49822, "Total num trained steps": 99072, "Timestamp in ms": 1701940345349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987338729064829, "Avg loss": 0.736410299083218, "Avg value loss": 0.44043368988786824, "Avg policy loss": 0.2959766078274697, "Total num played games": 49916, "Total num trained steps": 99200, "Timestamp in ms": 1701940396304, "logtype": "training_step"}
{"Avg objective": 22.078125, "Games time in secs": 148.13131837919354, "Avg game time in secs": 2.0231357462180313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.66, "agent_stopped_0": 0.37}, "Total num played games": 49920, "Total num trained steps": 99323, "Timestamp in ms": 1701940445251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986142771445711, "Avg loss": 0.39602863299660385, "Avg value loss": 0.10685799404745921, "Avg policy loss": 0.28917063889093697, "Total num played games": 49996, "Total num trained steps": 99328, "Timestamp in ms": 1701940449051, "logtype": "training_step"}
{"Total num played games": 50010, "Total num trained steps": 99328, "Timestamp in ms": 1701940506937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.28125}
{"Avg objective": 21.015625, "Games time in secs": 63.66863784939051, "Avg game time in secs": 1.6101183771970682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.34}, "Total num played games": 50048, "Total num trained steps": 99331, "Timestamp in ms": 1701940508920, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849912182660068, "Avg loss": 1.0910245922859758, "Avg value loss": 0.7652974432567134, "Avg policy loss": 0.32572714146226645, "Total num played games": 50104, "Total num trained steps": 99456, "Timestamp in ms": 1701940558548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875459045186012, "Avg loss": 0.3685410547768697, "Avg value loss": 0.08369491863413714, "Avg policy loss": 0.28484613623004407, "Total num played games": 50104, "Total num trained steps": 99584, "Timestamp in ms": 1701940607709, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 145.88680209964514, "Avg game time in secs": 1.789611740357941, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 50176, "Total num trained steps": 99702, "Timestamp in ms": 1701940654807, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862948207171314, "Avg loss": 0.6025145128369331, "Avg value loss": 0.31999143832945265, "Avg policy loss": 0.28252307267393917, "Total num played games": 50200, "Total num trained steps": 99712, "Timestamp in ms": 1701940658653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888446215139441, "Avg loss": 0.7009560968726873, "Avg value loss": 0.3832574994303286, "Avg policy loss": 0.31769860710483044, "Total num played games": 50200, "Total num trained steps": 99840, "Timestamp in ms": 1701940707390, "logtype": "training_step"}
{"Total num played games": 50294, "Total num trained steps": 99933, "Timestamp in ms": 1701940814199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.65625}
{"Avg objective": 22.4375, "Games time in secs": 161.04497859999537, "Avg game time in secs": 1.880426303978311, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 50304, "Total num trained steps": 99934, "Timestamp in ms": 1701940815852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839445899817416, "Avg loss": 1.2735144109465182, "Avg value loss": 0.9652443928353023, "Avg policy loss": 0.308270042296499, "Total num played games": 50388, "Total num trained steps": 99968, "Timestamp in ms": 1701940829329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865047233468287, "Avg loss": 0.48725218372419477, "Avg value loss": 0.18022757262224331, "Avg policy loss": 0.307024612207897, "Total num played games": 50388, "Total num trained steps": 100096, "Timestamp in ms": 1701940879489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890450107168374, "Avg loss": 0.3616821067407727, "Avg value loss": 0.08261097955983132, "Avg policy loss": 0.2790711246198043, "Total num played games": 50388, "Total num trained steps": 100224, "Timestamp in ms": 1701940931384, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 132.79040138050914, "Avg game time in secs": 1.732828750333283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 50432, "Total num trained steps": 100270, "Timestamp in ms": 1701940948643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878768670020999, "Avg loss": 0.7413589488714933, "Avg value loss": 0.45646385531290434, "Avg policy loss": 0.2848950973711908, "Total num played games": 50482, "Total num trained steps": 100352, "Timestamp in ms": 1701940980130, "logtype": "training_step"}
{"Avg objective": 22.4375, "Games time in secs": 73.59604414179921, "Avg game time in secs": 1.8856811060686596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 50560, "Total num trained steps": 100460, "Timestamp in ms": 1701941022239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867130654856058, "Avg loss": 0.6428163331001997, "Avg value loss": 0.3615670324070379, "Avg policy loss": 0.2812492987141013, "Total num played games": 50576, "Total num trained steps": 100480, "Timestamp in ms": 1701941029778, "logtype": "training_step"}
{"Total num played games": 50576, "Total num trained steps": 100534, "Timestamp in ms": 1701941110678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.45703125}
{"Ratio train steps to played games": 1.9855338464574699, "Avg loss": 1.0234301313757896, "Avg value loss": 0.7027819670620374, "Avg policy loss": 0.3206481746165082, "Total num played games": 50670, "Total num trained steps": 100608, "Timestamp in ms": 1701941140065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880599960528913, "Avg loss": 0.40494598308578134, "Avg value loss": 0.11241765340673737, "Avg policy loss": 0.29252833186183125, "Total num played games": 50670, "Total num trained steps": 100736, "Timestamp in ms": 1701941190832, "logtype": "training_step"}
{"Avg objective": 23.0546875, "Games time in secs": 207.26637820526958, "Avg game time in secs": 1.8740810894523747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 50688, "Total num trained steps": 100832, "Timestamp in ms": 1701941229505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868415868888627, "Avg loss": 0.7400042400695384, "Avg value loss": 0.4485724029073026, "Avg policy loss": 0.29143182549159974, "Total num played games": 50766, "Total num trained steps": 100864, "Timestamp in ms": 1701941241213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893629594610567, "Avg loss": 0.4364996924996376, "Avg value loss": 0.14820262393914163, "Avg policy loss": 0.28829706821125, "Total num played games": 50766, "Total num trained steps": 100992, "Timestamp in ms": 1701941291445, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 74.93184467405081, "Avg game time in secs": 1.688525429170113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 50816, "Total num trained steps": 101025, "Timestamp in ms": 1701941304437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881247296606503, "Avg loss": 0.62799509963952, "Avg value loss": 0.3329843430838082, "Avg policy loss": 0.29501074843574315, "Total num played games": 50862, "Total num trained steps": 101120, "Timestamp in ms": 1701941342958, "logtype": "training_step"}
{"Total num played games": 50862, "Total num trained steps": 101136, "Timestamp in ms": 1701941421071, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.68359375}
{"Avg objective": 21.0859375, "Games time in secs": 119.75999672338367, "Avg game time in secs": 1.8000113283633254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 50944, "Total num trained steps": 101142, "Timestamp in ms": 1701941424197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869495250804616, "Avg loss": 0.9712338850367814, "Avg value loss": 0.6635472921770997, "Avg policy loss": 0.3076865803450346, "Total num played games": 50956, "Total num trained steps": 101248, "Timestamp in ms": 1701941466884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894811209671088, "Avg loss": 0.35332567687146366, "Avg value loss": 0.07667808618862182, "Avg policy loss": 0.2766475873067975, "Total num played games": 50956, "Total num trained steps": 101376, "Timestamp in ms": 1701941517981, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883251714005876, "Avg loss": 0.7182090706191957, "Avg value loss": 0.4379165768623352, "Avg policy loss": 0.28029249026440084, "Total num played games": 51050, "Total num trained steps": 101504, "Timestamp in ms": 1701941567887, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 178.59326111897826, "Avg game time in secs": 1.7509990071703214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.44, "agent_stopped_0": 0.6}, "Total num played games": 51072, "Total num trained steps": 101593, "Timestamp in ms": 1701941602791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871734709838886, "Avg loss": 0.7232219283469021, "Avg value loss": 0.4470027002389543, "Avg policy loss": 0.27621923154219985, "Total num played games": 51144, "Total num trained steps": 101632, "Timestamp in ms": 1701941618244, "logtype": "training_step"}
{"Total num played games": 51144, "Total num trained steps": 101736, "Timestamp in ms": 1701941743871, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.03515625}
{"Avg objective": 22.4296875, "Games time in secs": 143.41052620485425, "Avg game time in secs": 1.6947276827704627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 51200, "Total num trained steps": 101739, "Timestamp in ms": 1701941746201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860259963308482, "Avg loss": 0.6372780282981694, "Avg value loss": 0.3593676660093479, "Avg policy loss": 0.2779103646753356, "Total num played games": 51238, "Total num trained steps": 101760, "Timestamp in ms": 1701941754284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885241422381825, "Avg loss": 0.4835842924658209, "Avg value loss": 0.19792956270975992, "Avg policy loss": 0.28565472993068397, "Total num played games": 51238, "Total num trained steps": 101888, "Timestamp in ms": 1701941806475, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 92.59273846819997, "Avg game time in secs": 1.7787249096436426, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 51328, "Total num trained steps": 101972, "Timestamp in ms": 1701941838794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872988662484903, "Avg loss": 0.6656262914184481, "Avg value loss": 0.39220858868793584, "Avg policy loss": 0.27341769996564835, "Total num played games": 51334, "Total num trained steps": 102016, "Timestamp in ms": 1701941855889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989772860092726, "Avg loss": 0.39112986891996115, "Avg value loss": 0.11454725457588211, "Avg policy loss": 0.27658261312171817, "Total num played games": 51334, "Total num trained steps": 102144, "Timestamp in ms": 1701941907907, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988644318270203, "Avg loss": 0.6191315290052444, "Avg value loss": 0.33334038354223594, "Avg policy loss": 0.2857911476166919, "Total num played games": 51428, "Total num trained steps": 102272, "Timestamp in ms": 1701941958285, "logtype": "training_step"}
{"Total num played games": 51428, "Total num trained steps": 102338, "Timestamp in ms": 1701942061990, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.703125}
{"Avg objective": 20.28125, "Games time in secs": 225.25227627903223, "Avg game time in secs": 1.6584317646629643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.43, "agent_stopped_0": 0.61}, "Total num played games": 51456, "Total num trained steps": 102340, "Timestamp in ms": 1701942064047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874810760451846, "Avg loss": 0.8358754735672846, "Avg value loss": 0.5538208707293961, "Avg policy loss": 0.28205460275057703, "Total num played games": 51522, "Total num trained steps": 102400, "Timestamp in ms": 1701942088429, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899848608361477, "Avg loss": 0.38396074576303363, "Avg value loss": 0.10343819609261118, "Avg policy loss": 0.2805225485935807, "Total num played games": 51522, "Total num trained steps": 102528, "Timestamp in ms": 1701942139102, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 79.03237245604396, "Avg game time in secs": 1.7523301058099605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 51584, "Total num trained steps": 102538, "Timestamp in ms": 1701942143079, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888406695598264, "Avg loss": 0.7798158305231482, "Avg value loss": 0.4805260880966671, "Avg policy loss": 0.299289743299596, "Total num played games": 51616, "Total num trained steps": 102656, "Timestamp in ms": 1701942190203, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877006381744344, "Avg loss": 0.6239229573402554, "Avg value loss": 0.3334347067575436, "Avg policy loss": 0.2904882513685152, "Total num played games": 51710, "Total num trained steps": 102784, "Timestamp in ms": 1701942240873, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 146.49767354875803, "Avg game time in secs": 1.9045736345869955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.61, "agent_stopped_0": 0.51}, "Total num played games": 51712, "Total num trained steps": 102909, "Timestamp in ms": 1701942289577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898681310182142, "Avg loss": 0.3856368334963918, "Avg value loss": 0.10355411368072964, "Avg policy loss": 0.28208271926268935, "Total num played games": 51718, "Total num trained steps": 102912, "Timestamp in ms": 1701942290382, "logtype": "training_step"}
{"Total num played games": 51806, "Total num trained steps": 102942, "Timestamp in ms": 1701942371546, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3203125}
{"Avg objective": 21.1796875, "Games time in secs": 83.94833089783788, "Avg game time in secs": 1.6986741551372688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 51840, "Total num trained steps": 102945, "Timestamp in ms": 1701942373525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853564547206166, "Avg loss": 1.1588751228991896, "Avg value loss": 0.8362880956265144, "Avg policy loss": 0.32258701778482646, "Total num played games": 51900, "Total num trained steps": 103040, "Timestamp in ms": 1701942410454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878227360308285, "Avg loss": 0.3850734138395637, "Avg value loss": 0.10748949873959646, "Avg policy loss": 0.27758391678798944, "Total num played games": 51900, "Total num trained steps": 103168, "Timestamp in ms": 1701942462046, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 136.17849260941148, "Avg game time in secs": 1.7177946744777728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.47, "agent_stopped_0": 0.58}, "Total num played games": 51968, "Total num trained steps": 103294, "Timestamp in ms": 1701942509707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987206617929973, "Avg loss": 0.3755651598330587, "Avg value loss": 0.11209134192904457, "Avg policy loss": 0.263473815866746, "Total num played games": 51980, "Total num trained steps": 103296, "Timestamp in ms": 1701942510171, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890760827755982, "Avg loss": 0.5751215786440298, "Avg value loss": 0.29714647360378876, "Avg policy loss": 0.2779751045163721, "Total num played games": 51996, "Total num trained steps": 103424, "Timestamp in ms": 1701942560399, "logtype": "training_step"}
{"Total num played games": 52090, "Total num trained steps": 103545, "Timestamp in ms": 1701942702630, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.171875}
{"Avg objective": 20.75, "Games time in secs": 194.53114710375667, "Avg game time in secs": 1.768368929188, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 52096, "Total num trained steps": 103548, "Timestamp in ms": 1701942704238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850477322393896, "Avg loss": 0.6300542519893497, "Avg value loss": 0.3525926204456482, "Avg policy loss": 0.2774616322712973, "Total num played games": 52166, "Total num trained steps": 103552, "Timestamp in ms": 1701942705628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868158822627626, "Avg loss": 0.6886087036691606, "Avg value loss": 0.3902831955929287, "Avg policy loss": 0.2983255092985928, "Total num played games": 52184, "Total num trained steps": 103680, "Timestamp in ms": 1701942757565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892687413766672, "Avg loss": 0.35702817514538765, "Avg value loss": 0.08180688909487799, "Avg policy loss": 0.2752212875057012, "Total num played games": 52184, "Total num trained steps": 103808, "Timestamp in ms": 1701942809835, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 126.04814683273435, "Avg game time in secs": 1.6352256663376465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 52224, "Total num trained steps": 103861, "Timestamp in ms": 1701942830286, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880642693190513, "Avg loss": 0.9291372824227437, "Avg value loss": 0.6348601864010561, "Avg policy loss": 0.29427710419986397, "Total num played games": 52280, "Total num trained steps": 103936, "Timestamp in ms": 1701942860609, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 77.83164005726576, "Avg game time in secs": 1.7517425746482331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 52352, "Total num trained steps": 104055, "Timestamp in ms": 1701942908118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869400847748884, "Avg loss": 0.5042211718391627, "Avg value loss": 0.21310134819941595, "Avg policy loss": 0.2911198188085109, "Total num played games": 52374, "Total num trained steps": 104064, "Timestamp in ms": 1701942911506, "logtype": "training_step"}
{"Total num played games": 52374, "Total num trained steps": 104146, "Timestamp in ms": 1701943031402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.01953125}
{"Ratio train steps to played games": 1.9858199283372722, "Avg loss": 0.7768522379919887, "Avg value loss": 0.4704748412477784, "Avg policy loss": 0.3063773970352486, "Total num played games": 52468, "Total num trained steps": 104192, "Timestamp in ms": 1701943050577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882595105588168, "Avg loss": 0.3988111566286534, "Avg value loss": 0.10338140890235081, "Avg policy loss": 0.2954297480173409, "Total num played games": 52468, "Total num trained steps": 104320, "Timestamp in ms": 1701943102792, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 237.5386631116271, "Avg game time in secs": 1.9508515066409018, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.61}, "Total num played games": 52480, "Total num trained steps": 104428, "Timestamp in ms": 1701943145657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869877867823307, "Avg loss": 0.5821451555239037, "Avg value loss": 0.2963814423128497, "Avg policy loss": 0.2857637086417526, "Total num played games": 52566, "Total num trained steps": 104448, "Timestamp in ms": 1701943153211, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894228208347602, "Avg loss": 0.5341421528719366, "Avg value loss": 0.21523535987944342, "Avg policy loss": 0.318906792672351, "Total num played games": 52566, "Total num trained steps": 104576, "Timestamp in ms": 1701943203293, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 77.29266780987382, "Avg game time in secs": 1.8380834632844198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 52608, "Total num trained steps": 104625, "Timestamp in ms": 1701943222949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988226804906764, "Avg loss": 0.8105369354598224, "Avg value loss": 0.49126953206723556, "Avg policy loss": 0.3192674112506211, "Total num played games": 52662, "Total num trained steps": 104704, "Timestamp in ms": 1701943252975, "logtype": "training_step"}
{"Total num played games": 52662, "Total num trained steps": 104749, "Timestamp in ms": 1701943336987, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4921875}
{"Avg objective": 20.953125, "Games time in secs": 117.04219509288669, "Avg game time in secs": 1.765591498464346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 52736, "Total num trained steps": 104753, "Timestamp in ms": 1701943339992, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871104708469178, "Avg loss": 0.6293695287313312, "Avg value loss": 0.30439116968773305, "Avg policy loss": 0.3249783634673804, "Total num played games": 52756, "Total num trained steps": 104832, "Timestamp in ms": 1701943371560, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895367351580864, "Avg loss": 0.3764359641354531, "Avg value loss": 0.084474416624289, "Avg policy loss": 0.2919615476857871, "Total num played games": 52756, "Total num trained steps": 104960, "Timestamp in ms": 1701943422223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884200567644277, "Avg loss": 0.7997568864375353, "Avg value loss": 0.4900587529700715, "Avg policy loss": 0.3096981266280636, "Total num played games": 52850, "Total num trained steps": 105088, "Timestamp in ms": 1701943471503, "logtype": "training_step"}
{"Avg objective": 22.7421875, "Games time in secs": 173.63836501538754, "Avg game time in secs": 1.8866858383407816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 52864, "Total num trained steps": 105192, "Timestamp in ms": 1701943513630, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873073436083408, "Avg loss": 0.6559073268435895, "Avg value loss": 0.3445784472860396, "Avg policy loss": 0.31132887897547334, "Total num played games": 52944, "Total num trained steps": 105216, "Timestamp in ms": 1701943522815, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897249924448475, "Avg loss": 0.502599198371172, "Avg value loss": 0.18381510878680274, "Avg policy loss": 0.31878408906050026, "Total num played games": 52944, "Total num trained steps": 105344, "Timestamp in ms": 1701943572606, "logtype": "training_step"}
{"Total num played games": 52944, "Total num trained steps": 105352, "Timestamp in ms": 1701943637501, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5546875}
{"Avg objective": 21.9375, "Games time in secs": 126.0231255479157, "Avg game time in secs": 1.6680072438612115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 52992, "Total num trained steps": 105355, "Timestamp in ms": 1701943639653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886119386100531, "Avg loss": 1.1944483679253608, "Avg value loss": 0.8822442678792868, "Avg policy loss": 0.3122040826128796, "Total num played games": 53038, "Total num trained steps": 105472, "Timestamp in ms": 1701943685470, "logtype": "training_step"}
{"Avg objective": 22.390625, "Games time in secs": 84.65879301354289, "Avg game time in secs": 1.8118514606612734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 53120, "Total num trained steps": 105571, "Timestamp in ms": 1701943724312, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987428012195581, "Avg loss": 0.6569639386143535, "Avg value loss": 0.34185848708148114, "Avg policy loss": 0.3151054517365992, "Total num played games": 53134, "Total num trained steps": 105600, "Timestamp in ms": 1701943735172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898370158467271, "Avg loss": 0.4713486498221755, "Avg value loss": 0.14609073431347497, "Avg policy loss": 0.32525791588705033, "Total num played games": 53134, "Total num trained steps": 105728, "Timestamp in ms": 1701943784094, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887277372811303, "Avg loss": 0.7154511860571802, "Avg value loss": 0.39589838846586645, "Avg policy loss": 0.3195527909556404, "Total num played games": 53228, "Total num trained steps": 105856, "Timestamp in ms": 1701943834322, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 146.7509749904275, "Avg game time in secs": 1.7760105493362062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 53248, "Total num trained steps": 105949, "Timestamp in ms": 1701943871063, "logtype": "played_game"}
{"Total num played games": 53322, "Total num trained steps": 105952, "Timestamp in ms": 1701943943837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.70703125}
{"Avg objective": 21.0, "Games time in secs": 75.08295280113816, "Avg game time in secs": 1.7757328822626732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 53376, "Total num trained steps": 105955, "Timestamp in ms": 1701943946146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984124606859368, "Avg loss": 0.9974298423621804, "Avg value loss": 0.6760313757986296, "Avg policy loss": 0.3213984608883038, "Total num played games": 53416, "Total num trained steps": 105984, "Timestamp in ms": 1701943956922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865208926164446, "Avg loss": 0.5672667960170656, "Avg value loss": 0.2392552248784341, "Avg policy loss": 0.32801156549248844, "Total num played games": 53416, "Total num trained steps": 106112, "Timestamp in ms": 1701944005943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988917178373521, "Avg loss": 0.3924273578450084, "Avg value loss": 0.09062429392361082, "Avg policy loss": 0.3018030624371022, "Total num played games": 53416, "Total num trained steps": 106240, "Timestamp in ms": 1701944057084, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 145.42837787047029, "Avg game time in secs": 1.9341640676138923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 53504, "Total num trained steps": 106329, "Timestamp in ms": 1701944091575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878153616146514, "Avg loss": 0.595988648943603, "Avg value loss": 0.2875791323313024, "Avg policy loss": 0.3084095121594146, "Total num played games": 53510, "Total num trained steps": 106368, "Timestamp in ms": 1701944106743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902074378620818, "Avg loss": 0.4105559946037829, "Avg value loss": 0.09494754881598055, "Avg policy loss": 0.315608446020633, "Total num played games": 53510, "Total num trained steps": 106496, "Timestamp in ms": 1701944157097, "logtype": "training_step"}
{"Total num played games": 53604, "Total num trained steps": 106555, "Timestamp in ms": 1701944232364, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.109375}
{"Avg objective": 20.53125, "Games time in secs": 142.9341910816729, "Avg game time in secs": 1.779898564418545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 53632, "Total num trained steps": 106558, "Timestamp in ms": 1701944234509, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856233006815895, "Avg loss": 1.198564208811149, "Avg value loss": 0.8551138965412974, "Avg policy loss": 0.34345032670535147, "Total num played games": 53698, "Total num trained steps": 106624, "Timestamp in ms": 1701944261240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879883794554731, "Avg loss": 0.43320891447365284, "Avg value loss": 0.1136779363732785, "Avg policy loss": 0.3195309777511284, "Total num played games": 53698, "Total num trained steps": 106752, "Timestamp in ms": 1701944312996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903907035643786, "Avg loss": 0.36760184331797063, "Avg value loss": 0.07261415250832215, "Avg policy loss": 0.2949876917991787, "Total num played games": 53698, "Total num trained steps": 106880, "Timestamp in ms": 1701944367832, "logtype": "training_step"}
{"Avg objective": 23.0546875, "Games time in secs": 137.38754266127944, "Avg game time in secs": 1.7870777067437302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 53760, "Total num trained steps": 106890, "Timestamp in ms": 1701944371897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892920880428318, "Avg loss": 0.7375068936962634, "Avg value loss": 0.4197928991052322, "Avg policy loss": 0.31771399453282356, "Total num played games": 53792, "Total num trained steps": 107008, "Timestamp in ms": 1701944420085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881973054225588, "Avg loss": 0.7290252100210637, "Avg value loss": 0.4093696212512441, "Avg policy loss": 0.3196555908070877, "Total num played games": 53886, "Total num trained steps": 107136, "Timestamp in ms": 1701944471915, "logtype": "training_step"}
{"Total num played games": 53886, "Total num trained steps": 107158, "Timestamp in ms": 1701944542474, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0390625}
{"Avg objective": 22.3671875, "Games time in secs": 171.3128929324448, "Avg game time in secs": 2.1404249589540996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 53888, "Total num trained steps": 107158, "Timestamp in ms": 1701944543210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871063356798815, "Avg loss": 0.9213787335902452, "Avg value loss": 0.5631206610123627, "Avg policy loss": 0.35825808136723936, "Total num played games": 53980, "Total num trained steps": 107264, "Timestamp in ms": 1701944584648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989477584290478, "Avg loss": 0.40528205898590386, "Avg value loss": 0.08775663515552878, "Avg policy loss": 0.3175254251109436, "Total num played games": 53980, "Total num trained steps": 107392, "Timestamp in ms": 1701944636906, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 117.18605579808354, "Avg game time in secs": 1.688897664891556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 54016, "Total num trained steps": 107453, "Timestamp in ms": 1701944660396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988386285460665, "Avg loss": 0.7669682695996016, "Avg value loss": 0.44261492282385007, "Avg policy loss": 0.32435334741603583, "Total num played games": 54074, "Total num trained steps": 107520, "Timestamp in ms": 1701944687866, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 74.67956837639213, "Avg game time in secs": 1.6735848493990488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 54144, "Total num trained steps": 107642, "Timestamp in ms": 1701944735076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987225401513753, "Avg loss": 0.48534792801365256, "Avg value loss": 0.16662399846245535, "Avg policy loss": 0.31872392958030105, "Total num played games": 54170, "Total num trained steps": 107648, "Timestamp in ms": 1701944737003, "logtype": "training_step"}
{"Total num played games": 54170, "Total num trained steps": 107759, "Timestamp in ms": 1701944852308, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.234375}
{"Ratio train steps to played games": 1.986123396727112, "Avg loss": 0.8288278270047158, "Avg value loss": 0.4989198529510759, "Avg policy loss": 0.3299079706193879, "Total num played games": 54264, "Total num trained steps": 107776, "Timestamp in ms": 1701944859532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988500663423264, "Avg loss": 0.6683832185808569, "Avg value loss": 0.319985892274417, "Avg policy loss": 0.34839732630643994, "Total num played games": 54264, "Total num trained steps": 107904, "Timestamp in ms": 1701944910153, "logtype": "training_step"}
{"Avg objective": 22.984375, "Games time in secs": 221.50984530895948, "Avg game time in secs": 1.9880079064460006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.69, "agent_stopped_0": 0.41}, "Total num played games": 54272, "Total num trained steps": 108020, "Timestamp in ms": 1701944956586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874167555833548, "Avg loss": 0.5310469684191048, "Avg value loss": 0.21994273259770125, "Avg policy loss": 0.31110423686914146, "Total num played games": 54358, "Total num trained steps": 108032, "Timestamp in ms": 1701944960967, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897715147724346, "Avg loss": 0.5994841028004885, "Avg value loss": 0.26862701095524244, "Avg policy loss": 0.3308570923982188, "Total num played games": 54358, "Total num trained steps": 108160, "Timestamp in ms": 1701945011456, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 74.45789260417223, "Avg game time in secs": 1.7112099135993049, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 54400, "Total num trained steps": 108209, "Timestamp in ms": 1701945031044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885958790906086, "Avg loss": 0.8713428208138794, "Avg value loss": 0.5306404799339361, "Avg policy loss": 0.34070233651436865, "Total num played games": 54454, "Total num trained steps": 108288, "Timestamp in ms": 1701945063063, "logtype": "training_step"}
{"Total num played games": 54454, "Total num trained steps": 108360, "Timestamp in ms": 1701945159685, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9140625}
{"Avg objective": 23.2265625, "Games time in secs": 131.34368458762765, "Avg game time in secs": 1.8861038319009822, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.63, "agent_stopped_0": 0.39}, "Total num played games": 54528, "Total num trained steps": 108365, "Timestamp in ms": 1701945162387, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875339150839628, "Avg loss": 0.7720274860039353, "Avg value loss": 0.4374668045784347, "Avg policy loss": 0.33456068707164377, "Total num played games": 54548, "Total num trained steps": 108416, "Timestamp in ms": 1701945182826, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898621397668108, "Avg loss": 0.42710630572400987, "Avg value loss": 0.09872472457936965, "Avg policy loss": 0.32838158134836704, "Total num played games": 54548, "Total num trained steps": 108544, "Timestamp in ms": 1701945236462, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887998243109697, "Avg loss": 0.7277654251083732, "Avg value loss": 0.3906974280544091, "Avg policy loss": 0.33706798939965665, "Total num played games": 54642, "Total num trained steps": 108672, "Timestamp in ms": 1701945287725, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 166.48237893357873, "Avg game time in secs": 1.8306901220057625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.54, "agent_stopped_0": 0.49}, "Total num played games": 54656, "Total num trained steps": 108776, "Timestamp in ms": 1701945328870, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877228880444315, "Avg loss": 0.6162153801415116, "Avg value loss": 0.29710176135995425, "Avg policy loss": 0.3191136211389676, "Total num played games": 54736, "Total num trained steps": 108800, "Timestamp in ms": 1701945337723, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900613855597777, "Avg loss": 0.47398794908076525, "Avg value loss": 0.15669971774332225, "Avg policy loss": 0.31728823063895106, "Total num played games": 54736, "Total num trained steps": 108928, "Timestamp in ms": 1701945387815, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 72.62748653069139, "Avg game time in secs": 1.7495584418356884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 54784, "Total num trained steps": 108962, "Timestamp in ms": 1701945401497, "logtype": "played_game"}
{"Total num played games": 54830, "Total num trained steps": 108962, "Timestamp in ms": 1701945467930, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6171875}
{"Avg objective": 21.4375, "Games time in secs": 69.47614459320903, "Avg game time in secs": 1.7741591720550787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 54912, "Total num trained steps": 108969, "Timestamp in ms": 1701945470974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855800742844658, "Avg loss": 1.4107615393586457, "Avg value loss": 1.072628029709449, "Avg policy loss": 0.3381335163721815, "Total num played games": 54924, "Total num trained steps": 109056, "Timestamp in ms": 1701945506669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878923603524872, "Avg loss": 0.42048782343044877, "Avg value loss": 0.10228843489312567, "Avg policy loss": 0.3181993893813342, "Total num played games": 54924, "Total num trained steps": 109184, "Timestamp in ms": 1701945556390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902410603743355, "Avg loss": 0.37375387898646295, "Avg value loss": 0.06985099776647985, "Avg policy loss": 0.3039028811035678, "Total num played games": 54924, "Total num trained steps": 109312, "Timestamp in ms": 1701945605445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989167181649642, "Avg loss": 1.065451483707875, "Avg value loss": 0.743752978858538, "Avg policy loss": 0.32169850158970803, "Total num played games": 55018, "Total num trained steps": 109440, "Timestamp in ms": 1701945655268, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 219.51146494224668, "Avg game time in secs": 1.8845202542142943, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 55040, "Total num trained steps": 109528, "Timestamp in ms": 1701945690485, "logtype": "played_game"}
{"Total num played games": 55112, "Total num trained steps": 109565, "Timestamp in ms": 1701945778527, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.00390625}
{"Ratio train steps to played games": 1.986655062373078, "Avg loss": 0.7514366635587066, "Avg value loss": 0.43788723487523384, "Avg policy loss": 0.31354943569749594, "Total num played games": 55140, "Total num trained steps": 109568, "Timestamp in ms": 1701945780667, "logtype": "training_step"}
{"Avg objective": 22.25, "Games time in secs": 90.3871609531343, "Avg game time in secs": 1.704496645135805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 55168, "Total num trained steps": 109568, "Timestamp in ms": 1701945780873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870303952468935, "Avg loss": 0.8610289366915822, "Avg value loss": 0.5296484567807056, "Avg policy loss": 0.3313804821809754, "Total num played games": 55206, "Total num trained steps": 109696, "Timestamp in ms": 1701945830735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893308698329892, "Avg loss": 0.38170394976623356, "Avg value loss": 0.08228289845283143, "Avg policy loss": 0.2994210522156209, "Total num played games": 55206, "Total num trained steps": 109824, "Timestamp in ms": 1701945881280, "logtype": "training_step"}
{"Avg objective": 21.9296875, "Games time in secs": 133.1114805713296, "Avg game time in secs": 1.7836509850458242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 55296, "Total num trained steps": 109907, "Timestamp in ms": 1701945913984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881921087844925, "Avg loss": 0.6371444193646312, "Avg value loss": 0.3420151041354984, "Avg policy loss": 0.29512930661439896, "Total num played games": 55302, "Total num trained steps": 109952, "Timestamp in ms": 1701945931279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905066724530758, "Avg loss": 0.3836825746111572, "Avg value loss": 0.09155655704671517, "Avg policy loss": 0.29212601704057306, "Total num played games": 55302, "Total num trained steps": 110080, "Timestamp in ms": 1701945981839, "logtype": "training_step"}
{"Total num played games": 55396, "Total num trained steps": 110167, "Timestamp in ms": 1701946083894, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4921875}
{"Avg objective": 21.71875, "Games time in secs": 172.0099056623876, "Avg game time in secs": 1.6601466714346316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.52, "agent_stopped_0": 0.49}, "Total num played games": 55424, "Total num trained steps": 110171, "Timestamp in ms": 1701946085994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860875833483511, "Avg loss": 1.1326530817896128, "Avg value loss": 0.8121576964040287, "Avg policy loss": 0.3204954033717513, "Total num played games": 55490, "Total num trained steps": 110208, "Timestamp in ms": 1701946099871, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883762840151378, "Avg loss": 0.42533468757756054, "Avg value loss": 0.12515895164688118, "Avg policy loss": 0.30017573304940015, "Total num played games": 55490, "Total num trained steps": 110336, "Timestamp in ms": 1701946149608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906830059470175, "Avg loss": 0.3449041023850441, "Avg value loss": 0.06521944038104266, "Avg policy loss": 0.2796846613055095, "Total num played games": 55490, "Total num trained steps": 110464, "Timestamp in ms": 1701946200582, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 118.48962880671024, "Avg game time in secs": 1.9124873190594371, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.65}, "Total num played games": 55552, "Total num trained steps": 110474, "Timestamp in ms": 1701946204484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.7699285475537181, "Avg value loss": 0.47965500451391563, "Avg policy loss": 0.29027353995479643, "Total num played games": 55584, "Total num trained steps": 110592, "Timestamp in ms": 1701946249996, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 73.8324811719358, "Avg game time in secs": 1.9943387235398404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 55680, "Total num trained steps": 110666, "Timestamp in ms": 1701946278316, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885057471264367, "Avg loss": 0.7522143616806716, "Avg value loss": 0.466733376175398, "Avg policy loss": 0.28548096818849444, "Total num played games": 55680, "Total num trained steps": 110720, "Timestamp in ms": 1701946299278, "logtype": "training_step"}
{"Total num played games": 55680, "Total num trained steps": 110767, "Timestamp in ms": 1701946381003, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1015625}
{"Ratio train steps to played games": 1.987431419657905, "Avg loss": 0.7101468530017883, "Avg value loss": 0.4164071212289855, "Avg policy loss": 0.293739726068452, "Total num played games": 55774, "Total num trained steps": 110848, "Timestamp in ms": 1701946414278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897443253128697, "Avg loss": 0.36471019382588565, "Avg value loss": 0.09660464528133161, "Avg policy loss": 0.2681055477587506, "Total num played games": 55774, "Total num trained steps": 110976, "Timestamp in ms": 1701946465669, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 213.11171600967646, "Avg game time in secs": 1.6254933486925438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 55808, "Total num trained steps": 111041, "Timestamp in ms": 1701946491428, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988616431000537, "Avg loss": 0.7631270653801039, "Avg value loss": 0.48810257253353484, "Avg policy loss": 0.2750244910130277, "Total num played games": 55870, "Total num trained steps": 111104, "Timestamp in ms": 1701946516595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906224274311894, "Avg loss": 0.3425792873604223, "Avg value loss": 0.0757920853793621, "Avg policy loss": 0.26678720174822956, "Total num played games": 55874, "Total num trained steps": 111232, "Timestamp in ms": 1701946567148, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 76.45552168041468, "Avg game time in secs": 1.7430007090151776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 55936, "Total num trained steps": 111234, "Timestamp in ms": 1701946567888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898506182545923, "Avg loss": 1.0733160353265703, "Avg value loss": 0.7845087509485893, "Avg policy loss": 0.28880727500654757, "Total num played games": 55964, "Total num trained steps": 111360, "Timestamp in ms": 1701946617494, "logtype": "training_step"}
{"Total num played games": 55964, "Total num trained steps": 111371, "Timestamp in ms": 1701946709207, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.86328125}
{"Ratio train steps to played games": 1.988797317064469, "Avg loss": 0.7124270577915013, "Avg value loss": 0.42450984474271536, "Avg policy loss": 0.28791721956804395, "Total num played games": 56058, "Total num trained steps": 111488, "Timestamp in ms": 1701946757756, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 237.60770609602332, "Avg game time in secs": 1.8941580221289769, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 56064, "Total num trained steps": 111608, "Timestamp in ms": 1701946805496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878183437221728, "Avg loss": 0.4168583960272372, "Avg value loss": 0.1545327156491112, "Avg policy loss": 0.2623256767401472, "Total num played games": 56150, "Total num trained steps": 111616, "Timestamp in ms": 1701946808358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990027069383103, "Avg loss": 0.6375062235165387, "Avg value loss": 0.3524824773776345, "Avg policy loss": 0.2850237436359748, "Total num played games": 56152, "Total num trained steps": 111744, "Timestamp in ms": 1701946861216, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 76.7924071289599, "Avg game time in secs": 1.7510984338878188, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 56192, "Total num trained steps": 111797, "Timestamp in ms": 1701946882289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889769939195676, "Avg loss": 0.6926352188456804, "Avg value loss": 0.4163608958479017, "Avg policy loss": 0.27627432195004076, "Total num played games": 56246, "Total num trained steps": 111872, "Timestamp in ms": 1701946910955, "logtype": "training_step"}
{"Total num played games": 56246, "Total num trained steps": 111971, "Timestamp in ms": 1701946984732, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0859375}
{"Avg objective": 23.3203125, "Games time in secs": 104.8789650388062, "Avg game time in secs": 1.8603597184701357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 56320, "Total num trained steps": 111976, "Timestamp in ms": 1701946987168, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879304224352148, "Avg loss": 0.6103740332182497, "Avg value loss": 0.3313678140111733, "Avg policy loss": 0.27900621306616813, "Total num played games": 56340, "Total num trained steps": 112000, "Timestamp in ms": 1701946996696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901845935392262, "Avg loss": 0.41960704792290926, "Avg value loss": 0.148359870625427, "Avg policy loss": 0.2712471804115921, "Total num played games": 56340, "Total num trained steps": 112128, "Timestamp in ms": 1701947045548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989155473650636, "Avg loss": 0.7456098541151732, "Avg value loss": 0.47286295573576353, "Avg policy loss": 0.27274689660407603, "Total num played games": 56434, "Total num trained steps": 112256, "Timestamp in ms": 1701947094621, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 147.98520498722792, "Avg game time in secs": 1.7994944918900728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 56448, "Total num trained steps": 112360, "Timestamp in ms": 1701947135153, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881120860458534, "Avg loss": 0.794568944722414, "Avg value loss": 0.5286001473723445, "Avg policy loss": 0.26596880389843136, "Total num played games": 56528, "Total num trained steps": 112384, "Timestamp in ms": 1701947144571, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990376450608548, "Avg loss": 0.7149336659349501, "Avg value loss": 0.4219472532859072, "Avg policy loss": 0.29298641602508724, "Total num played games": 56528, "Total num trained steps": 112512, "Timestamp in ms": 1701947194402, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 74.33389307558537, "Avg game time in secs": 1.7342768642993178, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 56576, "Total num trained steps": 112550, "Timestamp in ms": 1701947209487, "logtype": "played_game"}
{"Total num played games": 56622, "Total num trained steps": 112571, "Timestamp in ms": 1701947287968, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.76171875}
{"Avg objective": 21.6953125, "Games time in secs": 81.97287714481354, "Avg game time in secs": 1.9080313928134274, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 56704, "Total num trained steps": 112579, "Timestamp in ms": 1701947291460, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860356865787432, "Avg loss": 1.205839736154303, "Avg value loss": 0.9000032910262235, "Avg policy loss": 0.3058364521712065, "Total num played games": 56716, "Total num trained steps": 112640, "Timestamp in ms": 1701947316183, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882925453134919, "Avg loss": 0.4142032330855727, "Avg value loss": 0.12012126459740102, "Avg policy loss": 0.2940819691866636, "Total num played games": 56716, "Total num trained steps": 112768, "Timestamp in ms": 1701947367492, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905317723393752, "Avg loss": 0.35129431751556695, "Avg value loss": 0.07735922106076032, "Avg policy loss": 0.27393509540706873, "Total num played games": 56716, "Total num trained steps": 112896, "Timestamp in ms": 1701947418260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894388509469831, "Avg loss": 0.6195650631561875, "Avg value loss": 0.32815665611997247, "Avg policy loss": 0.29140840633772314, "Total num played games": 56812, "Total num trained steps": 113024, "Timestamp in ms": 1701947468879, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 212.81906858459115, "Avg game time in secs": 1.910670176759595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.63, "agent_stopped_0": 0.46}, "Total num played games": 56832, "Total num trained steps": 113117, "Timestamp in ms": 1701947504279, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884019259832004, "Avg loss": 0.629304820438847, "Avg value loss": 0.3491364920628257, "Avg policy loss": 0.28016832971479744, "Total num played games": 56906, "Total num trained steps": 113152, "Timestamp in ms": 1701947517824, "logtype": "training_step"}
{"Total num played games": 56906, "Total num trained steps": 113175, "Timestamp in ms": 1701947585359, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.55078125}
{"Avg objective": 21.1796875, "Games time in secs": 83.36178011447191, "Avg game time in secs": 1.7859407184587326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 56960, "Total num trained steps": 113180, "Timestamp in ms": 1701947587641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873508771929824, "Avg loss": 0.9539295365102589, "Avg value loss": 0.6350475853541866, "Avg policy loss": 0.3188819495262578, "Total num played games": 57000, "Total num trained steps": 113280, "Timestamp in ms": 1701947626985, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896140350877194, "Avg loss": 0.3727071115281433, "Avg value loss": 0.0871025710075628, "Avg policy loss": 0.2856045422377065, "Total num played games": 57000, "Total num trained steps": 113408, "Timestamp in ms": 1701947678377, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 126.34878670796752, "Avg game time in secs": 2.032502075424418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.76, "agent_stopped_0": 0.31}, "Total num played games": 57088, "Total num trained steps": 113498, "Timestamp in ms": 1701947713990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885802361018672, "Avg loss": 0.6670313726644963, "Avg value loss": 0.3783100769214798, "Avg policy loss": 0.28872129460796714, "Total num played games": 57094, "Total num trained steps": 113536, "Timestamp in ms": 1701947729276, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908221529407644, "Avg loss": 0.39172553620301187, "Avg value loss": 0.0993521225755103, "Avg policy loss": 0.29237341426778585, "Total num played games": 57094, "Total num trained steps": 113664, "Timestamp in ms": 1701947780846, "logtype": "training_step"}
{"Total num played games": 57188, "Total num trained steps": 113775, "Timestamp in ms": 1701947956004, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66796875}
{"Avg objective": 20.890625, "Games time in secs": 243.99128944426775, "Avg game time in secs": 1.6873600128456019, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 57216, "Total num trained steps": 113777, "Timestamp in ms": 1701947957982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865228169407492, "Avg loss": 1.2434501505922526, "Avg value loss": 0.9347771461762022, "Avg policy loss": 0.3086730029899627, "Total num played games": 57282, "Total num trained steps": 113792, "Timestamp in ms": 1701947963714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988739918298942, "Avg loss": 1.0966999330557883, "Avg value loss": 0.7637160941376351, "Avg policy loss": 0.3329838588833809, "Total num played games": 57282, "Total num trained steps": 113920, "Timestamp in ms": 1701948012633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909919346391536, "Avg loss": 0.39124407700728625, "Avg value loss": 0.09824518804089166, "Avg policy loss": 0.29299889085814357, "Total num played games": 57282, "Total num trained steps": 114048, "Timestamp in ms": 1701948064656, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 110.58977666124701, "Avg game time in secs": 1.808463428664254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 57344, "Total num trained steps": 114058, "Timestamp in ms": 1701948068571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989891596082122, "Avg loss": 0.7735812873579562, "Avg value loss": 0.45106207247590646, "Avg policy loss": 0.32251921587157995, "Total num played games": 57378, "Total num trained steps": 114176, "Timestamp in ms": 1701948117359, "logtype": "training_step"}
{"Avg objective": 22.1796875, "Games time in secs": 87.3380712941289, "Avg game time in secs": 2.200989420089172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.75, "agent_stopped_0": 0.38}, "Total num played games": 57472, "Total num trained steps": 114274, "Timestamp in ms": 1701948155910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888641425389755, "Avg loss": 1.1213131877593696, "Avg value loss": 0.7938922684406862, "Avg policy loss": 0.3274209046503529, "Total num played games": 57472, "Total num trained steps": 114304, "Timestamp in ms": 1701948168343, "logtype": "training_step"}
{"Total num played games": 57472, "Total num trained steps": 114379, "Timestamp in ms": 1701948259291, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.02734375}
{"Ratio train steps to played games": 1.9878400444706945, "Avg loss": 1.0517295103054494, "Avg value loss": 0.6990367434336804, "Avg policy loss": 0.35269276541657746, "Total num played games": 57566, "Total num trained steps": 114432, "Timestamp in ms": 1701948280112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900635791960533, "Avg loss": 0.47801033849827945, "Avg value loss": 0.14094787545036525, "Avg policy loss": 0.33706246444489807, "Total num played games": 57566, "Total num trained steps": 114560, "Timestamp in ms": 1701948330426, "logtype": "training_step"}
{"Avg objective": 22.9375, "Games time in secs": 200.26746800541878, "Avg game time in secs": 1.8404567741672508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 57600, "Total num trained steps": 114625, "Timestamp in ms": 1701948356177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889702056813847, "Avg loss": 0.6665824032388628, "Avg value loss": 0.3412485609005671, "Avg policy loss": 0.32533384347334504, "Total num played games": 57662, "Total num trained steps": 114688, "Timestamp in ms": 1701948382330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906376781441797, "Avg loss": 0.4212119057774544, "Avg value loss": 0.10519225028110668, "Avg policy loss": 0.3160196535754949, "Total num played games": 57678, "Total num trained steps": 114816, "Timestamp in ms": 1701948435078, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 79.83390776067972, "Avg game time in secs": 1.8046554613101762, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 57728, "Total num trained steps": 114818, "Timestamp in ms": 1701948436011, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900966099934208, "Avg loss": 0.7944946000352502, "Avg value loss": 0.4572661590646021, "Avg policy loss": 0.33722843788564205, "Total num played games": 57758, "Total num trained steps": 114944, "Timestamp in ms": 1701948484613, "logtype": "training_step"}
{"Total num played games": 57758, "Total num trained steps": 114983, "Timestamp in ms": 1701948571005, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3046875}
{"Ratio train steps to played games": 1.9890755721496232, "Avg loss": 0.8712876702193171, "Avg value loss": 0.534313001728151, "Avg policy loss": 0.33697466587182134, "Total num played games": 57852, "Total num trained steps": 115072, "Timestamp in ms": 1701948607504, "logtype": "training_step"}
{"Avg objective": 22.0390625, "Games time in secs": 220.25876566395164, "Avg game time in secs": 2.080746299121529, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.73}, "Total num played games": 57856, "Total num trained steps": 115196, "Timestamp in ms": 1701948656270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886069394096324, "Avg loss": 0.4340043382253498, "Avg value loss": 0.1170686628902331, "Avg policy loss": 0.3169356780126691, "Total num played games": 57930, "Total num trained steps": 115200, "Timestamp in ms": 1701948657694, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899748076060324, "Avg loss": 1.1548486887477338, "Avg value loss": 0.8085253776516765, "Avg policy loss": 0.34632330550812185, "Total num played games": 57954, "Total num trained steps": 115328, "Timestamp in ms": 1701948707607, "logtype": "training_step"}
{"Avg objective": 22.890625, "Games time in secs": 79.4991848692298, "Avg game time in secs": 1.7453218932496384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.63}, "Total num played games": 57984, "Total num trained steps": 115402, "Timestamp in ms": 1701948735769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988957414553473, "Avg loss": 0.8268853165209293, "Avg value loss": 0.49324863124638796, "Avg policy loss": 0.33363668667152524, "Total num played games": 58048, "Total num trained steps": 115456, "Timestamp in ms": 1701948758123, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911797133406837, "Avg loss": 0.4520903055090457, "Avg value loss": 0.1288733835099265, "Avg policy loss": 0.3232169233961031, "Total num played games": 58048, "Total num trained steps": 115584, "Timestamp in ms": 1701948810616, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 77.87998241186142, "Avg game time in secs": 1.897341112693539, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 58112, "Total num trained steps": 115587, "Timestamp in ms": 1701948813649, "logtype": "played_game"}
{"Total num played games": 58142, "Total num trained steps": 115587, "Timestamp in ms": 1701948882401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.57421875}
{"Ratio train steps to played games": 1.9869496531355175, "Avg loss": 1.2722408075351268, "Avg value loss": 0.9042719508870505, "Avg policy loss": 0.3679688593838364, "Total num played games": 58236, "Total num trained steps": 115712, "Timestamp in ms": 1701948933714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891304347826086, "Avg loss": 0.4298093931283802, "Avg value loss": 0.10065022384515032, "Avg policy loss": 0.32915917155332863, "Total num played games": 58236, "Total num trained steps": 115840, "Timestamp in ms": 1701948986682, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 224.75948967784643, "Avg game time in secs": 2.1212441262614448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 58240, "Total num trained steps": 115963, "Timestamp in ms": 1701949038409, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882728114391524, "Avg loss": 0.4291990026831627, "Avg value loss": 0.11740655664470978, "Avg policy loss": 0.3117924485122785, "Total num played games": 58324, "Total num trained steps": 115968, "Timestamp in ms": 1701949040318, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902626345745045, "Avg loss": 1.0278030880726874, "Avg value loss": 0.6816079206182621, "Avg policy loss": 0.346195166464895, "Total num played games": 58332, "Total num trained steps": 116096, "Timestamp in ms": 1701949092478, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 78.59692201763391, "Avg game time in secs": 1.6940577519126236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.58}, "Total num played games": 58368, "Total num trained steps": 116158, "Timestamp in ms": 1701949117006, "logtype": "played_game"}
{"Total num played games": 58426, "Total num trained steps": 116189, "Timestamp in ms": 1701949182225, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66015625}
{"Avg objective": 21.609375, "Games time in secs": 67.98036376014352, "Avg game time in secs": 2.027778800431406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 58496, "Total num trained steps": 116194, "Timestamp in ms": 1701949184987, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860560492139439, "Avg loss": 1.088061957852915, "Avg value loss": 0.7514584278105758, "Avg policy loss": 0.3366035375511274, "Total num played games": 58520, "Total num trained steps": 116224, "Timestamp in ms": 1701949196870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882433356117566, "Avg loss": 0.5871872692368925, "Avg value loss": 0.2517808363190852, "Avg policy loss": 0.33540643949527293, "Total num played games": 58520, "Total num trained steps": 116352, "Timestamp in ms": 1701949247454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.3970498414710164, "Avg value loss": 0.08630233735311776, "Avg policy loss": 0.3107475023716688, "Total num played games": 58520, "Total num trained steps": 116480, "Timestamp in ms": 1701949297780, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894052615416111, "Avg loss": 0.7462733844295144, "Avg value loss": 0.4274920711177401, "Avg policy loss": 0.31878131232224405, "Total num played games": 58614, "Total num trained steps": 116608, "Timestamp in ms": 1701949349459, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 209.11119697615504, "Avg game time in secs": 2.029261249816045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.75, "agent_stopped_0": 0.38}, "Total num played games": 58624, "Total num trained steps": 116721, "Timestamp in ms": 1701949394098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988332481689661, "Avg loss": 0.6738381898030639, "Avg value loss": 0.3615035149268806, "Avg policy loss": 0.3123346782522276, "Total num played games": 58710, "Total num trained steps": 116736, "Timestamp in ms": 1701949400173, "logtype": "training_step"}
{"Total num played games": 58710, "Total num trained steps": 116791, "Timestamp in ms": 1701949505765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5546875}
{"Avg objective": 21.8046875, "Games time in secs": 113.87957130372524, "Avg game time in secs": 1.7253170665353537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 58752, "Total num trained steps": 116794, "Timestamp in ms": 1701949507978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873477994694237, "Avg loss": 1.2657080474309623, "Avg value loss": 0.9003449217416346, "Avg policy loss": 0.36536314501427114, "Total num played games": 58804, "Total num trained steps": 116864, "Timestamp in ms": 1701949535078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989524522141351, "Avg loss": 0.47301111719571054, "Avg value loss": 0.13306973042199388, "Avg policy loss": 0.3399413856677711, "Total num played games": 58804, "Total num trained steps": 116992, "Timestamp in ms": 1701949585119, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 120.28789283707738, "Avg game time in secs": 2.0468070873466786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.7}, "Total num played games": 58880, "Total num trained steps": 117103, "Timestamp in ms": 1701949628266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988522530476417, "Avg loss": 0.7057408881373703, "Avg value loss": 0.38639287432306446, "Avg policy loss": 0.3193480165209621, "Total num played games": 58898, "Total num trained steps": 117120, "Timestamp in ms": 1701949635068, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906957791436042, "Avg loss": 0.6335405954159796, "Avg value loss": 0.30395740596577525, "Avg policy loss": 0.3295831863069907, "Total num played games": 58898, "Total num trained steps": 117248, "Timestamp in ms": 1701949686185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896765663140765, "Avg loss": 1.062373040476814, "Avg value loss": 0.7268980695225764, "Avg policy loss": 0.3354749759892002, "Total num played games": 58992, "Total num trained steps": 117376, "Timestamp in ms": 1701949734780, "logtype": "training_step"}
{"Total num played games": 58992, "Total num trained steps": 117391, "Timestamp in ms": 1701949817831, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.01953125}
{"Avg objective": 22.8671875, "Games time in secs": 191.3985528126359, "Avg game time in secs": 2.0107869311759714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 59008, "Total num trained steps": 117395, "Timestamp in ms": 1701949819664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886944453846935, "Avg loss": 0.7161524496041238, "Avg value loss": 0.3838876227964647, "Avg policy loss": 0.3322648353641853, "Total num played games": 59086, "Total num trained steps": 117504, "Timestamp in ms": 1701949862912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908607792031954, "Avg loss": 0.3922329214401543, "Avg value loss": 0.08655410871142522, "Avg policy loss": 0.30567881383467466, "Total num played games": 59086, "Total num trained steps": 117632, "Timestamp in ms": 1701949914803, "logtype": "training_step"}
{"Avg objective": 22.421875, "Games time in secs": 109.54524104297161, "Avg game time in secs": 1.723166744253831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.49}, "Total num played games": 59136, "Total num trained steps": 117665, "Timestamp in ms": 1701949929210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989861439675566, "Avg loss": 0.7315560516435653, "Avg value loss": 0.40719687729142606, "Avg policy loss": 0.3243591790087521, "Total num played games": 59180, "Total num trained steps": 117760, "Timestamp in ms": 1701949966135, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 75.2343515790999, "Avg game time in secs": 1.9861374904285185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 59264, "Total num trained steps": 117858, "Timestamp in ms": 1701950004444, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888652697641462, "Avg loss": 0.7996014207601547, "Avg value loss": 0.48438960712519474, "Avg policy loss": 0.3152118268189952, "Total num played games": 59274, "Total num trained steps": 117888, "Timestamp in ms": 1701950016275, "logtype": "training_step"}
{"Total num played games": 59274, "Total num trained steps": 117992, "Timestamp in ms": 1701950135903, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.91796875}
{"Ratio train steps to played games": 1.987872254413152, "Avg loss": 0.782108370680362, "Avg value loss": 0.44795699685346335, "Avg policy loss": 0.33415137499105185, "Total num played games": 59368, "Total num trained steps": 118016, "Timestamp in ms": 1701950145912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990028298073036, "Avg loss": 0.5518319171387702, "Avg value loss": 0.21946501306956634, "Avg policy loss": 0.3323669049423188, "Total num played games": 59368, "Total num trained steps": 118144, "Timestamp in ms": 1701950195795, "logtype": "training_step"}
{"Avg objective": 22.6640625, "Games time in secs": 224.95277246832848, "Avg game time in secs": 1.9251501943508629, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 59392, "Total num trained steps": 118228, "Timestamp in ms": 1701950229397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889681151621148, "Avg loss": 0.7814771849662066, "Avg value loss": 0.46679851759108715, "Avg policy loss": 0.314678659546189, "Total num played games": 59464, "Total num trained steps": 118272, "Timestamp in ms": 1701950247284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991120678057312, "Avg loss": 0.43417060910724103, "Avg value loss": 0.11657990879029967, "Avg policy loss": 0.31759070430416614, "Total num played games": 59464, "Total num trained steps": 118400, "Timestamp in ms": 1701950302479, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 81.77629265189171, "Avg game time in secs": 1.9281686635513324, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 59520, "Total num trained steps": 118422, "Timestamp in ms": 1701950311173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900604432505038, "Avg loss": 1.0043010858353227, "Avg value loss": 0.6714725502824876, "Avg policy loss": 0.3328285177703947, "Total num played games": 59560, "Total num trained steps": 118528, "Timestamp in ms": 1701950353943, "logtype": "training_step"}
{"Total num played games": 59560, "Total num trained steps": 118592, "Timestamp in ms": 1701950459226, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.43359375}
{"Avg objective": 21.1953125, "Games time in secs": 151.97552871331573, "Avg game time in secs": 1.9442978054576088, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 59648, "Total num trained steps": 118602, "Timestamp in ms": 1701950463149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989070305427968, "Avg loss": 0.9879122595302761, "Avg value loss": 0.6561620723223314, "Avg policy loss": 0.3317502080462873, "Total num played games": 59654, "Total num trained steps": 118656, "Timestamp in ms": 1701950485251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912160123378146, "Avg loss": 0.4296943754889071, "Avg value loss": 0.10758935281774029, "Avg policy loss": 0.32210502214729786, "Total num played games": 59654, "Total num trained steps": 118784, "Timestamp in ms": 1701950536812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990225614246502, "Avg loss": 0.7326537894550711, "Avg value loss": 0.39089114233502187, "Avg policy loss": 0.3417626479640603, "Total num played games": 59748, "Total num trained steps": 118912, "Timestamp in ms": 1701950587865, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 157.05237652733922, "Avg game time in secs": 1.8886919216893148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.6, "agent_stopped_0": 0.5}, "Total num played games": 59776, "Total num trained steps": 118988, "Timestamp in ms": 1701950620201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892383275960028, "Avg loss": 0.7478603350464255, "Avg value loss": 0.4195496299653314, "Avg policy loss": 0.3283107049064711, "Total num played games": 59842, "Total num trained steps": 119040, "Timestamp in ms": 1701950643548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913605828682197, "Avg loss": 0.4192307365592569, "Avg value loss": 0.09864684654166922, "Avg policy loss": 0.32058388844598085, "Total num played games": 59842, "Total num trained steps": 119168, "Timestamp in ms": 1701950701660, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 85.18228344246745, "Avg game time in secs": 1.84320110004046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.61}, "Total num played games": 59904, "Total num trained steps": 119178, "Timestamp in ms": 1701950705384, "logtype": "played_game"}
{"Total num played games": 59936, "Total num trained steps": 119197, "Timestamp in ms": 1701950800205, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.45703125}
{"Ratio train steps to played games": 1.987256371814093, "Avg loss": 1.3389967870898545, "Avg value loss": 0.9833722934417892, "Avg policy loss": 0.35562449390999973, "Total num played games": 60030, "Total num trained steps": 119296, "Timestamp in ms": 1701950843385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894052973513243, "Avg loss": 0.4016048084013164, "Avg value loss": 0.08427576842950657, "Avg policy loss": 0.31732904084492475, "Total num played games": 60030, "Total num trained steps": 119424, "Timestamp in ms": 1701950900310, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 251.30572777986526, "Avg game time in secs": 2.0671190144203138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.7}, "Total num played games": 60032, "Total num trained steps": 119551, "Timestamp in ms": 1701950956690, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913385302152042, "Avg loss": 0.3682261551730335, "Avg value loss": 0.0598261249542702, "Avg policy loss": 0.3084000295493752, "Total num played games": 60036, "Total num trained steps": 119552, "Timestamp in ms": 1701950956907, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905528574279823, "Avg loss": 1.0844971989281476, "Avg value loss": 0.7443889756686985, "Avg policy loss": 0.3401082126656547, "Total num played games": 60124, "Total num trained steps": 119680, "Timestamp in ms": 1701951012356, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 83.04142139479518, "Avg game time in secs": 1.8740040047559887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 60160, "Total num trained steps": 119742, "Timestamp in ms": 1701951039733, "logtype": "played_game"}
{"Total num played games": 60218, "Total num trained steps": 119800, "Timestamp in ms": 1701951154510, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.125}
{"Avg objective": 21.6015625, "Games time in secs": 117.66869295015931, "Avg game time in secs": 2.1176247934345156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.75, "agent_stopped_0": 0.38}, "Total num played games": 60288, "Total num trained steps": 119806, "Timestamp in ms": 1701951157401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986667993234504, "Avg loss": 0.9349101253319532, "Avg value loss": 0.5926692592620384, "Avg policy loss": 0.3422408712795004, "Total num played games": 60306, "Total num trained steps": 119808, "Timestamp in ms": 1701951158386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885760710969624, "Avg loss": 0.9988353881053627, "Avg value loss": 0.637984343979042, "Avg policy loss": 0.3608510351041332, "Total num played games": 60312, "Total num trained steps": 119936, "Timestamp in ms": 1701951217395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907149489322191, "Avg loss": 0.3938574781641364, "Avg value loss": 0.07824591628741473, "Avg policy loss": 0.31561156059615314, "Total num played games": 60312, "Total num trained steps": 120064, "Timestamp in ms": 1701951275971, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897195642816938, "Avg loss": 0.8968878050800413, "Avg value loss": 0.5610274788050447, "Avg policy loss": 0.3358603277010843, "Total num played games": 60406, "Total num trained steps": 120192, "Timestamp in ms": 1701951331665, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 222.21753111481667, "Avg game time in secs": 1.9294557717221323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 60416, "Total num trained steps": 120303, "Timestamp in ms": 1701951379619, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886945886086411, "Avg loss": 0.5670956990215927, "Avg value loss": 0.24521150524378754, "Avg policy loss": 0.3218841953203082, "Total num played games": 60502, "Total num trained steps": 120320, "Timestamp in ms": 1701951387362, "logtype": "training_step"}
{"Total num played games": 60502, "Total num trained steps": 120403, "Timestamp in ms": 1701951503438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.640625}
{"Avg objective": 21.8359375, "Games time in secs": 125.78192531690001, "Avg game time in secs": 1.659525593277067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 60544, "Total num trained steps": 120406, "Timestamp in ms": 1701951505401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877054591062115, "Avg loss": 1.0714092294219881, "Avg value loss": 0.7348614687798545, "Avg policy loss": 0.33654776657931507, "Total num played games": 60596, "Total num trained steps": 120448, "Timestamp in ms": 1701951523418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898343124958744, "Avg loss": 0.49894921435043216, "Avg value loss": 0.17287603591103107, "Avg policy loss": 0.32607318193186074, "Total num played games": 60596, "Total num trained steps": 120576, "Timestamp in ms": 1701951584001, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 128.52132151275873, "Avg game time in secs": 1.8986771458003204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.61}, "Total num played games": 60672, "Total num trained steps": 120686, "Timestamp in ms": 1701951633922, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888614269237106, "Avg loss": 0.6277054392267019, "Avg value loss": 0.31782515029772185, "Avg policy loss": 0.30988027818966657, "Total num played games": 60690, "Total num trained steps": 120704, "Timestamp in ms": 1701951642569, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909705058493985, "Avg loss": 0.573905449360609, "Avg value loss": 0.24851905248942785, "Avg policy loss": 0.32538639137055725, "Total num played games": 60690, "Total num trained steps": 120832, "Timestamp in ms": 1701951700808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899973677283496, "Avg loss": 0.8344556824304163, "Avg value loss": 0.5129561624489725, "Avg policy loss": 0.3214995200978592, "Total num played games": 60784, "Total num trained steps": 120960, "Timestamp in ms": 1701951757390, "logtype": "training_step"}
{"Total num played games": 60784, "Total num trained steps": 121005, "Timestamp in ms": 1701951836817, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.375}
{"Avg objective": 22.1484375, "Games time in secs": 204.5527907088399, "Avg game time in secs": 1.814427864504978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 60800, "Total num trained steps": 121008, "Timestamp in ms": 1701951838475, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890272347974638, "Avg loss": 0.8711421440821141, "Avg value loss": 0.5385186081693973, "Avg policy loss": 0.3326235399581492, "Total num played games": 60878, "Total num trained steps": 121088, "Timestamp in ms": 1701951875136, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911298005847762, "Avg loss": 0.40281054843217134, "Avg value loss": 0.08988486425369047, "Avg policy loss": 0.31292568368371576, "Total num played games": 60878, "Total num trained steps": 121216, "Timestamp in ms": 1701951930651, "logtype": "training_step"}
{"Avg objective": 23.0703125, "Games time in secs": 107.19645468518138, "Avg game time in secs": 1.584783282421995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 60928, "Total num trained steps": 121250, "Timestamp in ms": 1701951945672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901594174375123, "Avg loss": 0.8764626472257078, "Avg value loss": 0.5524968304962385, "Avg policy loss": 0.32396581198554486, "Total num played games": 60972, "Total num trained steps": 121344, "Timestamp in ms": 1701951988892, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 84.96468711644411, "Avg game time in secs": 1.9092994557286147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 61056, "Total num trained steps": 121439, "Timestamp in ms": 1701952030637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891756460223364, "Avg loss": 0.7711121514439583, "Avg value loss": 0.4467168928531464, "Avg policy loss": 0.32439525320660323, "Total num played games": 61066, "Total num trained steps": 121472, "Timestamp in ms": 1701952045031, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912881144990666, "Avg loss": 0.44099902198649943, "Avg value loss": 0.12665690074209124, "Avg policy loss": 0.31434212427120656, "Total num played games": 61066, "Total num trained steps": 121600, "Timestamp in ms": 1701952101361, "logtype": "training_step"}
{"Total num played games": 61066, "Total num trained steps": 121608, "Timestamp in ms": 1701952183013, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.24609375}
{"Ratio train steps to played games": 1.9903204708960105, "Avg loss": 0.8394089038483799, "Avg value loss": 0.5111434681748506, "Avg policy loss": 0.3282654337817803, "Total num played games": 61160, "Total num trained steps": 121728, "Timestamp in ms": 1701952234029, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 241.10789347440004, "Avg game time in secs": 1.8436315330327488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.71, "agent_stopped_0": 0.41}, "Total num played games": 61184, "Total num trained steps": 121812, "Timestamp in ms": 1701952271747, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98933947170797, "Avg loss": 0.6601865314878523, "Avg value loss": 0.3496768047043588, "Avg policy loss": 0.31050973921082914, "Total num played games": 61254, "Total num trained steps": 121856, "Timestamp in ms": 1701952290613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991445456623241, "Avg loss": 0.41238267393782735, "Avg value loss": 0.09751124563626945, "Avg policy loss": 0.3148714292328805, "Total num played games": 61254, "Total num trained steps": 121984, "Timestamp in ms": 1701952348483, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 84.30026677623391, "Avg game time in secs": 1.7406404781213496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 61312, "Total num trained steps": 122001, "Timestamp in ms": 1701952356047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904805372628285, "Avg loss": 1.013093126937747, "Avg value loss": 0.6893020859570242, "Avg policy loss": 0.3237910437164828, "Total num played games": 61348, "Total num trained steps": 122112, "Timestamp in ms": 1701952407696, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 87.87122805789113, "Avg game time in secs": 1.9652581266127527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 61440, "Total num trained steps": 122194, "Timestamp in ms": 1701952443919, "logtype": "played_game"}
{"Total num played games": 61444, "Total num trained steps": 122210, "Timestamp in ms": 1701952527173, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.74609375}
{"Ratio train steps to played games": 1.9863986479898599, "Avg loss": 1.2765423355158418, "Avg value loss": 0.9456158599059563, "Avg policy loss": 0.33092648128513247, "Total num played games": 61538, "Total num trained steps": 122240, "Timestamp in ms": 1701952540369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988478663589977, "Avg loss": 0.6245361068286002, "Avg value loss": 0.2709640580578707, "Avg policy loss": 0.35357204591855407, "Total num played games": 61538, "Total num trained steps": 122368, "Timestamp in ms": 1701952594934, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905749293119699, "Avg loss": 0.39458844996988773, "Avg value loss": 0.07177528465399519, "Avg policy loss": 0.32281316444277763, "Total num played games": 61538, "Total num trained steps": 122496, "Timestamp in ms": 1701952650183, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 238.2529662437737, "Avg game time in secs": 1.6554881097690668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 61568, "Total num trained steps": 122569, "Timestamp in ms": 1701952682172, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896157840083073, "Avg loss": 0.8790783709846437, "Avg value loss": 0.5503778344718739, "Avg policy loss": 0.32870053208898753, "Total num played games": 61632, "Total num trained steps": 122624, "Timestamp in ms": 1701952706958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991692627206646, "Avg loss": 0.40640384308062494, "Avg value loss": 0.08545913724810816, "Avg policy loss": 0.32094470388256013, "Total num played games": 61632, "Total num trained steps": 122752, "Timestamp in ms": 1701952765795, "logtype": "training_step"}
{"Avg objective": 22.8984375, "Games time in secs": 86.11438808217645, "Avg game time in secs": 1.8372021461254917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.64, "agent_stopped_0": 0.4}, "Total num played games": 61696, "Total num trained steps": 122758, "Timestamp in ms": 1701952768286, "logtype": "played_game"}
{"Total num played games": 61726, "Total num trained steps": 122811, "Timestamp in ms": 1701952856657, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.61328125}
{"Ratio train steps to played games": 1.9877062439340019, "Avg loss": 1.5984622419346124, "Avg value loss": 1.2249460458406247, "Avg policy loss": 0.3735161987133324, "Total num played games": 61820, "Total num trained steps": 122880, "Timestamp in ms": 1701952887705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897767712714332, "Avg loss": 0.46320582879707217, "Avg value loss": 0.11551805207272992, "Avg policy loss": 0.34768777491990477, "Total num played games": 61820, "Total num trained steps": 123008, "Timestamp in ms": 1701952943166, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 229.76819328963757, "Avg game time in secs": 2.028635751485126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.72}, "Total num played games": 61824, "Total num trained steps": 123132, "Timestamp in ms": 1701952998054, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891283277332643, "Avg loss": 0.4726134280208498, "Avg value loss": 0.14960746275028214, "Avg policy loss": 0.32300597080029547, "Total num played games": 61904, "Total num trained steps": 123136, "Timestamp in ms": 1701952999751, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908262807674915, "Avg loss": 0.842601211508736, "Avg value loss": 0.4956458520318847, "Avg policy loss": 0.3469553554896265, "Total num played games": 61916, "Total num trained steps": 123264, "Timestamp in ms": 1701953054494, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 82.71957892179489, "Avg game time in secs": 1.7533835424401332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 61952, "Total num trained steps": 123325, "Timestamp in ms": 1701953080774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989487601173777, "Avg loss": 0.9472568212077022, "Avg value loss": 0.6064416516455822, "Avg policy loss": 0.3408151724142954, "Total num played games": 62022, "Total num trained steps": 123392, "Timestamp in ms": 1701953109257, "logtype": "training_step"}
{"Total num played games": 62022, "Total num trained steps": 123412, "Timestamp in ms": 1701953184063, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.53515625}
{"Avg objective": 21.0859375, "Games time in secs": 105.67514748126268, "Avg game time in secs": 1.6914761728257872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 62080, "Total num trained steps": 123416, "Timestamp in ms": 1701953186450, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885375748599394, "Avg loss": 0.7573110612574965, "Avg value loss": 0.399045673198998, "Avg policy loss": 0.3582653874764219, "Total num played games": 62116, "Total num trained steps": 123520, "Timestamp in ms": 1701953232564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905821366475627, "Avg loss": 0.40702016465365887, "Avg value loss": 0.07208002710831352, "Avg policy loss": 0.33494013582821935, "Total num played games": 62116, "Total num trained steps": 123648, "Timestamp in ms": 1701953287444, "logtype": "training_step"}
{"Avg objective": 22.734375, "Games time in secs": 136.5819107964635, "Avg game time in secs": 1.9710719009162858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.71, "agent_stopped_0": 0.37}, "Total num played games": 62208, "Total num trained steps": 123729, "Timestamp in ms": 1701953323032, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989647966564861, "Avg loss": 0.8470021276734769, "Avg value loss": 0.5068577830097638, "Avg policy loss": 0.34014434122946113, "Total num played games": 62210, "Total num trained steps": 123776, "Timestamp in ms": 1701953344469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917055135830253, "Avg loss": 0.4599851449020207, "Avg value loss": 0.11621716973604634, "Avg policy loss": 0.3437679741764441, "Total num played games": 62210, "Total num trained steps": 123904, "Timestamp in ms": 1701953400519, "logtype": "training_step"}
{"Total num played games": 62304, "Total num trained steps": 124014, "Timestamp in ms": 1701953599735, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6875}
{"Avg objective": 21.3984375, "Games time in secs": 278.61099379882216, "Avg game time in secs": 1.8024868170614354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 62336, "Total num trained steps": 124016, "Timestamp in ms": 1701953601643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877399916663996, "Avg loss": 1.0146742227952927, "Avg value loss": 0.6456008745590225, "Avg policy loss": 0.36907335347495973, "Total num played games": 62398, "Total num trained steps": 124032, "Timestamp in ms": 1701953608020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989807365620693, "Avg loss": 0.61325798695907, "Avg value loss": 0.2459483280836139, "Avg policy loss": 0.36730965762399137, "Total num played games": 62398, "Total num trained steps": 124160, "Timestamp in ms": 1701953665499, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917948717948717, "Avg loss": 0.4004422421567142, "Avg value loss": 0.06736957069369964, "Avg policy loss": 0.33307267318014055, "Total num played games": 62400, "Total num trained steps": 124288, "Timestamp in ms": 1701953720357, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 119.63051457330585, "Avg game time in secs": 1.6961966957023833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 62464, "Total num trained steps": 124290, "Timestamp in ms": 1701953721274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908471213236472, "Avg loss": 0.7943347841501236, "Avg value loss": 0.44956484899739735, "Avg policy loss": 0.3447699387324974, "Total num played games": 62494, "Total num trained steps": 124416, "Timestamp in ms": 1701953775144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898386323693882, "Avg loss": 0.7580558015033603, "Avg value loss": 0.41997688048286363, "Avg policy loss": 0.3380789216607809, "Total num played games": 62590, "Total num trained steps": 124544, "Timestamp in ms": 1701953830277, "logtype": "training_step"}
{"Total num played games": 62590, "Total num trained steps": 124615, "Timestamp in ms": 1701953924679, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6640625}
{"Avg objective": 21.9140625, "Games time in secs": 204.41222082078457, "Avg game time in secs": 1.8646324482106138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.71, "agent_stopped_0": 0.33}, "Total num played games": 62592, "Total num trained steps": 124615, "Timestamp in ms": 1701953925686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888966881500862, "Avg loss": 0.8007050000596792, "Avg value loss": 0.4526341217861045, "Avg policy loss": 0.34807087562512606, "Total num played games": 62684, "Total num trained steps": 124672, "Timestamp in ms": 1701953950337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990938676536277, "Avg loss": 0.43685913272202015, "Avg value loss": 0.09296144885593094, "Avg policy loss": 0.34389768238179386, "Total num played games": 62684, "Total num trained steps": 124800, "Timestamp in ms": 1701954008933, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 112.22538717836142, "Avg game time in secs": 1.6996762430353556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 62720, "Total num trained steps": 124861, "Timestamp in ms": 1701954037911, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899964955876261, "Avg loss": 0.8361320223193616, "Avg value loss": 0.49815666186623275, "Avg policy loss": 0.3379753528861329, "Total num played games": 62778, "Total num trained steps": 124928, "Timestamp in ms": 1701954068731, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 89.14189283922315, "Avg game time in secs": 1.8645461911801249, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 62848, "Total num trained steps": 125050, "Timestamp in ms": 1701954127054, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890412266191628, "Avg loss": 0.4834981777239591, "Avg value loss": 0.1570052983588539, "Avg policy loss": 0.3264928753487766, "Total num played games": 62872, "Total num trained steps": 125056, "Timestamp in ms": 1701954129788, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910771090469526, "Avg loss": 0.5724194240756333, "Avg value loss": 0.23143169938703068, "Avg policy loss": 0.34098772262223065, "Total num played games": 62872, "Total num trained steps": 125184, "Timestamp in ms": 1701954185663, "logtype": "training_step"}
{"Total num played games": 62872, "Total num trained steps": 125216, "Timestamp in ms": 1701954264165, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.26953125}
{"Ratio train steps to played games": 1.9901534161293397, "Avg loss": 0.8076416510157287, "Avg value loss": 0.47400856943568215, "Avg policy loss": 0.33363307581748813, "Total num played games": 62966, "Total num trained steps": 125312, "Timestamp in ms": 1701954304889, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 225.9141160622239, "Avg game time in secs": 1.9681278021889739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 62976, "Total num trained steps": 125423, "Timestamp in ms": 1701954352968, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891535314452444, "Avg loss": 0.7006587591022253, "Avg value loss": 0.37536952522350475, "Avg policy loss": 0.325289232772775, "Total num played games": 63062, "Total num trained steps": 125440, "Timestamp in ms": 1701954359609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991183279946719, "Avg loss": 0.6928740076255053, "Avg value loss": 0.35365418693982065, "Avg policy loss": 0.33921981835737824, "Total num played games": 63062, "Total num trained steps": 125568, "Timestamp in ms": 1701954415311, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 83.97038486599922, "Avg game time in secs": 1.691458726505516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 63104, "Total num trained steps": 125617, "Timestamp in ms": 1701954436938, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902463740578884, "Avg loss": 0.7821841796394438, "Avg value loss": 0.44435528345638886, "Avg policy loss": 0.33782889565918595, "Total num played games": 63156, "Total num trained steps": 125696, "Timestamp in ms": 1701954471726, "logtype": "training_step"}
{"Avg objective": 22.515625, "Games time in secs": 82.98443871736526, "Avg game time in secs": 1.8942529470368754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 63232, "Total num trained steps": 125806, "Timestamp in ms": 1701954519923, "logtype": "played_game"}
{"Total num played games": 63252, "Total num trained steps": 125817, "Timestamp in ms": 1701954579946, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.63671875}
{"Ratio train steps to played games": 1.986673824486058, "Avg loss": 0.708327304571867, "Avg value loss": 0.37705998166347854, "Avg policy loss": 0.33126733161043376, "Total num played games": 63334, "Total num trained steps": 125824, "Timestamp in ms": 1701954583682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883023395320936, "Avg loss": 1.0227386865299195, "Avg value loss": 0.654263170727063, "Avg policy loss": 0.3684755116701126, "Total num played games": 63346, "Total num trained steps": 125952, "Timestamp in ms": 1701954639265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990338774350393, "Avg loss": 0.40409183013252914, "Avg value loss": 0.07242097158450633, "Avg policy loss": 0.3316708590136841, "Total num played games": 63346, "Total num trained steps": 126080, "Timestamp in ms": 1701954698120, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 223.1501455269754, "Avg game time in secs": 1.9950755477475468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.7, "agent_stopped_0": 0.39}, "Total num played games": 63360, "Total num trained steps": 126183, "Timestamp in ms": 1701954743073, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989344598215693, "Avg loss": 0.7907544013578445, "Avg value loss": 0.46662195728276856, "Avg policy loss": 0.324132444569841, "Total num played games": 63442, "Total num trained steps": 126208, "Timestamp in ms": 1701954753338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913621890860944, "Avg loss": 0.6126913386397064, "Avg value loss": 0.2652854010812007, "Avg policy loss": 0.34740593773312867, "Total num played games": 63442, "Total num trained steps": 126336, "Timestamp in ms": 1701954810181, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 84.04982820153236, "Avg game time in secs": 1.921600474161096, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.68}, "Total num played games": 63488, "Total num trained steps": 126377, "Timestamp in ms": 1701954827123, "logtype": "played_game"}
{"Total num played games": 63536, "Total num trained steps": 126422, "Timestamp in ms": 1701954906577, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.453125}
{"Avg objective": 21.9296875, "Games time in secs": 82.654670689255, "Avg game time in secs": 2.028570090071298, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.74}, "Total num played games": 63616, "Total num trained steps": 126427, "Timestamp in ms": 1701954909778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874901775891876, "Avg loss": 1.2628845430444926, "Avg value loss": 0.9061414869502187, "Avg policy loss": 0.35674304247368127, "Total num played games": 63630, "Total num trained steps": 126464, "Timestamp in ms": 1701954927229, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895018073235895, "Avg loss": 0.49301791680045426, "Avg value loss": 0.14476631188881584, "Avg policy loss": 0.3482515977229923, "Total num played games": 63630, "Total num trained steps": 126592, "Timestamp in ms": 1701954981490, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915134370579914, "Avg loss": 0.39159641112200916, "Avg value loss": 0.059576276486041024, "Avg policy loss": 0.33202013734262437, "Total num played games": 63630, "Total num trained steps": 126720, "Timestamp in ms": 1701955038300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905219219784702, "Avg loss": 0.8109919931739569, "Avg value loss": 0.4781717212172225, "Avg policy loss": 0.33282027894165367, "Total num played games": 63726, "Total num trained steps": 126848, "Timestamp in ms": 1701955094710, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 226.54013078287244, "Avg game time in secs": 1.9652740115416236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.67}, "Total num played games": 63744, "Total num trained steps": 126944, "Timestamp in ms": 1701955136318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989595738013162, "Avg loss": 0.6474043710622936, "Avg value loss": 0.329368691687705, "Avg policy loss": 0.3180356697412208, "Total num played games": 63820, "Total num trained steps": 126976, "Timestamp in ms": 1701955149842, "logtype": "training_step"}
{"Total num played games": 63820, "Total num trained steps": 127026, "Timestamp in ms": 1701955231771, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.609375}
{"Avg objective": 21.328125, "Games time in secs": 97.89945613592863, "Avg game time in secs": 1.718198092887178, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 63872, "Total num trained steps": 127031, "Timestamp in ms": 1701955234218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98865663234972, "Avg loss": 1.0247656940482557, "Avg value loss": 0.6803381350473501, "Avg policy loss": 0.34442755731288344, "Total num played games": 63914, "Total num trained steps": 127104, "Timestamp in ms": 1701955264573, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906749694902526, "Avg loss": 0.3934671892784536, "Avg value loss": 0.08297230739844963, "Avg policy loss": 0.31049488054122776, "Total num played games": 63914, "Total num trained steps": 127232, "Timestamp in ms": 1701955319538, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 125.44050601124763, "Avg game time in secs": 1.8782672499364708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 64000, "Total num trained steps": 127325, "Timestamp in ms": 1701955359659, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897512810898639, "Avg loss": 0.6148871730547398, "Avg value loss": 0.3179441262909677, "Avg policy loss": 0.2969430427765474, "Total num played games": 64008, "Total num trained steps": 127360, "Timestamp in ms": 1701955376751, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917354080739909, "Avg loss": 0.39172719372436404, "Avg value loss": 0.08823549080989324, "Avg policy loss": 0.3034917034674436, "Total num played games": 64008, "Total num trained steps": 127488, "Timestamp in ms": 1701955430740, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907494072132785, "Avg loss": 0.8456153706647456, "Avg value loss": 0.526163286092924, "Avg policy loss": 0.31945208145771176, "Total num played games": 64104, "Total num trained steps": 127616, "Timestamp in ms": 1701955483717, "logtype": "training_step"}
{"Total num played games": 64104, "Total num trained steps": 127627, "Timestamp in ms": 1701955501470, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.21484375}
{"Avg objective": 20.578125, "Games time in secs": 144.0166873820126, "Avg game time in secs": 1.8339437831018586, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 64128, "Total num trained steps": 127630, "Timestamp in ms": 1701955503675, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898439203713512, "Avg loss": 0.7083948333747685, "Avg value loss": 0.4020699724787846, "Avg policy loss": 0.30632486334070563, "Total num played games": 64198, "Total num trained steps": 127744, "Timestamp in ms": 1701955554509, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918377519548895, "Avg loss": 0.3490081559866667, "Avg value loss": 0.056413997866911814, "Avg policy loss": 0.29259416076820344, "Total num played games": 64198, "Total num trained steps": 127872, "Timestamp in ms": 1701955612592, "logtype": "training_step"}
{"Avg objective": 22.8828125, "Games time in secs": 116.06366382911801, "Avg game time in secs": 1.8058716227824334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 64256, "Total num trained steps": 127889, "Timestamp in ms": 1701955619739, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909164437255025, "Avg loss": 1.2161673144437373, "Avg value loss": 0.8947598704253323, "Avg policy loss": 0.32140743848867714, "Total num played games": 64292, "Total num trained steps": 128000, "Timestamp in ms": 1701955670878, "logtype": "training_step"}
{"Avg objective": 22.515625, "Games time in secs": 88.30288925766945, "Avg game time in secs": 1.9287101465451997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 64384, "Total num trained steps": 128080, "Timestamp in ms": 1701955708042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899978256142639, "Avg loss": 0.8904875533189625, "Avg value loss": 0.5902100164676085, "Avg policy loss": 0.3002775366185233, "Total num played games": 64386, "Total num trained steps": 128128, "Timestamp in ms": 1701955729683, "logtype": "training_step"}
{"Total num played games": 64386, "Total num trained steps": 128230, "Timestamp in ms": 1701955830923, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.27734375}
{"Ratio train steps to played games": 1.9890663771712158, "Avg loss": 0.7759550912305713, "Avg value loss": 0.4813898572465405, "Avg policy loss": 0.29456523386761546, "Total num played games": 64480, "Total num trained steps": 128256, "Timestamp in ms": 1701955842258, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910669975186104, "Avg loss": 0.644189098617062, "Avg value loss": 0.3318033464020118, "Avg policy loss": 0.31238575314637274, "Total num played games": 64480, "Total num trained steps": 128384, "Timestamp in ms": 1701955894874, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 216.50826914608479, "Avg game time in secs": 1.7326867467199918, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 64512, "Total num trained steps": 128453, "Timestamp in ms": 1701955924551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901353485923128, "Avg loss": 0.6362075251527131, "Avg value loss": 0.3396295431011822, "Avg policy loss": 0.2965779845835641, "Total num played games": 64574, "Total num trained steps": 128512, "Timestamp in ms": 1701955954155, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918707999132885, "Avg loss": 0.3664086733479053, "Avg value loss": 0.07824087754124776, "Avg policy loss": 0.28816779772751033, "Total num played games": 64582, "Total num trained steps": 128640, "Timestamp in ms": 1701956014745, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 90.98740350455046, "Avg game time in secs": 1.7302581309631933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 64640, "Total num trained steps": 128642, "Timestamp in ms": 1701956015538, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912012123461371, "Avg loss": 0.697698455536738, "Avg value loss": 0.4052502898266539, "Avg policy loss": 0.29244816955178976, "Total num played games": 64668, "Total num trained steps": 128768, "Timestamp in ms": 1701956070396, "logtype": "training_step"}
{"Total num played games": 64762, "Total num trained steps": 128833, "Timestamp in ms": 1701956151458, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5546875}
{"Avg objective": 22.5390625, "Games time in secs": 137.3792427740991, "Avg game time in secs": 1.9303035949415062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.73, "agent_stopped_0": 0.31}, "Total num played games": 64768, "Total num trained steps": 128835, "Timestamp in ms": 1701956152917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874182804983347, "Avg loss": 1.3504730020649731, "Avg value loss": 1.047021401260281, "Avg policy loss": 0.3034516006009653, "Total num played games": 64856, "Total num trained steps": 128896, "Timestamp in ms": 1701956179504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893918835574196, "Avg loss": 0.4413383121136576, "Avg value loss": 0.13600631296867505, "Avg policy loss": 0.3053319964092225, "Total num played games": 64856, "Total num trained steps": 129024, "Timestamp in ms": 1701956239032, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913654866165043, "Avg loss": 0.34143122285604477, "Avg value loss": 0.059762246324680746, "Avg policy loss": 0.28166897688061, "Total num played games": 64856, "Total num trained steps": 129152, "Timestamp in ms": 1701956294419, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 165.23589615523815, "Avg game time in secs": 1.6681665184150916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 64896, "Total num trained steps": 129204, "Timestamp in ms": 1701956318153, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990454195535027, "Avg loss": 0.7391260840231553, "Avg value loss": 0.4518951773934532, "Avg policy loss": 0.28723091434221715, "Total num played games": 64950, "Total num trained steps": 129280, "Timestamp in ms": 1701956349830, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 80.63714110478759, "Avg game time in secs": 1.7322317671205383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 65024, "Total num trained steps": 129394, "Timestamp in ms": 1701956398791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895455384047722, "Avg loss": 0.5529041530098766, "Avg value loss": 0.26751776863238774, "Avg policy loss": 0.2853863911004737, "Total num played games": 65044, "Total num trained steps": 129408, "Timestamp in ms": 1701956404237, "logtype": "training_step"}
{"Total num played games": 65044, "Total num trained steps": 129438, "Timestamp in ms": 1701956435382, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.64453125}
{"Ratio train steps to played games": 1.9886395038226534, "Avg loss": 0.9754423566628247, "Avg value loss": 0.6580407430883497, "Avg policy loss": 0.3174016176490113, "Total num played games": 65138, "Total num trained steps": 129536, "Timestamp in ms": 1701956479015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906045626208972, "Avg loss": 0.3673630841076374, "Avg value loss": 0.07885341907967813, "Avg policy loss": 0.28850966435857117, "Total num played games": 65138, "Total num trained steps": 129664, "Timestamp in ms": 1701956533014, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 180.30789698660374, "Avg game time in secs": 1.7560085472941864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 65152, "Total num trained steps": 129768, "Timestamp in ms": 1701956579099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896829776796665, "Avg loss": 0.6548590026795864, "Avg value loss": 0.3819079935201444, "Avg policy loss": 0.27295101003255695, "Total num played games": 65232, "Total num trained steps": 129792, "Timestamp in ms": 1701956590272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916605347068923, "Avg loss": 0.4804560209158808, "Avg value loss": 0.1970316241204273, "Avg policy loss": 0.28342439141124487, "Total num played games": 65232, "Total num trained steps": 129920, "Timestamp in ms": 1701956645561, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 82.45763038098812, "Avg game time in secs": 1.6533784233324695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.52}, "Total num played games": 65280, "Total num trained steps": 129957, "Timestamp in ms": 1701956661557, "logtype": "played_game"}
{"Total num played games": 65326, "Total num trained steps": 130040, "Timestamp in ms": 1701956764097, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3046875}
{"Avg objective": 22.8125, "Games time in secs": 105.27235922589898, "Avg game time in secs": 1.7219605909194797, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 65408, "Total num trained steps": 130044, "Timestamp in ms": 1701956766829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879543856430952, "Avg loss": 1.052493707393296, "Avg value loss": 0.7600056307564955, "Avg policy loss": 0.29248807742260396, "Total num played games": 65418, "Total num trained steps": 130048, "Timestamp in ms": 1701956768271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989850198715989, "Avg loss": 0.7788968107197434, "Avg value loss": 0.48154807279934175, "Avg policy loss": 0.29734872828703374, "Total num played games": 65420, "Total num trained steps": 130176, "Timestamp in ms": 1701956821170, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918067869153164, "Avg loss": 0.345995687879622, "Avg value loss": 0.06866483855992556, "Avg policy loss": 0.27733085211366415, "Total num played games": 65420, "Total num trained steps": 130304, "Timestamp in ms": 1701956876666, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908874439051196, "Avg loss": 0.7688726664055139, "Avg value loss": 0.47349768597632647, "Avg policy loss": 0.29537497425917536, "Total num played games": 65514, "Total num trained steps": 130432, "Timestamp in ms": 1701956930427, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 202.83080357313156, "Avg game time in secs": 1.768108667631168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 65536, "Total num trained steps": 130520, "Timestamp in ms": 1701956969660, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899405578417924, "Avg loss": 0.9112869901582599, "Avg value loss": 0.6207631136348937, "Avg policy loss": 0.29052385955583304, "Total num played games": 65610, "Total num trained steps": 130560, "Timestamp in ms": 1701956986609, "logtype": "training_step"}
