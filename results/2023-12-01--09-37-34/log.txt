{"Avg objective": 18.71875, "Games time in secs": 185.97181194461882, "Avg game time in secs": 49.510415712124086, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 6.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.66, "played_steps": 2.6, "reached_maximum_moves": 0.01}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1701423646342, "logtype": "played_game"}
{"Avg objective": 16.796875, "Games time in secs": 162.6406854428351, "Avg game time in secs": 83.717962024195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 6.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 4.95, "agent_stopped_0": 0.22, "reached_maximum_moves": 0.07}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1701423808983, "logtype": "played_game"}
{"Ratio train steps to played games": 0.3657142857142857, "Avg loss": 60.37140738219023, "Avg value loss": 58.01871607452631, "Avg policy loss": 2.352691086009145, "Total num played games": 350, "Total num trained steps": 128, "Timestamp in ms": 1701423892234, "logtype": "training_step"}
{"Avg objective": 18.71875, "Games time in secs": 128.16656083613634, "Avg game time in secs": 74.45562518358929, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 5.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.57, "played_steps": 3.92, "reached_maximum_moves": 0.01}, "Total num played games": 384, "Total num trained steps": 201, "Timestamp in ms": 1701423937149, "logtype": "played_game"}
{"Ratio train steps to played games": 0.5691964285714286, "Avg loss": 8.35818288847804, "Avg value loss": 6.511103939265013, "Avg policy loss": 1.8470789128914475, "Total num played games": 448, "Total num trained steps": 256, "Timestamp in ms": 1701423971302, "logtype": "training_step"}
{"Ratio train steps to played games": 0.8571428571428571, "Avg loss": 5.368021199479699, "Avg value loss": 3.715915910899639, "Avg policy loss": 1.652105325832963, "Total num played games": 448, "Total num trained steps": 384, "Timestamp in ms": 1701424051835, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 124.29334608651698, "Avg game time in secs": 9.133481574885081, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.3}, "Total num played games": 512, "Total num trained steps": 398, "Timestamp in ms": 1701424061443, "logtype": "played_game"}
{"Ratio train steps to played games": 0.9411764705882353, "Avg loss": 5.230363391339779, "Avg value loss": 3.762206426821649, "Avg policy loss": 1.4681569719687104, "Total num played games": 544, "Total num trained steps": 512, "Timestamp in ms": 1701424131552, "logtype": "training_step"}
{"Avg objective": 19.875, "Games time in secs": 125.89035411737859, "Avg game time in secs": 10.3681037130591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.55}, "Total num played games": 640, "Total num trained steps": 603, "Timestamp in ms": 1701424187333, "logtype": "played_game"}
{"Total num played games": 642, "Total num trained steps": 603, "Timestamp in ms": 1701424223343, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.203125}
{"Ratio train steps to played games": 0.8695652173913043, "Avg loss": 3.806085715070367, "Avg value loss": 2.443866830319166, "Avg policy loss": 1.3622188521549106, "Total num played games": 736, "Total num trained steps": 640, "Timestamp in ms": 1701424243017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.0421195652173914, "Avg loss": 5.126739649102092, "Avg value loss": 3.91395768430084, "Avg policy loss": 1.212781984359026, "Total num played games": 736, "Total num trained steps": 768, "Timestamp in ms": 1701424306725, "logtype": "training_step"}
{"Ratio train steps to played games": 1.2173913043478262, "Avg loss": 3.827843524515629, "Avg value loss": 2.6278709806501865, "Avg policy loss": 1.199972572736442, "Total num played games": 736, "Total num trained steps": 896, "Timestamp in ms": 1701424370506, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 223.33716804347932, "Avg game time in secs": 8.323923876232584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 0.27, "agent_stopped_0": 0.8}, "Total num played games": 768, "Total num trained steps": 979, "Timestamp in ms": 1701424410671, "logtype": "played_game"}
{"Ratio train steps to played games": 1.2278177458033572, "Avg loss": 3.916994407773018, "Avg value loss": 2.7449222025461495, "Avg policy loss": 1.1720722084864974, "Total num played games": 834, "Total num trained steps": 1024, "Timestamp in ms": 1701424432291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.381294964028777, "Avg loss": 3.642597233876586, "Avg value loss": 2.521810157224536, "Avg policy loss": 1.1207870882935822, "Total num played games": 834, "Total num trained steps": 1152, "Timestamp in ms": 1701424493497, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 96.09723300114274, "Avg game time in secs": 8.53835035963857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.38, "agent_stopped_0": 0.68}, "Total num played games": 896, "Total num trained steps": 1181, "Timestamp in ms": 1701424506768, "logtype": "played_game"}
{"Total num played games": 934, "Total num trained steps": 1206, "Timestamp in ms": 1701424654134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0859375}
{"Avg objective": 21.0078125, "Games time in secs": 166.8417711313814, "Avg game time in secs": 12.753486480767606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.69, "agent_stopped_0": 0.7, "reached_maximum_moves": 0.02}, "Total num played games": 1024, "Total num trained steps": 1246, "Timestamp in ms": 1701424673610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.25, "Avg loss": 4.2412955686450005, "Avg value loss": 3.1736998204141855, "Avg policy loss": 1.0675957668572664, "Total num played games": 1024, "Total num trained steps": 1280, "Timestamp in ms": 1701424690237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3686770428015564, "Avg loss": 3.194632777944207, "Avg value loss": 2.1606978313066065, "Avg policy loss": 1.0339349531568587, "Total num played games": 1028, "Total num trained steps": 1408, "Timestamp in ms": 1701424753685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.4931906614785992, "Avg loss": 2.7227850379422307, "Avg value loss": 1.7237618979997933, "Avg policy loss": 0.9990231511183083, "Total num played games": 1028, "Total num trained steps": 1536, "Timestamp in ms": 1701424817318, "logtype": "training_step"}
{"Ratio train steps to played games": 1.472566371681416, "Avg loss": 3.189495529048145, "Avg value loss": 2.219986505806446, "Avg policy loss": 0.9695090311579406, "Total num played games": 1130, "Total num trained steps": 1664, "Timestamp in ms": 1701424879994, "logtype": "training_step"}
{"Avg objective": 19.984375, "Games time in secs": 255.44370786845684, "Avg game time in secs": 8.341437502065673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_more": 0.26, "played_steps": 0.36, "agent_stopped_0": 0.74}, "Total num played games": 1152, "Total num trained steps": 1763, "Timestamp in ms": 1701424929054, "logtype": "played_game"}
{"Ratio train steps to played games": 1.4592833876221498, "Avg loss": 2.3446723632514477, "Avg value loss": 1.3880033264867961, "Avg policy loss": 0.9566690353676677, "Total num played games": 1228, "Total num trained steps": 1792, "Timestamp in ms": 1701424942807, "logtype": "training_step"}
{"Total num played games": 1232, "Total num trained steps": 1807, "Timestamp in ms": 1701425079924, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.40625}
{"Avg objective": 20.8828125, "Games time in secs": 157.89130081422627, "Avg game time in secs": 7.76434457898722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.25}, "Total num played games": 1280, "Total num trained steps": 1820, "Timestamp in ms": 1701425086945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.4479638009049773, "Avg loss": 2.6552187828347087, "Avg value loss": 1.7222259961999953, "Avg policy loss": 0.9329927517101169, "Total num played games": 1326, "Total num trained steps": 1920, "Timestamp in ms": 1701425136337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5444947209653093, "Avg loss": 1.776717759668827, "Avg value loss": 0.9010017849504948, "Avg policy loss": 0.8757159761153162, "Total num played games": 1326, "Total num trained steps": 2048, "Timestamp in ms": 1701425198380, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 168.46796040795743, "Avg game time in secs": 7.771580219137832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.36, "agent_stopped_0": 0.66}, "Total num played games": 1408, "Total num trained steps": 2163, "Timestamp in ms": 1701425255413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.532394366197183, "Avg loss": 1.7539771301671863, "Avg value loss": 0.8991583450697362, "Avg policy loss": 0.8548187781125307, "Total num played games": 1420, "Total num trained steps": 2176, "Timestamp in ms": 1701425261761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.615007012622721, "Avg loss": 1.863816517405212, "Avg value loss": 1.032761471811682, "Avg policy loss": 0.8310550474561751, "Total num played games": 1426, "Total num trained steps": 2304, "Timestamp in ms": 1701425325926, "logtype": "training_step"}
{"Total num played games": 1524, "Total num trained steps": 2409, "Timestamp in ms": 1701425512711, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.7890625}
{"Avg objective": 20.1171875, "Games time in secs": 263.30887384712696, "Avg game time in secs": 7.880908068065764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.45, "agent_stopped_0": 0.72}, "Total num played games": 1536, "Total num trained steps": 2420, "Timestamp in ms": 1701425518722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.529559748427673, "Avg loss": 2.0550024257972836, "Avg value loss": 1.2435605600476265, "Avg policy loss": 0.8114418620243669, "Total num played games": 1590, "Total num trained steps": 2432, "Timestamp in ms": 1701425523816, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5822002472187886, "Avg loss": 1.8765434799715877, "Avg value loss": 1.1578041720204055, "Avg policy loss": 0.7187392911873758, "Total num played games": 1618, "Total num trained steps": 2560, "Timestamp in ms": 1701425586712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6606922126081582, "Avg loss": 1.4809415750205517, "Avg value loss": 0.7758792832028121, "Avg policy loss": 0.7050622906535864, "Total num played games": 1618, "Total num trained steps": 2688, "Timestamp in ms": 1701425661646, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 169.811106717214, "Avg game time in secs": 8.312568006353104, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.41}, "Total num played games": 1664, "Total num trained steps": 2738, "Timestamp in ms": 1701425688534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.641025641025641, "Avg loss": 1.7759606586769223, "Avg value loss": 1.1339897059369832, "Avg policy loss": 0.6419709583278745, "Total num played games": 1716, "Total num trained steps": 2816, "Timestamp in ms": 1701425727018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6496636771300448, "Avg loss": 1.4998491974547505, "Avg value loss": 0.8981357223819941, "Avg policy loss": 0.601713479263708, "Total num played games": 1784, "Total num trained steps": 2944, "Timestamp in ms": 1701425788479, "logtype": "training_step"}
{"Avg objective": 19.125, "Games time in secs": 100.91650792211294, "Avg game time in secs": 7.43758574637468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.24, "played_steps": 0.28}, "Total num played games": 1792, "Total num trained steps": 2945, "Timestamp in ms": 1701425789450, "logtype": "played_game"}
{"Total num played games": 1816, "Total num trained steps": 3011, "Timestamp in ms": 1701425863322, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9140625}
{"Ratio train steps to played games": 1.610062893081761, "Avg loss": 1.9793399842455983, "Avg value loss": 1.4835183219984174, "Avg policy loss": 0.4958216589875519, "Total num played games": 1908, "Total num trained steps": 3072, "Timestamp in ms": 1701425891951, "logtype": "training_step"}
{"Ratio train steps to played games": 1.675392670157068, "Avg loss": 1.3928737416863441, "Avg value loss": 0.9161495892331004, "Avg policy loss": 0.4767241640947759, "Total num played games": 1910, "Total num trained steps": 3200, "Timestamp in ms": 1701425951385, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 216.8206830471754, "Avg game time in secs": 7.838894891887321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.34, "agent_stopped_0": 0.7}, "Total num played games": 1920, "Total num trained steps": 3318, "Timestamp in ms": 1701426006273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6825075834175935, "Avg loss": 1.4203923344612122, "Avg value loss": 0.9590222525876015, "Avg policy loss": 0.46137008629739285, "Total num played games": 1978, "Total num trained steps": 3328, "Timestamp in ms": 1701426010379, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7211155378486056, "Avg loss": 1.5777224823832512, "Avg value loss": 1.1223031000699848, "Avg policy loss": 0.45541937719099224, "Total num played games": 2008, "Total num trained steps": 3456, "Timestamp in ms": 1701426071395, "logtype": "training_step"}
{"Avg objective": 21.796875, "Games time in secs": 93.328573288396, "Avg game time in secs": 5.639123349857982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.21}, "Total num played games": 2048, "Total num trained steps": 3515, "Timestamp in ms": 1701426099601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.703422053231939, "Avg loss": 1.4278996870853007, "Avg value loss": 0.991168238222599, "Avg policy loss": 0.4367314532864839, "Total num played games": 2104, "Total num trained steps": 3584, "Timestamp in ms": 1701426130615, "logtype": "training_step"}
{"Total num played games": 2104, "Total num trained steps": 3614, "Timestamp in ms": 1701426189432, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.26171875}
{"Avg objective": 20.375, "Games time in secs": 98.19263931177557, "Avg game time in secs": 4.880405236253864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.24}, "Total num played games": 2176, "Total num trained steps": 3629, "Timestamp in ms": 1701426197794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6888080072793448, "Avg loss": 1.5626254891976714, "Avg value loss": 1.143247531261295, "Avg policy loss": 0.4193779530469328, "Total num played games": 2198, "Total num trained steps": 3712, "Timestamp in ms": 1701426235936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7470427661510464, "Avg loss": 1.0400203559547663, "Avg value loss": 0.6230999333783984, "Avg policy loss": 0.4169204169884324, "Total num played games": 2198, "Total num trained steps": 3840, "Timestamp in ms": 1701426294946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7297297297297298, "Avg loss": 1.270480951294303, "Avg value loss": 0.8757216222584248, "Avg policy loss": 0.3947593269404024, "Total num played games": 2294, "Total num trained steps": 3968, "Timestamp in ms": 1701426353613, "logtype": "training_step"}
{"Avg objective": 19.6484375, "Games time in secs": 211.39279884658754, "Avg game time in secs": 5.82241611473728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.3}, "Total num played games": 2304, "Total num trained steps": 4084, "Timestamp in ms": 1701426409188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7311918850380388, "Avg loss": 1.0201213844120502, "Avg value loss": 0.6353701138868928, "Avg policy loss": 0.384751264937222, "Total num played games": 2366, "Total num trained steps": 4096, "Timestamp in ms": 1701426414476, "logtype": "training_step"}
{"Total num played games": 2390, "Total num trained steps": 4216, "Timestamp in ms": 1701426510265, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.53125}
{"Ratio train steps to played games": 1.765468227424749, "Avg loss": 1.141338664572686, "Avg value loss": 0.7462731141131371, "Avg policy loss": 0.3950655518565327, "Total num played games": 2390, "Total num trained steps": 4224, "Timestamp in ms": 1701426514279, "logtype": "training_step"}
{"Avg objective": 20.0546875, "Games time in secs": 108.16159050166607, "Avg game time in secs": 5.618957644226612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.31}, "Total num played games": 2432, "Total num trained steps": 4231, "Timestamp in ms": 1701426517350, "logtype": "played_game"}
{"Ratio train steps to played games": 1.752012882447665, "Avg loss": 1.4458210114389658, "Avg value loss": 1.056034616427496, "Avg policy loss": 0.389786395477131, "Total num played games": 2484, "Total num trained steps": 4352, "Timestamp in ms": 1701426575733, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 118.51133979670703, "Avg game time in secs": 5.767436035443097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.34, "agent_stopped_0": 0.67}, "Total num played games": 2560, "Total num trained steps": 4474, "Timestamp in ms": 1701426635861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7391304347826086, "Avg loss": 1.2090686280280352, "Avg value loss": 0.836438165511936, "Avg policy loss": 0.37263045622967184, "Total num played games": 2576, "Total num trained steps": 4480, "Timestamp in ms": 1701426638372, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7846630518977538, "Avg loss": 1.5253246081992984, "Avg value loss": 1.138976369984448, "Avg policy loss": 0.3863482370506972, "Total num played games": 2582, "Total num trained steps": 4608, "Timestamp in ms": 1701426695705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7684839432412247, "Avg loss": 1.405781497247517, "Avg value loss": 1.0335290771909058, "Avg policy loss": 0.37225242517888546, "Total num played games": 2678, "Total num trained steps": 4736, "Timestamp in ms": 1701426755822, "logtype": "training_step"}
{"Total num played games": 2678, "Total num trained steps": 4816, "Timestamp in ms": 1701426835593, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5390625}
{"Avg objective": 19.765625, "Games time in secs": 203.644453689456, "Avg game time in secs": 5.54328326828545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 2688, "Total num trained steps": 4824, "Timestamp in ms": 1701426839506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7546897546897546, "Avg loss": 1.3238451038487256, "Avg value loss": 0.9581150186713785, "Avg policy loss": 0.36573009053245187, "Total num played games": 2772, "Total num trained steps": 4864, "Timestamp in ms": 1701426858366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8005050505050506, "Avg loss": 1.0527649959549308, "Avg value loss": 0.6755872082430869, "Avg policy loss": 0.3771777923684567, "Total num played games": 2772, "Total num trained steps": 4992, "Timestamp in ms": 1701426917808, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 102.38908513262868, "Avg game time in secs": 5.197650783375138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.31}, "Total num played games": 2816, "Total num trained steps": 5044, "Timestamp in ms": 1701426941895, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7852161785216178, "Avg loss": 1.042272727470845, "Avg value loss": 0.6775497095659375, "Avg policy loss": 0.3647230213973671, "Total num played games": 2868, "Total num trained steps": 5120, "Timestamp in ms": 1701426977887, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 91.24295724742115, "Avg game time in secs": 4.735369151094346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 2944, "Total num trained steps": 5241, "Timestamp in ms": 1701427033138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7765741367637102, "Avg loss": 0.9946355493739247, "Avg value loss": 0.6265142136253417, "Avg policy loss": 0.3681213369127363, "Total num played games": 2954, "Total num trained steps": 5248, "Timestamp in ms": 1701427035913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8137651821862348, "Avg loss": 1.2080097245052457, "Avg value loss": 0.8313875726889819, "Avg policy loss": 0.3766221513506025, "Total num played games": 2964, "Total num trained steps": 5376, "Timestamp in ms": 1701427092184, "logtype": "training_step"}
{"Total num played games": 3058, "Total num trained steps": 5419, "Timestamp in ms": 1701427148089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.03125}
{"Avg objective": 21.765625, "Games time in secs": 118.67185526899993, "Avg game time in secs": 4.951254555635387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.48}, "Total num played games": 3072, "Total num trained steps": 5425, "Timestamp in ms": 1701427151810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7461928934010151, "Avg loss": 1.3615852422080934, "Avg value loss": 0.9827141740825027, "Avg policy loss": 0.37887107429560274, "Total num played games": 3152, "Total num trained steps": 5504, "Timestamp in ms": 1701427188811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7868020304568528, "Avg loss": 0.8646182203665376, "Avg value loss": 0.487280395347625, "Avg policy loss": 0.3773378178011626, "Total num played games": 3152, "Total num trained steps": 5632, "Timestamp in ms": 1701427245993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8274111675126903, "Avg loss": 0.7653362355194986, "Avg value loss": 0.40588377229869366, "Avg policy loss": 0.35945246438495815, "Total num played games": 3152, "Total num trained steps": 5760, "Timestamp in ms": 1701427304196, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 171.49525130726397, "Avg game time in secs": 3.9962867795693455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.78, "agent_stopped_more": 0.22, "played_steps": 0.26}, "Total num played games": 3200, "Total num trained steps": 5802, "Timestamp in ms": 1701427323305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8116923076923077, "Avg loss": 0.9566327929496765, "Avg value loss": 0.5891502464655787, "Avg policy loss": 0.3674825376365334, "Total num played games": 3250, "Total num trained steps": 5888, "Timestamp in ms": 1701427361504, "logtype": "training_step"}
{"Avg objective": 20.1484375, "Games time in secs": 90.80477739498019, "Avg game time in secs": 4.427664852439193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.42, "agent_stopped_0": 0.61}, "Total num played games": 3328, "Total num trained steps": 6005, "Timestamp in ms": 1701427414110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8011976047904192, "Avg loss": 0.8472292120568454, "Avg value loss": 0.4759127604775131, "Avg policy loss": 0.3713164501823485, "Total num played games": 3340, "Total num trained steps": 6016, "Timestamp in ms": 1701427418376, "logtype": "training_step"}
{"Total num played games": 3346, "Total num trained steps": 6022, "Timestamp in ms": 1701427461843, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3046875}
{"Ratio train steps to played games": 1.786046511627907, "Avg loss": 1.028536831960082, "Avg value loss": 0.6503871649038047, "Avg policy loss": 0.37814966519363225, "Total num played games": 3440, "Total num trained steps": 6144, "Timestamp in ms": 1701427518704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8229651162790699, "Avg loss": 0.853493541944772, "Avg value loss": 0.49735180917195976, "Avg policy loss": 0.3561417357996106, "Total num played games": 3440, "Total num trained steps": 6272, "Timestamp in ms": 1701427577237, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 208.50841138884425, "Avg game time in secs": 4.585036927062902, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.38, "agent_stopped_0": 0.64}, "Total num played games": 3456, "Total num trained steps": 6374, "Timestamp in ms": 1701427622619, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8089315997738835, "Avg loss": 0.9879304929636419, "Avg value loss": 0.6483127735555172, "Avg policy loss": 0.3396177205722779, "Total num played games": 3538, "Total num trained steps": 6400, "Timestamp in ms": 1701427633729, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8451102317693613, "Avg loss": 1.0104071972891688, "Avg value loss": 0.669013662263751, "Avg policy loss": 0.3413935344433412, "Total num played games": 3538, "Total num trained steps": 6528, "Timestamp in ms": 1701427690932, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 87.83936991728842, "Avg game time in secs": 3.5125693226291332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.27}, "Total num played games": 3584, "Total num trained steps": 6572, "Timestamp in ms": 1701427710458, "logtype": "played_game"}
{"Total num played games": 3634, "Total num trained steps": 6624, "Timestamp in ms": 1701427763772, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.51953125}
{"Avg objective": 20.203125, "Games time in secs": 61.12378014624119, "Avg game time in secs": 4.099797352580936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 3712, "Total num trained steps": 6638, "Timestamp in ms": 1701427771582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7863660762211486, "Avg loss": 1.2355470098555088, "Avg value loss": 0.8699072969611734, "Avg policy loss": 0.36563972057774663, "Total num played games": 3726, "Total num trained steps": 6656, "Timestamp in ms": 1701427780375, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8197424892703862, "Avg loss": 0.8945465418510139, "Avg value loss": 0.5219553266651928, "Avg policy loss": 0.37259121611714363, "Total num played games": 3728, "Total num trained steps": 6784, "Timestamp in ms": 1701427836943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.854077253218884, "Avg loss": 0.7301643462851644, "Avg value loss": 0.3728303115349263, "Avg policy loss": 0.3573340366128832, "Total num played games": 3728, "Total num trained steps": 6912, "Timestamp in ms": 1701427895913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8410041841004183, "Avg loss": 0.9422498252242804, "Avg value loss": 0.5862383299972862, "Avg policy loss": 0.35601149243302643, "Total num played games": 3824, "Total num trained steps": 7040, "Timestamp in ms": 1701427953095, "logtype": "training_step"}
{"Avg objective": 21.234375, "Games time in secs": 224.77516662701964, "Avg game time in secs": 4.153727286829962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 3840, "Total num trained steps": 7141, "Timestamp in ms": 1701427996358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8285714285714285, "Avg loss": 0.9140186528675258, "Avg value loss": 0.5417514590080827, "Avg policy loss": 0.3722671954892576, "Total num played games": 3920, "Total num trained steps": 7168, "Timestamp in ms": 1701428007884, "logtype": "training_step"}
{"Total num played games": 3920, "Total num trained steps": 7225, "Timestamp in ms": 1701428058956, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.98828125}
{"Avg objective": 20.8828125, "Games time in secs": 67.68827687576413, "Avg game time in secs": 3.05202996431035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.27}, "Total num played games": 3968, "Total num trained steps": 7235, "Timestamp in ms": 1701428064046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8176382660687593, "Avg loss": 0.9936327808536589, "Avg value loss": 0.6363587961532176, "Avg policy loss": 0.3572739869123325, "Total num played games": 4014, "Total num trained steps": 7296, "Timestamp in ms": 1701428091669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8495266567015447, "Avg loss": 0.7876087483018637, "Avg value loss": 0.4457849124446511, "Avg policy loss": 0.34182382957078516, "Total num played games": 4014, "Total num trained steps": 7424, "Timestamp in ms": 1701428146849, "logtype": "training_step"}
{"Avg objective": 19.65625, "Games time in secs": 131.61207688599825, "Avg game time in secs": 3.8366648265364347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 4096, "Total num trained steps": 7530, "Timestamp in ms": 1701428195658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.837469586374696, "Avg loss": 0.7570550730451941, "Avg value loss": 0.4359422726556659, "Avg policy loss": 0.3211128000402823, "Total num played games": 4110, "Total num trained steps": 7552, "Timestamp in ms": 1701428205051, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8686131386861313, "Avg loss": 0.7024524370208383, "Avg value loss": 0.3604452470317483, "Avg policy loss": 0.34200718998908997, "Total num played games": 4110, "Total num trained steps": 7680, "Timestamp in ms": 1701428263957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8563956252971945, "Avg loss": 0.8154290057718754, "Avg value loss": 0.4724765488645062, "Avg policy loss": 0.34295245446264744, "Total num played games": 4206, "Total num trained steps": 7808, "Timestamp in ms": 1701428320006, "logtype": "training_step"}
{"Total num played games": 4206, "Total num trained steps": 7827, "Timestamp in ms": 1701428355155, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.23046875}
{"Avg objective": 19.890625, "Games time in secs": 162.83465607091784, "Avg game time in secs": 3.5322020702442387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.44, "agent_stopped_0": 0.6}, "Total num played games": 4224, "Total num trained steps": 7832, "Timestamp in ms": 1701428358493, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8455813953488371, "Avg loss": 0.853044668212533, "Avg value loss": 0.5168747995048761, "Avg policy loss": 0.33616986381821334, "Total num played games": 4300, "Total num trained steps": 7936, "Timestamp in ms": 1701428404330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8751162790697675, "Avg loss": 0.6632673146668822, "Avg value loss": 0.3464263075729832, "Avg policy loss": 0.31684100290294737, "Total num played games": 4300, "Total num trained steps": 8064, "Timestamp in ms": 1701428460846, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 116.53306491859257, "Avg game time in secs": 3.346727618132718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.36}, "Total num played games": 4352, "Total num trained steps": 8097, "Timestamp in ms": 1701428475026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8635122838944496, "Avg loss": 0.8403516369871795, "Avg value loss": 0.5131721005309373, "Avg policy loss": 0.32717953179962933, "Total num played games": 4396, "Total num trained steps": 8192, "Timestamp in ms": 1701428518247, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 88.55783123709261, "Avg game time in secs": 3.2958888941357145, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 4480, "Total num trained steps": 8295, "Timestamp in ms": 1701428563584, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8521816562778273, "Avg loss": 0.7282804765272886, "Avg value loss": 0.40164120960980654, "Avg policy loss": 0.32663926505483687, "Total num played games": 4492, "Total num trained steps": 8320, "Timestamp in ms": 1701428575628, "logtype": "training_step"}
{"Total num played games": 4492, "Total num trained steps": 8431, "Timestamp in ms": 1701428650225, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.86328125}
{"Ratio train steps to played games": 1.8437363596682672, "Avg loss": 0.7389547852799296, "Avg value loss": 0.4131137776421383, "Avg policy loss": 0.3258410118287429, "Total num played games": 4580, "Total num trained steps": 8448, "Timestamp in ms": 1701428658678, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8700392498909726, "Avg loss": 0.8215157394297421, "Avg value loss": 0.49346246116328984, "Avg policy loss": 0.3280532838543877, "Total num played games": 4586, "Total num trained steps": 8576, "Timestamp in ms": 1701428716407, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 193.16982577368617, "Avg game time in secs": 3.400252258652472, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.44, "agent_stopped_0": 0.64}, "Total num played games": 4608, "Total num trained steps": 8667, "Timestamp in ms": 1701428756754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.859034600598035, "Avg loss": 0.8147067306563258, "Avg value loss": 0.4961491001304239, "Avg policy loss": 0.31855762749910355, "Total num played games": 4682, "Total num trained steps": 8704, "Timestamp in ms": 1701428773338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8863733447244768, "Avg loss": 0.7536276816390455, "Avg value loss": 0.42602238641120493, "Avg policy loss": 0.32760529476217926, "Total num played games": 4682, "Total num trained steps": 8832, "Timestamp in ms": 1701428830501, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 86.94779586046934, "Avg game time in secs": 3.0536524117778754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 4736, "Total num trained steps": 8861, "Timestamp in ms": 1701428843702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.875261615738803, "Avg loss": 0.9677729909308255, "Avg value loss": 0.6260338600259274, "Avg policy loss": 0.34173912927508354, "Total num played games": 4778, "Total num trained steps": 8960, "Timestamp in ms": 1701428888697, "logtype": "training_step"}
{"Total num played games": 4778, "Total num trained steps": 9033, "Timestamp in ms": 1701428946908, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.51171875}
{"Avg objective": 19.1796875, "Games time in secs": 110.72690946795046, "Avg game time in secs": 3.2161363180639455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 4864, "Total num trained steps": 9047, "Timestamp in ms": 1701428954429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8653530377668308, "Avg loss": 0.8137440737336874, "Avg value loss": 0.4783452053088695, "Avg policy loss": 0.3353988672606647, "Total num played games": 4872, "Total num trained steps": 9088, "Timestamp in ms": 1701428973029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8916256157635467, "Avg loss": 0.6652203798294067, "Avg value loss": 0.3257921999320388, "Avg policy loss": 0.33942817838396877, "Total num played games": 4872, "Total num trained steps": 9216, "Timestamp in ms": 1701429030336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8808373590982286, "Avg loss": 0.819013842381537, "Avg value loss": 0.4757230975665152, "Avg policy loss": 0.34329074423294514, "Total num played games": 4968, "Total num trained steps": 9344, "Timestamp in ms": 1701429086947, "logtype": "training_step"}
{"Avg objective": 19.7734375, "Games time in secs": 169.79918816313148, "Avg game time in secs": 3.1509723519557156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.42, "agent_stopped_0": 0.64}, "Total num played games": 4992, "Total num trained steps": 9430, "Timestamp in ms": 1701429124228, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8704581358609795, "Avg loss": 0.7802643170580268, "Avg value loss": 0.4455284251598641, "Avg policy loss": 0.3347358946921304, "Total num played games": 5064, "Total num trained steps": 9472, "Timestamp in ms": 1701429142995, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8955371248025277, "Avg loss": 0.7059704465791583, "Avg value loss": 0.35194370069075376, "Avg policy loss": 0.3540267429780215, "Total num played games": 5064, "Total num trained steps": 9600, "Timestamp in ms": 1701429198174, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 85.29064688272774, "Avg game time in secs": 2.651722037247964, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.34}, "Total num played games": 5120, "Total num trained steps": 9625, "Timestamp in ms": 1701429209519, "logtype": "played_game"}
{"Total num played games": 5160, "Total num trained steps": 9634, "Timestamp in ms": 1701429235853, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.30078125}
{"Avg objective": 20.859375, "Games time in secs": 33.27959230542183, "Avg game time in secs": 3.0756875484075863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.46, "agent_stopped_0": 0.58}, "Total num played games": 5248, "Total num trained steps": 9648, "Timestamp in ms": 1701429242799, "logtype": "played_game"}
{"Ratio train steps to played games": 1.851541682527598, "Avg loss": 0.9900932777673006, "Avg value loss": 0.6268430894706398, "Avg policy loss": 0.3632501842221245, "Total num played games": 5254, "Total num trained steps": 9728, "Timestamp in ms": 1701429279418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8759040730871717, "Avg loss": 0.7120498968288302, "Avg value loss": 0.3505793691147119, "Avg policy loss": 0.36147052980959415, "Total num played games": 5254, "Total num trained steps": 9856, "Timestamp in ms": 1701429335245, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9002664636467452, "Avg loss": 0.6423566683661193, "Avg value loss": 0.2913930600043386, "Avg policy loss": 0.3509636071976274, "Total num played games": 5254, "Total num trained steps": 9984, "Timestamp in ms": 1701429392502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8900934579439252, "Avg loss": 0.8181455777958035, "Avg value loss": 0.46369655325543135, "Avg policy loss": 0.3544490225613117, "Total num played games": 5350, "Total num trained steps": 10112, "Timestamp in ms": 1701429449062, "logtype": "training_step"}
{"Avg objective": 18.953125, "Games time in secs": 243.1913161519915, "Avg game time in secs": 2.969590520558995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 5376, "Total num trained steps": 10194, "Timestamp in ms": 1701429485991, "logtype": "played_game"}
{"Total num played games": 5446, "Total num trained steps": 10237, "Timestamp in ms": 1701429525384, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.046875}
{"Ratio train steps to played games": 1.8802791039294895, "Avg loss": 0.7783833239227533, "Avg value loss": 0.42032028234098107, "Avg policy loss": 0.3580630359938368, "Total num played games": 5446, "Total num trained steps": 10240, "Timestamp in ms": 1701429526935, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 43.12622081115842, "Avg game time in secs": 2.758562509683543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.4}, "Total num played games": 5504, "Total num trained steps": 10244, "Timestamp in ms": 1701429529117, "logtype": "played_game"}
{"Ratio train steps to played games": 1.871480144404332, "Avg loss": 0.9278651960194111, "Avg value loss": 0.570982517907396, "Avg policy loss": 0.3568826799746603, "Total num played games": 5540, "Total num trained steps": 10368, "Timestamp in ms": 1701429584405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8945848375451264, "Avg loss": 0.6504877808038145, "Avg value loss": 0.30851684021763504, "Avg policy loss": 0.3419709348818287, "Total num played games": 5540, "Total num trained steps": 10496, "Timestamp in ms": 1701429641170, "logtype": "training_step"}
{"Avg objective": 19.5234375, "Games time in secs": 152.74005788564682, "Avg game time in secs": 3.0929625827702694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 5632, "Total num trained steps": 10587, "Timestamp in ms": 1701429681857, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8850248403122782, "Avg loss": 0.7785484062042087, "Avg value loss": 0.43061683676205575, "Avg policy loss": 0.3479315704898909, "Total num played games": 5636, "Total num trained steps": 10624, "Timestamp in ms": 1701429698902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.907735982966643, "Avg loss": 0.6844346388243139, "Avg value loss": 0.3295738671440631, "Avg policy loss": 0.3548607723787427, "Total num played games": 5636, "Total num trained steps": 10752, "Timestamp in ms": 1701429755164, "logtype": "training_step"}
{"Total num played games": 5732, "Total num trained steps": 10837, "Timestamp in ms": 1701429816763, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1328125}
{"Avg objective": 20.078125, "Games time in secs": 138.0922792274505, "Avg game time in secs": 2.766354072417016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.38, "agent_stopped_0": 0.68}, "Total num played games": 5760, "Total num trained steps": 10843, "Timestamp in ms": 1701429819949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8674905595605904, "Avg loss": 0.9253307455219328, "Avg value loss": 0.567941791494377, "Avg policy loss": 0.3573889520484954, "Total num played games": 5826, "Total num trained steps": 10880, "Timestamp in ms": 1701429837204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8894610367318916, "Avg loss": 0.7045466341078281, "Avg value loss": 0.3452264830702916, "Avg policy loss": 0.35932015301659703, "Total num played games": 5826, "Total num trained steps": 11008, "Timestamp in ms": 1701429894366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9114315139031925, "Avg loss": 0.6242866194806993, "Avg value loss": 0.28528073732741177, "Avg policy loss": 0.339005880523473, "Total num played games": 5826, "Total num trained steps": 11136, "Timestamp in ms": 1701429950101, "logtype": "training_step"}
{"Avg objective": 19.53125, "Games time in secs": 135.75404596328735, "Avg game time in secs": 2.667914706893498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 5888, "Total num trained steps": 11150, "Timestamp in ms": 1701429955704, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9020601148260723, "Avg loss": 0.7846046853810549, "Avg value loss": 0.42682425293605775, "Avg policy loss": 0.35778042557649314, "Total num played games": 5922, "Total num trained steps": 11264, "Timestamp in ms": 1701430006434, "logtype": "training_step"}
{"Avg objective": 20.984375, "Games time in secs": 88.30058492533863, "Avg game time in secs": 3.4313756876654224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.61, "agent_stopped_0": 0.47}, "Total num played games": 6016, "Total num trained steps": 11349, "Timestamp in ms": 1701430044004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8929877035559988, "Avg loss": 0.8175230654887855, "Avg value loss": 0.44901855231728405, "Avg policy loss": 0.36850451468490064, "Total num played games": 6018, "Total num trained steps": 11392, "Timestamp in ms": 1701430062652, "logtype": "training_step"}
{"Total num played games": 6018, "Total num trained steps": 11441, "Timestamp in ms": 1701430105970, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.23828125}
{"Ratio train steps to played games": 1.8848167539267016, "Avg loss": 0.9201793158426881, "Avg value loss": 0.541791309020482, "Avg policy loss": 0.3783880043774843, "Total num played games": 6112, "Total num trained steps": 11520, "Timestamp in ms": 1701430142625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.905759162303665, "Avg loss": 0.6972471671178937, "Avg value loss": 0.3250528259668499, "Avg policy loss": 0.37219434475991875, "Total num played games": 6112, "Total num trained steps": 11648, "Timestamp in ms": 1701430200975, "logtype": "training_step"}
{"Avg objective": 20.4296875, "Games time in secs": 189.51965001784265, "Avg game time in secs": 2.8384904880804243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.43, "agent_stopped_0": 0.62}, "Total num played games": 6144, "Total num trained steps": 11719, "Timestamp in ms": 1701430233524, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8969072164948453, "Avg loss": 0.8068599884863943, "Avg value loss": 0.435154685867019, "Avg policy loss": 0.3717053052969277, "Total num played games": 6208, "Total num trained steps": 11776, "Timestamp in ms": 1701430258843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9173646907216495, "Avg loss": 0.6792921689338982, "Avg value loss": 0.3095569834113121, "Avg policy loss": 0.36973518365994096, "Total num played games": 6208, "Total num trained steps": 11904, "Timestamp in ms": 1701430315437, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 85.88894353061914, "Avg game time in secs": 2.726290206090198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 6272, "Total num trained steps": 11914, "Timestamp in ms": 1701430319413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9092351634401776, "Avg loss": 0.8656369545497, "Avg value loss": 0.498472458566539, "Avg policy loss": 0.3671644984278828, "Total num played games": 6302, "Total num trained steps": 12032, "Timestamp in ms": 1701430372041, "logtype": "training_step"}
{"Total num played games": 6302, "Total num trained steps": 12041, "Timestamp in ms": 1701430399575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.35546875}
{"Ratio train steps to played games": 1.9011882426516573, "Avg loss": 0.8919375534169376, "Avg value loss": 0.5194426912348717, "Avg policy loss": 0.3724948647432029, "Total num played games": 6396, "Total num trained steps": 12160, "Timestamp in ms": 1701430454389, "logtype": "training_step"}
{"Avg objective": 20.46875, "Games time in secs": 191.928252261132, "Avg game time in secs": 2.922011091155582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 6400, "Total num trained steps": 12283, "Timestamp in ms": 1701430511342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9091050341827223, "Avg loss": 0.6303140309173614, "Avg value loss": 0.2659772465704009, "Avg policy loss": 0.3643367770127952, "Total num played games": 6436, "Total num trained steps": 12288, "Timestamp in ms": 1701430513163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9125077017868146, "Avg loss": 0.9022910483181477, "Avg value loss": 0.5061499305302277, "Avg policy loss": 0.39614111836999655, "Total num played games": 6492, "Total num trained steps": 12416, "Timestamp in ms": 1701430571440, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 87.07145002298057, "Avg game time in secs": 3.0045962773729116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 6528, "Total num trained steps": 12479, "Timestamp in ms": 1701430598414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9040680024286583, "Avg loss": 1.0970169350039214, "Avg value loss": 0.7193763186223805, "Avg policy loss": 0.3776406205724925, "Total num played games": 6588, "Total num trained steps": 12544, "Timestamp in ms": 1701430629697, "logtype": "training_step"}
{"Total num played games": 6588, "Total num trained steps": 12644, "Timestamp in ms": 1701430695557, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.51171875}
{"Avg objective": 19.7265625, "Games time in secs": 102.08390618674457, "Avg game time in secs": 2.8570643084531184, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 6656, "Total num trained steps": 12654, "Timestamp in ms": 1701430700498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8964381921580364, "Avg loss": 0.9614213178865612, "Avg value loss": 0.5846629531588405, "Avg policy loss": 0.3767583640292287, "Total num played games": 6682, "Total num trained steps": 12672, "Timestamp in ms": 1701430711002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9155941334929663, "Avg loss": 0.9954185415990651, "Avg value loss": 0.6046530527528375, "Avg policy loss": 0.3907654914073646, "Total num played games": 6682, "Total num trained steps": 12800, "Timestamp in ms": 1701430772065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9073473000885217, "Avg loss": 1.01606011018157, "Avg value loss": 0.630331051768735, "Avg policy loss": 0.38572905818000436, "Total num played games": 6778, "Total num trained steps": 12928, "Timestamp in ms": 1701430829594, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 183.5957359354943, "Avg game time in secs": 3.4635757473442936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.66}, "Total num played games": 6784, "Total num trained steps": 13048, "Timestamp in ms": 1701430884093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.90154383920769, "Avg loss": 0.8954576072283089, "Avg value loss": 0.5090028430568054, "Avg policy loss": 0.3864547641715035, "Total num played games": 6864, "Total num trained steps": 13056, "Timestamp in ms": 1701430887473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.918509895227008, "Avg loss": 1.0421190219931304, "Avg value loss": 0.6513703614473343, "Avg policy loss": 0.3907486607786268, "Total num played games": 6872, "Total num trained steps": 13184, "Timestamp in ms": 1701430944622, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 84.57605045288801, "Avg game time in secs": 2.6657444201409817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.38}, "Total num played games": 6912, "Total num trained steps": 13239, "Timestamp in ms": 1701430968670, "logtype": "played_game"}
{"Total num played games": 6968, "Total num trained steps": 13247, "Timestamp in ms": 1701430990406, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.62890625}
{"Avg objective": 20.234375, "Games time in secs": 26.56299125775695, "Avg game time in secs": 2.7426188120880397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 7040, "Total num trained steps": 13257, "Timestamp in ms": 1701430995233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8850184083828945, "Avg loss": 1.1583046833984554, "Avg value loss": 0.7528751392383128, "Avg policy loss": 0.405429549748078, "Total num played games": 7062, "Total num trained steps": 13312, "Timestamp in ms": 1701431021924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9031435853865761, "Avg loss": 0.816573241725564, "Avg value loss": 0.40195538895204663, "Avg policy loss": 0.41461785207502544, "Total num played games": 7062, "Total num trained steps": 13440, "Timestamp in ms": 1701431078535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9212687623902578, "Avg loss": 0.7006003577262163, "Avg value loss": 0.31013896386139095, "Avg policy loss": 0.3904613899067044, "Total num played games": 7062, "Total num trained steps": 13568, "Timestamp in ms": 1701431137246, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9128491620111732, "Avg loss": 0.8171180146746337, "Avg value loss": 0.4392433710163459, "Avg policy loss": 0.3778746409807354, "Total num played games": 7160, "Total num trained steps": 13696, "Timestamp in ms": 1701431196175, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 252.98870863765478, "Avg game time in secs": 2.7551035732176388, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.46, "agent_stopped_0": 0.58}, "Total num played games": 7168, "Total num trained steps": 13812, "Timestamp in ms": 1701431248222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9057071960297767, "Avg loss": 0.7012401884421706, "Avg value loss": 0.3290950144873932, "Avg policy loss": 0.3721451766323298, "Total num played games": 7254, "Total num trained steps": 13824, "Timestamp in ms": 1701431252900, "logtype": "training_step"}
{"Total num played games": 7256, "Total num trained steps": 13848, "Timestamp in ms": 1701431291094, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3671875}
{"Avg objective": 20.96875, "Games time in secs": 46.36398964934051, "Avg game time in secs": 2.5192019794048974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.37}, "Total num played games": 7296, "Total num trained steps": 13854, "Timestamp in ms": 1701431294586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8982312925170068, "Avg loss": 1.052441016305238, "Avg value loss": 0.6448893113993108, "Avg policy loss": 0.4075516937300563, "Total num played games": 7350, "Total num trained steps": 13952, "Timestamp in ms": 1701431340088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9156462585034013, "Avg loss": 0.7392191370017827, "Avg value loss": 0.36191401933319867, "Avg policy loss": 0.3773051162716001, "Total num played games": 7350, "Total num trained steps": 14080, "Timestamp in ms": 1701431398214, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 155.3679518494755, "Avg game time in secs": 2.598457899177447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.39, "agent_stopped_0": 0.62}, "Total num played games": 7424, "Total num trained steps": 14197, "Timestamp in ms": 1701431449954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9080042976094547, "Avg loss": 0.6968734327238053, "Avg value loss": 0.33519349386915565, "Avg policy loss": 0.3616799416486174, "Total num played games": 7446, "Total num trained steps": 14208, "Timestamp in ms": 1701431454546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9253290357238786, "Avg loss": 0.7417860212735832, "Avg value loss": 0.37051171250641346, "Avg policy loss": 0.3712743050418794, "Total num played games": 7446, "Total num trained steps": 14336, "Timestamp in ms": 1701431512711, "logtype": "training_step"}
{"Total num played games": 7540, "Total num trained steps": 14449, "Timestamp in ms": 1701431586207, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.05859375}
{"Avg objective": 20.28125, "Games time in secs": 138.85299715958536, "Avg game time in secs": 3.487334284276585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.61}, "Total num played games": 7552, "Total num trained steps": 14454, "Timestamp in ms": 1701431588807, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8961719979024647, "Avg loss": 0.8007167230825871, "Avg value loss": 0.4388387211365625, "Avg policy loss": 0.3618779999669641, "Total num played games": 7626, "Total num trained steps": 14464, "Timestamp in ms": 1701431593160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9113177888394026, "Avg loss": 0.788551012519747, "Avg value loss": 0.40872183453757316, "Avg policy loss": 0.3798291755374521, "Total num played games": 7634, "Total num trained steps": 14592, "Timestamp in ms": 1701431652751, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9282158763426775, "Avg loss": 0.6529966201633215, "Avg value loss": 0.2876680687768385, "Avg policy loss": 0.36532854952383786, "Total num played games": 7634, "Total num trained steps": 14720, "Timestamp in ms": 1701431709680, "logtype": "training_step"}
{"Avg objective": 19.5078125, "Games time in secs": 140.46287164837122, "Avg game time in secs": 2.7341013275145087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 7680, "Total num trained steps": 14763, "Timestamp in ms": 1701431729270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9208279430789132, "Avg loss": 0.7949818794149905, "Avg value loss": 0.41567872930318117, "Avg policy loss": 0.3793031561654061, "Total num played games": 7730, "Total num trained steps": 14848, "Timestamp in ms": 1701431767113, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 88.90702042542398, "Avg game time in secs": 3.0812122221977916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.64}, "Total num played games": 7808, "Total num trained steps": 14958, "Timestamp in ms": 1701431818177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9136212624584719, "Avg loss": 0.8279990269802511, "Avg value loss": 0.4656637373846024, "Avg policy loss": 0.3623352989088744, "Total num played games": 7826, "Total num trained steps": 14976, "Timestamp in ms": 1701431825846, "logtype": "training_step"}
{"Total num played games": 7826, "Total num trained steps": 15053, "Timestamp in ms": 1701431885831, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.06640625}
{"Ratio train steps to played games": 1.9070707070707071, "Avg loss": 0.8608960313722491, "Avg value loss": 0.48347293911501765, "Avg policy loss": 0.37742309109307826, "Total num played games": 7920, "Total num trained steps": 15104, "Timestamp in ms": 1701431910759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9232323232323232, "Avg loss": 0.6784365822095424, "Avg value loss": 0.2999833020148799, "Avg policy loss": 0.3784532807767391, "Total num played games": 7920, "Total num trained steps": 15232, "Timestamp in ms": 1701431969654, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 197.71634047664702, "Avg game time in secs": 2.9463500903511886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 7936, "Total num trained steps": 15334, "Timestamp in ms": 1701432015893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9161676646706587, "Avg loss": 0.6971777263097465, "Avg value loss": 0.3413099682657048, "Avg policy loss": 0.35586775722913444, "Total num played games": 8016, "Total num trained steps": 15360, "Timestamp in ms": 1701432028303, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9321357285429142, "Avg loss": 0.6339316449593753, "Avg value loss": 0.2851346677634865, "Avg policy loss": 0.3487969759153202, "Total num played games": 8016, "Total num trained steps": 15488, "Timestamp in ms": 1701432086409, "logtype": "training_step"}
{"Avg objective": 19.453125, "Games time in secs": 88.14541566185653, "Avg game time in secs": 3.0655296636978164, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.53}, "Total num played games": 8064, "Total num trained steps": 15528, "Timestamp in ms": 1701432104039, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9250493096646943, "Avg loss": 0.686730615561828, "Avg value loss": 0.3310152710182592, "Avg policy loss": 0.355715349316597, "Total num played games": 8112, "Total num trained steps": 15616, "Timestamp in ms": 1701432144038, "logtype": "training_step"}
{"Total num played games": 8112, "Total num trained steps": 15654, "Timestamp in ms": 1701432181626, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3125}
{"Avg objective": 21.9609375, "Games time in secs": 83.23561076447368, "Avg game time in secs": 3.318035290503758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.63, "agent_stopped_0": 0.42}, "Total num played games": 8192, "Total num trained steps": 15664, "Timestamp in ms": 1701432187275, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9185961491591519, "Avg loss": 0.7987368325702846, "Avg value loss": 0.425804847269319, "Avg policy loss": 0.3729319872800261, "Total num played games": 8206, "Total num trained steps": 15744, "Timestamp in ms": 1701432222704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9340726297830855, "Avg loss": 0.6019084416329861, "Avg value loss": 0.23416839982382953, "Avg policy loss": 0.36774003645405173, "Total num played games": 8206, "Total num trained steps": 15872, "Timestamp in ms": 1701432281259, "logtype": "training_step"}
{"Ratio train steps to played games": 1.927246446639364, "Avg loss": 0.8747335132211447, "Avg value loss": 0.4918669613543898, "Avg policy loss": 0.3828665560577065, "Total num played games": 8302, "Total num trained steps": 16000, "Timestamp in ms": 1701432339595, "logtype": "training_step"}
{"Avg objective": 19.9140625, "Games time in secs": 195.56454150378704, "Avg game time in secs": 3.1273913720360724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 8320, "Total num trained steps": 16097, "Timestamp in ms": 1701432382839, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9204572517266016, "Avg loss": 0.8030739903915673, "Avg value loss": 0.4251740025356412, "Avg policy loss": 0.37789998785592616, "Total num played games": 8398, "Total num trained steps": 16128, "Timestamp in ms": 1701432397148, "logtype": "training_step"}
{"Total num played games": 8398, "Total num trained steps": 16255, "Timestamp in ms": 1701432477979, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.46875}
{"Ratio train steps to played games": 1.9356989759466539, "Avg loss": 0.7401024834252894, "Avg value loss": 0.3457090381998569, "Avg policy loss": 0.39439344592392445, "Total num played games": 8398, "Total num trained steps": 16256, "Timestamp in ms": 1701432479162, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 99.55724693275988, "Avg game time in secs": 2.724702197869192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 8448, "Total num trained steps": 16263, "Timestamp in ms": 1701432482397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.929345266132831, "Avg loss": 0.8123576850630343, "Avg value loss": 0.4190200987504795, "Avg policy loss": 0.3933375852648169, "Total num played games": 8492, "Total num trained steps": 16384, "Timestamp in ms": 1701432538729, "logtype": "training_step"}
{"Avg objective": 20.2109375, "Games time in secs": 100.92486465908587, "Avg game time in secs": 3.2871946624072734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.66}, "Total num played games": 8576, "Total num trained steps": 16485, "Timestamp in ms": 1701432583322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9226828132277596, "Avg loss": 0.7438043472357094, "Avg value loss": 0.36310481128748506, "Avg policy loss": 0.38069953373633325, "Total num played games": 8588, "Total num trained steps": 16512, "Timestamp in ms": 1701432595762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9375873311597578, "Avg loss": 0.6981357238255441, "Avg value loss": 0.29802802682388574, "Avg policy loss": 0.4001076980493963, "Total num played games": 8588, "Total num trained steps": 16640, "Timestamp in ms": 1701432655231, "logtype": "training_step"}
{"Ratio train steps to played games": 1.930907415937356, "Avg loss": 0.7786970427259803, "Avg value loss": 0.3780326237902045, "Avg policy loss": 0.4006644166074693, "Total num played games": 8684, "Total num trained steps": 16768, "Timestamp in ms": 1701432715482, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 174.26346890814602, "Avg game time in secs": 3.257532523624832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 8704, "Total num trained steps": 16857, "Timestamp in ms": 1701432757585, "logtype": "played_game"}
{"Total num played games": 8776, "Total num trained steps": 16857, "Timestamp in ms": 1701432785647, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.71484375}
{"Avg objective": 19.4609375, "Games time in secs": 32.96088865399361, "Avg game time in secs": 3.2483315875870176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 8832, "Total num trained steps": 16866, "Timestamp in ms": 1701432790546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.904847801578354, "Avg loss": 0.818392320536077, "Avg value loss": 0.4324699885910377, "Avg policy loss": 0.3859223343897611, "Total num played games": 8870, "Total num trained steps": 16896, "Timestamp in ms": 1701432804142, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9192784667418263, "Avg loss": 0.7944518178701401, "Avg value loss": 0.3786617318401113, "Avg policy loss": 0.4157900873105973, "Total num played games": 8870, "Total num trained steps": 17024, "Timestamp in ms": 1701432862523, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9337091319052988, "Avg loss": 0.6555478032678366, "Avg value loss": 0.2665805446449667, "Avg policy loss": 0.3889672541990876, "Total num played games": 8870, "Total num trained steps": 17152, "Timestamp in ms": 1701432920646, "logtype": "training_step"}
{"Avg objective": 19.8125, "Games time in secs": 170.30080525390804, "Avg game time in secs": 3.0439608447777573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.58, "agent_stopped_0": 0.51}, "Total num played games": 8960, "Total num trained steps": 17243, "Timestamp in ms": 1701432960847, "logtype": "played_game"}
{"Ratio train steps to played games": 1.926851025869759, "Avg loss": 0.7918072938919067, "Avg value loss": 0.3947786421049386, "Avg policy loss": 0.39702864713035524, "Total num played games": 8968, "Total num trained steps": 17280, "Timestamp in ms": 1701432978387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9411239964317573, "Avg loss": 0.6940087527036667, "Avg value loss": 0.28585657908115536, "Avg policy loss": 0.408152170246467, "Total num played games": 8968, "Total num trained steps": 17408, "Timestamp in ms": 1701433036958, "logtype": "training_step"}
{"Total num played games": 9064, "Total num trained steps": 17460, "Timestamp in ms": 1701433092012, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.92578125}
{"Avg objective": 18.6328125, "Games time in secs": 134.7132449708879, "Avg game time in secs": 2.9327553342591273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 9088, "Total num trained steps": 17466, "Timestamp in ms": 1701433095560, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9148285651889059, "Avg loss": 0.9206638161558658, "Avg value loss": 0.5014330465346575, "Avg policy loss": 0.4192307684570551, "Total num played games": 9158, "Total num trained steps": 17536, "Timestamp in ms": 1701433128653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9288054160297008, "Avg loss": 0.6259839572012424, "Avg value loss": 0.2382906893035397, "Avg policy loss": 0.38769326568581164, "Total num played games": 9158, "Total num trained steps": 17664, "Timestamp in ms": 1701433186970, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9427822668704957, "Avg loss": 0.6235918798483908, "Avg value loss": 0.2383192079141736, "Avg policy loss": 0.3852726723998785, "Total num played games": 9158, "Total num trained steps": 17792, "Timestamp in ms": 1701433245882, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 161.17451415024698, "Avg game time in secs": 3.3735051168187056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 9216, "Total num trained steps": 17816, "Timestamp in ms": 1701433256735, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9368785127539991, "Avg loss": 0.828791530802846, "Avg value loss": 0.43530514067970216, "Avg policy loss": 0.3934863891918212, "Total num played games": 9252, "Total num trained steps": 17920, "Timestamp in ms": 1701433303967, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 87.59736174158752, "Avg game time in secs": 3.859985318573308, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 9344, "Total num trained steps": 18008, "Timestamp in ms": 1701433344333, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9302673796791443, "Avg loss": 0.9036421333439648, "Avg value loss": 0.5139287149067968, "Avg policy loss": 0.3897134130820632, "Total num played games": 9350, "Total num trained steps": 18048, "Timestamp in ms": 1701433362070, "logtype": "training_step"}
{"Total num played games": 9350, "Total num trained steps": 18061, "Timestamp in ms": 1701433399451, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.79296875}
{"Ratio train steps to played games": 1.9246082168572638, "Avg loss": 0.9249086230993271, "Avg value loss": 0.49399413727223873, "Avg policy loss": 0.43091448419727385, "Total num played games": 9444, "Total num trained steps": 18176, "Timestamp in ms": 1701433453536, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9381617958492163, "Avg loss": 0.6655565975233912, "Avg value loss": 0.25994432100560516, "Avg policy loss": 0.40561227151192725, "Total num played games": 9444, "Total num trained steps": 18304, "Timestamp in ms": 1701433513179, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 204.6064127292484, "Avg game time in secs": 3.407809339565574, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 9472, "Total num trained steps": 18382, "Timestamp in ms": 1701433548939, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9320754716981132, "Avg loss": 0.7256858730688691, "Avg value loss": 0.32648800732567906, "Avg policy loss": 0.3991978687699884, "Total num played games": 9540, "Total num trained steps": 18432, "Timestamp in ms": 1701433572919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9454926624737945, "Avg loss": 0.6898362897336483, "Avg value loss": 0.28710958908777684, "Avg policy loss": 0.40272670122794807, "Total num played games": 9540, "Total num trained steps": 18560, "Timestamp in ms": 1701433631957, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 91.92235465534031, "Avg game time in secs": 3.6036656070500612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 9600, "Total num trained steps": 18578, "Timestamp in ms": 1701433640862, "logtype": "played_game"}
{"Total num played games": 9636, "Total num trained steps": 18663, "Timestamp in ms": 1701433706042, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.91796875}
{"Avg objective": 20.546875, "Games time in secs": 74.96424311026931, "Avg game time in secs": 3.557101764701656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 9728, "Total num trained steps": 18681, "Timestamp in ms": 1701433715826, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9206577595066803, "Avg loss": 1.0305465226992965, "Avg value loss": 0.6120246002683416, "Avg policy loss": 0.4185219230130315, "Total num played games": 9730, "Total num trained steps": 18688, "Timestamp in ms": 1701433718975, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9338129496402878, "Avg loss": 0.7972317989915609, "Avg value loss": 0.38203774322755635, "Avg policy loss": 0.4151940473821014, "Total num played games": 9730, "Total num trained steps": 18816, "Timestamp in ms": 1701433777418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9469681397738952, "Avg loss": 0.650954510550946, "Avg value loss": 0.24890271667391062, "Avg policy loss": 0.40205179317854345, "Total num played games": 9730, "Total num trained steps": 18944, "Timestamp in ms": 1701433835592, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9409729289639732, "Avg loss": 0.8038756800815463, "Avg value loss": 0.39827064680866897, "Avg policy loss": 0.40560503536835313, "Total num played games": 9826, "Total num trained steps": 19072, "Timestamp in ms": 1701433893671, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 211.03132551722229, "Avg game time in secs": 3.067777844640659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 9856, "Total num trained steps": 19146, "Timestamp in ms": 1701433926858, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9350937311026002, "Avg loss": 0.7783578685484827, "Avg value loss": 0.3746944507583976, "Avg policy loss": 0.403663415228948, "Total num played games": 9922, "Total num trained steps": 19200, "Timestamp in ms": 1701433950108, "logtype": "training_step"}
{"Total num played games": 9922, "Total num trained steps": 19265, "Timestamp in ms": 1701434005326, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.78125}
{"Avg objective": 19.7109375, "Games time in secs": 83.5320837162435, "Avg game time in secs": 3.0945025091641583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 9984, "Total num trained steps": 19274, "Timestamp in ms": 1701434010390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9297124600638977, "Avg loss": 0.8661674843169749, "Avg value loss": 0.4493164278101176, "Avg policy loss": 0.4168510597664863, "Total num played games": 10016, "Total num trained steps": 19328, "Timestamp in ms": 1701434035298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9424920127795526, "Avg loss": 0.674399106297642, "Avg value loss": 0.2754025956382975, "Avg policy loss": 0.3989965117070824, "Total num played games": 10016, "Total num trained steps": 19456, "Timestamp in ms": 1701434093176, "logtype": "training_step"}
{"Avg objective": 19.84375, "Games time in secs": 122.00653000548482, "Avg game time in secs": 3.5957788726809667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 10112, "Total num trained steps": 19543, "Timestamp in ms": 1701434132397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.936325884912003, "Avg loss": 0.7908803287427872, "Avg value loss": 0.39292129513341933, "Avg policy loss": 0.3979590297676623, "Total num played games": 10114, "Total num trained steps": 19584, "Timestamp in ms": 1701434150613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9489816096499901, "Avg loss": 0.6607066122815013, "Avg value loss": 0.26578336604870856, "Avg policy loss": 0.39492324902676046, "Total num played games": 10114, "Total num trained steps": 19712, "Timestamp in ms": 1701434210140, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9435736677115987, "Avg loss": 0.8233161172829568, "Avg value loss": 0.4112024352652952, "Avg policy loss": 0.4121136844623834, "Total num played games": 10208, "Total num trained steps": 19840, "Timestamp in ms": 1701434267444, "logtype": "training_step"}
{"Total num played games": 10208, "Total num trained steps": 19867, "Timestamp in ms": 1701434310435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.60546875}
{"Avg objective": 19.0234375, "Games time in secs": 182.2830452248454, "Avg game time in secs": 3.4558209600800183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 10240, "Total num trained steps": 19876, "Timestamp in ms": 1701434314680, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9382644146767618, "Avg loss": 0.7901949253864586, "Avg value loss": 0.3767584749730304, "Avg policy loss": 0.4134364486671984, "Total num played games": 10302, "Total num trained steps": 19968, "Timestamp in ms": 1701434358456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.950310559006211, "Avg loss": 0.6425764546729624, "Avg value loss": 0.2394788364181295, "Avg policy loss": 0.4030976209323853, "Total num played games": 10304, "Total num trained steps": 20096, "Timestamp in ms": 1701434414787, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 103.23156937025487, "Avg game time in secs": 3.5827436669787858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 10368, "Total num trained steps": 20103, "Timestamp in ms": 1701434417912, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9449894210425083, "Avg loss": 0.7974827717989683, "Avg value loss": 0.38787722820416093, "Avg policy loss": 0.4096055442932993, "Total num played games": 10398, "Total num trained steps": 20224, "Timestamp in ms": 1701434474844, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 97.5941678788513, "Avg game time in secs": 4.080245516903233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.71}, "Total num played games": 10496, "Total num trained steps": 20314, "Timestamp in ms": 1701434515506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9389291158536586, "Avg loss": 0.8054426538292319, "Avg value loss": 0.4023954102303833, "Avg policy loss": 0.4030472529120743, "Total num played games": 10496, "Total num trained steps": 20352, "Timestamp in ms": 1701434532358, "logtype": "training_step"}
{"Total num played games": 10496, "Total num trained steps": 20470, "Timestamp in ms": 1701434614374, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.68359375}
{"Ratio train steps to played games": 1.9449192782526117, "Avg loss": 0.6669662371277809, "Avg value loss": 0.266279817558825, "Avg policy loss": 0.40068642259575427, "Total num played games": 10528, "Total num trained steps": 20480, "Timestamp in ms": 1701434619153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9459867799811144, "Avg loss": 0.841208138037473, "Avg value loss": 0.4211744397180155, "Avg policy loss": 0.42003369494341314, "Total num played games": 10590, "Total num trained steps": 20608, "Timestamp in ms": 1701434680960, "logtype": "training_step"}
{"Avg objective": 19.921875, "Games time in secs": 196.51280791684985, "Avg game time in secs": 3.6603531547734747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 10624, "Total num trained steps": 20675, "Timestamp in ms": 1701434712019, "logtype": "played_game"}
{"Ratio train steps to played games": 1.940482874789444, "Avg loss": 0.7563815084286034, "Avg value loss": 0.3437785218702629, "Avg policy loss": 0.4126029829494655, "Total num played games": 10686, "Total num trained steps": 20736, "Timestamp in ms": 1701434739562, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9524611641399963, "Avg loss": 0.709827161161229, "Avg value loss": 0.3056675682310015, "Avg policy loss": 0.40415959618985653, "Total num played games": 10686, "Total num trained steps": 20864, "Timestamp in ms": 1701434798549, "logtype": "training_step"}
{"Avg objective": 19.828125, "Games time in secs": 89.826950147748, "Avg game time in secs": 3.3192444749292918, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 10752, "Total num trained steps": 20871, "Timestamp in ms": 1701434801846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.946948618067149, "Avg loss": 0.7406321899034083, "Avg value loss": 0.33804096886888146, "Avg policy loss": 0.402591226156801, "Total num played games": 10782, "Total num trained steps": 20992, "Timestamp in ms": 1701434857409, "logtype": "training_step"}
{"Total num played games": 10878, "Total num trained steps": 21073, "Timestamp in ms": 1701434915196, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6328125}
{"Avg objective": 20.171875, "Games time in secs": 115.41310051828623, "Avg game time in secs": 3.4310880828707013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 10880, "Total num trained steps": 21077, "Timestamp in ms": 1701434917259, "logtype": "played_game"}
{"Ratio train steps to played games": 1.924899744804958, "Avg loss": 0.8478536796756089, "Avg value loss": 0.4527140222489834, "Avg policy loss": 0.39513966138474643, "Total num played games": 10972, "Total num trained steps": 21120, "Timestamp in ms": 1701434937104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9364746627779803, "Avg loss": 0.698871327098459, "Avg value loss": 0.29845191282220185, "Avg policy loss": 0.4004194166045636, "Total num played games": 10972, "Total num trained steps": 21248, "Timestamp in ms": 1701434994831, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948231862923806, "Avg loss": 0.6316928016021848, "Avg value loss": 0.25974448199849576, "Avg policy loss": 0.371948319952935, "Total num played games": 10972, "Total num trained steps": 21376, "Timestamp in ms": 1701435053169, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 164.68358428403735, "Avg game time in secs": 3.1609490371629363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 11008, "Total num trained steps": 21440, "Timestamp in ms": 1701435081943, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9428080954101916, "Avg loss": 0.8531082312110811, "Avg value loss": 0.4832123441156, "Avg policy loss": 0.36989588709548116, "Total num played games": 11068, "Total num trained steps": 21504, "Timestamp in ms": 1701435110787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9498828195420947, "Avg loss": 0.6188695402815938, "Avg value loss": 0.25579271430615336, "Avg policy loss": 0.3630768188741058, "Total num played games": 11094, "Total num trained steps": 21632, "Timestamp in ms": 1701435171200, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 91.8924624491483, "Avg game time in secs": 3.514263602613937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 11136, "Total num trained steps": 21638, "Timestamp in ms": 1701435173835, "logtype": "played_game"}
{"Total num played games": 11164, "Total num trained steps": 21673, "Timestamp in ms": 1701435219266, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.76953125}
{"Ratio train steps to played games": 1.9328477527091845, "Avg loss": 0.9130754950456321, "Avg value loss": 0.512610848993063, "Avg policy loss": 0.40046464931219816, "Total num played games": 11258, "Total num trained steps": 21760, "Timestamp in ms": 1701435259528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9442174453721799, "Avg loss": 0.6446857054252177, "Avg value loss": 0.2581219987478107, "Avg policy loss": 0.38656370737589896, "Total num played games": 11258, "Total num trained steps": 21888, "Timestamp in ms": 1701435318614, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 200.07038717530668, "Avg game time in secs": 4.121418982773321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.69}, "Total num played games": 11264, "Total num trained steps": 22009, "Timestamp in ms": 1701435373906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.944189332391381, "Avg loss": 0.7342697388958186, "Avg value loss": 0.36257586220745, "Avg policy loss": 0.37169387354515493, "Total num played games": 11324, "Total num trained steps": 22016, "Timestamp in ms": 1701435376635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.950325876343139, "Avg loss": 0.7672877828590572, "Avg value loss": 0.37649146118201315, "Avg policy loss": 0.39079632447101176, "Total num played games": 11354, "Total num trained steps": 22144, "Timestamp in ms": 1701435435525, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 90.05369454622269, "Avg game time in secs": 3.3136553485674085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 11392, "Total num trained steps": 22205, "Timestamp in ms": 1701435463960, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9454926624737945, "Avg loss": 0.7061091819778085, "Avg value loss": 0.3259207112714648, "Avg policy loss": 0.3801884709391743, "Total num played games": 11448, "Total num trained steps": 22272, "Timestamp in ms": 1701435493411, "logtype": "training_step"}
{"Total num played games": 11448, "Total num trained steps": 22274, "Timestamp in ms": 1701435521644, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.98046875}
{"Avg objective": 19.671875, "Games time in secs": 66.64182597398758, "Avg game time in secs": 4.059840338421054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.69, "agent_stopped_0": 0.39}, "Total num played games": 11520, "Total num trained steps": 22293, "Timestamp in ms": 1701435530602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9407381736267544, "Avg loss": 0.8436384634114802, "Avg value loss": 0.44579159922432154, "Avg policy loss": 0.3978468622080982, "Total num played games": 11542, "Total num trained steps": 22400, "Timestamp in ms": 1701435578835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9518281060474787, "Avg loss": 0.7328845490701497, "Avg value loss": 0.35400496248621494, "Avg policy loss": 0.3788795880973339, "Total num played games": 11542, "Total num trained steps": 22528, "Timestamp in ms": 1701435636684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.946726241622272, "Avg loss": 0.8012611968442798, "Avg value loss": 0.41817402886226773, "Avg policy loss": 0.3830871693789959, "Total num played games": 11638, "Total num trained steps": 22656, "Timestamp in ms": 1701435695000, "logtype": "training_step"}
{"Avg objective": 19.9140625, "Games time in secs": 216.22876162827015, "Avg game time in secs": 4.196300857118331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.71}, "Total num played games": 11648, "Total num trained steps": 22769, "Timestamp in ms": 1701435746831, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9430325771789188, "Avg loss": 0.7087927237153053, "Avg value loss": 0.3230689119081944, "Avg policy loss": 0.3857238064520061, "Total num played games": 11726, "Total num trained steps": 22784, "Timestamp in ms": 1701435753176, "logtype": "training_step"}
{"Total num played games": 11734, "Total num trained steps": 22875, "Timestamp in ms": 1701435819519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.63671875}
{"Avg objective": 20.4375, "Games time in secs": 77.35355063341558, "Avg game time in secs": 3.334309607060277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 11776, "Total num trained steps": 22884, "Timestamp in ms": 1701435824185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9370984105512343, "Avg loss": 0.8803654280491173, "Avg value loss": 0.48173164762556553, "Avg policy loss": 0.3986337911337614, "Total num played games": 11828, "Total num trained steps": 22912, "Timestamp in ms": 1701435837089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9479201893811295, "Avg loss": 0.6794503191486001, "Avg value loss": 0.2918984566349536, "Avg policy loss": 0.38755185762420297, "Total num played games": 11828, "Total num trained steps": 23040, "Timestamp in ms": 1701435895676, "logtype": "training_step"}
{"Avg objective": 20.2421875, "Games time in secs": 123.23097628355026, "Avg game time in secs": 3.441046870793798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 11904, "Total num trained steps": 23156, "Timestamp in ms": 1701435947416, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9429721569942973, "Avg loss": 0.6719116764143109, "Avg value loss": 0.3027393124066293, "Avg policy loss": 0.3691723607480526, "Total num played games": 11924, "Total num trained steps": 23168, "Timestamp in ms": 1701435953244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9537068097953707, "Avg loss": 0.6870134838391095, "Avg value loss": 0.3011438709218055, "Avg policy loss": 0.3858696175739169, "Total num played games": 11924, "Total num trained steps": 23296, "Timestamp in ms": 1701436015297, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948344701380802, "Avg loss": 0.7541133794002235, "Avg value loss": 0.3730920848902315, "Avg policy loss": 0.3810212970711291, "Total num played games": 12022, "Total num trained steps": 23424, "Timestamp in ms": 1701436072029, "logtype": "training_step"}
{"Total num played games": 12022, "Total num trained steps": 23476, "Timestamp in ms": 1701436122115, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.68359375}
{"Avg objective": 20.7421875, "Games time in secs": 177.5739940404892, "Avg game time in secs": 3.267204961288371, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 12032, "Total num trained steps": 23481, "Timestamp in ms": 1701436124990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9438758666226477, "Avg loss": 0.7185767916962504, "Avg value loss": 0.3458707083482295, "Avg policy loss": 0.37270608358085155, "Total num played games": 12116, "Total num trained steps": 23552, "Timestamp in ms": 1701436156968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9544404093760317, "Avg loss": 0.5908071100711823, "Avg value loss": 0.22958389820996672, "Avg policy loss": 0.3612232080195099, "Total num played games": 12116, "Total num trained steps": 23680, "Timestamp in ms": 1701436215602, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 111.59217018447816, "Avg game time in secs": 3.3813615134276915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 12160, "Total num trained steps": 23727, "Timestamp in ms": 1701436236582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9495578119882082, "Avg loss": 0.7165326189715415, "Avg value loss": 0.3474043683381751, "Avg policy loss": 0.36912825028412044, "Total num played games": 12212, "Total num trained steps": 23808, "Timestamp in ms": 1701436271789, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 88.11244331486523, "Avg game time in secs": 3.510664859917597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.63}, "Total num played games": 12288, "Total num trained steps": 23926, "Timestamp in ms": 1701436324694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9447513812154695, "Avg loss": 0.6515647757332772, "Avg value loss": 0.2932616277830675, "Avg policy loss": 0.35830314457416534, "Total num played games": 12308, "Total num trained steps": 23936, "Timestamp in ms": 1701436329115, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9551511212219694, "Avg loss": 0.6784766428172588, "Avg value loss": 0.304413944366388, "Avg policy loss": 0.3740626994986087, "Total num played games": 12308, "Total num trained steps": 24064, "Timestamp in ms": 1701436386369, "logtype": "training_step"}
{"Total num played games": 12308, "Total num trained steps": 24079, "Timestamp in ms": 1701436438794, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.27734375}
{"Ratio train steps to played games": 1.9506531204644413, "Avg loss": 0.7628270098939538, "Avg value loss": 0.38302679278422147, "Avg policy loss": 0.3798002190887928, "Total num played games": 12402, "Total num trained steps": 24192, "Timestamp in ms": 1701436491578, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 215.47343192249537, "Avg game time in secs": 3.4270662729541073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.65, "agent_stopped_0": 0.43}, "Total num played games": 12416, "Total num trained steps": 24298, "Timestamp in ms": 1701436540168, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9462227912932137, "Avg loss": 0.8084703886415809, "Avg value loss": 0.4460346532287076, "Avg policy loss": 0.3624357325024903, "Total num played games": 12496, "Total num trained steps": 24320, "Timestamp in ms": 1701436550140, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9561529844775165, "Avg loss": 0.7328005000017583, "Avg value loss": 0.3571231726091355, "Avg policy loss": 0.37567733135074377, "Total num played games": 12498, "Total num trained steps": 24448, "Timestamp in ms": 1701436608765, "logtype": "training_step"}
{"Avg objective": 20.2578125, "Games time in secs": 90.42914761602879, "Avg game time in secs": 3.652015127852792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.7, "agent_stopped_0": 0.4}, "Total num played games": 12544, "Total num trained steps": 24494, "Timestamp in ms": 1701436630597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9510955859002859, "Avg loss": 0.8877903711982071, "Avg value loss": 0.4950970043428242, "Avg policy loss": 0.3926933698821813, "Total num played games": 12596, "Total num trained steps": 24576, "Timestamp in ms": 1701436667858, "logtype": "training_step"}
{"Total num played games": 12596, "Total num trained steps": 24679, "Timestamp in ms": 1701436785370, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.85546875}
{"Avg objective": 21.0859375, "Games time in secs": 161.48031025193632, "Avg game time in secs": 3.5611030920699704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 12672, "Total num trained steps": 24693, "Timestamp in ms": 1701436792078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.946729708431836, "Avg loss": 0.8465049518272281, "Avg value loss": 0.4536664964398369, "Avg policy loss": 0.39283845759928226, "Total num played games": 12690, "Total num trained steps": 24704, "Timestamp in ms": 1701436796671, "logtype": "training_step"}
{"Ratio train steps to played games": 1.956816390858944, "Avg loss": 0.7523771431297064, "Avg value loss": 0.3450154783204198, "Avg policy loss": 0.40736166504211724, "Total num played games": 12690, "Total num trained steps": 24832, "Timestamp in ms": 1701436856429, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9515246286161063, "Avg loss": 0.7997822556644678, "Avg value loss": 0.3895876840688288, "Avg policy loss": 0.4101945711299777, "Total num played games": 12790, "Total num trained steps": 24960, "Timestamp in ms": 1701436914585, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 173.77988905832171, "Avg game time in secs": 4.186852092694608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.7, "agent_stopped_0": 0.44}, "Total num played games": 12800, "Total num trained steps": 25074, "Timestamp in ms": 1701436965858, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9475236764477566, "Avg loss": 0.6778110829181969, "Avg value loss": 0.29014584538526833, "Avg policy loss": 0.3876652349717915, "Total num played games": 12882, "Total num trained steps": 25088, "Timestamp in ms": 1701436971903, "logtype": "training_step"}
{"Ratio train steps to played games": 1.956548727498448, "Avg loss": 0.7402536899317056, "Avg value loss": 0.3409435694338754, "Avg policy loss": 0.39931012433953583, "Total num played games": 12888, "Total num trained steps": 25216, "Timestamp in ms": 1701437030128, "logtype": "training_step"}
{"Avg objective": 19.671875, "Games time in secs": 91.03200579620898, "Avg game time in secs": 3.622714539276785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 12928, "Total num trained steps": 25274, "Timestamp in ms": 1701437056890, "logtype": "played_game"}
{"Total num played games": 12986, "Total num trained steps": 25283, "Timestamp in ms": 1701437089720, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.69921875}
{"Avg objective": 20.8515625, "Games time in secs": 40.20787990279496, "Avg game time in secs": 4.177864859710098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 13056, "Total num trained steps": 25298, "Timestamp in ms": 1701437097098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9376146788990827, "Avg loss": 0.8798575173132122, "Avg value loss": 0.47140906017739326, "Avg policy loss": 0.40844845678657293, "Total num played games": 13080, "Total num trained steps": 25344, "Timestamp in ms": 1701437117837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9474006116207951, "Avg loss": 0.7042427191045135, "Avg value loss": 0.2867827140726149, "Avg policy loss": 0.41746000456623733, "Total num played games": 13080, "Total num trained steps": 25472, "Timestamp in ms": 1701437175498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9571865443425076, "Avg loss": 0.6185060902498662, "Avg value loss": 0.2278563615400344, "Avg policy loss": 0.39064972731284797, "Total num played games": 13080, "Total num trained steps": 25600, "Timestamp in ms": 1701437232495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95264116575592, "Avg loss": 0.7475110092200339, "Avg value loss": 0.35661678994074464, "Avg policy loss": 0.3908942157868296, "Total num played games": 13176, "Total num trained steps": 25728, "Timestamp in ms": 1701437290207, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 245.76032657921314, "Avg game time in secs": 3.7862793185777264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 13184, "Total num trained steps": 25844, "Timestamp in ms": 1701437342858, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9487488694603556, "Avg loss": 0.6272224974818528, "Avg value loss": 0.260002403287217, "Avg policy loss": 0.36722009046934545, "Total num played games": 13268, "Total num trained steps": 25856, "Timestamp in ms": 1701437348002, "logtype": "training_step"}
{"Total num played games": 13272, "Total num trained steps": 25885, "Timestamp in ms": 1701437409268, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0703125}
{"Avg objective": 20.4140625, "Games time in secs": 71.47877402603626, "Avg game time in secs": 3.117115979868686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.53}, "Total num played games": 13312, "Total num trained steps": 25894, "Timestamp in ms": 1701437414337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9439622923836601, "Avg loss": 0.8699167212471366, "Avg value loss": 0.46827089972794056, "Avg policy loss": 0.40164582384750247, "Total num played games": 13366, "Total num trained steps": 25984, "Timestamp in ms": 1701437455772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9536136465659135, "Avg loss": 0.6225429270416498, "Avg value loss": 0.23784753715153784, "Avg policy loss": 0.3846953841857612, "Total num played games": 13366, "Total num trained steps": 26112, "Timestamp in ms": 1701437513379, "logtype": "training_step"}
{"Avg objective": 19.6796875, "Games time in secs": 154.63177022524178, "Avg game time in secs": 3.8355335366213694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 13440, "Total num trained steps": 26236, "Timestamp in ms": 1701437568969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9503493384866954, "Avg loss": 0.6212481681723148, "Avg value loss": 0.25404028163757175, "Avg policy loss": 0.3672078850213438, "Total num played games": 13454, "Total num trained steps": 26240, "Timestamp in ms": 1701437570825, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9586985589065518, "Avg loss": 0.704401490278542, "Avg value loss": 0.3166197072714567, "Avg policy loss": 0.3877817806787789, "Total num played games": 13462, "Total num trained steps": 26368, "Timestamp in ms": 1701437627327, "logtype": "training_step"}
{"Total num played games": 13558, "Total num trained steps": 26485, "Timestamp in ms": 1701437701990, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8125}
{"Avg objective": 20.171875, "Games time in secs": 136.02473043091595, "Avg game time in secs": 4.018616368979565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 13568, "Total num trained steps": 26489, "Timestamp in ms": 1701437704994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9473761575775392, "Avg loss": 0.7349350925069302, "Avg value loss": 0.3427399714710191, "Avg policy loss": 0.39219512278214097, "Total num played games": 13604, "Total num trained steps": 26496, "Timestamp in ms": 1701437707528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9501904482859653, "Avg loss": 0.7795182904228568, "Avg value loss": 0.3762416902463883, "Avg policy loss": 0.4032765980809927, "Total num played games": 13652, "Total num trained steps": 26624, "Timestamp in ms": 1701437768088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959566363902725, "Avg loss": 0.6229993174783885, "Avg value loss": 0.2381197641370818, "Avg policy loss": 0.3848795483354479, "Total num played games": 13652, "Total num trained steps": 26752, "Timestamp in ms": 1701437826738, "logtype": "training_step"}
{"Avg objective": 18.8359375, "Games time in secs": 144.76183860749006, "Avg game time in secs": 3.7501468742266297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 13696, "Total num trained steps": 26802, "Timestamp in ms": 1701437849756, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955193482688391, "Avg loss": 0.7898180021438748, "Avg value loss": 0.3977351684588939, "Avg policy loss": 0.3920828315895051, "Total num played games": 13748, "Total num trained steps": 26880, "Timestamp in ms": 1701437883776, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 86.32530776411295, "Avg game time in secs": 3.793399332673289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.64}, "Total num played games": 13824, "Total num trained steps": 26996, "Timestamp in ms": 1701437936081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9508812481941635, "Avg loss": 0.7088103014975786, "Avg value loss": 0.31689188978634775, "Avg policy loss": 0.3919184193946421, "Total num played games": 13844, "Total num trained steps": 27008, "Timestamp in ms": 1701437941079, "logtype": "training_step"}
{"Total num played games": 13844, "Total num trained steps": 27085, "Timestamp in ms": 1701438001582, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.73828125}
{"Ratio train steps to played games": 1.946907734251686, "Avg loss": 0.7877724906429648, "Avg value loss": 0.3879595856415108, "Avg policy loss": 0.3998129037208855, "Total num played games": 13938, "Total num trained steps": 27136, "Timestamp in ms": 1701438025272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.956091261300043, "Avg loss": 0.6455827234312892, "Avg value loss": 0.25415796623565257, "Avg policy loss": 0.3914247544016689, "Total num played games": 13938, "Total num trained steps": 27264, "Timestamp in ms": 1701438085713, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 198.10822487808764, "Avg game time in secs": 3.6047544201719575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 13952, "Total num trained steps": 27370, "Timestamp in ms": 1701438134190, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9517600114008835, "Avg loss": 0.714807981159538, "Avg value loss": 0.3180028131464496, "Avg policy loss": 0.3968051669653505, "Total num played games": 14034, "Total num trained steps": 27392, "Timestamp in ms": 1701438143262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9609519737779677, "Avg loss": 0.6825279123149812, "Avg value loss": 0.2945025151129812, "Avg policy loss": 0.3880253981333226, "Total num played games": 14034, "Total num trained steps": 27520, "Timestamp in ms": 1701438200334, "logtype": "training_step"}
{"Avg objective": 19.546875, "Games time in secs": 86.04788678698242, "Avg game time in secs": 3.33725558045262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 14080, "Total num trained steps": 27564, "Timestamp in ms": 1701438220238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956687898089172, "Avg loss": 0.8057881034910679, "Avg value loss": 0.41202280996367335, "Avg policy loss": 0.39376529958099127, "Total num played games": 14130, "Total num trained steps": 27648, "Timestamp in ms": 1701438255638, "logtype": "training_step"}
{"Total num played games": 14130, "Total num trained steps": 27686, "Timestamp in ms": 1701438296339, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.2421875}
{"Avg objective": 22.1328125, "Games time in secs": 83.71213212236762, "Avg game time in secs": 3.6886524657165864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 14208, "Total num trained steps": 27701, "Timestamp in ms": 1701438303950, "logtype": "played_game"}
{"Ratio train steps to played games": 1.952755905511811, "Avg loss": 0.7689364207908511, "Avg value loss": 0.37162506801541895, "Avg policy loss": 0.3973113556858152, "Total num played games": 14224, "Total num trained steps": 27776, "Timestamp in ms": 1701438336991, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9616844769403825, "Avg loss": 0.6096166444476694, "Avg value loss": 0.23204938636627048, "Avg policy loss": 0.377567257033661, "Total num played games": 14224, "Total num trained steps": 27904, "Timestamp in ms": 1701438396650, "logtype": "training_step"}
{"Ratio train steps to played games": 1.957815337337617, "Avg loss": 0.7209154283627868, "Avg value loss": 0.33348982804454863, "Avg policy loss": 0.38742560148239136, "Total num played games": 14318, "Total num trained steps": 28032, "Timestamp in ms": 1701438456891, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 197.9173898436129, "Avg game time in secs": 3.6057114298746455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 14336, "Total num trained steps": 28131, "Timestamp in ms": 1701438501867, "logtype": "played_game"}
{"Ratio train steps to played games": 1.953656167614819, "Avg loss": 0.7050353607628495, "Avg value loss": 0.33099070377647877, "Avg policy loss": 0.3740446523297578, "Total num played games": 14414, "Total num trained steps": 28160, "Timestamp in ms": 1701438515181, "logtype": "training_step"}
{"Total num played games": 14414, "Total num trained steps": 28287, "Timestamp in ms": 1701438597304, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0859375}
{"Ratio train steps to played games": 1.9624670459275704, "Avg loss": 0.6775911096483469, "Avg value loss": 0.29656962759327143, "Avg policy loss": 0.3810214775148779, "Total num played games": 14414, "Total num trained steps": 28288, "Timestamp in ms": 1701438598637, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 100.72225058451295, "Avg game time in secs": 3.804488212466822, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 14464, "Total num trained steps": 28297, "Timestamp in ms": 1701438602590, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9586435070306039, "Avg loss": 0.765882427804172, "Avg value loss": 0.37768171180505306, "Avg policy loss": 0.3882007210049778, "Total num played games": 14508, "Total num trained steps": 28416, "Timestamp in ms": 1701438656074, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 98.85948004946113, "Avg game time in secs": 3.9961529108986724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.72, "agent_stopped_0": 0.39}, "Total num played games": 14592, "Total num trained steps": 28519, "Timestamp in ms": 1701438701449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9545330046562586, "Avg loss": 0.6947780407499522, "Avg value loss": 0.32481754140462726, "Avg policy loss": 0.3699604955036193, "Total num played games": 14604, "Total num trained steps": 28544, "Timestamp in ms": 1701438712876, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9632977266502327, "Avg loss": 0.6301099434494972, "Avg value loss": 0.26570870308205485, "Avg policy loss": 0.3644012368749827, "Total num played games": 14604, "Total num trained steps": 28672, "Timestamp in ms": 1701438768742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95891715412869, "Avg loss": 0.7576987326610833, "Avg value loss": 0.3777290000580251, "Avg policy loss": 0.3799697330687195, "Total num played games": 14702, "Total num trained steps": 28800, "Timestamp in ms": 1701438825583, "logtype": "training_step"}
{"Total num played games": 14702, "Total num trained steps": 28890, "Timestamp in ms": 1701438889591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1328125}
{"Avg objective": 20.5625, "Games time in secs": 192.13810909166932, "Avg game time in secs": 3.645575167698553, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 14720, "Total num trained steps": 28897, "Timestamp in ms": 1701438893587, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9551230062178968, "Avg loss": 0.685201819986105, "Avg value loss": 0.3068611316848546, "Avg policy loss": 0.37834068620577455, "Total num played games": 14796, "Total num trained steps": 28928, "Timestamp in ms": 1701438907379, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9637739929710734, "Avg loss": 0.655223848996684, "Avg value loss": 0.2652326205279678, "Avg policy loss": 0.3899912287015468, "Total num played games": 14796, "Total num trained steps": 29056, "Timestamp in ms": 1701438966272, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 87.91089152358472, "Avg game time in secs": 3.840862936602207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.67}, "Total num played games": 14848, "Total num trained steps": 29090, "Timestamp in ms": 1701438981498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.959709911361805, "Avg loss": 0.7553871853742748, "Avg value loss": 0.3548320768168196, "Avg policy loss": 0.400555104482919, "Total num played games": 14892, "Total num trained steps": 29184, "Timestamp in ms": 1701439023923, "logtype": "training_step"}
{"Avg objective": 19.4140625, "Games time in secs": 89.95930507779121, "Avg game time in secs": 3.996077581832651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.74}, "Total num played games": 14976, "Total num trained steps": 29288, "Timestamp in ms": 1701439071458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9556978916466508, "Avg loss": 0.732009700499475, "Avg value loss": 0.34218931454233825, "Avg policy loss": 0.38982038339599967, "Total num played games": 14988, "Total num trained steps": 29312, "Timestamp in ms": 1701439081681, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9642380571123566, "Avg loss": 0.7158452142030001, "Avg value loss": 0.3205788068007678, "Avg policy loss": 0.39526641136035323, "Total num played games": 14988, "Total num trained steps": 29440, "Timestamp in ms": 1701439141154, "logtype": "training_step"}
{"Total num played games": 15084, "Total num trained steps": 29493, "Timestamp in ms": 1701439192095, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.34765625}
{"Avg objective": 19.828125, "Games time in secs": 125.03175958991051, "Avg game time in secs": 3.7565071292046923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 15104, "Total num trained steps": 29501, "Timestamp in ms": 1701439196490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9480827513506391, "Avg loss": 1.1019842838868499, "Avg value loss": 0.7123153246939182, "Avg policy loss": 0.3896689673420042, "Total num played games": 15178, "Total num trained steps": 29568, "Timestamp in ms": 1701439226832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9565160100144947, "Avg loss": 0.7998279887251556, "Avg value loss": 0.40679279365576804, "Avg policy loss": 0.3930351948365569, "Total num played games": 15178, "Total num trained steps": 29696, "Timestamp in ms": 1701439285067, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648833838450388, "Avg loss": 0.7195250610820949, "Avg value loss": 0.3408708410570398, "Avg policy loss": 0.3786542161833495, "Total num played games": 15178, "Total num trained steps": 29824, "Timestamp in ms": 1701439341891, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 158.6557031273842, "Avg game time in secs": 3.7738564637838863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 15232, "Total num trained steps": 29853, "Timestamp in ms": 1701439355146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9609794421893414, "Avg loss": 0.7673682081513107, "Avg value loss": 0.3851006805198267, "Avg policy loss": 0.3822675244882703, "Total num played games": 15274, "Total num trained steps": 29952, "Timestamp in ms": 1701439398285, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 87.67542477883399, "Avg game time in secs": 3.641986845890642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 15360, "Total num trained steps": 30051, "Timestamp in ms": 1701439442821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9568045797553995, "Avg loss": 0.6853850532788783, "Avg value loss": 0.31078046886250377, "Avg policy loss": 0.37460458488203585, "Total num played games": 15372, "Total num trained steps": 30080, "Timestamp in ms": 1701439455869, "logtype": "training_step"}
{"Total num played games": 15372, "Total num trained steps": 30093, "Timestamp in ms": 1701439485801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.84765625}
{"Ratio train steps to played games": 1.9531876373981638, "Avg loss": 0.774577412288636, "Avg value loss": 0.37685853370931, "Avg policy loss": 0.39771887846291065, "Total num played games": 15466, "Total num trained steps": 30208, "Timestamp in ms": 1701439537413, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9614638562006983, "Avg loss": 0.5577322740573436, "Avg value loss": 0.18697331263683736, "Avg policy loss": 0.37075896142050624, "Total num played games": 15466, "Total num trained steps": 30336, "Timestamp in ms": 1701439594786, "logtype": "training_step"}
{"Avg objective": 19.8203125, "Games time in secs": 192.70850742794573, "Avg game time in secs": 3.4122323282063007, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 15488, "Total num trained steps": 30427, "Timestamp in ms": 1701439635530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9575889988433364, "Avg loss": 0.6703670606948435, "Avg value loss": 0.3103838880197145, "Avg policy loss": 0.3599831727333367, "Total num played games": 15562, "Total num trained steps": 30464, "Timestamp in ms": 1701439651852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9658141627040226, "Avg loss": 0.5939305005595088, "Avg value loss": 0.2202864167629741, "Avg policy loss": 0.37364408653229475, "Total num played games": 15562, "Total num trained steps": 30592, "Timestamp in ms": 1701439708833, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 86.38007879629731, "Avg game time in secs": 3.2174522386922035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 15616, "Total num trained steps": 30621, "Timestamp in ms": 1701439721910, "logtype": "played_game"}
{"Total num played games": 15660, "Total num trained steps": 30694, "Timestamp in ms": 1701439781438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.875}
{"Avg objective": 20.1484375, "Games time in secs": 66.96608768776059, "Avg game time in secs": 3.6783199614001205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 15744, "Total num trained steps": 30708, "Timestamp in ms": 1701439788876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9499809572172146, "Avg loss": 0.787109058117494, "Avg value loss": 0.4105455977260135, "Avg policy loss": 0.3765634624287486, "Total num played games": 15754, "Total num trained steps": 30720, "Timestamp in ms": 1701439793987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9581058778722864, "Avg loss": 0.7146412502042949, "Avg value loss": 0.33308328688144684, "Avg policy loss": 0.3815579628571868, "Total num played games": 15754, "Total num trained steps": 30848, "Timestamp in ms": 1701439852369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9662307985273582, "Avg loss": 0.5647100463975221, "Avg value loss": 0.2028747108997777, "Avg policy loss": 0.3618353318888694, "Total num played games": 15754, "Total num trained steps": 30976, "Timestamp in ms": 1701439909463, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962397476340694, "Avg loss": 0.7181717338971794, "Avg value loss": 0.34360076452139765, "Avg policy loss": 0.3745709713548422, "Total num played games": 15850, "Total num trained steps": 31104, "Timestamp in ms": 1701439966438, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 217.49748130701482, "Avg game time in secs": 3.6240389876329573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 15872, "Total num trained steps": 31194, "Timestamp in ms": 1701440006374, "logtype": "played_game"}
{"Ratio train steps to played games": 1.958547598143735, "Avg loss": 0.6785956209059805, "Avg value loss": 0.3028248035116121, "Avg policy loss": 0.3757708186749369, "Total num played games": 15946, "Total num trained steps": 31232, "Timestamp in ms": 1701440023408, "logtype": "training_step"}
{"Total num played games": 15946, "Total num trained steps": 31297, "Timestamp in ms": 1701440079032, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.00390625}
{"Avg objective": 20.8828125, "Games time in secs": 79.04744127579033, "Avg game time in secs": 3.9953485898149665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.73}, "Total num played games": 16000, "Total num trained steps": 31310, "Timestamp in ms": 1701440085421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9551122194513715, "Avg loss": 0.7570478590205312, "Avg value loss": 0.37891770259011537, "Avg policy loss": 0.3781301591079682, "Total num played games": 16040, "Total num trained steps": 31360, "Timestamp in ms": 1701440107668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9630922693266832, "Avg loss": 0.6279273603577167, "Avg value loss": 0.24537509470246732, "Avg policy loss": 0.3825522686820477, "Total num played games": 16040, "Total num trained steps": 31488, "Timestamp in ms": 1701440169230, "logtype": "training_step"}
{"Avg objective": 19.578125, "Games time in secs": 127.22847842425108, "Avg game time in secs": 4.067785578619805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 16128, "Total num trained steps": 31585, "Timestamp in ms": 1701440212650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9593455627169063, "Avg loss": 0.6758478635456413, "Avg value loss": 0.311086458270438, "Avg policy loss": 0.3647614079527557, "Total num played games": 16136, "Total num trained steps": 31616, "Timestamp in ms": 1701440226279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9672781358453149, "Avg loss": 0.6298078787513077, "Avg value loss": 0.25651355634909123, "Avg policy loss": 0.3732943246141076, "Total num played games": 16136, "Total num trained steps": 31744, "Timestamp in ms": 1701440282846, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9635288319369146, "Avg loss": 0.6887764467392117, "Avg value loss": 0.3111229627393186, "Avg policy loss": 0.3776534809730947, "Total num played games": 16232, "Total num trained steps": 31872, "Timestamp in ms": 1701440339887, "logtype": "training_step"}
{"Total num played games": 16232, "Total num trained steps": 31901, "Timestamp in ms": 1701440375426, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8203125}
{"Avg objective": 20.2578125, "Games time in secs": 166.9251747354865, "Avg game time in secs": 3.502305970483576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 16256, "Total num trained steps": 31910, "Timestamp in ms": 1701440379575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9600637020703173, "Avg loss": 0.7527746092528105, "Avg value loss": 0.3731896980898455, "Avg policy loss": 0.37958490545861423, "Total num played games": 16326, "Total num trained steps": 32000, "Timestamp in ms": 1701440419755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9678427048879088, "Avg loss": 0.5919326436705887, "Avg value loss": 0.24019828846212476, "Avg policy loss": 0.3517343506682664, "Total num played games": 16326, "Total num trained steps": 32128, "Timestamp in ms": 1701440478593, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 108.59378990530968, "Avg game time in secs": 3.9797430409671506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 16384, "Total num trained steps": 32149, "Timestamp in ms": 1701440488169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9641943734015346, "Avg loss": 0.7529102342668921, "Avg value loss": 0.37780185823794454, "Avg policy loss": 0.3751083742827177, "Total num played games": 16422, "Total num trained steps": 32256, "Timestamp in ms": 1701440535929, "logtype": "training_step"}
{"Avg objective": 19.640625, "Games time in secs": 92.05250665172935, "Avg game time in secs": 4.039812146482291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.71, "agent_stopped_0": 0.4}, "Total num played games": 16512, "Total num trained steps": 32356, "Timestamp in ms": 1701440580222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9605279089478145, "Avg loss": 0.6654247564729303, "Avg value loss": 0.2913502623559907, "Avg policy loss": 0.37407449446618557, "Total num played games": 16518, "Total num trained steps": 32384, "Timestamp in ms": 1701440592307, "logtype": "training_step"}
{"Total num played games": 16518, "Total num trained steps": 32501, "Timestamp in ms": 1701440671946, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9453125}
{"Ratio train steps to played games": 1.9623370352486722, "Avg loss": 0.5959498973097652, "Avg value loss": 0.23230522277299315, "Avg policy loss": 0.3636446704622358, "Total num played games": 16568, "Total num trained steps": 32512, "Timestamp in ms": 1701440677359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648446905851191, "Avg loss": 0.7422087243758142, "Avg value loss": 0.37149038817733526, "Avg policy loss": 0.3707183348014951, "Total num played games": 16612, "Total num trained steps": 32640, "Timestamp in ms": 1701440734048, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 188.35186221636832, "Avg game time in secs": 3.9495455104479333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.58, "agent_stopped_0": 0.53}, "Total num played games": 16640, "Total num trained steps": 32719, "Timestamp in ms": 1701440768574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9612161838640172, "Avg loss": 0.687031460693106, "Avg value loss": 0.31968196376692504, "Avg policy loss": 0.36734949820674956, "Total num played games": 16708, "Total num trained steps": 32768, "Timestamp in ms": 1701440790782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9688771845822362, "Avg loss": 0.5762675774749368, "Avg value loss": 0.2184986473293975, "Avg policy loss": 0.35776893817819655, "Total num played games": 16708, "Total num trained steps": 32896, "Timestamp in ms": 1701440848291, "logtype": "training_step"}
{"Avg objective": 19.265625, "Games time in secs": 87.55319103598595, "Avg game time in secs": 3.4391748546477174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 16768, "Total num trained steps": 32914, "Timestamp in ms": 1701440856127, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9652463699119258, "Avg loss": 0.6817947833333164, "Avg value loss": 0.31938078615348786, "Avg policy loss": 0.3624140019528568, "Total num played games": 16804, "Total num trained steps": 33024, "Timestamp in ms": 1701440905945, "logtype": "training_step"}
{"Avg objective": 19.875, "Games time in secs": 90.69423147290945, "Avg game time in secs": 4.095094561896985, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.75, "agent_stopped_0": 0.32}, "Total num played games": 16896, "Total num trained steps": 33105, "Timestamp in ms": 1701440946821, "logtype": "played_game"}
{"Total num played games": 16900, "Total num trained steps": 33105, "Timestamp in ms": 1701440966488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.58984375}
{"Ratio train steps to played games": 1.950806166882429, "Avg loss": 0.7991326993796974, "Avg value loss": 0.4373541650711559, "Avg policy loss": 0.3617785298265517, "Total num played games": 16994, "Total num trained steps": 33152, "Timestamp in ms": 1701440989087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9583382370248323, "Avg loss": 0.6908392291516066, "Avg value loss": 0.29252432368230075, "Avg policy loss": 0.39831490628421307, "Total num played games": 16994, "Total num trained steps": 33280, "Timestamp in ms": 1701441046141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9658703071672354, "Avg loss": 0.5741535387933254, "Avg value loss": 0.19979620835511014, "Avg policy loss": 0.3743573317769915, "Total num played games": 16994, "Total num trained steps": 33408, "Timestamp in ms": 1701441103163, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 190.44421824626625, "Avg game time in secs": 3.650129461355391, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 17024, "Total num trained steps": 33485, "Timestamp in ms": 1701441137266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9623171445289642, "Avg loss": 0.6588281786534935, "Avg value loss": 0.29404725233325735, "Avg policy loss": 0.36478092160541564, "Total num played games": 17090, "Total num trained steps": 33536, "Timestamp in ms": 1701441160213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9698069046225863, "Avg loss": 0.5902220536954701, "Avg value loss": 0.20874843455385417, "Avg policy loss": 0.38147361972369254, "Total num played games": 17090, "Total num trained steps": 33664, "Timestamp in ms": 1701441218373, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 88.23805341124535, "Avg game time in secs": 3.928201339105726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 17152, "Total num trained steps": 33681, "Timestamp in ms": 1701441225504, "logtype": "played_game"}
{"Total num played games": 17186, "Total num trained steps": 33707, "Timestamp in ms": 1701441270744, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.921875}
{"Avg objective": 19.375, "Games time in secs": 61.20243895240128, "Avg game time in secs": 4.83881887854659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.77, "agent_stopped_0": 0.31}, "Total num played games": 17280, "Total num trained steps": 33742, "Timestamp in ms": 1701441286706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9555555555555555, "Avg loss": 0.8905121402349323, "Avg value loss": 0.49207580799702555, "Avg policy loss": 0.39843633281998336, "Total num played games": 17280, "Total num trained steps": 33792, "Timestamp in ms": 1701441310005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962962962962963, "Avg loss": 0.6265318288933486, "Avg value loss": 0.24418187735136598, "Avg policy loss": 0.3823499558493495, "Total num played games": 17280, "Total num trained steps": 33920, "Timestamp in ms": 1701441368567, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9703703703703703, "Avg loss": 0.53540443116799, "Avg value loss": 0.17022073431871831, "Avg policy loss": 0.3651836996432394, "Total num played games": 17280, "Total num trained steps": 34048, "Timestamp in ms": 1701441424765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9668508287292819, "Avg loss": 0.6865333230234683, "Avg value loss": 0.31462997454218566, "Avg policy loss": 0.3719033459201455, "Total num played games": 17376, "Total num trained steps": 34176, "Timestamp in ms": 1701441481696, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 227.86122958175838, "Avg game time in secs": 3.5442588847363368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.64, "agent_stopped_0": 0.46}, "Total num played games": 17408, "Total num trained steps": 34249, "Timestamp in ms": 1701441514568, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9633699633699633, "Avg loss": 0.6338096105027944, "Avg value loss": 0.2714426993043162, "Avg policy loss": 0.36236691172234714, "Total num played games": 17472, "Total num trained steps": 34304, "Timestamp in ms": 1701441539483, "logtype": "training_step"}
{"Total num played games": 17472, "Total num trained steps": 34310, "Timestamp in ms": 1701441566240, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.65234375}
{"Avg objective": 19.3828125, "Games time in secs": 58.00597003661096, "Avg game time in secs": 3.8536849615484243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.67, "agent_stopped_0": 0.4}, "Total num played games": 17536, "Total num trained steps": 34321, "Timestamp in ms": 1701441572574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960150290333599, "Avg loss": 0.7467539953067899, "Avg value loss": 0.37164474790915847, "Avg policy loss": 0.37510923971422017, "Total num played games": 17566, "Total num trained steps": 34432, "Timestamp in ms": 1701441624075, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9673801662302175, "Avg loss": 0.544986474327743, "Avg value loss": 0.19513505371287465, "Avg policy loss": 0.34985142247751355, "Total num played games": 17566, "Total num trained steps": 34560, "Timestamp in ms": 1701441683130, "logtype": "training_step"}
{"Ratio train steps to played games": 1.963990488053448, "Avg loss": 0.661678820149973, "Avg value loss": 0.3095645890571177, "Avg policy loss": 0.35211422480642796, "Total num played games": 17662, "Total num trained steps": 34688, "Timestamp in ms": 1701441740194, "logtype": "training_step"}
{"Avg objective": 20.15625, "Games time in secs": 225.56809234432876, "Avg game time in secs": 4.406026638986077, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.77, "agent_stopped_0": 0.38}, "Total num played games": 17664, "Total num trained steps": 34815, "Timestamp in ms": 1701441798142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710144927536233, "Avg loss": 0.6051982236094773, "Avg value loss": 0.2549773292266764, "Avg policy loss": 0.35022089537233114, "Total num played games": 17664, "Total num trained steps": 34816, "Timestamp in ms": 1701441798224, "logtype": "training_step"}
{"Total num played games": 17758, "Total num trained steps": 34914, "Timestamp in ms": 1701441873854, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.27734375}
{"Avg objective": 21.4296875, "Games time in secs": 80.5159111674875, "Avg game time in secs": 3.189746531730634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 17792, "Total num trained steps": 34923, "Timestamp in ms": 1701441878658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9576470588235295, "Avg loss": 0.8354520727880299, "Avg value loss": 0.4609322956530377, "Avg policy loss": 0.37451977701857686, "Total num played games": 17850, "Total num trained steps": 34944, "Timestamp in ms": 1701441887496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645978041676002, "Avg loss": 0.6835210220888257, "Avg value loss": 0.30565902299713343, "Avg policy loss": 0.37786200386472046, "Total num played games": 17852, "Total num trained steps": 35072, "Timestamp in ms": 1701441946450, "logtype": "training_step"}
{"Ratio train steps to played games": 1.969120608637279, "Avg loss": 0.5688344044610858, "Avg value loss": 0.21317500481382012, "Avg policy loss": 0.3556593985995278, "Total num played games": 17874, "Total num trained steps": 35200, "Timestamp in ms": 1701442004497, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 127.65138655900955, "Avg game time in secs": 4.028147995675681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 17920, "Total num trained steps": 35203, "Timestamp in ms": 1701442006309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9683530198350792, "Avg loss": 0.71812808746472, "Avg value loss": 0.349824242759496, "Avg policy loss": 0.3683038481976837, "Total num played games": 17948, "Total num trained steps": 35328, "Timestamp in ms": 1701442063087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9649745067612503, "Avg loss": 0.7680019058752805, "Avg value loss": 0.41543170250952244, "Avg policy loss": 0.3525701961480081, "Total num played games": 18044, "Total num trained steps": 35456, "Timestamp in ms": 1701442121592, "logtype": "training_step"}
{"Total num played games": 18044, "Total num trained steps": 35514, "Timestamp in ms": 1701442177051, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Avg objective": 19.8984375, "Games time in secs": 173.42030688002706, "Avg game time in secs": 4.5200195720244665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.7}, "Total num played games": 18048, "Total num trained steps": 35517, "Timestamp in ms": 1701442179730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9618480538096814, "Avg loss": 0.7136431252583861, "Avg value loss": 0.3374916061293334, "Avg policy loss": 0.37615151749923825, "Total num played games": 18138, "Total num trained steps": 35584, "Timestamp in ms": 1701442210551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9689050611974859, "Avg loss": 0.5843059096951038, "Avg value loss": 0.22005659970454872, "Avg policy loss": 0.364249310689047, "Total num played games": 18138, "Total num trained steps": 35712, "Timestamp in ms": 1701442269371, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 116.63692963682115, "Avg game time in secs": 3.6719167804549215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 18176, "Total num trained steps": 35774, "Timestamp in ms": 1701442296367, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9655588461116595, "Avg loss": 0.663964054081589, "Avg value loss": 0.2936789400409907, "Avg policy loss": 0.37028511287644506, "Total num played games": 18234, "Total num trained steps": 35840, "Timestamp in ms": 1701442328183, "logtype": "training_step"}
{"Avg objective": 19.28125, "Games time in secs": 90.06058342568576, "Avg game time in secs": 4.019652631541248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 18304, "Total num trained steps": 35967, "Timestamp in ms": 1701442386428, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9646056368800524, "Avg loss": 0.5874729440547526, "Avg value loss": 0.22265765396878123, "Avg policy loss": 0.3648152945097536, "Total num played games": 18306, "Total num trained steps": 35968, "Timestamp in ms": 1701442386889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.7034147633239627, "Avg value loss": 0.32683601323515177, "Avg policy loss": 0.37657875125296414, "Total num played games": 18330, "Total num trained steps": 36096, "Timestamp in ms": 1701442447027, "logtype": "training_step"}
{"Total num played games": 18330, "Total num trained steps": 36116, "Timestamp in ms": 1701442490193, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.88671875}
{"Ratio train steps to played games": 1.9661311333043856, "Avg loss": 0.7052942125592381, "Avg value loss": 0.341035561170429, "Avg policy loss": 0.36425864906050265, "Total num played games": 18424, "Total num trained steps": 36224, "Timestamp in ms": 1701442540536, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 209.20629957132041, "Avg game time in secs": 4.08606920974853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 18432, "Total num trained steps": 36342, "Timestamp in ms": 1701442595634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964335891062358, "Avg loss": 0.5494911000132561, "Avg value loss": 0.21404169080778956, "Avg policy loss": 0.33544941199943423, "Total num played games": 18506, "Total num trained steps": 36352, "Timestamp in ms": 1701442599778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9695497246517655, "Avg loss": 0.6370137487538159, "Avg value loss": 0.2890479125780985, "Avg policy loss": 0.3479658387368545, "Total num played games": 18522, "Total num trained steps": 36480, "Timestamp in ms": 1701442656673, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 88.55685422942042, "Avg game time in secs": 3.7713023596443236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 18560, "Total num trained steps": 36540, "Timestamp in ms": 1701442684191, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9662692018476744, "Avg loss": 0.6669960932340473, "Avg value loss": 0.312029913533479, "Avg policy loss": 0.3549661753932014, "Total num played games": 18618, "Total num trained steps": 36608, "Timestamp in ms": 1701442714405, "logtype": "training_step"}
{"Total num played games": 18618, "Total num trained steps": 36717, "Timestamp in ms": 1701442797227, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2890625}
{"Avg objective": 20.015625, "Games time in secs": 121.03190318867564, "Avg game time in secs": 3.9862931990646757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.8, "agent_stopped_0": 0.29}, "Total num played games": 18688, "Total num trained steps": 36731, "Timestamp in ms": 1701442805223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9638618625040094, "Avg loss": 0.5903256363235414, "Avg value loss": 0.2437895298935473, "Avg policy loss": 0.3465361064299941, "Total num played games": 18706, "Total num trained steps": 36736, "Timestamp in ms": 1701442807599, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970072680632749, "Avg loss": 0.6162043290678412, "Avg value loss": 0.26522485981695354, "Avg policy loss": 0.350979465758428, "Total num played games": 18712, "Total num trained steps": 36864, "Timestamp in ms": 1701442867409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9666135034556087, "Avg loss": 0.6534484322182834, "Avg value loss": 0.2963916892185807, "Avg policy loss": 0.35705674323253334, "Total num played games": 18810, "Total num trained steps": 36992, "Timestamp in ms": 1701442924741, "logtype": "training_step"}
{"Avg objective": 19.6796875, "Games time in secs": 173.52276061847806, "Avg game time in secs": 4.14077495066158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.75, "agent_stopped_0": 0.34}, "Total num played games": 18816, "Total num trained steps": 37113, "Timestamp in ms": 1701442978746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9673521305914776, "Avg loss": 0.5565498096402735, "Avg value loss": 0.20621175441192463, "Avg policy loss": 0.35033805505372584, "Total num played games": 18868, "Total num trained steps": 37120, "Timestamp in ms": 1701442981604, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9695431472081217, "Avg loss": 0.7485388075001538, "Avg value loss": 0.3724167176987976, "Avg policy loss": 0.37612208840437233, "Total num played games": 18912, "Total num trained steps": 37248, "Timestamp in ms": 1701443041739, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 95.56314386613667, "Avg game time in secs": 4.005280198252876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.69}, "Total num played games": 18944, "Total num trained steps": 37320, "Timestamp in ms": 1701443074309, "logtype": "played_game"}
{"Total num played games": 19008, "Total num trained steps": 37321, "Timestamp in ms": 1701443102868, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.96875}
{"Avg objective": 19.953125, "Games time in secs": 34.788021663203835, "Avg game time in secs": 3.816877834717161, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 19072, "Total num trained steps": 37333, "Timestamp in ms": 1701443109097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9566537535336614, "Avg loss": 0.7348464985843748, "Avg value loss": 0.3513307955581695, "Avg policy loss": 0.38351570605300367, "Total num played games": 19102, "Total num trained steps": 37376, "Timestamp in ms": 1701443129311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9633546225526124, "Avg loss": 0.6076381134334952, "Avg value loss": 0.23134457995183766, "Avg policy loss": 0.37629353790543973, "Total num played games": 19102, "Total num trained steps": 37504, "Timestamp in ms": 1701443188039, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9700554915715631, "Avg loss": 0.5293036091607064, "Avg value loss": 0.17695177672430873, "Avg policy loss": 0.3523518309229985, "Total num played games": 19102, "Total num trained steps": 37632, "Timestamp in ms": 1701443244892, "logtype": "training_step"}
{"Avg objective": 19.9375, "Games time in secs": 170.79133907146752, "Avg game time in secs": 4.018920796515886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.73, "agent_stopped_0": 0.38}, "Total num played games": 19200, "Total num trained steps": 37712, "Timestamp in ms": 1701443279889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666666666666666, "Avg loss": 0.6551426739897579, "Avg value loss": 0.28896092768991366, "Avg policy loss": 0.36618174496106803, "Total num played games": 19200, "Total num trained steps": 37760, "Timestamp in ms": 1701443301503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9733333333333334, "Avg loss": 0.5545773289632052, "Avg value loss": 0.19299711642088369, "Avg policy loss": 0.36158021446317434, "Total num played games": 19200, "Total num trained steps": 37888, "Timestamp in ms": 1701443359185, "logtype": "training_step"}
{"Total num played games": 19296, "Total num trained steps": 37924, "Timestamp in ms": 1701443402401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.12890625}
{"Avg objective": 20.234375, "Games time in secs": 126.4446319770068, "Avg game time in secs": 3.470029404226807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 19328, "Total num trained steps": 37932, "Timestamp in ms": 1701443406334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960598246518824, "Avg loss": 0.8772158846259117, "Avg value loss": 0.494127219542861, "Avg policy loss": 0.38308865996077657, "Total num played games": 19390, "Total num trained steps": 38016, "Timestamp in ms": 1701443444191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9671995874161938, "Avg loss": 0.5633939185645431, "Avg value loss": 0.2079724067589268, "Avg policy loss": 0.3554215105250478, "Total num played games": 19390, "Total num trained steps": 38144, "Timestamp in ms": 1701443502609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738009283135638, "Avg loss": 0.5250870627351105, "Avg value loss": 0.18033585732337087, "Avg policy loss": 0.3447512020356953, "Total num played games": 19390, "Total num trained steps": 38272, "Timestamp in ms": 1701443560311, "logtype": "training_step"}
{"Avg objective": 19.78125, "Games time in secs": 157.68740796484053, "Avg game time in secs": 3.5326643575390335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.69}, "Total num played games": 19456, "Total num trained steps": 38281, "Timestamp in ms": 1701443564021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706455917068664, "Avg loss": 0.7731016057077795, "Avg value loss": 0.41746823547873646, "Avg policy loss": 0.35563336918130517, "Total num played games": 19486, "Total num trained steps": 38400, "Timestamp in ms": 1701443617159, "logtype": "training_step"}
{"Total num played games": 19582, "Total num trained steps": 38526, "Timestamp in ms": 1701443702241, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.13671875}
{"Ratio train steps to played games": 1.9675211929322847, "Avg loss": 0.6897337199188769, "Avg value loss": 0.3281620711204596, "Avg policy loss": 0.36157164350152016, "Total num played games": 19582, "Total num trained steps": 38528, "Timestamp in ms": 1701443704069, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 140.23602827452123, "Avg game time in secs": 4.8618251199804945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.81}, "Total num played games": 19584, "Total num trained steps": 38528, "Timestamp in ms": 1701443704257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964626956698516, "Avg loss": 0.7828180962242186, "Avg value loss": 0.3958212543511763, "Avg policy loss": 0.3869968382641673, "Total num played games": 19676, "Total num trained steps": 38656, "Timestamp in ms": 1701443763133, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971132343972352, "Avg loss": 0.531014607520774, "Avg value loss": 0.16790203761775047, "Avg policy loss": 0.36311256885528564, "Total num played games": 19676, "Total num trained steps": 38784, "Timestamp in ms": 1701443820452, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 145.2722353283316, "Avg game time in secs": 3.8513927494495874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 19712, "Total num trained steps": 38849, "Timestamp in ms": 1701443849530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9680356059073436, "Avg loss": 0.6884894124232233, "Avg value loss": 0.3238617453025654, "Avg policy loss": 0.3646276635117829, "Total num played games": 19772, "Total num trained steps": 38912, "Timestamp in ms": 1701443877237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971865845034852, "Avg loss": 0.5687144047114998, "Avg value loss": 0.20240066113183275, "Avg policy loss": 0.36631374224089086, "Total num played games": 19798, "Total num trained steps": 39040, "Timestamp in ms": 1701443932343, "logtype": "training_step"}
{"Avg objective": 19.65625, "Games time in secs": 85.20728548243642, "Avg game time in secs": 4.37438581972674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.84}, "Total num played games": 19840, "Total num trained steps": 39045, "Timestamp in ms": 1701443934737, "logtype": "played_game"}
{"Total num played games": 19868, "Total num trained steps": 39129, "Timestamp in ms": 1701444000258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.796875}
{"Ratio train steps to played games": 1.9621280432822363, "Avg loss": 0.7689994296524674, "Avg value loss": 0.3857825458981097, "Avg policy loss": 0.38321688468568027, "Total num played games": 19962, "Total num trained steps": 39168, "Timestamp in ms": 1701444018798, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9685402264302174, "Avg loss": 0.5957043927628547, "Avg value loss": 0.22752825601492077, "Avg policy loss": 0.36817613197490573, "Total num played games": 19962, "Total num trained steps": 39296, "Timestamp in ms": 1701444078107, "logtype": "training_step"}
{"Avg objective": 20.171875, "Games time in secs": 196.9550762679428, "Avg game time in secs": 4.195977106690407, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.71, "agent_stopped_0": 0.39}, "Total num played games": 19968, "Total num trained steps": 39418, "Timestamp in ms": 1701444131692, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708058388322336, "Avg loss": 0.5399259992409497, "Avg value loss": 0.18188171432120726, "Avg policy loss": 0.3580442825332284, "Total num played games": 20002, "Total num trained steps": 39424, "Timestamp in ms": 1701444134229, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971881543523781, "Avg loss": 0.6940811222884804, "Avg value loss": 0.31519341957755387, "Avg policy loss": 0.3788877078332007, "Total num played games": 20058, "Total num trained steps": 39552, "Timestamp in ms": 1701444192358, "logtype": "training_step"}
{"Avg objective": 20.3203125, "Games time in secs": 90.0956613831222, "Avg game time in secs": 4.19112695576041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.73}, "Total num played games": 20096, "Total num trained steps": 39614, "Timestamp in ms": 1701444221788, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968839932519599, "Avg loss": 0.6901901268865913, "Avg value loss": 0.30992454465013, "Avg policy loss": 0.3802655797917396, "Total num played games": 20154, "Total num trained steps": 39680, "Timestamp in ms": 1701444251934, "logtype": "training_step"}
{"Total num played games": 20154, "Total num trained steps": 39730, "Timestamp in ms": 1701444311309, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.97265625}
{"Avg objective": 19.96875, "Games time in secs": 96.40175409428775, "Avg game time in secs": 4.2070948240871076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 20224, "Total num trained steps": 39744, "Timestamp in ms": 1701444318190, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9660213354405374, "Avg loss": 0.7223618614953011, "Avg value loss": 0.3342572133988142, "Avg policy loss": 0.38810464332345873, "Total num played games": 20248, "Total num trained steps": 39808, "Timestamp in ms": 1701444346414, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9723429474516, "Avg loss": 0.7189318344462663, "Avg value loss": 0.34944744396489114, "Avg policy loss": 0.36948439315892756, "Total num played games": 20248, "Total num trained steps": 39936, "Timestamp in ms": 1701444405695, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9693275658670861, "Avg loss": 0.7611230777110904, "Avg value loss": 0.3818862646003254, "Avg policy loss": 0.37923681852407753, "Total num played games": 20344, "Total num trained steps": 40064, "Timestamp in ms": 1701444464445, "logtype": "training_step"}
{"Avg objective": 19.9921875, "Games time in secs": 199.54437742754817, "Avg game time in secs": 4.0595602725225035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 20352, "Total num trained steps": 40181, "Timestamp in ms": 1701444517735, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969423755390043, "Avg loss": 0.5765539002604783, "Avg value loss": 0.21219879284035414, "Avg policy loss": 0.36435510823503137, "Total num played games": 20408, "Total num trained steps": 40192, "Timestamp in ms": 1701444522325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726027397260273, "Avg loss": 0.6459706476889551, "Avg value loss": 0.2792918108170852, "Avg policy loss": 0.3666788407135755, "Total num played games": 20440, "Total num trained steps": 40320, "Timestamp in ms": 1701444581186, "logtype": "training_step"}
{"Total num played games": 20440, "Total num trained steps": 40333, "Timestamp in ms": 1701444615083, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.60546875}
{"Avg objective": 21.4375, "Games time in secs": 102.35765600390732, "Avg game time in secs": 3.8701909147348488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 20480, "Total num trained steps": 40342, "Timestamp in ms": 1701444620092, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9698061751241842, "Avg loss": 0.6270630657672882, "Avg value loss": 0.2699927161447704, "Avg policy loss": 0.3570703463628888, "Total num played games": 20534, "Total num trained steps": 40448, "Timestamp in ms": 1701444669142, "logtype": "training_step"}
{"Avg objective": 19.1328125, "Games time in secs": 109.09752609580755, "Avg game time in secs": 4.624780656929943, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.74, "agent_stopped_0": 0.38}, "Total num played games": 20608, "Total num trained steps": 40574, "Timestamp in ms": 1701444729190, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968944099378882, "Avg loss": 0.5719488819595426, "Avg value loss": 0.2181933717802167, "Avg policy loss": 0.3537555120419711, "Total num played games": 20608, "Total num trained steps": 40576, "Timestamp in ms": 1701444729664, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9730489578284052, "Avg loss": 0.6564609855413437, "Avg value loss": 0.2887769865337759, "Avg policy loss": 0.36768399248830974, "Total num played games": 20630, "Total num trained steps": 40704, "Timestamp in ms": 1701444790477, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9700858824664673, "Avg loss": 0.7434616044629365, "Avg value loss": 0.38559478387469426, "Avg policy loss": 0.3578668279806152, "Total num played games": 20726, "Total num trained steps": 40832, "Timestamp in ms": 1701444848358, "logtype": "training_step"}
{"Total num played games": 20726, "Total num trained steps": 40933, "Timestamp in ms": 1701444924806, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.703125}
{"Avg objective": 19.7578125, "Games time in secs": 198.83193942531943, "Avg game time in secs": 4.710078862088267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.71, "agent_stopped_0": 0.42}, "Total num played games": 20736, "Total num trained steps": 40937, "Timestamp in ms": 1701444928022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967528100682102, "Avg loss": 0.597572079161182, "Avg value loss": 0.23048867075704038, "Avg policy loss": 0.3670834098011255, "Total num played games": 20818, "Total num trained steps": 40960, "Timestamp in ms": 1701444938247, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9734870317002882, "Avg loss": 0.6388213180471212, "Avg value loss": 0.2736251894966699, "Avg policy loss": 0.3651961307041347, "Total num played games": 20820, "Total num trained steps": 41088, "Timestamp in ms": 1701444997004, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 92.27865322679281, "Avg game time in secs": 4.122236546856584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 20864, "Total num trained steps": 41139, "Timestamp in ms": 1701445020301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9705488621151273, "Avg loss": 0.6910697638522834, "Avg value loss": 0.3241852648789063, "Avg policy loss": 0.3668845030479133, "Total num played games": 20916, "Total num trained steps": 41216, "Timestamp in ms": 1701445055447, "logtype": "training_step"}
{"Avg objective": 20.4296875, "Games time in secs": 89.01208766363561, "Avg game time in secs": 4.515490076635615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.74, "agent_stopped_0": 0.38}, "Total num played games": 20992, "Total num trained steps": 41335, "Timestamp in ms": 1701445109313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9681995620298962, "Avg loss": 0.5868181341793388, "Avg value loss": 0.22867113357642666, "Avg policy loss": 0.3581470020581037, "Total num played games": 21006, "Total num trained steps": 41344, "Timestamp in ms": 1701445113158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737292975442604, "Avg loss": 0.6183019920717925, "Avg value loss": 0.2529979719547555, "Avg policy loss": 0.3653040232602507, "Total num played games": 21012, "Total num trained steps": 41472, "Timestamp in ms": 1701445173955, "logtype": "training_step"}
{"Total num played games": 21110, "Total num trained steps": 41536, "Timestamp in ms": 1701445227788, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5}
{"Avg objective": 20.2421875, "Games time in secs": 121.33380805514753, "Avg game time in secs": 4.53661314045894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 21120, "Total num trained steps": 41542, "Timestamp in ms": 1701445230650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9618939822674968, "Avg loss": 0.7785319362301379, "Avg value loss": 0.4088997180806473, "Avg policy loss": 0.3696322189643979, "Total num played games": 21204, "Total num trained steps": 41600, "Timestamp in ms": 1701445257952, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967930579136012, "Avg loss": 0.5894904397428036, "Avg value loss": 0.22604943864280358, "Avg policy loss": 0.3634409985970706, "Total num played games": 21204, "Total num trained steps": 41728, "Timestamp in ms": 1701445317236, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9739671760045274, "Avg loss": 0.5044743143953383, "Avg value loss": 0.17009892669739202, "Avg policy loss": 0.33437538996804506, "Total num played games": 21204, "Total num trained steps": 41856, "Timestamp in ms": 1701445377049, "logtype": "training_step"}
{"Avg objective": 19.203125, "Games time in secs": 168.41517233476043, "Avg game time in secs": 4.259871027214103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.7}, "Total num played games": 21248, "Total num trained steps": 41907, "Timestamp in ms": 1701445399066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710798122065727, "Avg loss": 0.7118826173245907, "Avg value loss": 0.3354313419549726, "Avg policy loss": 0.3764512689085677, "Total num played games": 21300, "Total num trained steps": 41984, "Timestamp in ms": 1701445435950, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 91.9070400763303, "Avg game time in secs": 4.5486067405872745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 21376, "Total num trained steps": 42106, "Timestamp in ms": 1701445490973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684023558006918, "Avg loss": 0.580821034964174, "Avg value loss": 0.20895655424101278, "Avg policy loss": 0.3718644760083407, "Total num played games": 21392, "Total num trained steps": 42112, "Timestamp in ms": 1701445493429, "logtype": "training_step"}
{"Total num played games": 21398, "Total num trained steps": 42138, "Timestamp in ms": 1701445531199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.45703125}
{"Ratio train steps to played games": 1.9653824678950307, "Avg loss": 0.9071832746267319, "Avg value loss": 0.49847411713562906, "Avg policy loss": 0.4087091570254415, "Total num played games": 21492, "Total num trained steps": 42240, "Timestamp in ms": 1701445578100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9713381723431975, "Avg loss": 0.6463546305894852, "Avg value loss": 0.26575181307271123, "Avg policy loss": 0.3806028172839433, "Total num played games": 21492, "Total num trained steps": 42368, "Timestamp in ms": 1701445638793, "logtype": "training_step"}
{"Avg objective": 21.1328125, "Games time in secs": 198.3433852326125, "Avg game time in secs": 4.002786907120026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.61, "agent_stopped_0": 0.47}, "Total num played games": 21504, "Total num trained steps": 42478, "Timestamp in ms": 1701445689316, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688658265381764, "Avg loss": 0.7022865733597428, "Avg value loss": 0.329146089265123, "Avg policy loss": 0.37314048153348267, "Total num played games": 21584, "Total num trained steps": 42496, "Timestamp in ms": 1701445696615, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744302390216788, "Avg loss": 0.6427030642516911, "Avg value loss": 0.24779660307103768, "Avg policy loss": 0.39490646112244576, "Total num played games": 21588, "Total num trained steps": 42624, "Timestamp in ms": 1701445755167, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 89.7644722443074, "Avg game time in secs": 3.8499388098425698, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 21632, "Total num trained steps": 42675, "Timestamp in ms": 1701445779081, "logtype": "played_game"}
{"Total num played games": 21684, "Total num trained steps": 42742, "Timestamp in ms": 1701445836901, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.34375}
{"Ratio train steps to played games": 1.968868011421203, "Avg loss": 0.6981383461970836, "Avg value loss": 0.30817748280242085, "Avg policy loss": 0.389960863860324, "Total num played games": 21714, "Total num trained steps": 42752, "Timestamp in ms": 1701445842028, "logtype": "training_step"}
{"Avg objective": 19.7890625, "Games time in secs": 65.97990498133004, "Avg game time in secs": 4.629275209837942, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.8, "agent_stopped_0": 0.31}, "Total num played games": 21760, "Total num trained steps": 42758, "Timestamp in ms": 1701445845061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9689595004132612, "Avg loss": 0.7014911260921508, "Avg value loss": 0.3034236741368659, "Avg policy loss": 0.39806744852103293, "Total num played games": 21778, "Total num trained steps": 42880, "Timestamp in ms": 1701445901880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748369914592707, "Avg loss": 0.5573688128497452, "Avg value loss": 0.18602212076075375, "Avg policy loss": 0.37134669348597527, "Total num played games": 21778, "Total num trained steps": 43008, "Timestamp in ms": 1701445958950, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9720215781292858, "Avg loss": 0.6797116061206907, "Avg value loss": 0.2907094500842504, "Avg policy loss": 0.38900215388275683, "Total num played games": 21874, "Total num trained steps": 43136, "Timestamp in ms": 1701446016254, "logtype": "training_step"}
{"Avg objective": 18.9765625, "Games time in secs": 218.0429601315409, "Avg game time in secs": 4.591385552441352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.69, "agent_stopped_0": 0.42}, "Total num played games": 21888, "Total num trained steps": 43242, "Timestamp in ms": 1701446063104, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969948092159184, "Avg loss": 0.6039684356655926, "Avg value loss": 0.22719108627643436, "Avg policy loss": 0.3767773495055735, "Total num played games": 21962, "Total num trained steps": 43264, "Timestamp in ms": 1701446072476, "logtype": "training_step"}
{"Total num played games": 21970, "Total num trained steps": 43343, "Timestamp in ms": 1701446138778, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.44921875}
{"Avg objective": 20.0, "Games time in secs": 80.6019913032651, "Avg game time in secs": 4.147443680543802, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.71, "agent_stopped_0": 0.39}, "Total num played games": 22016, "Total num trained steps": 43353, "Timestamp in ms": 1701446143707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666424945612764, "Avg loss": 0.7288339163642377, "Avg value loss": 0.3283771356800571, "Avg policy loss": 0.40045678662136197, "Total num played games": 22064, "Total num trained steps": 43392, "Timestamp in ms": 1701446162557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9724437998549673, "Avg loss": 0.5799547501374036, "Avg value loss": 0.19371084409067407, "Avg policy loss": 0.3862439065705985, "Total num played games": 22064, "Total num trained steps": 43520, "Timestamp in ms": 1701446219793, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 127.46731453947723, "Avg game time in secs": 4.071965346127399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 22144, "Total num trained steps": 43632, "Timestamp in ms": 1701446271175, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696750902527076, "Avg loss": 0.59655048744753, "Avg value loss": 0.23259881074773148, "Avg policy loss": 0.3639516776893288, "Total num played games": 22160, "Total num trained steps": 43648, "Timestamp in ms": 1701446278326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9754512635379062, "Avg loss": 0.6208420831244439, "Avg value loss": 0.2390796662075445, "Avg policy loss": 0.38176241610199213, "Total num played games": 22160, "Total num trained steps": 43776, "Timestamp in ms": 1701446337349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726815240833933, "Avg loss": 0.6533917714841664, "Avg value loss": 0.27496451197657734, "Avg policy loss": 0.37842725589871407, "Total num played games": 22256, "Total num trained steps": 43904, "Timestamp in ms": 1701446393655, "logtype": "training_step"}
{"Total num played games": 22256, "Total num trained steps": 43945, "Timestamp in ms": 1701446438090, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.859375}
{"Avg objective": 21.734375, "Games time in secs": 170.3513910714537, "Avg game time in secs": 3.820842247645487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 22272, "Total num trained steps": 43952, "Timestamp in ms": 1701446441526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701118568232663, "Avg loss": 0.7028983139898628, "Avg value loss": 0.314984904252924, "Avg policy loss": 0.3879134135786444, "Total num played games": 22350, "Total num trained steps": 44032, "Timestamp in ms": 1701446480316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758389261744966, "Avg loss": 0.5607145831454545, "Avg value loss": 0.18731784191913903, "Avg policy loss": 0.37339674145914614, "Total num played games": 22350, "Total num trained steps": 44160, "Timestamp in ms": 1701446537916, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 114.32652869448066, "Avg game time in secs": 3.7859916412853636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 22400, "Total num trained steps": 44199, "Timestamp in ms": 1701446555853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730909738928986, "Avg loss": 0.647627383004874, "Avg value loss": 0.2738765067188069, "Avg policy loss": 0.37375087663531303, "Total num played games": 22446, "Total num trained steps": 44288, "Timestamp in ms": 1701446595673, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 86.51254681311548, "Avg game time in secs": 4.180099321281887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 22528, "Total num trained steps": 44394, "Timestamp in ms": 1701446642366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970366427113832, "Avg loss": 0.582973547745496, "Avg value loss": 0.21381759183714166, "Avg policy loss": 0.3691559561993927, "Total num played games": 22542, "Total num trained steps": 44416, "Timestamp in ms": 1701446651993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9760447165291455, "Avg loss": 0.5693695258814842, "Avg value loss": 0.19185000273864716, "Avg policy loss": 0.3775195190683007, "Total num played games": 22542, "Total num trained steps": 44544, "Timestamp in ms": 1701446709739, "logtype": "training_step"}
{"Total num played games": 22542, "Total num trained steps": 44547, "Timestamp in ms": 1701446732326, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.16796875}
{"Ratio train steps to played games": 1.9734935500971904, "Avg loss": 0.751559630734846, "Avg value loss": 0.3725679608178325, "Avg policy loss": 0.3789916702080518, "Total num played games": 22636, "Total num trained steps": 44672, "Timestamp in ms": 1701446792124, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 192.49949076399207, "Avg game time in secs": 3.6264570296480088, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.69, "agent_stopped_0": 0.44}, "Total num played games": 22656, "Total num trained steps": 44769, "Timestamp in ms": 1701446834865, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707900756642618, "Avg loss": 0.6955205095000565, "Avg value loss": 0.32853966974653304, "Avg policy loss": 0.36698084557428956, "Total num played games": 22732, "Total num trained steps": 44800, "Timestamp in ms": 1701446849111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976420904451874, "Avg loss": 0.5835555451922119, "Avg value loss": 0.20363678655121475, "Avg policy loss": 0.37991875666193664, "Total num played games": 22732, "Total num trained steps": 44928, "Timestamp in ms": 1701446906355, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 86.73072626069188, "Avg game time in secs": 3.740554775155033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 22784, "Total num trained steps": 44962, "Timestamp in ms": 1701446921596, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737164885228666, "Avg loss": 0.622285517398268, "Avg value loss": 0.25223199470201507, "Avg policy loss": 0.37005351879633963, "Total num played games": 22828, "Total num trained steps": 45056, "Timestamp in ms": 1701446963825, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 87.82342346943915, "Avg game time in secs": 3.7107488281617407, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 22912, "Total num trained steps": 45149, "Timestamp in ms": 1701447009420, "logtype": "played_game"}
{"Total num played games": 22924, "Total num trained steps": 45149, "Timestamp in ms": 1701447026575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.59375}
{"Ratio train steps to played games": 1.9629854896168215, "Avg loss": 0.7185087334364653, "Avg value loss": 0.36004782508825883, "Avg policy loss": 0.3584609036333859, "Total num played games": 23018, "Total num trained steps": 45184, "Timestamp in ms": 1701447044117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968546355026501, "Avg loss": 0.7060062268283218, "Avg value loss": 0.3386440925532952, "Avg policy loss": 0.3673621341586113, "Total num played games": 23018, "Total num trained steps": 45312, "Timestamp in ms": 1701447102487, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9741072204361805, "Avg loss": 0.5085810106247663, "Avg value loss": 0.16480507008964196, "Avg policy loss": 0.3437759436201304, "Total num played games": 23018, "Total num trained steps": 45440, "Timestamp in ms": 1701447161448, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 192.36612391285598, "Avg game time in secs": 3.3727716485154815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 23040, "Total num trained steps": 45531, "Timestamp in ms": 1701447201786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9714026131348965, "Avg loss": 0.5704506819602102, "Avg value loss": 0.2332161240046844, "Avg policy loss": 0.3372345595853403, "Total num played games": 23114, "Total num trained steps": 45568, "Timestamp in ms": 1701447219672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9769836462749848, "Avg loss": 0.5300245741382241, "Avg value loss": 0.18407505884533748, "Avg policy loss": 0.34594951558392495, "Total num played games": 23114, "Total num trained steps": 45696, "Timestamp in ms": 1701447275972, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 88.01203714124858, "Avg game time in secs": 3.5048908220633166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 23168, "Total num trained steps": 45726, "Timestamp in ms": 1701447289798, "logtype": "played_game"}
{"Total num played games": 23210, "Total num trained steps": 45753, "Timestamp in ms": 1701447322312, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1328125}
{"Avg objective": 20.515625, "Games time in secs": 40.552248353138566, "Avg game time in secs": 3.835411920386832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 23296, "Total num trained steps": 45768, "Timestamp in ms": 1701447330351, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9663577068314453, "Avg loss": 0.7330657651182264, "Avg value loss": 0.37770068779354915, "Avg policy loss": 0.3553650798276067, "Total num played games": 23304, "Total num trained steps": 45824, "Timestamp in ms": 1701447356358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9718503261242706, "Avg loss": 0.5088289484847337, "Avg value loss": 0.17250316735589877, "Avg policy loss": 0.3363257811870426, "Total num played games": 23304, "Total num trained steps": 45952, "Timestamp in ms": 1701447412992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9773429454170959, "Avg loss": 0.45430631237104535, "Avg value loss": 0.13140175578882918, "Avg policy loss": 0.3229045607149601, "Total num played games": 23304, "Total num trained steps": 46080, "Timestamp in ms": 1701447471389, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9747008547008547, "Avg loss": 0.572178044822067, "Avg value loss": 0.24726532289059833, "Avg policy loss": 0.32491272513289005, "Total num played games": 23400, "Total num trained steps": 46208, "Timestamp in ms": 1701447529521, "logtype": "training_step"}
{"Avg objective": 20.5546875, "Games time in secs": 239.46938351541758, "Avg game time in secs": 3.7977532018121565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 23424, "Total num trained steps": 46296, "Timestamp in ms": 1701447569820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972080354102826, "Avg loss": 0.681669733254239, "Avg value loss": 0.3568018320365809, "Avg policy loss": 0.32486789964605123, "Total num played games": 23496, "Total num trained steps": 46336, "Timestamp in ms": 1701447587502, "logtype": "training_step"}
{"Total num played games": 23496, "Total num trained steps": 46354, "Timestamp in ms": 1701447615517, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.046875}
{"Avg objective": 20.4296875, "Games time in secs": 51.358050445094705, "Avg game time in secs": 3.582583064911887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 23552, "Total num trained steps": 46365, "Timestamp in ms": 1701447621178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696481559983043, "Avg loss": 0.6432321174070239, "Avg value loss": 0.308800611179322, "Avg policy loss": 0.3344315050635487, "Total num played games": 23590, "Total num trained steps": 46464, "Timestamp in ms": 1701447665716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975074183976261, "Avg loss": 0.46151439705863595, "Avg value loss": 0.1448741159401834, "Avg policy loss": 0.31664027902297676, "Total num played games": 23590, "Total num trained steps": 46592, "Timestamp in ms": 1701447724652, "logtype": "training_step"}
{"Avg objective": 20.25, "Games time in secs": 148.67335150018334, "Avg game time in secs": 3.8880846149113495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.63}, "Total num played games": 23680, "Total num trained steps": 46686, "Timestamp in ms": 1701447769852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972306653157717, "Avg loss": 0.5687316649127752, "Avg value loss": 0.25720466405618936, "Avg policy loss": 0.3115270002745092, "Total num played games": 23688, "Total num trained steps": 46720, "Timestamp in ms": 1701447784530, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777102330293819, "Avg loss": 0.5906063369475305, "Avg value loss": 0.2776351748034358, "Avg policy loss": 0.31297116342466325, "Total num played games": 23688, "Total num trained steps": 46848, "Timestamp in ms": 1701447843262, "logtype": "training_step"}
{"Total num played games": 23784, "Total num trained steps": 46954, "Timestamp in ms": 1701447916321, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.73828125}
{"Avg objective": 20.1484375, "Games time in secs": 150.35350826568902, "Avg game time in secs": 3.7019311401236337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 23808, "Total num trained steps": 46962, "Timestamp in ms": 1701447920206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967333947566798, "Avg loss": 0.6022750639822334, "Avg value loss": 0.2761393862310797, "Avg policy loss": 0.32613568170927465, "Total num played games": 23878, "Total num trained steps": 46976, "Timestamp in ms": 1701447926986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972694530530195, "Avg loss": 0.6236721035093069, "Avg value loss": 0.27721145149553195, "Avg policy loss": 0.3464606483466923, "Total num played games": 23878, "Total num trained steps": 47104, "Timestamp in ms": 1701447987188, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9780551134935924, "Avg loss": 0.4730072496458888, "Avg value loss": 0.1602352544432506, "Avg policy loss": 0.3127719974145293, "Total num played games": 23878, "Total num trained steps": 47232, "Timestamp in ms": 1701448044615, "logtype": "training_step"}
{"Avg objective": 20.5546875, "Games time in secs": 135.5207956470549, "Avg game time in secs": 3.4367180811677827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 23936, "Total num trained steps": 47254, "Timestamp in ms": 1701448055727, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754734295486778, "Avg loss": 0.5761581531260163, "Avg value loss": 0.2527259884518571, "Avg policy loss": 0.32343216927256435, "Total num played games": 23974, "Total num trained steps": 47360, "Timestamp in ms": 1701448102114, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 89.2373969964683, "Avg game time in secs": 3.7559681949205697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 24064, "Total num trained steps": 47453, "Timestamp in ms": 1701448144964, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9729123390112173, "Avg loss": 0.5531382027547807, "Avg value loss": 0.2303840506938286, "Avg policy loss": 0.32275415502954274, "Total num played games": 24070, "Total num trained steps": 47488, "Timestamp in ms": 1701448160406, "logtype": "training_step"}
{"Total num played games": 24070, "Total num trained steps": 47557, "Timestamp in ms": 1701448211014, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.35546875}
{"Ratio train steps to played games": 1.9705346796887933, "Avg loss": 0.5913289070595056, "Avg value loss": 0.2612227014033124, "Avg policy loss": 0.3301062068203464, "Total num played games": 24164, "Total num trained steps": 47616, "Timestamp in ms": 1701448238186, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758318159245158, "Avg loss": 0.49133839062415063, "Avg value loss": 0.1708796415477991, "Avg policy loss": 0.3204587472137064, "Total num played games": 24164, "Total num trained steps": 47744, "Timestamp in ms": 1701448296384, "logtype": "training_step"}
{"Avg objective": 19.390625, "Games time in secs": 186.5583530496806, "Avg game time in secs": 3.599356367281871, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.54, "agent_stopped_0": 0.48}, "Total num played games": 24192, "Total num trained steps": 47823, "Timestamp in ms": 1701448331523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973126700189597, "Avg loss": 0.5438900294248015, "Avg value loss": 0.22495959309162572, "Avg policy loss": 0.31893043394666165, "Total num played games": 24262, "Total num trained steps": 47872, "Timestamp in ms": 1701448353209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978402440029676, "Avg loss": 0.4927568936254829, "Avg value loss": 0.16894993121968582, "Avg policy loss": 0.3238069631624967, "Total num played games": 24262, "Total num trained steps": 48000, "Timestamp in ms": 1701448411187, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 90.25949299521744, "Avg game time in secs": 3.470182388467947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.6}, "Total num played games": 24320, "Total num trained steps": 48025, "Timestamp in ms": 1701448421782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758190327613105, "Avg loss": 0.5883626542054117, "Avg value loss": 0.25971217593178153, "Avg policy loss": 0.32865047932136804, "Total num played games": 24358, "Total num trained steps": 48128, "Timestamp in ms": 1701448468762, "logtype": "training_step"}
{"Total num played games": 24358, "Total num trained steps": 48161, "Timestamp in ms": 1701448503702, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.234375}
{"Avg objective": 20.0, "Games time in secs": 91.137949148193, "Avg game time in secs": 3.9117920130083803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 24448, "Total num trained steps": 48180, "Timestamp in ms": 1701448512921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973499100278096, "Avg loss": 0.5855302321724594, "Avg value loss": 0.2519843328045681, "Avg policy loss": 0.33354589832015336, "Total num played games": 24452, "Total num trained steps": 48256, "Timestamp in ms": 1701448547580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9787338459021757, "Avg loss": 0.46850572479888797, "Avg value loss": 0.1448424172704108, "Avg policy loss": 0.3236633047927171, "Total num played games": 24452, "Total num trained steps": 48384, "Timestamp in ms": 1701448606551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97620987453153, "Avg loss": 0.5843315890524536, "Avg value loss": 0.24602848204085603, "Avg policy loss": 0.33830310485791415, "Total num played games": 24548, "Total num trained steps": 48512, "Timestamp in ms": 1701448666016, "logtype": "training_step"}
{"Avg objective": 19.7578125, "Games time in secs": 188.77752687223256, "Avg game time in secs": 3.342481284707901, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 24576, "Total num trained steps": 48591, "Timestamp in ms": 1701448701698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9738657576495415, "Avg loss": 0.5999392997473478, "Avg value loss": 0.2711025964235887, "Avg policy loss": 0.3288367019267753, "Total num played games": 24642, "Total num trained steps": 48640, "Timestamp in ms": 1701448724065, "logtype": "training_step"}
{"Total num played games": 24642, "Total num trained steps": 48762, "Timestamp in ms": 1701448794969, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1484375}
{"Ratio train steps to played games": 1.9771345171491121, "Avg loss": 0.5112166306935251, "Avg value loss": 0.16783124266657978, "Avg policy loss": 0.34338538616430014, "Total num played games": 24662, "Total num trained steps": 48768, "Timestamp in ms": 1701448798352, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 99.0591841749847, "Avg game time in secs": 3.359124626251287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 24704, "Total num trained steps": 48773, "Timestamp in ms": 1701448800758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9766736739974127, "Avg loss": 0.6194676517043263, "Avg value loss": 0.2800372063065879, "Avg policy loss": 0.3394304469693452, "Total num played games": 24736, "Total num trained steps": 48896, "Timestamp in ms": 1701448854537, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 92.40429231896996, "Avg game time in secs": 3.8134609427215764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 24832, "Total num trained steps": 48979, "Timestamp in ms": 1701448893163, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9742268041237114, "Avg loss": 0.5751997302286327, "Avg value loss": 0.23778197390493006, "Avg policy loss": 0.3374177555087954, "Total num played games": 24832, "Total num trained steps": 49024, "Timestamp in ms": 1701448914051, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793814432989691, "Avg loss": 0.4928283041808754, "Avg value loss": 0.16108898783568293, "Avg policy loss": 0.3317393173929304, "Total num played games": 24832, "Total num trained steps": 49152, "Timestamp in ms": 1701448971656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9768934531450577, "Avg loss": 0.5975907088723034, "Avg value loss": 0.2543565671076067, "Avg policy loss": 0.34323414240498096, "Total num played games": 24928, "Total num trained steps": 49280, "Timestamp in ms": 1701449031696, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 169.98486336134374, "Avg game time in secs": 2.905012917224667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 24960, "Total num trained steps": 49352, "Timestamp in ms": 1701449063148, "logtype": "played_game"}
{"Total num played games": 25024, "Total num trained steps": 49362, "Timestamp in ms": 1701449085709, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0}
{"Avg objective": 20.0, "Games time in secs": 28.42149819433689, "Avg game time in secs": 3.5558908875245834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.66, "agent_stopped_0": 0.42}, "Total num played games": 25088, "Total num trained steps": 49375, "Timestamp in ms": 1701449091569, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967035592005733, "Avg loss": 0.6432310580275953, "Avg value loss": 0.2989292411948554, "Avg policy loss": 0.34430182073265314, "Total num played games": 25118, "Total num trained steps": 49408, "Timestamp in ms": 1701449106016, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9721315391352814, "Avg loss": 0.5442359575536102, "Avg value loss": 0.19194557674927637, "Avg policy loss": 0.35229038330726326, "Total num played games": 25118, "Total num trained steps": 49536, "Timestamp in ms": 1701449164237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771876741778804, "Avg loss": 0.4607945180032402, "Avg value loss": 0.13602548511698842, "Avg policy loss": 0.3247690306743607, "Total num played games": 25118, "Total num trained steps": 49664, "Timestamp in ms": 1701449222575, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9747759181407154, "Avg loss": 0.5999001991003752, "Avg value loss": 0.2678636972559616, "Avg policy loss": 0.3320365028921515, "Total num played games": 25214, "Total num trained steps": 49792, "Timestamp in ms": 1701449280296, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 244.84076397679746, "Avg game time in secs": 3.785292820626637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.67, "agent_stopped_0": 0.44}, "Total num played games": 25216, "Total num trained steps": 49917, "Timestamp in ms": 1701449336410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9796954314720812, "Avg loss": 0.47819007956422865, "Avg value loss": 0.1456446053343825, "Avg policy loss": 0.33254547137767076, "Total num played games": 25216, "Total num trained steps": 49920, "Timestamp in ms": 1701449337500, "logtype": "training_step"}
{"Total num played games": 25310, "Total num trained steps": 49965, "Timestamp in ms": 1701449374943, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.234375}
{"Avg objective": 21.46875, "Games time in secs": 42.61341457255185, "Avg game time in secs": 3.1537183844775427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 25344, "Total num trained steps": 49973, "Timestamp in ms": 1701449379025, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9700834514249725, "Avg loss": 0.6705115446820855, "Avg value loss": 0.31705142301507294, "Avg policy loss": 0.35346012259833515, "Total num played games": 25404, "Total num trained steps": 50048, "Timestamp in ms": 1701449413440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9751220280270823, "Avg loss": 0.485304641071707, "Avg value loss": 0.14374487492023036, "Avg policy loss": 0.3415597665589303, "Total num played games": 25404, "Total num trained steps": 50176, "Timestamp in ms": 1701449471041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764262140499764, "Avg loss": 0.46637938148342073, "Avg value loss": 0.13790466747013852, "Avg policy loss": 0.32847471442073584, "Total num played games": 25450, "Total num trained steps": 50304, "Timestamp in ms": 1701449527093, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 148.9574181549251, "Avg game time in secs": 3.1512508702726336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 25472, "Total num trained steps": 50305, "Timestamp in ms": 1701449527981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777254901960784, "Avg loss": 0.562619193457067, "Avg value loss": 0.23300818435382098, "Avg policy loss": 0.3296110074734315, "Total num played games": 25500, "Total num trained steps": 50432, "Timestamp in ms": 1701449583497, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.5603143491316587, "Avg value loss": 0.2332443055929616, "Avg policy loss": 0.32707004144322127, "Total num played games": 25596, "Total num trained steps": 50560, "Timestamp in ms": 1701449640635, "logtype": "training_step"}
{"Total num played games": 25596, "Total num trained steps": 50566, "Timestamp in ms": 1701449660201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.77734375}
{"Avg objective": 20.2109375, "Games time in secs": 134.942203912884, "Avg game time in secs": 3.5731446871213848, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.68}, "Total num played games": 25600, "Total num trained steps": 50571, "Timestamp in ms": 1701449662924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730634488127676, "Avg loss": 0.601351777324453, "Avg value loss": 0.2525099170161411, "Avg policy loss": 0.34884186019189656, "Total num played games": 25690, "Total num trained steps": 50688, "Timestamp in ms": 1701449715330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9780459322693655, "Avg loss": 0.45066430210135877, "Avg value loss": 0.13499859196599573, "Avg policy loss": 0.31566571176517755, "Total num played games": 25690, "Total num trained steps": 50816, "Timestamp in ms": 1701449772740, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 136.98550731502473, "Avg game time in secs": 2.7142468457168434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 25728, "Total num trained steps": 50876, "Timestamp in ms": 1701449799909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754924771211415, "Avg loss": 0.5482713477686048, "Avg value loss": 0.22602732526138425, "Avg policy loss": 0.3222440240206197, "Total num played games": 25788, "Total num trained steps": 50944, "Timestamp in ms": 1701449830862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977618586640852, "Avg loss": 0.47776867472566664, "Avg value loss": 0.15258395118871704, "Avg policy loss": 0.32518472021911293, "Total num played games": 25824, "Total num trained steps": 51072, "Timestamp in ms": 1701449887472, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 89.22793104685843, "Avg game time in secs": 3.4565069486998254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 25856, "Total num trained steps": 51076, "Timestamp in ms": 1701449889138, "logtype": "played_game"}
{"Total num played games": 25884, "Total num trained steps": 51170, "Timestamp in ms": 1701449947911, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.859375}
{"Ratio train steps to played games": 1.9708984525367619, "Avg loss": 0.59790244163014, "Avg value loss": 0.270313004788477, "Avg policy loss": 0.3275894426042214, "Total num played games": 25978, "Total num trained steps": 51200, "Timestamp in ms": 1701449961100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757872045577027, "Avg loss": 0.4874168671667576, "Avg value loss": 0.16255890863249078, "Avg policy loss": 0.32485795428510755, "Total num played games": 25978, "Total num trained steps": 51328, "Timestamp in ms": 1701450017966, "logtype": "training_step"}
{"Avg objective": 19.6953125, "Games time in secs": 181.97495193965733, "Avg game time in secs": 3.3318118595634587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 25984, "Total num trained steps": 51448, "Timestamp in ms": 1701450071113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757333742896637, "Avg loss": 0.45600341144017875, "Avg value loss": 0.13775655563222244, "Avg policy loss": 0.31824685144238174, "Total num played games": 26044, "Total num trained steps": 51456, "Timestamp in ms": 1701450074064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978369256730843, "Avg loss": 0.5935864571947604, "Avg value loss": 0.2691055794712156, "Avg policy loss": 0.3244808721356094, "Total num played games": 26074, "Total num trained steps": 51584, "Timestamp in ms": 1701450131516, "logtype": "training_step"}
{"Avg objective": 20.2578125, "Games time in secs": 86.80014571174979, "Avg game time in secs": 3.0892234168568393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 26112, "Total num trained steps": 51643, "Timestamp in ms": 1701450157913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9760030569354223, "Avg loss": 0.5457657482475042, "Avg value loss": 0.22596293105743825, "Avg policy loss": 0.31980281963478774, "Total num played games": 26170, "Total num trained steps": 51712, "Timestamp in ms": 1701450188344, "logtype": "training_step"}
{"Total num played games": 26170, "Total num trained steps": 51774, "Timestamp in ms": 1701450232941, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.78515625}
{"Avg objective": 20.2265625, "Games time in secs": 80.48041076771915, "Avg game time in secs": 3.442256715381518, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 26240, "Total num trained steps": 51785, "Timestamp in ms": 1701450238394, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973804447151995, "Avg loss": 0.5646440363489091, "Avg value loss": 0.23272900155279785, "Avg policy loss": 0.3319150358438492, "Total num played games": 26264, "Total num trained steps": 51840, "Timestamp in ms": 1701450263623, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786780383795308, "Avg loss": 0.465668621705845, "Avg value loss": 0.13966510468162596, "Avg policy loss": 0.3260035142302513, "Total num played games": 26264, "Total num trained steps": 51968, "Timestamp in ms": 1701450321299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758780247288175, "Avg loss": 0.6142556297127157, "Avg value loss": 0.2867039750562981, "Avg policy loss": 0.3275516484864056, "Total num played games": 26366, "Total num trained steps": 52096, "Timestamp in ms": 1701450379116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807327618903132, "Avg loss": 0.5787666609976441, "Avg value loss": 0.25428240204928443, "Avg policy loss": 0.32448426098562777, "Total num played games": 26366, "Total num trained steps": 52224, "Timestamp in ms": 1701450438634, "logtype": "training_step"}
{"Avg objective": 19.3203125, "Games time in secs": 200.6433291491121, "Avg game time in secs": 3.5427664375310997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.68, "agent_stopped_0": 0.42}, "Total num played games": 26368, "Total num trained steps": 52225, "Timestamp in ms": 1701450439037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785336356764929, "Avg loss": 0.6447990187443793, "Avg value loss": 0.2991102351807058, "Avg policy loss": 0.34568878216668963, "Total num played games": 26460, "Total num trained steps": 52352, "Timestamp in ms": 1701450496587, "logtype": "training_step"}
{"Total num played games": 26460, "Total num trained steps": 52374, "Timestamp in ms": 1701450521946, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.7734375}
{"Avg objective": 20.5234375, "Games time in secs": 86.27164698578417, "Avg game time in secs": 2.931079575253534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 26496, "Total num trained steps": 52380, "Timestamp in ms": 1701450525309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9763500790841304, "Avg loss": 0.6166603569872677, "Avg value loss": 0.2753054052591324, "Avg policy loss": 0.3413549535907805, "Total num played games": 26554, "Total num trained steps": 52480, "Timestamp in ms": 1701450570739, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 102.50140835903585, "Avg game time in secs": 3.294569826044608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.58}, "Total num played games": 26624, "Total num trained steps": 52606, "Timestamp in ms": 1701450627810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9752196440639784, "Avg loss": 0.46736021945253015, "Avg value loss": 0.13731908542104065, "Avg policy loss": 0.3300411347299814, "Total num played games": 26634, "Total num trained steps": 52608, "Timestamp in ms": 1701450628665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788367729831144, "Avg loss": 0.5405148072168231, "Avg value loss": 0.21452419372508302, "Avg policy loss": 0.32599061622750014, "Total num played games": 26650, "Total num trained steps": 52736, "Timestamp in ms": 1701450686455, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9765198534360278, "Avg loss": 0.5959321120753884, "Avg value loss": 0.2768675492843613, "Avg policy loss": 0.31906455860007554, "Total num played games": 26746, "Total num trained steps": 52864, "Timestamp in ms": 1701450744982, "logtype": "training_step"}
{"Total num played games": 26746, "Total num trained steps": 52974, "Timestamp in ms": 1701450812683, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.19921875}
{"Avg objective": 19.6171875, "Games time in secs": 187.1759606525302, "Avg game time in secs": 3.221809196547838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.65}, "Total num played games": 26752, "Total num trained steps": 52977, "Timestamp in ms": 1701450814987, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9743666169895677, "Avg loss": 0.4709956073202193, "Avg value loss": 0.16009733744431287, "Avg policy loss": 0.31089827441610396, "Total num played games": 26840, "Total num trained steps": 52992, "Timestamp in ms": 1701450821732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791356184798807, "Avg loss": 0.5128250494599342, "Avg value loss": 0.18538721866207197, "Avg policy loss": 0.32743782876059413, "Total num played games": 26840, "Total num trained steps": 53120, "Timestamp in ms": 1701450880016, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 90.28356439061463, "Avg game time in secs": 2.6002829338394804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 26880, "Total num trained steps": 53176, "Timestamp in ms": 1701450905270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768339768339769, "Avg loss": 0.5707349663134664, "Avg value loss": 0.2453328860574402, "Avg policy loss": 0.3254020782187581, "Total num played games": 26936, "Total num trained steps": 53248, "Timestamp in ms": 1701450937879, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 87.69887723773718, "Avg game time in secs": 2.8715019232331542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 27008, "Total num trained steps": 53368, "Timestamp in ms": 1701450992969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9745486830423202, "Avg loss": 0.494641785742715, "Avg value loss": 0.1614649877883494, "Avg policy loss": 0.3331768001662567, "Total num played games": 27032, "Total num trained steps": 53376, "Timestamp in ms": 1701450996028, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792838117786327, "Avg loss": 0.5569100785069168, "Avg value loss": 0.22091358993202448, "Avg policy loss": 0.3359964871779084, "Total num played games": 27032, "Total num trained steps": 53504, "Timestamp in ms": 1701451054294, "logtype": "training_step"}
{"Total num played games": 27128, "Total num trained steps": 53577, "Timestamp in ms": 1701451101064, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.89453125}
{"Avg objective": 20.0859375, "Games time in secs": 111.01975026726723, "Avg game time in secs": 3.1003932219027774, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.53, "agent_stopped_0": 0.53}, "Total num played games": 27136, "Total num trained steps": 53581, "Timestamp in ms": 1701451103989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701711850708985, "Avg loss": 0.6410405684728175, "Avg value loss": 0.2945468619582243, "Avg policy loss": 0.34649370645638555, "Total num played games": 27222, "Total num trained steps": 53632, "Timestamp in ms": 1701451127025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974873264271545, "Avg loss": 0.50329047604464, "Avg value loss": 0.16606767888879403, "Avg policy loss": 0.3372227968648076, "Total num played games": 27222, "Total num trained steps": 53760, "Timestamp in ms": 1701451186402, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795753434721917, "Avg loss": 0.46840930520556867, "Avg value loss": 0.1474887986551039, "Avg policy loss": 0.3209205059101805, "Total num played games": 27222, "Total num trained steps": 53888, "Timestamp in ms": 1701451245520, "logtype": "training_step"}
{"Avg objective": 19.8125, "Games time in secs": 164.63844251818955, "Avg game time in secs": 2.9054563006939134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 27264, "Total num trained steps": 53940, "Timestamp in ms": 1701451268628, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773043414598432, "Avg loss": 0.5346153939608485, "Avg value loss": 0.20811626710928977, "Avg policy loss": 0.3264991254545748, "Total num played games": 27318, "Total num trained steps": 54016, "Timestamp in ms": 1701451302861, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 87.1424779240042, "Avg game time in secs": 2.9820563576504355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 27392, "Total num trained steps": 54134, "Timestamp in ms": 1701451355770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750492449113592, "Avg loss": 0.5175602063536644, "Avg value loss": 0.18919951282441616, "Avg policy loss": 0.32836069422774017, "Total num played games": 27414, "Total num trained steps": 54144, "Timestamp in ms": 1701451359701, "logtype": "training_step"}
{"Total num played games": 27414, "Total num trained steps": 54177, "Timestamp in ms": 1701451388801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.58984375}
{"Ratio train steps to played games": 1.9729533226697689, "Avg loss": 0.630649103783071, "Avg value loss": 0.2815884413430467, "Avg policy loss": 0.34906066465191543, "Total num played games": 27508, "Total num trained steps": 54272, "Timestamp in ms": 1701451433614, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776065144685182, "Avg loss": 0.47891166480258107, "Avg value loss": 0.12785800819983706, "Avg policy loss": 0.3510536558460444, "Total num played games": 27508, "Total num trained steps": 54400, "Timestamp in ms": 1701451493099, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 187.4465021789074, "Avg game time in secs": 3.2278770222474122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 27520, "Total num trained steps": 54509, "Timestamp in ms": 1701451543217, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975365889001594, "Avg loss": 0.4792257519438863, "Avg value loss": 0.1553949920926243, "Avg policy loss": 0.32383076031692326, "Total num played games": 27604, "Total num trained steps": 54528, "Timestamp in ms": 1701451551098, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800028981307056, "Avg loss": 0.5374240917153656, "Avg value loss": 0.18996112374588847, "Avg policy loss": 0.3474629642441869, "Total num played games": 27604, "Total num trained steps": 54656, "Timestamp in ms": 1701451609844, "logtype": "training_step"}
{"Avg objective": 19.0625, "Games time in secs": 90.1607544478029, "Avg game time in secs": 2.908563868244528, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 27648, "Total num trained steps": 54704, "Timestamp in ms": 1701451633378, "logtype": "played_game"}
{"Total num played games": 27700, "Total num trained steps": 54780, "Timestamp in ms": 1701451680887, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.4765625}
{"Ratio train steps to played games": 1.97733342958204, "Avg loss": 0.5812821113504469, "Avg value loss": 0.24059465987375006, "Avg policy loss": 0.340687446994707, "Total num played games": 27704, "Total num trained steps": 54784, "Timestamp in ms": 1701451683379, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 53.115297347307205, "Avg game time in secs": 3.111568772525061, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 27776, "Total num trained steps": 54792, "Timestamp in ms": 1701451686494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756782039289056, "Avg loss": 0.6042966889217496, "Avg value loss": 0.24040425359271467, "Avg policy loss": 0.3638924341648817, "Total num played games": 27794, "Total num trained steps": 54912, "Timestamp in ms": 1701451741716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802835144275743, "Avg loss": 0.49622743856161833, "Avg value loss": 0.15240796451689675, "Avg policy loss": 0.34381947154179215, "Total num played games": 27794, "Total num trained steps": 55040, "Timestamp in ms": 1701451800337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9780207959842238, "Avg loss": 0.5733225129079074, "Avg value loss": 0.2233247288968414, "Avg policy loss": 0.3499977863393724, "Total num played games": 27890, "Total num trained steps": 55168, "Timestamp in ms": 1701451856425, "logtype": "training_step"}
{"Avg objective": 19.609375, "Games time in secs": 217.30010359734297, "Avg game time in secs": 3.1975424422853393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.58}, "Total num played games": 27904, "Total num trained steps": 55274, "Timestamp in ms": 1701451903794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758450653898378, "Avg loss": 0.5413282064255327, "Avg value loss": 0.19813541288021952, "Avg policy loss": 0.34319278958719224, "Total num played games": 27986, "Total num trained steps": 55296, "Timestamp in ms": 1701451913365, "logtype": "training_step"}
{"Total num played games": 27986, "Total num trained steps": 55381, "Timestamp in ms": 1701451967058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.33984375}
{"Avg objective": 20.28125, "Games time in secs": 67.627835592255, "Avg game time in secs": 2.8596819356025662, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.58}, "Total num played games": 28032, "Total num trained steps": 55391, "Timestamp in ms": 1701451971422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737891737891737, "Avg loss": 0.6521608142647892, "Avg value loss": 0.2914052463020198, "Avg policy loss": 0.36075557046569884, "Total num played games": 28080, "Total num trained steps": 55424, "Timestamp in ms": 1701451986113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783475783475784, "Avg loss": 0.53812431008555, "Avg value loss": 0.18136515287915245, "Avg policy loss": 0.3567591584287584, "Total num played games": 28080, "Total num trained steps": 55552, "Timestamp in ms": 1701452043776, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 119.4872147552669, "Avg game time in secs": 3.36320571914257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 28160, "Total num trained steps": 55659, "Timestamp in ms": 1701452090909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761499148211243, "Avg loss": 0.5173505856655538, "Avg value loss": 0.18398558750050142, "Avg policy loss": 0.3333649975247681, "Total num played games": 28176, "Total num trained steps": 55680, "Timestamp in ms": 1701452100878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9806927881885292, "Avg loss": 0.5203412531409413, "Avg value loss": 0.16367999144131318, "Avg policy loss": 0.35666125756688416, "Total num played games": 28176, "Total num trained steps": 55808, "Timestamp in ms": 1701452161511, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783546721369456, "Avg loss": 0.6052192857023329, "Avg value loss": 0.249971091048792, "Avg policy loss": 0.3552481911610812, "Total num played games": 28274, "Total num trained steps": 55936, "Timestamp in ms": 1701452219663, "logtype": "training_step"}
{"Total num played games": 28274, "Total num trained steps": 55981, "Timestamp in ms": 1701452254429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.22265625}
{"Avg objective": 21.0859375, "Games time in secs": 166.7725878432393, "Avg game time in secs": 2.9501823055179557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 28288, "Total num trained steps": 55986, "Timestamp in ms": 1701452257682, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976311336717428, "Avg loss": 0.6097317519597709, "Avg value loss": 0.2512911520898342, "Avg policy loss": 0.35844060010276735, "Total num played games": 28368, "Total num trained steps": 56064, "Timestamp in ms": 1701452294447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808234630569657, "Avg loss": 0.488223580410704, "Avg value loss": 0.1281412605312653, "Avg policy loss": 0.3600823183078319, "Total num played games": 28368, "Total num trained steps": 56192, "Timestamp in ms": 1701452354757, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 114.88828298076987, "Avg game time in secs": 2.919498290924821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 28416, "Total num trained steps": 56232, "Timestamp in ms": 1701452372570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786396852164136, "Avg loss": 0.6253739059902728, "Avg value loss": 0.255460248386953, "Avg policy loss": 0.36991365859284997, "Total num played games": 28464, "Total num trained steps": 56320, "Timestamp in ms": 1701452412604, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 88.10566657967865, "Avg game time in secs": 3.0870331558253383, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 28544, "Total num trained steps": 56428, "Timestamp in ms": 1701452460676, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764705882352942, "Avg loss": 0.5710498983971775, "Avg value loss": 0.2090130434371531, "Avg policy loss": 0.3620368563570082, "Total num played games": 28560, "Total num trained steps": 56448, "Timestamp in ms": 1701452469416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980952380952381, "Avg loss": 0.5474446786101907, "Avg value loss": 0.17551303643267602, "Avg policy loss": 0.3719316474162042, "Total num played games": 28560, "Total num trained steps": 56576, "Timestamp in ms": 1701452526789, "logtype": "training_step"}
{"Total num played games": 28560, "Total num trained steps": 56582, "Timestamp in ms": 1701452541639, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.15234375}
{"Ratio train steps to played games": 1.9789209185454038, "Avg loss": 0.6310675197746605, "Avg value loss": 0.2551778079359792, "Avg policy loss": 0.37588971317745745, "Total num played games": 28654, "Total num trained steps": 56704, "Timestamp in ms": 1701452598126, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 180.6481157708913, "Avg game time in secs": 3.0043490535899764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 28672, "Total num trained steps": 56802, "Timestamp in ms": 1701452641324, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767652173913044, "Avg loss": 0.6228088848292828, "Avg value loss": 0.25981425086501986, "Avg policy loss": 0.36299463431350887, "Total num played games": 28750, "Total num trained steps": 56832, "Timestamp in ms": 1701452655027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812173913043478, "Avg loss": 0.5246966760605574, "Avg value loss": 0.16069438634440303, "Avg policy loss": 0.36400229344144464, "Total num played games": 28750, "Total num trained steps": 56960, "Timestamp in ms": 1701452713230, "logtype": "training_step"}
{"Avg objective": 21.2578125, "Games time in secs": 88.6268155630678, "Avg game time in secs": 2.8090343630465213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 28800, "Total num trained steps": 56995, "Timestamp in ms": 1701452729951, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9790612216598489, "Avg loss": 0.5815319586545229, "Avg value loss": 0.2208432318875566, "Avg policy loss": 0.3606887240894139, "Total num played games": 28846, "Total num trained steps": 57088, "Timestamp in ms": 1701452774078, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 91.82991455495358, "Avg game time in secs": 3.380297051524394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 28928, "Total num trained steps": 57182, "Timestamp in ms": 1701452821781, "logtype": "played_game"}
{"Total num played games": 28940, "Total num trained steps": 57182, "Timestamp in ms": 1701452832238, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3828125}
{"Ratio train steps to played games": 1.9706550940276917, "Avg loss": 0.6856673886068165, "Avg value loss": 0.3228679387248121, "Avg policy loss": 0.3627994426060468, "Total num played games": 29034, "Total num trained steps": 57216, "Timestamp in ms": 1701452848813, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9750292760212165, "Avg loss": 0.6085799848660827, "Avg value loss": 0.22236775676719844, "Avg policy loss": 0.3862122322898358, "Total num played games": 29034, "Total num trained steps": 57344, "Timestamp in ms": 1701452907602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979437900392643, "Avg loss": 0.476889600045979, "Avg value loss": 0.1206447739386931, "Avg policy loss": 0.3562448266893625, "Total num played games": 29034, "Total num trained steps": 57472, "Timestamp in ms": 1701452966167, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 183.07869854941964, "Avg game time in secs": 2.96490259753773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 29056, "Total num trained steps": 57561, "Timestamp in ms": 1701453004861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774787146388355, "Avg loss": 0.5495430673472583, "Avg value loss": 0.19312009267741814, "Avg policy loss": 0.3564229770563543, "Total num played games": 29128, "Total num trained steps": 57600, "Timestamp in ms": 1701453022625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818731117824773, "Avg loss": 0.5172929060645401, "Avg value loss": 0.15488389454549178, "Avg policy loss": 0.36240901285782456, "Total num played games": 29128, "Total num trained steps": 57728, "Timestamp in ms": 1701453082272, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 87.74802425131202, "Avg game time in secs": 2.7535836817114614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 29184, "Total num trained steps": 57752, "Timestamp in ms": 1701453092609, "logtype": "played_game"}
{"Total num played games": 29224, "Total num trained steps": 57784, "Timestamp in ms": 1701453121413, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3828125}
{"Avg objective": 19.6640625, "Games time in secs": 35.317924816161394, "Avg game time in secs": 2.8064625068509486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 29312, "Total num trained steps": 57798, "Timestamp in ms": 1701453127927, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9733951838461015, "Avg loss": 0.6988670204300433, "Avg value loss": 0.33903175735031255, "Avg policy loss": 0.35983526008203626, "Total num played games": 29318, "Total num trained steps": 57856, "Timestamp in ms": 1701453153922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777611023944335, "Avg loss": 0.5915121922735125, "Avg value loss": 0.24574431218206882, "Avg policy loss": 0.3457678793929517, "Total num played games": 29318, "Total num trained steps": 57984, "Timestamp in ms": 1701453212275, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821270209427655, "Avg loss": 0.48178470763377845, "Avg value loss": 0.14581972593441606, "Avg policy loss": 0.3359649827471003, "Total num played games": 29318, "Total num trained steps": 58112, "Timestamp in ms": 1701453269408, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798748980146859, "Avg loss": 0.6001895216759294, "Avg value loss": 0.24869884049985558, "Avg policy loss": 0.35149067896418273, "Total num played games": 29416, "Total num trained steps": 58240, "Timestamp in ms": 1701453326829, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 236.61445095017552, "Avg game time in secs": 2.6611075754481135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 29440, "Total num trained steps": 58326, "Timestamp in ms": 1701453364541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777717538628354, "Avg loss": 0.5288792012725025, "Avg value loss": 0.18318136793095618, "Avg policy loss": 0.34569783660117537, "Total num played games": 29512, "Total num trained steps": 58368, "Timestamp in ms": 1701453383707, "logtype": "training_step"}
{"Total num played games": 29512, "Total num trained steps": 58387, "Timestamp in ms": 1701453407623, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.27734375}
{"Avg objective": 21.234375, "Games time in secs": 47.31891441717744, "Avg game time in secs": 2.549939810851356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 29568, "Total num trained steps": 58394, "Timestamp in ms": 1701453411860, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758157130311422, "Avg loss": 0.6153993546031415, "Avg value loss": 0.2512570655089803, "Avg policy loss": 0.36414229311048985, "Total num played games": 29606, "Total num trained steps": 58496, "Timestamp in ms": 1701453457831, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801391609808823, "Avg loss": 0.4509221874177456, "Avg value loss": 0.11527978407684714, "Avg policy loss": 0.33564240380655974, "Total num played games": 29606, "Total num trained steps": 58624, "Timestamp in ms": 1701453517057, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 145.45623228512704, "Avg game time in secs": 3.241133261457435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 29696, "Total num trained steps": 58713, "Timestamp in ms": 1701453557317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780486162547977, "Avg loss": 0.5022977681364864, "Avg value loss": 0.17333653941750526, "Avg policy loss": 0.3289612296503037, "Total num played games": 29702, "Total num trained steps": 58752, "Timestamp in ms": 1701453575809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823580903642852, "Avg loss": 0.44806476798839867, "Avg value loss": 0.12498358526499942, "Avg policy loss": 0.3230811805697158, "Total num played games": 29702, "Total num trained steps": 58880, "Timestamp in ms": 1701453632458, "logtype": "training_step"}
{"Total num played games": 29798, "Total num trained steps": 58990, "Timestamp in ms": 1701453695433, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3046875}
{"Avg objective": 20.796875, "Games time in secs": 141.8141979407519, "Avg game time in secs": 2.7498193641367834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 29824, "Total num trained steps": 58997, "Timestamp in ms": 1701453699131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741719638675141, "Avg loss": 0.6009285699110478, "Avg value loss": 0.26405182864982635, "Avg policy loss": 0.33687673893291503, "Total num played games": 29890, "Total num trained steps": 59008, "Timestamp in ms": 1701453703667, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783219590525893, "Avg loss": 0.5112145415041596, "Avg value loss": 0.1797870981390588, "Avg policy loss": 0.3314274449367076, "Total num played games": 29892, "Total num trained steps": 59136, "Timestamp in ms": 1701453762190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826040412150407, "Avg loss": 0.43361725471913815, "Avg value loss": 0.1115768343443051, "Avg policy loss": 0.32204042037483305, "Total num played games": 29892, "Total num trained steps": 59264, "Timestamp in ms": 1701453821168, "logtype": "training_step"}
{"Avg objective": 20.2578125, "Games time in secs": 129.4177007675171, "Avg game time in secs": 3.126135053083999, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 29952, "Total num trained steps": 59281, "Timestamp in ms": 1701453828549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803934644881627, "Avg loss": 0.563952469965443, "Avg value loss": 0.2376107761519961, "Avg policy loss": 0.32634170120581985, "Total num played games": 29990, "Total num trained steps": 59392, "Timestamp in ms": 1701453878606, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 89.5947797242552, "Avg game time in secs": 3.0771942634455627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.64}, "Total num played games": 30080, "Total num trained steps": 59481, "Timestamp in ms": 1701453918144, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783287907997076, "Avg loss": 0.5164142206776887, "Avg value loss": 0.19948541338089854, "Avg policy loss": 0.31692880764603615, "Total num played games": 30086, "Total num trained steps": 59520, "Timestamp in ms": 1701453935947, "logtype": "training_step"}
{"Total num played games": 30086, "Total num trained steps": 59593, "Timestamp in ms": 1701453984010, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.38671875}
{"Ratio train steps to played games": 1.9764082173624917, "Avg loss": 0.5766710257157683, "Avg value loss": 0.25004283589078113, "Avg policy loss": 0.32662819186225533, "Total num played games": 30180, "Total num trained steps": 59648, "Timestamp in ms": 1701454009445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980649436713055, "Avg loss": 0.450474860612303, "Avg value loss": 0.1327439248561859, "Avg policy loss": 0.31773093389347196, "Total num played games": 30180, "Total num trained steps": 59776, "Timestamp in ms": 1701454066033, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 183.75163964368403, "Avg game time in secs": 2.725229891453637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.51, "agent_stopped_0": 0.57}, "Total num played games": 30208, "Total num trained steps": 59853, "Timestamp in ms": 1701454101896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978466213092014, "Avg loss": 0.5337714210618287, "Avg value loss": 0.21367568365531042, "Avg policy loss": 0.3200957396766171, "Total num played games": 30278, "Total num trained steps": 59904, "Timestamp in ms": 1701454125619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826937050003304, "Avg loss": 0.46842547599226236, "Avg value loss": 0.1477115147281438, "Avg policy loss": 0.32071396382525563, "Total num played games": 30278, "Total num trained steps": 60032, "Timestamp in ms": 1701454183534, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 90.33837625943124, "Avg game time in secs": 2.6432661934086354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 30336, "Total num trained steps": 60053, "Timestamp in ms": 1701454192234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806413379864358, "Avg loss": 0.5201089507900178, "Avg value loss": 0.19873433950124308, "Avg policy loss": 0.32137461425736547, "Total num played games": 30374, "Total num trained steps": 60160, "Timestamp in ms": 1701454240577, "logtype": "training_step"}
{"Total num played games": 30374, "Total num trained steps": 60196, "Timestamp in ms": 1701454269546, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.46875}
{"Avg objective": 19.65625, "Games time in secs": 83.35935691557825, "Avg game time in secs": 2.896945629065158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 30464, "Total num trained steps": 60207, "Timestamp in ms": 1701454275594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978731784166995, "Avg loss": 0.5652725442778319, "Avg value loss": 0.24512839829549193, "Avg policy loss": 0.320144145633094, "Total num played games": 30468, "Total num trained steps": 60288, "Timestamp in ms": 1701454312607, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982932913220428, "Avg loss": 0.4782827158924192, "Avg value loss": 0.17328201764030382, "Avg policy loss": 0.3050006969133392, "Total num played games": 30468, "Total num trained steps": 60416, "Timestamp in ms": 1701454369896, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808925533307158, "Avg loss": 0.5837054699659348, "Avg value loss": 0.2651249612099491, "Avg policy loss": 0.3185805093962699, "Total num played games": 30564, "Total num trained steps": 60544, "Timestamp in ms": 1701454426125, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 184.23906110599637, "Avg game time in secs": 2.500361023572623, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 30592, "Total num trained steps": 60622, "Timestamp in ms": 1701454459833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788649706457926, "Avg loss": 0.5552979146596044, "Avg value loss": 0.24012428557034582, "Avg policy loss": 0.3151736257132143, "Total num played games": 30660, "Total num trained steps": 60672, "Timestamp in ms": 1701454482222, "logtype": "training_step"}
{"Total num played games": 30660, "Total num trained steps": 60796, "Timestamp in ms": 1701454551685, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.7734375}
{"Ratio train steps to played games": 1.9823932181284643, "Avg loss": 0.4440403813496232, "Avg value loss": 0.13322548306314275, "Avg policy loss": 0.31081489846110344, "Total num played games": 30670, "Total num trained steps": 60800, "Timestamp in ms": 1701454554320, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 95.90916245616972, "Avg game time in secs": 2.7110031471966067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 30720, "Total num trained steps": 60803, "Timestamp in ms": 1701454555742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811406646289913, "Avg loss": 0.5446311826817691, "Avg value loss": 0.21688698971411213, "Avg policy loss": 0.32774419779889286, "Total num played games": 30754, "Total num trained steps": 60928, "Timestamp in ms": 1701454613987, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 93.77443678118289, "Avg game time in secs": 2.982659536690335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 30848, "Total num trained steps": 61008, "Timestamp in ms": 1701454649517, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791247974068071, "Avg loss": 0.6255000892560929, "Avg value loss": 0.30264639237429947, "Avg policy loss": 0.322853697813116, "Total num played games": 30850, "Total num trained steps": 61056, "Timestamp in ms": 1701454669862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832739059967586, "Avg loss": 0.45410023839212954, "Avg value loss": 0.13698528340319172, "Avg policy loss": 0.31711495702620596, "Total num played games": 30850, "Total num trained steps": 61184, "Timestamp in ms": 1701454727196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813857290589452, "Avg loss": 0.5316715694498271, "Avg value loss": 0.20440390560543165, "Avg policy loss": 0.32726766797713935, "Total num played games": 30944, "Total num trained steps": 61312, "Timestamp in ms": 1701454785073, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 166.5730404984206, "Avg game time in secs": 2.418778402468888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 30976, "Total num trained steps": 61382, "Timestamp in ms": 1701454816090, "logtype": "played_game"}
{"Total num played games": 31040, "Total num trained steps": 61397, "Timestamp in ms": 1701454836770, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9765625}
{"Avg objective": 20.1015625, "Games time in secs": 24.954208496958017, "Avg game time in secs": 2.561604805086972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 31104, "Total num trained steps": 61404, "Timestamp in ms": 1701454841045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973405280400848, "Avg loss": 0.5996768679469824, "Avg value loss": 0.279587048542453, "Avg policy loss": 0.32008981751278043, "Total num played games": 31134, "Total num trained steps": 61440, "Timestamp in ms": 1701454858057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977484422175114, "Avg loss": 0.4751885293517262, "Avg value loss": 0.15361641545314342, "Avg policy loss": 0.32157211482990533, "Total num played games": 31134, "Total num trained steps": 61568, "Timestamp in ms": 1701454915945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816278024025182, "Avg loss": 0.4104435071349144, "Avg value loss": 0.10487056581769139, "Avg policy loss": 0.30557294201571494, "Total num played games": 31134, "Total num trained steps": 61696, "Timestamp in ms": 1701454972903, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797617522736006, "Avg loss": 0.5107482969760895, "Avg value loss": 0.19553802252630703, "Avg policy loss": 0.31521027418784797, "Total num played games": 31228, "Total num trained steps": 61824, "Timestamp in ms": 1701455030997, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 245.05572560988367, "Avg game time in secs": 3.0290573941747425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 31232, "Total num trained steps": 61948, "Timestamp in ms": 1701455086101, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801828293805537, "Avg loss": 0.44508113362826407, "Avg value loss": 0.13494059382355772, "Avg policy loss": 0.31014054105617106, "Total num played games": 31286, "Total num trained steps": 61952, "Timestamp in ms": 1701455087661, "logtype": "training_step"}
{"Total num played games": 31324, "Total num trained steps": 61999, "Timestamp in ms": 1701455121446, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.53125}
{"Avg objective": 20.234375, "Games time in secs": 38.703998260200024, "Avg game time in secs": 2.624471099639777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.42}, "Total num played games": 31360, "Total num trained steps": 62006, "Timestamp in ms": 1701455124805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9759373607486155, "Avg loss": 0.6132567634340376, "Avg value loss": 0.276766215916723, "Avg policy loss": 0.33649055287241936, "Total num played games": 31418, "Total num trained steps": 62080, "Timestamp in ms": 1701455159857, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800114583996435, "Avg loss": 0.4909887972753495, "Avg value loss": 0.1691089541418478, "Avg policy loss": 0.32187984068877995, "Total num played games": 31418, "Total num trained steps": 62208, "Timestamp in ms": 1701455217755, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 151.5200283266604, "Avg game time in secs": 2.5777061898843385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 31488, "Total num trained steps": 62332, "Timestamp in ms": 1701455276325, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786376333164042, "Avg loss": 0.45182330906391144, "Avg value loss": 0.1316063195699826, "Avg policy loss": 0.3202169928699732, "Total num played games": 31504, "Total num trained steps": 62336, "Timestamp in ms": 1701455277879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821031922320238, "Avg loss": 0.5425440184772015, "Avg value loss": 0.2199180977186188, "Avg policy loss": 0.32262592460028827, "Total num played games": 31514, "Total num trained steps": 62464, "Timestamp in ms": 1701455339844, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802581624905087, "Avg loss": 0.5147196566686034, "Avg value loss": 0.20032044799881987, "Avg policy loss": 0.31439920724369586, "Total num played games": 31608, "Total num trained steps": 62592, "Timestamp in ms": 1701455397530, "logtype": "training_step"}
{"Total num played games": 31608, "Total num trained steps": 62599, "Timestamp in ms": 1701455431350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.71875}
{"Avg objective": 21.125, "Games time in secs": 157.25327681936324, "Avg game time in secs": 2.7855369503377005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 31616, "Total num trained steps": 62603, "Timestamp in ms": 1701455433578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9784240741909027, "Avg loss": 0.5332101895473897, "Avg value loss": 0.20449161110445857, "Avg policy loss": 0.3287185779772699, "Total num played games": 31702, "Total num trained steps": 62720, "Timestamp in ms": 1701455484787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824616743423127, "Avg loss": 0.4305032631382346, "Avg value loss": 0.12381827417993918, "Avg policy loss": 0.3066849894821644, "Total num played games": 31702, "Total num trained steps": 62848, "Timestamp in ms": 1701455542085, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 132.07064786739647, "Avg game time in secs": 2.348451730023953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 31744, "Total num trained steps": 62899, "Timestamp in ms": 1701455565649, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806264938986036, "Avg loss": 0.5503430715762079, "Avg value loss": 0.22827320330543444, "Avg policy loss": 0.3220698689110577, "Total num played games": 31796, "Total num trained steps": 62976, "Timestamp in ms": 1701455600384, "logtype": "training_step"}
{"Avg objective": 19.859375, "Games time in secs": 85.53040446527302, "Avg game time in secs": 2.6320320305094356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 31872, "Total num trained steps": 63090, "Timestamp in ms": 1701455651180, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786466825536184, "Avg loss": 0.4576958315446973, "Avg value loss": 0.14796057355124503, "Avg policy loss": 0.30973525787703693, "Total num played games": 31892, "Total num trained steps": 63104, "Timestamp in ms": 1701455656879, "logtype": "training_step"}
{"Total num played games": 31892, "Total num trained steps": 63201, "Timestamp in ms": 1701455713511, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.48828125}
{"Ratio train steps to played games": 1.976833614706434, "Avg loss": 0.5382259807083756, "Avg value loss": 0.22065008315257728, "Avg policy loss": 0.31757589627522975, "Total num played games": 31986, "Total num trained steps": 63232, "Timestamp in ms": 1701455727857, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808353654723942, "Avg loss": 0.5016450008843094, "Avg value loss": 0.1779999315040186, "Avg policy loss": 0.3236450725235045, "Total num played games": 31986, "Total num trained steps": 63360, "Timestamp in ms": 1701455786329, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 181.2746696230024, "Avg game time in secs": 2.5653671833570115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 32000, "Total num trained steps": 63465, "Timestamp in ms": 1701455832455, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789289944517174, "Avg loss": 0.5051485865842551, "Avg value loss": 0.19277826193138026, "Avg policy loss": 0.31237032439094037, "Total num played games": 32082, "Total num trained steps": 63488, "Timestamp in ms": 1701455842217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982918770650209, "Avg loss": 0.46962089859880507, "Avg value loss": 0.1573804075596854, "Avg policy loss": 0.3122404945315793, "Total num played games": 32082, "Total num trained steps": 63616, "Timestamp in ms": 1701455898823, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 85.94688681699336, "Avg game time in secs": 2.4189556462224573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.36}, "Total num played games": 32128, "Total num trained steps": 63660, "Timestamp in ms": 1701455918402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980980794331531, "Avg loss": 0.5312785124406219, "Avg value loss": 0.20722472306806594, "Avg policy loss": 0.3240537855308503, "Total num played games": 32178, "Total num trained steps": 63744, "Timestamp in ms": 1701455955046, "logtype": "training_step"}
{"Total num played games": 32178, "Total num trained steps": 63805, "Timestamp in ms": 1701455997441, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.91015625}
{"Avg objective": 20.609375, "Games time in secs": 83.95595793798566, "Avg game time in secs": 2.9135956019890727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 32256, "Total num trained steps": 63812, "Timestamp in ms": 1701456002358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791769955379277, "Avg loss": 0.5793198943138123, "Avg value loss": 0.26258972921641544, "Avg policy loss": 0.316730166436173, "Total num played games": 32272, "Total num trained steps": 63872, "Timestamp in ms": 1701456029000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983112295488349, "Avg loss": 0.45741739054210484, "Avg value loss": 0.14513290050672367, "Avg policy loss": 0.3122844905592501, "Total num played games": 32272, "Total num trained steps": 64000, "Timestamp in ms": 1701456086158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981216015818092, "Avg loss": 0.4753149801399559, "Avg value loss": 0.16325422361842357, "Avg policy loss": 0.3120607543969527, "Total num played games": 32368, "Total num trained steps": 64128, "Timestamp in ms": 1701456145434, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 188.06118663400412, "Avg game time in secs": 2.680194730113726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 32384, "Total num trained steps": 64229, "Timestamp in ms": 1701456190419, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793001478560868, "Avg loss": 0.48436490702442825, "Avg value loss": 0.17524108133511618, "Avg policy loss": 0.30912382679525763, "Total num played games": 32464, "Total num trained steps": 64256, "Timestamp in ms": 1701456202580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832429768358797, "Avg loss": 0.4522511512041092, "Avg value loss": 0.1337459264032077, "Avg policy loss": 0.31850522477179766, "Total num played games": 32464, "Total num trained steps": 64384, "Timestamp in ms": 1701456259723, "logtype": "training_step"}
{"Total num played games": 32464, "Total num trained steps": 64407, "Timestamp in ms": 1701456283956, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.85546875}
{"Avg objective": 20.7421875, "Games time in secs": 97.30781347863376, "Avg game time in secs": 2.492713014493347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 32512, "Total num trained steps": 64414, "Timestamp in ms": 1701456287727, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814484919221083, "Avg loss": 0.5413908699993044, "Avg value loss": 0.23241677990881726, "Avg policy loss": 0.3089740911964327, "Total num played games": 32558, "Total num trained steps": 64512, "Timestamp in ms": 1701456333208, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 92.16336800903082, "Avg game time in secs": 2.5809474679408595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 32640, "Total num trained steps": 64614, "Timestamp in ms": 1701456379891, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795430881362162, "Avg loss": 0.4670204084832221, "Avg value loss": 0.15161899360828102, "Avg policy loss": 0.31540141673758626, "Total num played games": 32654, "Total num trained steps": 64640, "Timestamp in ms": 1701456391383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834323513198995, "Avg loss": 0.43186254892498255, "Avg value loss": 0.12072091159643605, "Avg policy loss": 0.3111416375031695, "Total num played games": 32654, "Total num trained steps": 64768, "Timestamp in ms": 1701456448519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981557251908397, "Avg loss": 0.5594833323266357, "Avg value loss": 0.24858028968446888, "Avg policy loss": 0.3109030444175005, "Total num played games": 32750, "Total num trained steps": 64896, "Timestamp in ms": 1701456504085, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 169.53021031431854, "Avg game time in secs": 2.4471184994181385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 32768, "Total num trained steps": 64993, "Timestamp in ms": 1701456549421, "logtype": "played_game"}
{"Total num played games": 32846, "Total num trained steps": 65010, "Timestamp in ms": 1701456571747, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.546875}
{"Avg objective": 20.6875, "Games time in secs": 25.86010072939098, "Avg game time in secs": 2.382047333056107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 32896, "Total num trained steps": 65017, "Timestamp in ms": 1701456575281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9743729884010446, "Avg loss": 0.48162879631854594, "Avg value loss": 0.18425874167587608, "Avg policy loss": 0.297370053245686, "Total num played games": 32934, "Total num trained steps": 65024, "Timestamp in ms": 1701456578020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977899210686096, "Avg loss": 0.5608681261073798, "Avg value loss": 0.23848277289653197, "Avg policy loss": 0.32238534942734987, "Total num played games": 32940, "Total num trained steps": 65152, "Timestamp in ms": 1701456637872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981785063752277, "Avg loss": 0.45374732557684183, "Avg value loss": 0.1598586766049266, "Avg policy loss": 0.29388865013606846, "Total num played games": 32940, "Total num trained steps": 65280, "Timestamp in ms": 1701456695745, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 164.04239165782928, "Avg game time in secs": 2.7760297838103725, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 33024, "Total num trained steps": 65378, "Timestamp in ms": 1701456739324, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800205848519707, "Avg loss": 0.4649258682038635, "Avg value loss": 0.17198140011169016, "Avg policy loss": 0.2929444693727419, "Total num played games": 33034, "Total num trained steps": 65408, "Timestamp in ms": 1701456753619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983895380517043, "Avg loss": 0.41858524014241993, "Avg value loss": 0.10831975712790154, "Avg policy loss": 0.3102654835674912, "Total num played games": 33034, "Total num trained steps": 65536, "Timestamp in ms": 1701456810514, "logtype": "training_step"}
{"Total num played games": 33130, "Total num trained steps": 65615, "Timestamp in ms": 1701456859195, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8359375}
{"Avg objective": 20.640625, "Games time in secs": 122.81576151028275, "Avg game time in secs": 2.6137629758304683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 33152, "Total num trained steps": 65621, "Timestamp in ms": 1701456862140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764026005297375, "Avg loss": 0.6378770228475332, "Avg value loss": 0.31861957104410976, "Avg policy loss": 0.31925745215266943, "Total num played games": 33224, "Total num trained steps": 65664, "Timestamp in ms": 1701456881097, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802552371779436, "Avg loss": 0.4624175128992647, "Avg value loss": 0.13364305073628202, "Avg policy loss": 0.3287744636181742, "Total num played games": 33224, "Total num trained steps": 65792, "Timestamp in ms": 1701456939347, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841078738261497, "Avg loss": 0.41162811825051904, "Avg value loss": 0.1026766519935336, "Avg policy loss": 0.308951468905434, "Total num played games": 33224, "Total num trained steps": 65920, "Timestamp in ms": 1701456995383, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 143.1089998073876, "Avg game time in secs": 2.3196980618376983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 33280, "Total num trained steps": 65942, "Timestamp in ms": 1701457005249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822328931572628, "Avg loss": 0.5009771923068911, "Avg value loss": 0.18425134135759436, "Avg policy loss": 0.31672585348133, "Total num played games": 33320, "Total num trained steps": 66048, "Timestamp in ms": 1701457052718, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 87.44917546026409, "Avg game time in secs": 2.4767100663739257, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 33408, "Total num trained steps": 66138, "Timestamp in ms": 1701457092698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803686856595644, "Avg loss": 0.4877828338649124, "Avg value loss": 0.18593959775171243, "Avg policy loss": 0.30184323294088244, "Total num played games": 33416, "Total num trained steps": 66176, "Timestamp in ms": 1701457110365, "logtype": "training_step"}
{"Total num played games": 33416, "Total num trained steps": 66216, "Timestamp in ms": 1701457141373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.515625}
{"Ratio train steps to played games": 1.9786332438078185, "Avg loss": 0.5726580102927983, "Avg value loss": 0.2532520603854209, "Avg policy loss": 0.3194059474626556, "Total num played games": 33510, "Total num trained steps": 66304, "Timestamp in ms": 1701457182015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824529991047448, "Avg loss": 0.41419416200369596, "Avg value loss": 0.10412537620868534, "Avg policy loss": 0.3100687877740711, "Total num played games": 33510, "Total num trained steps": 66432, "Timestamp in ms": 1701457238688, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 181.15483958087862, "Avg game time in secs": 2.4625873377372045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 33536, "Total num trained steps": 66513, "Timestamp in ms": 1701457273853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805987026126286, "Avg loss": 0.526930421590805, "Avg value loss": 0.21573872151202522, "Avg policy loss": 0.31119170086458325, "Total num played games": 33606, "Total num trained steps": 66560, "Timestamp in ms": 1701457294334, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844075462714992, "Avg loss": 0.4350894312374294, "Avg value loss": 0.1215679275628645, "Avg policy loss": 0.3135215020738542, "Total num played games": 33606, "Total num trained steps": 66688, "Timestamp in ms": 1701457352240, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 87.0385545566678, "Avg game time in secs": 2.372502865284332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 33664, "Total num trained steps": 66707, "Timestamp in ms": 1701457360892, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826706231454005, "Avg loss": 0.5217141306493431, "Avg value loss": 0.20682921700063162, "Avg policy loss": 0.3148849162971601, "Total num played games": 33700, "Total num trained steps": 66816, "Timestamp in ms": 1701457409853, "logtype": "training_step"}
{"Total num played games": 33700, "Total num trained steps": 66817, "Timestamp in ms": 1701457423796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.59765625}
{"Avg objective": 20.1015625, "Games time in secs": 68.277203341946, "Avg game time in secs": 2.762883430972579, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.71}, "Total num played games": 33792, "Total num trained steps": 66828, "Timestamp in ms": 1701457429169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9809433627271114, "Avg loss": 0.5375933584291488, "Avg value loss": 0.2025707418215461, "Avg policy loss": 0.33502261620014906, "Total num played games": 33794, "Total num trained steps": 66944, "Timestamp in ms": 1701457482250, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847310173403563, "Avg loss": 0.4056267763953656, "Avg value loss": 0.08537640495342202, "Avg policy loss": 0.320250372053124, "Total num played games": 33794, "Total num trained steps": 67072, "Timestamp in ms": 1701457540253, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828858070227207, "Avg loss": 0.5082727132830769, "Avg value loss": 0.19133916625287384, "Avg policy loss": 0.3169335483107716, "Total num played games": 33890, "Total num trained steps": 67200, "Timestamp in ms": 1701457596616, "logtype": "training_step"}
{"Avg objective": 19.6953125, "Games time in secs": 201.1602695696056, "Avg game time in secs": 2.1428060063626617, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.32, "agent_stopped_0": 0.71}, "Total num played games": 33920, "Total num trained steps": 67273, "Timestamp in ms": 1701457630330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810510210086507, "Avg loss": 0.47578757884912193, "Avg value loss": 0.1585578169033397, "Avg policy loss": 0.3172297615092248, "Total num played games": 33986, "Total num trained steps": 67328, "Timestamp in ms": 1701457654888, "logtype": "training_step"}
{"Total num played games": 33986, "Total num trained steps": 67421, "Timestamp in ms": 1701457710528, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.7890625}
{"Avg objective": 20.2109375, "Games time in secs": 83.84276916831732, "Avg game time in secs": 2.237453870475292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 34048, "Total num trained steps": 67428, "Timestamp in ms": 1701457714174, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979342723004695, "Avg loss": 0.4842181499116123, "Avg value loss": 0.16610304257483222, "Avg policy loss": 0.31811510981060565, "Total num played games": 34080, "Total num trained steps": 67456, "Timestamp in ms": 1701457725960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830985915492958, "Avg loss": 0.4420335434842855, "Avg value loss": 0.11731895140837878, "Avg policy loss": 0.324714592192322, "Total num played games": 34080, "Total num trained steps": 67584, "Timestamp in ms": 1701457782679, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 102.947559973225, "Avg game time in secs": 2.4583142047777073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 34176, "Total num trained steps": 67664, "Timestamp in ms": 1701457817121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981157469717362, "Avg loss": 0.5003978936001658, "Avg value loss": 0.18191578690311871, "Avg policy loss": 0.3184821057366207, "Total num played games": 34178, "Total num trained steps": 67712, "Timestamp in ms": 1701457837297, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849025689039732, "Avg loss": 0.43463170854374766, "Avg value loss": 0.11016366648254916, "Avg policy loss": 0.3244680459611118, "Total num played games": 34178, "Total num trained steps": 67840, "Timestamp in ms": 1701457894390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830775514967613, "Avg loss": 0.5005257520824671, "Avg value loss": 0.16996240019216202, "Avg policy loss": 0.33056334871798754, "Total num played games": 34274, "Total num trained steps": 67968, "Timestamp in ms": 1701457950753, "logtype": "training_step"}
{"Total num played games": 34274, "Total num trained steps": 68024, "Timestamp in ms": 1701457990954, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.69921875}
{"Avg objective": 20.3671875, "Games time in secs": 176.7762625850737, "Avg game time in secs": 2.188502099044854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 34304, "Total num trained steps": 68029, "Timestamp in ms": 1701457993898, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813780260707634, "Avg loss": 0.516945050098002, "Avg value loss": 0.18803118157666177, "Avg policy loss": 0.3289138685213402, "Total num played games": 34368, "Total num trained steps": 68096, "Timestamp in ms": 1701458023935, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851024208566108, "Avg loss": 0.44432656234130263, "Avg value loss": 0.11845422690385021, "Avg policy loss": 0.32587233395315707, "Total num played games": 34368, "Total num trained steps": 68224, "Timestamp in ms": 1701458083604, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 92.72092735953629, "Avg game time in secs": 2.1799312889343128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.38}, "Total num played games": 34432, "Total num trained steps": 68231, "Timestamp in ms": 1701458086619, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834020080088213, "Avg loss": 0.5284881626721472, "Avg value loss": 0.20113209693226963, "Avg policy loss": 0.3273560660891235, "Total num played games": 34462, "Total num trained steps": 68352, "Timestamp in ms": 1701458141521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817108461627504, "Avg loss": 0.566099944524467, "Avg value loss": 0.23459977837046608, "Avg policy loss": 0.3315001626033336, "Total num played games": 34556, "Total num trained steps": 68480, "Timestamp in ms": 1701458198389, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 167.55328726954758, "Avg game time in secs": 2.6076067057583714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 34560, "Total num trained steps": 68603, "Timestamp in ms": 1701458254172, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816301773438854, "Avg loss": 0.44173212675377727, "Avg value loss": 0.10492217101273127, "Avg policy loss": 0.3368099567014724, "Total num played games": 34620, "Total num trained steps": 68608, "Timestamp in ms": 1701458255981, "logtype": "training_step"}
{"Total num played games": 34650, "Total num trained steps": 68625, "Timestamp in ms": 1701458278702, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.99609375}
{"Avg objective": 19.609375, "Games time in secs": 27.60671362094581, "Avg game time in secs": 2.4228728983580368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 34688, "Total num trained steps": 68630, "Timestamp in ms": 1701458281779, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978355975132397, "Avg loss": 0.6578005694318563, "Avg value loss": 0.2963633634499274, "Avg policy loss": 0.36143720895051956, "Total num played games": 34744, "Total num trained steps": 68736, "Timestamp in ms": 1701458329657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820400644715634, "Avg loss": 0.42036536103114486, "Avg value loss": 0.08370290551101789, "Avg policy loss": 0.336662451736629, "Total num played games": 34744, "Total num trained steps": 68864, "Timestamp in ms": 1701458386102, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 157.58014255948365, "Avg game time in secs": 2.225473755694111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 34816, "Total num trained steps": 68984, "Timestamp in ms": 1701458439359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802525832376578, "Avg loss": 0.45671813003718853, "Avg value loss": 0.13555670590722002, "Avg policy loss": 0.3211614217143506, "Total num played games": 34840, "Total num trained steps": 68992, "Timestamp in ms": 1701458442662, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839265212399542, "Avg loss": 0.4592047699261457, "Avg value loss": 0.12562514308956452, "Avg policy loss": 0.33357962605077773, "Total num played games": 34840, "Total num trained steps": 69120, "Timestamp in ms": 1701458499887, "logtype": "training_step"}
{"Total num played games": 34938, "Total num trained steps": 69228, "Timestamp in ms": 1701458563295, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.59765625}
{"Avg objective": 20.015625, "Games time in secs": 126.27334753237665, "Avg game time in secs": 2.4840326740813907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.49, "agent_stopped_0": 0.53}, "Total num played games": 34944, "Total num trained steps": 69231, "Timestamp in ms": 1701458565633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976707010733044, "Avg loss": 0.5391609657090157, "Avg value loss": 0.20547449323930778, "Avg policy loss": 0.33368647017050534, "Total num played games": 35032, "Total num trained steps": 69248, "Timestamp in ms": 1701458572785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980360812970998, "Avg loss": 0.4968612384982407, "Avg value loss": 0.16974930342985317, "Avg policy loss": 0.3271119361743331, "Total num played games": 35032, "Total num trained steps": 69376, "Timestamp in ms": 1701458630042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840146152089517, "Avg loss": 0.38404074066784233, "Avg value loss": 0.07808321813354269, "Avg policy loss": 0.305957522476092, "Total num played games": 35032, "Total num trained steps": 69504, "Timestamp in ms": 1701458685306, "logtype": "training_step"}
{"Avg objective": 20.1796875, "Games time in secs": 143.16432134062052, "Avg game time in secs": 2.326820412912639, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 35072, "Total num trained steps": 69558, "Timestamp in ms": 1701458708797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822363926212707, "Avg loss": 0.4920817008242011, "Avg value loss": 0.17618233954999596, "Avg policy loss": 0.3158993610413745, "Total num played games": 35128, "Total num trained steps": 69632, "Timestamp in ms": 1701458741044, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 87.6194883659482, "Avg game time in secs": 2.4371445887809386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 35200, "Total num trained steps": 69751, "Timestamp in ms": 1701458796417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805803191187326, "Avg loss": 0.4257780361222103, "Avg value loss": 0.1179570697422605, "Avg policy loss": 0.30782096460461617, "Total num played games": 35222, "Total num trained steps": 69760, "Timestamp in ms": 1701458800818, "logtype": "training_step"}
{"Total num played games": 35222, "Total num trained steps": 69830, "Timestamp in ms": 1701458845505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.4296875}
{"Ratio train steps to played games": 1.9789330615018688, "Avg loss": 0.5599662908352911, "Avg value loss": 0.23815980297513306, "Avg policy loss": 0.3218064868124202, "Total num played games": 35316, "Total num trained steps": 69888, "Timestamp in ms": 1701458875250, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982557481028429, "Avg loss": 0.411377634620294, "Avg value loss": 0.11536401463672519, "Avg policy loss": 0.2960136232431978, "Total num played games": 35316, "Total num trained steps": 70016, "Timestamp in ms": 1701458933287, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 186.96988288126886, "Avg game time in secs": 2.5367683461663546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 35328, "Total num trained steps": 70124, "Timestamp in ms": 1701458983387, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980909347641909, "Avg loss": 0.42691964586265385, "Avg value loss": 0.13730527588631958, "Avg policy loss": 0.2896143707912415, "Total num played games": 35410, "Total num trained steps": 70144, "Timestamp in ms": 1701458992656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845241457215477, "Avg loss": 0.4384895423427224, "Avg value loss": 0.13418516030651517, "Avg policy loss": 0.3043043817160651, "Total num played games": 35410, "Total num trained steps": 70272, "Timestamp in ms": 1701459050821, "logtype": "training_step"}
{"Avg objective": 20.5, "Games time in secs": 85.60656703822315, "Avg game time in secs": 2.199309800605988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 35456, "Total num trained steps": 70314, "Timestamp in ms": 1701459068994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982763476595505, "Avg loss": 0.4547021046746522, "Avg value loss": 0.16172015861957334, "Avg policy loss": 0.292981946724467, "Total num played games": 35506, "Total num trained steps": 70400, "Timestamp in ms": 1701459107697, "logtype": "training_step"}
{"Total num played games": 35506, "Total num trained steps": 70434, "Timestamp in ms": 1701459136484, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.02734375}
{"Avg objective": 20.484375, "Games time in secs": 72.45232579670846, "Avg game time in secs": 2.2999823245045263, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 35584, "Total num trained steps": 70443, "Timestamp in ms": 1701459141447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981123595505618, "Avg loss": 0.49777152528986335, "Avg value loss": 0.1938377305632457, "Avg policy loss": 0.30393379426095635, "Total num played games": 35600, "Total num trained steps": 70528, "Timestamp in ms": 1701459178544, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984691011235955, "Avg loss": 0.36771980044431984, "Avg value loss": 0.08159586577676237, "Avg policy loss": 0.2861239332705736, "Total num played games": 35600, "Total num trained steps": 70656, "Timestamp in ms": 1701459236513, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826340261049802, "Avg loss": 0.4767149309627712, "Avg value loss": 0.18393826333340257, "Avg policy loss": 0.29277667053975165, "Total num played games": 35702, "Total num trained steps": 70784, "Timestamp in ms": 1701459293615, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 201.67774713598192, "Avg game time in secs": 2.4607715295715025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.49, "agent_stopped_0": 0.57}, "Total num played games": 35712, "Total num trained steps": 70897, "Timestamp in ms": 1701459343126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9809755279919543, "Avg loss": 0.4180569925811142, "Avg value loss": 0.1330556535976939, "Avg policy loss": 0.28500133799389005, "Total num played games": 35796, "Total num trained steps": 70912, "Timestamp in ms": 1701459349621, "logtype": "training_step"}
{"Total num played games": 35796, "Total num trained steps": 71034, "Timestamp in ms": 1701459414627, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.13671875}
{"Ratio train steps to played games": 1.9835539174624448, "Avg loss": 0.4319467630703002, "Avg value loss": 0.14224320123321377, "Avg policy loss": 0.2897035600617528, "Total num played games": 35814, "Total num trained steps": 71040, "Timestamp in ms": 1701459417446, "logtype": "training_step"}
{"Avg objective": 19.46875, "Games time in secs": 74.88762116990983, "Avg game time in secs": 2.2820669869397534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.34}, "Total num played games": 35840, "Total num trained steps": 71041, "Timestamp in ms": 1701459418013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829200334354973, "Avg loss": 0.46721068397164345, "Avg value loss": 0.18381644989131019, "Avg policy loss": 0.2833942341385409, "Total num played games": 35890, "Total num trained steps": 71168, "Timestamp in ms": 1701459475914, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 104.93141457810998, "Avg game time in secs": 2.3218124253035057, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 35968, "Total num trained steps": 71275, "Timestamp in ms": 1701459522945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812972432192086, "Avg loss": 0.39049576106481254, "Avg value loss": 0.11166622629389167, "Avg policy loss": 0.27882953512016684, "Total num played games": 35984, "Total num trained steps": 71296, "Timestamp in ms": 1701459531648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848821698532682, "Avg loss": 0.3932847052346915, "Avg value loss": 0.10783238304429688, "Avg policy loss": 0.2854523233836517, "Total num played games": 35984, "Total num trained steps": 71424, "Timestamp in ms": 1701459589573, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832584954820112, "Avg loss": 0.474762151716277, "Avg value loss": 0.18816895384225063, "Avg policy loss": 0.2865932004060596, "Total num played games": 36078, "Total num trained steps": 71552, "Timestamp in ms": 1701459649872, "logtype": "training_step"}
{"Total num played games": 36078, "Total num trained steps": 71638, "Timestamp in ms": 1701459700340, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.46484375}
{"Avg objective": 21.3828125, "Games time in secs": 180.23417400568724, "Avg game time in secs": 2.40071298807743, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 36096, "Total num trained steps": 71643, "Timestamp in ms": 1701459703179, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981643259980095, "Avg loss": 0.47873778990469873, "Avg value loss": 0.198739646904869, "Avg policy loss": 0.27999814262147993, "Total num played games": 36172, "Total num trained steps": 71680, "Timestamp in ms": 1701459720190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851542629658299, "Avg loss": 0.4365266030654311, "Avg value loss": 0.15125998694566078, "Avg policy loss": 0.28526661510113627, "Total num played games": 36172, "Total num trained steps": 71808, "Timestamp in ms": 1701459778970, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 89.0959385316819, "Avg game time in secs": 2.2904552742111264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 36224, "Total num trained steps": 71839, "Timestamp in ms": 1701459792275, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834564905701997, "Avg loss": 0.4782732594758272, "Avg value loss": 0.18801628128858283, "Avg policy loss": 0.2902569805737585, "Total num played games": 36268, "Total num trained steps": 71936, "Timestamp in ms": 1701459837470, "logtype": "training_step"}
{"Avg objective": 20.0546875, "Games time in secs": 91.5274770911783, "Avg game time in secs": 2.2965620983595727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.42, "agent_stopped_0": 0.59}, "Total num played games": 36352, "Total num trained steps": 72030, "Timestamp in ms": 1701459883803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818491832132445, "Avg loss": 0.4217858307529241, "Avg value loss": 0.13223321965779178, "Avg policy loss": 0.2895526122301817, "Total num played games": 36362, "Total num trained steps": 72064, "Timestamp in ms": 1701459898234, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853418403828171, "Avg loss": 0.39409785042516887, "Avg value loss": 0.1151363747776486, "Avg policy loss": 0.2789614754728973, "Total num played games": 36362, "Total num trained steps": 72192, "Timestamp in ms": 1701459957819, "logtype": "training_step"}
{"Total num played games": 36458, "Total num trained steps": 72240, "Timestamp in ms": 1701459990956, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.20703125}
{"Avg objective": 21.7421875, "Games time in secs": 109.7330104727298, "Avg game time in secs": 2.185322250268655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.37}, "Total num played games": 36480, "Total num trained steps": 72244, "Timestamp in ms": 1701459993536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785511052746771, "Avg loss": 0.5440588227938861, "Avg value loss": 0.23810006919666193, "Avg policy loss": 0.3059587507741526, "Total num played games": 36552, "Total num trained steps": 72320, "Timestamp in ms": 1701460028776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820256073539069, "Avg loss": 0.3774537539575249, "Avg value loss": 0.0868471346620936, "Avg policy loss": 0.2906066196737811, "Total num played games": 36552, "Total num trained steps": 72448, "Timestamp in ms": 1701460088482, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855548260013132, "Avg loss": 0.36044920166023076, "Avg value loss": 0.07673103240085766, "Avg policy loss": 0.2837181683862582, "Total num played games": 36552, "Total num trained steps": 72576, "Timestamp in ms": 1701460148466, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 164.38800260052085, "Avg game time in secs": 2.1918771268829005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 36608, "Total num trained steps": 72598, "Timestamp in ms": 1701460157924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983846321763807, "Avg loss": 0.48862072662450373, "Avg value loss": 0.17947734572226182, "Avg policy loss": 0.30914337967988104, "Total num played games": 36648, "Total num trained steps": 72704, "Timestamp in ms": 1701460206928, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 89.01820812374353, "Avg game time in secs": 2.2428161789430305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.4, "agent_stopped_0": 0.61}, "Total num played games": 36736, "Total num trained steps": 72792, "Timestamp in ms": 1701460246943, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821467450468104, "Avg loss": 0.43208557553589344, "Avg value loss": 0.1414957826200407, "Avg policy loss": 0.2905897932359949, "Total num played games": 36744, "Total num trained steps": 72832, "Timestamp in ms": 1701460264693, "logtype": "training_step"}
{"Total num played games": 36744, "Total num trained steps": 72840, "Timestamp in ms": 1701460279620, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.875}
{"Ratio train steps to played games": 1.980563548509691, "Avg loss": 0.4860932899173349, "Avg value loss": 0.19031161174643785, "Avg policy loss": 0.29578167852014303, "Total num played games": 36838, "Total num trained steps": 72960, "Timestamp in ms": 1701460336037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840110755198437, "Avg loss": 0.35602478333748877, "Avg value loss": 0.07486964165582322, "Avg policy loss": 0.2811551394406706, "Total num played games": 36838, "Total num trained steps": 73088, "Timestamp in ms": 1701460396917, "logtype": "training_step"}
{"Avg objective": 19.6171875, "Games time in secs": 187.3388632554561, "Avg game time in secs": 2.2137544501019875, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0390625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.42, "agent_stopped_0": 0.61}, "Total num played games": 36864, "Total num trained steps": 73168, "Timestamp in ms": 1701460434282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982454240225279, "Avg loss": 0.4219480531755835, "Avg value loss": 0.14600350661203265, "Avg policy loss": 0.2759445437695831, "Total num played games": 36932, "Total num trained steps": 73216, "Timestamp in ms": 1701460456839, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859200693165817, "Avg loss": 0.3763026718515903, "Avg value loss": 0.09961742995074019, "Avg policy loss": 0.2766852475469932, "Total num played games": 36932, "Total num trained steps": 73344, "Timestamp in ms": 1701460521450, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 94.19690117612481, "Avg game time in secs": 2.1310979092668276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.39}, "Total num played games": 36992, "Total num trained steps": 73357, "Timestamp in ms": 1701460528479, "logtype": "played_game"}
{"Total num played games": 37028, "Total num trained steps": 73442, "Timestamp in ms": 1701460582876, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.265625}
{"Avg objective": 21.9765625, "Games time in secs": 59.191002609208226, "Avg game time in secs": 2.2866813978471328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.46}, "Total num played games": 37120, "Total num trained steps": 73451, "Timestamp in ms": 1701460587670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792037066968375, "Avg loss": 0.547591709997505, "Avg value loss": 0.25627274040016346, "Avg policy loss": 0.29131897061597556, "Total num played games": 37122, "Total num trained steps": 73472, "Timestamp in ms": 1701460597415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982651796778191, "Avg loss": 0.40820275084115565, "Avg value loss": 0.11516655728337355, "Avg policy loss": 0.2930361909093335, "Total num played games": 37122, "Total num trained steps": 73600, "Timestamp in ms": 1701460662474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860998868595443, "Avg loss": 0.35380403557792306, "Avg value loss": 0.07145974363083951, "Avg policy loss": 0.2823442901717499, "Total num played games": 37122, "Total num trained steps": 73728, "Timestamp in ms": 1701460725393, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845227858985384, "Avg loss": 0.5135577897308394, "Avg value loss": 0.2143756827863399, "Avg policy loss": 0.2991821067407727, "Total num played games": 37216, "Total num trained steps": 73856, "Timestamp in ms": 1701460788682, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 232.7837752494961, "Avg game time in secs": 2.000084968734882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.36, "agent_stopped_0": 0.66}, "Total num played games": 37248, "Total num trained steps": 73925, "Timestamp in ms": 1701460820454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828473413379073, "Avg loss": 0.4717621395830065, "Avg value loss": 0.17735884996363893, "Avg policy loss": 0.2944032916566357, "Total num played games": 37312, "Total num trained steps": 73984, "Timestamp in ms": 1701460852253, "logtype": "training_step"}
{"Total num played games": 37312, "Total num trained steps": 74042, "Timestamp in ms": 1701460894599, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.54296875}
{"Avg objective": 21.3203125, "Games time in secs": 77.9409254398197, "Avg game time in secs": 2.2464274109661346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 37376, "Total num trained steps": 74048, "Timestamp in ms": 1701460898395, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812864246377586, "Avg loss": 0.4927227539010346, "Avg value loss": 0.18601526430575177, "Avg policy loss": 0.30670749326236546, "Total num played games": 37406, "Total num trained steps": 74112, "Timestamp in ms": 1701460930398, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98470833556114, "Avg loss": 0.39764380524866283, "Avg value loss": 0.09452217200305313, "Avg policy loss": 0.30312163184862584, "Total num played games": 37406, "Total num trained steps": 74240, "Timestamp in ms": 1701460995625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983040904485094, "Avg loss": 0.4935628219973296, "Avg value loss": 0.18569303647382185, "Avg policy loss": 0.30786978523246944, "Total num played games": 37502, "Total num trained steps": 74368, "Timestamp in ms": 1701461062787, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 230.04319075122476, "Avg game time in secs": 2.4654959740437334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 37504, "Total num trained steps": 74493, "Timestamp in ms": 1701461128438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851569578425625, "Avg loss": 0.37283316208049655, "Avg value loss": 0.07589068287052214, "Avg policy loss": 0.29694248060695827, "Total num played games": 37520, "Total num trained steps": 74496, "Timestamp in ms": 1701461129795, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848920097882754, "Avg loss": 0.45445080986246467, "Avg value loss": 0.15449566685128957, "Avg policy loss": 0.29995514266192913, "Total num played games": 37596, "Total num trained steps": 74624, "Timestamp in ms": 1701461194913, "logtype": "training_step"}
{"Total num played games": 37596, "Total num trained steps": 74642, "Timestamp in ms": 1701461216273, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.7265625}
{"Avg objective": 20.4765625, "Games time in secs": 91.0315637178719, "Avg game time in secs": 2.1729507571435533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.34}, "Total num played games": 37632, "Total num trained steps": 74648, "Timestamp in ms": 1701461219470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983337755372778, "Avg loss": 0.4392464340198785, "Avg value loss": 0.14052991432254203, "Avg policy loss": 0.29871651995927095, "Total num played games": 37690, "Total num trained steps": 74752, "Timestamp in ms": 1701461273337, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 114.99502206780016, "Avg game time in secs": 2.3157169827318285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 37760, "Total num trained steps": 74876, "Timestamp in ms": 1701461334465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9817912343849249, "Avg loss": 0.3762952219694853, "Avg value loss": 0.08798653809935786, "Avg policy loss": 0.28830868436489254, "Total num played games": 37784, "Total num trained steps": 74880, "Timestamp in ms": 1701461336771, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851789117086598, "Avg loss": 0.4691000375896692, "Avg value loss": 0.16419216140639037, "Avg policy loss": 0.3049078762996942, "Total num played games": 37784, "Total num trained steps": 75008, "Timestamp in ms": 1701461402087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836316595385184, "Avg loss": 0.48978930176235735, "Avg value loss": 0.1809920609521214, "Avg policy loss": 0.30879724014084786, "Total num played games": 37878, "Total num trained steps": 75136, "Timestamp in ms": 1701461467601, "logtype": "training_step"}
{"Total num played games": 37878, "Total num trained steps": 75242, "Timestamp in ms": 1701461533455, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.59375}
{"Avg objective": 20.921875, "Games time in secs": 201.13535375893116, "Avg game time in secs": 2.366058556799544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 37888, "Total num trained steps": 75244, "Timestamp in ms": 1701461535601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820920678394607, "Avg loss": 0.4639832600951195, "Avg value loss": 0.16206586448242888, "Avg policy loss": 0.30191739345900714, "Total num played games": 37972, "Total num trained steps": 75264, "Timestamp in ms": 1701461546174, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854629727167386, "Avg loss": 0.4138975706882775, "Avg value loss": 0.12023730130749755, "Avg policy loss": 0.29366027109790593, "Total num played games": 37972, "Total num trained steps": 75392, "Timestamp in ms": 1701461610647, "logtype": "training_step"}
{"Avg objective": 19.984375, "Games time in secs": 100.3515569511801, "Avg game time in secs": 1.9292433585069375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.27}, "Total num played games": 38016, "Total num trained steps": 75437, "Timestamp in ms": 1701461635952, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839226606420428, "Avg loss": 0.4817701082210988, "Avg value loss": 0.18884186129434966, "Avg policy loss": 0.29292824724689126, "Total num played games": 38066, "Total num trained steps": 75520, "Timestamp in ms": 1701461677835, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 95.78907542303205, "Avg game time in secs": 2.296863607291016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.42, "agent_stopped_0": 0.62}, "Total num played games": 38144, "Total num trained steps": 75625, "Timestamp in ms": 1701461731741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823899371069182, "Avg loss": 0.4181513988878578, "Avg value loss": 0.13327708904398605, "Avg policy loss": 0.2848743130452931, "Total num played games": 38160, "Total num trained steps": 75648, "Timestamp in ms": 1701461743158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857442348008385, "Avg loss": 0.39621206535957754, "Avg value loss": 0.11178187996847555, "Avg policy loss": 0.2844301877776161, "Total num played games": 38160, "Total num trained steps": 75776, "Timestamp in ms": 1701461809962, "logtype": "training_step"}
{"Total num played games": 38254, "Total num trained steps": 75842, "Timestamp in ms": 1701461850975, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.48046875}
{"Avg objective": 20.203125, "Games time in secs": 121.86751244962215, "Avg game time in secs": 2.0636603485327214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.34}, "Total num played games": 38272, "Total num trained steps": 75847, "Timestamp in ms": 1701461853609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793470324397622, "Avg loss": 0.5600687622791156, "Avg value loss": 0.2779365537571721, "Avg policy loss": 0.2821322081144899, "Total num played games": 38348, "Total num trained steps": 75904, "Timestamp in ms": 1701461885940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982684885782831, "Avg loss": 0.36864328663796186, "Avg value loss": 0.1047742587106768, "Avg policy loss": 0.2638690291205421, "Total num played games": 38348, "Total num trained steps": 76032, "Timestamp in ms": 1701461952108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860227391258995, "Avg loss": 0.3279812923865393, "Avg value loss": 0.07501469759154133, "Avg policy loss": 0.25296659383457154, "Total num played games": 38348, "Total num trained steps": 76160, "Timestamp in ms": 1701462018233, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 179.6633593607694, "Avg game time in secs": 2.053587037458783, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.33}, "Total num played games": 38400, "Total num trained steps": 76190, "Timestamp in ms": 1701462033273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.42178170289844275, "Avg value loss": 0.15792331864940934, "Avg policy loss": 0.2638583815423772, "Total num played games": 38442, "Total num trained steps": 76288, "Timestamp in ms": 1701462083086, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 96.40470745973289, "Avg game time in secs": 2.15525652555516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 38528, "Total num trained steps": 76379, "Timestamp in ms": 1701462129677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828740463957653, "Avg loss": 0.4235101349186152, "Avg value loss": 0.16501621741917916, "Avg policy loss": 0.25849391578231007, "Total num played games": 38538, "Total num trained steps": 76416, "Timestamp in ms": 1701462147873, "logtype": "training_step"}
{"Total num played games": 38538, "Total num trained steps": 76444, "Timestamp in ms": 1701462171717, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3828125}
{"Ratio train steps to played games": 1.9813626009525782, "Avg loss": 0.4575557252392173, "Avg value loss": 0.19113621261203662, "Avg policy loss": 0.2664195115212351, "Total num played games": 38632, "Total num trained steps": 76544, "Timestamp in ms": 1701462224373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846759163387866, "Avg loss": 0.3193526854738593, "Avg value loss": 0.06832106719957665, "Avg policy loss": 0.25103161786682904, "Total num played games": 38632, "Total num trained steps": 76672, "Timestamp in ms": 1701462287483, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 199.12776048108935, "Avg game time in secs": 2.060191939366632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.39, "agent_stopped_0": 0.66}, "Total num played games": 38656, "Total num trained steps": 76757, "Timestamp in ms": 1701462328805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830613509605453, "Avg loss": 0.41337760782334954, "Avg value loss": 0.16057041269959882, "Avg policy loss": 0.2528071905253455, "Total num played games": 38728, "Total num trained steps": 76800, "Timestamp in ms": 1701462352446, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863664532121463, "Avg loss": 0.34504298586398363, "Avg value loss": 0.09748586887144484, "Avg policy loss": 0.24755711457692087, "Total num played games": 38728, "Total num trained steps": 76928, "Timestamp in ms": 1701462417117, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 99.7084900867194, "Avg game time in secs": 2.1244192935264437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.37}, "Total num played games": 38784, "Total num trained steps": 76950, "Timestamp in ms": 1701462428514, "logtype": "played_game"}
{"Total num played games": 38822, "Total num trained steps": 77047, "Timestamp in ms": 1701462487409, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.51171875}
{"Avg objective": 20.9375, "Games time in secs": 63.09263717755675, "Avg game time in secs": 2.0283520527300425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 38912, "Total num trained steps": 77054, "Timestamp in ms": 1701462491607, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800339192106076, "Avg loss": 0.4938521299045533, "Avg value loss": 0.24033968357252888, "Avg policy loss": 0.2535124422283843, "Total num played games": 38916, "Total num trained steps": 77056, "Timestamp in ms": 1701462492657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833487511563368, "Avg loss": 0.42732323554810137, "Avg value loss": 0.16623588613583706, "Avg policy loss": 0.26108734775334597, "Total num played games": 38916, "Total num trained steps": 77184, "Timestamp in ms": 1701462557136, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866378867303938, "Avg loss": 0.31715850508771837, "Avg value loss": 0.07106289401417598, "Avg policy loss": 0.24609560961835086, "Total num played games": 38916, "Total num trained steps": 77312, "Timestamp in ms": 1701462624038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851320174314278, "Avg loss": 0.41176602616906166, "Avg value loss": 0.16226692937198095, "Avg policy loss": 0.24949909711722285, "Total num played games": 39010, "Total num trained steps": 77440, "Timestamp in ms": 1701462690421, "logtype": "training_step"}
{"Avg objective": 19.5625, "Games time in secs": 237.09807289205492, "Avg game time in secs": 1.95514110129443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.36}, "Total num played games": 39040, "Total num trained steps": 77513, "Timestamp in ms": 1701462728706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836078150572831, "Avg loss": 0.3981147522572428, "Avg value loss": 0.15243092822493054, "Avg policy loss": 0.24568382534198463, "Total num played games": 39104, "Total num trained steps": 77568, "Timestamp in ms": 1701462755993, "logtype": "training_step"}
{"Total num played games": 39104, "Total num trained steps": 77647, "Timestamp in ms": 1701462808538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.33984375}
{"Avg objective": 21.6484375, "Games time in secs": 83.28339923731983, "Avg game time in secs": 2.0924556885147467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.37, "agent_stopped_0": 0.64}, "Total num played games": 39168, "Total num trained steps": 77653, "Timestamp in ms": 1701462811989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982141946017654, "Avg loss": 0.4222523153293878, "Avg value loss": 0.177267045393819, "Avg policy loss": 0.24498527229297906, "Total num played games": 39198, "Total num trained steps": 77696, "Timestamp in ms": 1701462834217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853819072401653, "Avg loss": 0.34395712811965495, "Avg value loss": 0.09635213034925982, "Avg policy loss": 0.24760499654803425, "Total num played games": 39198, "Total num trained steps": 77824, "Timestamp in ms": 1701462896718, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983788873619382, "Avg loss": 0.42015580751467496, "Avg value loss": 0.170592241542181, "Avg policy loss": 0.24956356431357563, "Total num played games": 39294, "Total num trained steps": 77952, "Timestamp in ms": 1701462959653, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 210.58861238323152, "Avg game time in secs": 2.3398693451163126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 39296, "Total num trained steps": 78079, "Timestamp in ms": 1701463022578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986970684039088, "Avg loss": 0.3297300306148827, "Avg value loss": 0.0778307961882092, "Avg policy loss": 0.25189923704601824, "Total num played games": 39296, "Total num trained steps": 78080, "Timestamp in ms": 1701463022700, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853777416734362, "Avg loss": 0.39484615926630795, "Avg value loss": 0.14228422191808932, "Avg policy loss": 0.25256194011308253, "Total num played games": 39392, "Total num trained steps": 78208, "Timestamp in ms": 1701463087229, "logtype": "training_step"}
{"Total num played games": 39392, "Total num trained steps": 78247, "Timestamp in ms": 1701463117520, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6015625}
{"Avg objective": 20.6875, "Games time in secs": 97.59992672689259, "Avg game time in secs": 1.90379434870556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.34}, "Total num played games": 39424, "Total num trained steps": 78249, "Timestamp in ms": 1701463120178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838930253760827, "Avg loss": 0.44342040980700403, "Avg value loss": 0.18231258503510617, "Avg policy loss": 0.2611078229965642, "Total num played games": 39486, "Total num trained steps": 78336, "Timestamp in ms": 1701463166622, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986103376702273, "Avg loss": 0.31916461733635515, "Avg value loss": 0.06796342640882358, "Avg policy loss": 0.2512011914514005, "Total num played games": 39504, "Total num trained steps": 78464, "Timestamp in ms": 1701463231950, "logtype": "training_step"}
{"Avg objective": 20.2421875, "Games time in secs": 112.52712659165263, "Avg game time in secs": 1.9116663892345969, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.34}, "Total num played games": 39552, "Total num trained steps": 78465, "Timestamp in ms": 1701463232705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855489869132434, "Avg loss": 0.4174432590370998, "Avg value loss": 0.16288684104802087, "Avg policy loss": 0.2545564133906737, "Total num played games": 39582, "Total num trained steps": 78592, "Timestamp in ms": 1701463301116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984070974896663, "Avg loss": 0.415100873215124, "Avg value loss": 0.1586288304242771, "Avg policy loss": 0.2564720429945737, "Total num played games": 39676, "Total num trained steps": 78720, "Timestamp in ms": 1701463368526, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 198.48212978988886, "Avg game time in secs": 2.1484492476156447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 39680, "Total num trained steps": 78843, "Timestamp in ms": 1701463431188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825748051294947, "Avg loss": 0.32683540612924844, "Avg value loss": 0.07986527460161597, "Avg policy loss": 0.24697013129480183, "Total num played games": 39766, "Total num trained steps": 78848, "Timestamp in ms": 1701463433754, "logtype": "training_step"}
{"Total num played games": 39770, "Total num trained steps": 78850, "Timestamp in ms": 1701463445937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.890625}
{"Avg objective": 20.3671875, "Games time in secs": 17.580385752022266, "Avg game time in secs": 1.8846997638902394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.33}, "Total num played games": 39808, "Total num trained steps": 78852, "Timestamp in ms": 1701463448768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981135861930564, "Avg loss": 0.5543876443989575, "Avg value loss": 0.2709251275518909, "Avg policy loss": 0.2834625147515908, "Total num played games": 39864, "Total num trained steps": 78976, "Timestamp in ms": 1701463510407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843467790487659, "Avg loss": 0.3316001145867631, "Avg value loss": 0.07336206256877631, "Avg policy loss": 0.25823805131949484, "Total num played games": 39864, "Total num trained steps": 79104, "Timestamp in ms": 1701463577065, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 190.38062925636768, "Avg game time in secs": 1.9647630442777881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 39936, "Total num trained steps": 79222, "Timestamp in ms": 1701463639149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828569998498424, "Avg loss": 0.353137141559273, "Avg value loss": 0.09419437512406148, "Avg policy loss": 0.2589427672792226, "Total num played games": 39958, "Total num trained steps": 79232, "Timestamp in ms": 1701463644412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860853896591422, "Avg loss": 0.423855027416721, "Avg value loss": 0.14474446087842807, "Avg policy loss": 0.2791105661308393, "Total num played games": 39958, "Total num trained steps": 79360, "Timestamp in ms": 1701463710681, "logtype": "training_step"}
{"Total num played games": 40052, "Total num trained steps": 79450, "Timestamp in ms": 1701463766754, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.56640625}
{"Avg objective": 20.9140625, "Games time in secs": 129.72476342320442, "Avg game time in secs": 1.9959471507754643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.33, "agent_stopped_0": 0.67}, "Total num played games": 40064, "Total num trained steps": 79453, "Timestamp in ms": 1701463768874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9799481891097495, "Avg loss": 0.5238760616630316, "Avg value loss": 0.2429359385278076, "Avg policy loss": 0.28094012138899416, "Total num played games": 40146, "Total num trained steps": 79488, "Timestamp in ms": 1701463788300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831614606685597, "Avg loss": 0.39694469631649554, "Avg value loss": 0.11670560436323285, "Avg policy loss": 0.28023909381590784, "Total num played games": 40146, "Total num trained steps": 79616, "Timestamp in ms": 1701463853588, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863249140636676, "Avg loss": 0.3323555716779083, "Avg value loss": 0.06393090946949087, "Avg policy loss": 0.2684246649732813, "Total num played games": 40146, "Total num trained steps": 79744, "Timestamp in ms": 1701463919845, "logtype": "training_step"}
{"Avg objective": 19.53125, "Games time in secs": 170.85697107575834, "Avg game time in secs": 1.91435289378569, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.33}, "Total num played games": 40192, "Total num trained steps": 79786, "Timestamp in ms": 1701463939731, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984865805168986, "Avg loss": 0.46301177504938096, "Avg value loss": 0.1888678812829312, "Avg policy loss": 0.2741438993252814, "Total num played games": 40240, "Total num trained steps": 79872, "Timestamp in ms": 1701463980443, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 90.92226888611913, "Avg game time in secs": 2.036640313846874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 40320, "Total num trained steps": 79974, "Timestamp in ms": 1701464030653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834382902761938, "Avg loss": 0.41003827459644526, "Avg value loss": 0.13427851488813758, "Avg policy loss": 0.2757597619201988, "Total num played games": 40334, "Total num trained steps": 80000, "Timestamp in ms": 1701464044647, "logtype": "training_step"}
{"Total num played games": 40334, "Total num trained steps": 80050, "Timestamp in ms": 1701464080683, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6484375}
{"Ratio train steps to played games": 1.9819926783417434, "Avg loss": 0.5087418623734266, "Avg value loss": 0.2231318274862133, "Avg policy loss": 0.28561003180220723, "Total num played games": 40428, "Total num trained steps": 80128, "Timestamp in ms": 1701464125254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851588008311072, "Avg loss": 0.3497492002788931, "Avg value loss": 0.08275438426062465, "Avg policy loss": 0.26699481974355876, "Total num played games": 40428, "Total num trained steps": 80256, "Timestamp in ms": 1701464188063, "logtype": "training_step"}
{"Avg objective": 19.8828125, "Games time in secs": 203.55180787667632, "Avg game time in secs": 1.9723974704538705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.34, "agent_stopped_0": 0.67}, "Total num played games": 40448, "Total num trained steps": 80348, "Timestamp in ms": 1701464234205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832231323398797, "Avg loss": 0.4049457424553111, "Avg value loss": 0.13620433636242524, "Avg policy loss": 0.26874140393920243, "Total num played games": 40532, "Total num trained steps": 80384, "Timestamp in ms": 1701464252787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863811309582553, "Avg loss": 0.3514595456654206, "Avg value loss": 0.07920631184242666, "Avg policy loss": 0.27225323382299393, "Total num played games": 40532, "Total num trained steps": 80512, "Timestamp in ms": 1701464316593, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 104.24851305037737, "Avg game time in secs": 1.8502743088174611, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.28}, "Total num played games": 40576, "Total num trained steps": 80557, "Timestamp in ms": 1701464338454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849357554275586, "Avg loss": 0.42924420826602727, "Avg value loss": 0.15825650564511307, "Avg policy loss": 0.27098770486190915, "Total num played games": 40626, "Total num trained steps": 80640, "Timestamp in ms": 1701464377548, "logtype": "training_step"}
{"Total num played games": 40626, "Total num trained steps": 80652, "Timestamp in ms": 1701464394503, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.26953125}
{"Avg objective": 20.546875, "Games time in secs": 59.784574791789055, "Avg game time in secs": 1.9681768184527755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 40704, "Total num trained steps": 80658, "Timestamp in ms": 1701464398239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834970530451865, "Avg loss": 0.44891377189196646, "Avg value loss": 0.1636677498172503, "Avg policy loss": 0.2852460260037333, "Total num played games": 40720, "Total num trained steps": 80768, "Timestamp in ms": 1701464454150, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866159135559922, "Avg loss": 0.3285487514222041, "Avg value loss": 0.05934057181002572, "Avg policy loss": 0.2692081806017086, "Total num played games": 40720, "Total num trained steps": 80896, "Timestamp in ms": 1701464519345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852011564659187, "Avg loss": 0.4505828011315316, "Avg value loss": 0.1733162064338103, "Avg policy loss": 0.27726659551262856, "Total num played games": 40814, "Total num trained steps": 81024, "Timestamp in ms": 1701464583194, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 230.19234461523592, "Avg game time in secs": 1.9894165752775734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.43, "agent_stopped_0": 0.65}, "Total num played games": 40832, "Total num trained steps": 81120, "Timestamp in ms": 1701464628431, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983768456047717, "Avg loss": 0.4510338739491999, "Avg value loss": 0.17789814330171794, "Avg policy loss": 0.27313573006540537, "Total num played games": 40908, "Total num trained steps": 81152, "Timestamp in ms": 1701464644526, "logtype": "training_step"}
{"Total num played games": 40908, "Total num trained steps": 81255, "Timestamp in ms": 1701464706169, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.0625}
{"Avg objective": 20.7890625, "Games time in secs": 80.89538421854377, "Avg game time in secs": 2.0632375092391158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 40960, "Total num trained steps": 81259, "Timestamp in ms": 1701464709327, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823423247646457, "Avg loss": 0.4300947868032381, "Avg value loss": 0.14593062046333216, "Avg policy loss": 0.2841641682898626, "Total num played games": 41002, "Total num trained steps": 81280, "Timestamp in ms": 1701464720197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985464123701283, "Avg loss": 0.3815348534844816, "Avg value loss": 0.10645657608984038, "Avg policy loss": 0.2750782782677561, "Total num played games": 41002, "Total num trained steps": 81408, "Timestamp in ms": 1701464785351, "logtype": "training_step"}
{"Avg objective": 19.90625, "Games time in secs": 122.82513682730496, "Avg game time in secs": 2.0270193347969325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.36, "agent_stopped_0": 0.66}, "Total num played games": 41088, "Total num trained steps": 81498, "Timestamp in ms": 1701464832152, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839408243710157, "Avg loss": 0.3787535597803071, "Avg value loss": 0.120593896106584, "Avg policy loss": 0.2581596643431112, "Total num played games": 41098, "Total num trained steps": 81536, "Timestamp in ms": 1701464850273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987055331159667, "Avg loss": 0.34613031800836325, "Avg value loss": 0.07791037257993594, "Avg policy loss": 0.26821994595229626, "Total num played games": 41098, "Total num trained steps": 81664, "Timestamp in ms": 1701464917931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855318735738214, "Avg loss": 0.42641986324451864, "Avg value loss": 0.16146065722568892, "Avg policy loss": 0.26495920412708074, "Total num played games": 41194, "Total num trained steps": 81792, "Timestamp in ms": 1701464982850, "logtype": "training_step"}
{"Total num played games": 41194, "Total num trained steps": 81858, "Timestamp in ms": 1701465024979, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.125}
{"Avg objective": 19.8046875, "Games time in secs": 195.36845521256328, "Avg game time in secs": 1.968176845475682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.33, "agent_stopped_0": 0.68}, "Total num played games": 41216, "Total num trained steps": 81863, "Timestamp in ms": 1701465027522, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841116062778532, "Avg loss": 0.4103750048670918, "Avg value loss": 0.14465652909711935, "Avg policy loss": 0.26571847358718514, "Total num played games": 41288, "Total num trained steps": 81920, "Timestamp in ms": 1701465056699, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872117806626624, "Avg loss": 0.335444999509491, "Avg value loss": 0.0668276876967866, "Avg policy loss": 0.2686173082329333, "Total num played games": 41288, "Total num trained steps": 82048, "Timestamp in ms": 1701465120717, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 103.84795100800693, "Avg game time in secs": 1.869447900200612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.26, "played_steps": 0.27}, "Total num played games": 41344, "Total num trained steps": 82069, "Timestamp in ms": 1701465131370, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857909235899667, "Avg loss": 0.4245629571378231, "Avg value loss": 0.15765827288851142, "Avg policy loss": 0.2669046875089407, "Total num played games": 41382, "Total num trained steps": 82176, "Timestamp in ms": 1701465187299, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 95.45648546889424, "Avg game time in secs": 2.0536407024919754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.39, "agent_stopped_0": 0.63}, "Total num played games": 41472, "Total num trained steps": 82259, "Timestamp in ms": 1701465226827, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843765068955541, "Avg loss": 0.4373199726687744, "Avg value loss": 0.17299837313476019, "Avg policy loss": 0.2643215989228338, "Total num played games": 41476, "Total num trained steps": 82304, "Timestamp in ms": 1701465248307, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874626289902595, "Avg loss": 0.35016534163150936, "Avg value loss": 0.09252085105981678, "Avg policy loss": 0.2576444922015071, "Total num played games": 41476, "Total num trained steps": 82432, "Timestamp in ms": 1701465309507, "logtype": "training_step"}
{"Total num played games": 41570, "Total num trained steps": 82462, "Timestamp in ms": 1701465333593, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.1953125}
{"Avg objective": 20.6640625, "Games time in secs": 109.60010898113251, "Avg game time in secs": 1.9205817583424505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.3, "agent_stopped_0": 0.72}, "Total num played games": 41600, "Total num trained steps": 82466, "Timestamp in ms": 1701465336427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815668202764978, "Avg loss": 0.49649962200783193, "Avg value loss": 0.22173168667359278, "Avg policy loss": 0.274767933296971, "Total num played games": 41664, "Total num trained steps": 82560, "Timestamp in ms": 1701465384399, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846150153609832, "Avg loss": 0.3651675069704652, "Avg value loss": 0.10711976396851242, "Avg policy loss": 0.2580477384617552, "Total num played games": 41664, "Total num trained steps": 82688, "Timestamp in ms": 1701465447376, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876872119815667, "Avg loss": 0.3349823490716517, "Avg value loss": 0.09016968082869425, "Avg policy loss": 0.24481266783550382, "Total num played games": 41664, "Total num trained steps": 82816, "Timestamp in ms": 1701465510896, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 177.07238322123885, "Avg game time in secs": 2.017909776448505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.4}, "Total num played games": 41728, "Total num trained steps": 82821, "Timestamp in ms": 1701465513500, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863020259590976, "Avg loss": 0.4422044847160578, "Avg value loss": 0.17202929451013915, "Avg policy loss": 0.2701751885470003, "Total num played games": 41758, "Total num trained steps": 82944, "Timestamp in ms": 1701465574206, "logtype": "training_step"}
{"Total num played games": 41852, "Total num trained steps": 83063, "Timestamp in ms": 1701465648341, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.33984375}
{"Avg objective": 20.8671875, "Games time in secs": 136.68922689184546, "Avg game time in secs": 2.16721328785934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.45, "agent_stopped_0": 0.57}, "Total num played games": 41856, "Total num trained steps": 83065, "Timestamp in ms": 1701465650189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980451056119773, "Avg loss": 0.4186950771836564, "Avg value loss": 0.15384800473111682, "Avg policy loss": 0.2648470700951293, "Total num played games": 41946, "Total num trained steps": 83072, "Timestamp in ms": 1701465653532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835025985791255, "Avg loss": 0.48973220284096897, "Avg value loss": 0.21635063708527014, "Avg policy loss": 0.27338156837504357, "Total num played games": 41946, "Total num trained steps": 83200, "Timestamp in ms": 1701465716733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986554141038478, "Avg loss": 0.32664418197236955, "Avg value loss": 0.06904717776342295, "Avg policy loss": 0.2575970031321049, "Total num played games": 41946, "Total num trained steps": 83328, "Timestamp in ms": 1701465781015, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 160.90798987820745, "Avg game time in secs": 1.9024397914326983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.29}, "Total num played games": 41984, "Total num trained steps": 83384, "Timestamp in ms": 1701465811097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851332064700284, "Avg loss": 0.428473791340366, "Avg value loss": 0.16623066601459868, "Avg policy loss": 0.26224312314298004, "Total num played games": 42040, "Total num trained steps": 83456, "Timestamp in ms": 1701465849842, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 99.08247809112072, "Avg game time in secs": 1.9643950477329781, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.33, "agent_stopped_0": 0.69}, "Total num played games": 42112, "Total num trained steps": 83574, "Timestamp in ms": 1701465910180, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983671919498766, "Avg loss": 0.36637008970137686, "Avg value loss": 0.11185598323936574, "Avg policy loss": 0.2545141049195081, "Total num played games": 42136, "Total num trained steps": 83584, "Timestamp in ms": 1701465915220, "logtype": "training_step"}
{"Total num played games": 42136, "Total num trained steps": 83663, "Timestamp in ms": 1701465966224, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6484375}
{"Ratio train steps to played games": 1.9822637935117216, "Avg loss": 0.4885119623504579, "Avg value loss": 0.22186184467864223, "Avg policy loss": 0.26665011909790337, "Total num played games": 42230, "Total num trained steps": 83712, "Timestamp in ms": 1701465991719, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852948141131896, "Avg loss": 0.36270613642409444, "Avg value loss": 0.09657623511156999, "Avg policy loss": 0.2661299002356827, "Total num played games": 42230, "Total num trained steps": 83840, "Timestamp in ms": 1701466056921, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 201.69811004400253, "Avg game time in secs": 2.0877743231976638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 42240, "Total num trained steps": 83952, "Timestamp in ms": 1701466111878, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839098383895661, "Avg loss": 0.3600829156348482, "Avg value loss": 0.1046922771492973, "Avg policy loss": 0.2553906384855509, "Total num played games": 42324, "Total num trained steps": 83968, "Timestamp in ms": 1701466120056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869577544655515, "Avg loss": 0.4226696325931698, "Avg value loss": 0.15994668056373484, "Avg policy loss": 0.2627229482168332, "Total num played games": 42324, "Total num trained steps": 84096, "Timestamp in ms": 1701466183644, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 94.93456600233912, "Avg game time in secs": 2.0288882566674147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.38}, "Total num played games": 42368, "Total num trained steps": 84140, "Timestamp in ms": 1701466206813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855485878636427, "Avg loss": 0.4031610145466402, "Avg value loss": 0.13440022093709558, "Avg policy loss": 0.2687607911648229, "Total num played games": 42418, "Total num trained steps": 84224, "Timestamp in ms": 1701466248427, "logtype": "training_step"}
{"Total num played games": 42418, "Total num trained steps": 84266, "Timestamp in ms": 1701466281129, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0234375}
{"Avg objective": 20.3359375, "Games time in secs": 78.28028947487473, "Avg game time in secs": 2.150193633104209, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 42496, "Total num trained steps": 84271, "Timestamp in ms": 1701466285093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841926985321792, "Avg loss": 0.417126088635996, "Avg value loss": 0.1406218440970406, "Avg policy loss": 0.27650424267631024, "Total num played games": 42512, "Total num trained steps": 84352, "Timestamp in ms": 1701466326380, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872036130974784, "Avg loss": 0.33740070869680494, "Avg value loss": 0.06679602488293312, "Avg policy loss": 0.2706046813400462, "Total num played games": 42512, "Total num trained steps": 84480, "Timestamp in ms": 1701466390463, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858235929211847, "Avg loss": 0.3947218346875161, "Avg value loss": 0.12575534606003202, "Avg policy loss": 0.2689664891222492, "Total num played games": 42606, "Total num trained steps": 84608, "Timestamp in ms": 1701466456053, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 220.41966161318123, "Avg game time in secs": 2.2309464155696332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 42624, "Total num trained steps": 84704, "Timestamp in ms": 1701466505513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843567046039998, "Avg loss": 0.37856283166911453, "Avg value loss": 0.1035739490762353, "Avg policy loss": 0.2749888844555244, "Total num played games": 42702, "Total num trained steps": 84736, "Timestamp in ms": 1701466520696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873542222846705, "Avg loss": 0.37262105057016015, "Avg value loss": 0.09768313984386623, "Avg policy loss": 0.27493791095912457, "Total num played games": 42702, "Total num trained steps": 84864, "Timestamp in ms": 1701466583625, "logtype": "training_step"}
{"Total num played games": 42702, "Total num trained steps": 84866, "Timestamp in ms": 1701466599462, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.08203125}
{"Avg objective": 19.4453125, "Games time in secs": 96.80039090849459, "Avg game time in secs": 1.848228202026803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.27}, "Total num played games": 42752, "Total num trained steps": 84871, "Timestamp in ms": 1701466602314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859799981306665, "Avg loss": 0.41960634221322834, "Avg value loss": 0.13562747489777394, "Avg policy loss": 0.2839788669953123, "Total num played games": 42796, "Total num trained steps": 84992, "Timestamp in ms": 1701466663221, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 107.84496469050646, "Avg game time in secs": 2.0550537326489575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 42880, "Total num trained steps": 85088, "Timestamp in ms": 1701466710159, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846117976218232, "Avg loss": 0.392142886063084, "Avg value loss": 0.12267934624105692, "Avg policy loss": 0.26946354063693434, "Total num played games": 42890, "Total num trained steps": 85120, "Timestamp in ms": 1701466725330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875961762648635, "Avg loss": 0.3490280882688239, "Avg value loss": 0.08147460542386398, "Avg policy loss": 0.26755348150618374, "Total num played games": 42890, "Total num trained steps": 85248, "Timestamp in ms": 1701466792070, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862274334636143, "Avg loss": 0.4160942556336522, "Avg value loss": 0.14397997071500868, "Avg policy loss": 0.27211428235750645, "Total num played games": 42984, "Total num trained steps": 85376, "Timestamp in ms": 1701466858515, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 193.17566788382828, "Avg game time in secs": 2.1831578434212133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 43008, "Total num trained steps": 85460, "Timestamp in ms": 1701466903335, "logtype": "played_game"}
{"Total num played games": 43078, "Total num trained steps": 85470, "Timestamp in ms": 1701466921811, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.13671875}
{"Avg objective": 19.9765625, "Games time in secs": 21.742937935516238, "Avg game time in secs": 2.07190224576334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 43136, "Total num trained steps": 85475, "Timestamp in ms": 1701466925078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805429445010656, "Avg loss": 0.4513823544839397, "Avg value loss": 0.17234915570588782, "Avg policy loss": 0.27903319464530796, "Total num played games": 43172, "Total num trained steps": 85504, "Timestamp in ms": 1701466939487, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835078291485222, "Avg loss": 0.41376764769665897, "Avg value loss": 0.13420377075090073, "Avg policy loss": 0.27956387493759394, "Total num played games": 43172, "Total num trained steps": 85632, "Timestamp in ms": 1701467006159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864727137959788, "Avg loss": 0.3637470487738028, "Avg value loss": 0.09412239925586618, "Avg policy loss": 0.2696246497798711, "Total num played games": 43172, "Total num trained steps": 85760, "Timestamp in ms": 1701467071136, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 186.76293992251158, "Avg game time in secs": 2.1045372900553048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.44, "agent_stopped_0": 0.58}, "Total num played games": 43264, "Total num trained steps": 85839, "Timestamp in ms": 1701467111841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850235740038829, "Avg loss": 0.43373932619579136, "Avg value loss": 0.1540704285434913, "Avg policy loss": 0.2796688962262124, "Total num played games": 43268, "Total num trained steps": 85888, "Timestamp in ms": 1701467135671, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879587686049736, "Avg loss": 0.3508985076332465, "Avg value loss": 0.07785938226152211, "Avg policy loss": 0.2730391244404018, "Total num played games": 43268, "Total num trained steps": 86016, "Timestamp in ms": 1701467198976, "logtype": "training_step"}
{"Total num played games": 43362, "Total num trained steps": 86072, "Timestamp in ms": 1701467236179, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.88671875}
{"Avg objective": 19.3125, "Games time in secs": 127.22747400589287, "Avg game time in secs": 2.0990571557777002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 43392, "Total num trained steps": 86077, "Timestamp in ms": 1701467239069, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823039396170838, "Avg loss": 0.562764250440523, "Avg value loss": 0.27401176444254816, "Avg policy loss": 0.2887524840189144, "Total num played games": 43456, "Total num trained steps": 86144, "Timestamp in ms": 1701467273340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852724594992637, "Avg loss": 0.36863176082260907, "Avg value loss": 0.09099008422344923, "Avg policy loss": 0.27764167229179293, "Total num played games": 43456, "Total num trained steps": 86272, "Timestamp in ms": 1701467337125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881949558173786, "Avg loss": 0.3543348421808332, "Avg value loss": 0.08594848713255487, "Avg policy loss": 0.26838635350577533, "Total num played games": 43456, "Total num trained steps": 86400, "Timestamp in ms": 1701467401105, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 164.7134662065655, "Avg game time in secs": 1.9497518559510354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.34}, "Total num played games": 43520, "Total num trained steps": 86406, "Timestamp in ms": 1701467403783, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867744305657604, "Avg loss": 0.47521472442895174, "Avg value loss": 0.18978494754992425, "Avg policy loss": 0.2854297753656283, "Total num played games": 43552, "Total num trained steps": 86528, "Timestamp in ms": 1701467467569, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 101.73437800817192, "Avg game time in secs": 2.1640802875626832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.46, "agent_stopped_0": 0.61}, "Total num played games": 43648, "Total num trained steps": 86599, "Timestamp in ms": 1701467505517, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853372434017595, "Avg loss": 0.45103351573925465, "Avg value loss": 0.1625187877798453, "Avg policy loss": 0.28851472679525614, "Total num played games": 43648, "Total num trained steps": 86656, "Timestamp in ms": 1701467534878, "logtype": "training_step"}
{"Total num played games": 43648, "Total num trained steps": 86672, "Timestamp in ms": 1701467554019, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.67578125}
{"Ratio train steps to played games": 1.9839970737506287, "Avg loss": 0.40759212593548, "Avg value loss": 0.13006386725464836, "Avg policy loss": 0.27752825792413205, "Total num played games": 43742, "Total num trained steps": 86784, "Timestamp in ms": 1701467610252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986900461798729, "Avg loss": 0.3259572540409863, "Avg value loss": 0.060778343526180834, "Avg policy loss": 0.2651789077790454, "Total num played games": 43742, "Total num trained steps": 86912, "Timestamp in ms": 1701467670572, "logtype": "training_step"}
{"Avg objective": 20.03125, "Games time in secs": 195.72841865196824, "Avg game time in secs": 1.8989479443407618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.3, "agent_stopped_0": 0.73}, "Total num played games": 43776, "Total num trained steps": 86976, "Timestamp in ms": 1701467701246, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854920388703865, "Avg loss": 0.4401206347392872, "Avg value loss": 0.17233378940727562, "Avg policy loss": 0.26778684405144304, "Total num played games": 43838, "Total num trained steps": 87040, "Timestamp in ms": 1701467732733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987323879440062, "Avg loss": 0.3599924851441756, "Avg value loss": 0.10155621991725639, "Avg policy loss": 0.25843626365531236, "Total num played games": 43862, "Total num trained steps": 87168, "Timestamp in ms": 1701467794018, "logtype": "training_step"}
{"Avg objective": 20.203125, "Games time in secs": 93.6992863714695, "Avg game time in secs": 1.9899938861344708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 43904, "Total num trained steps": 87169, "Timestamp in ms": 1701467794945, "logtype": "played_game"}
{"Total num played games": 43932, "Total num trained steps": 87273, "Timestamp in ms": 1701467858002, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.62109375}
{"Ratio train steps to played games": 1.9828283287148503, "Avg loss": 0.48996996972709894, "Avg value loss": 0.22221792736672796, "Avg policy loss": 0.2677520434372127, "Total num played games": 44026, "Total num trained steps": 87296, "Timestamp in ms": 1701467869713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857357016308546, "Avg loss": 0.4012498132651672, "Avg value loss": 0.13171977922320366, "Avg policy loss": 0.26953003264497966, "Total num played games": 44026, "Total num trained steps": 87424, "Timestamp in ms": 1701467926982, "logtype": "training_step"}
{"Avg objective": 20.1640625, "Games time in secs": 191.35750429145992, "Avg game time in secs": 2.455458059310331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 44032, "Total num trained steps": 87543, "Timestamp in ms": 1701467986303, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984406165004533, "Avg loss": 0.32283691002521664, "Avg value loss": 0.07391190790804103, "Avg policy loss": 0.24892500322312117, "Total num played games": 44120, "Total num trained steps": 87552, "Timestamp in ms": 1701467990226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872172612302252, "Avg loss": 0.4414793271571398, "Avg value loss": 0.17828558196197264, "Avg policy loss": 0.26319374330341816, "Total num played games": 44122, "Total num trained steps": 87680, "Timestamp in ms": 1701468052438, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 92.8307447489351, "Avg game time in secs": 2.088176339471829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.36}, "Total num played games": 44160, "Total num trained steps": 87737, "Timestamp in ms": 1701468079134, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858874615523792, "Avg loss": 0.43492116895504296, "Avg value loss": 0.18013784041977488, "Avg policy loss": 0.25478332838974893, "Total num played games": 44216, "Total num trained steps": 87808, "Timestamp in ms": 1701468113722, "logtype": "training_step"}
{"Total num played games": 44216, "Total num trained steps": 87873, "Timestamp in ms": 1701468157280, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6875}
{"Avg objective": 20.09375, "Games time in secs": 81.85661272704601, "Avg game time in secs": 2.075130480050575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.39}, "Total num played games": 44288, "Total num trained steps": 87880, "Timestamp in ms": 1701468160991, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845633039945836, "Avg loss": 0.3765400822740048, "Avg value loss": 0.1264134645462036, "Avg policy loss": 0.2501266156323254, "Total num played games": 44310, "Total num trained steps": 87936, "Timestamp in ms": 1701468189080, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874520424283457, "Avg loss": 0.3184843244962394, "Avg value loss": 0.06447047615074553, "Avg policy loss": 0.2540138482581824, "Total num played games": 44310, "Total num trained steps": 88064, "Timestamp in ms": 1701468251112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861273759120799, "Avg loss": 0.40172397636342794, "Avg value loss": 0.15163124233367853, "Avg policy loss": 0.2500927326036617, "Total num played games": 44404, "Total num trained steps": 88192, "Timestamp in ms": 1701468316450, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 206.6424088086933, "Avg game time in secs": 2.1220406711217947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.4}, "Total num played games": 44416, "Total num trained steps": 88300, "Timestamp in ms": 1701468367633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848083059912804, "Avg loss": 0.378887542639859, "Avg value loss": 0.12922737188637257, "Avg policy loss": 0.2496601736638695, "Total num played games": 44498, "Total num trained steps": 88320, "Timestamp in ms": 1701468377473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876848397680795, "Avg loss": 0.3723190459422767, "Avg value loss": 0.11749747654539533, "Avg policy loss": 0.2548215731512755, "Total num played games": 44498, "Total num trained steps": 88448, "Timestamp in ms": 1701468439552, "logtype": "training_step"}
{"Total num played games": 44498, "Total num trained steps": 88476, "Timestamp in ms": 1701468463566, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.71484375}
{"Avg objective": 19.875, "Games time in secs": 99.14043060876429, "Avg game time in secs": 1.9857478927151533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.29}, "Total num played games": 44544, "Total num trained steps": 88482, "Timestamp in ms": 1701468466774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986342841765339, "Avg loss": 0.3867092572618276, "Avg value loss": 0.13732962115318514, "Avg policy loss": 0.2493796335766092, "Total num played games": 44592, "Total num trained steps": 88576, "Timestamp in ms": 1701468514721, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 98.62532537430525, "Avg game time in secs": 2.081406189245172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.33}, "Total num played games": 44672, "Total num trained steps": 88679, "Timestamp in ms": 1701468565399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850512464754062, "Avg loss": 0.39661321765743196, "Avg value loss": 0.14648830250371248, "Avg policy loss": 0.25012491655070335, "Total num played games": 44686, "Total num trained steps": 88704, "Timestamp in ms": 1701468577395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987915678288502, "Avg loss": 0.3509551075985655, "Avg value loss": 0.10470299443113618, "Avg policy loss": 0.24625211185775697, "Total num played games": 44686, "Total num trained steps": 88832, "Timestamp in ms": 1701468637735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866011612326933, "Avg loss": 0.39715685264673084, "Avg value loss": 0.1434423853061162, "Avg policy loss": 0.2537144662346691, "Total num played games": 44780, "Total num trained steps": 88960, "Timestamp in ms": 1701468699415, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 178.7092044055462, "Avg game time in secs": 1.917001356210676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.3, "agent_stopped_0": 0.73}, "Total num played games": 44800, "Total num trained steps": 89052, "Timestamp in ms": 1701468744108, "logtype": "played_game"}
{"Total num played games": 44876, "Total num trained steps": 89080, "Timestamp in ms": 1701468766845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.18359375}
{"Avg objective": 20.2890625, "Games time in secs": 26.036993354558945, "Avg game time in secs": 1.952588094616658, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.3}, "Total num played games": 44928, "Total num trained steps": 89086, "Timestamp in ms": 1701468770145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819354838709677, "Avg loss": 0.3713268816936761, "Avg value loss": 0.12817585913580842, "Avg policy loss": 0.24315102223772556, "Total num played games": 44948, "Total num trained steps": 89088, "Timestamp in ms": 1701468770792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839003780297977, "Avg loss": 0.4769514109939337, "Avg value loss": 0.22357083766837604, "Avg policy loss": 0.25338057370390743, "Total num played games": 44970, "Total num trained steps": 89216, "Timestamp in ms": 1701468836704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867467200355793, "Avg loss": 0.2915446305414662, "Avg value loss": 0.058486945228651166, "Avg policy loss": 0.2330576881649904, "Total num played games": 44970, "Total num trained steps": 89344, "Timestamp in ms": 1701468898496, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 171.78332628123462, "Avg game time in secs": 2.4332997418241575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 45056, "Total num trained steps": 89436, "Timestamp in ms": 1701468941929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985420734954731, "Avg loss": 0.38511376653332263, "Avg value loss": 0.14135279884794727, "Avg policy loss": 0.2437609649496153, "Total num played games": 45064, "Total num trained steps": 89472, "Timestamp in ms": 1701468960781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882833303745784, "Avg loss": 0.34890715568326414, "Avg value loss": 0.08932418713811785, "Avg policy loss": 0.25958296889439225, "Total num played games": 45064, "Total num trained steps": 89600, "Timestamp in ms": 1701469023636, "logtype": "training_step"}
{"Total num played games": 45160, "Total num trained steps": 89680, "Timestamp in ms": 1701469071388, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5}
{"Avg objective": 19.453125, "Games time in secs": 131.97302775643766, "Avg game time in secs": 2.0896295901329722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 45184, "Total num trained steps": 89683, "Timestamp in ms": 1701469073902, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982763954567552, "Avg loss": 0.5024731908924878, "Avg value loss": 0.24331671837717295, "Avg policy loss": 0.2591564744943753, "Total num played games": 45254, "Total num trained steps": 89728, "Timestamp in ms": 1701469094041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985592433818005, "Avg loss": 0.3260825863108039, "Avg value loss": 0.07813819032162428, "Avg policy loss": 0.24794439447578043, "Total num played games": 45254, "Total num trained steps": 89856, "Timestamp in ms": 1701469153072, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988420913068458, "Avg loss": 0.28351176308933645, "Avg value loss": 0.04800156407873146, "Avg policy loss": 0.23551019979640841, "Total num played games": 45254, "Total num trained steps": 89984, "Timestamp in ms": 1701469213548, "logtype": "training_step"}
{"Avg objective": 19.15625, "Games time in secs": 147.53118540905416, "Avg game time in secs": 2.0260554952401435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.33, "agent_stopped_0": 0.7}, "Total num played games": 45312, "Total num trained steps": 90002, "Timestamp in ms": 1701469221434, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871218135309165, "Avg loss": 0.4431730502983555, "Avg value loss": 0.1893410762422718, "Avg policy loss": 0.25383197178598493, "Total num played games": 45348, "Total num trained steps": 90112, "Timestamp in ms": 1701469270402, "logtype": "training_step"}
{"Avg objective": 20.59375, "Games time in secs": 85.36112213134766, "Avg game time in secs": 2.18460394894646, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 45440, "Total num trained steps": 90193, "Timestamp in ms": 1701469306795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985740691840507, "Avg loss": 0.3952567212982103, "Avg value loss": 0.1476344169350341, "Avg policy loss": 0.24762230517808348, "Total num played games": 45444, "Total num trained steps": 90240, "Timestamp in ms": 1701469327995, "logtype": "training_step"}
{"Total num played games": 45444, "Total num trained steps": 90282, "Timestamp in ms": 1701469357441, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3515625}
{"Ratio train steps to played games": 1.9844525451271466, "Avg loss": 0.4086135501274839, "Avg value loss": 0.15460825027548708, "Avg policy loss": 0.25400530081242323, "Total num played games": 45538, "Total num trained steps": 90368, "Timestamp in ms": 1701469396113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872633844261935, "Avg loss": 0.33085687062703073, "Avg value loss": 0.08708729481440969, "Avg policy loss": 0.24376957200001925, "Total num played games": 45538, "Total num trained steps": 90496, "Timestamp in ms": 1701469454446, "logtype": "training_step"}
{"Avg objective": 19.953125, "Games time in secs": 179.9679746516049, "Avg game time in secs": 1.9741100235114573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.23, "played_steps": 0.26, "agent_stopped_0": 0.77}, "Total num played games": 45568, "Total num trained steps": 90569, "Timestamp in ms": 1701469486763, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858877152999956, "Avg loss": 0.3855908965924755, "Avg value loss": 0.14515971249784343, "Avg policy loss": 0.24043118336703628, "Total num played games": 45634, "Total num trained steps": 90624, "Timestamp in ms": 1701469511089, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886926414515493, "Avg loss": 0.32337823475245386, "Avg value loss": 0.07552742832922377, "Avg policy loss": 0.24785080750007182, "Total num played games": 45634, "Total num trained steps": 90752, "Timestamp in ms": 1701469568254, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 85.72372565045953, "Avg game time in secs": 2.125713317116606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.33}, "Total num played games": 45696, "Total num trained steps": 90762, "Timestamp in ms": 1701469572487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873168598294337, "Avg loss": 0.39419190224725753, "Avg value loss": 0.13751345133641735, "Avg policy loss": 0.25667845306452364, "Total num played games": 45730, "Total num trained steps": 90880, "Timestamp in ms": 1701469625574, "logtype": "training_step"}
{"Total num played games": 45730, "Total num trained steps": 90883, "Timestamp in ms": 1701469639376, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.58203125}
{"Avg objective": 21.34375, "Games time in secs": 72.44087919220328, "Avg game time in secs": 2.261575728363823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 45824, "Total num trained steps": 90894, "Timestamp in ms": 1701469644928, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860335195530727, "Avg loss": 0.4424525205977261, "Avg value loss": 0.17205642047338188, "Avg policy loss": 0.2703961010556668, "Total num played games": 45824, "Total num trained steps": 91008, "Timestamp in ms": 1701469696300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988826815642458, "Avg loss": 0.31541500764433295, "Avg value loss": 0.06330798749695532, "Avg policy loss": 0.25210701872128993, "Total num played games": 45824, "Total num trained steps": 91136, "Timestamp in ms": 1701469754600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874564459930313, "Avg loss": 0.3994322487851605, "Avg value loss": 0.13489366747671738, "Avg policy loss": 0.2645385832292959, "Total num played games": 45920, "Total num trained steps": 91264, "Timestamp in ms": 1701469811848, "logtype": "training_step"}
{"Avg objective": 19.390625, "Games time in secs": 197.7324876859784, "Avg game time in secs": 2.0639070702600293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.31}, "Total num played games": 45952, "Total num trained steps": 91333, "Timestamp in ms": 1701469842661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986178119702699, "Avg loss": 0.40535178571008146, "Avg value loss": 0.14344811392948031, "Avg policy loss": 0.26190366747323424, "Total num played games": 46014, "Total num trained steps": 91392, "Timestamp in ms": 1701469870397, "logtype": "training_step"}
{"Total num played games": 46014, "Total num trained steps": 91483, "Timestamp in ms": 1701469921366, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.35546875}
{"Avg objective": 21.359375, "Games time in secs": 81.97779636643827, "Avg game time in secs": 2.1168981824885122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.36}, "Total num played games": 46080, "Total num trained steps": 91490, "Timestamp in ms": 1701469924638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849050056389346, "Avg loss": 0.3770622406154871, "Avg value loss": 0.12080887838965282, "Avg policy loss": 0.2562533610034734, "Total num played games": 46108, "Total num trained steps": 91520, "Timestamp in ms": 1701469937695, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876810965559122, "Avg loss": 0.32729778019711375, "Avg value loss": 0.0766983499925118, "Avg policy loss": 0.2505994267994538, "Total num played games": 46108, "Total num trained steps": 91648, "Timestamp in ms": 1701469994864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986321530603411, "Avg loss": 0.4148749040905386, "Avg value loss": 0.15793116734130308, "Avg policy loss": 0.2569437362253666, "Total num played games": 46204, "Total num trained steps": 91776, "Timestamp in ms": 1701470051619, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 183.11533459462225, "Avg game time in secs": 2.377767950107227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 46208, "Total num trained steps": 91899, "Timestamp in ms": 1701470107754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855679903210475, "Avg loss": 0.3211424312321469, "Avg value loss": 0.0710752390732523, "Avg policy loss": 0.25006719201337546, "Total num played games": 46284, "Total num trained steps": 91904, "Timestamp in ms": 1701470109990, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878180482958228, "Avg loss": 0.404858740279451, "Avg value loss": 0.14626299482188188, "Avg policy loss": 0.258595744962804, "Total num played games": 46298, "Total num trained steps": 92032, "Timestamp in ms": 1701470167081, "logtype": "training_step"}
{"Total num played games": 46298, "Total num trained steps": 92083, "Timestamp in ms": 1701470204100, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.12890625}
{"Avg objective": 20.125, "Games time in secs": 99.2200102135539, "Avg game time in secs": 1.9859727526491042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.24, "played_steps": 0.27}, "Total num played games": 46336, "Total num trained steps": 92087, "Timestamp in ms": 1701470206974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865494050698396, "Avg loss": 0.4813320585526526, "Avg value loss": 0.21899165064678527, "Avg policy loss": 0.26234040840063244, "Total num played games": 46392, "Total num trained steps": 92160, "Timestamp in ms": 1701470239894, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 85.77122741006315, "Avg game time in secs": 2.0401872718939558, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.34}, "Total num played games": 46464, "Total num trained steps": 92279, "Timestamp in ms": 1701470292745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852858925267822, "Avg loss": 0.37505456642247736, "Avg value loss": 0.11049330866080709, "Avg policy loss": 0.2645612577907741, "Total num played games": 46486, "Total num trained steps": 92288, "Timestamp in ms": 1701470296888, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988039409714753, "Avg loss": 0.37254573043901473, "Avg value loss": 0.11739059470710345, "Avg policy loss": 0.25515513750724494, "Total num played games": 46486, "Total num trained steps": 92416, "Timestamp in ms": 1701470355164, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867754401030486, "Avg loss": 0.43609702645335346, "Avg value loss": 0.180201057868544, "Avg policy loss": 0.2558959719026461, "Total num played games": 46580, "Total num trained steps": 92544, "Timestamp in ms": 1701470413048, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 169.46374565176666, "Avg game time in secs": 2.2950554006238235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.41, "agent_stopped_0": 0.63}, "Total num played games": 46592, "Total num trained steps": 92652, "Timestamp in ms": 1701470462209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985516561683164, "Avg loss": 0.3528643895406276, "Avg value loss": 0.0910469324735459, "Avg policy loss": 0.2618174599483609, "Total num played games": 46674, "Total num trained steps": 92672, "Timestamp in ms": 1701470470754, "logtype": "training_step"}
{"Total num played games": 46674, "Total num trained steps": 92686, "Timestamp in ms": 1701470488703, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.43359375}
{"Avg objective": 20.7734375, "Games time in secs": 29.63473236002028, "Avg game time in secs": 2.17004059140163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.3}, "Total num played games": 46720, "Total num trained steps": 92692, "Timestamp in ms": 1701470491844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842627437564146, "Avg loss": 0.4755681592505425, "Avg value loss": 0.19160632853163406, "Avg policy loss": 0.2839618312427774, "Total num played games": 46768, "Total num trained steps": 92800, "Timestamp in ms": 1701470539726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869996578857338, "Avg loss": 0.3381466211285442, "Avg value loss": 0.06512906582793221, "Avg policy loss": 0.273017555125989, "Total num played games": 46768, "Total num trained steps": 92928, "Timestamp in ms": 1701470596404, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 151.78020058199763, "Avg game time in secs": 2.44073191419011, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 46848, "Total num trained steps": 93031, "Timestamp in ms": 1701470643624, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857453800520677, "Avg loss": 0.36850850738119334, "Avg value loss": 0.1068933721689973, "Avg policy loss": 0.26161513791885227, "Total num played games": 46862, "Total num trained steps": 93056, "Timestamp in ms": 1701470654821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884768042337075, "Avg loss": 0.3513679647585377, "Avg value loss": 0.08695624305983074, "Avg policy loss": 0.2644117200979963, "Total num played games": 46862, "Total num trained steps": 93184, "Timestamp in ms": 1701470712065, "logtype": "training_step"}
{"Total num played games": 46956, "Total num trained steps": 93288, "Timestamp in ms": 1701470768765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.41015625}
{"Avg objective": 21.078125, "Games time in secs": 127.36119196005166, "Avg game time in secs": 2.3442892410239438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.39}, "Total num played games": 46976, "Total num trained steps": 93291, "Timestamp in ms": 1701470770986, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983251859723698, "Avg loss": 0.48261858127079904, "Avg value loss": 0.21848720108391717, "Avg policy loss": 0.2641313860658556, "Total num played games": 47050, "Total num trained steps": 93312, "Timestamp in ms": 1701470779991, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859723698193412, "Avg loss": 0.40624885191209614, "Avg value loss": 0.12255731064942665, "Avg policy loss": 0.2836915380321443, "Total num played games": 47050, "Total num trained steps": 93440, "Timestamp in ms": 1701470839141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886928799149841, "Avg loss": 0.3047716178698465, "Avg value loss": 0.04876280567259528, "Avg policy loss": 0.2560088128084317, "Total num played games": 47050, "Total num trained steps": 93568, "Timestamp in ms": 1701470896688, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 137.20937054418027, "Avg game time in secs": 1.875030931973015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.25, "played_steps": 0.26}, "Total num played games": 47104, "Total num trained steps": 93593, "Timestamp in ms": 1701470908195, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873584185296738, "Avg loss": 0.43702598800882697, "Avg value loss": 0.16484051404404454, "Avg policy loss": 0.2721854696283117, "Total num played games": 47146, "Total num trained steps": 93696, "Timestamp in ms": 1701470956482, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 90.85214089602232, "Avg game time in secs": 2.3027328169555403, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.45, "agent_stopped_0": 0.6}, "Total num played games": 47232, "Total num trained steps": 93789, "Timestamp in ms": 1701470999048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861134631668078, "Avg loss": 0.3939976361580193, "Avg value loss": 0.12736204656539485, "Avg policy loss": 0.26663559197913855, "Total num played games": 47240, "Total num trained steps": 93824, "Timestamp in ms": 1701471015345, "logtype": "training_step"}
{"Total num played games": 47240, "Total num trained steps": 93889, "Timestamp in ms": 1701471056860, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.515625}
{"Ratio train steps to played games": 1.9848734524865848, "Avg loss": 0.40742316632531583, "Avg value loss": 0.13367802783614025, "Avg policy loss": 0.27374513971153647, "Total num played games": 47334, "Total num trained steps": 93952, "Timestamp in ms": 1701471088650, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875776397515528, "Avg loss": 0.3328404547646642, "Avg value loss": 0.06759315071394667, "Avg policy loss": 0.2652473010821268, "Total num played games": 47334, "Total num trained steps": 94080, "Timestamp in ms": 1701471147676, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 184.4777402188629, "Avg game time in secs": 2.117552956289728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.36, "agent_stopped_0": 0.66}, "Total num played games": 47360, "Total num trained steps": 94161, "Timestamp in ms": 1701471183526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862534261016234, "Avg loss": 0.3928343094885349, "Avg value loss": 0.13392987972474657, "Avg policy loss": 0.2589044302003458, "Total num played games": 47430, "Total num trained steps": 94208, "Timestamp in ms": 1701471204535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889521399957832, "Avg loss": 0.3455102088628337, "Avg value loss": 0.07577567821135744, "Avg policy loss": 0.26973453164100647, "Total num played games": 47430, "Total num trained steps": 94336, "Timestamp in ms": 1701471264037, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 88.45101335830986, "Avg game time in secs": 2.1113561877718894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.37}, "Total num played games": 47488, "Total num trained steps": 94354, "Timestamp in ms": 1701471271977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877114720983082, "Avg loss": 0.42128927970770746, "Avg value loss": 0.1517884763306938, "Avg policy loss": 0.2695008021546528, "Total num played games": 47524, "Total num trained steps": 94464, "Timestamp in ms": 1701471322172, "logtype": "training_step"}
{"Total num played games": 47524, "Total num trained steps": 94490, "Timestamp in ms": 1701471347470, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9609375}
{"Avg objective": 21.8359375, "Games time in secs": 79.64865759946406, "Avg game time in secs": 2.2925995031546336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 47616, "Total num trained steps": 94498, "Timestamp in ms": 1701471351626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864757024654542, "Avg loss": 0.4423629615921527, "Avg value loss": 0.17513560160296038, "Avg policy loss": 0.2672273612115532, "Total num played games": 47618, "Total num trained steps": 94592, "Timestamp in ms": 1701471397054, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891637616027553, "Avg loss": 0.3256801088573411, "Avg value loss": 0.06557705922750756, "Avg policy loss": 0.2601030516671017, "Total num played games": 47618, "Total num trained steps": 94720, "Timestamp in ms": 1701471455473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987844238588255, "Avg loss": 0.4400765069294721, "Avg value loss": 0.16671263036550954, "Avg policy loss": 0.2733638791833073, "Total num played games": 47714, "Total num trained steps": 94848, "Timestamp in ms": 1701471513181, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 193.9232506863773, "Avg game time in secs": 2.1174001742037944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.39}, "Total num played games": 47744, "Total num trained steps": 94920, "Timestamp in ms": 1701471545549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866131191432397, "Avg loss": 0.4077842684928328, "Avg value loss": 0.1422468990786001, "Avg policy loss": 0.2655373658053577, "Total num played games": 47808, "Total num trained steps": 94976, "Timestamp in ms": 1701471570119, "logtype": "training_step"}
{"Total num played games": 47808, "Total num trained steps": 95090, "Timestamp in ms": 1701471635170, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.73046875}
{"Avg objective": 20.6484375, "Games time in secs": 93.01805912144482, "Avg game time in secs": 2.0668361217249185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.37}, "Total num played games": 47872, "Total num trained steps": 95097, "Timestamp in ms": 1701471638567, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853868314475387, "Avg loss": 0.35651940084062517, "Avg value loss": 0.09479507536161691, "Avg policy loss": 0.26172432792373, "Total num played games": 47902, "Total num trained steps": 95104, "Timestamp in ms": 1701471641532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880589536971316, "Avg loss": 0.40862107812426984, "Avg value loss": 0.13824566989205778, "Avg policy loss": 0.2703754104441032, "Total num played games": 47902, "Total num trained steps": 95232, "Timestamp in ms": 1701471698801, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 92.86285547725856, "Avg game time in secs": 2.4432461286633043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 48000, "Total num trained steps": 95306, "Timestamp in ms": 1701471731436, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865838923378192, "Avg loss": 0.38571040821261704, "Avg value loss": 0.12000543269095942, "Avg policy loss": 0.2657049766276032, "Total num played games": 48002, "Total num trained steps": 95360, "Timestamp in ms": 1701471755580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892296154326903, "Avg loss": 0.3490870438981801, "Avg value loss": 0.07600535015808418, "Avg policy loss": 0.2730816930998117, "Total num played games": 48002, "Total num trained steps": 95488, "Timestamp in ms": 1701471813830, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987920495654705, "Avg loss": 0.5144466436468065, "Avg value loss": 0.21912875966518186, "Avg policy loss": 0.2953178840689361, "Total num played games": 48098, "Total num trained steps": 95616, "Timestamp in ms": 1701471871685, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 172.30232234299183, "Avg game time in secs": 2.2498405808000825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.46, "agent_stopped_0": 0.61}, "Total num played games": 48128, "Total num trained steps": 95689, "Timestamp in ms": 1701471903733, "logtype": "played_game"}
{"Total num played games": 48192, "Total num trained steps": 95690, "Timestamp in ms": 1701471918694, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6953125}
{"Avg objective": 20.6640625, "Games time in secs": 18.481414828449488, "Avg game time in secs": 2.12123402209545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 48256, "Total num trained steps": 95697, "Timestamp in ms": 1701471922214, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828314625357246, "Avg loss": 0.5410446966998279, "Avg value loss": 0.24501407315256074, "Avg policy loss": 0.2960306212771684, "Total num played games": 48286, "Total num trained steps": 95744, "Timestamp in ms": 1701471943641, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855030443606843, "Avg loss": 0.3870242980774492, "Avg value loss": 0.09861827228451148, "Avg policy loss": 0.2884060265496373, "Total num played games": 48286, "Total num trained steps": 95872, "Timestamp in ms": 1701471999878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881539162490163, "Avg loss": 0.3326679649762809, "Avg value loss": 0.05430431276909076, "Avg policy loss": 0.27836365113034844, "Total num played games": 48286, "Total num trained steps": 96000, "Timestamp in ms": 1701472057973, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869367507234394, "Avg loss": 0.41340164898429066, "Avg value loss": 0.12724696595978457, "Avg policy loss": 0.28615468100178987, "Total num played games": 48380, "Total num trained steps": 96128, "Timestamp in ms": 1701472116605, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 250.6397073175758, "Avg game time in secs": 2.4734554678871064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 48384, "Total num trained steps": 96251, "Timestamp in ms": 1701472172854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860520777452235, "Avg loss": 0.3742508930154145, "Avg value loss": 0.07563459977973253, "Avg policy loss": 0.2986162941670045, "Total num played games": 48464, "Total num trained steps": 96256, "Timestamp in ms": 1701472175061, "logtype": "training_step"}
{"Total num played games": 48474, "Total num trained steps": 96292, "Timestamp in ms": 1701472203402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.84375}
{"Avg objective": 20.6484375, "Games time in secs": 33.53541754744947, "Avg game time in secs": 2.0697681810852373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.34}, "Total num played games": 48512, "Total num trained steps": 96298, "Timestamp in ms": 1701472206390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845165541097018, "Avg loss": 0.6593878248240799, "Avg value loss": 0.3324754641507752, "Avg policy loss": 0.32691236259415746, "Total num played games": 48568, "Total num trained steps": 96384, "Timestamp in ms": 1701472245986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871520342612419, "Avg loss": 0.39020925271324813, "Avg value loss": 0.0796321150555741, "Avg policy loss": 0.31057713786140084, "Total num played games": 48568, "Total num trained steps": 96512, "Timestamp in ms": 1701472304740, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 152.54050221852958, "Avg game time in secs": 2.1191688650869764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 48640, "Total num trained steps": 96631, "Timestamp in ms": 1701472358930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986025482942869, "Avg loss": 0.3631175709888339, "Avg value loss": 0.0719710850098636, "Avg policy loss": 0.2911464854842052, "Total num played games": 48660, "Total num trained steps": 96640, "Timestamp in ms": 1701472363037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988574246845588, "Avg loss": 0.42257213685661554, "Avg value loss": 0.11381761988741346, "Avg policy loss": 0.3087545152520761, "Total num played games": 48662, "Total num trained steps": 96768, "Timestamp in ms": 1701472418451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873451472639265, "Avg loss": 0.44336970057338476, "Avg value loss": 0.13661052274983376, "Avg policy loss": 0.306759174214676, "Total num played games": 48756, "Total num trained steps": 96896, "Timestamp in ms": 1701472478307, "logtype": "training_step"}
{"Total num played games": 48756, "Total num trained steps": 96896, "Timestamp in ms": 1701472488698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.546875}
{"Avg objective": 19.7421875, "Games time in secs": 131.88912264630198, "Avg game time in secs": 2.3428406012099003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.43}, "Total num played games": 48768, "Total num trained steps": 96899, "Timestamp in ms": 1701472490820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861617195496417, "Avg loss": 0.5220293824095279, "Avg value loss": 0.19069402513559908, "Avg policy loss": 0.3313353550620377, "Total num played games": 48850, "Total num trained steps": 97024, "Timestamp in ms": 1701472547586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887819856704196, "Avg loss": 0.3575334020424634, "Avg value loss": 0.050043864554027095, "Avg policy loss": 0.30748953903093934, "Total num played games": 48850, "Total num trained steps": 97152, "Timestamp in ms": 1701472606078, "logtype": "training_step"}
{"Avg objective": 20.34375, "Games time in secs": 133.7694674655795, "Avg game time in secs": 2.020237090968294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.32}, "Total num played games": 48896, "Total num trained steps": 97194, "Timestamp in ms": 1701472624589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874964246312263, "Avg loss": 0.44134327420033514, "Avg value loss": 0.1310037466173526, "Avg policy loss": 0.3103395269718021, "Total num played games": 48946, "Total num trained steps": 97280, "Timestamp in ms": 1701472663273, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 87.95630843564868, "Avg game time in secs": 2.278857208424597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 49024, "Total num trained steps": 97387, "Timestamp in ms": 1701472712546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862158965784429, "Avg loss": 0.4325851856265217, "Avg value loss": 0.1268503658066038, "Avg policy loss": 0.30573481984902173, "Total num played games": 49042, "Total num trained steps": 97408, "Timestamp in ms": 1701472722198, "logtype": "training_step"}
{"Total num played games": 49042, "Total num trained steps": 97499, "Timestamp in ms": 1701472776818, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.296875}
{"Ratio train steps to played games": 1.9850211657440573, "Avg loss": 0.5190643719397485, "Avg value loss": 0.1940546814003028, "Avg policy loss": 0.3250096912961453, "Total num played games": 49136, "Total num trained steps": 97536, "Timestamp in ms": 1701472794358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876058287202865, "Avg loss": 0.4176142367068678, "Avg value loss": 0.09660162575892173, "Avg policy loss": 0.3210126089397818, "Total num played games": 49136, "Total num trained steps": 97664, "Timestamp in ms": 1701472851849, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 184.13580641523004, "Avg game time in secs": 2.279501925149816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 49152, "Total num trained steps": 97764, "Timestamp in ms": 1701472896682, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864310379849686, "Avg loss": 0.42728976160287857, "Avg value loss": 0.11643257626565173, "Avg policy loss": 0.31085718609392643, "Total num played games": 49230, "Total num trained steps": 97792, "Timestamp in ms": 1701472908880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890107657932155, "Avg loss": 0.38978246657643467, "Avg value loss": 0.09139747501467355, "Avg policy loss": 0.2983849924057722, "Total num played games": 49230, "Total num trained steps": 97920, "Timestamp in ms": 1701472966403, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 85.03606073744595, "Avg game time in secs": 2.0928241082438035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.31}, "Total num played games": 49280, "Total num trained steps": 97954, "Timestamp in ms": 1701472981718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878355364528424, "Avg loss": 0.5395490603987128, "Avg value loss": 0.22812215803423896, "Avg policy loss": 0.31142690184060484, "Total num played games": 49324, "Total num trained steps": 98048, "Timestamp in ms": 1701473023720, "logtype": "training_step"}
{"Total num played games": 49324, "Total num trained steps": 98100, "Timestamp in ms": 1701473059304, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.375}
{"Avg objective": 21.03125, "Games time in secs": 81.50775385834277, "Avg game time in secs": 2.16219125931093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 49408, "Total num trained steps": 98108, "Timestamp in ms": 1701473063226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866243069326965, "Avg loss": 0.485182500211522, "Avg value loss": 0.16066275880439207, "Avg policy loss": 0.32451974076684564, "Total num played games": 49418, "Total num trained steps": 98176, "Timestamp in ms": 1701473094761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892346918126997, "Avg loss": 0.3783337592612952, "Avg value loss": 0.06936045172915328, "Avg policy loss": 0.3089733086526394, "Total num played games": 49418, "Total num trained steps": 98304, "Timestamp in ms": 1701473153241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879630003635336, "Avg loss": 0.4885115441866219, "Avg value loss": 0.169213045417564, "Avg policy loss": 0.31929849938023835, "Total num played games": 49514, "Total num trained steps": 98432, "Timestamp in ms": 1701473212509, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 189.88165389746428, "Avg game time in secs": 2.12505999111454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.44, "agent_stopped_0": 0.59}, "Total num played games": 49536, "Total num trained steps": 98521, "Timestamp in ms": 1701473253107, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866962305986697, "Avg loss": 0.44456085260026157, "Avg value loss": 0.14216417787247337, "Avg policy loss": 0.30239666998386383, "Total num played games": 49610, "Total num trained steps": 98560, "Timestamp in ms": 1701473270261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892763555734732, "Avg loss": 0.3790279794484377, "Avg value loss": 0.08232696048798971, "Avg policy loss": 0.2967010230058804, "Total num played games": 49610, "Total num trained steps": 98688, "Timestamp in ms": 1701473328440, "logtype": "training_step"}
{"Total num played games": 49610, "Total num trained steps": 98702, "Timestamp in ms": 1701473347505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5546875}
{"Avg objective": 21.0078125, "Games time in secs": 97.53421509638429, "Avg game time in secs": 2.2084076354803983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.43}, "Total num played games": 49664, "Total num trained steps": 98708, "Timestamp in ms": 1701473350642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880894897794945, "Avg loss": 0.448357991874218, "Avg value loss": 0.15386295641656034, "Avg policy loss": 0.29449503403156996, "Total num played games": 49704, "Total num trained steps": 98816, "Timestamp in ms": 1701473399054, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 89.63185545615852, "Avg game time in secs": 2.18698956532171, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 49792, "Total num trained steps": 98905, "Timestamp in ms": 1701473440274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868273092369477, "Avg loss": 0.44447558908723295, "Avg value loss": 0.15207976941019297, "Avg policy loss": 0.2923958150204271, "Total num played games": 49800, "Total num trained steps": 98944, "Timestamp in ms": 1701473458083, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893975903614458, "Avg loss": 0.3918669687118381, "Avg value loss": 0.09683935838984326, "Avg policy loss": 0.29502761154435575, "Total num played games": 49800, "Total num trained steps": 99072, "Timestamp in ms": 1701473515796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880556334923243, "Avg loss": 0.44696872122585773, "Avg value loss": 0.15406848266138695, "Avg policy loss": 0.2929002376040444, "Total num played games": 49898, "Total num trained steps": 99200, "Timestamp in ms": 1701473573171, "logtype": "training_step"}
{"Avg objective": 20.9921875, "Games time in secs": 171.4272088035941, "Avg game time in secs": 2.1040536194777815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 49920, "Total num trained steps": 99288, "Timestamp in ms": 1701473611701, "logtype": "played_game"}
{"Total num played games": 49994, "Total num trained steps": 99306, "Timestamp in ms": 1701473636050, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.09375}
{"Avg objective": 21.5546875, "Games time in secs": 28.012191221117973, "Avg game time in secs": 2.259870568261249, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 50048, "Total num trained steps": 99312, "Timestamp in ms": 1701473639713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830697971570037, "Avg loss": 0.46135983639396727, "Avg value loss": 0.17881207013851963, "Avg policy loss": 0.2825477694859728, "Total num played games": 50088, "Total num trained steps": 99328, "Timestamp in ms": 1701473647046, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856252994729275, "Avg loss": 0.4805972105823457, "Avg value loss": 0.16409568829112686, "Avg policy loss": 0.31650152150541544, "Total num played games": 50088, "Total num trained steps": 99456, "Timestamp in ms": 1701473705840, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881808017888516, "Avg loss": 0.3583264136686921, "Avg value loss": 0.0646561463654507, "Avg policy loss": 0.2936702669830993, "Total num played games": 50088, "Total num trained steps": 99584, "Timestamp in ms": 1701473763145, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 162.91358299180865, "Avg game time in secs": 2.3866428103210637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 50176, "Total num trained steps": 99672, "Timestamp in ms": 1701473802627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869281045751634, "Avg loss": 0.42023342091124505, "Avg value loss": 0.12639545957790688, "Avg policy loss": 0.293837963254191, "Total num played games": 50184, "Total num trained steps": 99712, "Timestamp in ms": 1701473819787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989478718316595, "Avg loss": 0.38224477390758693, "Avg value loss": 0.08128625073004514, "Avg policy loss": 0.30095851980149746, "Total num played games": 50184, "Total num trained steps": 99840, "Timestamp in ms": 1701473877272, "logtype": "training_step"}
{"Total num played games": 50284, "Total num trained steps": 99908, "Timestamp in ms": 1701473925247, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.02734375}
{"Avg objective": 19.2421875, "Games time in secs": 125.34343924932182, "Avg game time in secs": 2.0764710757212015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.38, "agent_stopped_0": 0.62}, "Total num played games": 50304, "Total num trained steps": 99912, "Timestamp in ms": 1701473927971, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843582516177696, "Avg loss": 0.6025790229905397, "Avg value loss": 0.2767725021985825, "Avg policy loss": 0.3258065222762525, "Total num played games": 50378, "Total num trained steps": 99968, "Timestamp in ms": 1701473952898, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868990432331572, "Avg loss": 0.4033298445865512, "Avg value loss": 0.08648706212989055, "Avg policy loss": 0.31684278429020196, "Total num played games": 50378, "Total num trained steps": 100096, "Timestamp in ms": 1701474010352, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989439834848545, "Avg loss": 0.3560526280198246, "Avg value loss": 0.051883281994378194, "Avg policy loss": 0.3041693465784192, "Total num played games": 50378, "Total num trained steps": 100224, "Timestamp in ms": 1701474068938, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 152.2787382043898, "Avg game time in secs": 2.13999274080561, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.38}, "Total num played games": 50432, "Total num trained steps": 100250, "Timestamp in ms": 1701474080250, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882707243620226, "Avg loss": 0.48996947589330375, "Avg value loss": 0.1707768854976166, "Avg policy loss": 0.31919258763082325, "Total num played games": 50472, "Total num trained steps": 100352, "Timestamp in ms": 1701474125508, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 87.14378912746906, "Avg game time in secs": 2.3252479453221895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.48, "agent_stopped_0": 0.52}, "Total num played games": 50560, "Total num trained steps": 100440, "Timestamp in ms": 1701474167393, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870075937351686, "Avg loss": 0.47532186040189117, "Avg value loss": 0.16824523644754663, "Avg policy loss": 0.3070766214514151, "Total num played games": 50568, "Total num trained steps": 100480, "Timestamp in ms": 1701474184543, "logtype": "training_step"}
{"Total num played games": 50568, "Total num trained steps": 100511, "Timestamp in ms": 1701474211043, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.125}
{"Ratio train steps to played games": 1.9858671193399393, "Avg loss": 0.5065112705342472, "Avg value loss": 0.17958725593052804, "Avg policy loss": 0.32692401530221105, "Total num played games": 50662, "Total num trained steps": 100608, "Timestamp in ms": 1701474256593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883936678378271, "Avg loss": 0.36697772331535816, "Avg value loss": 0.0668234821932856, "Avg policy loss": 0.3001542399870232, "Total num played games": 50662, "Total num trained steps": 100736, "Timestamp in ms": 1701474315276, "logtype": "training_step"}
{"Avg objective": 20.671875, "Games time in secs": 183.98825263790786, "Avg game time in secs": 2.1116780720913084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.39, "agent_stopped_0": 0.65}, "Total num played games": 50688, "Total num trained steps": 100817, "Timestamp in ms": 1701474351382, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872330364882969, "Avg loss": 0.4380971882492304, "Avg value loss": 0.13676055578980595, "Avg policy loss": 0.30133663467131555, "Total num played games": 50756, "Total num trained steps": 100864, "Timestamp in ms": 1701474372761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897352037197573, "Avg loss": 0.37915212486404926, "Avg value loss": 0.08111300109885633, "Avg policy loss": 0.29803912271745503, "Total num played games": 50756, "Total num trained steps": 100992, "Timestamp in ms": 1701474431161, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 85.94184999726713, "Avg game time in secs": 2.2412628698075423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 50816, "Total num trained steps": 101006, "Timestamp in ms": 1701474437324, "logtype": "played_game"}
{"Total num played games": 50850, "Total num trained steps": 101112, "Timestamp in ms": 1701474496971, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.28515625}
{"Ratio train steps to played games": 1.9857821766623462, "Avg loss": 0.48937747860327363, "Avg value loss": 0.177459219325101, "Avg policy loss": 0.31191825529094785, "Total num played games": 50916, "Total num trained steps": 101120, "Timestamp in ms": 1701474500972, "logtype": "training_step"}
{"Avg objective": 20.390625, "Games time in secs": 66.08561083115637, "Avg game time in secs": 2.499214178606053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 50944, "Total num trained steps": 101125, "Timestamp in ms": 1701474503410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874371859296482, "Avg loss": 0.46359749301336706, "Avg value loss": 0.14699098450364545, "Avg policy loss": 0.3166065097320825, "Total num played games": 50944, "Total num trained steps": 101248, "Timestamp in ms": 1701474558686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899497487437185, "Avg loss": 0.3561204015277326, "Avg value loss": 0.05902861195500009, "Avg policy loss": 0.2970917890779674, "Total num played games": 50944, "Total num trained steps": 101376, "Timestamp in ms": 1701474615273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988792664289353, "Avg loss": 0.46339057432487607, "Avg value loss": 0.14891118364175782, "Avg policy loss": 0.31447939190547913, "Total num played games": 51038, "Total num trained steps": 101504, "Timestamp in ms": 1701474672332, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 199.2178540173918, "Avg game time in secs": 2.1422794168029213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.39}, "Total num played games": 51072, "Total num trained steps": 101569, "Timestamp in ms": 1701474702627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876398341547368, "Avg loss": 0.4553690280299634, "Avg value loss": 0.14722082024673, "Avg policy loss": 0.30814820423256606, "Total num played games": 51132, "Total num trained steps": 101632, "Timestamp in ms": 1701474731712, "logtype": "training_step"}
{"Total num played games": 51132, "Total num trained steps": 101713, "Timestamp in ms": 1701474782592, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.22265625}
{"Avg objective": 21.140625, "Games time in secs": 84.38176560401917, "Avg game time in secs": 2.2668974826665362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 51200, "Total num trained steps": 101721, "Timestamp in ms": 1701474787009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864912349197672, "Avg loss": 0.47339326422661543, "Avg value loss": 0.1624878613220062, "Avg policy loss": 0.31090539996512234, "Total num played games": 51226, "Total num trained steps": 101760, "Timestamp in ms": 1701474804059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988989966032874, "Avg loss": 0.41401201323606074, "Avg value loss": 0.10030358916264959, "Avg policy loss": 0.31370842223986983, "Total num played games": 51226, "Total num trained steps": 101888, "Timestamp in ms": 1701474862417, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877440473870855, "Avg loss": 0.5097201091703027, "Avg value loss": 0.19285402208333835, "Avg policy loss": 0.3168660909868777, "Total num played games": 51322, "Total num trained steps": 102016, "Timestamp in ms": 1701474921011, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 186.2160714622587, "Avg game time in secs": 2.2960527720715618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 51328, "Total num trained steps": 102135, "Timestamp in ms": 1701474973226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866189512992065, "Avg loss": 0.3998025079490617, "Avg value loss": 0.09356211547856219, "Avg policy loss": 0.3062403940130025, "Total num played games": 51416, "Total num trained steps": 102144, "Timestamp in ms": 1701474976759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890310786106034, "Avg loss": 0.5325747772585601, "Avg value loss": 0.20194375334540382, "Avg policy loss": 0.3306310278130695, "Total num played games": 51418, "Total num trained steps": 102272, "Timestamp in ms": 1701475033315, "logtype": "training_step"}
{"Total num played games": 51418, "Total num trained steps": 102313, "Timestamp in ms": 1701475065058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.26171875}
{"Avg objective": 19.546875, "Games time in secs": 94.76285907253623, "Avg game time in secs": 2.0949694631417515, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 51456, "Total num trained steps": 102319, "Timestamp in ms": 1701475067989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878863177512036, "Avg loss": 0.459697826532647, "Avg value loss": 0.13068750378442928, "Avg policy loss": 0.32901032525114715, "Total num played games": 51512, "Total num trained steps": 102400, "Timestamp in ms": 1701475104659, "logtype": "training_step"}
{"Avg objective": 20.671875, "Games time in secs": 90.22200691141188, "Avg game time in secs": 2.317240228803712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 51584, "Total num trained steps": 102520, "Timestamp in ms": 1701475158211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867457272410185, "Avg loss": 0.40742510627023876, "Avg value loss": 0.090976121078711, "Avg policy loss": 0.31644898804370314, "Total num played games": 51606, "Total num trained steps": 102528, "Timestamp in ms": 1701475161740, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892260589853894, "Avg loss": 0.44585307547822595, "Avg value loss": 0.13122237153584138, "Avg policy loss": 0.3146307042334229, "Total num played games": 51606, "Total num trained steps": 102656, "Timestamp in ms": 1701475220107, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880082008432942, "Avg loss": 0.47520301467739046, "Avg value loss": 0.16624262719415128, "Avg policy loss": 0.3089603838743642, "Total num played games": 51702, "Total num trained steps": 102784, "Timestamp in ms": 1701475276978, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 168.1266979686916, "Avg game time in secs": 2.3286514723440632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 51712, "Total num trained steps": 102896, "Timestamp in ms": 1701475326338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868715730944475, "Avg loss": 0.39093689643777907, "Avg value loss": 0.08757883845828474, "Avg policy loss": 0.3033580589108169, "Total num played games": 51796, "Total num trained steps": 102912, "Timestamp in ms": 1701475333224, "logtype": "training_step"}
{"Total num played games": 51796, "Total num trained steps": 102915, "Timestamp in ms": 1701475345821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.02734375}
{"Avg objective": 20.765625, "Games time in secs": 22.588437920436263, "Avg game time in secs": 2.0723111029947177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.39}, "Total num played games": 51840, "Total num trained steps": 102920, "Timestamp in ms": 1701475348926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857197918674119, "Avg loss": 0.548814038047567, "Avg value loss": 0.2245539771975018, "Avg policy loss": 0.3242600620724261, "Total num played games": 51890, "Total num trained steps": 103040, "Timestamp in ms": 1701475403872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882058200038544, "Avg loss": 0.35271414276212454, "Avg value loss": 0.05979560621199198, "Avg policy loss": 0.2929185383254662, "Total num played games": 51890, "Total num trained steps": 103168, "Timestamp in ms": 1701475461485, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 161.3621388822794, "Avg game time in secs": 2.148398971388815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.43}, "Total num played games": 51968, "Total num trained steps": 103274, "Timestamp in ms": 1701475510288, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869964990574385, "Avg loss": 0.40349427273031324, "Avg value loss": 0.12051698233699426, "Avg policy loss": 0.282977290218696, "Total num played games": 51986, "Total num trained steps": 103296, "Timestamp in ms": 1701475519928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894587004193436, "Avg loss": 0.4077722489601001, "Avg value loss": 0.1014934784907382, "Avg policy loss": 0.3062787699745968, "Total num played games": 51986, "Total num trained steps": 103424, "Timestamp in ms": 1701475577849, "logtype": "training_step"}
{"Total num played games": 52082, "Total num trained steps": 103519, "Timestamp in ms": 1701475631604, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.98828125}
{"Avg objective": 21.3125, "Games time in secs": 123.71335464529693, "Avg game time in secs": 2.1040418240445433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 52096, "Total num trained steps": 103523, "Timestamp in ms": 1701475634002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846672799754677, "Avg loss": 0.5225793342106044, "Avg value loss": 0.22522982652299106, "Avg policy loss": 0.29734950535930693, "Total num played games": 52176, "Total num trained steps": 103552, "Timestamp in ms": 1701475648078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987120515179393, "Avg loss": 0.4088306659832597, "Avg value loss": 0.10425054436200298, "Avg policy loss": 0.3045801243279129, "Total num played games": 52176, "Total num trained steps": 103680, "Timestamp in ms": 1701475705357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989573750383318, "Avg loss": 0.3499272890621796, "Avg value loss": 0.06081136001739651, "Avg policy loss": 0.28911593137308955, "Total num played games": 52176, "Total num trained steps": 103808, "Timestamp in ms": 1701475763415, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 145.82608673535287, "Avg game time in secs": 2.13942112470977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.37, "agent_stopped_0": 0.66}, "Total num played games": 52224, "Total num trained steps": 103846, "Timestamp in ms": 1701475779828, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884446145016261, "Avg loss": 0.44237948511727154, "Avg value loss": 0.14916827525303233, "Avg policy loss": 0.2932112138951197, "Total num played games": 52270, "Total num trained steps": 103936, "Timestamp in ms": 1701475819915, "logtype": "training_step"}
{"Avg objective": 20.390625, "Games time in secs": 84.7640272770077, "Avg game time in secs": 2.1868766768020578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 52352, "Total num trained steps": 104036, "Timestamp in ms": 1701475864592, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873195325032464, "Avg loss": 0.41047488478943706, "Avg value loss": 0.11882822363986634, "Avg policy loss": 0.2916466605383903, "Total num played games": 52364, "Total num trained steps": 104064, "Timestamp in ms": 1701475877360, "logtype": "training_step"}
{"Total num played games": 52364, "Total num trained steps": 104119, "Timestamp in ms": 1701475914116, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.83203125}
{"Ratio train steps to played games": 1.9861984825956003, "Avg loss": 0.5076090632937849, "Avg value loss": 0.1970270796737168, "Avg policy loss": 0.31058198562823236, "Total num played games": 52458, "Total num trained steps": 104192, "Timestamp in ms": 1701475947816, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886385298715163, "Avg loss": 0.36267828522250056, "Avg value loss": 0.06639391777571291, "Avg policy loss": 0.29628436744678766, "Total num played games": 52458, "Total num trained steps": 104320, "Timestamp in ms": 1701476006465, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 180.91971116885543, "Avg game time in secs": 2.1137591160077136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.35}, "Total num played games": 52480, "Total num trained steps": 104408, "Timestamp in ms": 1701476045512, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987441488754424, "Avg loss": 0.4224681833293289, "Avg value loss": 0.13562327591353096, "Avg policy loss": 0.286844908259809, "Total num played games": 52554, "Total num trained steps": 104448, "Timestamp in ms": 1701476062724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898770788141722, "Avg loss": 0.35530485038179904, "Avg value loss": 0.06861192898941226, "Avg policy loss": 0.2866929199080914, "Total num played games": 52554, "Total num trained steps": 104576, "Timestamp in ms": 1701476120470, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 86.32061042636633, "Avg game time in secs": 2.1547730121092172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 52608, "Total num trained steps": 104602, "Timestamp in ms": 1701476131833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887555082814161, "Avg loss": 0.4739224824588746, "Avg value loss": 0.1721320049255155, "Avg policy loss": 0.30179047561250627, "Total num played games": 52648, "Total num trained steps": 104704, "Timestamp in ms": 1701476177988, "logtype": "training_step"}
{"Total num played games": 52648, "Total num trained steps": 104721, "Timestamp in ms": 1701476197733, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.81640625}
{"Avg objective": 20.9375, "Games time in secs": 71.0041486620903, "Avg game time in secs": 2.2899147321877535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 52736, "Total num trained steps": 104731, "Timestamp in ms": 1701476202837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987637935611088, "Avg loss": 0.4758266438730061, "Avg value loss": 0.1689806934155058, "Avg policy loss": 0.3068459511268884, "Total num played games": 52742, "Total num trained steps": 104832, "Timestamp in ms": 1701476246762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900648439573774, "Avg loss": 0.3402928411960602, "Avg value loss": 0.0524624454556033, "Avg policy loss": 0.2878303927136585, "Total num played games": 52742, "Total num trained steps": 104960, "Timestamp in ms": 1701476302960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888716454067148, "Avg loss": 0.4494068520143628, "Avg value loss": 0.15348184781032614, "Avg policy loss": 0.2959250033600256, "Total num played games": 52838, "Total num trained steps": 105088, "Timestamp in ms": 1701476360081, "logtype": "training_step"}
{"Avg objective": 21.234375, "Games time in secs": 194.74444233067334, "Avg game time in secs": 1.9905044715414988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.38, "agent_stopped_0": 0.63}, "Total num played games": 52864, "Total num trained steps": 105170, "Timestamp in ms": 1701476397582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877578780321923, "Avg loss": 0.43058975611347705, "Avg value loss": 0.1450778621074278, "Avg policy loss": 0.2855118931038305, "Total num played games": 52932, "Total num trained steps": 105216, "Timestamp in ms": 1701476417690, "logtype": "training_step"}
{"Total num played games": 52932, "Total num trained steps": 105325, "Timestamp in ms": 1701476477297, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8671875}
{"Avg objective": 21.0, "Games time in secs": 83.25212239660323, "Avg game time in secs": 2.1819865016732365, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.52}, "Total num played games": 52992, "Total num trained steps": 105332, "Timestamp in ms": 1701476480834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866480594425375, "Avg loss": 0.3902214558329433, "Avg value loss": 0.10832594640669413, "Avg policy loss": 0.28189550805836916, "Total num played games": 53026, "Total num trained steps": 105344, "Timestamp in ms": 1701476485957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890619695998188, "Avg loss": 0.4004053877433762, "Avg value loss": 0.11989168936270289, "Avg policy loss": 0.2805136980023235, "Total num played games": 53026, "Total num trained steps": 105472, "Timestamp in ms": 1701476544482, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 102.31751723587513, "Avg game time in secs": 2.3712646539206617, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 53120, "Total num trained steps": 105555, "Timestamp in ms": 1701476583151, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879518072289157, "Avg loss": 0.38975297764409333, "Avg value loss": 0.11103567341342568, "Avg policy loss": 0.2787173044634983, "Total num played games": 53120, "Total num trained steps": 105600, "Timestamp in ms": 1701476603672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903614457831325, "Avg loss": 0.34501047839876264, "Avg value loss": 0.06988604654907249, "Avg policy loss": 0.275124431704171, "Total num played games": 53120, "Total num trained steps": 105728, "Timestamp in ms": 1701476661101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892509489983838, "Avg loss": 0.3956196744693443, "Avg value loss": 0.11615246575092897, "Avg policy loss": 0.2794672098243609, "Total num played games": 53214, "Total num trained steps": 105856, "Timestamp in ms": 1701476716651, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 162.64770201593637, "Avg game time in secs": 1.9528577062446857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.34}, "Total num played games": 53248, "Total num trained steps": 105921, "Timestamp in ms": 1701476745799, "logtype": "played_game"}
{"Total num played games": 53308, "Total num trained steps": 105928, "Timestamp in ms": 1701476760530, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5625}
{"Avg objective": 20.75, "Games time in secs": 18.834041140973568, "Avg game time in secs": 2.414812601855374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 53376, "Total num trained steps": 105937, "Timestamp in ms": 1701476764634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846447698588068, "Avg loss": 0.5735594269353896, "Avg value loss": 0.2754744491248857, "Avg policy loss": 0.29808497754856944, "Total num played games": 53402, "Total num trained steps": 105984, "Timestamp in ms": 1701476786495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870416838320661, "Avg loss": 0.40768517774995416, "Avg value loss": 0.10873938357690349, "Avg policy loss": 0.2989457960939035, "Total num played games": 53402, "Total num trained steps": 106112, "Timestamp in ms": 1701476844912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894385978053257, "Avg loss": 0.33788515522610396, "Avg value loss": 0.05378302506869659, "Avg policy loss": 0.28410213033203036, "Total num played games": 53402, "Total num trained steps": 106240, "Timestamp in ms": 1701476900343, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883168835053089, "Avg loss": 0.4129713320871815, "Avg value loss": 0.1321782043960411, "Avg policy loss": 0.2807931317947805, "Total num played games": 53496, "Total num trained steps": 106368, "Timestamp in ms": 1701476956740, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 243.10295252501965, "Avg game time in secs": 2.3177227708656574, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 53504, "Total num trained steps": 106483, "Timestamp in ms": 1701477007737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872364247061018, "Avg loss": 0.4118323151487857, "Avg value loss": 0.1300737638375722, "Avg policy loss": 0.2817585516022518, "Total num played games": 53590, "Total num trained steps": 106496, "Timestamp in ms": 1701477013241, "logtype": "training_step"}
{"Total num played games": 53590, "Total num trained steps": 106531, "Timestamp in ms": 1701477042848, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.62890625}
{"Avg objective": 20.7421875, "Games time in secs": 38.232920380309224, "Avg game time in secs": 1.9936579390778206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.35}, "Total num played games": 53632, "Total num trained steps": 106537, "Timestamp in ms": 1701477045970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861411221220475, "Avg loss": 0.5556430311407894, "Avg value loss": 0.24727813864592463, "Avg policy loss": 0.3083648926112801, "Total num played games": 53684, "Total num trained steps": 106624, "Timestamp in ms": 1701477085326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885068176737948, "Avg loss": 0.3730788801331073, "Avg value loss": 0.07402464005281217, "Avg policy loss": 0.2990542413899675, "Total num played games": 53684, "Total num trained steps": 106752, "Timestamp in ms": 1701477142268, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 146.8047257401049, "Avg game time in secs": 2.325526813074248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 53760, "Total num trained steps": 106864, "Timestamp in ms": 1701477192775, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874112090445908, "Avg loss": 0.4008564763935283, "Avg value loss": 0.10697203560266644, "Avg policy loss": 0.29388444393407553, "Total num played games": 53778, "Total num trained steps": 106880, "Timestamp in ms": 1701477200345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898099594629775, "Avg loss": 0.42204210080672055, "Avg value loss": 0.11451801282237284, "Avg policy loss": 0.30752408783882856, "Total num played games": 53778, "Total num trained steps": 107008, "Timestamp in ms": 1701477258092, "logtype": "training_step"}
{"Total num played games": 53876, "Total num trained steps": 107133, "Timestamp in ms": 1701477328670, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.00390625}
{"Ratio train steps to played games": 1.9885477763753805, "Avg loss": 0.4472962331492454, "Avg value loss": 0.14397635485511273, "Avg policy loss": 0.30331987945828587, "Total num played games": 53876, "Total num trained steps": 107136, "Timestamp in ms": 1701477330234, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 138.12152788229287, "Avg game time in secs": 2.2232168040645774, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.42, "agent_stopped_0": 0.64}, "Total num played games": 53888, "Total num trained steps": 107137, "Timestamp in ms": 1701477330896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874745228830832, "Avg loss": 0.4377700719051063, "Avg value loss": 0.13649316929513589, "Avg policy loss": 0.30127690359950066, "Total num played games": 53970, "Total num trained steps": 107264, "Timestamp in ms": 1701477388197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989827682045581, "Avg loss": 0.3486364777199924, "Avg value loss": 0.05704946132027544, "Avg policy loss": 0.2915870160795748, "Total num played games": 53970, "Total num trained steps": 107392, "Timestamp in ms": 1701477446755, "logtype": "training_step"}
{"Avg objective": 19.0859375, "Games time in secs": 135.00670322962105, "Avg game time in secs": 1.951281057758024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 54016, "Total num trained steps": 107434, "Timestamp in ms": 1701477465903, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886069394096324, "Avg loss": 0.434965725755319, "Avg value loss": 0.14355072868056595, "Avg policy loss": 0.29141499986872077, "Total num played games": 54068, "Total num trained steps": 107520, "Timestamp in ms": 1701477503536, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 88.67818300239742, "Avg game time in secs": 2.162556201015832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.42}, "Total num played games": 54144, "Total num trained steps": 107631, "Timestamp in ms": 1701477554581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875004615782284, "Avg loss": 0.3943202323280275, "Avg value loss": 0.11248030644492246, "Avg policy loss": 0.2818399262614548, "Total num played games": 54162, "Total num trained steps": 107648, "Timestamp in ms": 1701477562906, "logtype": "training_step"}
{"Total num played games": 54162, "Total num trained steps": 107733, "Timestamp in ms": 1701477613049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0390625}
{"Ratio train steps to played games": 1.9864346800353878, "Avg loss": 0.4481809944845736, "Avg value loss": 0.1550014976237435, "Avg policy loss": 0.2931794954929501, "Total num played games": 54256, "Total num trained steps": 107776, "Timestamp in ms": 1701477632776, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98879386611619, "Avg loss": 0.3697613710537553, "Avg value loss": 0.08378940777038224, "Avg policy loss": 0.2859719635453075, "Total num played games": 54256, "Total num trained steps": 107904, "Timestamp in ms": 1701477693572, "logtype": "training_step"}
{"Avg objective": 19.609375, "Games time in secs": 184.8885232936591, "Avg game time in secs": 2.055678025339148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 54272, "Total num trained steps": 108004, "Timestamp in ms": 1701477739470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876361495437151, "Avg loss": 0.39291990688070655, "Avg value loss": 0.11716225193231367, "Avg policy loss": 0.2757576546864584, "Total num played games": 54352, "Total num trained steps": 108032, "Timestamp in ms": 1701477752406, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899911686782454, "Avg loss": 0.37447388586588204, "Avg value loss": 0.08867658139206469, "Avg policy loss": 0.285797304706648, "Total num played games": 54352, "Total num trained steps": 108160, "Timestamp in ms": 1701477810237, "logtype": "training_step"}
{"Avg objective": 19.921875, "Games time in secs": 88.19811383634806, "Avg game time in secs": 2.0857552692468744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 54400, "Total num trained steps": 108198, "Timestamp in ms": 1701477827668, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888333823097266, "Avg loss": 0.44907286926172674, "Avg value loss": 0.1618288045283407, "Avg policy loss": 0.28724406799301505, "Total num played games": 54448, "Total num trained steps": 108288, "Timestamp in ms": 1701477868408, "logtype": "training_step"}
{"Total num played games": 54448, "Total num trained steps": 108333, "Timestamp in ms": 1701477899782, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9921875}
{"Avg objective": 19.734375, "Games time in secs": 76.31591016985476, "Avg game time in secs": 2.2435050023632357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.45, "agent_stopped_0": 0.57}, "Total num played games": 54528, "Total num trained steps": 108340, "Timestamp in ms": 1701477903984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877525576619852, "Avg loss": 0.4447410067077726, "Avg value loss": 0.15845624374924228, "Avg policy loss": 0.2862847583601251, "Total num played games": 54542, "Total num trained steps": 108416, "Timestamp in ms": 1701477938030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900993729602874, "Avg loss": 0.3548708287999034, "Avg value loss": 0.06675892139901407, "Avg policy loss": 0.28811190789565444, "Total num played games": 54542, "Total num trained steps": 108544, "Timestamp in ms": 1701477996006, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890182297386338, "Avg loss": 0.45396316912956536, "Avg value loss": 0.17210129913291894, "Avg policy loss": 0.2818618715973571, "Total num played games": 54636, "Total num trained steps": 108672, "Timestamp in ms": 1701478051697, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 188.07869539037347, "Avg game time in secs": 2.303951841779053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.51, "agent_stopped_0": 0.56}, "Total num played games": 54656, "Total num trained steps": 108765, "Timestamp in ms": 1701478092063, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878681575677848, "Avg loss": 0.40174840728286654, "Avg value loss": 0.11907535782665946, "Avg policy loss": 0.2826730509987101, "Total num played games": 54732, "Total num trained steps": 108800, "Timestamp in ms": 1701478108416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902068259884529, "Avg loss": 0.3747957502491772, "Avg value loss": 0.08372219049488194, "Avg policy loss": 0.2910735618788749, "Total num played games": 54732, "Total num trained steps": 108928, "Timestamp in ms": 1701478164981, "logtype": "training_step"}
{"Total num played games": 54732, "Total num trained steps": 108933, "Timestamp in ms": 1701478180063, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.671875}
{"Avg objective": 20.9453125, "Games time in secs": 91.17330120131373, "Avg game time in secs": 2.131770902109565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 54784, "Total num trained steps": 108940, "Timestamp in ms": 1701478183237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891292452486047, "Avg loss": 0.46288816491141915, "Avg value loss": 0.15990824566688389, "Avg policy loss": 0.30297991691622883, "Total num played games": 54826, "Total num trained steps": 109056, "Timestamp in ms": 1701478234840, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 91.0973454285413, "Avg game time in secs": 2.17316587267851, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 54912, "Total num trained steps": 109148, "Timestamp in ms": 1701478274334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880553532410778, "Avg loss": 0.40926375973504037, "Avg value loss": 0.11853150051319972, "Avg policy loss": 0.29073225939646363, "Total num played games": 54920, "Total num trained steps": 109184, "Timestamp in ms": 1701478290168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903860160233067, "Avg loss": 0.37567222339566797, "Avg value loss": 0.08121015361393802, "Avg policy loss": 0.29446206672582775, "Total num played games": 54920, "Total num trained steps": 109312, "Timestamp in ms": 1701478346045, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989239493965392, "Avg loss": 0.4301525494083762, "Avg value loss": 0.13993485760875046, "Avg policy loss": 0.2902176914503798, "Total num played games": 55016, "Total num trained steps": 109440, "Timestamp in ms": 1701478402399, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 164.35067503899336, "Avg game time in secs": 2.030953706271248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 55040, "Total num trained steps": 109524, "Timestamp in ms": 1701478438685, "logtype": "played_game"}
{"Total num played games": 55112, "Total num trained steps": 109536, "Timestamp in ms": 1701478457592, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.83203125}
{"Avg objective": 20.8203125, "Games time in secs": 22.345585564151406, "Avg game time in secs": 2.0535140837018844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.4}, "Total num played games": 55168, "Total num trained steps": 109542, "Timestamp in ms": 1701478461031, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847118066876788, "Avg loss": 0.4855570736108348, "Avg value loss": 0.1973217466729693, "Avg policy loss": 0.2882353246677667, "Total num played games": 55206, "Total num trained steps": 109568, "Timestamp in ms": 1701478472559, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870303952468935, "Avg loss": 0.4206499441061169, "Avg value loss": 0.11775915377074853, "Avg policy loss": 0.30289079004433006, "Total num played games": 55206, "Total num trained steps": 109696, "Timestamp in ms": 1701478529702, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989348983806108, "Avg loss": 0.3234048596350476, "Avg value loss": 0.0455065997375641, "Avg policy loss": 0.2778982622548938, "Total num played games": 55206, "Total num trained steps": 109824, "Timestamp in ms": 1701478587172, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 164.3283813688904, "Avg game time in secs": 2.4390068885695655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 55296, "Total num trained steps": 109911, "Timestamp in ms": 1701478625359, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882820976491862, "Avg loss": 0.42280859977472574, "Avg value loss": 0.14133660508377943, "Avg policy loss": 0.2814719963353127, "Total num played games": 55300, "Total num trained steps": 109952, "Timestamp in ms": 1701478643270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905967450271247, "Avg loss": 0.34941876388620585, "Avg value loss": 0.07330359192565084, "Avg policy loss": 0.27611517324112356, "Total num played games": 55300, "Total num trained steps": 110080, "Timestamp in ms": 1701478699893, "logtype": "training_step"}
{"Total num played games": 55394, "Total num trained steps": 110137, "Timestamp in ms": 1701478738422, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.49609375}
{"Avg objective": 20.2421875, "Games time in secs": 115.85919722728431, "Avg game time in secs": 2.141538061769097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 55424, "Total num trained steps": 110143, "Timestamp in ms": 1701478741218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986159169550173, "Avg loss": 0.5431860245298594, "Avg value loss": 0.23954941288684495, "Avg policy loss": 0.3036366152809933, "Total num played games": 55488, "Total num trained steps": 110208, "Timestamp in ms": 1701478771369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988465974625144, "Avg loss": 0.3690929366275668, "Avg value loss": 0.0702193870965857, "Avg policy loss": 0.29887354862876236, "Total num played games": 55488, "Total num trained steps": 110336, "Timestamp in ms": 1701478828116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907727797001153, "Avg loss": 0.32803819864057004, "Avg value loss": 0.04507226408168208, "Avg policy loss": 0.2829659323906526, "Total num played games": 55488, "Total num trained steps": 110464, "Timestamp in ms": 1701478886772, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 148.32529268413782, "Avg game time in secs": 2.0283423849905375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.35}, "Total num played games": 55552, "Total num trained steps": 110471, "Timestamp in ms": 1701478889544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.4453738328302279, "Avg value loss": 0.15162998693995178, "Avg policy loss": 0.2937438429798931, "Total num played games": 55584, "Total num trained steps": 110592, "Timestamp in ms": 1701478943989, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 85.9981007874012, "Avg game time in secs": 2.313874533341732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 55680, "Total num trained steps": 110666, "Timestamp in ms": 1701478975542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884343234797601, "Avg loss": 0.43960143136791885, "Avg value loss": 0.15776194838690571, "Avg policy loss": 0.2818394839996472, "Total num played games": 55682, "Total num trained steps": 110720, "Timestamp in ms": 1701478999925, "logtype": "training_step"}
{"Total num played games": 55682, "Total num trained steps": 110738, "Timestamp in ms": 1701479020959, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4375}
{"Ratio train steps to played games": 1.987378083763626, "Avg loss": 0.44001806108281016, "Avg value loss": 0.1370136470941361, "Avg policy loss": 0.30300441663712263, "Total num played games": 55776, "Total num trained steps": 110848, "Timestamp in ms": 1701479072209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896729776247848, "Avg loss": 0.3479488000739366, "Avg value loss": 0.05901403786265291, "Avg policy loss": 0.2889347607269883, "Total num played games": 55776, "Total num trained steps": 110976, "Timestamp in ms": 1701479128562, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 182.30229352414608, "Avg game time in secs": 2.04524939271505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 55808, "Total num trained steps": 111045, "Timestamp in ms": 1701479157844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885985323071416, "Avg loss": 0.4094066540710628, "Avg value loss": 0.12042198001290672, "Avg policy loss": 0.28898467286489904, "Total num played games": 55870, "Total num trained steps": 111104, "Timestamp in ms": 1701479184510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907470379783083, "Avg loss": 0.3429089911514893, "Avg value loss": 0.06254688979242928, "Avg policy loss": 0.2803621019702405, "Total num played games": 55872, "Total num trained steps": 111232, "Timestamp in ms": 1701479240849, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 84.48437074385583, "Avg game time in secs": 2.1788387468695873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.44}, "Total num played games": 55936, "Total num trained steps": 111235, "Timestamp in ms": 1701479242329, "logtype": "played_game"}
{"Total num played games": 55964, "Total num trained steps": 111342, "Timestamp in ms": 1701479303666, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.00390625}
{"Ratio train steps to played games": 1.9864961290092404, "Avg loss": 0.4527031409088522, "Avg value loss": 0.1700903737801127, "Avg policy loss": 0.28261276555713266, "Total num played games": 56058, "Total num trained steps": 111360, "Timestamp in ms": 1701479312364, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887794783973742, "Avg loss": 0.43009089899715036, "Avg value loss": 0.1438600885157939, "Avg policy loss": 0.2862308091716841, "Total num played games": 56058, "Total num trained steps": 111488, "Timestamp in ms": 1701479372509, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 183.86457685753703, "Avg game time in secs": 2.370684185749269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 56064, "Total num trained steps": 111608, "Timestamp in ms": 1701479426194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987747542384955, "Avg loss": 0.32584448996931314, "Avg value loss": 0.05528252825024538, "Avg policy loss": 0.27056196134071797, "Total num played games": 56152, "Total num trained steps": 111616, "Timestamp in ms": 1701479429311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899561919008442, "Avg loss": 0.39688908215612173, "Avg value loss": 0.12295978047768585, "Avg policy loss": 0.27392930001951754, "Total num played games": 56154, "Total num trained steps": 111744, "Timestamp in ms": 1701479486402, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 86.01060130260885, "Avg game time in secs": 2.136018391000107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.36}, "Total num played games": 56192, "Total num trained steps": 111801, "Timestamp in ms": 1701479512204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889062722230124, "Avg loss": 0.41594445845112205, "Avg value loss": 0.13615643620141782, "Avg policy loss": 0.2797880213474855, "Total num played games": 56248, "Total num trained steps": 111872, "Timestamp in ms": 1701479543687, "logtype": "training_step"}
{"Total num played games": 56248, "Total num trained steps": 111945, "Timestamp in ms": 1701479591138, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.28515625}
{"Avg objective": 21.1640625, "Games time in secs": 82.90933418273926, "Avg game time in secs": 2.235227913799463, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 56320, "Total num trained steps": 111949, "Timestamp in ms": 1701479595114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878598558801603, "Avg loss": 0.4616741731297225, "Avg value loss": 0.17883636959595606, "Avg policy loss": 0.2828378037083894, "Total num played games": 56342, "Total num trained steps": 112000, "Timestamp in ms": 1701479618456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990131695715452, "Avg loss": 0.34958293521776795, "Avg value loss": 0.0735747525759507, "Avg policy loss": 0.27600818418432027, "Total num played games": 56342, "Total num trained steps": 112128, "Timestamp in ms": 1701479676424, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890849812176625, "Avg loss": 0.3926531416364014, "Avg value loss": 0.1163516046362929, "Avg policy loss": 0.2763015335658565, "Total num played games": 56436, "Total num trained steps": 112256, "Timestamp in ms": 1701479733052, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 187.22453717887402, "Avg game time in secs": 2.3543309966480592, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.45, "agent_stopped_0": 0.6}, "Total num played games": 56448, "Total num trained steps": 112364, "Timestamp in ms": 1701479782338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880417477445604, "Avg loss": 0.37694970332086086, "Avg value loss": 0.09946630551712587, "Avg policy loss": 0.27748339832760394, "Total num played games": 56530, "Total num trained steps": 112384, "Timestamp in ms": 1701479791079, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903060321952946, "Avg loss": 0.39543170016258955, "Avg value loss": 0.10090865637175739, "Avg policy loss": 0.2945230439072475, "Total num played games": 56530, "Total num trained steps": 112512, "Timestamp in ms": 1701479849274, "logtype": "training_step"}
{"Total num played games": 56530, "Total num trained steps": 112547, "Timestamp in ms": 1701479879412, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.57421875}
{"Avg objective": 20.046875, "Games time in secs": 100.03373990766704, "Avg game time in secs": 2.214733344691922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 56576, "Total num trained steps": 112552, "Timestamp in ms": 1701479882372, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891922438455834, "Avg loss": 0.4699448390165344, "Avg value loss": 0.17038490035338327, "Avg policy loss": 0.2995599383721128, "Total num played games": 56626, "Total num trained steps": 112640, "Timestamp in ms": 1701479920738, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 86.62101626582444, "Avg game time in secs": 2.086779449527967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 56704, "Total num trained steps": 112747, "Timestamp in ms": 1701479968994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881346967559943, "Avg loss": 0.4109180199448019, "Avg value loss": 0.12109291861997917, "Avg policy loss": 0.289825098705478, "Total num played games": 56720, "Total num trained steps": 112768, "Timestamp in ms": 1701479978266, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903913963328632, "Avg loss": 0.3800173453055322, "Avg value loss": 0.0889828444342129, "Avg policy loss": 0.29103450116235763, "Total num played games": 56720, "Total num trained steps": 112896, "Timestamp in ms": 1701480034360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989351216249516, "Avg loss": 0.43201024062000215, "Avg value loss": 0.14925838258932345, "Avg policy loss": 0.28275185904931277, "Total num played games": 56814, "Total num trained steps": 113024, "Timestamp in ms": 1701480092680, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 166.73569632321596, "Avg game time in secs": 2.249342991053709, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 56832, "Total num trained steps": 113120, "Timestamp in ms": 1701480135730, "logtype": "played_game"}
{"Total num played games": 56908, "Total num trained steps": 113148, "Timestamp in ms": 1701480161402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.703125}
{"Ratio train steps to played games": 1.9877731712458717, "Avg loss": 0.39155390311498195, "Avg value loss": 0.10601473682618234, "Avg policy loss": 0.2855391678167507, "Total num played games": 56922, "Total num trained steps": 113152, "Timestamp in ms": 1701480163831, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 28.871394051238894, "Avg game time in secs": 2.145161940919934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 56960, "Total num trained steps": 113153, "Timestamp in ms": 1701480164602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872986912739903, "Avg loss": 0.5192677886225283, "Avg value loss": 0.2059721568657551, "Avg policy loss": 0.3132956348126754, "Total num played games": 57002, "Total num trained steps": 113280, "Timestamp in ms": 1701480220909, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895442265183678, "Avg loss": 0.33516312402207404, "Avg value loss": 0.05387604370480403, "Avg policy loss": 0.28128707979340106, "Total num played games": 57002, "Total num trained steps": 113408, "Timestamp in ms": 1701480278502, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 154.7560540791601, "Avg game time in secs": 2.235518036686699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 57088, "Total num trained steps": 113500, "Timestamp in ms": 1701480319360, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884409261270097, "Avg loss": 0.4119954485213384, "Avg value loss": 0.12734679243294522, "Avg policy loss": 0.28464865195564926, "Total num played games": 57098, "Total num trained steps": 113536, "Timestamp in ms": 1701480335580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990682685908438, "Avg loss": 0.37658466410357505, "Avg value loss": 0.08192508571664803, "Avg policy loss": 0.2946595778921619, "Total num played games": 57098, "Total num trained steps": 113664, "Timestamp in ms": 1701480393943, "logtype": "training_step"}
{"Total num played games": 57194, "Total num trained steps": 113750, "Timestamp in ms": 1701480448093, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.984375}
{"Avg objective": 21.3046875, "Games time in secs": 131.14375318400562, "Avg game time in secs": 2.2708542233449407, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 57216, "Total num trained steps": 113754, "Timestamp in ms": 1701480450504, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986314760508309, "Avg loss": 0.5578552004881203, "Avg value loss": 0.2518923422176158, "Avg policy loss": 0.30596285476349294, "Total num played games": 57288, "Total num trained steps": 113792, "Timestamp in ms": 1701480468770, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885490853232788, "Avg loss": 0.4067268546205014, "Avg value loss": 0.09612001210916787, "Avg policy loss": 0.3106068433262408, "Total num played games": 57288, "Total num trained steps": 113920, "Timestamp in ms": 1701480526500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990765954475632, "Avg loss": 0.35409030178561807, "Avg value loss": 0.05175443709595129, "Avg policy loss": 0.3023358639329672, "Total num played games": 57288, "Total num trained steps": 114048, "Timestamp in ms": 1701480583517, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 142.8379379492253, "Avg game time in secs": 2.1345804619923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 57344, "Total num trained steps": 114070, "Timestamp in ms": 1701480593342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897528841797079, "Avg loss": 0.4442446723114699, "Avg value loss": 0.138665359467268, "Avg policy loss": 0.3055793101666495, "Total num played games": 57382, "Total num trained steps": 114176, "Timestamp in ms": 1701480640783, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 86.94278695061803, "Avg game time in secs": 2.284071816771757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 57472, "Total num trained steps": 114261, "Timestamp in ms": 1701480680285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887257289999305, "Avg loss": 0.46521049563307315, "Avg value loss": 0.1617931474756915, "Avg policy loss": 0.303417349467054, "Total num played games": 57476, "Total num trained steps": 114304, "Timestamp in ms": 1701480699109, "logtype": "training_step"}
{"Total num played games": 57476, "Total num trained steps": 114354, "Timestamp in ms": 1701480733182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48828125}
{"Ratio train steps to played games": 1.9877019280875456, "Avg loss": 0.5281576318666339, "Avg value loss": 0.19499730310053565, "Avg policy loss": 0.3331603263504803, "Total num played games": 57570, "Total num trained steps": 114432, "Timestamp in ms": 1701480768464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899253083203057, "Avg loss": 0.39938154304400086, "Avg value loss": 0.07719586012535729, "Avg policy loss": 0.32218568585813046, "Total num played games": 57570, "Total num trained steps": 114560, "Timestamp in ms": 1701480825962, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 178.02812638692558, "Avg game time in secs": 2.0106047600274906, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 57600, "Total num trained steps": 114632, "Timestamp in ms": 1701480858314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888322408351542, "Avg loss": 0.47148454934358597, "Avg value loss": 0.16141803612117656, "Avg policy loss": 0.3100665140664205, "Total num played games": 57666, "Total num trained steps": 114688, "Timestamp in ms": 1701480883427, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991051919675372, "Avg loss": 0.39200110197998583, "Avg value loss": 0.06990784691879526, "Avg policy loss": 0.32209325255826116, "Total num played games": 57666, "Total num trained steps": 114816, "Timestamp in ms": 1701480939902, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 86.16358786448836, "Avg game time in secs": 2.332152186179883, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 57728, "Total num trained steps": 114827, "Timestamp in ms": 1701480944477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899414840206364, "Avg loss": 0.426111709093675, "Avg value loss": 0.12204641129937954, "Avg policy loss": 0.30406529596075416, "Total num played games": 57762, "Total num trained steps": 114944, "Timestamp in ms": 1701480995002, "logtype": "training_step"}
{"Total num played games": 57762, "Total num trained steps": 114955, "Timestamp in ms": 1701481013468, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.98828125}
{"Avg objective": 21.5078125, "Games time in secs": 75.62046040594578, "Avg game time in secs": 2.391169881055248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 57856, "Total num trained steps": 114968, "Timestamp in ms": 1701481020098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988938053097345, "Avg loss": 0.4610758333001286, "Avg value loss": 0.14803508552722633, "Avg policy loss": 0.3130407468415797, "Total num played games": 57856, "Total num trained steps": 115072, "Timestamp in ms": 1701481066207, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991150442477876, "Avg loss": 0.36107415379956365, "Avg value loss": 0.05437215810525231, "Avg policy loss": 0.3067019957816228, "Total num played games": 57856, "Total num trained steps": 115200, "Timestamp in ms": 1701481121705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901121656600518, "Avg loss": 0.4496692009270191, "Avg value loss": 0.1351201732759364, "Avg policy loss": 0.3145490273600444, "Total num played games": 57950, "Total num trained steps": 115328, "Timestamp in ms": 1701481177578, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 186.0957649499178, "Avg game time in secs": 2.0727894641895546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 57984, "Total num trained steps": 115393, "Timestamp in ms": 1701481206194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891117083591758, "Avg loss": 0.48738763364963233, "Avg value loss": 0.17621969374886248, "Avg policy loss": 0.3111679401481524, "Total num played games": 58044, "Total num trained steps": 115456, "Timestamp in ms": 1701481234350, "logtype": "training_step"}
{"Total num played games": 58044, "Total num trained steps": 115555, "Timestamp in ms": 1701481291065, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8515625}
{"Avg objective": 20.84375, "Games time in secs": 89.20365733280778, "Avg game time in secs": 2.3970298552158056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 58112, "Total num trained steps": 115564, "Timestamp in ms": 1701481295397, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880972857683443, "Avg loss": 0.43042548769153655, "Avg value loss": 0.11946907482342795, "Avg policy loss": 0.31095641653519124, "Total num played games": 58138, "Total num trained steps": 115584, "Timestamp in ms": 1701481304249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902989438921188, "Avg loss": 0.4148962297476828, "Avg value loss": 0.09835493154241703, "Avg policy loss": 0.316541300737299, "Total num played games": 58138, "Total num trained steps": 115712, "Timestamp in ms": 1701481361191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989284242340981, "Avg loss": 0.4864962534047663, "Avg value loss": 0.17558869990170933, "Avg policy loss": 0.31090755213517696, "Total num played games": 58232, "Total num trained steps": 115840, "Timestamp in ms": 1701481418104, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 174.70509644784033, "Avg game time in secs": 2.5157910931884544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 58240, "Total num trained steps": 115956, "Timestamp in ms": 1701481470103, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882728114391524, "Avg loss": 0.41598003380931914, "Avg value loss": 0.09836472733877599, "Avg policy loss": 0.3176153072854504, "Total num played games": 58326, "Total num trained steps": 115968, "Timestamp in ms": 1701481475367, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904673730411824, "Avg loss": 0.45511811110191047, "Avg value loss": 0.13797739549772814, "Avg policy loss": 0.3171407110057771, "Total num played games": 58326, "Total num trained steps": 116096, "Timestamp in ms": 1701481531943, "logtype": "training_step"}
{"Avg objective": 19.4921875, "Games time in secs": 83.27875018119812, "Avg game time in secs": 2.180117099764175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.37}, "Total num played games": 58368, "Total num trained steps": 116146, "Timestamp in ms": 1701481553381, "logtype": "played_game"}
{"Total num played games": 58420, "Total num trained steps": 116157, "Timestamp in ms": 1701481570438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4609375}
{"Avg objective": 21.0390625, "Games time in secs": 21.201508151367307, "Avg game time in secs": 2.2897118702239823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 58496, "Total num trained steps": 116165, "Timestamp in ms": 1701481574583, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862596985336842, "Avg loss": 0.541276435367763, "Avg value loss": 0.2301090605033096, "Avg policy loss": 0.311167377862148, "Total num played games": 58514, "Total num trained steps": 116224, "Timestamp in ms": 1701481601232, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884472092148888, "Avg loss": 0.3837795932777226, "Avg value loss": 0.08798863179981709, "Avg policy loss": 0.29579096310772, "Total num played games": 58514, "Total num trained steps": 116352, "Timestamp in ms": 1701481658326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906347198960932, "Avg loss": 0.3362813302082941, "Avg value loss": 0.05112641655432526, "Avg policy loss": 0.285154914483428, "Total num played games": 58514, "Total num trained steps": 116480, "Timestamp in ms": 1701481714523, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895580958880736, "Avg loss": 0.4197727954015136, "Avg value loss": 0.12264127773232758, "Avg policy loss": 0.2971315181348473, "Total num played games": 58610, "Total num trained steps": 116608, "Timestamp in ms": 1701481770484, "logtype": "training_step"}
{"Avg objective": 19.6171875, "Games time in secs": 243.45627702586353, "Avg game time in secs": 2.1446111835102784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.49, "agent_stopped_0": 0.53}, "Total num played games": 58624, "Total num trained steps": 116712, "Timestamp in ms": 1701481818040, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988484993016046, "Avg loss": 0.4094684725860134, "Avg value loss": 0.11741939641069621, "Avg policy loss": 0.2920490740798414, "Total num played games": 58706, "Total num trained steps": 116736, "Timestamp in ms": 1701481828380, "logtype": "training_step"}
{"Total num played games": 58706, "Total num trained steps": 116757, "Timestamp in ms": 1701481849672, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.76953125}
{"Avg objective": 20.125, "Games time in secs": 34.68186954781413, "Avg game time in secs": 2.132363031501882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 58752, "Total num trained steps": 116763, "Timestamp in ms": 1701481852722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874829931972788, "Avg loss": 0.48664284171536565, "Avg value loss": 0.18461855317582376, "Avg policy loss": 0.302024289034307, "Total num played games": 58800, "Total num trained steps": 116864, "Timestamp in ms": 1701481900727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896598639455783, "Avg loss": 0.3373377413954586, "Avg value loss": 0.05771139627904631, "Avg policy loss": 0.2796263440977782, "Total num played games": 58800, "Total num trained steps": 116992, "Timestamp in ms": 1701481958209, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 150.98101215995848, "Avg game time in secs": 2.1424241540953517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 58880, "Total num trained steps": 117096, "Timestamp in ms": 1701482003703, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885730779679436, "Avg loss": 0.38785271195229143, "Avg value loss": 0.11153910601569805, "Avg policy loss": 0.27631360630039126, "Total num played games": 58896, "Total num trained steps": 117120, "Timestamp in ms": 1701482014791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907464004346644, "Avg loss": 0.3912917443085462, "Avg value loss": 0.10250196349807084, "Avg policy loss": 0.2887897836044431, "Total num played games": 58896, "Total num trained steps": 117248, "Timestamp in ms": 1701482073292, "logtype": "training_step"}
{"Total num played games": 58992, "Total num trained steps": 117361, "Timestamp in ms": 1701482134818, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.32421875}
{"Avg objective": 20.203125, "Games time in secs": 133.39495517127216, "Avg game time in secs": 2.324917137477314, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 59008, "Total num trained steps": 117364, "Timestamp in ms": 1701482137098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986595355764674, "Avg loss": 0.4295053188689053, "Avg value loss": 0.14371834353369195, "Avg policy loss": 0.2857869752915576, "Total num played games": 59084, "Total num trained steps": 117376, "Timestamp in ms": 1701482143013, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886944453846935, "Avg loss": 0.43321325490251184, "Avg value loss": 0.14606299929437228, "Avg policy loss": 0.2871502547059208, "Total num played games": 59086, "Total num trained steps": 117504, "Timestamp in ms": 1701482203027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908607792031954, "Avg loss": 0.32833855925127864, "Avg value loss": 0.05301852221600711, "Avg policy loss": 0.275320035754703, "Total num played games": 59086, "Total num trained steps": 117632, "Timestamp in ms": 1701482259649, "logtype": "training_step"}
{"Avg objective": 20.34375, "Games time in secs": 137.2906668651849, "Avg game time in secs": 2.0880911535350606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 59136, "Total num trained steps": 117665, "Timestamp in ms": 1701482274388, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898445420750253, "Avg loss": 0.41986370948143303, "Avg value loss": 0.145736055332236, "Avg policy loss": 0.27412765356712043, "Total num played games": 59180, "Total num trained steps": 117760, "Timestamp in ms": 1701482317282, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 86.91432456858456, "Avg game time in secs": 2.289120504152379, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 59264, "Total num trained steps": 117857, "Timestamp in ms": 1701482361303, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888652697641462, "Avg loss": 0.3847805019468069, "Avg value loss": 0.10768934644875117, "Avg policy loss": 0.27709116030018777, "Total num played games": 59274, "Total num trained steps": 117888, "Timestamp in ms": 1701482375384, "logtype": "training_step"}
{"Total num played games": 59274, "Total num trained steps": 117961, "Timestamp in ms": 1701482419756, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.671875}
{"Ratio train steps to played games": 1.987872254413152, "Avg loss": 0.47635686164721847, "Avg value loss": 0.18635500976233743, "Avg policy loss": 0.29000185150653124, "Total num played games": 59368, "Total num trained steps": 118016, "Timestamp in ms": 1701482445287, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990028298073036, "Avg loss": 0.36603167199064046, "Avg value loss": 0.0694781489437446, "Avg policy loss": 0.2965535222319886, "Total num played games": 59368, "Total num trained steps": 118144, "Timestamp in ms": 1701482501542, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 178.37037462741137, "Avg game time in secs": 2.085734043663251, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.41, "agent_stopped_0": 0.6}, "Total num played games": 59392, "Total num trained steps": 118229, "Timestamp in ms": 1701482539673, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890350139584945, "Avg loss": 0.4017959370976314, "Avg value loss": 0.11187877311022021, "Avg policy loss": 0.2899171661119908, "Total num played games": 59462, "Total num trained steps": 118272, "Timestamp in ms": 1701482558899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911876492549865, "Avg loss": 0.37242845771834254, "Avg value loss": 0.07138366834260523, "Avg policy loss": 0.3010447926353663, "Total num played games": 59462, "Total num trained steps": 118400, "Timestamp in ms": 1701482615314, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 83.23764786683023, "Avg game time in secs": 2.1360258231288753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 59520, "Total num trained steps": 118418, "Timestamp in ms": 1701482622911, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901272708955975, "Avg loss": 0.45311106042936444, "Avg value loss": 0.14140458533074707, "Avg policy loss": 0.3117064759135246, "Total num played games": 59558, "Total num trained steps": 118528, "Timestamp in ms": 1701482670809, "logtype": "training_step"}
{"Total num played games": 59558, "Total num trained steps": 118565, "Timestamp in ms": 1701482698199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.59375}
{"Avg objective": 20.9375, "Games time in secs": 80.87900364026427, "Avg game time in secs": 2.459926276191254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 59648, "Total num trained steps": 118575, "Timestamp in ms": 1701482703790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891369945684974, "Avg loss": 0.45106306532397866, "Avg value loss": 0.14249978351290338, "Avg policy loss": 0.3085632810834795, "Total num played games": 59652, "Total num trained steps": 118656, "Timestamp in ms": 1701482741027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912827734191645, "Avg loss": 0.34660196118056774, "Avg value loss": 0.05443416703201365, "Avg policy loss": 0.29216779163107276, "Total num played games": 59652, "Total num trained steps": 118784, "Timestamp in ms": 1701482799628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902088772845954, "Avg loss": 0.47826299583539367, "Avg value loss": 0.1780591056740377, "Avg policy loss": 0.300203891354613, "Total num played games": 59748, "Total num trained steps": 118912, "Timestamp in ms": 1701482857820, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 188.01435826532543, "Avg game time in secs": 2.125853840028867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 59776, "Total num trained steps": 118989, "Timestamp in ms": 1701482891805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892383275960028, "Avg loss": 0.4468876253813505, "Avg value loss": 0.1499934807070531, "Avg policy loss": 0.2968941475264728, "Total num played games": 59842, "Total num trained steps": 119040, "Timestamp in ms": 1701482913707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913772935396543, "Avg loss": 0.3684910002630204, "Avg value loss": 0.07591365693951957, "Avg policy loss": 0.2925773450406268, "Total num played games": 59842, "Total num trained steps": 119168, "Timestamp in ms": 1701482968752, "logtype": "training_step"}
{"Total num played games": 59842, "Total num trained steps": 119169, "Timestamp in ms": 1701482981683, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.14453125}
{"Avg objective": 21.3984375, "Games time in secs": 93.26496710814536, "Avg game time in secs": 2.0683233458694303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 59904, "Total num trained steps": 119175, "Timestamp in ms": 1701482985070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903897490656701, "Avg loss": 0.45341196842491627, "Avg value loss": 0.14330519072245806, "Avg policy loss": 0.31010677420999855, "Total num played games": 59936, "Total num trained steps": 119296, "Timestamp in ms": 1701483039030, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 88.00374194607139, "Avg game time in secs": 2.432744703721255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 60032, "Total num trained steps": 119372, "Timestamp in ms": 1701483073074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893223614072495, "Avg loss": 0.43550437572412193, "Avg value loss": 0.1274918429844547, "Avg policy loss": 0.30801253172103316, "Total num played games": 60032, "Total num trained steps": 119424, "Timestamp in ms": 1701483096389, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914712153518124, "Avg loss": 0.3610673469956964, "Avg value loss": 0.05915827055287082, "Avg policy loss": 0.3019090766320005, "Total num played games": 60032, "Total num trained steps": 119552, "Timestamp in ms": 1701483152668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904866447127698, "Avg loss": 0.5023937034420669, "Avg value loss": 0.18185893379268236, "Avg policy loss": 0.32053476897999644, "Total num played games": 60126, "Total num trained steps": 119680, "Timestamp in ms": 1701483209980, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 165.30259418301284, "Avg game time in secs": 1.967163075998542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.34, "agent_stopped_0": 0.7}, "Total num played games": 60160, "Total num trained steps": 119745, "Timestamp in ms": 1701483238376, "logtype": "played_game"}
{"Total num played games": 60220, "Total num trained steps": 119769, "Timestamp in ms": 1701483262578, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.57421875}
{"Avg objective": 20.65625, "Games time in secs": 27.865166114643216, "Avg game time in secs": 2.282211046127486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 60288, "Total num trained steps": 119777, "Timestamp in ms": 1701483266242, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864044832045629, "Avg loss": 0.5703266016207635, "Avg value loss": 0.24717692396370694, "Avg policy loss": 0.32314967713318765, "Total num played games": 60314, "Total num trained steps": 119808, "Timestamp in ms": 1701483280472, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885267102165334, "Avg loss": 0.4447712665423751, "Avg value loss": 0.11770394796621986, "Avg policy loss": 0.32706732023507357, "Total num played games": 60314, "Total num trained steps": 119936, "Timestamp in ms": 1701483337352, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906489372285041, "Avg loss": 0.36745538213290274, "Avg value loss": 0.0573607720725704, "Avg policy loss": 0.3100946106715128, "Total num played games": 60314, "Total num trained steps": 120064, "Timestamp in ms": 1701483392331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896043701373944, "Avg loss": 0.5004275180399418, "Avg value loss": 0.18753208403359167, "Avg policy loss": 0.3128954351413995, "Total num played games": 60410, "Total num trained steps": 120192, "Timestamp in ms": 1701483450577, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 236.06797739863396, "Avg game time in secs": 2.253585736863897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 60416, "Total num trained steps": 120311, "Timestamp in ms": 1701483502310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988628850985059, "Avg loss": 0.38966329069808125, "Avg value loss": 0.08598301527672447, "Avg policy loss": 0.30368027673102915, "Total num played games": 60504, "Total num trained steps": 120320, "Timestamp in ms": 1701483506051, "logtype": "training_step"}
{"Total num played games": 60504, "Total num trained steps": 120370, "Timestamp in ms": 1701483545537, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2890625}
{"Avg objective": 20.265625, "Games time in secs": 46.1978233512491, "Avg game time in secs": 2.018034045555396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.42}, "Total num played games": 60544, "Total num trained steps": 120375, "Timestamp in ms": 1701483548508, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876563582956532, "Avg loss": 0.5179131540935487, "Avg value loss": 0.19707103865221143, "Avg policy loss": 0.32084212033078074, "Total num played games": 60598, "Total num trained steps": 120448, "Timestamp in ms": 1701483580828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897686392290175, "Avg loss": 0.3831543535925448, "Avg value loss": 0.06898985797306523, "Avg policy loss": 0.3141644949791953, "Total num played games": 60598, "Total num trained steps": 120576, "Timestamp in ms": 1701483637753, "logtype": "training_step"}
{"Avg objective": 20.015625, "Games time in secs": 139.84648721292615, "Avg game time in secs": 2.250543740548892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 60672, "Total num trained steps": 120691, "Timestamp in ms": 1701483688354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988779410795492, "Avg loss": 0.3867343314923346, "Avg value loss": 0.08986405798350461, "Avg policy loss": 0.2968702740035951, "Total num played games": 60692, "Total num trained steps": 120704, "Timestamp in ms": 1701483693859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990904896856258, "Avg loss": 0.43614538945257664, "Avg value loss": 0.1240259969199542, "Avg policy loss": 0.3121193952392787, "Total num played games": 60692, "Total num trained steps": 120832, "Timestamp in ms": 1701483750792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899318922120226, "Avg loss": 0.4822855032980442, "Avg value loss": 0.16165416411240585, "Avg policy loss": 0.3206313392147422, "Total num played games": 60786, "Total num trained steps": 120960, "Timestamp in ms": 1701483806701, "logtype": "training_step"}
{"Total num played games": 60786, "Total num trained steps": 120973, "Timestamp in ms": 1701483824323, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.20703125}
{"Avg objective": 20.65625, "Games time in secs": 138.4188319593668, "Avg game time in secs": 2.289412681464455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 60800, "Total num trained steps": 120978, "Timestamp in ms": 1701483826773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889454664914585, "Avg loss": 0.4912678529508412, "Avg value loss": 0.1623302871012129, "Avg policy loss": 0.32893756416160613, "Total num played games": 60880, "Total num trained steps": 121088, "Timestamp in ms": 1701483878189, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910643889618922, "Avg loss": 0.3539856222923845, "Avg value loss": 0.05368412789539434, "Avg policy loss": 0.30030149139929563, "Total num played games": 60880, "Total num trained steps": 121216, "Timestamp in ms": 1701483934693, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 125.25557080470026, "Avg game time in secs": 1.9988262350670993, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 60928, "Total num trained steps": 121254, "Timestamp in ms": 1701483952030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900288638152717, "Avg loss": 0.4762453434523195, "Avg value loss": 0.15799461206188425, "Avg policy loss": 0.3182507309829816, "Total num played games": 60976, "Total num trained steps": 121344, "Timestamp in ms": 1701483990503, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 85.36534630320966, "Avg game time in secs": 2.3282161159149837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 61056, "Total num trained steps": 121448, "Timestamp in ms": 1701484037394, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890617324381856, "Avg loss": 0.440159656573087, "Avg value loss": 0.12739969656104222, "Avg policy loss": 0.3127599590225145, "Total num played games": 61070, "Total num trained steps": 121472, "Timestamp in ms": 1701484048023, "logtype": "training_step"}
{"Total num played games": 61070, "Total num trained steps": 121574, "Timestamp in ms": 1701484107706, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.98828125}
{"Ratio train steps to played games": 1.9880975737361848, "Avg loss": 0.4989759873133153, "Avg value loss": 0.17304247827269137, "Avg policy loss": 0.3259335127659142, "Total num played games": 61164, "Total num trained steps": 121600, "Timestamp in ms": 1701484119692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990190308024328, "Avg loss": 0.4693849759642035, "Avg value loss": 0.14003239493467845, "Avg policy loss": 0.3293525781482458, "Total num played games": 61164, "Total num trained steps": 121728, "Timestamp in ms": 1701484177870, "logtype": "training_step"}
{"Avg objective": 19.8984375, "Games time in secs": 182.48176576569676, "Avg game time in secs": 2.346574238879839, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.56, "agent_stopped_0": 0.45}, "Total num played games": 61184, "Total num trained steps": 121820, "Timestamp in ms": 1701484219877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892258970256946, "Avg loss": 0.4222864599432796, "Avg value loss": 0.10716624441556633, "Avg policy loss": 0.31512021634262055, "Total num played games": 61258, "Total num trained steps": 121856, "Timestamp in ms": 1701484235365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991315420026772, "Avg loss": 0.41279831784777343, "Avg value loss": 0.09421059605665505, "Avg policy loss": 0.3185877214418724, "Total num played games": 61258, "Total num trained steps": 121984, "Timestamp in ms": 1701484294106, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 85.58779270388186, "Avg game time in secs": 2.075840456629521, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.45}, "Total num played games": 61312, "Total num trained steps": 122010, "Timestamp in ms": 1701484305465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902858819310885, "Avg loss": 0.5007364209741354, "Avg value loss": 0.1792871266079601, "Avg policy loss": 0.32144929049536586, "Total num played games": 61354, "Total num trained steps": 122112, "Timestamp in ms": 1701484350506, "logtype": "training_step"}
{"Total num played games": 61354, "Total num trained steps": 122176, "Timestamp in ms": 1701484392040, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.75}
{"Avg objective": 21.296875, "Games time in secs": 90.98222333751619, "Avg game time in secs": 2.2821519860153785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 61440, "Total num trained steps": 122185, "Timestamp in ms": 1701484396447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893243067308943, "Avg loss": 0.44783621770329773, "Avg value loss": 0.1327634548943024, "Avg policy loss": 0.3150727605680004, "Total num played games": 61448, "Total num trained steps": 122240, "Timestamp in ms": 1701484421669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914073688321834, "Avg loss": 0.36550401255954057, "Avg value loss": 0.06450988442520611, "Avg policy loss": 0.3009941274067387, "Total num played games": 61448, "Total num trained steps": 122368, "Timestamp in ms": 1701484477975, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904293003152318, "Avg loss": 0.4380482432898134, "Avg value loss": 0.1398304599279072, "Avg policy loss": 0.2982177825178951, "Total num played games": 61542, "Total num trained steps": 122496, "Timestamp in ms": 1701484535531, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 174.68721743114293, "Avg game time in secs": 2.1435988048033323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 61568, "Total num trained steps": 122577, "Timestamp in ms": 1701484571135, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894866636381336, "Avg loss": 0.4520846111699939, "Avg value loss": 0.1536950788286049, "Avg policy loss": 0.29838953306898475, "Total num played games": 61636, "Total num trained steps": 122624, "Timestamp in ms": 1701484591263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915633720552923, "Avg loss": 0.38159822206944227, "Avg value loss": 0.08516406372655183, "Avg policy loss": 0.29643415892496705, "Total num played games": 61636, "Total num trained steps": 122752, "Timestamp in ms": 1701484648568, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 83.67858034558594, "Avg game time in secs": 2.0760344535374315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 61696, "Total num trained steps": 122766, "Timestamp in ms": 1701484654813, "logtype": "played_game"}
{"Total num played games": 61730, "Total num trained steps": 122776, "Timestamp in ms": 1701484673517, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0625}
{"Avg objective": 20.4921875, "Games time in secs": 24.09472086466849, "Avg game time in secs": 2.3695640024816385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 61824, "Total num trained steps": 122786, "Timestamp in ms": 1701484678908, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875776397515528, "Avg loss": 0.6075091913808137, "Avg value loss": 0.28689926987863146, "Avg policy loss": 0.3206099197268486, "Total num played games": 61824, "Total num trained steps": 122880, "Timestamp in ms": 1701484720309, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989648033126294, "Avg loss": 0.3708754063118249, "Avg value loss": 0.06618400290608406, "Avg policy loss": 0.30469140387140214, "Total num played games": 61824, "Total num trained steps": 123008, "Timestamp in ms": 1701484776481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917184265010353, "Avg loss": 0.34102605551015586, "Avg value loss": 0.05258583085378632, "Avg policy loss": 0.2884402248309925, "Total num played games": 61824, "Total num trained steps": 123136, "Timestamp in ms": 1701484832655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990569084684452, "Avg loss": 0.4537806874141097, "Avg value loss": 0.15276845556218177, "Avg policy loss": 0.3010122295236215, "Total num played games": 61924, "Total num trained steps": 123264, "Timestamp in ms": 1701484889745, "logtype": "training_step"}
{"Avg objective": 19.9296875, "Games time in secs": 243.91528260707855, "Avg game time in secs": 1.9547604979015887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 61952, "Total num trained steps": 123341, "Timestamp in ms": 1701484922824, "logtype": "played_game"}
{"Total num played games": 62018, "Total num trained steps": 123377, "Timestamp in ms": 1701484953650, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.83984375}
{"Avg objective": 21.0390625, "Games time in secs": 34.67438000254333, "Avg game time in secs": 2.07440232441877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 62080, "Total num trained steps": 123383, "Timestamp in ms": 1701484957498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986604842864503, "Avg loss": 0.5159190553240478, "Avg value loss": 0.21369179303292185, "Avg policy loss": 0.30222726333886385, "Total num played games": 62112, "Total num trained steps": 123392, "Timestamp in ms": 1701484962404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988665636269964, "Avg loss": 0.5093603397253901, "Avg value loss": 0.1843154095695354, "Avg policy loss": 0.3250449306797236, "Total num played games": 62112, "Total num trained steps": 123520, "Timestamp in ms": 1701485023474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990726429675425, "Avg loss": 0.35839182301424444, "Avg value loss": 0.05536052447860129, "Avg policy loss": 0.30303129786625504, "Total num played games": 62112, "Total num trained steps": 123648, "Timestamp in ms": 1701485081802, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989775905861171, "Avg loss": 0.4317844300530851, "Avg value loss": 0.13203798633185215, "Avg policy loss": 0.2997464401414618, "Total num played games": 62206, "Total num trained steps": 123776, "Timestamp in ms": 1701485138009, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 236.71377542056143, "Avg game time in secs": 2.2129409996268805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 62208, "Total num trained steps": 123902, "Timestamp in ms": 1701485194212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916414839580787, "Avg loss": 0.38022747775539756, "Avg value loss": 0.0724126435816288, "Avg policy loss": 0.3078148312633857, "Total num played games": 62210, "Total num trained steps": 123904, "Timestamp in ms": 1701485195025, "logtype": "training_step"}
{"Total num played games": 62300, "Total num trained steps": 123978, "Timestamp in ms": 1701485240910, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.078125}
{"Avg objective": 20.59375, "Games time in secs": 49.297771314159036, "Avg game time in secs": 1.9941101960575907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 62336, "Total num trained steps": 123982, "Timestamp in ms": 1701485243510, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878674231496618, "Avg loss": 0.5327441664412618, "Avg value loss": 0.22302159675746225, "Avg policy loss": 0.3097225708188489, "Total num played games": 62394, "Total num trained steps": 124032, "Timestamp in ms": 1701485267090, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899349296406705, "Avg loss": 0.35941808484494686, "Avg value loss": 0.0685553572839126, "Avg policy loss": 0.29086272860877216, "Total num played games": 62394, "Total num trained steps": 124160, "Timestamp in ms": 1701485324474, "logtype": "training_step"}
{"Avg objective": 20.1953125, "Games time in secs": 134.04708124883473, "Avg game time in secs": 1.9775604396418203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.43, "agent_stopped_0": 0.58}, "Total num played games": 62464, "Total num trained steps": 124283, "Timestamp in ms": 1701485377557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889898860581232, "Avg loss": 0.3485750441905111, "Avg value loss": 0.06617101025767624, "Avg policy loss": 0.2824040383566171, "Total num played games": 62488, "Total num trained steps": 124288, "Timestamp in ms": 1701485379764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991022276277045, "Avg loss": 0.47516145394183695, "Avg value loss": 0.1702652674575802, "Avg policy loss": 0.3048961873864755, "Total num played games": 62488, "Total num trained steps": 124416, "Timestamp in ms": 1701485435601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990029400485747, "Avg loss": 0.5210584264714271, "Avg value loss": 0.2141446989553515, "Avg policy loss": 0.30691372649744153, "Total num played games": 62584, "Total num trained steps": 124544, "Timestamp in ms": 1701485492375, "logtype": "training_step"}
{"Total num played games": 62584, "Total num trained steps": 124579, "Timestamp in ms": 1701485522690, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.76953125}
{"Avg objective": 20.7890625, "Games time in secs": 147.60084967501462, "Avg game time in secs": 2.302147986149066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 62592, "Total num trained steps": 124583, "Timestamp in ms": 1701485525158, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890870799961708, "Avg loss": 0.4582474904600531, "Avg value loss": 0.14582608419004828, "Avg policy loss": 0.3124214083654806, "Total num played games": 62678, "Total num trained steps": 124672, "Timestamp in ms": 1701485564348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911292638565365, "Avg loss": 0.36253730568569154, "Avg value loss": 0.06413331782096066, "Avg policy loss": 0.2984039845177904, "Total num played games": 62678, "Total num trained steps": 124800, "Timestamp in ms": 1701485622054, "logtype": "training_step"}
{"Avg objective": 18.8671875, "Games time in secs": 119.55465175956488, "Avg game time in secs": 2.0697090743196895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 62720, "Total num trained steps": 124850, "Timestamp in ms": 1701485644713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901232994551885, "Avg loss": 0.43669768678955734, "Avg value loss": 0.13416739302920178, "Avg policy loss": 0.30253029288724065, "Total num played games": 62774, "Total num trained steps": 124928, "Timestamp in ms": 1701485679257, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 86.33713890425861, "Avg game time in secs": 2.235834936131141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.49, "agent_stopped_0": 0.53}, "Total num played games": 62848, "Total num trained steps": 125043, "Timestamp in ms": 1701485731050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890571319506298, "Avg loss": 0.39602263492997736, "Avg value loss": 0.10394418545183726, "Avg policy loss": 0.29207845113705844, "Total num played games": 62872, "Total num trained steps": 125056, "Timestamp in ms": 1701485736700, "logtype": "training_step"}
{"Total num played games": 62872, "Total num trained steps": 125179, "Timestamp in ms": 1701485804833, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.08984375}
{"Ratio train steps to played games": 1.9901433976662108, "Avg loss": 0.40827125683426857, "Avg value loss": 0.10664854719652794, "Avg policy loss": 0.3016227121697739, "Total num played games": 62902, "Total num trained steps": 125184, "Timestamp in ms": 1701485807587, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901534161293397, "Avg loss": 0.4678581408225, "Avg value loss": 0.15407506391056813, "Avg policy loss": 0.3137830765917897, "Total num played games": 62966, "Total num trained steps": 125312, "Timestamp in ms": 1701485863508, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 182.78168464452028, "Avg game time in secs": 2.1506920473184437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 62976, "Total num trained steps": 125424, "Timestamp in ms": 1701485913832, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891535314452444, "Avg loss": 0.3642192608676851, "Avg value loss": 0.0787046547193313, "Avg policy loss": 0.28551460709422827, "Total num played games": 63062, "Total num trained steps": 125440, "Timestamp in ms": 1701485921136, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991183279946719, "Avg loss": 0.3851115829311311, "Avg value loss": 0.09176628102432005, "Avg policy loss": 0.29334530199412256, "Total num played games": 63062, "Total num trained steps": 125568, "Timestamp in ms": 1701485977458, "logtype": "training_step"}
{"Avg objective": 19.8359375, "Games time in secs": 85.01878347620368, "Avg game time in secs": 1.8213585074117873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 63104, "Total num trained steps": 125617, "Timestamp in ms": 1701485998851, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901833496944172, "Avg loss": 0.4361864133970812, "Avg value loss": 0.14425775982090272, "Avg policy loss": 0.29192865767981857, "Total num played games": 63158, "Total num trained steps": 125696, "Timestamp in ms": 1701486033176, "logtype": "training_step"}
{"Total num played games": 63158, "Total num trained steps": 125783, "Timestamp in ms": 1701486085408, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0546875}
{"Avg objective": 21.078125, "Games time in secs": 90.56092224270105, "Avg game time in secs": 2.1448482675332343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 63232, "Total num trained steps": 125791, "Timestamp in ms": 1701486089412, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892493517991525, "Avg loss": 0.4085572272306308, "Avg value loss": 0.1210195156163536, "Avg policy loss": 0.28753770934417844, "Total num played games": 63252, "Total num trained steps": 125824, "Timestamp in ms": 1701486103681, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912730032251944, "Avg loss": 0.34047291276510805, "Avg value loss": 0.06609601314994507, "Avg policy loss": 0.2743768999353051, "Total num played games": 63252, "Total num trained steps": 125952, "Timestamp in ms": 1701486161226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902601502809876, "Avg loss": 0.4159538144012913, "Avg value loss": 0.13701391872018576, "Avg policy loss": 0.2789398954482749, "Total num played games": 63348, "Total num trained steps": 126080, "Timestamp in ms": 1701486219021, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 176.7819843441248, "Avg game time in secs": 2.085657533709309, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 63360, "Total num trained steps": 126188, "Timestamp in ms": 1701486266194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989328835787018, "Avg loss": 0.3685926175676286, "Avg value loss": 0.09301672299625352, "Avg policy loss": 0.27557589404750615, "Total num played games": 63442, "Total num trained steps": 126208, "Timestamp in ms": 1701486275622, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913621890860944, "Avg loss": 0.35236066998913884, "Avg value loss": 0.07135852219653316, "Avg policy loss": 0.28100214700680226, "Total num played games": 63442, "Total num trained steps": 126336, "Timestamp in ms": 1701486331414, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 83.97557500563562, "Avg game time in secs": 2.047595880969311, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.42}, "Total num played games": 63488, "Total num trained steps": 126378, "Timestamp in ms": 1701486350170, "logtype": "played_game"}
{"Total num played games": 63540, "Total num trained steps": 126383, "Timestamp in ms": 1701486365282, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Avg objective": 20.7421875, "Games time in secs": 19.19685084372759, "Avg game time in secs": 2.2217360604554415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.54}, "Total num played games": 63616, "Total num trained steps": 126391, "Timestamp in ms": 1701486369366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987365244994814, "Avg loss": 0.5726335012586787, "Avg value loss": 0.2704947930906201, "Avg policy loss": 0.3021387024782598, "Total num played games": 63634, "Total num trained steps": 126464, "Timestamp in ms": 1701486401928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893767482792217, "Avg loss": 0.3700253809802234, "Avg value loss": 0.07730182830709964, "Avg policy loss": 0.2927235553506762, "Total num played games": 63634, "Total num trained steps": 126592, "Timestamp in ms": 1701486458327, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913882515636294, "Avg loss": 0.32203931629192084, "Avg value loss": 0.04689098619564902, "Avg policy loss": 0.2751483282772824, "Total num played games": 63634, "Total num trained steps": 126720, "Timestamp in ms": 1701486516964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990459452673864, "Avg loss": 0.40185403323266655, "Avg value loss": 0.12628346506971866, "Avg policy loss": 0.2755705682793632, "Total num played games": 63728, "Total num trained steps": 126848, "Timestamp in ms": 1701486573715, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 249.25369891524315, "Avg game time in secs": 2.1507582010381157, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 63744, "Total num trained steps": 126948, "Timestamp in ms": 1701486618620, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989533389740215, "Avg loss": 0.37219784245826304, "Avg value loss": 0.09754220372997224, "Avg policy loss": 0.27465563733130693, "Total num played games": 63822, "Total num trained steps": 126976, "Timestamp in ms": 1701486630345, "logtype": "training_step"}
{"Total num played games": 63822, "Total num trained steps": 126985, "Timestamp in ms": 1701486646414, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.015625}
{"Avg objective": 20.3359375, "Games time in secs": 30.938511276617646, "Avg game time in secs": 2.027656582664349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 63872, "Total num trained steps": 126990, "Timestamp in ms": 1701486649559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886100506915327, "Avg loss": 0.48617374803870916, "Avg value loss": 0.17588100483408198, "Avg policy loss": 0.3102927387226373, "Total num played games": 63916, "Total num trained steps": 127104, "Timestamp in ms": 1701486703105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990612679141373, "Avg loss": 0.3435386628843844, "Avg value loss": 0.05791764192690607, "Avg policy loss": 0.28562102175783366, "Total num played games": 63916, "Total num trained steps": 127232, "Timestamp in ms": 1701486761394, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 154.27836749143898, "Avg game time in secs": 2.1607910837919917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.52, "agent_stopped_0": 0.49}, "Total num played games": 64000, "Total num trained steps": 127329, "Timestamp in ms": 1701486803837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896891110763943, "Avg loss": 0.3881479959236458, "Avg value loss": 0.11274622491328046, "Avg policy loss": 0.2754017725819722, "Total num played games": 64010, "Total num trained steps": 127360, "Timestamp in ms": 1701486817783, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916887986252148, "Avg loss": 0.3577352277934551, "Avg value loss": 0.0782129586150404, "Avg policy loss": 0.27952226798515767, "Total num played games": 64010, "Total num trained steps": 127488, "Timestamp in ms": 1701486874597, "logtype": "training_step"}
{"Total num played games": 64104, "Total num trained steps": 127587, "Timestamp in ms": 1701486931653, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.390625}
{"Avg objective": 21.0703125, "Games time in secs": 130.54316600225866, "Avg game time in secs": 2.2193956976698246, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 64128, "Total num trained steps": 127591, "Timestamp in ms": 1701486934381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878500887878128, "Avg loss": 0.5240746469935402, "Avg value loss": 0.24018060264643282, "Avg policy loss": 0.2838940431829542, "Total num played games": 64198, "Total num trained steps": 127616, "Timestamp in ms": 1701486945850, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898439203713512, "Avg loss": 0.38235506718046963, "Avg value loss": 0.09057915513403714, "Avg policy loss": 0.2917759146075696, "Total num played games": 64198, "Total num trained steps": 127744, "Timestamp in ms": 1701487003526, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918377519548895, "Avg loss": 0.32673316448926926, "Avg value loss": 0.04606401137425564, "Avg policy loss": 0.28066915553063154, "Total num played games": 64198, "Total num trained steps": 127872, "Timestamp in ms": 1701487062038, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 135.9290195275098, "Avg game time in secs": 2.057990594956209, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.43, "agent_stopped_0": 0.58}, "Total num played games": 64256, "Total num trained steps": 127890, "Timestamp in ms": 1701487070310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909164437255025, "Avg loss": 0.422769759548828, "Avg value loss": 0.13801463489653543, "Avg policy loss": 0.28475512785371393, "Total num played games": 64292, "Total num trained steps": 128000, "Timestamp in ms": 1701487118520, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 83.38051191531122, "Avg game time in secs": 2.241757633993984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 64384, "Total num trained steps": 128081, "Timestamp in ms": 1701487153690, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899360129216623, "Avg loss": 0.39141463581472635, "Avg value loss": 0.11450385738862678, "Avg policy loss": 0.2769107799977064, "Total num played games": 64388, "Total num trained steps": 128128, "Timestamp in ms": 1701487174296, "logtype": "training_step"}
{"Total num played games": 64388, "Total num trained steps": 128189, "Timestamp in ms": 1701487212511, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Ratio train steps to played games": 1.9890201916813994, "Avg loss": 0.4649676950648427, "Avg value loss": 0.1843291137192864, "Avg policy loss": 0.28063858789391816, "Total num played games": 64482, "Total num trained steps": 128256, "Timestamp in ms": 1701487242939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910052417728978, "Avg loss": 0.351801210665144, "Avg value loss": 0.06181799518526532, "Avg policy loss": 0.2899832137627527, "Total num played games": 64482, "Total num trained steps": 128384, "Timestamp in ms": 1701487300001, "logtype": "training_step"}
{"Avg objective": 20.15625, "Games time in secs": 178.70032837614417, "Avg game time in secs": 1.9314680008246796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 64512, "Total num trained steps": 128457, "Timestamp in ms": 1701487332391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900737115956393, "Avg loss": 0.3918503781314939, "Avg value loss": 0.11159268007031642, "Avg policy loss": 0.28025769675150514, "Total num played games": 64576, "Total num trained steps": 128512, "Timestamp in ms": 1701487357018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920713577799802, "Avg loss": 0.33632268523797393, "Avg value loss": 0.05690578857320361, "Avg policy loss": 0.27941689698491246, "Total num played games": 64576, "Total num trained steps": 128640, "Timestamp in ms": 1701487413975, "logtype": "training_step"}
{"Avg objective": 19.921875, "Games time in secs": 84.73840965889394, "Avg game time in secs": 2.1333616355987033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 64640, "Total num trained steps": 128647, "Timestamp in ms": 1701487417129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911550950981909, "Avg loss": 0.43259367102291435, "Avg value loss": 0.13579082598153036, "Avg policy loss": 0.2968028470641002, "Total num played games": 64670, "Total num trained steps": 128768, "Timestamp in ms": 1701487471331, "logtype": "training_step"}
{"Total num played games": 64670, "Total num trained steps": 128793, "Timestamp in ms": 1701487496200, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.46484375}
{"Ratio train steps to played games": 1.9902414921870175, "Avg loss": 0.4202677025459707, "Avg value loss": 0.12102365421014838, "Avg policy loss": 0.29924405203200877, "Total num played games": 64764, "Total num trained steps": 128896, "Timestamp in ms": 1701487543745, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 181.44789429195225, "Avg game time in secs": 2.2267510742822196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 64768, "Total num trained steps": 129019, "Timestamp in ms": 1701487598577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900055524708495, "Avg loss": 0.3339967743959278, "Avg value loss": 0.05188007341348566, "Avg policy loss": 0.28211670089513063, "Total num played games": 64834, "Total num trained steps": 129024, "Timestamp in ms": 1701487600485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913040796817663, "Avg loss": 0.4660515831783414, "Avg value loss": 0.159576554375235, "Avg policy loss": 0.30647502571810037, "Total num played games": 64858, "Total num trained steps": 129152, "Timestamp in ms": 1701487656086, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 82.78942881524563, "Avg game time in secs": 2.008997219032608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 64896, "Total num trained steps": 129209, "Timestamp in ms": 1701487681367, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903929055302376, "Avg loss": 0.47415154217742383, "Avg value loss": 0.1777015516126994, "Avg policy loss": 0.2964499912923202, "Total num played games": 64952, "Total num trained steps": 129280, "Timestamp in ms": 1701487713696, "logtype": "training_step"}
{"Total num played games": 64952, "Total num trained steps": 129393, "Timestamp in ms": 1701487780118, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.69921875}
{"Avg objective": 20.75, "Games time in secs": 102.50711780972779, "Avg game time in secs": 2.196174583179527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.59}, "Total num played games": 65024, "Total num trained steps": 129401, "Timestamp in ms": 1701487783875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894231951789447, "Avg loss": 0.36437821900472045, "Avg value loss": 0.07844083374948241, "Avg policy loss": 0.2859373880783096, "Total num played games": 65048, "Total num trained steps": 129408, "Timestamp in ms": 1701487786781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913909728200714, "Avg loss": 0.4169859467074275, "Avg value loss": 0.13270779146114364, "Avg policy loss": 0.28427815181203187, "Total num played games": 65048, "Total num trained steps": 129536, "Timestamp in ms": 1701487842247, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904823309078628, "Avg loss": 0.39288254105485976, "Avg value loss": 0.11275254350039177, "Avg policy loss": 0.280129999271594, "Total num played games": 65142, "Total num trained steps": 129664, "Timestamp in ms": 1701487896336, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 160.79938657209277, "Avg game time in secs": 2.075556206749752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 65152, "Total num trained steps": 129776, "Timestamp in ms": 1701487944674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895763075602428, "Avg loss": 0.35911805264186114, "Avg value loss": 0.08647258626297116, "Avg policy loss": 0.2726454639341682, "Total num played games": 65236, "Total num trained steps": 129792, "Timestamp in ms": 1701487951392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915384143724324, "Avg loss": 0.3873230363242328, "Avg value loss": 0.10074166845879517, "Avg policy loss": 0.28658136911690235, "Total num played games": 65236, "Total num trained steps": 129920, "Timestamp in ms": 1701488007499, "logtype": "training_step"}
{"Avg objective": 19.6640625, "Games time in secs": 82.73836280964315, "Avg game time in secs": 2.101345143193612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 65280, "Total num trained steps": 129966, "Timestamp in ms": 1701488027413, "logtype": "played_game"}
{"Total num played games": 65332, "Total num trained steps": 129993, "Timestamp in ms": 1701488054856, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5078125}
{"Avg objective": 20.90625, "Games time in secs": 31.21667530760169, "Avg game time in secs": 2.1296321838890435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 65408, "Total num trained steps": 130001, "Timestamp in ms": 1701488058630, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876960229878031, "Avg loss": 0.5204264468047768, "Avg value loss": 0.23166766970825847, "Avg policy loss": 0.28875877731479704, "Total num played games": 65426, "Total num trained steps": 130048, "Timestamp in ms": 1701488079242, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896524317549598, "Avg loss": 0.3774250887800008, "Avg value loss": 0.08379359808168374, "Avg policy loss": 0.29363148950506, "Total num played games": 65426, "Total num trained steps": 130176, "Timestamp in ms": 1701488136235, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99162412496561, "Avg loss": 0.3213707407703623, "Avg value loss": 0.049633349117357284, "Avg policy loss": 0.2717373949708417, "Total num played games": 65426, "Total num trained steps": 130304, "Timestamp in ms": 1701488192344, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907203907203908, "Avg loss": 0.37906295934226364, "Avg value loss": 0.10906974246609025, "Avg policy loss": 0.26999321684706956, "Total num played games": 65520, "Total num trained steps": 130432, "Timestamp in ms": 1701488248659, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 233.3969726804644, "Avg game time in secs": 1.9106818858272163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.43, "agent_stopped_0": 0.63}, "Total num played games": 65536, "Total num trained steps": 130531, "Timestamp in ms": 1701488292027, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989819245892645, "Avg loss": 0.36862189800012857, "Avg value loss": 0.0966027962276712, "Avg policy loss": 0.27201910002622753, "Total num played games": 65614, "Total num trained steps": 130560, "Timestamp in ms": 1701488304327, "logtype": "training_step"}
{"Total num played games": 65614, "Total num trained steps": 130595, "Timestamp in ms": 1701488335649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9609375}
{"Avg objective": 21.0234375, "Games time in secs": 46.57416376657784, "Avg game time in secs": 2.0142851053824415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.37}, "Total num played games": 65664, "Total num trained steps": 130601, "Timestamp in ms": 1701488338601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988920679369331, "Avg loss": 0.47481358074583113, "Avg value loss": 0.1886084385914728, "Avg policy loss": 0.28620514448266476, "Total num played games": 65708, "Total num trained steps": 130688, "Timestamp in ms": 1701488379357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908686917879101, "Avg loss": 0.3242797751445323, "Avg value loss": 0.051385422848397866, "Avg policy loss": 0.2728943530237302, "Total num played games": 65708, "Total num trained steps": 130816, "Timestamp in ms": 1701488437558, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 141.16343050263822, "Avg game time in secs": 2.1281368659692816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 65792, "Total num trained steps": 130912, "Timestamp in ms": 1701488479764, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899699097291876, "Avg loss": 0.37907044659368694, "Avg value loss": 0.10994691094674636, "Avg policy loss": 0.26912353292573243, "Total num played games": 65802, "Total num trained steps": 130944, "Timestamp in ms": 1701488494535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919151393574663, "Avg loss": 0.3737470917403698, "Avg value loss": 0.09786917705787346, "Avg policy loss": 0.2758779141586274, "Total num played games": 65802, "Total num trained steps": 131072, "Timestamp in ms": 1701488551820, "logtype": "training_step"}
{"Total num played games": 65896, "Total num trained steps": 131197, "Timestamp in ms": 1701488620141, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.890625}
{"Ratio train steps to played games": 1.9908348760280417, "Avg loss": 0.4384253427851945, "Avg value loss": 0.15543057105969638, "Avg policy loss": 0.2829947704449296, "Total num played games": 65902, "Total num trained steps": 131200, "Timestamp in ms": 1701488622301, "logtype": "training_step"}
{"Avg objective": 21.234375, "Games time in secs": 143.03363895975053, "Avg game time in secs": 2.102655329523259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 65920, "Total num trained steps": 131201, "Timestamp in ms": 1701488622798, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901197151083498, "Avg loss": 0.445499939378351, "Avg value loss": 0.15895156297483481, "Avg policy loss": 0.28654837771318853, "Total num played games": 65990, "Total num trained steps": 131328, "Timestamp in ms": 1701488678850, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920594029398393, "Avg loss": 0.3186451636720449, "Avg value loss": 0.049103953686426394, "Avg policy loss": 0.2695412104949355, "Total num played games": 65990, "Total num trained steps": 131456, "Timestamp in ms": 1701488736944, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 121.75085400603712, "Avg game time in secs": 1.8970538875437342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 66048, "Total num trained steps": 131474, "Timestamp in ms": 1701488744549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911476302887234, "Avg loss": 0.44696358940564096, "Avg value loss": 0.15712885462562554, "Avg policy loss": 0.2898347368463874, "Total num played games": 66084, "Total num trained steps": 131584, "Timestamp in ms": 1701488795218, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 87.20153324306011, "Avg game time in secs": 2.2569187915651128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 66176, "Total num trained steps": 131667, "Timestamp in ms": 1701488831751, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902535585844239, "Avg loss": 0.4054107062984258, "Avg value loss": 0.12409951890003867, "Avg policy loss": 0.2813111904542893, "Total num played games": 66178, "Total num trained steps": 131712, "Timestamp in ms": 1701488851197, "logtype": "training_step"}
{"Total num played games": 66178, "Total num trained steps": 131797, "Timestamp in ms": 1701488902402, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.953125}
{"Ratio train steps to played games": 1.9893771125060358, "Avg loss": 0.4149497130420059, "Avg value loss": 0.1280729063146282, "Avg policy loss": 0.2868768034968525, "Total num played games": 66272, "Total num trained steps": 131840, "Timestamp in ms": 1701488922325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913085465958473, "Avg loss": 0.36134383850730956, "Avg value loss": 0.07281925235292874, "Avg policy loss": 0.28852458659093827, "Total num played games": 66272, "Total num trained steps": 131968, "Timestamp in ms": 1701488977958, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 176.08647199347615, "Avg game time in secs": 1.98502846264455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.4, "agent_stopped_0": 0.62}, "Total num played games": 66304, "Total num trained steps": 132037, "Timestamp in ms": 1701489007837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904167796763403, "Avg loss": 0.4349855442997068, "Avg value loss": 0.14776332778274082, "Avg policy loss": 0.28722221916541457, "Total num played games": 66366, "Total num trained steps": 132096, "Timestamp in ms": 1701489033402, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991970231100666, "Avg loss": 0.3575801707338542, "Avg value loss": 0.07095935373217799, "Avg policy loss": 0.28662081889342517, "Total num played games": 66374, "Total num trained steps": 132224, "Timestamp in ms": 1701489088934, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 82.17596151307225, "Avg game time in secs": 2.074309847463155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 66432, "Total num trained steps": 132226, "Timestamp in ms": 1701489090013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914535058681915, "Avg loss": 0.4433900157455355, "Avg value loss": 0.14724391454365104, "Avg policy loss": 0.29614609898999333, "Total num played games": 66460, "Total num trained steps": 132352, "Timestamp in ms": 1701489144954, "logtype": "training_step"}
{"Total num played games": 66460, "Total num trained steps": 132398, "Timestamp in ms": 1701489178076, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.01171875}
{"Ratio train steps to played games": 1.9905640532499924, "Avg loss": 0.41388086043298244, "Avg value loss": 0.12506011439836584, "Avg policy loss": 0.28882074798457325, "Total num played games": 66554, "Total num trained steps": 132480, "Timestamp in ms": 1701489214212, "logtype": "training_step"}
{"Avg objective": 20.5546875, "Games time in secs": 177.21880383603275, "Avg game time in secs": 2.25668106842204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.56}, "Total num played games": 66560, "Total num trained steps": 132599, "Timestamp in ms": 1701489267232, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896771095906853, "Avg loss": 0.3529443545266986, "Avg value loss": 0.07052613864652812, "Avg policy loss": 0.2824182159965858, "Total num played games": 66648, "Total num trained steps": 132608, "Timestamp in ms": 1701489271019, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915976473412556, "Avg loss": 0.4094262047437951, "Avg value loss": 0.13713462627492845, "Avg policy loss": 0.27229157858528197, "Total num played games": 66648, "Total num trained steps": 132736, "Timestamp in ms": 1701489329192, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 86.28511086292565, "Avg game time in secs": 1.9224736509349896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 66688, "Total num trained steps": 132788, "Timestamp in ms": 1701489353518, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990650845019777, "Avg loss": 0.44436082371976227, "Avg value loss": 0.16959395905723795, "Avg policy loss": 0.2747668599477038, "Total num played games": 66744, "Total num trained steps": 132864, "Timestamp in ms": 1701489387504, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 85.81885431148112, "Avg game time in secs": 2.158341626593028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 66816, "Total num trained steps": 132983, "Timestamp in ms": 1701489439338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897663006074389, "Avg loss": 0.3380397899309173, "Avg value loss": 0.07006373602780513, "Avg policy loss": 0.26797605375759304, "Total num played games": 66838, "Total num trained steps": 132992, "Timestamp in ms": 1701489442915, "logtype": "training_step"}
{"Total num played games": 66838, "Total num trained steps": 133001, "Timestamp in ms": 1701489461191, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2578125}
{"Ratio train steps to played games": 1.9888842407219267, "Avg loss": 0.5303861873690039, "Avg value loss": 0.21757646391051821, "Avg policy loss": 0.3128097258741036, "Total num played games": 66932, "Total num trained steps": 133120, "Timestamp in ms": 1701489512872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907966294149286, "Avg loss": 0.34954218030907214, "Avg value loss": 0.058810319867916405, "Avg policy loss": 0.29073185950983316, "Total num played games": 66932, "Total num trained steps": 133248, "Timestamp in ms": 1701489569827, "logtype": "training_step"}
{"Avg objective": 20.1875, "Games time in secs": 178.64189026132226, "Avg game time in secs": 2.3224866549426224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 66944, "Total num trained steps": 133356, "Timestamp in ms": 1701489617980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899143615910244, "Avg loss": 0.3759437457192689, "Avg value loss": 0.10105338779976591, "Avg policy loss": 0.2748903619358316, "Total num played games": 67026, "Total num trained steps": 133376, "Timestamp in ms": 1701489627070, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918240682720139, "Avg loss": 0.39906548243016005, "Avg value loss": 0.10779061791254207, "Avg policy loss": 0.29127486736979336, "Total num played games": 67026, "Total num trained steps": 133504, "Timestamp in ms": 1701489683497, "logtype": "training_step"}
{"Avg objective": 19.6796875, "Games time in secs": 84.35702958330512, "Avg game time in secs": 2.061422895785654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 67072, "Total num trained steps": 133546, "Timestamp in ms": 1701489702337, "logtype": "played_game"}
{"Total num played games": 67120, "Total num trained steps": 133601, "Timestamp in ms": 1701489740628, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.796875}
{"Avg objective": 20.796875, "Games time in secs": 42.19927912019193, "Avg game time in secs": 2.198425255337497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 67200, "Total num trained steps": 133609, "Timestamp in ms": 1701489744536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881572291486893, "Avg loss": 0.5309355987701565, "Avg value loss": 0.230103616573615, "Avg policy loss": 0.30083198205102235, "Total num played games": 67214, "Total num trained steps": 133632, "Timestamp in ms": 1701489754912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900615943107092, "Avg loss": 0.4242681497707963, "Avg value loss": 0.11524803197244182, "Avg policy loss": 0.30902011680882424, "Total num played games": 67214, "Total num trained steps": 133760, "Timestamp in ms": 1701489811536, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919659594727288, "Avg loss": 0.3351683708606288, "Avg value loss": 0.051988913415698335, "Avg policy loss": 0.28317945974413306, "Total num played games": 67214, "Total num trained steps": 133888, "Timestamp in ms": 1701489867469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910857550365484, "Avg loss": 0.3977856293786317, "Avg value loss": 0.11478731912211515, "Avg policy loss": 0.2829983099363744, "Total num played games": 67308, "Total num trained steps": 134016, "Timestamp in ms": 1701489924354, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 220.40986154973507, "Avg game time in secs": 2.147702332236804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 67328, "Total num trained steps": 134108, "Timestamp in ms": 1701489964947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902080056971603, "Avg loss": 0.38060213543940336, "Avg value loss": 0.11392117309151217, "Avg policy loss": 0.26668096624780446, "Total num played games": 67402, "Total num trained steps": 134144, "Timestamp in ms": 1701489981213, "logtype": "training_step"}
{"Total num played games": 67402, "Total num trained steps": 134205, "Timestamp in ms": 1701490020962, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.92578125}
{"Avg objective": 20.0625, "Games time in secs": 59.13287522830069, "Avg game time in secs": 1.9350323971593753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.39}, "Total num played games": 67456, "Total num trained steps": 134209, "Timestamp in ms": 1701490024080, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989332701197108, "Avg loss": 0.4407107261940837, "Avg value loss": 0.15893667604541406, "Avg policy loss": 0.281774053000845, "Total num played games": 67496, "Total num trained steps": 134272, "Timestamp in ms": 1701490051372, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912291098731776, "Avg loss": 0.35439149767626077, "Avg value loss": 0.07607499620644376, "Avg policy loss": 0.27831650292500854, "Total num played games": 67496, "Total num trained steps": 134400, "Timestamp in ms": 1701490107239, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 121.73180057294667, "Avg game time in secs": 2.2056418043066515, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 67584, "Total num trained steps": 134490, "Timestamp in ms": 1701490145811, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903536026039355, "Avg loss": 0.38143956172280014, "Avg value loss": 0.1052288607461378, "Avg policy loss": 0.2762106992304325, "Total num played games": 67590, "Total num trained steps": 134528, "Timestamp in ms": 1701490162632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922473738718744, "Avg loss": 0.3402400186751038, "Avg value loss": 0.06686924563837238, "Avg policy loss": 0.2733707735314965, "Total num played games": 67590, "Total num trained steps": 134656, "Timestamp in ms": 1701490219640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913716683411147, "Avg loss": 0.43509664479643106, "Avg value loss": 0.13987709837965667, "Avg policy loss": 0.2952195481630042, "Total num played games": 67684, "Total num trained steps": 134784, "Timestamp in ms": 1701490274912, "logtype": "training_step"}
{"Total num played games": 67684, "Total num trained steps": 134805, "Timestamp in ms": 1701490297683, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8046875}
{"Avg objective": 21.828125, "Games time in secs": 154.54906475171447, "Avg game time in secs": 2.187609078915557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 67712, "Total num trained steps": 134810, "Timestamp in ms": 1701490300361, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904983918085515, "Avg loss": 0.44618529872968793, "Avg value loss": 0.15424604760482907, "Avg policy loss": 0.29193925438448787, "Total num played games": 67778, "Total num trained steps": 134912, "Timestamp in ms": 1701490345512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923869102068519, "Avg loss": 0.3212770096724853, "Avg value loss": 0.05279517093731556, "Avg policy loss": 0.26848183723632246, "Total num played games": 67778, "Total num trained steps": 135040, "Timestamp in ms": 1701490402180, "logtype": "training_step"}
{"Avg objective": 19.671875, "Games time in secs": 106.28569879755378, "Avg game time in secs": 2.029745117048151, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.46}, "Total num played games": 67840, "Total num trained steps": 135050, "Timestamp in ms": 1701490406647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991454754397855, "Avg loss": 0.4384592422284186, "Avg value loss": 0.15422385031706654, "Avg policy loss": 0.28423539153300226, "Total num played games": 67874, "Total num trained steps": 135168, "Timestamp in ms": 1701490457998, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 85.50003753602505, "Avg game time in secs": 2.2843720793607645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 67968, "Total num trained steps": 135246, "Timestamp in ms": 1701490492147, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905252317198765, "Avg loss": 0.4145127913216129, "Avg value loss": 0.13218776632857043, "Avg policy loss": 0.28232502401806414, "Total num played games": 67970, "Total num trained steps": 135296, "Timestamp in ms": 1701490512903, "logtype": "training_step"}
{"Total num played games": 67970, "Total num trained steps": 135405, "Timestamp in ms": 1701490576743, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.28125}
{"Ratio train steps to played games": 1.9896567936060179, "Avg loss": 0.3609324914868921, "Avg value loss": 0.08714422330376692, "Avg policy loss": 0.27378826891072094, "Total num played games": 68064, "Total num trained steps": 135424, "Timestamp in ms": 1701490585048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991522684532205, "Avg loss": 0.4199428795836866, "Avg value loss": 0.12437940126983449, "Avg policy loss": 0.29556347453035414, "Total num played games": 68064, "Total num trained steps": 135552, "Timestamp in ms": 1701490641435, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 180.14937509968877, "Avg game time in secs": 1.9573785086977296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.45, "agent_stopped_0": 0.6}, "Total num played games": 68096, "Total num trained steps": 135621, "Timestamp in ms": 1701490672296, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905956572769954, "Avg loss": 0.45023294363636523, "Avg value loss": 0.15826735932205338, "Avg policy loss": 0.2919655899750069, "Total num played games": 68160, "Total num trained steps": 135680, "Timestamp in ms": 1701490697548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924735915492957, "Avg loss": 0.3800756454002112, "Avg value loss": 0.08007895082118921, "Avg policy loss": 0.29999669699463993, "Total num played games": 68160, "Total num trained steps": 135808, "Timestamp in ms": 1701490754228, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 85.02630540728569, "Avg game time in secs": 2.27958944819693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 68224, "Total num trained steps": 135815, "Timestamp in ms": 1701490757323, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916195387816098, "Avg loss": 0.4351868014782667, "Avg value loss": 0.13185832486487925, "Avg policy loss": 0.3033284777775407, "Total num played games": 68254, "Total num trained steps": 135936, "Timestamp in ms": 1701490811096, "logtype": "training_step"}
{"Total num played games": 68348, "Total num trained steps": 136007, "Timestamp in ms": 1701490855489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5625}
{"Avg objective": 20.8828125, "Games time in secs": 100.22025568410754, "Avg game time in secs": 2.5123589006398106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.61}, "Total num played games": 68352, "Total num trained steps": 136011, "Timestamp in ms": 1701490857543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880044417170744, "Avg loss": 0.5384363329503685, "Avg value loss": 0.22835009658592753, "Avg policy loss": 0.31008624006062746, "Total num played games": 68442, "Total num trained steps": 136064, "Timestamp in ms": 1701490883069, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989889249291371, "Avg loss": 0.4026468510273844, "Avg value loss": 0.08931985977687873, "Avg policy loss": 0.31332699209451675, "Total num played games": 68442, "Total num trained steps": 136192, "Timestamp in ms": 1701490939262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917594459542387, "Avg loss": 0.33920144417788833, "Avg value loss": 0.05073624037322588, "Avg policy loss": 0.28846520208753645, "Total num played games": 68442, "Total num trained steps": 136320, "Timestamp in ms": 1701490995037, "logtype": "training_step"}
{"Avg objective": 19.203125, "Games time in secs": 162.42606288939714, "Avg game time in secs": 2.1838190606213175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 68480, "Total num trained steps": 136378, "Timestamp in ms": 1701491019970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908807050309327, "Avg loss": 0.4200364227872342, "Avg value loss": 0.12321378452179488, "Avg policy loss": 0.29682263813447207, "Total num played games": 68536, "Total num trained steps": 136448, "Timestamp in ms": 1701491050169, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 83.60981424339116, "Avg game time in secs": 2.0937189275718993, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.48, "agent_stopped_0": 0.54}, "Total num played games": 68608, "Total num trained steps": 136567, "Timestamp in ms": 1701491103580, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900335130409441, "Avg loss": 0.36850309593137354, "Avg value loss": 0.07744560114224441, "Avg policy loss": 0.29105749598238617, "Total num played games": 68630, "Total num trained steps": 136576, "Timestamp in ms": 1701491107349, "logtype": "training_step"}
{"Total num played games": 68632, "Total num trained steps": 136608, "Timestamp in ms": 1701491133858, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.55078125}
{"Ratio train steps to played games": 1.9891162005645606, "Avg loss": 0.5595821249298751, "Avg value loss": 0.23513110779458657, "Avg policy loss": 0.3244510175427422, "Total num played games": 68726, "Total num trained steps": 136704, "Timestamp in ms": 1701491180993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909786689171494, "Avg loss": 0.36548823420889676, "Avg value loss": 0.06215967843309045, "Avg policy loss": 0.3033285546116531, "Total num played games": 68726, "Total num trained steps": 136832, "Timestamp in ms": 1701491239140, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 185.75840328261256, "Avg game time in secs": 2.3517577945021912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.62}, "Total num played games": 68736, "Total num trained steps": 136944, "Timestamp in ms": 1701491289338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900034871556433, "Avg loss": 0.38414311211090535, "Avg value loss": 0.08885097099118866, "Avg policy loss": 0.29529213928617537, "Total num played games": 68824, "Total num trained steps": 136960, "Timestamp in ms": 1701491296056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918633034987796, "Avg loss": 0.4363859093282372, "Avg value loss": 0.11650957737583667, "Avg policy loss": 0.3198763314867392, "Total num played games": 68824, "Total num trained steps": 137088, "Timestamp in ms": 1701491352941, "logtype": "training_step"}
{"Avg objective": 19.7578125, "Games time in secs": 87.33905029855669, "Avg game time in secs": 2.071981269007665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 68864, "Total num trained steps": 137142, "Timestamp in ms": 1701491376679, "logtype": "played_game"}
{"Total num played games": 68918, "Total num trained steps": 137212, "Timestamp in ms": 1701491419367, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.81640625}
{"Ratio train steps to played games": 1.9901952252487454, "Avg loss": 0.4349798683542758, "Avg value loss": 0.1244698105729185, "Avg policy loss": 0.3105100595857948, "Total num played games": 68942, "Total num trained steps": 137216, "Timestamp in ms": 1701491422007, "logtype": "training_step"}
{"Avg objective": 20.1953125, "Games time in secs": 46.56637015752494, "Avg game time in secs": 2.286615906559746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 68992, "Total num trained steps": 137218, "Timestamp in ms": 1701491423245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901466411638555, "Avg loss": 0.5096059083007276, "Avg value loss": 0.17322158804745413, "Avg policy loss": 0.3363843197003007, "Total num played games": 69012, "Total num trained steps": 137344, "Timestamp in ms": 1701491480108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992001391062424, "Avg loss": 0.35484249284490943, "Avg value loss": 0.047015037533128634, "Avg policy loss": 0.3078274562722072, "Total num played games": 69012, "Total num trained steps": 137472, "Timestamp in ms": 1701491537153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911440395913524, "Avg loss": 0.4634234888944775, "Avg value loss": 0.149887267005397, "Avg policy loss": 0.3135362162720412, "Total num played games": 69106, "Total num trained steps": 137600, "Timestamp in ms": 1701491594793, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 217.2258816510439, "Avg game time in secs": 2.4502227351767942, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.66, "agent_stopped_0": 0.42}, "Total num played games": 69120, "Total num trained steps": 137704, "Timestamp in ms": 1701491640471, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902890173410404, "Avg loss": 0.4035265740239993, "Avg value loss": 0.10050477593904361, "Avg policy loss": 0.3030217931373045, "Total num played games": 69200, "Total num trained steps": 137728, "Timestamp in ms": 1701491650943, "logtype": "training_step"}
{"Total num played games": 69200, "Total num trained steps": 137815, "Timestamp in ms": 1701491704861, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.51953125}
{"Avg objective": 20.234375, "Games time in secs": 67.60991115309298, "Avg game time in secs": 2.121986735932296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 69248, "Total num trained steps": 137820, "Timestamp in ms": 1701491708081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989436314832453, "Avg loss": 0.47395013796631247, "Avg value loss": 0.16492776697850786, "Avg policy loss": 0.30902237130794674, "Total num played games": 69294, "Total num trained steps": 137856, "Timestamp in ms": 1701491724294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912835166103848, "Avg loss": 0.39075977611355484, "Avg value loss": 0.08545777760446072, "Avg policy loss": 0.3053019955987111, "Total num played games": 69294, "Total num trained steps": 137984, "Timestamp in ms": 1701491782250, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 117.9534564241767, "Avg game time in secs": 2.2840940327732824, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 69376, "Total num trained steps": 138084, "Timestamp in ms": 1701491826035, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.40409255819395185, "Avg value loss": 0.10229923843871802, "Avg policy loss": 0.3017933175433427, "Total num played games": 69388, "Total num trained steps": 138112, "Timestamp in ms": 1701491838244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922753213812185, "Avg loss": 0.36828808835707605, "Avg value loss": 0.06535438500577584, "Avg policy loss": 0.30293370236177, "Total num played games": 69388, "Total num trained steps": 138240, "Timestamp in ms": 1701491894731, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913649185423983, "Avg loss": 0.44665455573704094, "Avg value loss": 0.14398800616618246, "Avg policy loss": 0.30266654782462865, "Total num played games": 69484, "Total num trained steps": 138368, "Timestamp in ms": 1701491952441, "logtype": "training_step"}
{"Total num played games": 69484, "Total num trained steps": 138418, "Timestamp in ms": 1701491987185, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8515625}
{"Avg objective": 21.15625, "Games time in secs": 163.97519060224295, "Avg game time in secs": 2.2636131371109514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 69504, "Total num trained steps": 138423, "Timestamp in ms": 1701491990010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905142430078473, "Avg loss": 0.4738674352411181, "Avg value loss": 0.1676697322691325, "Avg policy loss": 0.3061977028846741, "Total num played games": 69578, "Total num trained steps": 138496, "Timestamp in ms": 1701492022224, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923539049699617, "Avg loss": 0.37308906740508974, "Avg value loss": 0.062157263077097014, "Avg policy loss": 0.310931803076528, "Total num played games": 69578, "Total num trained steps": 138624, "Timestamp in ms": 1701492079683, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 100.89133730717003, "Avg game time in secs": 2.0818139162583975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 69632, "Total num trained steps": 138651, "Timestamp in ms": 1701492090902, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991503042829257, "Avg loss": 0.4195578962098807, "Avg value loss": 0.12268352002138272, "Avg policy loss": 0.2968743764795363, "Total num played games": 69672, "Total num trained steps": 138752, "Timestamp in ms": 1701492136141, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 85.56288664788008, "Avg game time in secs": 2.3554419231950305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 69760, "Total num trained steps": 138841, "Timestamp in ms": 1701492176465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906544735257863, "Avg loss": 0.4221525117754936, "Avg value loss": 0.1326712376321666, "Avg policy loss": 0.2894812738522887, "Total num played games": 69766, "Total num trained steps": 138880, "Timestamp in ms": 1701492193911, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992489178109681, "Avg loss": 0.3759607324609533, "Avg value loss": 0.08012761562713422, "Avg policy loss": 0.29583311825990677, "Total num played games": 69766, "Total num trained steps": 139008, "Timestamp in ms": 1701492251773, "logtype": "training_step"}
{"Total num played games": 69858, "Total num trained steps": 139022, "Timestamp in ms": 1701492269394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.15625}
{"Avg objective": 21.0625, "Games time in secs": 95.74251641519368, "Avg game time in secs": 2.089201304479502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.42, "agent_stopped_0": 0.59}, "Total num played games": 69888, "Total num trained steps": 139026, "Timestamp in ms": 1701492272207, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989021043000915, "Avg loss": 0.5917101253289729, "Avg value loss": 0.281925533170579, "Avg policy loss": 0.30978459178004414, "Total num played games": 69952, "Total num trained steps": 139136, "Timestamp in ms": 1701492322577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908508691674291, "Avg loss": 0.36017442459706217, "Avg value loss": 0.06393513022339903, "Avg policy loss": 0.2962392943445593, "Total num played games": 69952, "Total num trained steps": 139264, "Timestamp in ms": 1701492377798, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926806953339433, "Avg loss": 0.32405685423873365, "Avg value loss": 0.04766193118121009, "Avg policy loss": 0.2763949242653325, "Total num played games": 69952, "Total num trained steps": 139392, "Timestamp in ms": 1701492435397, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 165.90576869621873, "Avg game time in secs": 2.0899268554057926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.45, "agent_stopped_0": 0.56}, "Total num played games": 70016, "Total num trained steps": 139399, "Timestamp in ms": 1701492438113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991833937698084, "Avg loss": 0.47430908458773047, "Avg value loss": 0.1844724080292508, "Avg policy loss": 0.2898366756271571, "Total num played games": 70046, "Total num trained steps": 139520, "Timestamp in ms": 1701492492760, "logtype": "training_step"}
{"Total num played games": 70142, "Total num trained steps": 139624, "Timestamp in ms": 1701492549215, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.46484375}
{"Avg objective": 21.078125, "Games time in secs": 112.35281840525568, "Avg game time in secs": 2.2888396339840256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 70144, "Total num trained steps": 139625, "Timestamp in ms": 1701492550466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882681246084628, "Avg loss": 0.46727281622588634, "Avg value loss": 0.17589742201380432, "Avg policy loss": 0.2913753936300054, "Total num played games": 70236, "Total num trained steps": 139648, "Timestamp in ms": 1701492560721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900905518537502, "Avg loss": 0.3987003677757457, "Avg value loss": 0.11149792786454782, "Avg policy loss": 0.28720244101714343, "Total num played games": 70236, "Total num trained steps": 139776, "Timestamp in ms": 1701492620316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919129790990375, "Avg loss": 0.3229939042357728, "Avg value loss": 0.04600492151803337, "Avg policy loss": 0.27698897989466786, "Total num played games": 70236, "Total num trained steps": 139904, "Timestamp in ms": 1701492676403, "logtype": "training_step"}
{"Avg objective": 19.4609375, "Games time in secs": 152.38566260412335, "Avg game time in secs": 1.9808942978270352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.44}, "Total num played games": 70272, "Total num trained steps": 139966, "Timestamp in ms": 1701492702852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910140476596714, "Avg loss": 0.41442101704888046, "Avg value loss": 0.1348403713782318, "Avg policy loss": 0.2795806465437636, "Total num played games": 70332, "Total num trained steps": 140032, "Timestamp in ms": 1701492731588, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 85.03680828399956, "Avg game time in secs": 2.046180836870917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 70400, "Total num trained steps": 140159, "Timestamp in ms": 1701492787889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906121289589547, "Avg loss": 0.3293311431771144, "Avg value loss": 0.060062870194087736, "Avg policy loss": 0.2692682724446058, "Total num played games": 70410, "Total num trained steps": 140160, "Timestamp in ms": 1701492788182, "logtype": "training_step"}
{"Total num played games": 70426, "Total num trained steps": 140227, "Timestamp in ms": 1701492827903, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.265625}
{"Ratio train steps to played games": 1.9893363584798638, "Avg loss": 0.4988724880386144, "Avg value loss": 0.20721928030252457, "Avg policy loss": 0.29165320936590433, "Total num played games": 70520, "Total num trained steps": 140288, "Timestamp in ms": 1701492854185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911372660238231, "Avg loss": 0.32988253596704453, "Avg value loss": 0.061224816789035685, "Avg policy loss": 0.26865771878510714, "Total num played games": 70520, "Total num trained steps": 140416, "Timestamp in ms": 1701492909900, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 174.32672391459346, "Avg game time in secs": 2.2583145666867495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 70528, "Total num trained steps": 140531, "Timestamp in ms": 1701492962216, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903135355595207, "Avg loss": 0.3359136156504974, "Avg value loss": 0.06939116075227503, "Avg policy loss": 0.26652245491277426, "Total num played games": 70614, "Total num trained steps": 140544, "Timestamp in ms": 1701492967651, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921262072676806, "Avg loss": 0.35723888932261616, "Avg value loss": 0.09290269421762787, "Avg policy loss": 0.26433619495946914, "Total num played games": 70614, "Total num trained steps": 140672, "Timestamp in ms": 1701493024594, "logtype": "training_step"}
{"Avg objective": 19.828125, "Games time in secs": 84.53545905277133, "Avg game time in secs": 1.8827600596705452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.39}, "Total num played games": 70656, "Total num trained steps": 140721, "Timestamp in ms": 1701493046752, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912317918257672, "Avg loss": 0.43791813123971224, "Avg value loss": 0.16286918718833476, "Avg policy loss": 0.27504894451703876, "Total num played games": 70710, "Total num trained steps": 140800, "Timestamp in ms": 1701493081378, "logtype": "training_step"}
{"Total num played games": 70710, "Total num trained steps": 140827, "Timestamp in ms": 1701493102871, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.35546875}
{"Avg objective": 20.9453125, "Games time in secs": 60.12983261235058, "Avg game time in secs": 2.0431942520226585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 70784, "Total num trained steps": 140836, "Timestamp in ms": 1701493106882, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903818993277216, "Avg loss": 0.43119983607903123, "Avg value loss": 0.1537179556034971, "Avg policy loss": 0.27748187887482345, "Total num played games": 70804, "Total num trained steps": 140928, "Timestamp in ms": 1701493149479, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992203830292074, "Avg loss": 0.3086843143682927, "Avg value loss": 0.05248277969076298, "Avg policy loss": 0.2562015353469178, "Total num played games": 70804, "Total num trained steps": 141056, "Timestamp in ms": 1701493206050, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913678806172248, "Avg loss": 0.4565552400890738, "Avg value loss": 0.1967298898671288, "Avg policy loss": 0.25982535269577056, "Total num played games": 70898, "Total num trained steps": 141184, "Timestamp in ms": 1701493261628, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 201.66501785628498, "Avg game time in secs": 2.111451826582197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 70912, "Total num trained steps": 141288, "Timestamp in ms": 1701493308547, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905341446923597, "Avg loss": 0.3560181590728462, "Avg value loss": 0.09276029671309516, "Avg policy loss": 0.26325786288361996, "Total num played games": 70992, "Total num trained steps": 141312, "Timestamp in ms": 1701493319413, "logtype": "training_step"}
{"Total num played games": 70992, "Total num trained steps": 141430, "Timestamp in ms": 1701493382843, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.640625}
{"Avg objective": 20.6015625, "Games time in secs": 77.2578451782465, "Avg game time in secs": 1.9422794058336876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 71040, "Total num trained steps": 141436, "Timestamp in ms": 1701493385805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898705683736635, "Avg loss": 0.3293313756585121, "Avg value loss": 0.07645417409366928, "Avg policy loss": 0.25287720072083175, "Total num played games": 71080, "Total num trained steps": 141440, "Timestamp in ms": 1701493387228, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915032495850098, "Avg loss": 0.3865810704883188, "Avg value loss": 0.13378431723685935, "Avg policy loss": 0.25279675459023565, "Total num played games": 71086, "Total num trained steps": 141568, "Timestamp in ms": 1701493443760, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 100.89370544627309, "Avg game time in secs": 1.981050578324357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 71168, "Total num trained steps": 141666, "Timestamp in ms": 1701493486699, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906156050686972, "Avg loss": 0.35627587675116956, "Avg value loss": 0.11228880593262147, "Avg policy loss": 0.24398707202635705, "Total num played games": 71182, "Total num trained steps": 141696, "Timestamp in ms": 1701493499464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924138124806834, "Avg loss": 0.3263605898246169, "Avg value loss": 0.07165817520581186, "Avg policy loss": 0.25470241683069617, "Total num played games": 71182, "Total num trained steps": 141824, "Timestamp in ms": 1701493557546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915820191929963, "Avg loss": 0.40603840653784573, "Avg value loss": 0.15544928002054803, "Avg policy loss": 0.25058912311214954, "Total num played games": 71276, "Total num trained steps": 141952, "Timestamp in ms": 1701493615501, "logtype": "training_step"}
{"Total num played games": 71276, "Total num trained steps": 142030, "Timestamp in ms": 1701493661184, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.703125}
{"Avg objective": 20.1328125, "Games time in secs": 177.18675354868174, "Avg game time in secs": 2.1079001320613315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 71296, "Total num trained steps": 142034, "Timestamp in ms": 1701493663886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907524169819253, "Avg loss": 0.3802668174030259, "Avg value loss": 0.1274762537505012, "Avg policy loss": 0.25279056385625154, "Total num played games": 71370, "Total num trained steps": 142080, "Timestamp in ms": 1701493684681, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925458876278548, "Avg loss": 0.3372176258126274, "Avg value loss": 0.07808568573091179, "Avg policy loss": 0.2591319375205785, "Total num played games": 71370, "Total num trained steps": 142208, "Timestamp in ms": 1701493742691, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 89.93584866449237, "Avg game time in secs": 2.1385102747153724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 71424, "Total num trained steps": 142234, "Timestamp in ms": 1701493753822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917161088100301, "Avg loss": 0.3653536653146148, "Avg value loss": 0.11374262979370542, "Avg policy loss": 0.2516110382275656, "Total num played games": 71464, "Total num trained steps": 142336, "Timestamp in ms": 1701493801054, "logtype": "training_step"}
{"Avg objective": 19.828125, "Games time in secs": 86.1739310156554, "Avg game time in secs": 2.1344604157056892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 71552, "Total num trained steps": 142424, "Timestamp in ms": 1701493839996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908328675237563, "Avg loss": 0.374157588230446, "Avg value loss": 0.12688376213191077, "Avg policy loss": 0.2472738274373114, "Total num played games": 71560, "Total num trained steps": 142464, "Timestamp in ms": 1701493857900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926215762996087, "Avg loss": 0.3264242250006646, "Avg value loss": 0.07845320948399603, "Avg policy loss": 0.24797101691365242, "Total num played games": 71560, "Total num trained steps": 142592, "Timestamp in ms": 1701493915441, "logtype": "training_step"}
{"Total num played games": 71654, "Total num trained steps": 142631, "Timestamp in ms": 1701493941991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.78125}
{"Avg objective": 20.9453125, "Games time in secs": 104.44175498373806, "Avg game time in secs": 1.980599096204969, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.44, "agent_stopped_0": 0.59}, "Total num played games": 71680, "Total num trained steps": 142636, "Timestamp in ms": 1701493944438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891704298377655, "Avg loss": 0.46434458310250193, "Avg value loss": 0.20263268874259666, "Avg policy loss": 0.26171189663000405, "Total num played games": 71748, "Total num trained steps": 142720, "Timestamp in ms": 1701493984385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909683893627697, "Avg loss": 0.3039112683618441, "Avg value loss": 0.061808379366993904, "Avg policy loss": 0.24210289237089455, "Total num played games": 71748, "Total num trained steps": 142848, "Timestamp in ms": 1701494042201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992738473546301, "Avg loss": 0.2741842564428225, "Avg value loss": 0.03919828659854829, "Avg policy loss": 0.23498596891295165, "Total num played games": 71748, "Total num trained steps": 142976, "Timestamp in ms": 1701494098905, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 160.90466174669564, "Avg game time in secs": 1.9220384134096093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 71808, "Total num trained steps": 142991, "Timestamp in ms": 1701494105342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919267280977702, "Avg loss": 0.36460813763551414, "Avg value loss": 0.11765851525706239, "Avg policy loss": 0.24694962007924914, "Total num played games": 71842, "Total num trained steps": 143104, "Timestamp in ms": 1701494156151, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 85.04858108051121, "Avg game time in secs": 2.2905948324187193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.61, "agent_stopped_0": 0.43}, "Total num played games": 71936, "Total num trained steps": 143181, "Timestamp in ms": 1701494190391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909785932721713, "Avg loss": 0.3604028928093612, "Avg value loss": 0.11813079449348152, "Avg policy loss": 0.24227209633681923, "Total num played games": 71940, "Total num trained steps": 143232, "Timestamp in ms": 1701494214873, "logtype": "training_step"}
{"Total num played games": 71940, "Total num trained steps": 143232, "Timestamp in ms": 1701494223425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5234375}
{"Ratio train steps to played games": 1.9901713079934475, "Avg loss": 0.4489169279113412, "Avg value loss": 0.18282624904531986, "Avg policy loss": 0.2660906793316826, "Total num played games": 72034, "Total num trained steps": 143360, "Timestamp in ms": 1701494279882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919482466612988, "Avg loss": 0.29459769662935287, "Avg value loss": 0.050934624290675856, "Avg policy loss": 0.24366307142190635, "Total num played games": 72034, "Total num trained steps": 143488, "Timestamp in ms": 1701494336945, "logtype": "training_step"}
{"Avg objective": 19.6640625, "Games time in secs": 178.94366814941168, "Avg game time in secs": 1.8302021080744453, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.36, "agent_stopped_0": 0.65}, "Total num played games": 72064, "Total num trained steps": 143560, "Timestamp in ms": 1701494369335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911268855368234, "Avg loss": 0.3329835385084152, "Avg value loss": 0.08944181408151053, "Avg policy loss": 0.24354172497987747, "Total num played games": 72128, "Total num trained steps": 143616, "Timestamp in ms": 1701494394467, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929015084294588, "Avg loss": 0.28522145992610604, "Avg value loss": 0.05197776071145199, "Avg policy loss": 0.23324369871988893, "Total num played games": 72128, "Total num trained steps": 143744, "Timestamp in ms": 1701494450038, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 83.3406129963696, "Avg game time in secs": 1.8084513498906745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.33}, "Total num played games": 72192, "Total num trained steps": 143750, "Timestamp in ms": 1701494452676, "logtype": "played_game"}
{"Total num played games": 72222, "Total num trained steps": 143832, "Timestamp in ms": 1701494501386, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.640625}
{"Ratio train steps to played games": 1.9894905691686486, "Avg loss": 0.4587952862493694, "Avg value loss": 0.20268629945348948, "Avg policy loss": 0.25610898656304926, "Total num played games": 72316, "Total num trained steps": 143872, "Timestamp in ms": 1701494519863, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912605785718236, "Avg loss": 0.32550339843146503, "Avg value loss": 0.06802581911324523, "Avg policy loss": 0.2574775777757168, "Total num played games": 72316, "Total num trained steps": 144000, "Timestamp in ms": 1701494577855, "logtype": "training_step"}
{"Avg objective": 20.1875, "Games time in secs": 178.83867450244725, "Avg game time in secs": 2.0914038312184857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 72320, "Total num trained steps": 144123, "Timestamp in ms": 1701494631514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908282225537322, "Avg loss": 0.2842805125983432, "Avg value loss": 0.042411216418258846, "Avg policy loss": 0.2418692926876247, "Total num played games": 72396, "Total num trained steps": 144128, "Timestamp in ms": 1701494633582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921559962437165, "Avg loss": 0.41965426690876484, "Avg value loss": 0.1536046615219675, "Avg policy loss": 0.2660496070748195, "Total num played games": 72412, "Total num trained steps": 144256, "Timestamp in ms": 1701494690268, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 86.72462797537446, "Avg game time in secs": 1.9269926159468014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 72448, "Total num trained steps": 144317, "Timestamp in ms": 1701494718239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912837204170575, "Avg loss": 0.3701063860207796, "Avg value loss": 0.11830422993807588, "Avg policy loss": 0.25180215656291693, "Total num played games": 72508, "Total num trained steps": 144384, "Timestamp in ms": 1701494747601, "logtype": "training_step"}
{"Total num played games": 72508, "Total num trained steps": 144433, "Timestamp in ms": 1701494779442, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.62890625}
{"Avg objective": 20.2421875, "Games time in secs": 64.93279821239412, "Avg game time in secs": 2.1473959918075707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 72576, "Total num trained steps": 144441, "Timestamp in ms": 1701494783172, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904685821327237, "Avg loss": 0.4208347980165854, "Avg value loss": 0.15635649728938006, "Avg policy loss": 0.2644783022115007, "Total num played games": 72602, "Total num trained steps": 144512, "Timestamp in ms": 1701494814968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922316189636649, "Avg loss": 0.3120252473745495, "Avg value loss": 0.05994733443367295, "Avg policy loss": 0.25207791465800256, "Total num played games": 72602, "Total num trained steps": 144640, "Timestamp in ms": 1701494872874, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913615230130128, "Avg loss": 0.38129539764486253, "Avg value loss": 0.12912954672356136, "Avg policy loss": 0.25216585269663483, "Total num played games": 72698, "Total num trained steps": 144768, "Timestamp in ms": 1701494931413, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 201.18458551354706, "Avg game time in secs": 2.303995743015548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 72704, "Total num trained steps": 144887, "Timestamp in ms": 1701494984357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905484119133972, "Avg loss": 0.31729222158901393, "Avg value loss": 0.06351977185113356, "Avg policy loss": 0.25377245189156383, "Total num played games": 72792, "Total num trained steps": 144896, "Timestamp in ms": 1701494988124, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923068469062535, "Avg loss": 0.3608710279222578, "Avg value loss": 0.10725049051688984, "Avg policy loss": 0.2536205358337611, "Total num played games": 72792, "Total num trained steps": 145024, "Timestamp in ms": 1701495044870, "logtype": "training_step"}
{"Total num played games": 72792, "Total num trained steps": 145033, "Timestamp in ms": 1701495059091, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9609375}
{"Avg objective": 20.0859375, "Games time in secs": 77.49566070362926, "Avg game time in secs": 1.7933271585643524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.36}, "Total num played games": 72832, "Total num trained steps": 145037, "Timestamp in ms": 1701495061853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914935652937464, "Avg loss": 0.3785672254161909, "Avg value loss": 0.11834686441579834, "Avg policy loss": 0.26022036431822926, "Total num played games": 72886, "Total num trained steps": 145152, "Timestamp in ms": 1701495111072, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 99.61246563307941, "Avg game time in secs": 2.065756363241235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 72960, "Total num trained steps": 145267, "Timestamp in ms": 1701495161466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906823787338996, "Avg loss": 0.3160886166151613, "Avg value loss": 0.07890011854760814, "Avg policy loss": 0.23718849988654256, "Total num played games": 72980, "Total num trained steps": 145280, "Timestamp in ms": 1701495167111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992422581529186, "Avg loss": 0.3598856951575726, "Avg value loss": 0.10150696695200168, "Avg policy loss": 0.25837873097043484, "Total num played games": 72980, "Total num trained steps": 145408, "Timestamp in ms": 1701495222509, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916112433971043, "Avg loss": 0.38515686930622905, "Avg value loss": 0.13227734017709736, "Avg policy loss": 0.25287952763028443, "Total num played games": 73074, "Total num trained steps": 145536, "Timestamp in ms": 1701495278249, "logtype": "training_step"}
{"Total num played games": 73074, "Total num trained steps": 145635, "Timestamp in ms": 1701495332220, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3671875}
{"Avg objective": 20.59375, "Games time in secs": 172.91903903149068, "Avg game time in secs": 2.0554316326160915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 73088, "Total num trained steps": 145638, "Timestamp in ms": 1701495334385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908156571178657, "Avg loss": 0.3557945704087615, "Avg value loss": 0.10096339354640804, "Avg policy loss": 0.254831176600419, "Total num played games": 73168, "Total num trained steps": 145664, "Timestamp in ms": 1701495345384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925513885851738, "Avg loss": 0.33623931847978383, "Avg value loss": 0.07963956132880412, "Avg policy loss": 0.2565997588681057, "Total num played games": 73168, "Total num trained steps": 145792, "Timestamp in ms": 1701495401747, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 83.93247523531318, "Avg game time in secs": 1.9363985994859831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.46, "agent_stopped_0": 0.55}, "Total num played games": 73216, "Total num trained steps": 145829, "Timestamp in ms": 1701495418318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917556168272774, "Avg loss": 0.3986821423750371, "Avg value loss": 0.13741232620668598, "Avg policy loss": 0.2612698180601001, "Total num played games": 73262, "Total num trained steps": 145920, "Timestamp in ms": 1701495458886, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 85.12378851883113, "Avg game time in secs": 2.050081679903087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 73344, "Total num trained steps": 146021, "Timestamp in ms": 1701495503442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990948252358362, "Avg loss": 0.362792294472456, "Avg value loss": 0.10592148749856278, "Avg policy loss": 0.2568708063336089, "Total num played games": 73356, "Total num trained steps": 146048, "Timestamp in ms": 1701495514918, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926931675663886, "Avg loss": 0.3311860157409683, "Avg value loss": 0.0694533872010652, "Avg policy loss": 0.2617326296167448, "Total num played games": 73356, "Total num trained steps": 146176, "Timestamp in ms": 1701495570250, "logtype": "training_step"}
{"Total num played games": 73452, "Total num trained steps": 146238, "Timestamp in ms": 1701495608415, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8984375}
{"Avg objective": 20.8046875, "Games time in secs": 107.39942656084895, "Avg game time in secs": 2.1130607301020063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.5, "agent_stopped_0": 0.53}, "Total num played games": 73472, "Total num trained steps": 146242, "Timestamp in ms": 1701495610841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892856171647677, "Avg loss": 0.5250723757781088, "Avg value loss": 0.23667083962936886, "Avg policy loss": 0.2884015383897349, "Total num played games": 73546, "Total num trained steps": 146304, "Timestamp in ms": 1701495638682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910124275963343, "Avg loss": 0.34605410078074783, "Avg value loss": 0.06801954499678686, "Avg policy loss": 0.2780345572391525, "Total num played games": 73546, "Total num trained steps": 146432, "Timestamp in ms": 1701495694518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927528349604329, "Avg loss": 0.30700591136701405, "Avg value loss": 0.0441730136226397, "Avg policy loss": 0.2628328986465931, "Total num played games": 73546, "Total num trained steps": 146560, "Timestamp in ms": 1701495751598, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 152.06788094900548, "Avg game time in secs": 2.0064654989982955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 73600, "Total num trained steps": 146586, "Timestamp in ms": 1701495762909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919608908202064, "Avg loss": 0.39885854499880224, "Avg value loss": 0.1251140290114563, "Avg policy loss": 0.27374451456125826, "Total num played games": 73640, "Total num trained steps": 146688, "Timestamp in ms": 1701495807113, "logtype": "training_step"}
{"Avg objective": 19.984375, "Games time in secs": 82.61029765754938, "Avg game time in secs": 2.1664478918683017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.58, "agent_stopped_0": 0.44}, "Total num played games": 73728, "Total num trained steps": 146776, "Timestamp in ms": 1701495845520, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911033958988824, "Avg loss": 0.39146570581942797, "Avg value loss": 0.12141534571128432, "Avg policy loss": 0.2700503618689254, "Total num played games": 73736, "Total num trained steps": 146816, "Timestamp in ms": 1701495863653, "logtype": "training_step"}
{"Total num played games": 73736, "Total num trained steps": 146838, "Timestamp in ms": 1701495885043, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48828125}
{"Ratio train steps to played games": 1.9903020452390627, "Avg loss": 0.4553484274074435, "Avg value loss": 0.1752863136061933, "Avg policy loss": 0.2800621164496988, "Total num played games": 73830, "Total num trained steps": 146944, "Timestamp in ms": 1701495932935, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920357578220236, "Avg loss": 0.32156050100456923, "Avg value loss": 0.05238698108587414, "Avg policy loss": 0.26917352073360234, "Total num played games": 73830, "Total num trained steps": 147072, "Timestamp in ms": 1701495989626, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 180.40691669471562, "Avg game time in secs": 1.974538684997242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 73856, "Total num trained steps": 147152, "Timestamp in ms": 1701496025927, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912342405713976, "Avg loss": 0.4311721606645733, "Avg value loss": 0.16509173424856272, "Avg policy loss": 0.2660804247716442, "Total num played games": 73924, "Total num trained steps": 147200, "Timestamp in ms": 1701496046685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929657486066772, "Avg loss": 0.34479438164271414, "Avg value loss": 0.07099886841024272, "Avg policy loss": 0.2737955142511055, "Total num played games": 73924, "Total num trained steps": 147328, "Timestamp in ms": 1701496104362, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 84.7821437381208, "Avg game time in secs": 2.00758390390547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 73984, "Total num trained steps": 147343, "Timestamp in ms": 1701496110709, "logtype": "played_game"}
{"Total num played games": 74026, "Total num trained steps": 147440, "Timestamp in ms": 1701496166122, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.16796875}
{"Avg objective": 20.6484375, "Games time in secs": 59.90159481205046, "Avg game time in secs": 2.2434174150257604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 74112, "Total num trained steps": 147449, "Timestamp in ms": 1701496170611, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894225580140312, "Avg loss": 0.5249786031199619, "Avg value loss": 0.23591404446051456, "Avg policy loss": 0.2890645614825189, "Total num played games": 74120, "Total num trained steps": 147456, "Timestamp in ms": 1701496173371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991149487317863, "Avg loss": 0.42933522956445813, "Avg value loss": 0.12978891341481358, "Avg policy loss": 0.2995463138213381, "Total num played games": 74120, "Total num trained steps": 147584, "Timestamp in ms": 1701496229465, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928764166216946, "Avg loss": 0.3289689274970442, "Avg value loss": 0.05101162758364808, "Avg policy loss": 0.2779572975123301, "Total num played games": 74120, "Total num trained steps": 147712, "Timestamp in ms": 1701496286409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920232833890266, "Avg loss": 0.4578552565071732, "Avg value loss": 0.17012008609890472, "Avg policy loss": 0.2877351716160774, "Total num played games": 74216, "Total num trained steps": 147840, "Timestamp in ms": 1701496342719, "logtype": "training_step"}
{"Avg objective": 20.296875, "Games time in secs": 209.49066176824272, "Avg game time in secs": 2.0876096147549106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 74240, "Total num trained steps": 147924, "Timestamp in ms": 1701496380102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912124882250033, "Avg loss": 0.4107403620146215, "Avg value loss": 0.1168515554163605, "Avg policy loss": 0.2938888097414747, "Total num played games": 74310, "Total num trained steps": 147968, "Timestamp in ms": 1701496398718, "logtype": "training_step"}
{"Total num played games": 74310, "Total num trained steps": 148042, "Timestamp in ms": 1701496451350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6953125}
{"Avg objective": 20.984375, "Games time in secs": 75.228086207062, "Avg game time in secs": 2.1292872498597717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.51}, "Total num played games": 74368, "Total num trained steps": 148051, "Timestamp in ms": 1701496455330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.4739898545667529, "Avg value loss": 0.16917168922373094, "Avg policy loss": 0.304818166536279, "Total num played games": 74404, "Total num trained steps": 148096, "Timestamp in ms": 1701496475149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921509596258267, "Avg loss": 0.3600306329317391, "Avg value loss": 0.06813344181864522, "Avg policy loss": 0.29189718677662313, "Total num played games": 74404, "Total num trained steps": 148224, "Timestamp in ms": 1701496533338, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 113.96334634162486, "Avg game time in secs": 2.3004553837818094, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 74496, "Total num trained steps": 148305, "Timestamp in ms": 1701496569293, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913554726301377, "Avg loss": 0.4027182715944946, "Avg value loss": 0.12098010763293132, "Avg policy loss": 0.2817381656495854, "Total num played games": 74498, "Total num trained steps": 148352, "Timestamp in ms": 1701496590382, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930736395607935, "Avg loss": 0.3407454307889566, "Avg value loss": 0.06132448057178408, "Avg policy loss": 0.2794209481216967, "Total num played games": 74498, "Total num trained steps": 148480, "Timestamp in ms": 1701496646349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922779922779923, "Avg loss": 0.4139818084659055, "Avg value loss": 0.1311468407511711, "Avg policy loss": 0.2828349677147344, "Total num played games": 74592, "Total num trained steps": 148608, "Timestamp in ms": 1701496702144, "logtype": "training_step"}
{"Total num played games": 74592, "Total num trained steps": 148642, "Timestamp in ms": 1701496729350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1875}
{"Avg objective": 19.984375, "Games time in secs": 162.7192113492638, "Avg game time in secs": 1.9601573013933375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 74624, "Total num trained steps": 148646, "Timestamp in ms": 1701496732013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991484347802801, "Avg loss": 0.4108482494484633, "Avg value loss": 0.1299888732319232, "Avg policy loss": 0.28085937444120646, "Total num played games": 74686, "Total num trained steps": 148736, "Timestamp in ms": 1701496772320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930380763669469, "Avg loss": 0.32254204619675875, "Avg value loss": 0.04907731572166085, "Avg policy loss": 0.27346472861245275, "Total num played games": 74690, "Total num trained steps": 148864, "Timestamp in ms": 1701496829164, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 98.55122047103941, "Avg game time in secs": 1.9857190786715364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 74752, "Total num trained steps": 148867, "Timestamp in ms": 1701496830564, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924043861995187, "Avg loss": 0.4133078217273578, "Avg value loss": 0.12654926691902801, "Avg policy loss": 0.2867585556814447, "Total num played games": 74780, "Total num trained steps": 148992, "Timestamp in ms": 1701496886333, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916125757940006, "Avg loss": 0.3998053789837286, "Avg value loss": 0.12503591304994188, "Avg policy loss": 0.27476946357637644, "Total num played games": 74874, "Total num trained steps": 149120, "Timestamp in ms": 1701496943821, "logtype": "training_step"}
{"Avg objective": 19.359375, "Games time in secs": 166.80626854859293, "Avg game time in secs": 2.0928130886750296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.47, "agent_stopped_0": 0.54}, "Total num played games": 74880, "Total num trained steps": 149239, "Timestamp in ms": 1701496997371, "logtype": "played_game"}
{"Total num played games": 74968, "Total num trained steps": 149242, "Timestamp in ms": 1701497008859, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.12109375}
{"Avg objective": 20.171875, "Games time in secs": 14.408793726935983, "Avg game time in secs": 1.9398450152366422, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 75008, "Total num trained steps": 149247, "Timestamp in ms": 1701497011780, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893897789981605, "Avg loss": 0.3353887051343918, "Avg value loss": 0.06947962314006872, "Avg policy loss": 0.2659090836532414, "Total num played games": 75016, "Total num trained steps": 149248, "Timestamp in ms": 1701497012082, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990034904478964, "Avg loss": 0.5216125873848796, "Avg value loss": 0.23028130928287283, "Avg policy loss": 0.29133127676323056, "Total num played games": 75062, "Total num trained steps": 149376, "Timestamp in ms": 1701497068669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991740161466521, "Avg loss": 0.32129874150268734, "Avg value loss": 0.04988228817819618, "Avg policy loss": 0.27141645504161716, "Total num played games": 75062, "Total num trained steps": 149504, "Timestamp in ms": 1701497126368, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 166.70901976712048, "Avg game time in secs": 2.1176919834542787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 75136, "Total num trained steps": 149619, "Timestamp in ms": 1701497178489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909521528553942, "Avg loss": 0.3385365684516728, "Avg value loss": 0.07752903875370976, "Avg policy loss": 0.2610075240954757, "Total num played games": 75156, "Total num trained steps": 149632, "Timestamp in ms": 1701497184088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926552770237904, "Avg loss": 0.3537578337127343, "Avg value loss": 0.08610881443019025, "Avg policy loss": 0.26764902169816196, "Total num played games": 75156, "Total num trained steps": 149760, "Timestamp in ms": 1701497241359, "logtype": "training_step"}
{"Total num played games": 75250, "Total num trained steps": 149843, "Timestamp in ms": 1701497289564, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.00390625}
{"Avg objective": 20.4296875, "Games time in secs": 113.33886125124991, "Avg game time in secs": 2.0434842590620974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 75264, "Total num trained steps": 149847, "Timestamp in ms": 1701497291828, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893820344022086, "Avg loss": 0.43906456942204386, "Avg value loss": 0.1777969978575129, "Avg policy loss": 0.2612675696145743, "Total num played games": 75344, "Total num trained steps": 149888, "Timestamp in ms": 1701497310661, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910809088978552, "Avg loss": 0.33263354550581425, "Avg value loss": 0.07144899378181435, "Avg policy loss": 0.2611845521023497, "Total num played games": 75344, "Total num trained steps": 150016, "Timestamp in ms": 1701497368812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927797833935017, "Avg loss": 0.2902520139468834, "Avg value loss": 0.04279053898062557, "Avg policy loss": 0.2474614770617336, "Total num played games": 75344, "Total num trained steps": 150144, "Timestamp in ms": 1701497423710, "logtype": "training_step"}
{"Avg objective": 19.9921875, "Games time in secs": 147.6699913404882, "Avg game time in secs": 1.8802439269202296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.38}, "Total num played games": 75392, "Total num trained steps": 150181, "Timestamp in ms": 1701497439498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919406150583245, "Avg loss": 0.39494955190457404, "Avg value loss": 0.14558707442483865, "Avg policy loss": 0.2493624744238332, "Total num played games": 75440, "Total num trained steps": 150272, "Timestamp in ms": 1701497480259, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 87.50697031989694, "Avg game time in secs": 2.1105293433502084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 75520, "Total num trained steps": 150376, "Timestamp in ms": 1701497527005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991103579750053, "Avg loss": 0.36560068209655583, "Avg value loss": 0.10831319804128725, "Avg policy loss": 0.25728748354595155, "Total num played games": 75536, "Total num trained steps": 150400, "Timestamp in ms": 1701497538136, "logtype": "training_step"}
{"Total num played games": 75536, "Total num trained steps": 150447, "Timestamp in ms": 1701497572401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.14453125}
{"Ratio train steps to played games": 1.9903213010710035, "Avg loss": 0.4505823974031955, "Avg value loss": 0.16982041735900566, "Avg policy loss": 0.2807619802188128, "Total num played games": 75630, "Total num trained steps": 150528, "Timestamp in ms": 1701497609632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920137511569482, "Avg loss": 0.3172644944861531, "Avg value loss": 0.05268211039947346, "Avg policy loss": 0.26458238484337926, "Total num played games": 75630, "Total num trained steps": 150656, "Timestamp in ms": 1701497667155, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 182.2440080177039, "Avg game time in secs": 2.0653550768474815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 75648, "Total num trained steps": 150752, "Timestamp in ms": 1701497709249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99123131371824, "Avg loss": 0.3475689650513232, "Avg value loss": 0.09442350764584262, "Avg policy loss": 0.2531454587588087, "Total num played games": 75724, "Total num trained steps": 150784, "Timestamp in ms": 1701497722890, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992921662880989, "Avg loss": 0.3142470532329753, "Avg value loss": 0.06731451400264632, "Avg policy loss": 0.2469325390411541, "Total num played games": 75724, "Total num trained steps": 150912, "Timestamp in ms": 1701497778881, "logtype": "training_step"}
{"Avg objective": 19.5390625, "Games time in secs": 82.33670740202069, "Avg game time in secs": 2.0722372959862696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 75776, "Total num trained steps": 150942, "Timestamp in ms": 1701497791586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921390698778654, "Avg loss": 0.3824613901088014, "Avg value loss": 0.13161610616953112, "Avg policy loss": 0.25084528559818864, "Total num played games": 75818, "Total num trained steps": 151040, "Timestamp in ms": 1701497835502, "logtype": "training_step"}
{"Total num played games": 75818, "Total num trained steps": 151049, "Timestamp in ms": 1701497851771, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.09765625}
{"Avg objective": 20.578125, "Games time in secs": 64.54288352839649, "Avg game time in secs": 2.2164067417761544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.58, "agent_stopped_0": 0.45}, "Total num played games": 75904, "Total num trained steps": 151056, "Timestamp in ms": 1701497856129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99135841500685, "Avg loss": 0.4196402473608032, "Avg value loss": 0.15523480711271986, "Avg policy loss": 0.26440544286742806, "Total num played games": 75912, "Total num trained steps": 151168, "Timestamp in ms": 1701497905611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930445779323427, "Avg loss": 0.28545412595849484, "Avg value loss": 0.04717263589554932, "Avg policy loss": 0.23828149016480893, "Total num played games": 75912, "Total num trained steps": 151296, "Timestamp in ms": 1701497962075, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922637686498434, "Avg loss": 0.39330192701891065, "Avg value loss": 0.13527489949774463, "Avg policy loss": 0.25802702317014337, "Total num played games": 76006, "Total num trained steps": 151424, "Timestamp in ms": 1701498017577, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 196.90937936306, "Avg game time in secs": 2.305799617053708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 76032, "Total num trained steps": 151505, "Timestamp in ms": 1701498053039, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991484888304862, "Avg loss": 0.3715892566833645, "Avg value loss": 0.12561007909243926, "Avg policy loss": 0.24597917776554823, "Total num played games": 76100, "Total num trained steps": 151552, "Timestamp in ms": 1701498074159, "logtype": "training_step"}
{"Total num played games": 76100, "Total num trained steps": 151652, "Timestamp in ms": 1701498130974, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Avg objective": 20.546875, "Games time in secs": 81.60201401263475, "Avg game time in secs": 2.1741119715734385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.53}, "Total num played games": 76160, "Total num trained steps": 151659, "Timestamp in ms": 1701498134641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907079297582486, "Avg loss": 0.3664963043993339, "Avg value loss": 0.1177374999388121, "Avg policy loss": 0.24875880277249962, "Total num played games": 76194, "Total num trained steps": 151680, "Timestamp in ms": 1701498143852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992387852061842, "Avg loss": 0.3485750100808218, "Avg value loss": 0.09784194879466668, "Avg policy loss": 0.2507330630905926, "Total num played games": 76194, "Total num trained steps": 151808, "Timestamp in ms": 1701498201767, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 101.53756226040423, "Avg game time in secs": 2.2997496119642165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 76288, "Total num trained steps": 151887, "Timestamp in ms": 1701498236184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916107382550337, "Avg loss": 0.3731019471306354, "Avg value loss": 0.13013516829232685, "Avg policy loss": 0.24296677997335792, "Total num played games": 76288, "Total num trained steps": 151936, "Timestamp in ms": 1701498257913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932885906040267, "Avg loss": 0.33058862981852144, "Avg value loss": 0.083993156964425, "Avg policy loss": 0.24659547244664282, "Total num played games": 76288, "Total num trained steps": 152064, "Timestamp in ms": 1701498316903, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924460620025135, "Avg loss": 0.4010768849402666, "Avg value loss": 0.15121393933077343, "Avg policy loss": 0.24986294703558087, "Total num played games": 76384, "Total num trained steps": 152192, "Timestamp in ms": 1701498374857, "logtype": "training_step"}
{"Total num played games": 76384, "Total num trained steps": 152252, "Timestamp in ms": 1701498415900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.375}
{"Avg objective": 19.8125, "Games time in secs": 182.5732141211629, "Avg game time in secs": 1.8848172469733981, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 76416, "Total num trained steps": 152258, "Timestamp in ms": 1701498418757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916838829467298, "Avg loss": 0.3381353204604238, "Avg value loss": 0.09181345772230998, "Avg policy loss": 0.24632185988593847, "Total num played games": 76478, "Total num trained steps": 152320, "Timestamp in ms": 1701498448721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930969563853154, "Avg loss": 0.2908857266884297, "Avg value loss": 0.04823216229851823, "Avg policy loss": 0.24265356408432126, "Total num played games": 76484, "Total num trained steps": 152448, "Timestamp in ms": 1701498505887, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 88.20194107666612, "Avg game time in secs": 2.0635601901012706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 76544, "Total num trained steps": 152450, "Timestamp in ms": 1701498506959, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925821449093664, "Avg loss": 0.36001360754016787, "Avg value loss": 0.11078137761796825, "Avg policy loss": 0.24923222872894257, "Total num played games": 76572, "Total num trained steps": 152576, "Timestamp in ms": 1701498562285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991808624422821, "Avg loss": 0.3646236170316115, "Avg value loss": 0.11845044000074267, "Avg policy loss": 0.2461731758667156, "Total num played games": 76666, "Total num trained steps": 152704, "Timestamp in ms": 1701498618910, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 165.14239640533924, "Avg game time in secs": 2.0894269196287496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 76672, "Total num trained steps": 152823, "Timestamp in ms": 1701498672102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910369984366858, "Avg loss": 0.3153192662866786, "Avg value loss": 0.06048852620006073, "Avg policy loss": 0.2548307398101315, "Total num played games": 76760, "Total num trained steps": 152832, "Timestamp in ms": 1701498676301, "logtype": "training_step"}
{"Total num played games": 76760, "Total num trained steps": 152855, "Timestamp in ms": 1701498699142, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.109375}
{"Avg objective": 20.6015625, "Games time in secs": 29.724521584808826, "Avg game time in secs": 1.9123886263696477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.38}, "Total num played games": 76800, "Total num trained steps": 152860, "Timestamp in ms": 1701498701827, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902672599994795, "Avg loss": 0.4709953654091805, "Avg value loss": 0.19953275125590153, "Avg policy loss": 0.27146261208690703, "Total num played games": 76854, "Total num trained steps": 152960, "Timestamp in ms": 1701498748899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919327556145419, "Avg loss": 0.3036785183940083, "Avg value loss": 0.04763576394179836, "Avg policy loss": 0.2560427525313571, "Total num played games": 76854, "Total num trained steps": 153088, "Timestamp in ms": 1701498805774, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 155.3254138249904, "Avg game time in secs": 1.8918733547325246, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 76928, "Total num trained steps": 153202, "Timestamp in ms": 1701498857153, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991111111111111, "Avg loss": 0.3105401116190478, "Avg value loss": 0.06285462364030536, "Avg policy loss": 0.2476854883134365, "Total num played games": 76950, "Total num trained steps": 153216, "Timestamp in ms": 1701498863292, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927745289148797, "Avg loss": 0.33051166916266084, "Avg value loss": 0.07744685620127711, "Avg policy loss": 0.2530648116953671, "Total num played games": 76950, "Total num trained steps": 153344, "Timestamp in ms": 1701498921087, "logtype": "training_step"}
{"Total num played games": 77046, "Total num trained steps": 153456, "Timestamp in ms": 1701498988909, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Avg objective": 20.390625, "Games time in secs": 133.67637787945569, "Avg game time in secs": 1.9737772246589884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 77056, "Total num trained steps": 153460, "Timestamp in ms": 1701498990829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895125745397977, "Avg loss": 0.3912124311318621, "Avg value loss": 0.14328198025759775, "Avg policy loss": 0.24793044955004007, "Total num played games": 77140, "Total num trained steps": 153472, "Timestamp in ms": 1701498996195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911848586984704, "Avg loss": 0.3640001672320068, "Avg value loss": 0.10203400914906524, "Avg policy loss": 0.2619661578210071, "Total num played games": 77140, "Total num trained steps": 153600, "Timestamp in ms": 1701499053921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928441794140523, "Avg loss": 0.28855024790391326, "Avg value loss": 0.042648923612432554, "Avg policy loss": 0.2459013219922781, "Total num played games": 77140, "Total num trained steps": 153728, "Timestamp in ms": 1701499110848, "logtype": "training_step"}
{"Avg objective": 20.4921875, "Games time in secs": 140.0884522292763, "Avg game time in secs": 1.8371329753281316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 77184, "Total num trained steps": 153774, "Timestamp in ms": 1701499130918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992076028692027, "Avg loss": 0.3683476496953517, "Avg value loss": 0.11692791250243317, "Avg policy loss": 0.2514197372365743, "Total num played games": 77234, "Total num trained steps": 153856, "Timestamp in ms": 1701499166026, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 82.70601858012378, "Avg game time in secs": 2.1467665180534823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 77312, "Total num trained steps": 153964, "Timestamp in ms": 1701499213624, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912582438898228, "Avg loss": 0.35390683508012444, "Avg value loss": 0.09114482306176797, "Avg policy loss": 0.26276201428845525, "Total num played games": 77330, "Total num trained steps": 153984, "Timestamp in ms": 1701499222305, "logtype": "training_step"}
{"Total num played games": 77330, "Total num trained steps": 154057, "Timestamp in ms": 1701499267219, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8828125}
{"Ratio train steps to played games": 1.9904939036991114, "Avg loss": 0.4727985968347639, "Avg value loss": 0.16820882743922994, "Avg policy loss": 0.3045897705014795, "Total num played games": 77424, "Total num trained steps": 154112, "Timestamp in ms": 1701499292308, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921471378383964, "Avg loss": 0.35213166498579085, "Avg value loss": 0.06310055885114707, "Avg policy loss": 0.28903110255487263, "Total num played games": 77424, "Total num trained steps": 154240, "Timestamp in ms": 1701499349879, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 179.7977151721716, "Avg game time in secs": 2.261006722241291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 77440, "Total num trained steps": 154340, "Timestamp in ms": 1701499393422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913826466111098, "Avg loss": 0.37813843018375337, "Avg value loss": 0.10163454341818579, "Avg policy loss": 0.27650388795882463, "Total num played games": 77518, "Total num trained steps": 154368, "Timestamp in ms": 1701499405882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930338760029929, "Avg loss": 0.3494712057290599, "Avg value loss": 0.0734384007519111, "Avg policy loss": 0.2760328052099794, "Total num played games": 77518, "Total num trained steps": 154496, "Timestamp in ms": 1701499461319, "logtype": "training_step"}
{"Avg objective": 19.9609375, "Games time in secs": 82.69337276928127, "Avg game time in secs": 1.9887434726115316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 77568, "Total num trained steps": 154530, "Timestamp in ms": 1701499476116, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922692367159718, "Avg loss": 0.3945765420794487, "Avg value loss": 0.12137514118512627, "Avg policy loss": 0.27320140367373824, "Total num played games": 77612, "Total num trained steps": 154624, "Timestamp in ms": 1701499517368, "logtype": "training_step"}
{"Total num played games": 77612, "Total num trained steps": 154659, "Timestamp in ms": 1701499544686, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0546875}
{"Avg objective": 20.03125, "Games time in secs": 72.83236930705607, "Avg game time in secs": 2.065954857651377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 77696, "Total num trained steps": 154668, "Timestamp in ms": 1701499548948, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915064473785808, "Avg loss": 0.43715305475052446, "Avg value loss": 0.16050568287028, "Avg policy loss": 0.27664737252052873, "Total num played games": 77706, "Total num trained steps": 154752, "Timestamp in ms": 1701499586969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993153681826371, "Avg loss": 0.313444611383602, "Avg value loss": 0.05231193960935343, "Avg policy loss": 0.2611326716141775, "Total num played games": 77706, "Total num trained steps": 154880, "Timestamp in ms": 1701499642747, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923907455012853, "Avg loss": 0.38977492263074964, "Avg value loss": 0.12289011130633298, "Avg policy loss": 0.2668848130851984, "Total num played games": 77800, "Total num trained steps": 155008, "Timestamp in ms": 1701499699934, "logtype": "training_step"}
{"Avg objective": 20.1171875, "Games time in secs": 187.8242218270898, "Avg game time in secs": 2.036867414281005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 77824, "Total num trained steps": 155092, "Timestamp in ms": 1701499736773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916296505507485, "Avg loss": 0.39184515341185033, "Avg value loss": 0.12636454863240942, "Avg policy loss": 0.2654806027421728, "Total num played games": 77894, "Total num trained steps": 155136, "Timestamp in ms": 1701499755908, "logtype": "training_step"}
{"Total num played games": 77894, "Total num trained steps": 155261, "Timestamp in ms": 1701499822529, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.40625}
{"Ratio train steps to played games": 1.9932217315394885, "Avg loss": 0.32996469864156097, "Avg value loss": 0.058216593926772475, "Avg policy loss": 0.27174810180440545, "Total num played games": 77896, "Total num trained steps": 155264, "Timestamp in ms": 1701499824317, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 89.17187691293657, "Avg game time in secs": 2.005338775299606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 77952, "Total num trained steps": 155268, "Timestamp in ms": 1701499825945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925116684618147, "Avg loss": 0.38539043406490237, "Avg value loss": 0.1060213063901756, "Avg policy loss": 0.2793691331753507, "Total num played games": 77988, "Total num trained steps": 155392, "Timestamp in ms": 1701499882365, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 91.72683296725154, "Avg game time in secs": 2.2280320459103677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 78080, "Total num trained steps": 155475, "Timestamp in ms": 1701499917672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917522604441484, "Avg loss": 0.37709570268634707, "Avg value loss": 0.10180711971770506, "Avg policy loss": 0.2752885833615437, "Total num played games": 78082, "Total num trained steps": 155520, "Timestamp in ms": 1701499938716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993391562716119, "Avg loss": 0.3268818809883669, "Avg value loss": 0.04905740180402063, "Avg policy loss": 0.2778244795044884, "Total num played games": 78082, "Total num trained steps": 155648, "Timestamp in ms": 1701499996313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926192181743758, "Avg loss": 0.42223254370037466, "Avg value loss": 0.13315873644023668, "Avg policy loss": 0.2890738019486889, "Total num played games": 78176, "Total num trained steps": 155776, "Timestamp in ms": 1701500052515, "logtype": "training_step"}
{"Avg objective": 19.7578125, "Games time in secs": 164.895334539935, "Avg game time in secs": 2.0565947897848673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 78208, "Total num trained steps": 155845, "Timestamp in ms": 1701500082567, "logtype": "played_game"}
{"Total num played games": 78270, "Total num trained steps": 155862, "Timestamp in ms": 1701500111128, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8359375}
{"Avg objective": 20.6015625, "Games time in secs": 32.142082426697016, "Avg game time in secs": 2.150430354522541, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 78336, "Total num trained steps": 155869, "Timestamp in ms": 1701500114709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894849675871573, "Avg loss": 0.5406748168170452, "Avg value loss": 0.23306025675265118, "Avg policy loss": 0.30761455988977104, "Total num played games": 78364, "Total num trained steps": 155904, "Timestamp in ms": 1701500131587, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911183706804145, "Avg loss": 0.4092161685694009, "Avg value loss": 0.10171009917394258, "Avg policy loss": 0.30750607163645327, "Total num played games": 78364, "Total num trained steps": 156032, "Timestamp in ms": 1701500188414, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927517737736715, "Avg loss": 0.3262347038835287, "Avg value loss": 0.04265860124723986, "Avg policy loss": 0.28357610129751265, "Total num played games": 78364, "Total num trained steps": 156160, "Timestamp in ms": 1701500242899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919829717810804, "Avg loss": 0.4403651747852564, "Avg value loss": 0.1512717841687845, "Avg policy loss": 0.2890933913877234, "Total num played games": 78458, "Total num trained steps": 156288, "Timestamp in ms": 1701500299825, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 236.84882074594498, "Avg game time in secs": 2.3027054425765527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.65, "agent_stopped_0": 0.42}, "Total num played games": 78464, "Total num trained steps": 156407, "Timestamp in ms": 1701500351558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912921705919797, "Avg loss": 0.34915453393477947, "Avg value loss": 0.0697669263172429, "Avg policy loss": 0.27938760502729565, "Total num played games": 78550, "Total num trained steps": 156416, "Timestamp in ms": 1701500354976, "logtype": "training_step"}
{"Total num played games": 78552, "Total num trained steps": 156465, "Timestamp in ms": 1701500387465, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5}
{"Avg objective": 20.390625, "Games time in secs": 39.05478401295841, "Avg game time in secs": 2.080756576411659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 78592, "Total num trained steps": 156470, "Timestamp in ms": 1701500390613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904890267782214, "Avg loss": 0.5741055689286441, "Avg value loss": 0.25335539306979626, "Avg policy loss": 0.320750173763372, "Total num played games": 78646, "Total num trained steps": 156544, "Timestamp in ms": 1701500424783, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992116572997991, "Avg loss": 0.37614544364623725, "Avg value loss": 0.07081427139928564, "Avg policy loss": 0.3053311675321311, "Total num played games": 78646, "Total num trained steps": 156672, "Timestamp in ms": 1701500480360, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 140.28336259163916, "Avg game time in secs": 2.1450758305290947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 78720, "Total num trained steps": 156787, "Timestamp in ms": 1701500530897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913639827279654, "Avg loss": 0.38610744499601424, "Avg value loss": 0.0903576340933796, "Avg policy loss": 0.29574980994220823, "Total num played games": 78740, "Total num trained steps": 156800, "Timestamp in ms": 1701500536918, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992976885953772, "Avg loss": 0.397438651882112, "Avg value loss": 0.10448750108480453, "Avg policy loss": 0.29295115265995264, "Total num played games": 78740, "Total num trained steps": 156928, "Timestamp in ms": 1701500594260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921863108224669, "Avg loss": 0.4484354357700795, "Avg value loss": 0.1484996577783022, "Avg policy loss": 0.29993577604182065, "Total num played games": 78836, "Total num trained steps": 157056, "Timestamp in ms": 1701500650140, "logtype": "training_step"}
{"Total num played games": 78836, "Total num trained steps": 157066, "Timestamp in ms": 1701500667561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.7265625}
{"Avg objective": 22.1015625, "Games time in secs": 139.12613813206553, "Avg game time in secs": 2.2604230327997357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 78848, "Total num trained steps": 157069, "Timestamp in ms": 1701500670023, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914354491321424, "Avg loss": 0.4572755943518132, "Avg value loss": 0.1545315931434743, "Avg policy loss": 0.30274400138296187, "Total num played games": 78930, "Total num trained steps": 157184, "Timestamp in ms": 1701500721221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930571392372989, "Avg loss": 0.33066826954018325, "Avg value loss": 0.04615835227014031, "Avg policy loss": 0.2845099166734144, "Total num played games": 78930, "Total num trained steps": 157312, "Timestamp in ms": 1701500778734, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 126.88156174495816, "Avg game time in secs": 2.1148071348579833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 78976, "Total num trained steps": 157354, "Timestamp in ms": 1701500796905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992293480461632, "Avg loss": 0.43807115289382637, "Avg value loss": 0.14674404566176236, "Avg policy loss": 0.2913271045545116, "Total num played games": 79024, "Total num trained steps": 157440, "Timestamp in ms": 1701500834382, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 83.07812195457518, "Avg game time in secs": 2.327433899321477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.61}, "Total num played games": 79104, "Total num trained steps": 157544, "Timestamp in ms": 1701500879983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99155691498774, "Avg loss": 0.3968522762879729, "Avg value loss": 0.10556396408355795, "Avg policy loss": 0.29128831427078694, "Total num played games": 79118, "Total num trained steps": 157568, "Timestamp in ms": 1701500889728, "logtype": "training_step"}
{"Total num played games": 79118, "Total num trained steps": 157668, "Timestamp in ms": 1701500945404, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5703125}
{"Ratio train steps to played games": 1.9908094733121244, "Avg loss": 0.44678206532262266, "Avg value loss": 0.1513084800390061, "Avg policy loss": 0.2954735839739442, "Total num played games": 79212, "Total num trained steps": 157696, "Timestamp in ms": 1701500958609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924127657425643, "Avg loss": 0.4081769958138466, "Avg value loss": 0.08799315273063257, "Avg policy loss": 0.32018384570255876, "Total num played games": 79212, "Total num trained steps": 157824, "Timestamp in ms": 1701501013863, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 176.12703432701528, "Avg game time in secs": 2.1300963598914677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 79232, "Total num trained steps": 157916, "Timestamp in ms": 1701501056110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916778049580108, "Avg loss": 0.4132856030482799, "Avg value loss": 0.11266923796210904, "Avg policy loss": 0.3006163649260998, "Total num played games": 79306, "Total num trained steps": 157952, "Timestamp in ms": 1701501071564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932918064206995, "Avg loss": 0.35564132407307625, "Avg value loss": 0.06437797647959087, "Avg policy loss": 0.2912633491214365, "Total num played games": 79306, "Total num trained steps": 158080, "Timestamp in ms": 1701501127233, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 82.2786130644381, "Avg game time in secs": 1.9371489520126488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.4, "agent_stopped_0": 0.62}, "Total num played games": 79360, "Total num trained steps": 158106, "Timestamp in ms": 1701501138389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924938918415154, "Avg loss": 0.4312916079070419, "Avg value loss": 0.13249102066038176, "Avg policy loss": 0.29880058800335974, "Total num played games": 79402, "Total num trained steps": 158208, "Timestamp in ms": 1701501182340, "logtype": "training_step"}
{"Total num played games": 79402, "Total num trained steps": 158271, "Timestamp in ms": 1701501221935, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0703125}
{"Avg objective": 20.359375, "Games time in secs": 87.9640139117837, "Avg game time in secs": 2.199230921745766, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 79488, "Total num trained steps": 158279, "Timestamp in ms": 1701501226353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917480124786153, "Avg loss": 0.4137110773008317, "Avg value loss": 0.11070491193095222, "Avg policy loss": 0.3030061620520428, "Total num played games": 79496, "Total num trained steps": 158336, "Timestamp in ms": 1701501251811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993358156385227, "Avg loss": 0.3316121557727456, "Avg value loss": 0.04906850168481469, "Avg policy loss": 0.2825436551356688, "Total num played games": 79496, "Total num trained steps": 158464, "Timestamp in ms": 1701501307682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926121372031662, "Avg loss": 0.41438180208206177, "Avg value loss": 0.11831276447628625, "Avg policy loss": 0.2960690369363874, "Total num played games": 79590, "Total num trained steps": 158592, "Timestamp in ms": 1701501363413, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 174.0522927865386, "Avg game time in secs": 2.0810811404517153, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 79616, "Total num trained steps": 158673, "Timestamp in ms": 1701501400406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918678781185684, "Avg loss": 0.3863852135837078, "Avg value loss": 0.10557496164983604, "Avg policy loss": 0.28081024857237935, "Total num played games": 79684, "Total num trained steps": 158720, "Timestamp in ms": 1701501421002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934742231815672, "Avg loss": 0.33322730369400233, "Avg value loss": 0.054168901187949814, "Avg policy loss": 0.27905840205494314, "Total num played games": 79684, "Total num trained steps": 158848, "Timestamp in ms": 1701501478529, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 84.42413929104805, "Avg game time in secs": 2.1326844441355206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 79744, "Total num trained steps": 158863, "Timestamp in ms": 1701501484830, "logtype": "played_game"}
{"Total num played games": 79778, "Total num trained steps": 158874, "Timestamp in ms": 1701501516568, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.63671875}
{"Avg objective": 20.953125, "Games time in secs": 36.92733442783356, "Avg game time in secs": 2.3181590505409986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 79872, "Total num trained steps": 158885, "Timestamp in ms": 1701501521757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903846153846154, "Avg loss": 0.5829292498528957, "Avg value loss": 0.2644649942521937, "Avg policy loss": 0.31846425135154277, "Total num played games": 79872, "Total num trained steps": 158976, "Timestamp in ms": 1701501561375, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919871794871795, "Avg loss": 0.34293233428616077, "Avg value loss": 0.057309944182634354, "Avg policy loss": 0.285622391034849, "Total num played games": 79872, "Total num trained steps": 159104, "Timestamp in ms": 1701501618224, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935897435897436, "Avg loss": 0.32282476068940014, "Avg value loss": 0.041036334267118946, "Avg policy loss": 0.2817884248215705, "Total num played games": 79872, "Total num trained steps": 159232, "Timestamp in ms": 1701501674913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992797118847539, "Avg loss": 0.3803692775545642, "Avg value loss": 0.09781170226051472, "Avg policy loss": 0.28255757491569966, "Total num played games": 79968, "Total num trained steps": 159360, "Timestamp in ms": 1701501730813, "logtype": "training_step"}
{"Avg objective": 19.0625, "Games time in secs": 238.90343016013503, "Avg game time in secs": 1.7360184165881947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.32}, "Total num played games": 80000, "Total num trained steps": 159429, "Timestamp in ms": 1701501760661, "logtype": "played_game"}
{"Total num played games": 80064, "Total num trained steps": 159430, "Timestamp in ms": 1701501773060, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.96875}
{"Total num played games": 80102, "Total num trained steps": 159430, "Timestamp in ms": 1701501784767, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.4296875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701627317987, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.26953125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701627490704, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.15234375}
