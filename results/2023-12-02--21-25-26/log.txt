{"Avg objective": 18.3828125, "Games time in secs": 124.75877601094544, "Avg game time in secs": 36.60941214031482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 6.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.64, "played_steps": 3.8, "reached_maximum_moves": 0.09}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1701552457470, "logtype": "played_game"}
{"Avg objective": 17.0390625, "Games time in secs": 76.90725380368531, "Avg game time in secs": 50.16326375301287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 6.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 5.05, "reached_maximum_moves": 0.16, "agent_stopped_0": 0.27}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1701552534377, "logtype": "played_game"}
{"Ratio train steps to played games": 0.38484848484848483, "Avg loss": 61.70554193109274, "Avg value loss": 59.72869182378054, "Avg policy loss": 1.9768505366519094, "Total num played games": 330, "Total num trained steps": 128, "Timestamp in ms": 1701552609729, "logtype": "training_step"}
{"Avg objective": 18.8984375, "Games time in secs": 110.69533554464579, "Avg game time in secs": 43.5578135849064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 5.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 4.51, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.12}, "Total num played games": 384, "Total num trained steps": 190, "Timestamp in ms": 1701552645073, "logtype": "played_game"}
{"Ratio train steps to played games": 0.6124401913875598, "Avg loss": 10.397044088691473, "Avg value loss": 8.706087712198496, "Avg policy loss": 1.6909564035013318, "Total num played games": 418, "Total num trained steps": 256, "Timestamp in ms": 1701552675703, "logtype": "training_step"}
{"Ratio train steps to played games": 0.8148936170212766, "Avg loss": 5.184513412415981, "Avg value loss": 3.6509943641722202, "Avg policy loss": 1.533519039861858, "Total num played games": 470, "Total num trained steps": 384, "Timestamp in ms": 1701552732057, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 108.93362381495535, "Avg game time in secs": 29.54190419256338, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 2.87, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.1}, "Total num played games": 512, "Total num trained steps": 435, "Timestamp in ms": 1701552754007, "logtype": "played_game"}
{"Ratio train steps to played games": 0.9922480620155039, "Avg loss": 4.808852508664131, "Avg value loss": 3.423360902816057, "Avg policy loss": 1.3854916235432029, "Total num played games": 516, "Total num trained steps": 512, "Timestamp in ms": 1701552788660, "logtype": "training_step"}
{"Total num played games": 618, "Total num trained steps": 603, "Timestamp in ms": 1701552924210, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6875}
{"Avg objective": 19.9375, "Games time in secs": 180.99544620886445, "Avg game time in secs": 26.640551100528683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 2.81, "reached_maximum_moves": 0.06, "agent_stopped_0": 0.52}, "Total num played games": 640, "Total num trained steps": 626, "Timestamp in ms": 1701552935002, "logtype": "played_game"}
{"Ratio train steps to played games": 0.9711246200607903, "Avg loss": 5.226954000070691, "Avg value loss": 3.954030151478946, "Avg policy loss": 1.2729238411411643, "Total num played games": 658, "Total num trained steps": 640, "Timestamp in ms": 1701552941502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.1130434782608696, "Avg loss": 5.027246490120888, "Avg value loss": 3.8544089049100876, "Avg policy loss": 1.172837583348155, "Total num played games": 690, "Total num trained steps": 768, "Timestamp in ms": 1701553001386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.2584269662921348, "Avg loss": 4.178982758894563, "Avg value loss": 3.028701154515147, "Avg policy loss": 1.1502816453576088, "Total num played games": 712, "Total num trained steps": 896, "Timestamp in ms": 1701553056210, "logtype": "training_step"}
{"Avg objective": 19.65625, "Games time in secs": 146.7714344598353, "Avg game time in secs": 23.945710394051275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.45, "played_steps": 2.71, "reached_maximum_moves": 0.11}, "Total num played games": 768, "Total num trained steps": 954, "Timestamp in ms": 1701553081774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.2832080200501252, "Avg loss": 4.352508781477809, "Avg value loss": 3.247007878497243, "Avg policy loss": 1.1055009085685015, "Total num played games": 798, "Total num trained steps": 1024, "Timestamp in ms": 1701553111911, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3211009174311927, "Avg loss": 3.8522525504231453, "Avg value loss": 2.785042437724769, "Avg policy loss": 1.0672101131640375, "Total num played games": 872, "Total num trained steps": 1152, "Timestamp in ms": 1701553167315, "logtype": "training_step"}
{"Avg objective": 18.796875, "Games time in secs": 141.67587000504136, "Avg game time in secs": 21.368546768499073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 2.24, "agent_stopped_0": 0.49, "reached_maximum_moves": 0.07}, "Total num played games": 896, "Total num trained steps": 1206, "Timestamp in ms": 1701553223451, "logtype": "played_game"}
{"Total num played games": 904, "Total num trained steps": 1206, "Timestamp in ms": 1701553269018, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8046875}
{"Ratio train steps to played games": 1.3195876288659794, "Avg loss": 3.160003697499633, "Avg value loss": 2.1202144445851445, "Avg policy loss": 1.039789255708456, "Total num played games": 970, "Total num trained steps": 1280, "Timestamp in ms": 1701553301962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.4126506024096386, "Avg loss": 2.8584504993632436, "Avg value loss": 1.8450100058689713, "Avg policy loss": 1.0134405069984496, "Total num played games": 996, "Total num trained steps": 1408, "Timestamp in ms": 1701553358271, "logtype": "training_step"}
{"Avg objective": 19.859375, "Games time in secs": 178.57306649535894, "Avg game time in secs": 21.457297556771664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 2.24, "agent_stopped_0": 0.6, "reached_maximum_moves": 0.06}, "Total num played games": 1024, "Total num trained steps": 1505, "Timestamp in ms": 1701553402024, "logtype": "played_game"}
{"Ratio train steps to played games": 1.4355140186915887, "Avg loss": 2.4625205686315894, "Avg value loss": 1.4848468354903162, "Avg policy loss": 0.9776737322099507, "Total num played games": 1070, "Total num trained steps": 1536, "Timestamp in ms": 1701553415727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.526605504587156, "Avg loss": 2.3800594862550497, "Avg value loss": 1.43440444720909, "Avg policy loss": 0.945655029732734, "Total num played games": 1090, "Total num trained steps": 1664, "Timestamp in ms": 1701553471966, "logtype": "training_step"}
{"Avg objective": 19.5625, "Games time in secs": 89.1954024899751, "Avg game time in secs": 12.84501988493139, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.39, "played_steps": 1.1, "reached_maximum_moves": 0.02}, "Total num played games": 1152, "Total num trained steps": 1709, "Timestamp in ms": 1701553491220, "logtype": "played_game"}
{"Ratio train steps to played games": 1.5212224108658743, "Avg loss": 2.43587876111269, "Avg value loss": 1.5163768427446485, "Avg policy loss": 0.9195019258186221, "Total num played games": 1178, "Total num trained steps": 1792, "Timestamp in ms": 1701553528439, "logtype": "training_step"}
{"Total num played games": 1194, "Total num trained steps": 1810, "Timestamp in ms": 1701553588292, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.671875}
{"Ratio train steps to played games": 1.501564945226917, "Avg loss": 2.5864046374335885, "Avg value loss": 1.7004018831066787, "Avg policy loss": 0.886002731975168, "Total num played games": 1278, "Total num trained steps": 1920, "Timestamp in ms": 1701553637989, "logtype": "training_step"}
{"Avg objective": 19.59375, "Games time in secs": 149.28650173172355, "Avg game time in secs": 19.036572107419488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 2.12, "agent_stopped_0": 0.51, "reached_maximum_moves": 0.07}, "Total num played games": 1280, "Total num trained steps": 1925, "Timestamp in ms": 1701553640506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.5942367601246106, "Avg loss": 2.109878271818161, "Avg value loss": 1.2261524768546224, "Avg policy loss": 0.8837257870472968, "Total num played games": 1284, "Total num trained steps": 2048, "Timestamp in ms": 1701553695277, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5745296671490594, "Avg loss": 2.242419498041272, "Avg value loss": 1.381270051933825, "Avg policy loss": 0.8611494405195117, "Total num played games": 1382, "Total num trained steps": 2176, "Timestamp in ms": 1701553751826, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 154.94423535838723, "Avg game time in secs": 10.63878353148175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "reached_maximum_moves": 0.04, "played_steps": 1.0, "agent_stopped_more": 0.24}, "Total num played games": 1408, "Total num trained steps": 2273, "Timestamp in ms": 1701553795451, "logtype": "played_game"}
{"Ratio train steps to played games": 1.564538043478261, "Avg loss": 2.2454534880816936, "Avg value loss": 1.3985661179758608, "Avg policy loss": 0.8468873756937683, "Total num played games": 1472, "Total num trained steps": 2304, "Timestamp in ms": 1701553809287, "logtype": "training_step"}
{"Total num played games": 1486, "Total num trained steps": 2410, "Timestamp in ms": 1701553966726, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6953125}
{"Ratio train steps to played games": 1.5916230366492146, "Avg loss": 2.5654440335929394, "Avg value loss": 1.7459233454428613, "Avg policy loss": 0.8195206969976425, "Total num played games": 1526, "Total num trained steps": 2432, "Timestamp in ms": 1701553975858, "logtype": "training_step"}
{"Avg objective": 19.7890625, "Games time in secs": 181.0307438019663, "Avg game time in secs": 11.769033342076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.29, "played_steps": 1.03, "reached_maximum_moves": 0.04}, "Total num played games": 1536, "Total num trained steps": 2433, "Timestamp in ms": 1701553976481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6264294790343075, "Avg loss": 2.402286031283438, "Avg value loss": 1.6634238110855222, "Avg policy loss": 0.7388622160069644, "Total num played games": 1574, "Total num trained steps": 2560, "Timestamp in ms": 1701554034891, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6173285198555956, "Avg loss": 1.7235360080376267, "Avg value loss": 0.994759208522737, "Avg policy loss": 0.7287768092937768, "Total num played games": 1662, "Total num trained steps": 2688, "Timestamp in ms": 1701554092014, "logtype": "training_step"}
{"Avg objective": 18.953125, "Games time in secs": 117.1105131432414, "Avg game time in secs": 12.472294205450453, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.45, "played_steps": 1.05, "reached_maximum_moves": 0.02}, "Total num played games": 1664, "Total num trained steps": 2691, "Timestamp in ms": 1701554093592, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6842105263157894, "Avg loss": 1.6634280383586884, "Avg value loss": 1.0075591951608658, "Avg policy loss": 0.6558688622899354, "Total num played games": 1672, "Total num trained steps": 2816, "Timestamp in ms": 1701554149713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.663276836158192, "Avg loss": 1.8038830757141113, "Avg value loss": 1.191242751199752, "Avg policy loss": 0.6126403217203915, "Total num played games": 1770, "Total num trained steps": 2944, "Timestamp in ms": 1701554207181, "logtype": "training_step"}
{"Total num played games": 1772, "Total num trained steps": 3012, "Timestamp in ms": 1701554277125, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.26953125}
{"Avg objective": 20.4140625, "Games time in secs": 191.72541322000325, "Avg game time in secs": 12.42387779596902, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 1.15, "reached_maximum_moves": 0.03, "agent_stopped_0": 0.62}, "Total num played games": 1792, "Total num trained steps": 3029, "Timestamp in ms": 1701554285318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6623376623376624, "Avg loss": 1.6497130943462253, "Avg value loss": 1.0699174511246383, "Avg policy loss": 0.5797956418246031, "Total num played games": 1848, "Total num trained steps": 3072, "Timestamp in ms": 1701554303844, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7241379310344827, "Avg loss": 1.5507199615240097, "Avg value loss": 1.0069767804816365, "Avg policy loss": 0.5437431794125587, "Total num played games": 1856, "Total num trained steps": 3200, "Timestamp in ms": 1701554360418, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 84.82866883091629, "Avg game time in secs": 9.996538919294835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.67}, "Total num played games": 1920, "Total num trained steps": 3223, "Timestamp in ms": 1701554370147, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7066666666666668, "Avg loss": 1.7452309634536505, "Avg value loss": 1.2270726431161165, "Avg policy loss": 0.5181583070661873, "Total num played games": 1950, "Total num trained steps": 3328, "Timestamp in ms": 1701554415889, "logtype": "training_step"}
{"Avg objective": 19.9765625, "Games time in secs": 96.4904677271843, "Avg game time in secs": 16.5980461443105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 1.59, "agent_stopped_0": 0.59, "reached_maximum_moves": 0.05}, "Total num played games": 2048, "Total num trained steps": 3447, "Timestamp in ms": 1701554466638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6858536585365853, "Avg loss": 1.667388228699565, "Avg value loss": 1.1527411653660238, "Avg policy loss": 0.5146470661275089, "Total num played games": 2050, "Total num trained steps": 3456, "Timestamp in ms": 1701554470586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.746101364522417, "Avg loss": 1.34548683417961, "Avg value loss": 0.8351678887847811, "Avg policy loss": 0.5103189470246434, "Total num played games": 2052, "Total num trained steps": 3584, "Timestamp in ms": 1701554526050, "logtype": "training_step"}
{"Total num played games": 2138, "Total num trained steps": 3612, "Timestamp in ms": 1701554584864, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.53125}
{"Avg objective": 20.75, "Games time in secs": 127.9632927775383, "Avg game time in secs": 9.909863406253862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.77, "agent_stopped_0": 0.71, "reached_maximum_moves": 0.01}, "Total num played games": 2176, "Total num trained steps": 3634, "Timestamp in ms": 1701554594601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.668615107913669, "Avg loss": 1.705397630110383, "Avg value loss": 1.2013566135428846, "Avg policy loss": 0.5040410200599581, "Total num played games": 2224, "Total num trained steps": 3712, "Timestamp in ms": 1701554630077, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7204301075268817, "Avg loss": 1.2703442312777042, "Avg value loss": 0.7701457375660539, "Avg policy loss": 0.500198487425223, "Total num played games": 2232, "Total num trained steps": 3840, "Timestamp in ms": 1701554686146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7541998231653404, "Avg loss": 1.111464872956276, "Avg value loss": 0.612459905911237, "Avg policy loss": 0.49900495540350676, "Total num played games": 2262, "Total num trained steps": 3968, "Timestamp in ms": 1701554743202, "logtype": "training_step"}
{"Avg objective": 19.9375, "Games time in secs": 152.59880759194493, "Avg game time in secs": 12.354665286882664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.37, "played_steps": 1.2, "reached_maximum_moves": 0.04}, "Total num played games": 2304, "Total num trained steps": 3977, "Timestamp in ms": 1701554747200, "logtype": "played_game"}
{"Ratio train steps to played games": 1.75793991416309, "Avg loss": 1.3219061396084726, "Avg value loss": 0.8394787919241935, "Avg policy loss": 0.48242735397070646, "Total num played games": 2330, "Total num trained steps": 4096, "Timestamp in ms": 1701554801193, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 153.3219774775207, "Avg game time in secs": 11.129461869088118, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.39, "played_steps": 1.12, "reached_maximum_moves": 0.02}, "Total num played games": 2432, "Total num trained steps": 4212, "Timestamp in ms": 1701554900522, "logtype": "played_game"}
{"Total num played games": 2432, "Total num trained steps": 4212, "Timestamp in ms": 1701554901966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.90625}
{"Ratio train steps to played games": 1.7335796387520526, "Avg loss": 1.306760842911899, "Avg value loss": 0.8284126445651054, "Avg policy loss": 0.4783481932245195, "Total num played games": 2436, "Total num trained steps": 4224, "Timestamp in ms": 1701554907412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7228820269200316, "Avg loss": 1.4684356143698096, "Avg value loss": 0.9967728299088776, "Avg policy loss": 0.4716627795714885, "Total num played games": 2526, "Total num trained steps": 4352, "Timestamp in ms": 1701554964699, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7735550277117973, "Avg loss": 1.1008079452440143, "Avg value loss": 0.626461596461013, "Avg policy loss": 0.47434634482488036, "Total num played games": 2526, "Total num trained steps": 4480, "Timestamp in ms": 1701555022254, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 154.89470676518977, "Avg game time in secs": 7.015535296726739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.3}, "Total num played games": 2560, "Total num trained steps": 4557, "Timestamp in ms": 1701555055417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.760122230710466, "Avg loss": 1.1123212845996022, "Avg value loss": 0.6600276050157845, "Avg policy loss": 0.4522936739958823, "Total num played games": 2618, "Total num trained steps": 4608, "Timestamp in ms": 1701555078451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8035034272658035, "Avg loss": 1.1745553626678884, "Avg value loss": 0.729768437333405, "Avg policy loss": 0.44478692556731403, "Total num played games": 2626, "Total num trained steps": 4736, "Timestamp in ms": 1701555135481, "logtype": "training_step"}
{"Avg objective": 19.8046875, "Games time in secs": 91.53032413311303, "Avg game time in secs": 9.193479074572679, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.34, "played_steps": 0.82, "reached_maximum_moves": 0.01}, "Total num played games": 2688, "Total num trained steps": 4762, "Timestamp in ms": 1701555146947, "logtype": "played_game"}
{"Total num played games": 2722, "Total num trained steps": 4815, "Timestamp in ms": 1701555205194, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0234375}
{"Ratio train steps to played games": 1.7309608540925268, "Avg loss": 1.7181426091119647, "Avg value loss": 1.2848078904207796, "Avg policy loss": 0.43333471892401576, "Total num played games": 2810, "Total num trained steps": 4864, "Timestamp in ms": 1701555228512, "logtype": "training_step"}
{"Avg objective": 20.171875, "Games time in secs": 99.63086059316993, "Avg game time in secs": 9.136670864245389, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.83, "agent_stopped_0": 0.51}, "Total num played games": 2816, "Total num trained steps": 4903, "Timestamp in ms": 1701555246578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7727272727272727, "Avg loss": 1.1454316973686218, "Avg value loss": 0.702115639578551, "Avg policy loss": 0.4433160664048046, "Total num played games": 2816, "Total num trained steps": 4992, "Timestamp in ms": 1701555285068, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8168914123491837, "Avg loss": 0.9519005278125405, "Avg value loss": 0.5146425208076835, "Avg policy loss": 0.4372580056078732, "Total num played games": 2818, "Total num trained steps": 5120, "Timestamp in ms": 1701555342873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7993827160493827, "Avg loss": 1.2694426062516868, "Avg value loss": 0.8388672734145075, "Avg policy loss": 0.43057534424588084, "Total num played games": 2916, "Total num trained steps": 5248, "Timestamp in ms": 1701555400054, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 192.37925798259676, "Avg game time in secs": 6.815253954642685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "reached_maximum_moves": 0.01, "played_steps": 0.45, "agent_stopped_more": 0.23}, "Total num played games": 2944, "Total num trained steps": 5334, "Timestamp in ms": 1701555438958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.786046511627907, "Avg loss": 1.2855655597522855, "Avg value loss": 0.8563056162092835, "Avg policy loss": 0.4292599519249052, "Total num played games": 3010, "Total num trained steps": 5376, "Timestamp in ms": 1701555456383, "logtype": "training_step"}
{"Total num played games": 3018, "Total num trained steps": 5415, "Timestamp in ms": 1701555511569, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8515625}
{"Avg objective": 21.3203125, "Games time in secs": 80.85224094241858, "Avg game time in secs": 7.690135499098687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.58}, "Total num played games": 3072, "Total num trained steps": 5433, "Timestamp in ms": 1701555519810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.770913770913771, "Avg loss": 1.2330250525847077, "Avg value loss": 0.780545748770237, "Avg policy loss": 0.4524793054442853, "Total num played games": 3108, "Total num trained steps": 5504, "Timestamp in ms": 1701555551015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8097686375321336, "Avg loss": 0.9535446087829769, "Avg value loss": 0.5162340099923313, "Avg policy loss": 0.43731059366837144, "Total num played games": 3112, "Total num trained steps": 5632, "Timestamp in ms": 1701555606250, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 137.25252598524094, "Avg game time in secs": 8.979954733309569, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.84, "agent_stopped_0": 0.57}, "Total num played games": 3200, "Total num trained steps": 5748, "Timestamp in ms": 1701555657063, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7966313162819714, "Avg loss": 1.0151570471934974, "Avg value loss": 0.5779970362782478, "Avg policy loss": 0.4371600018348545, "Total num played games": 3206, "Total num trained steps": 5760, "Timestamp in ms": 1701555662130, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8331257783312578, "Avg loss": 1.0777836148627102, "Avg value loss": 0.6472948235459626, "Avg policy loss": 0.43048879504203796, "Total num played games": 3212, "Total num trained steps": 5888, "Timestamp in ms": 1701555719881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.818621523579202, "Avg loss": 1.2383253569714725, "Avg value loss": 0.8018560039345175, "Avg policy loss": 0.43646935652941465, "Total num played games": 3308, "Total num trained steps": 6016, "Timestamp in ms": 1701555774740, "logtype": "training_step"}
{"Total num played games": 3308, "Total num trained steps": 6017, "Timestamp in ms": 1701555812105, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7890625}
{"Avg objective": 19.453125, "Games time in secs": 160.4461687915027, "Avg game time in secs": 7.313527045494993, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.8, "agent_stopped_0": 0.56, "reached_maximum_moves": 0.01}, "Total num played games": 3328, "Total num trained steps": 6029, "Timestamp in ms": 1701555817509, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8059964726631392, "Avg loss": 1.2254521432332695, "Avg value loss": 0.8193235397338867, "Avg policy loss": 0.4061286065261811, "Total num played games": 3402, "Total num trained steps": 6144, "Timestamp in ms": 1701555869820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8436213991769548, "Avg loss": 0.861266478896141, "Avg value loss": 0.45976071525365114, "Avg policy loss": 0.4015057620126754, "Total num played games": 3402, "Total num trained steps": 6272, "Timestamp in ms": 1701555924987, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 122.460040172562, "Avg game time in secs": 5.637020736685372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.23, "played_steps": 0.3}, "Total num played games": 3456, "Total num trained steps": 6308, "Timestamp in ms": 1701555939969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8285714285714285, "Avg loss": 1.0291115627624094, "Avg value loss": 0.6218402360100299, "Avg policy loss": 0.40727132675237954, "Total num played games": 3500, "Total num trained steps": 6400, "Timestamp in ms": 1701555980174, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 88.67788392677903, "Avg game time in secs": 6.178255099133821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.53, "agent_stopped_0": 0.59}, "Total num played games": 3584, "Total num trained steps": 6514, "Timestamp in ms": 1701556028647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8163606010016695, "Avg loss": 0.9437286173924804, "Avg value loss": 0.5278013406787068, "Avg policy loss": 0.4159272804390639, "Total num played games": 3594, "Total num trained steps": 6528, "Timestamp in ms": 1701556035004, "logtype": "training_step"}
{"Total num played games": 3598, "Total num trained steps": 6619, "Timestamp in ms": 1701556112202, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6484375}
{"Ratio train steps to played games": 1.8037940379403794, "Avg loss": 1.049712436273694, "Avg value loss": 0.6567579668480903, "Avg policy loss": 0.39295446942560375, "Total num played games": 3690, "Total num trained steps": 6656, "Timestamp in ms": 1701556128211, "logtype": "training_step"}
{"Ratio train steps to played games": 1.837486457204767, "Avg loss": 0.9657906270585954, "Avg value loss": 0.572338443947956, "Avg policy loss": 0.3934521833434701, "Total num played games": 3692, "Total num trained steps": 6784, "Timestamp in ms": 1701556184091, "logtype": "training_step"}
{"Avg objective": 19.9140625, "Games time in secs": 198.67261307872832, "Avg game time in secs": 6.431435035672621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.55, "agent_stopped_0": 0.62}, "Total num played games": 3712, "Total num trained steps": 6885, "Timestamp in ms": 1701556227320, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8256735340729002, "Avg loss": 0.8743405998684466, "Avg value loss": 0.5004942102823406, "Avg policy loss": 0.37384639075025916, "Total num played games": 3786, "Total num trained steps": 6912, "Timestamp in ms": 1701556238015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8575197889182058, "Avg loss": 0.8999863271601498, "Avg value loss": 0.5113844131119549, "Avg policy loss": 0.38860191055573523, "Total num played games": 3790, "Total num trained steps": 7040, "Timestamp in ms": 1701556292217, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 84.28236194886267, "Avg game time in secs": 6.369979690367472, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.55}, "Total num played games": 3840, "Total num trained steps": 7086, "Timestamp in ms": 1701556311602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8426735218508998, "Avg loss": 0.9517273488454521, "Avg value loss": 0.5658787766005844, "Avg policy loss": 0.38584857364185154, "Total num played games": 3890, "Total num trained steps": 7168, "Timestamp in ms": 1701556346599, "logtype": "training_step"}
{"Total num played games": 3890, "Total num trained steps": 7222, "Timestamp in ms": 1701556440222, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.66015625}
{"Avg objective": 20.9921875, "Games time in secs": 139.63855732046068, "Avg game time in secs": 6.149315996459336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.61, "agent_stopped_0": 0.53}, "Total num played games": 3968, "Total num trained steps": 7247, "Timestamp in ms": 1701556451241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8313253012048192, "Avg loss": 0.9585769278928638, "Avg value loss": 0.5669769567903131, "Avg policy loss": 0.39159997343085706, "Total num played games": 3984, "Total num trained steps": 7296, "Timestamp in ms": 1701556471796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8634538152610443, "Avg loss": 0.8240074226632714, "Avg value loss": 0.41770130360964686, "Avg policy loss": 0.4063061161432415, "Total num played games": 3984, "Total num trained steps": 7424, "Timestamp in ms": 1701556525790, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8500734933855953, "Avg loss": 0.9426754340529442, "Avg value loss": 0.5508387682493776, "Avg policy loss": 0.3918366669677198, "Total num played games": 4082, "Total num trained steps": 7552, "Timestamp in ms": 1701556579290, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 173.9631549604237, "Avg game time in secs": 6.001471873401897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.53}, "Total num played games": 4096, "Total num trained steps": 7661, "Timestamp in ms": 1701556625204, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8382000957395883, "Avg loss": 0.8431377746164799, "Avg value loss": 0.4617980995681137, "Avg policy loss": 0.3813396757468581, "Total num played games": 4178, "Total num trained steps": 7680, "Timestamp in ms": 1701556632977, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8679425837320573, "Avg loss": 0.915909537114203, "Avg value loss": 0.5272716369945556, "Avg policy loss": 0.3886378987226635, "Total num played games": 4180, "Total num trained steps": 7808, "Timestamp in ms": 1701556686606, "logtype": "training_step"}
{"Total num played games": 4180, "Total num trained steps": 7823, "Timestamp in ms": 1701556726692, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0078125}
{"Avg objective": 20.375, "Games time in secs": 108.04106730222702, "Avg game time in secs": 4.6926210851815995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.3}, "Total num played games": 4224, "Total num trained steps": 7838, "Timestamp in ms": 1701556733245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8568086102012167, "Avg loss": 1.627201281953603, "Avg value loss": 1.2540003883186728, "Avg policy loss": 0.3732009020168334, "Total num played games": 4274, "Total num trained steps": 7936, "Timestamp in ms": 1701556776593, "logtype": "training_step"}
{"Avg objective": 20.5, "Games time in secs": 94.04569633305073, "Avg game time in secs": 5.6108111075736815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 4352, "Total num trained steps": 8059, "Timestamp in ms": 1701556827291, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8461538461538463, "Avg loss": 1.3789549004286528, "Avg value loss": 1.005984462564811, "Avg policy loss": 0.372970434371382, "Total num played games": 4368, "Total num trained steps": 8064, "Timestamp in ms": 1701556829450, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8737419945105216, "Avg loss": 0.8911399021744728, "Avg value loss": 0.49851702083833516, "Avg policy loss": 0.3926228790078312, "Total num played games": 4372, "Total num trained steps": 8192, "Timestamp in ms": 1701556883078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.861297539149888, "Avg loss": 0.9648959799669683, "Avg value loss": 0.5780675201676786, "Avg policy loss": 0.38682844839058816, "Total num played games": 4470, "Total num trained steps": 8320, "Timestamp in ms": 1701556936017, "logtype": "training_step"}
{"Total num played games": 4470, "Total num trained steps": 8424, "Timestamp in ms": 1701557027867, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8203125}
{"Avg objective": 19.9921875, "Games time in secs": 204.1662130150944, "Avg game time in secs": 6.36738376528956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.75, "agent_stopped_0": 0.47}, "Total num played games": 4480, "Total num trained steps": 8431, "Timestamp in ms": 1701557031458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8542581211589113, "Avg loss": 0.8401512308046222, "Avg value loss": 0.4515036374796182, "Avg policy loss": 0.3886475916951895, "Total num played games": 4556, "Total num trained steps": 8448, "Timestamp in ms": 1701557038287, "logtype": "training_step"}
{"Ratio train steps to played games": 1.878011388523872, "Avg loss": 0.8383487351238728, "Avg value loss": 0.44104769360274076, "Avg policy loss": 0.3973010405898094, "Total num played games": 4566, "Total num trained steps": 8576, "Timestamp in ms": 1701557092393, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 84.32449668459594, "Avg game time in secs": 4.544840140733868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.38, "agent_stopped_0": 0.69}, "Total num played games": 4608, "Total num trained steps": 8631, "Timestamp in ms": 1701557115782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.867009867009867, "Avg loss": 0.9055492468178272, "Avg value loss": 0.5343159877229482, "Avg policy loss": 0.37123325280845165, "Total num played games": 4662, "Total num trained steps": 8704, "Timestamp in ms": 1701557145740, "logtype": "training_step"}
{"Avg objective": 20.390625, "Games time in secs": 81.49593033455312, "Avg game time in secs": 4.85390275750251, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 4736, "Total num trained steps": 8830, "Timestamp in ms": 1701557197278, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8640776699029127, "Avg loss": 0.849386855494231, "Avg value loss": 0.4800265117082745, "Avg policy loss": 0.3693603496067226, "Total num played games": 4738, "Total num trained steps": 8832, "Timestamp in ms": 1701557198110, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8823529411764706, "Avg loss": 0.8406514930538833, "Avg value loss": 0.489843821618706, "Avg policy loss": 0.3508076735306531, "Total num played games": 4760, "Total num trained steps": 8960, "Timestamp in ms": 1701557250371, "logtype": "training_step"}
{"Total num played games": 4856, "Total num trained steps": 9026, "Timestamp in ms": 1701557311459, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.52734375}
{"Avg objective": 20.1015625, "Games time in secs": 117.3538574129343, "Avg game time in secs": 5.691366434562951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.57, "agent_stopped_0": 0.55}, "Total num played games": 4864, "Total num trained steps": 9032, "Timestamp in ms": 1701557314632, "logtype": "played_game"}
{"Ratio train steps to played games": 1.835959595959596, "Avg loss": 0.9920816565863788, "Avg value loss": 0.6307415665360168, "Avg policy loss": 0.36134008143562824, "Total num played games": 4950, "Total num trained steps": 9088, "Timestamp in ms": 1701557338180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8618181818181818, "Avg loss": 0.7601869758218527, "Avg value loss": 0.3833087293896824, "Avg policy loss": 0.3768782439874485, "Total num played games": 4950, "Total num trained steps": 9216, "Timestamp in ms": 1701557391352, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8876767676767676, "Avg loss": 0.6722995617892593, "Avg value loss": 0.3209980925312266, "Avg policy loss": 0.35130147193558514, "Total num played games": 4950, "Total num trained steps": 9344, "Timestamp in ms": 1701557444745, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 153.94752099178731, "Avg game time in secs": 4.431419712622301, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.53}, "Total num played games": 4992, "Total num trained steps": 9403, "Timestamp in ms": 1701557468580, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8771304003170828, "Avg loss": 0.836156954523176, "Avg value loss": 0.47832218604162335, "Avg policy loss": 0.35783476661890745, "Total num played games": 5046, "Total num trained steps": 9472, "Timestamp in ms": 1701557497703, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 79.87410886213183, "Avg game time in secs": 4.657341863770853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 5120, "Total num trained steps": 9595, "Timestamp in ms": 1701557548454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8720748829953198, "Avg loss": 0.701749483589083, "Avg value loss": 0.3415254042483866, "Avg policy loss": 0.36022408585995436, "Total num played games": 5128, "Total num trained steps": 9600, "Timestamp in ms": 1701557550398, "logtype": "training_step"}
{"Total num played games": 5142, "Total num trained steps": 9629, "Timestamp in ms": 1701557597234, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.41796875}
{"Ratio train steps to played games": 1.8579067990832696, "Avg loss": 1.2491560620255768, "Avg value loss": 0.8756053291726857, "Avg policy loss": 0.373550730291754, "Total num played games": 5236, "Total num trained steps": 9728, "Timestamp in ms": 1701557638917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8823529411764706, "Avg loss": 0.932824638672173, "Avg value loss": 0.5535340423230082, "Avg policy loss": 0.3792905907612294, "Total num played games": 5236, "Total num trained steps": 9856, "Timestamp in ms": 1701557690130, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 187.2417909540236, "Avg game time in secs": 5.067025975920842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.62, "agent_stopped_0": 0.55}, "Total num played games": 5248, "Total num trained steps": 9966, "Timestamp in ms": 1701557735696, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8738738738738738, "Avg loss": 0.917881106492132, "Avg value loss": 0.5488710994832218, "Avg policy loss": 0.3690100065432489, "Total num played games": 5328, "Total num trained steps": 9984, "Timestamp in ms": 1701557742653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8964741185296323, "Avg loss": 0.9194041732698679, "Avg value loss": 0.5446493744384497, "Avg policy loss": 0.3747548018582165, "Total num played games": 5332, "Total num trained steps": 10112, "Timestamp in ms": 1701557795259, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 81.16893665678799, "Avg game time in secs": 3.604655305360211, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.34}, "Total num played games": 5376, "Total num trained steps": 10161, "Timestamp in ms": 1701557816865, "logtype": "played_game"}
{"Total num played games": 5428, "Total num trained steps": 10229, "Timestamp in ms": 1701557881686, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5859375}
{"Ratio train steps to played games": 1.869295363271267, "Avg loss": 0.9967093742452562, "Avg value loss": 0.6313833484891802, "Avg policy loss": 0.36532602459192276, "Total num played games": 5476, "Total num trained steps": 10240, "Timestamp in ms": 1701557886589, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 71.98502274043858, "Avg game time in secs": 3.7032108291168697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 5504, "Total num trained steps": 10245, "Timestamp in ms": 1701557888850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8775805867439335, "Avg loss": 0.9408029639162123, "Avg value loss": 0.57563521200791, "Avg policy loss": 0.36516774841584265, "Total num played games": 5522, "Total num trained steps": 10368, "Timestamp in ms": 1701557940495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9007605939876857, "Avg loss": 0.7924636141397059, "Avg value loss": 0.44311859435401857, "Avg policy loss": 0.3493450217647478, "Total num played games": 5522, "Total num trained steps": 10496, "Timestamp in ms": 1701557992399, "logtype": "training_step"}
{"Ratio train steps to played games": 1.891064435742257, "Avg loss": 0.9047356708906591, "Avg value loss": 0.5475728083401918, "Avg policy loss": 0.3571628632489592, "Total num played games": 5618, "Total num trained steps": 10624, "Timestamp in ms": 1701558044691, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 200.00349656678736, "Avg game time in secs": 4.2860370033595245, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.59, "agent_stopped_0": 0.54}, "Total num played games": 5632, "Total num trained steps": 10730, "Timestamp in ms": 1701558088854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8816940847042352, "Avg loss": 0.7495708595961332, "Avg value loss": 0.39324335055425763, "Avg policy loss": 0.3563275069463998, "Total num played games": 5714, "Total num trained steps": 10752, "Timestamp in ms": 1701558097829, "logtype": "training_step"}
{"Total num played games": 5714, "Total num trained steps": 10831, "Timestamp in ms": 1701558170617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6328125}
{"Avg objective": 20.1328125, "Games time in secs": 85.55373352020979, "Avg game time in secs": 3.02958825857786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 5760, "Total num trained steps": 10840, "Timestamp in ms": 1701558174408, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8731060606060606, "Avg loss": 0.8821529145352542, "Avg value loss": 0.5064327769214287, "Avg policy loss": 0.37572013679891825, "Total num played games": 5808, "Total num trained steps": 10880, "Timestamp in ms": 1701558191939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8953168044077136, "Avg loss": 0.7130487663671374, "Avg value loss": 0.33902398427017033, "Avg policy loss": 0.37402478395961225, "Total num played games": 5808, "Total num trained steps": 11008, "Timestamp in ms": 1701558245065, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 116.72337523289025, "Avg game time in secs": 3.439579271245748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.52}, "Total num played games": 5888, "Total num trained steps": 11122, "Timestamp in ms": 1701558291131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.886178861788618, "Avg loss": 0.7263160001020879, "Avg value loss": 0.37400746054481715, "Avg policy loss": 0.35230853990651667, "Total num played games": 5904, "Total num trained steps": 11136, "Timestamp in ms": 1701558296940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9078590785907859, "Avg loss": 0.7807132741436362, "Avg value loss": 0.4323363065486774, "Avg policy loss": 0.34837696712929755, "Total num played games": 5904, "Total num trained steps": 11264, "Timestamp in ms": 1701558347836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8986666666666667, "Avg loss": 0.8360641272738576, "Avg value loss": 0.4710039747878909, "Avg policy loss": 0.3650601510889828, "Total num played games": 6000, "Total num trained steps": 11392, "Timestamp in ms": 1701558401527, "logtype": "training_step"}
{"Total num played games": 6000, "Total num trained steps": 11435, "Timestamp in ms": 1701558450883, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Avg objective": 19.921875, "Games time in secs": 163.58212760090828, "Avg game time in secs": 3.948062452036538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 6016, "Total num trained steps": 11442, "Timestamp in ms": 1701558454713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8903839842468002, "Avg loss": 0.8605840210802853, "Avg value loss": 0.49388241744600236, "Avg policy loss": 0.3667016008403152, "Total num played games": 6094, "Total num trained steps": 11520, "Timestamp in ms": 1701558487403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9113882507384312, "Avg loss": 0.6710060792975128, "Avg value loss": 0.3038887601578608, "Avg policy loss": 0.36711732065305114, "Total num played games": 6094, "Total num trained steps": 11648, "Timestamp in ms": 1701558541833, "logtype": "training_step"}
{"Avg objective": 20.0234375, "Games time in secs": 102.30940649844706, "Avg game time in secs": 3.705594430633937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.54}, "Total num played games": 6144, "Total num trained steps": 11685, "Timestamp in ms": 1701558557023, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9024232633279483, "Avg loss": 0.8698482639156282, "Avg value loss": 0.49133454891853034, "Avg policy loss": 0.37851370964199305, "Total num played games": 6190, "Total num trained steps": 11776, "Timestamp in ms": 1701558594175, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 81.774757752195, "Avg game time in secs": 3.195300097868312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 6272, "Total num trained steps": 11882, "Timestamp in ms": 1701558638798, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8937321030862233, "Avg loss": 0.7871402013115585, "Avg value loss": 0.42707616079133004, "Avg policy loss": 0.3600640358636156, "Total num played games": 6286, "Total num trained steps": 11904, "Timestamp in ms": 1701558647784, "logtype": "training_step"}
{"Ratio train steps to played games": 1.913935730194082, "Avg loss": 0.7021294564474374, "Avg value loss": 0.34970006928779185, "Avg policy loss": 0.35242939181625843, "Total num played games": 6286, "Total num trained steps": 12032, "Timestamp in ms": 1701558701110, "logtype": "training_step"}
{"Total num played games": 6286, "Total num trained steps": 12035, "Timestamp in ms": 1701558735261, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.265625}
{"Ratio train steps to played games": 1.9059561128526645, "Avg loss": 0.7863259413279593, "Avg value loss": 0.43679467670153826, "Avg policy loss": 0.3495312709128484, "Total num played games": 6380, "Total num trained steps": 12160, "Timestamp in ms": 1701558788406, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 188.63581400737166, "Avg game time in secs": 3.139334984749439, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 6400, "Total num trained steps": 12255, "Timestamp in ms": 1701558827434, "logtype": "played_game"}
{"Ratio train steps to played games": 1.897313156269302, "Avg loss": 0.7454600129276514, "Avg value loss": 0.4032966102240607, "Avg policy loss": 0.3421633986290544, "Total num played games": 6476, "Total num trained steps": 12288, "Timestamp in ms": 1701558841069, "logtype": "training_step"}
{"Ratio train steps to played games": 1.917232859789994, "Avg loss": 0.7899131923913956, "Avg value loss": 0.43846415868029, "Avg policy loss": 0.35144903138279915, "Total num played games": 6476, "Total num trained steps": 12416, "Timestamp in ms": 1701558894542, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 80.91130581125617, "Avg game time in secs": 3.063414536169148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 6528, "Total num trained steps": 12451, "Timestamp in ms": 1701558908345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9087035909920878, "Avg loss": 0.7944201133213937, "Avg value loss": 0.4432566858595237, "Avg policy loss": 0.3511634280439466, "Total num played games": 6572, "Total num trained steps": 12544, "Timestamp in ms": 1701558946943, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 82.85639168322086, "Avg game time in secs": 3.4813190252898494, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.57}, "Total num played games": 6656, "Total num trained steps": 12636, "Timestamp in ms": 1701558991202, "logtype": "played_game"}
{"Total num played games": 6666, "Total num trained steps": 12636, "Timestamp in ms": 1701559013044, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.03515625}
{"Ratio train steps to played games": 1.8745562130177515, "Avg loss": 0.8599502928555012, "Avg value loss": 0.5155636291019619, "Avg policy loss": 0.3443866635207087, "Total num played games": 6760, "Total num trained steps": 12672, "Timestamp in ms": 1701559028207, "logtype": "training_step"}
{"Ratio train steps to played games": 1.893491124260355, "Avg loss": 0.7551715434528887, "Avg value loss": 0.39928246615454555, "Avg policy loss": 0.3558890747372061, "Total num played games": 6760, "Total num trained steps": 12800, "Timestamp in ms": 1701559078548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9124260355029585, "Avg loss": 0.6230945962015539, "Avg value loss": 0.28033435496035963, "Avg policy loss": 0.3427602412411943, "Total num played games": 6760, "Total num trained steps": 12928, "Timestamp in ms": 1701559131212, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 176.18654406443238, "Avg game time in secs": 2.9586985971109243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.41, "agent_stopped_0": 0.65}, "Total num played games": 6784, "Total num trained steps": 13016, "Timestamp in ms": 1701559167388, "logtype": "played_game"}
{"Ratio train steps to played games": 1.904171528588098, "Avg loss": 0.7331038319971412, "Avg value loss": 0.4014796637929976, "Avg policy loss": 0.3316241743741557, "Total num played games": 6856, "Total num trained steps": 13056, "Timestamp in ms": 1701559183261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9229871645274212, "Avg loss": 0.6137061833869666, "Avg value loss": 0.27691410249099135, "Avg policy loss": 0.33679208427201957, "Total num played games": 6856, "Total num trained steps": 13184, "Timestamp in ms": 1701559235622, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 78.76156774163246, "Avg game time in secs": 3.1013810593867674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 6912, "Total num trained steps": 13211, "Timestamp in ms": 1701559246150, "logtype": "played_game"}
{"Total num played games": 6954, "Total num trained steps": 13239, "Timestamp in ms": 1701559279357, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8828125}
{"Avg objective": 20.1171875, "Games time in secs": 39.56193601153791, "Avg game time in secs": 3.0322515186999226, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 7040, "Total num trained steps": 13253, "Timestamp in ms": 1701559285712, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8887627695800226, "Avg loss": 0.941592562245205, "Avg value loss": 0.59932432603091, "Avg policy loss": 0.3422682353993878, "Total num played games": 7048, "Total num trained steps": 13312, "Timestamp in ms": 1701559310021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9069239500567536, "Avg loss": 0.6567175921518356, "Avg value loss": 0.31666789983864874, "Avg policy loss": 0.3400496942922473, "Total num played games": 7048, "Total num trained steps": 13440, "Timestamp in ms": 1701559362652, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9250851305334846, "Avg loss": 0.6219957664143294, "Avg value loss": 0.30840734823141247, "Avg policy loss": 0.31358842027839273, "Total num played games": 7048, "Total num trained steps": 13568, "Timestamp in ms": 1701559415383, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9165966974531206, "Avg loss": 0.7968716046307236, "Avg value loss": 0.48130966862663627, "Avg policy loss": 0.31556194298900664, "Total num played games": 7146, "Total num trained steps": 13696, "Timestamp in ms": 1701559467971, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 219.21543237566948, "Avg game time in secs": 3.012356796738459, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.51, "agent_stopped_0": 0.59}, "Total num played games": 7168, "Total num trained steps": 13787, "Timestamp in ms": 1701559504928, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9078112061827215, "Avg loss": 0.7080234258901328, "Avg value loss": 0.39222614478785545, "Avg policy loss": 0.3157972762128338, "Total num played games": 7246, "Total num trained steps": 13824, "Timestamp in ms": 1701559520195, "logtype": "training_step"}
{"Total num played games": 7246, "Total num trained steps": 13839, "Timestamp in ms": 1701559546685, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.609375}
{"Avg objective": 21.125, "Games time in secs": 46.17517826333642, "Avg game time in secs": 2.9493373075820273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 7296, "Total num trained steps": 13848, "Timestamp in ms": 1701559551103, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9008174386920982, "Avg loss": 0.8755387309938669, "Avg value loss": 0.5321640754118562, "Avg policy loss": 0.3433746541850269, "Total num played games": 7340, "Total num trained steps": 13952, "Timestamp in ms": 1701559594461, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9182561307901906, "Avg loss": 0.6257813898846507, "Avg value loss": 0.28994653711561114, "Avg policy loss": 0.3358348528854549, "Total num played games": 7340, "Total num trained steps": 14080, "Timestamp in ms": 1701559645988, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 135.134363187477, "Avg game time in secs": 3.019647121313028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 7424, "Total num trained steps": 14179, "Timestamp in ms": 1701559686237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9107046799354492, "Avg loss": 0.6960030123591423, "Avg value loss": 0.3773457270581275, "Avg policy loss": 0.31865728343836963, "Total num played games": 7436, "Total num trained steps": 14208, "Timestamp in ms": 1701559698579, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9279182356105433, "Avg loss": 0.6590293773915619, "Avg value loss": 0.33716142224147916, "Avg policy loss": 0.3218679508427158, "Total num played games": 7436, "Total num trained steps": 14336, "Timestamp in ms": 1701559752864, "logtype": "training_step"}
{"Total num played games": 7534, "Total num trained steps": 14442, "Timestamp in ms": 1701559820895, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.43359375}
{"Avg objective": 20.625, "Games time in secs": 137.3963420074433, "Avg game time in secs": 3.15420089190593, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.57, "agent_stopped_0": 0.56}, "Total num played games": 7552, "Total num trained steps": 14447, "Timestamp in ms": 1701559823634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8961719979024647, "Avg loss": 0.8940271362662315, "Avg value loss": 0.5614714855328202, "Avg policy loss": 0.3325556415366009, "Total num played games": 7628, "Total num trained steps": 14464, "Timestamp in ms": 1701559830755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.912952281069743, "Avg loss": 0.7712888033129275, "Avg value loss": 0.4175557531416416, "Avg policy loss": 0.35373305156826973, "Total num played games": 7628, "Total num trained steps": 14592, "Timestamp in ms": 1701559884141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9297325642370216, "Avg loss": 0.7477054456248879, "Avg value loss": 0.41004486102610826, "Avg policy loss": 0.3376605836674571, "Total num played games": 7628, "Total num trained steps": 14720, "Timestamp in ms": 1701559935736, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 124.78766266256571, "Avg game time in secs": 2.6649868355307262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 7680, "Total num trained steps": 14753, "Timestamp in ms": 1701559948422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9223200414293113, "Avg loss": 0.8332165617030114, "Avg value loss": 0.49959163228049874, "Avg policy loss": 0.3336249302374199, "Total num played games": 7724, "Total num trained steps": 14848, "Timestamp in ms": 1701559989083, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 84.70000160485506, "Avg game time in secs": 2.9198527257249225, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 7808, "Total num trained steps": 14955, "Timestamp in ms": 1701560033122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9155794320798158, "Avg loss": 0.7557470218744129, "Avg value loss": 0.4326652663294226, "Avg policy loss": 0.32308175729122013, "Total num played games": 7818, "Total num trained steps": 14976, "Timestamp in ms": 1701560041955, "logtype": "training_step"}
{"Total num played games": 7818, "Total num trained steps": 15043, "Timestamp in ms": 1701560100617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.59765625}
{"Ratio train steps to played games": 1.9089989888776542, "Avg loss": 0.9581679608672857, "Avg value loss": 0.6203605614136904, "Avg policy loss": 0.3378074037609622, "Total num played games": 7912, "Total num trained steps": 15104, "Timestamp in ms": 1701560126547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9251769464105157, "Avg loss": 0.6604546920862049, "Avg value loss": 0.3211752782808617, "Avg policy loss": 0.33927941392175853, "Total num played games": 7912, "Total num trained steps": 15232, "Timestamp in ms": 1701560179045, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 182.96827077679336, "Avg game time in secs": 3.18258874512685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.64, "agent_stopped_0": 0.54}, "Total num played games": 7936, "Total num trained steps": 15318, "Timestamp in ms": 1701560216090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9180819180819182, "Avg loss": 0.729568547103554, "Avg value loss": 0.3935656084213406, "Avg policy loss": 0.3360029443865642, "Total num played games": 8008, "Total num trained steps": 15360, "Timestamp in ms": 1701560232797, "logtype": "training_step"}
{"Ratio train steps to played games": 1.934065934065934, "Avg loss": 0.6500228161457926, "Avg value loss": 0.308266123640351, "Avg policy loss": 0.34175669215619564, "Total num played games": 8008, "Total num trained steps": 15488, "Timestamp in ms": 1701560284496, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 78.90594909712672, "Avg game time in secs": 2.848792497825343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 8064, "Total num trained steps": 15511, "Timestamp in ms": 1701560294996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9269496544916092, "Avg loss": 0.8012481227051467, "Avg value loss": 0.45534617523662746, "Avg policy loss": 0.3459019516594708, "Total num played games": 8104, "Total num trained steps": 15616, "Timestamp in ms": 1701560338445, "logtype": "training_step"}
{"Total num played games": 8104, "Total num trained steps": 15643, "Timestamp in ms": 1701560372112, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6796875}
{"Avg objective": 20.40625, "Games time in secs": 83.38600361533463, "Avg game time in secs": 3.0431393247417873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 8192, "Total num trained steps": 15656, "Timestamp in ms": 1701560378382, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9204684069285192, "Avg loss": 0.7617015046998858, "Avg value loss": 0.40591153921559453, "Avg policy loss": 0.3557899647857994, "Total num played games": 8198, "Total num trained steps": 15744, "Timestamp in ms": 1701560414523, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9360819712124908, "Avg loss": 0.6554566666018218, "Avg value loss": 0.333697036257945, "Avg policy loss": 0.32175963348709047, "Total num played games": 8198, "Total num trained steps": 15872, "Timestamp in ms": 1701560467126, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9286403085824493, "Avg loss": 0.8239835775457323, "Avg value loss": 0.47311869030818343, "Avg policy loss": 0.35086488584056497, "Total num played games": 8296, "Total num trained steps": 16000, "Timestamp in ms": 1701560519205, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 176.68908206932247, "Avg game time in secs": 2.6845496773603372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.56}, "Total num played games": 8320, "Total num trained steps": 16087, "Timestamp in ms": 1701560555072, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9218303145853193, "Avg loss": 0.7463336719665676, "Avg value loss": 0.4013190605910495, "Avg policy loss": 0.3450146069517359, "Total num played games": 8392, "Total num trained steps": 16128, "Timestamp in ms": 1701560571984, "logtype": "training_step"}
{"Total num played games": 8392, "Total num trained steps": 16246, "Timestamp in ms": 1701560642890, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.65234375}
{"Avg objective": 20.0546875, "Games time in secs": 91.68207594938576, "Avg game time in secs": 2.684682161125238, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 8448, "Total num trained steps": 16254, "Timestamp in ms": 1701560646754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9224219489120151, "Avg loss": 0.657434941502288, "Avg value loss": 0.31116669985931367, "Avg policy loss": 0.3462682378012687, "Total num played games": 8454, "Total num trained steps": 16256, "Timestamp in ms": 1701560647326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9307094037237804, "Avg loss": 0.842915490269661, "Avg value loss": 0.48131041729357094, "Avg policy loss": 0.3616050744894892, "Total num played games": 8486, "Total num trained steps": 16384, "Timestamp in ms": 1701560700490, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 90.92654834501445, "Avg game time in secs": 2.8262605808267836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 8576, "Total num trained steps": 16474, "Timestamp in ms": 1701560737681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9244755244755245, "Avg loss": 0.7166706251446158, "Avg value loss": 0.36392044136300683, "Avg policy loss": 0.3527501862263307, "Total num played games": 8580, "Total num trained steps": 16512, "Timestamp in ms": 1701560752454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9393939393939394, "Avg loss": 0.6347317127510905, "Avg value loss": 0.2710337816970423, "Avg policy loss": 0.36369793280027807, "Total num played games": 8580, "Total num trained steps": 16640, "Timestamp in ms": 1701560804832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9326878745965883, "Avg loss": 0.8066418296657503, "Avg value loss": 0.4629810769110918, "Avg policy loss": 0.34366075426805764, "Total num played games": 8676, "Total num trained steps": 16768, "Timestamp in ms": 1701560856881, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 150.5730560105294, "Avg game time in secs": 2.4988124668452656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.43}, "Total num played games": 8704, "Total num trained steps": 16845, "Timestamp in ms": 1701560888254, "logtype": "played_game"}
{"Total num played games": 8770, "Total num trained steps": 16850, "Timestamp in ms": 1701560911045, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.640625}
{"Avg objective": 20.421875, "Games time in secs": 26.780474895611405, "Avg game time in secs": 2.3465308920276584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 8832, "Total num trained steps": 16859, "Timestamp in ms": 1701560915034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9061371841155235, "Avg loss": 0.8667119359597564, "Avg value loss": 0.5266471381764859, "Avg policy loss": 0.34006479824893177, "Total num played games": 8864, "Total num trained steps": 16896, "Timestamp in ms": 1701560930737, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9205776173285198, "Avg loss": 0.711021717172116, "Avg value loss": 0.35176816838793457, "Avg policy loss": 0.35925355181097984, "Total num played games": 8864, "Total num trained steps": 17024, "Timestamp in ms": 1701560984331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9350180505415162, "Avg loss": 0.5862565254792571, "Avg value loss": 0.25095669738948345, "Avg policy loss": 0.3352998261107132, "Total num played games": 8864, "Total num trained steps": 17152, "Timestamp in ms": 1701561037229, "logtype": "training_step"}
{"Avg objective": 20.1875, "Games time in secs": 157.36927588284016, "Avg game time in secs": 2.985104033839889, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.67}, "Total num played games": 8960, "Total num trained steps": 17237, "Timestamp in ms": 1701561072404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9285714285714286, "Avg loss": 0.7305293087847531, "Avg value loss": 0.38678606506437063, "Avg policy loss": 0.34374323836527765, "Total num played games": 8960, "Total num trained steps": 17280, "Timestamp in ms": 1701561091751, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9428571428571428, "Avg loss": 0.6103471021633595, "Avg value loss": 0.2599786566570401, "Avg policy loss": 0.3503684481838718, "Total num played games": 8960, "Total num trained steps": 17408, "Timestamp in ms": 1701561146939, "logtype": "training_step"}
{"Total num played games": 9056, "Total num trained steps": 17454, "Timestamp in ms": 1701561186168, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6171875}
{"Avg objective": 20.7109375, "Games time in secs": 116.98603504523635, "Avg game time in secs": 2.1977373566041933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 9088, "Total num trained steps": 17460, "Timestamp in ms": 1701561189390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.916502732240437, "Avg loss": 1.0406154294032604, "Avg value loss": 0.6860516436863691, "Avg policy loss": 0.35456378757953644, "Total num played games": 9150, "Total num trained steps": 17536, "Timestamp in ms": 1701561220917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9304918032786886, "Avg loss": 0.6470627225935459, "Avg value loss": 0.3001078369561583, "Avg policy loss": 0.34695488843135536, "Total num played games": 9150, "Total num trained steps": 17664, "Timestamp in ms": 1701561273772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.944055944055944, "Avg loss": 0.6637656558305025, "Avg value loss": 0.31742674205452204, "Avg policy loss": 0.34633891098201275, "Total num played games": 9152, "Total num trained steps": 17792, "Timestamp in ms": 1701561325788, "logtype": "training_step"}
{"Avg objective": 19.6875, "Games time in secs": 138.86317410692573, "Avg game time in secs": 2.639744244806934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 9216, "Total num trained steps": 17798, "Timestamp in ms": 1701561328253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9377162629757785, "Avg loss": 0.8100722229573876, "Avg value loss": 0.4593786463374272, "Avg policy loss": 0.35069358348846436, "Total num played games": 9248, "Total num trained steps": 17920, "Timestamp in ms": 1701561378698, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9318133162063797, "Avg loss": 0.7291746120899916, "Avg value loss": 0.38723085122182965, "Avg policy loss": 0.34194376040250063, "Total num played games": 9342, "Total num trained steps": 18048, "Timestamp in ms": 1701561431064, "logtype": "training_step"}
{"Total num played games": 9342, "Total num trained steps": 18058, "Timestamp in ms": 1701561456580, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8359375}
{"Avg objective": 20.9609375, "Games time in secs": 130.0610631890595, "Avg game time in secs": 2.7461965417751344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 9344, "Total num trained steps": 18061, "Timestamp in ms": 1701561458314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9262399321746502, "Avg loss": 0.7910776599310338, "Avg value loss": 0.4404167312895879, "Avg policy loss": 0.35066092875786126, "Total num played games": 9436, "Total num trained steps": 18176, "Timestamp in ms": 1701561507517, "logtype": "training_step"}
{"Ratio train steps to played games": 1.939805002119542, "Avg loss": 0.700626322766766, "Avg value loss": 0.36911374528426677, "Avg policy loss": 0.33151257794816047, "Total num played games": 9436, "Total num trained steps": 18304, "Timestamp in ms": 1701561561285, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 127.88224610313773, "Avg game time in secs": 2.2826657764817355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 9472, "Total num trained steps": 18367, "Timestamp in ms": 1701561586197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.934102833158447, "Avg loss": 0.882918264484033, "Avg value loss": 0.5489442613907158, "Avg policy loss": 0.3339740000665188, "Total num played games": 9530, "Total num trained steps": 18432, "Timestamp in ms": 1701561613239, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 78.16956207714975, "Avg game time in secs": 2.46806345807272, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.5, "agent_stopped_0": 0.53}, "Total num played games": 9600, "Total num trained steps": 18557, "Timestamp in ms": 1701561664366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9305179945912212, "Avg loss": 0.687732209218666, "Avg value loss": 0.3531131346244365, "Avg policy loss": 0.3346190757583827, "Total num played games": 9614, "Total num trained steps": 18560, "Timestamp in ms": 1701561665302, "logtype": "training_step"}
{"Total num played games": 9626, "Total num trained steps": 18661, "Timestamp in ms": 1701561722980, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.76171875}
{"Ratio train steps to played games": 1.9226337448559672, "Avg loss": 0.8900113804265857, "Avg value loss": 0.539409123826772, "Avg policy loss": 0.35060225462075323, "Total num played games": 9720, "Total num trained steps": 18688, "Timestamp in ms": 1701561734574, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9358024691358025, "Avg loss": 0.7371302689425647, "Avg value loss": 0.3824723317520693, "Avg policy loss": 0.35465792985633016, "Total num played games": 9720, "Total num trained steps": 18816, "Timestamp in ms": 1701561788112, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 172.5495305042714, "Avg game time in secs": 2.6346259135752916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 9728, "Total num trained steps": 18932, "Timestamp in ms": 1701561836916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.930697105584998, "Avg loss": 0.7310936395078897, "Avg value loss": 0.40840890270192176, "Avg policy loss": 0.3226847336627543, "Total num played games": 9812, "Total num trained steps": 18944, "Timestamp in ms": 1701561841668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.943346240065213, "Avg loss": 0.7605685538146645, "Avg value loss": 0.4185815673554316, "Avg policy loss": 0.3419869880890474, "Total num played games": 9814, "Total num trained steps": 19072, "Timestamp in ms": 1701561895792, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 80.06935245729983, "Avg game time in secs": 2.3210064087907085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 9856, "Total num trained steps": 19123, "Timestamp in ms": 1701561916985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9378280177634235, "Avg loss": 0.7039474577177316, "Avg value loss": 0.3696827975800261, "Avg policy loss": 0.3342646610690281, "Total num played games": 9908, "Total num trained steps": 19200, "Timestamp in ms": 1701561949182, "logtype": "training_step"}
{"Total num played games": 9908, "Total num trained steps": 19261, "Timestamp in ms": 1701561991564, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.05078125}
{"Avg objective": 20.046875, "Games time in secs": 79.27186615951359, "Avg game time in secs": 2.599208767845994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 9984, "Total num trained steps": 19271, "Timestamp in ms": 1701561996257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9324135172965407, "Avg loss": 0.721410168800503, "Avg value loss": 0.3899789898423478, "Avg policy loss": 0.3314311803551391, "Total num played games": 10002, "Total num trained steps": 19328, "Timestamp in ms": 1701562020043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9452109578084382, "Avg loss": 0.6061796341091394, "Avg value loss": 0.2713970207842067, "Avg policy loss": 0.33478261320851743, "Total num played games": 10002, "Total num trained steps": 19456, "Timestamp in ms": 1701562071211, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9393939393939394, "Avg loss": 0.757098819129169, "Avg value loss": 0.4243947974173352, "Avg policy loss": 0.33270402217749506, "Total num played games": 10098, "Total num trained steps": 19584, "Timestamp in ms": 1701562125091, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 172.49610150791705, "Avg game time in secs": 2.3757043130899547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 10112, "Total num trained steps": 19690, "Timestamp in ms": 1701562168754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.934065934065934, "Avg loss": 0.6499964783433825, "Avg value loss": 0.3309883791953325, "Avg policy loss": 0.3190080941421911, "Total num played games": 10192, "Total num trained steps": 19712, "Timestamp in ms": 1701562177855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9462428879733176, "Avg loss": 0.689381325384602, "Avg value loss": 0.3536448326194659, "Avg policy loss": 0.33573649905156344, "Total num played games": 10194, "Total num trained steps": 19840, "Timestamp in ms": 1701562230962, "logtype": "training_step"}
{"Total num played games": 10194, "Total num trained steps": 19864, "Timestamp in ms": 1701562270173, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6796875}
{"Avg objective": 20.0, "Games time in secs": 105.08322141319513, "Avg game time in secs": 2.427368305856362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 10240, "Total num trained steps": 19871, "Timestamp in ms": 1701562273837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9409020217729394, "Avg loss": 0.7296081667300314, "Avg value loss": 0.39550341747235507, "Avg policy loss": 0.33410474518314004, "Total num played games": 10288, "Total num trained steps": 19968, "Timestamp in ms": 1701562315145, "logtype": "training_step"}
{"Avg objective": 19.4921875, "Games time in secs": 85.42085061594844, "Avg game time in secs": 2.5108146393467905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 10368, "Total num trained steps": 20077, "Timestamp in ms": 1701562359258, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9352850539291218, "Avg loss": 0.66986178397201, "Avg value loss": 0.3363971763756126, "Avg policy loss": 0.3334646043367684, "Total num played games": 10384, "Total num trained steps": 20096, "Timestamp in ms": 1701562367194, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9476117103235748, "Avg loss": 0.7153088427148759, "Avg value loss": 0.36614355409983546, "Avg policy loss": 0.34916528372559696, "Total num played games": 10384, "Total num trained steps": 20224, "Timestamp in ms": 1701562421983, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9419847328244275, "Avg loss": 0.7236032646615058, "Avg value loss": 0.37988588912412524, "Avg policy loss": 0.3437173736747354, "Total num played games": 10480, "Total num trained steps": 20352, "Timestamp in ms": 1701562475339, "logtype": "training_step"}
{"Avg objective": 20.0546875, "Games time in secs": 158.32716779783368, "Avg game time in secs": 2.5033596451830817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.57, "agent_stopped_0": 0.49}, "Total num played games": 10496, "Total num trained steps": 20453, "Timestamp in ms": 1701562517585, "logtype": "played_game"}
{"Total num played games": 10578, "Total num trained steps": 20466, "Timestamp in ms": 1701562543222, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5}
{"Avg objective": 20.78125, "Games time in secs": 29.093336990103126, "Avg game time in secs": 2.3893316136236535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 10624, "Total num trained steps": 20472, "Timestamp in ms": 1701562546679, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9194001874414246, "Avg loss": 0.6949281729757786, "Avg value loss": 0.3600210561417043, "Avg policy loss": 0.33490712265484035, "Total num played games": 10670, "Total num trained steps": 20480, "Timestamp in ms": 1701562549529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9310344827586208, "Avg loss": 0.8085261147934943, "Avg value loss": 0.4487028905423358, "Avg policy loss": 0.35982322157360613, "Total num played games": 10672, "Total num trained steps": 20608, "Timestamp in ms": 1701562602176, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9430284857571214, "Avg loss": 0.6118896435946226, "Avg value loss": 0.2582899712724611, "Avg policy loss": 0.3535996722057462, "Total num played games": 10672, "Total num trained steps": 20736, "Timestamp in ms": 1701562654162, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 152.08254957944155, "Avg game time in secs": 2.435250839611399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 10752, "Total num trained steps": 20843, "Timestamp in ms": 1701562698761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.937592867756315, "Avg loss": 0.675006473204121, "Avg value loss": 0.34600195405073464, "Avg policy loss": 0.3290045214816928, "Total num played games": 10768, "Total num trained steps": 20864, "Timestamp in ms": 1701562706833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.949479940564636, "Avg loss": 0.6458274568431079, "Avg value loss": 0.2942561930976808, "Avg policy loss": 0.3515712693333626, "Total num played games": 10768, "Total num trained steps": 20992, "Timestamp in ms": 1701562761343, "logtype": "training_step"}
{"Total num played games": 10864, "Total num trained steps": 21067, "Timestamp in ms": 1701562809755, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5}
{"Avg objective": 21.3046875, "Games time in secs": 113.26853444613516, "Avg game time in secs": 2.326524831398274, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 10880, "Total num trained steps": 21072, "Timestamp in ms": 1701562812030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9273590071180873, "Avg loss": 0.9510897647123784, "Avg value loss": 0.5870898531284183, "Avg policy loss": 0.363999915542081, "Total num played games": 10958, "Total num trained steps": 21120, "Timestamp in ms": 1701562831533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9390399707975907, "Avg loss": 0.6906947051174939, "Avg value loss": 0.3235210336279124, "Avg policy loss": 0.36717367183882743, "Total num played games": 10958, "Total num trained steps": 21248, "Timestamp in ms": 1701562884999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9507209344770944, "Avg loss": 0.6043002416845411, "Avg value loss": 0.23934597161132842, "Avg policy loss": 0.3649542765924707, "Total num played games": 10958, "Total num trained steps": 21376, "Timestamp in ms": 1701562938272, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 140.07540920749307, "Avg game time in secs": 2.255545551510295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 11008, "Total num trained steps": 21410, "Timestamp in ms": 1701562952105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.945359146010494, "Avg loss": 0.7319273168686777, "Avg value loss": 0.37969459232408553, "Avg policy loss": 0.35223272861912847, "Total num played games": 11054, "Total num trained steps": 21504, "Timestamp in ms": 1701562990520, "logtype": "training_step"}
{"Avg objective": 19.703125, "Games time in secs": 81.00483135320246, "Avg game time in secs": 2.453736969604506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 11136, "Total num trained steps": 21606, "Timestamp in ms": 1701563033110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9400896860986547, "Avg loss": 0.7293938905932009, "Avg value loss": 0.3792572529055178, "Avg policy loss": 0.3501366430427879, "Total num played games": 11150, "Total num trained steps": 21632, "Timestamp in ms": 1701563043293, "logtype": "training_step"}
{"Total num played games": 11150, "Total num trained steps": 21668, "Timestamp in ms": 1701563076269, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.64453125}
{"Ratio train steps to played games": 1.935254357879758, "Avg loss": 0.8306594807654619, "Avg value loss": 0.47654694109223783, "Avg policy loss": 0.3541125359479338, "Total num played games": 11244, "Total num trained steps": 21760, "Timestamp in ms": 1701563115072, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9466382070437567, "Avg loss": 0.6273372026626021, "Avg value loss": 0.2861999131273478, "Avg policy loss": 0.341137291979976, "Total num played games": 11244, "Total num trained steps": 21888, "Timestamp in ms": 1701563167745, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 172.01145032793283, "Avg game time in secs": 2.248130980748101, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 11264, "Total num trained steps": 21980, "Timestamp in ms": 1701563205122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9417886752513671, "Avg loss": 0.6910379496403039, "Avg value loss": 0.359242596430704, "Avg policy loss": 0.33179534994997084, "Total num played games": 11338, "Total num trained steps": 22016, "Timestamp in ms": 1701563219400, "logtype": "training_step"}
{"Ratio train steps to played games": 1.953078144293526, "Avg loss": 0.5977619444020092, "Avg value loss": 0.2668747036950663, "Avg policy loss": 0.33088723779655993, "Total num played games": 11338, "Total num trained steps": 22144, "Timestamp in ms": 1701563272862, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 78.8464426305145, "Avg game time in secs": 2.3162161949730944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 11392, "Total num trained steps": 22171, "Timestamp in ms": 1701563283969, "logtype": "played_game"}
{"Total num played games": 11434, "Total num trained steps": 22271, "Timestamp in ms": 1701563342608, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5234375}
{"Ratio train steps to played games": 1.9478747594892427, "Avg loss": 0.7223308384418488, "Avg value loss": 0.37928693532012403, "Avg policy loss": 0.3430439019575715, "Total num played games": 11434, "Total num trained steps": 22272, "Timestamp in ms": 1701563343313, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 63.52043945342302, "Avg game time in secs": 2.5926897964818636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.75}, "Total num played games": 11520, "Total num trained steps": 22283, "Timestamp in ms": 1701563347490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9430950728660652, "Avg loss": 0.7385185312014073, "Avg value loss": 0.3780909178312868, "Avg policy loss": 0.3604276163969189, "Total num played games": 11528, "Total num trained steps": 22400, "Timestamp in ms": 1701563396322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9541984732824427, "Avg loss": 0.5749344227369875, "Avg value loss": 0.23887647327501327, "Avg policy loss": 0.3360579467844218, "Total num played games": 11528, "Total num trained steps": 22528, "Timestamp in ms": 1701563448638, "logtype": "training_step"}
{"Ratio train steps to played games": 1.949406298399587, "Avg loss": 0.7047224554698914, "Avg value loss": 0.35286050161812454, "Avg policy loss": 0.351861949195154, "Total num played games": 11622, "Total num trained steps": 22656, "Timestamp in ms": 1701563501710, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 187.91235377267003, "Avg game time in secs": 2.2028648552077357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 11648, "Total num trained steps": 22738, "Timestamp in ms": 1701563535402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9446910208262205, "Avg loss": 0.7014770687092096, "Avg value loss": 0.35361031314823776, "Avg policy loss": 0.3478667566087097, "Total num played games": 11716, "Total num trained steps": 22784, "Timestamp in ms": 1701563554215, "logtype": "training_step"}
{"Total num played games": 11716, "Total num trained steps": 22871, "Timestamp in ms": 1701563609631, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.54296875}
{"Avg objective": 20.6328125, "Games time in secs": 77.63531357608736, "Avg game time in secs": 2.1742820368817775, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 11776, "Total num trained steps": 22877, "Timestamp in ms": 1701563613038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9400508044030482, "Avg loss": 0.722935723606497, "Avg value loss": 0.36916592135094106, "Avg policy loss": 0.3537697985302657, "Total num played games": 11810, "Total num trained steps": 22912, "Timestamp in ms": 1701563628389, "logtype": "training_step"}
{"Ratio train steps to played games": 1.950804403048264, "Avg loss": 0.5642946627922356, "Avg value loss": 0.22433313366491348, "Avg policy loss": 0.3399615284288302, "Total num played games": 11810, "Total num trained steps": 23040, "Timestamp in ms": 1701563682241, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 102.71430989541113, "Avg game time in secs": 2.6170650188578293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.72, "agent_stopped_0": 0.37}, "Total num played games": 11904, "Total num trained steps": 23122, "Timestamp in ms": 1701563715752, "logtype": "played_game"}
{"Ratio train steps to played games": 1.945582801477998, "Avg loss": 0.7091894359327853, "Avg value loss": 0.3694194401614368, "Avg policy loss": 0.3397700027562678, "Total num played games": 11908, "Total num trained steps": 23168, "Timestamp in ms": 1701563734949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9563318777292575, "Avg loss": 0.6096080280840397, "Avg value loss": 0.2706098227063194, "Avg policy loss": 0.33899820630904287, "Total num played games": 11908, "Total num trained steps": 23296, "Timestamp in ms": 1701563787979, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9516747208798533, "Avg loss": 0.8531071220058948, "Avg value loss": 0.5088970727520064, "Avg policy loss": 0.34421005425974727, "Total num played games": 12002, "Total num trained steps": 23424, "Timestamp in ms": 1701563841701, "logtype": "training_step"}
{"Total num played games": 12002, "Total num trained steps": 23474, "Timestamp in ms": 1701563883549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6171875}
{"Avg objective": 19.7578125, "Games time in secs": 170.85517895966768, "Avg game time in secs": 2.1083571796043543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 12032, "Total num trained steps": 23481, "Timestamp in ms": 1701563886607, "logtype": "played_game"}
{"Ratio train steps to played games": 1.947089947089947, "Avg loss": 0.7301784618757665, "Avg value loss": 0.38369080051779747, "Avg policy loss": 0.34648766345344484, "Total num played games": 12096, "Total num trained steps": 23552, "Timestamp in ms": 1701563917289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9576719576719577, "Avg loss": 0.6594469863921404, "Avg value loss": 0.31186301400884986, "Avg policy loss": 0.3475839742459357, "Total num played games": 12096, "Total num trained steps": 23680, "Timestamp in ms": 1701563971799, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 88.67259311676025, "Avg game time in secs": 2.420653715103981, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.7}, "Total num played games": 12160, "Total num trained steps": 23689, "Timestamp in ms": 1701563975280, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9530762920426579, "Avg loss": 0.7569657198619097, "Avg value loss": 0.3987343313638121, "Avg policy loss": 0.3582313871011138, "Total num played games": 12190, "Total num trained steps": 23808, "Timestamp in ms": 1701564025085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9485509605991533, "Avg loss": 0.7036959619726986, "Avg value loss": 0.34573826065752655, "Avg policy loss": 0.3579576963093132, "Total num played games": 12284, "Total num trained steps": 23936, "Timestamp in ms": 1701564077090, "logtype": "training_step"}
{"Avg objective": 20.2109375, "Games time in secs": 152.51942252740264, "Avg game time in secs": 2.594021920041996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.67, "agent_stopped_0": 0.41}, "Total num played games": 12288, "Total num trained steps": 24060, "Timestamp in ms": 1701564127800, "logtype": "played_game"}
{"Ratio train steps to played games": 1.949449125081011, "Avg loss": 0.5758950917515904, "Avg value loss": 0.2302940384251997, "Avg policy loss": 0.3456010513473302, "Total num played games": 12344, "Total num trained steps": 24064, "Timestamp in ms": 1701564129326, "logtype": "training_step"}
{"Total num played games": 12384, "Total num trained steps": 24076, "Timestamp in ms": 1701564153638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15625}
{"Avg objective": 20.171875, "Games time in secs": 28.866986406967044, "Avg game time in secs": 2.108904684209847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 12416, "Total num trained steps": 24081, "Timestamp in ms": 1701564156667, "logtype": "played_game"}
{"Ratio train steps to played games": 1.938772239140888, "Avg loss": 0.8322586412541568, "Avg value loss": 0.45818831864744425, "Avg policy loss": 0.37407032609917223, "Total num played games": 12478, "Total num trained steps": 24192, "Timestamp in ms": 1701564203122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9490302933162367, "Avg loss": 0.5674489366356283, "Avg value loss": 0.22460854542441666, "Avg policy loss": 0.3428403885336593, "Total num played games": 12478, "Total num trained steps": 24320, "Timestamp in ms": 1701564256395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9583466837552066, "Avg loss": 0.5448085379321128, "Avg value loss": 0.20354024367406964, "Avg policy loss": 0.34126829472370446, "Total num played games": 12484, "Total num trained steps": 24448, "Timestamp in ms": 1701564309694, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 154.7348624356091, "Avg game time in secs": 2.145230660433299, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 12544, "Total num trained steps": 24452, "Timestamp in ms": 1701564311402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9547406936048362, "Avg loss": 0.86406325455755, "Avg value loss": 0.487956594559364, "Avg policy loss": 0.37610666221007705, "Total num played games": 12572, "Total num trained steps": 24576, "Timestamp in ms": 1701564362590, "logtype": "training_step"}
{"Total num played games": 12666, "Total num trained steps": 24680, "Timestamp in ms": 1701564424759, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.35546875}
{"Avg objective": 19.8828125, "Games time in secs": 115.44141486659646, "Avg game time in secs": 2.511628648469923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 12672, "Total num trained steps": 24684, "Timestamp in ms": 1701564426843, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9360501567398118, "Avg loss": 0.9280395917594433, "Avg value loss": 0.5612390413880348, "Avg policy loss": 0.36680054664611816, "Total num played games": 12760, "Total num trained steps": 24704, "Timestamp in ms": 1701564434861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9460815047021944, "Avg loss": 0.7464205701835454, "Avg value loss": 0.35476671520154923, "Avg policy loss": 0.39165385626256466, "Total num played games": 12760, "Total num trained steps": 24832, "Timestamp in ms": 1701564487466, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9561128526645768, "Avg loss": 0.6132101470138878, "Avg value loss": 0.23577510577160865, "Avg policy loss": 0.3774350443854928, "Total num played games": 12760, "Total num trained steps": 24960, "Timestamp in ms": 1701564539690, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 135.28576209396124, "Avg game time in secs": 2.1299733890773496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 12800, "Total num trained steps": 25015, "Timestamp in ms": 1701564562129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9517659872413256, "Avg loss": 0.7173574147745967, "Avg value loss": 0.3583938166266307, "Avg policy loss": 0.35896359488833696, "Total num played games": 12854, "Total num trained steps": 25088, "Timestamp in ms": 1701564591362, "logtype": "training_step"}
{"Avg objective": 19.171875, "Games time in secs": 77.51513313315809, "Avg game time in secs": 2.428863522451138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 12928, "Total num trained steps": 25205, "Timestamp in ms": 1701564639644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9471814671814671, "Avg loss": 0.6103665044065565, "Avg value loss": 0.2587783383205533, "Avg policy loss": 0.35158816329203546, "Total num played games": 12950, "Total num trained steps": 25216, "Timestamp in ms": 1701564644029, "logtype": "training_step"}
{"Total num played games": 12950, "Total num trained steps": 25283, "Timestamp in ms": 1701564688096, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.58203125}
{"Ratio train steps to played games": 1.9429622815087397, "Avg loss": 0.8278043325990438, "Avg value loss": 0.46861842449288815, "Avg policy loss": 0.3591859054286033, "Total num played games": 13044, "Total num trained steps": 25344, "Timestamp in ms": 1701564715306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9527752223244403, "Avg loss": 0.5999750285409391, "Avg value loss": 0.2507867367239669, "Avg policy loss": 0.34918829263187945, "Total num played games": 13044, "Total num trained steps": 25472, "Timestamp in ms": 1701564768176, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 172.94272109121084, "Avg game time in secs": 2.2185691619524732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 13056, "Total num trained steps": 25580, "Timestamp in ms": 1701564812587, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9485462018572082, "Avg loss": 0.6202579634264112, "Avg value loss": 0.29227258975151926, "Avg policy loss": 0.32798537833150476, "Total num played games": 13138, "Total num trained steps": 25600, "Timestamp in ms": 1701564820041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.958288932866494, "Avg loss": 0.6993797095492482, "Avg value loss": 0.3587594946147874, "Avg policy loss": 0.34062021085992455, "Total num played games": 13138, "Total num trained steps": 25728, "Timestamp in ms": 1701564873063, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 77.26565095037222, "Avg game time in secs": 2.3004050783929415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 13184, "Total num trained steps": 25770, "Timestamp in ms": 1701564889853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9540507859733978, "Avg loss": 0.7450672383420169, "Avg value loss": 0.406153381569311, "Avg policy loss": 0.33891386061441153, "Total num played games": 13232, "Total num trained steps": 25856, "Timestamp in ms": 1701564924384, "logtype": "training_step"}
{"Total num played games": 13232, "Total num trained steps": 25884, "Timestamp in ms": 1701564971645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1171875}
{"Avg objective": 20.6015625, "Games time in secs": 86.72894524596632, "Avg game time in secs": 2.3332078249950428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 13312, "Total num trained steps": 25896, "Timestamp in ms": 1701564976582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.94987242983641, "Avg loss": 0.7326811777893454, "Avg value loss": 0.379943918553181, "Avg policy loss": 0.3527372543467209, "Total num played games": 13326, "Total num trained steps": 25984, "Timestamp in ms": 1701565012767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9594777127420082, "Avg loss": 0.5631879766006023, "Avg value loss": 0.2371379538672045, "Avg policy loss": 0.326050023897551, "Total num played games": 13326, "Total num trained steps": 26112, "Timestamp in ms": 1701565065080, "logtype": "training_step"}
{"Ratio train steps to played games": 1.955290611028316, "Avg loss": 0.7346676168963313, "Avg value loss": 0.4004914266988635, "Avg policy loss": 0.3341761894989759, "Total num played games": 13420, "Total num trained steps": 26240, "Timestamp in ms": 1701565117578, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 179.13950502686203, "Avg game time in secs": 2.2838184149586596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.54, "agent_stopped_0": 0.57}, "Total num played games": 13440, "Total num trained steps": 26332, "Timestamp in ms": 1701565155722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9514505624629959, "Avg loss": 0.7067541577853262, "Avg value loss": 0.3762599122710526, "Avg policy loss": 0.33049424726050347, "Total num played games": 13512, "Total num trained steps": 26368, "Timestamp in ms": 1701565169844, "logtype": "training_step"}
{"Total num played games": 13514, "Total num trained steps": 26487, "Timestamp in ms": 1701565236037, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.38671875}
{"Ratio train steps to played games": 1.953406074904158, "Avg loss": 0.6270919772796333, "Avg value loss": 0.28931803186424077, "Avg policy loss": 0.337773944134824, "Total num played games": 13564, "Total num trained steps": 26496, "Timestamp in ms": 1701565239985, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 84.53159209154546, "Avg game time in secs": 2.3893749133712845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.61}, "Total num played games": 13568, "Total num trained steps": 26496, "Timestamp in ms": 1701565240253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956496178718401, "Avg loss": 0.6650023749098182, "Avg value loss": 0.3287904402241111, "Avg policy loss": 0.33621193608269095, "Total num played games": 13608, "Total num trained steps": 26624, "Timestamp in ms": 1701565293582, "logtype": "training_step"}
{"Avg objective": 19.5, "Games time in secs": 90.75256335176528, "Avg game time in secs": 2.4337143465381814, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 13696, "Total num trained steps": 26714, "Timestamp in ms": 1701565331006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9521307647402217, "Avg loss": 0.6566822796594352, "Avg value loss": 0.3242150036385283, "Avg policy loss": 0.3324672777671367, "Total num played games": 13704, "Total num trained steps": 26752, "Timestamp in ms": 1701565346755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9614711033274956, "Avg loss": 0.5627035826910287, "Avg value loss": 0.23492455552332103, "Avg policy loss": 0.3277790267020464, "Total num played games": 13704, "Total num trained steps": 26880, "Timestamp in ms": 1701565399331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9573126540078272, "Avg loss": 0.6939740586094558, "Avg value loss": 0.3551752541679889, "Avg policy loss": 0.3387988059548661, "Total num played games": 13798, "Total num trained steps": 27008, "Timestamp in ms": 1701565450848, "logtype": "training_step"}
{"Avg objective": 19.9296875, "Games time in secs": 153.1155418753624, "Avg game time in secs": 2.184871461169678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 13824, "Total num trained steps": 27088, "Timestamp in ms": 1701565484122, "logtype": "played_game"}
{"Total num played games": 13892, "Total num trained steps": 27088, "Timestamp in ms": 1701565503272, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.328125}
{"Avg objective": 21.1953125, "Games time in secs": 22.979787999764085, "Avg game time in secs": 2.526197931234492, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.63, "agent_stopped_0": 0.42}, "Total num played games": 13952, "Total num trained steps": 27097, "Timestamp in ms": 1701565507102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9402259402259403, "Avg loss": 0.8090115888044238, "Avg value loss": 0.47024566563777626, "Avg policy loss": 0.3387659282889217, "Total num played games": 13986, "Total num trained steps": 27136, "Timestamp in ms": 1701565523199, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9493779493779493, "Avg loss": 0.627681816695258, "Avg value loss": 0.2827825821004808, "Avg policy loss": 0.3448992329649627, "Total num played games": 13986, "Total num trained steps": 27264, "Timestamp in ms": 1701565576084, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9585299585299585, "Avg loss": 0.5361289603170007, "Avg value loss": 0.21274114272091538, "Avg policy loss": 0.3233878188766539, "Total num played games": 13986, "Total num trained steps": 27392, "Timestamp in ms": 1701565629146, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 158.51959918998182, "Avg game time in secs": 2.552143255568808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 14080, "Total num trained steps": 27478, "Timestamp in ms": 1701565665623, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9545454545454546, "Avg loss": 0.6407406821381301, "Avg value loss": 0.31906575558241457, "Avg policy loss": 0.3216749286511913, "Total num played games": 14080, "Total num trained steps": 27520, "Timestamp in ms": 1701565683455, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9636363636363636, "Avg loss": 0.5663067041896284, "Avg value loss": 0.2334755671909079, "Avg policy loss": 0.3328311392106116, "Total num played games": 14080, "Total num trained steps": 27648, "Timestamp in ms": 1701565736372, "logtype": "training_step"}
{"Total num played games": 14174, "Total num trained steps": 27688, "Timestamp in ms": 1701565768803, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.80078125}
{"Avg objective": 21.03125, "Games time in secs": 106.2350152079016, "Avg game time in secs": 2.1721563043101924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.57}, "Total num played games": 14208, "Total num trained steps": 27694, "Timestamp in ms": 1701565771858, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9467339500981218, "Avg loss": 0.8015304617583752, "Avg value loss": 0.45196876220870763, "Avg policy loss": 0.3495616954751313, "Total num played games": 14268, "Total num trained steps": 27776, "Timestamp in ms": 1701565806919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9557050742921223, "Avg loss": 0.6141764100175351, "Avg value loss": 0.27667318540625274, "Avg policy loss": 0.33750322135165334, "Total num played games": 14268, "Total num trained steps": 27904, "Timestamp in ms": 1701565857995, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9564489112227805, "Avg loss": 0.5221206534188241, "Avg value loss": 0.1993764084763825, "Avg policy loss": 0.32274424377828836, "Total num played games": 14324, "Total num trained steps": 28032, "Timestamp in ms": 1701565911029, "logtype": "training_step"}
{"Avg objective": 20.6875, "Games time in secs": 139.56366604566574, "Avg game time in secs": 2.245616679385421, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 14336, "Total num trained steps": 28033, "Timestamp in ms": 1701565911422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9596381350034795, "Avg loss": 0.7055986323393881, "Avg value loss": 0.3600888270884752, "Avg policy loss": 0.3455098064150661, "Total num played games": 14370, "Total num trained steps": 28160, "Timestamp in ms": 1701565962173, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 83.51064050197601, "Avg game time in secs": 2.531788551568752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 14464, "Total num trained steps": 28240, "Timestamp in ms": 1701565994932, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9549412577747063, "Avg loss": 0.7247719520237297, "Avg value loss": 0.3736705022165552, "Avg policy loss": 0.3511014486430213, "Total num played games": 14470, "Total num trained steps": 28288, "Timestamp in ms": 1701566014193, "logtype": "training_step"}
{"Total num played games": 14470, "Total num trained steps": 28291, "Timestamp in ms": 1701566044733, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0859375}
{"Ratio train steps to played games": 1.9511123317769843, "Avg loss": 0.838037485955283, "Avg value loss": 0.46771169698331505, "Avg policy loss": 0.37032578559592366, "Total num played games": 14564, "Total num trained steps": 28416, "Timestamp in ms": 1701566097348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959901126064268, "Avg loss": 0.6104270529467613, "Avg value loss": 0.2602989412844181, "Avg policy loss": 0.3501281135249883, "Total num played games": 14564, "Total num trained steps": 28544, "Timestamp in ms": 1701566148944, "logtype": "training_step"}
{"Avg objective": 19.2421875, "Games time in secs": 186.2795536480844, "Avg game time in secs": 2.4598307405685773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 14592, "Total num trained steps": 28622, "Timestamp in ms": 1701566181212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9557298772169167, "Avg loss": 0.668067051563412, "Avg value loss": 0.3262530892388895, "Avg policy loss": 0.3418139601126313, "Total num played games": 14660, "Total num trained steps": 28672, "Timestamp in ms": 1701566201858, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645293315143246, "Avg loss": 0.6375770978629589, "Avg value loss": 0.2839906733715907, "Avg policy loss": 0.3535864281002432, "Total num played games": 14660, "Total num trained steps": 28800, "Timestamp in ms": 1701566254132, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 79.06773065961897, "Avg game time in secs": 2.3714908033871325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 14720, "Total num trained steps": 28814, "Timestamp in ms": 1701566260280, "logtype": "played_game"}
{"Total num played games": 14754, "Total num trained steps": 28892, "Timestamp in ms": 1701566314370, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.875}
{"Avg objective": 20.828125, "Games time in secs": 60.111127980053425, "Avg game time in secs": 2.4810245313565247, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.71}, "Total num played games": 14848, "Total num trained steps": 28905, "Timestamp in ms": 1701566320391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9482758620689655, "Avg loss": 0.8270026296377182, "Avg value loss": 0.47059258562512696, "Avg policy loss": 0.35641003609634936, "Total num played games": 14848, "Total num trained steps": 28928, "Timestamp in ms": 1701566329867, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9568292025862069, "Avg loss": 0.9084109656978399, "Avg value loss": 0.5470487569691613, "Avg policy loss": 0.36136220558546484, "Total num played games": 14848, "Total num trained steps": 29056, "Timestamp in ms": 1701566381780, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9655172413793103, "Avg loss": 0.9498664254788309, "Avg value loss": 0.5977809742325917, "Avg policy loss": 0.352085450431332, "Total num played games": 14848, "Total num trained steps": 29184, "Timestamp in ms": 1701566436691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.961718645428992, "Avg loss": 0.8637081864289939, "Avg value loss": 0.48997846560087055, "Avg policy loss": 0.3737297230400145, "Total num played games": 14942, "Total num trained steps": 29312, "Timestamp in ms": 1701566489098, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 195.33752855844796, "Avg game time in secs": 2.2694043279916514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 14976, "Total num trained steps": 29378, "Timestamp in ms": 1701566515729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9577071419071685, "Avg loss": 0.6467481234576553, "Avg value loss": 0.2899610681924969, "Avg policy loss": 0.3567870531696826, "Total num played games": 15038, "Total num trained steps": 29440, "Timestamp in ms": 1701566541659, "logtype": "training_step"}
{"Total num played games": 15038, "Total num trained steps": 29492, "Timestamp in ms": 1701566588944, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.98046875}
{"Avg objective": 21.28125, "Games time in secs": 77.3809113278985, "Avg game time in secs": 2.2391545280697756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 15104, "Total num trained steps": 29499, "Timestamp in ms": 1701566593110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9540047581284694, "Avg loss": 0.7564393579959869, "Avg value loss": 0.39332449750509113, "Avg policy loss": 0.36311485921032727, "Total num played games": 15132, "Total num trained steps": 29568, "Timestamp in ms": 1701566620833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9624636531853026, "Avg loss": 0.5744652398861945, "Avg value loss": 0.22298299078829587, "Avg policy loss": 0.3514822507277131, "Total num played games": 15132, "Total num trained steps": 29696, "Timestamp in ms": 1701566674208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9587547615920136, "Avg loss": 0.6878666516859084, "Avg value loss": 0.3414162858389318, "Avg policy loss": 0.3464503660798073, "Total num played games": 15226, "Total num trained steps": 29824, "Timestamp in ms": 1701566725822, "logtype": "training_step"}
{"Avg objective": 19.6953125, "Games time in secs": 181.0074209999293, "Avg game time in secs": 2.7560540562553797, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.74, "agent_stopped_0": 0.38}, "Total num played games": 15232, "Total num trained steps": 29944, "Timestamp in ms": 1701566774117, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9563030698889614, "Avg loss": 0.5908667736221105, "Avg value loss": 0.2485434715053998, "Avg policy loss": 0.34232329891528934, "Total num played games": 15310, "Total num trained steps": 29952, "Timestamp in ms": 1701566776884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9631901840490797, "Avg loss": 0.7201952496543527, "Avg value loss": 0.3678665637271479, "Avg policy loss": 0.352328690700233, "Total num played games": 15322, "Total num trained steps": 30080, "Timestamp in ms": 1701566828871, "logtype": "training_step"}
{"Total num played games": 15322, "Total num trained steps": 30096, "Timestamp in ms": 1701566857567, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15625}
{"Avg objective": 20.78125, "Games time in secs": 86.68458943814039, "Avg game time in secs": 2.1958010223024758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 15360, "Total num trained steps": 30103, "Timestamp in ms": 1701566860802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9595225739491438, "Avg loss": 0.7169908084906638, "Avg value loss": 0.35370466869790107, "Avg policy loss": 0.3632861371152103, "Total num played games": 15416, "Total num trained steps": 30208, "Timestamp in ms": 1701566903725, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 92.58442656509578, "Avg game time in secs": 2.423183824517764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 15488, "Total num trained steps": 30328, "Timestamp in ms": 1701566953386, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9556472408457968, "Avg loss": 0.5907410911750048, "Avg value loss": 0.24606778449378908, "Avg policy loss": 0.3446733094751835, "Total num played games": 15512, "Total num trained steps": 30336, "Timestamp in ms": 1701566956696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.963898916967509, "Avg loss": 0.7436529856640846, "Avg value loss": 0.37544947618152946, "Avg policy loss": 0.36820350238122046, "Total num played games": 15512, "Total num trained steps": 30464, "Timestamp in ms": 1701567009263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9600205023065096, "Avg loss": 0.8232599638868123, "Avg value loss": 0.4660206660628319, "Avg policy loss": 0.35723928979132324, "Total num played games": 15608, "Total num trained steps": 30592, "Timestamp in ms": 1701567060880, "logtype": "training_step"}
{"Total num played games": 15608, "Total num trained steps": 30696, "Timestamp in ms": 1701567122353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.19140625}
{"Avg objective": 21.0703125, "Games time in secs": 170.97942438535392, "Avg game time in secs": 2.4842215746612055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 15616, "Total num trained steps": 30699, "Timestamp in ms": 1701567124366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9564386702330914, "Avg loss": 0.6517352622468024, "Avg value loss": 0.2878041951917112, "Avg policy loss": 0.3639310635626316, "Total num played games": 15702, "Total num trained steps": 30720, "Timestamp in ms": 1701567132765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645904980257292, "Avg loss": 0.6641292821150273, "Avg value loss": 0.300554454093799, "Avg policy loss": 0.3635748296510428, "Total num played games": 15702, "Total num trained steps": 30848, "Timestamp in ms": 1701567185122, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 81.65980581194162, "Avg game time in secs": 2.097548099962296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.45}, "Total num played games": 15744, "Total num trained steps": 30899, "Timestamp in ms": 1701567206026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9600101240192356, "Avg loss": 0.6776576796546578, "Avg value loss": 0.32555177772883326, "Avg policy loss": 0.352105897734873, "Total num played games": 15804, "Total num trained steps": 30976, "Timestamp in ms": 1701567238844, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9621498864496594, "Avg loss": 0.5598486640956253, "Avg value loss": 0.2192063940456137, "Avg policy loss": 0.3406422716798261, "Total num played games": 15852, "Total num trained steps": 31104, "Timestamp in ms": 1701567291098, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 85.65137718431652, "Avg game time in secs": 2.355980838430696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 15872, "Total num trained steps": 31105, "Timestamp in ms": 1701567291677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9642138364779875, "Avg loss": 0.6560839738231152, "Avg value loss": 0.30616231134627014, "Avg policy loss": 0.3499216642230749, "Total num played games": 15900, "Total num trained steps": 31232, "Timestamp in ms": 1701567343441, "logtype": "training_step"}
{"Total num played games": 15994, "Total num trained steps": 31296, "Timestamp in ms": 1701567387808, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.890625}
{"Avg objective": 20.28125, "Games time in secs": 97.97132657282054, "Avg game time in secs": 2.688237319656764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.72, "agent_stopped_0": 0.4}, "Total num played games": 16000, "Total num trained steps": 31300, "Timestamp in ms": 1701567389649, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9492168075584286, "Avg loss": 0.7951603659894317, "Avg value loss": 0.4352444434771314, "Avg policy loss": 0.3599159219302237, "Total num played games": 16088, "Total num trained steps": 31360, "Timestamp in ms": 1701567415186, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9572352063649925, "Avg loss": 0.5864163360092789, "Avg value loss": 0.2328664194792509, "Avg policy loss": 0.35354991536587477, "Total num played games": 16088, "Total num trained steps": 31488, "Timestamp in ms": 1701567467800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965191447041273, "Avg loss": 0.5158288108650595, "Avg value loss": 0.18586099887033924, "Avg policy loss": 0.329967814264819, "Total num played games": 16088, "Total num trained steps": 31616, "Timestamp in ms": 1701567520623, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 153.61128682084382, "Avg game time in secs": 1.853020031878259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 16128, "Total num trained steps": 31670, "Timestamp in ms": 1701567543260, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9616858237547892, "Avg loss": 0.7400538937654346, "Avg value loss": 0.4038798906840384, "Avg policy loss": 0.33617400366347283, "Total num played games": 16182, "Total num trained steps": 31744, "Timestamp in ms": 1701567572557, "logtype": "training_step"}
{"Avg objective": 20.1953125, "Games time in secs": 77.14958168752491, "Avg game time in secs": 2.3466008016548585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 16256, "Total num trained steps": 31861, "Timestamp in ms": 1701567620414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9579800958348692, "Avg loss": 0.5984050245024264, "Avg value loss": 0.2738476190716028, "Avg policy loss": 0.32455740333534777, "Total num played games": 16278, "Total num trained steps": 31872, "Timestamp in ms": 1701567625267, "logtype": "training_step"}
{"Total num played games": 16278, "Total num trained steps": 31900, "Timestamp in ms": 1701567654818, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9296875}
{"Ratio train steps to played games": 1.9545565599804544, "Avg loss": 0.7479767047334462, "Avg value loss": 0.40809684817213565, "Avg policy loss": 0.33987984829582274, "Total num played games": 16372, "Total num trained steps": 32000, "Timestamp in ms": 1701567695540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9623747862203762, "Avg loss": 0.5664482046850026, "Avg value loss": 0.2426508233183995, "Avg policy loss": 0.32379738020244986, "Total num played games": 16372, "Total num trained steps": 32128, "Timestamp in ms": 1701567747487, "logtype": "training_step"}
{"Avg objective": 20.1796875, "Games time in secs": 171.75302090868354, "Avg game time in secs": 2.5128413336351514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 16384, "Total num trained steps": 32236, "Timestamp in ms": 1701567792167, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9589457063038989, "Avg loss": 0.5761327666696161, "Avg value loss": 0.2701977175893262, "Avg policy loss": 0.305935048032552, "Total num played games": 16466, "Total num trained steps": 32256, "Timestamp in ms": 1701567800250, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9667193003765335, "Avg loss": 0.6153812468983233, "Avg value loss": 0.29997793305665255, "Avg policy loss": 0.3154033136088401, "Total num played games": 16466, "Total num trained steps": 32384, "Timestamp in ms": 1701567852022, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 77.58943394757807, "Avg game time in secs": 2.2732929120975314, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 16512, "Total num trained steps": 32426, "Timestamp in ms": 1701567869756, "logtype": "played_game"}
{"Total num played games": 16560, "Total num trained steps": 32502, "Timestamp in ms": 1701567915591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.828125}
{"Avg objective": 20.484375, "Games time in secs": 50.427623024210334, "Avg game time in secs": 2.397739045016351, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.72, "agent_stopped_0": 0.38}, "Total num played games": 16640, "Total num trained steps": 32511, "Timestamp in ms": 1701567920184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9529072561268621, "Avg loss": 0.8008231653366238, "Avg value loss": 0.48500963917467743, "Avg policy loss": 0.3158135242993012, "Total num played games": 16648, "Total num trained steps": 32512, "Timestamp in ms": 1701567920607, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959829470397502, "Avg loss": 0.7133559356443584, "Avg value loss": 0.3759809492621571, "Avg policy loss": 0.3373749910388142, "Total num played games": 16654, "Total num trained steps": 32640, "Timestamp in ms": 1701567972542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9675753572715264, "Avg loss": 0.5244248190429062, "Avg value loss": 0.2143864700337872, "Avg policy loss": 0.31003834831062704, "Total num played games": 16654, "Total num trained steps": 32768, "Timestamp in ms": 1701568025799, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9641748268449963, "Avg loss": 0.7321462228428572, "Avg value loss": 0.4081619915086776, "Avg policy loss": 0.3239842317998409, "Total num played games": 16748, "Total num trained steps": 32896, "Timestamp in ms": 1701568078283, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 195.41720300354064, "Avg game time in secs": 2.443267677052063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.5, "agent_stopped_0": 0.6}, "Total num played games": 16768, "Total num trained steps": 32990, "Timestamp in ms": 1701568115601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9603466698326013, "Avg loss": 0.626450422918424, "Avg value loss": 0.3167372359894216, "Avg policy loss": 0.3097131825052202, "Total num played games": 16846, "Total num trained steps": 33024, "Timestamp in ms": 1701568129983, "logtype": "training_step"}
{"Total num played games": 16846, "Total num trained steps": 33102, "Timestamp in ms": 1701568180698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1015625}
{"Avg objective": 19.9921875, "Games time in secs": 68.66461016237736, "Avg game time in secs": 2.213791657384718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 16896, "Total num trained steps": 33110, "Timestamp in ms": 1701568184267, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9570247933884297, "Avg loss": 0.6822188976220787, "Avg value loss": 0.3576116389594972, "Avg policy loss": 0.32460726238787174, "Total num played games": 16940, "Total num trained steps": 33152, "Timestamp in ms": 1701568202648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645808736717827, "Avg loss": 0.6135356288868934, "Avg value loss": 0.29345920111518353, "Avg policy loss": 0.3200764307985082, "Total num played games": 16940, "Total num trained steps": 33280, "Timestamp in ms": 1701568255455, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 110.72351416386664, "Avg game time in secs": 2.475120069546392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 17024, "Total num trained steps": 33378, "Timestamp in ms": 1701568294990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9610237144869689, "Avg loss": 0.5994284255430102, "Avg value loss": 0.28758924250723794, "Avg policy loss": 0.31183918309397995, "Total num played games": 17036, "Total num trained steps": 33408, "Timestamp in ms": 1701568306626, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968537215308758, "Avg loss": 0.6882754953112453, "Avg value loss": 0.377081741229631, "Avg policy loss": 0.31119375152047724, "Total num played games": 17036, "Total num trained steps": 33536, "Timestamp in ms": 1701568358203, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9649778192855476, "Avg loss": 0.7417232382576913, "Avg value loss": 0.4191577743040398, "Avg policy loss": 0.3225654651178047, "Total num played games": 17132, "Total num trained steps": 33664, "Timestamp in ms": 1701568410481, "logtype": "training_step"}
{"Total num played games": 17132, "Total num trained steps": 33705, "Timestamp in ms": 1701568447536, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.01953125}
{"Avg objective": 20.859375, "Games time in secs": 155.33230904117227, "Avg game time in secs": 2.391337368710083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.56, "agent_stopped_0": 0.53}, "Total num played games": 17152, "Total num trained steps": 33711, "Timestamp in ms": 1701568450323, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9616277719725996, "Avg loss": 0.6647023069672287, "Avg value loss": 0.3460419693728909, "Avg policy loss": 0.31866033480037004, "Total num played games": 17226, "Total num trained steps": 33792, "Timestamp in ms": 1701568482712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9691164518750726, "Avg loss": 0.5323735144920647, "Avg value loss": 0.22527972020907328, "Avg policy loss": 0.30709379632025957, "Total num played games": 17226, "Total num trained steps": 33920, "Timestamp in ms": 1701568534946, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 96.12915617227554, "Avg game time in secs": 2.375808985772892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 17280, "Total num trained steps": 33947, "Timestamp in ms": 1701568546452, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9658198614318707, "Avg loss": 0.6726208885665983, "Avg value loss": 0.3486043974990025, "Avg policy loss": 0.32401649083476514, "Total num played games": 17320, "Total num trained steps": 34048, "Timestamp in ms": 1701568588444, "logtype": "training_step"}
{"Avg objective": 19.796875, "Games time in secs": 80.29758343286812, "Avg game time in secs": 2.598391159088351, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.72, "agent_stopped_0": 0.41}, "Total num played games": 17408, "Total num trained steps": 34141, "Timestamp in ms": 1701568626750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9625588606868036, "Avg loss": 0.6492924250196666, "Avg value loss": 0.3358343990985304, "Avg policy loss": 0.3134580245241523, "Total num played games": 17414, "Total num trained steps": 34176, "Timestamp in ms": 1701568641628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9698518433444354, "Avg loss": 0.5548174162395298, "Avg value loss": 0.24619061104021966, "Avg policy loss": 0.3086268031038344, "Total num played games": 17414, "Total num trained steps": 34304, "Timestamp in ms": 1701568693644, "logtype": "training_step"}
{"Total num played games": 17414, "Total num trained steps": 34305, "Timestamp in ms": 1701568712631, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8125}
{"Ratio train steps to played games": 1.9666438199680145, "Avg loss": 0.6731409803032875, "Avg value loss": 0.34810632350854576, "Avg policy loss": 0.3250346549320966, "Total num played games": 17508, "Total num trained steps": 34432, "Timestamp in ms": 1701568766743, "logtype": "training_step"}
{"Avg objective": 19.71875, "Games time in secs": 173.23215791210532, "Avg game time in secs": 2.19914561760379, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 17536, "Total num trained steps": 34510, "Timestamp in ms": 1701568799982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9631901840490797, "Avg loss": 0.6114366974215955, "Avg value loss": 0.3045441722497344, "Avg policy loss": 0.30689252098090947, "Total num played games": 17604, "Total num trained steps": 34560, "Timestamp in ms": 1701568820545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9704044535332879, "Avg loss": 0.5552181019447744, "Avg value loss": 0.24650754081085324, "Avg policy loss": 0.30871055962052196, "Total num played games": 17604, "Total num trained steps": 34688, "Timestamp in ms": 1701568872453, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 78.9315406344831, "Avg game time in secs": 2.622191722795833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 17664, "Total num trained steps": 34704, "Timestamp in ms": 1701568878913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9667834143034686, "Avg loss": 0.6642065171618015, "Avg value loss": 0.3439271659590304, "Avg policy loss": 0.32027935259975493, "Total num played games": 17702, "Total num trained steps": 34816, "Timestamp in ms": 1701568924367, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 80.6316535640508, "Avg game time in secs": 2.660279624411487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 17792, "Total num trained steps": 34904, "Timestamp in ms": 1701568959547, "logtype": "played_game"}
{"Total num played games": 17796, "Total num trained steps": 34905, "Timestamp in ms": 1701568973770, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.015625}
{"Ratio train steps to played games": 1.9532699832308553, "Avg loss": 0.6757306901272386, "Avg value loss": 0.3574989008484408, "Avg policy loss": 0.31823179381899536, "Total num played games": 17890, "Total num trained steps": 34944, "Timestamp in ms": 1701568989881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960424818334265, "Avg loss": 0.6165138657670468, "Avg value loss": 0.273587666451931, "Avg policy loss": 0.3429261960554868, "Total num played games": 17890, "Total num trained steps": 35072, "Timestamp in ms": 1701569043300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9675796534376746, "Avg loss": 0.5232023471035063, "Avg value loss": 0.2028495449339971, "Avg policy loss": 0.32035279914271086, "Total num played games": 17890, "Total num trained steps": 35200, "Timestamp in ms": 1701569095042, "logtype": "training_step"}
{"Avg objective": 19.859375, "Games time in secs": 166.2868747357279, "Avg game time in secs": 2.419730430308846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.62, "agent_stopped_0": 0.51}, "Total num played games": 17920, "Total num trained steps": 35274, "Timestamp in ms": 1701569125834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9641943734015346, "Avg loss": 0.6893567503429949, "Avg value loss": 0.3705990979797207, "Avg policy loss": 0.31875765533186495, "Total num played games": 17986, "Total num trained steps": 35328, "Timestamp in ms": 1701569147443, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971311019681975, "Avg loss": 0.6035359152592719, "Avg value loss": 0.2699033470125869, "Avg policy loss": 0.3336325720883906, "Total num played games": 17986, "Total num trained steps": 35456, "Timestamp in ms": 1701569200392, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 79.18726259469986, "Avg game time in secs": 2.5137441292608855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 18048, "Total num trained steps": 35467, "Timestamp in ms": 1701569205021, "logtype": "played_game"}
{"Total num played games": 18080, "Total num trained steps": 35507, "Timestamp in ms": 1701569241262, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.84375}
{"Ratio train steps to played games": 1.9579619236271597, "Avg loss": 0.799898813245818, "Avg value loss": 0.43822876969352365, "Avg policy loss": 0.36167004017625004, "Total num played games": 18174, "Total num trained steps": 35584, "Timestamp in ms": 1701569273905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9650049521294157, "Avg loss": 0.6396615656558424, "Avg value loss": 0.30321987823117524, "Avg policy loss": 0.33644168940372765, "Total num played games": 18174, "Total num trained steps": 35712, "Timestamp in ms": 1701569326717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971830985915493, "Avg loss": 0.6183940849732608, "Avg value loss": 0.29412431811215356, "Avg policy loss": 0.3242697640089318, "Total num played games": 18174, "Total num trained steps": 35840, "Timestamp in ms": 1701569379278, "logtype": "training_step"}
{"Avg objective": 19.5625, "Games time in secs": 174.25763696804643, "Avg game time in secs": 2.629362813779153, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.71}, "Total num played games": 18176, "Total num trained steps": 35840, "Timestamp in ms": 1701569379279, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9686918445539134, "Avg loss": 0.8187983313109726, "Avg value loss": 0.4778247835347429, "Avg policy loss": 0.34097354859113693, "Total num played games": 18270, "Total num trained steps": 35968, "Timestamp in ms": 1701569430474, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 78.31907200068235, "Avg game time in secs": 2.284976493450813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 18304, "Total num trained steps": 36035, "Timestamp in ms": 1701569457598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9653707938582163, "Avg loss": 0.686323937959969, "Avg value loss": 0.33466891665011644, "Avg policy loss": 0.35165502433665097, "Total num played games": 18366, "Total num trained steps": 36096, "Timestamp in ms": 1701569482155, "logtype": "training_step"}
{"Total num played games": 18366, "Total num trained steps": 36111, "Timestamp in ms": 1701569504394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.984375}
{"Avg objective": 21.515625, "Games time in secs": 50.88842209242284, "Avg game time in secs": 2.4190265129727777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 18432, "Total num trained steps": 36119, "Timestamp in ms": 1701569508487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.962296858071506, "Avg loss": 0.7391930038575083, "Avg value loss": 0.36443472874816507, "Avg policy loss": 0.3747582759242505, "Total num played games": 18460, "Total num trained steps": 36224, "Timestamp in ms": 1701569551507, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.5489870507735759, "Avg value loss": 0.19667346437927336, "Avg policy loss": 0.3523135844152421, "Total num played games": 18460, "Total num trained steps": 36352, "Timestamp in ms": 1701569604353, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966152851137221, "Avg loss": 0.6964845391921699, "Avg value loss": 0.33374324411852285, "Avg policy loss": 0.3627412971109152, "Total num played games": 18554, "Total num trained steps": 36480, "Timestamp in ms": 1701569657303, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 198.0151679534465, "Avg game time in secs": 2.746602223123773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.76, "agent_stopped_0": 0.35}, "Total num played games": 18560, "Total num trained steps": 36600, "Timestamp in ms": 1701569706502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9639484978540773, "Avg loss": 0.5715644976589829, "Avg value loss": 0.2249162526568398, "Avg policy loss": 0.34664825070649385, "Total num played games": 18640, "Total num trained steps": 36608, "Timestamp in ms": 1701569709266, "logtype": "training_step"}
{"Total num played games": 18650, "Total num trained steps": 36715, "Timestamp in ms": 1701569772870, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.65234375}
{"Avg objective": 20.625, "Games time in secs": 69.57801804505289, "Avg game time in secs": 2.176098058320349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 18688, "Total num trained steps": 36721, "Timestamp in ms": 1701569776080, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9598804950917628, "Avg loss": 0.7558281815145165, "Avg value loss": 0.3927097540581599, "Avg policy loss": 0.36311842524446547, "Total num played games": 18744, "Total num trained steps": 36736, "Timestamp in ms": 1701569782054, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966655996585574, "Avg loss": 0.645622284617275, "Avg value loss": 0.28063106164336205, "Avg policy loss": 0.3649912248365581, "Total num played games": 18744, "Total num trained steps": 36864, "Timestamp in ms": 1701569834187, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 108.17329006828368, "Avg game time in secs": 2.121802676250809, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 18816, "Total num trained steps": 36985, "Timestamp in ms": 1701569884253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96410746522247, "Avg loss": 0.5517518376000226, "Avg value loss": 0.20738982257898897, "Avg policy loss": 0.34436201583594084, "Total num played games": 18834, "Total num trained steps": 36992, "Timestamp in ms": 1701569887006, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9704851895105637, "Avg loss": 0.5920105297118425, "Avg value loss": 0.2430483049247414, "Avg policy loss": 0.34896222432143986, "Total num played games": 18838, "Total num trained steps": 37120, "Timestamp in ms": 1701569939359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967462497358969, "Avg loss": 0.6155646594706923, "Avg value loss": 0.27351807162631303, "Avg policy loss": 0.34204659063834697, "Total num played games": 18932, "Total num trained steps": 37248, "Timestamp in ms": 1701569991053, "logtype": "training_step"}
{"Total num played games": 18932, "Total num trained steps": 37319, "Timestamp in ms": 1701570036447, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8359375}
{"Avg objective": 19.5546875, "Games time in secs": 154.54944117367268, "Avg game time in secs": 2.695265428206767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.68, "agent_stopped_0": 0.42}, "Total num played games": 18944, "Total num trained steps": 37324, "Timestamp in ms": 1701570038803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9644696730789446, "Avg loss": 0.6574543316382915, "Avg value loss": 0.3079952350817621, "Avg policy loss": 0.349459097487852, "Total num played games": 19026, "Total num trained steps": 37376, "Timestamp in ms": 1701570060392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9711973089456534, "Avg loss": 0.5718558668158948, "Avg value loss": 0.23242696846136823, "Avg policy loss": 0.33942889666650444, "Total num played games": 19026, "Total num trained steps": 37504, "Timestamp in ms": 1701570113021, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 90.83079771324992, "Avg game time in secs": 2.3384842679661233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.6}, "Total num played games": 19072, "Total num trained steps": 37547, "Timestamp in ms": 1701570129634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679949796046439, "Avg loss": 0.6822349978610873, "Avg value loss": 0.33064076537266374, "Avg policy loss": 0.35159423714503646, "Total num played games": 19122, "Total num trained steps": 37632, "Timestamp in ms": 1701570164502, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 79.8795681912452, "Avg game time in secs": 2.3920438045461196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 19200, "Total num trained steps": 37744, "Timestamp in ms": 1701570209513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9650291423813488, "Avg loss": 0.6135790708940476, "Avg value loss": 0.269047660054639, "Avg policy loss": 0.3445314113050699, "Total num played games": 19216, "Total num trained steps": 37760, "Timestamp in ms": 1701570215915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9716902581182347, "Avg loss": 0.5872297540772706, "Avg value loss": 0.24283087445655838, "Avg policy loss": 0.3443988759536296, "Total num played games": 19216, "Total num trained steps": 37888, "Timestamp in ms": 1701570268033, "logtype": "training_step"}
{"Total num played games": 19310, "Total num trained steps": 37921, "Timestamp in ms": 1701570300063, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.78515625}
{"Avg objective": 20.0234375, "Games time in secs": 93.23619680292904, "Avg game time in secs": 2.4739857397944434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 19328, "Total num trained steps": 37926, "Timestamp in ms": 1701570302750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9591836734693877, "Avg loss": 0.772724837064743, "Avg value loss": 0.42025078216101974, "Avg policy loss": 0.3524740480352193, "Total num played games": 19404, "Total num trained steps": 38016, "Timestamp in ms": 1701570340416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9657802514945373, "Avg loss": 0.5520159562584013, "Avg value loss": 0.2189337558229454, "Avg policy loss": 0.33308220421895385, "Total num played games": 19404, "Total num trained steps": 38144, "Timestamp in ms": 1701570392291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9723768295196866, "Avg loss": 0.4926289434079081, "Avg value loss": 0.173010146652814, "Avg policy loss": 0.31961879367008805, "Total num played games": 19404, "Total num trained steps": 38272, "Timestamp in ms": 1701570444854, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 154.93074700795114, "Avg game time in secs": 2.491733779257629, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.65}, "Total num played games": 19456, "Total num trained steps": 38303, "Timestamp in ms": 1701570457681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9691794871794872, "Avg loss": 0.6665094429627061, "Avg value loss": 0.3348818566882983, "Avg policy loss": 0.33162759023252875, "Total num played games": 19500, "Total num trained steps": 38400, "Timestamp in ms": 1701570496889, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 79.76475751772523, "Avg game time in secs": 2.7484688026452204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.77, "agent_stopped_0": 0.37}, "Total num played games": 19584, "Total num trained steps": 38502, "Timestamp in ms": 1701570537446, "logtype": "played_game"}
{"Total num played games": 19594, "Total num trained steps": 38524, "Timestamp in ms": 1701570562256, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.80078125}
{"Ratio train steps to played games": 1.9659148892744158, "Avg loss": 0.7671727875713259, "Avg value loss": 0.43610999872907996, "Avg policy loss": 0.3310627880273387, "Total num played games": 19598, "Total num trained steps": 38528, "Timestamp in ms": 1701570564105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9633787078423406, "Avg loss": 0.7833586616907269, "Avg value loss": 0.41728230915032327, "Avg policy loss": 0.36607635277323425, "Total num played games": 19688, "Total num trained steps": 38656, "Timestamp in ms": 1701570617724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9699309223892727, "Avg loss": 0.528878744225949, "Avg value loss": 0.19595204503275454, "Avg policy loss": 0.3329267023364082, "Total num played games": 19688, "Total num trained steps": 38784, "Timestamp in ms": 1701570669095, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 165.7621257826686, "Avg game time in secs": 2.6694701246597106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.68, "agent_stopped_0": 0.43}, "Total num played games": 19712, "Total num trained steps": 38870, "Timestamp in ms": 1701570703209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666430809663398, "Avg loss": 0.6237344075925648, "Avg value loss": 0.2931181056192145, "Avg policy loss": 0.3306163006927818, "Total num played games": 19786, "Total num trained steps": 38912, "Timestamp in ms": 1701570720283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9731123016274132, "Avg loss": 0.5476434815209359, "Avg value loss": 0.2096723672002554, "Avg policy loss": 0.33797111082822084, "Total num played games": 19786, "Total num trained steps": 39040, "Timestamp in ms": 1701570772630, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 81.04797106422484, "Avg game time in secs": 2.4975064716563793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.64, "agent_stopped_0": 0.47}, "Total num played games": 19840, "Total num trained steps": 39069, "Timestamp in ms": 1701570784257, "logtype": "played_game"}
{"Total num played games": 19882, "Total num trained steps": 39127, "Timestamp in ms": 1701570824494, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5703125}
{"Avg objective": 20.5078125, "Games time in secs": 45.91158739104867, "Avg game time in secs": 2.881230217477423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.74, "agent_stopped_0": 0.39}, "Total num played games": 19968, "Total num trained steps": 39140, "Timestamp in ms": 1701570830169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960752903484181, "Avg loss": 0.742101342882961, "Avg value loss": 0.40633632871322334, "Avg policy loss": 0.3357650201069191, "Total num played games": 19976, "Total num trained steps": 39168, "Timestamp in ms": 1701570842240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9671605927112534, "Avg loss": 0.5611937658395618, "Avg value loss": 0.23039151192642748, "Avg policy loss": 0.3308022578712553, "Total num played games": 19976, "Total num trained steps": 39296, "Timestamp in ms": 1701570895988, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973568281938326, "Avg loss": 0.4811369723174721, "Avg value loss": 0.1709637886378914, "Avg policy loss": 0.31017318356316537, "Total num played games": 19976, "Total num trained steps": 39424, "Timestamp in ms": 1701570948228, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970309853541895, "Avg loss": 0.6952011606190354, "Avg value loss": 0.36072122992482036, "Avg policy loss": 0.3344799302285537, "Total num played games": 20074, "Total num trained steps": 39552, "Timestamp in ms": 1701571000349, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 206.38040256127715, "Avg game time in secs": 2.3280782429355895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 20096, "Total num trained steps": 39642, "Timestamp in ms": 1701571036550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9674732249107496, "Avg loss": 0.6094735432416201, "Avg value loss": 0.27898625715170056, "Avg policy loss": 0.3304872838780284, "Total num played games": 20168, "Total num trained steps": 39680, "Timestamp in ms": 1701571051376, "logtype": "training_step"}
{"Total num played games": 20168, "Total num trained steps": 39729, "Timestamp in ms": 1701571087363, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.86328125}
{"Avg objective": 19.515625, "Games time in secs": 54.91635769419372, "Avg game time in secs": 2.7957282909192145, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.72, "agent_stopped_0": 0.38}, "Total num played games": 20224, "Total num trained steps": 39738, "Timestamp in ms": 1701571091466, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964662915802981, "Avg loss": 0.7426760264206678, "Avg value loss": 0.39439181913621724, "Avg policy loss": 0.3482842077501118, "Total num played games": 20262, "Total num trained steps": 39808, "Timestamp in ms": 1701571120151, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9709801599052414, "Avg loss": 0.6795908554922789, "Avg value loss": 0.3413268765434623, "Avg policy loss": 0.3382639744086191, "Total num played games": 20262, "Total num trained steps": 39936, "Timestamp in ms": 1701571173860, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 120.15529017150402, "Avg game time in secs": 2.925733272539219, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.8, "agent_stopped_0": 0.34}, "Total num played games": 20352, "Total num trained steps": 40027, "Timestamp in ms": 1701571211621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679732783181059, "Avg loss": 0.7645944068208337, "Avg value loss": 0.4222420818405226, "Avg policy loss": 0.3423523267265409, "Total num played games": 20358, "Total num trained steps": 40064, "Timestamp in ms": 1701571226628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742607328814226, "Avg loss": 0.5905659445561469, "Avg value loss": 0.23644699167925864, "Avg policy loss": 0.35411895369179547, "Total num played games": 20358, "Total num trained steps": 40192, "Timestamp in ms": 1701571281093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712525667351128, "Avg loss": 0.6938545643351972, "Avg value loss": 0.34430299687664956, "Avg policy loss": 0.349551567574963, "Total num played games": 20454, "Total num trained steps": 40320, "Timestamp in ms": 1701571334067, "logtype": "training_step"}
{"Total num played games": 20454, "Total num trained steps": 40330, "Timestamp in ms": 1701571354342, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.12890625}
{"Avg objective": 19.6796875, "Games time in secs": 145.94420354999602, "Avg game time in secs": 2.570735841683927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 20480, "Total num trained steps": 40336, "Timestamp in ms": 1701571357566, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684640840957757, "Avg loss": 0.7277263321448117, "Avg value loss": 0.3818926482927054, "Avg policy loss": 0.34583368990570307, "Total num played games": 20548, "Total num trained steps": 40448, "Timestamp in ms": 1701571403220, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9746934008175978, "Avg loss": 0.5248957914300263, "Avg value loss": 0.20251147903036326, "Avg policy loss": 0.3223843122832477, "Total num played games": 20548, "Total num trained steps": 40576, "Timestamp in ms": 1701571455166, "logtype": "training_step"}
{"Avg objective": 19.7109375, "Games time in secs": 104.95504358410835, "Avg game time in secs": 2.7219978221546626, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.67}, "Total num played games": 20608, "Total num trained steps": 40593, "Timestamp in ms": 1701571462521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9719019474857087, "Avg loss": 0.6878248304128647, "Avg value loss": 0.35212920629419386, "Avg policy loss": 0.3356956234201789, "Total num played games": 20642, "Total num trained steps": 40704, "Timestamp in ms": 1701571507500, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 79.9731820076704, "Avg game time in secs": 3.061509180057328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.72, "agent_stopped_0": 0.4}, "Total num played games": 20736, "Total num trained steps": 40792, "Timestamp in ms": 1701571542494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9689458964220272, "Avg loss": 0.7242327639833093, "Avg value loss": 0.3890758169000037, "Avg policy loss": 0.3351569422520697, "Total num played games": 20738, "Total num trained steps": 40832, "Timestamp in ms": 1701571558330, "logtype": "training_step"}
{"Total num played games": 20738, "Total num trained steps": 40932, "Timestamp in ms": 1701571623274, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.79296875}
{"Ratio train steps to played games": 1.9663946231397023, "Avg loss": 0.7577098745387048, "Avg value loss": 0.4166849358007312, "Avg policy loss": 0.34102493175305426, "Total num played games": 20830, "Total num trained steps": 40960, "Timestamp in ms": 1701571636201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9723502304147464, "Avg loss": 0.6503421610686928, "Avg value loss": 0.28726456488948315, "Avg policy loss": 0.3630775958299637, "Total num played games": 20832, "Total num trained steps": 41088, "Timestamp in ms": 1701571688874, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 175.0753200855106, "Avg game time in secs": 2.6894301830761833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.69, "agent_stopped_0": 0.46}, "Total num played games": 20864, "Total num trained steps": 41159, "Timestamp in ms": 1701571717570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694189602446484, "Avg loss": 0.6809604482259601, "Avg value loss": 0.3333353706402704, "Avg policy loss": 0.347625071182847, "Total num played games": 20928, "Total num trained steps": 41216, "Timestamp in ms": 1701571741884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755351681957187, "Avg loss": 0.5631173648871481, "Avg value loss": 0.2109800044563599, "Avg policy loss": 0.35213735792785883, "Total num played games": 20928, "Total num trained steps": 41344, "Timestamp in ms": 1701571795485, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 81.12338674068451, "Avg game time in secs": 2.5005453420453705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 20992, "Total num trained steps": 41353, "Timestamp in ms": 1701571798693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726027397260273, "Avg loss": 0.6748692353721708, "Avg value loss": 0.3297526935348287, "Avg policy loss": 0.3451165466103703, "Total num played games": 21024, "Total num trained steps": 41472, "Timestamp in ms": 1701571846491, "logtype": "training_step"}
{"Total num played games": 21024, "Total num trained steps": 41534, "Timestamp in ms": 1701571891930, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.88671875}
{"Ratio train steps to played games": 1.9698835116961833, "Avg loss": 0.6394124338403344, "Avg value loss": 0.3035368293058127, "Avg policy loss": 0.3358756033703685, "Total num played games": 21118, "Total num trained steps": 41600, "Timestamp in ms": 1701571921235, "logtype": "training_step"}
{"Avg objective": 19.8359375, "Games time in secs": 174.1534618884325, "Avg game time in secs": 3.0635331435478292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.77, "agent_stopped_0": 0.36}, "Total num played games": 21120, "Total num trained steps": 41726, "Timestamp in ms": 1701571972847, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757575757575758, "Avg loss": 0.5391670714598149, "Avg value loss": 0.20619466569041833, "Avg policy loss": 0.3329724078066647, "Total num played games": 21120, "Total num trained steps": 41728, "Timestamp in ms": 1701571973497, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973036673894598, "Avg loss": 0.657690326217562, "Avg value loss": 0.31797491619363427, "Avg policy loss": 0.33971541258506477, "Total num played games": 21214, "Total num trained steps": 41856, "Timestamp in ms": 1701572026196, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 80.77463203296065, "Avg game time in secs": 2.372367361065699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 21248, "Total num trained steps": 41923, "Timestamp in ms": 1701572053621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701548568747067, "Avg loss": 0.6615584988612682, "Avg value loss": 0.3145689289085567, "Avg policy loss": 0.3469895690213889, "Total num played games": 21310, "Total num trained steps": 41984, "Timestamp in ms": 1701572078289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757905601951768, "Avg loss": 0.5417260099202394, "Avg value loss": 0.20110270159784704, "Avg policy loss": 0.34062330587767065, "Total num played games": 21314, "Total num trained steps": 42112, "Timestamp in ms": 1701572131132, "logtype": "training_step"}
{"Avg objective": 19.21875, "Games time in secs": 79.76412708126009, "Avg game time in secs": 2.6525815856439294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 21376, "Total num trained steps": 42117, "Timestamp in ms": 1701572133386, "logtype": "played_game"}
{"Total num played games": 21404, "Total num trained steps": 42136, "Timestamp in ms": 1701572162598, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.07421875}
{"Ratio train steps to played games": 1.964833938040748, "Avg loss": 0.7860364438965917, "Avg value loss": 0.41152722493279725, "Avg policy loss": 0.37450921814888716, "Total num played games": 21498, "Total num trained steps": 42240, "Timestamp in ms": 1701572207153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970787980277235, "Avg loss": 0.4906879775226116, "Avg value loss": 0.1497271368280053, "Avg policy loss": 0.34096083976328373, "Total num played games": 21498, "Total num trained steps": 42368, "Timestamp in ms": 1701572259355, "logtype": "training_step"}
{"Avg objective": 19.7734375, "Games time in secs": 175.16284725628793, "Avg game time in secs": 3.105322416187846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 21504, "Total num trained steps": 42488, "Timestamp in ms": 1701572308549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694132913152285, "Avg loss": 0.513030746486038, "Avg value loss": 0.18282197369262576, "Avg policy loss": 0.3302087753545493, "Total num played games": 21578, "Total num trained steps": 42496, "Timestamp in ms": 1701572311500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738816337871632, "Avg loss": 0.649581297300756, "Avg value loss": 0.2915700816665776, "Avg policy loss": 0.35801121941767633, "Total num played games": 21594, "Total num trained steps": 42624, "Timestamp in ms": 1701572364612, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 80.53735827282071, "Avg game time in secs": 2.5688058368687052, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 21632, "Total num trained steps": 42684, "Timestamp in ms": 1701572389086, "logtype": "played_game"}
{"Total num played games": 21690, "Total num trained steps": 42740, "Timestamp in ms": 1701572433621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.26171875}
{"Avg objective": 22.0078125, "Games time in secs": 49.33080026879907, "Avg game time in secs": 2.673439631398651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 21760, "Total num trained steps": 42749, "Timestamp in ms": 1701572438417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.963442638008634, "Avg loss": 0.8133221361786127, "Avg value loss": 0.45887485530693084, "Avg policy loss": 0.3544472847133875, "Total num played games": 21772, "Total num trained steps": 42752, "Timestamp in ms": 1701572439524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9684171869261844, "Avg loss": 0.7599675308447331, "Avg value loss": 0.39413174567744136, "Avg policy loss": 0.365835786331445, "Total num played games": 21784, "Total num trained steps": 42880, "Timestamp in ms": 1701572493792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974293059125964, "Avg loss": 0.5545845106244087, "Avg value loss": 0.21164738608058542, "Avg policy loss": 0.34293712524231523, "Total num played games": 21784, "Total num trained steps": 43008, "Timestamp in ms": 1701572547994, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9714808043875685, "Avg loss": 0.6320330565795302, "Avg value loss": 0.2948631674516946, "Avg policy loss": 0.33716988808009773, "Total num played games": 21880, "Total num trained steps": 43136, "Timestamp in ms": 1701572599902, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 210.16399833373725, "Avg game time in secs": 2.8615510129311588, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.71, "agent_stopped_0": 0.43}, "Total num played games": 21888, "Total num trained steps": 43253, "Timestamp in ms": 1701572648581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9695893653828644, "Avg loss": 0.5637367055751383, "Avg value loss": 0.23216922709252685, "Avg policy loss": 0.3315674763871357, "Total num played games": 21966, "Total num trained steps": 43264, "Timestamp in ms": 1701572652483, "logtype": "training_step"}
{"Total num played games": 21976, "Total num trained steps": 43344, "Timestamp in ms": 1701572703991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.109375}
{"Avg objective": 20.796875, "Games time in secs": 58.88828178681433, "Avg game time in secs": 2.508052947508986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 22016, "Total num trained steps": 43352, "Timestamp in ms": 1701572707470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9661078386950612, "Avg loss": 0.8228388517163694, "Avg value loss": 0.45730187196750194, "Avg policy loss": 0.3655369789339602, "Total num played games": 22070, "Total num trained steps": 43392, "Timestamp in ms": 1701572724158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9719075668328048, "Avg loss": 0.5697811050340533, "Avg value loss": 0.22249672858742997, "Avg policy loss": 0.3472843805793673, "Total num played games": 22070, "Total num trained steps": 43520, "Timestamp in ms": 1701572777172, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 117.22944398038089, "Avg game time in secs": 2.9246177597960923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.74}, "Total num played games": 22144, "Total num trained steps": 43639, "Timestamp in ms": 1701572824700, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9691419290805738, "Avg loss": 0.561416054610163, "Avg value loss": 0.22445672855246812, "Avg policy loss": 0.3369593257084489, "Total num played games": 22166, "Total num trained steps": 43648, "Timestamp in ms": 1701572828103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9749165388432735, "Avg loss": 0.6238074104767293, "Avg value loss": 0.2714801770634949, "Avg policy loss": 0.3523272315505892, "Total num played games": 22166, "Total num trained steps": 43776, "Timestamp in ms": 1701572879508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97214985176534, "Avg loss": 0.6955178757198155, "Avg value loss": 0.3454707768978551, "Avg policy loss": 0.350047102663666, "Total num played games": 22262, "Total num trained steps": 43904, "Timestamp in ms": 1701572931203, "logtype": "training_step"}
{"Total num played games": 22262, "Total num trained steps": 43946, "Timestamp in ms": 1701572968175, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.26171875}
{"Avg objective": 21.421875, "Games time in secs": 146.32575432397425, "Avg game time in secs": 3.005220172199188, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 22272, "Total num trained steps": 43952, "Timestamp in ms": 1701572971025, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969583109679728, "Avg loss": 0.6476123139727861, "Avg value loss": 0.29735556128434837, "Avg policy loss": 0.3502567565301433, "Total num played games": 22356, "Total num trained steps": 44032, "Timestamp in ms": 1701573004496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.48467927356250584, "Avg value loss": 0.15294981538318098, "Avg policy loss": 0.3317294605076313, "Total num played games": 22356, "Total num trained steps": 44160, "Timestamp in ms": 1701573055962, "logtype": "training_step"}
{"Avg objective": 20.2421875, "Games time in secs": 104.54878737591207, "Avg game time in secs": 2.47657438335591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 22400, "Total num trained steps": 44207, "Timestamp in ms": 1701573075574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9723879932306048, "Avg loss": 0.6349895808380097, "Avg value loss": 0.2868084315559827, "Avg policy loss": 0.34818114642985165, "Total num played games": 22454, "Total num trained steps": 44288, "Timestamp in ms": 1701573109143, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 80.6135089378804, "Avg game time in secs": 2.7775616766448366, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.67, "agent_stopped_0": 0.42}, "Total num played games": 22528, "Total num trained steps": 44407, "Timestamp in ms": 1701573156188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9698421145999645, "Avg loss": 0.5441958901938051, "Avg value loss": 0.2151706161093898, "Avg policy loss": 0.32902527844998986, "Total num played games": 22548, "Total num trained steps": 44416, "Timestamp in ms": 1701573159741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755188930282066, "Avg loss": 0.6095258854329586, "Avg value loss": 0.25778055912815034, "Avg policy loss": 0.3517453265376389, "Total num played games": 22548, "Total num trained steps": 44544, "Timestamp in ms": 1701573211616, "logtype": "training_step"}
{"Total num played games": 22548, "Total num trained steps": 44546, "Timestamp in ms": 1701573236390, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.30859375}
{"Ratio train steps to played games": 1.9729705856373112, "Avg loss": 0.7303385473787785, "Avg value loss": 0.3990672552608885, "Avg policy loss": 0.33127129229251295, "Total num played games": 22642, "Total num trained steps": 44672, "Timestamp in ms": 1701573287652, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 174.632667331025, "Avg game time in secs": 2.962747615587432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 22656, "Total num trained steps": 44777, "Timestamp in ms": 1701573330821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970270032544639, "Avg loss": 0.668573624221608, "Avg value loss": 0.349168139626272, "Avg policy loss": 0.31940547679550946, "Total num played games": 22738, "Total num trained steps": 44800, "Timestamp in ms": 1701573339838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758993754947665, "Avg loss": 0.5366959250532091, "Avg value loss": 0.21189626248087734, "Avg policy loss": 0.3247996625723317, "Total num played games": 22738, "Total num trained steps": 44928, "Timestamp in ms": 1701573391379, "logtype": "training_step"}
{"Avg objective": 19.65625, "Games time in secs": 78.48913347907364, "Avg game time in secs": 2.811851903781644, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.7}, "Total num played games": 22784, "Total num trained steps": 44974, "Timestamp in ms": 1701573409310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731978628361215, "Avg loss": 0.6004295165184885, "Avg value loss": 0.2792885440867394, "Avg policy loss": 0.3211409717332572, "Total num played games": 22834, "Total num trained steps": 45056, "Timestamp in ms": 1701573445782, "logtype": "training_step"}
{"Total num played games": 22834, "Total num trained steps": 45149, "Timestamp in ms": 1701573501823, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.88671875}
{"Avg objective": 19.7421875, "Games time in secs": 98.17195931822062, "Avg game time in secs": 3.1509692446124973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.84, "agent_stopped_0": 0.33}, "Total num played games": 22912, "Total num trained steps": 45162, "Timestamp in ms": 1701573507482, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706908583391487, "Avg loss": 0.5803880554158241, "Avg value loss": 0.2597384504042566, "Avg policy loss": 0.32064960384741426, "Total num played games": 22928, "Total num trained steps": 45184, "Timestamp in ms": 1701573517387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9762735519888346, "Avg loss": 0.5816320090088993, "Avg value loss": 0.24676247884053737, "Avg policy loss": 0.334869526559487, "Total num played games": 22928, "Total num trained steps": 45312, "Timestamp in ms": 1701573570946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9735927727588602, "Avg loss": 0.667048187693581, "Avg value loss": 0.32848533923970535, "Avg policy loss": 0.3385628464166075, "Total num played games": 23024, "Total num trained steps": 45440, "Timestamp in ms": 1701573622109, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 158.17145920358598, "Avg game time in secs": 3.2682935124466894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.77, "agent_stopped_0": 0.41}, "Total num played games": 23040, "Total num trained steps": 45543, "Timestamp in ms": 1701573665653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708910034602076, "Avg loss": 0.6602863571606576, "Avg value loss": 0.31897672824561596, "Avg policy loss": 0.3413096268195659, "Total num played games": 23120, "Total num trained steps": 45568, "Timestamp in ms": 1701573675803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764705882352942, "Avg loss": 0.6655654672067612, "Avg value loss": 0.32802968355827034, "Avg policy loss": 0.33753578178584576, "Total num played games": 23120, "Total num trained steps": 45696, "Timestamp in ms": 1701573729269, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 79.29735764674842, "Avg game time in secs": 2.8241365262510953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.68, "agent_stopped_0": 0.42}, "Total num played games": 23168, "Total num trained steps": 45736, "Timestamp in ms": 1701573744951, "logtype": "played_game"}
{"Total num played games": 23216, "Total num trained steps": 45750, "Timestamp in ms": 1701573772708, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1015625}
{"Avg objective": 20.4609375, "Games time in secs": 33.15404509939253, "Avg game time in secs": 2.9732163213193417, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.83, "agent_stopped_0": 0.38}, "Total num played games": 23296, "Total num trained steps": 45761, "Timestamp in ms": 1701573778105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9658515658515658, "Avg loss": 0.827949772356078, "Avg value loss": 0.46089400054188445, "Avg policy loss": 0.36705577024258673, "Total num played games": 23310, "Total num trained steps": 45824, "Timestamp in ms": 1701573803265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712998712998713, "Avg loss": 0.6153395685832947, "Avg value loss": 0.2530214856378734, "Avg policy loss": 0.362318083178252, "Total num played games": 23310, "Total num trained steps": 45952, "Timestamp in ms": 1701573855042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9768339768339769, "Avg loss": 0.5836915175896138, "Avg value loss": 0.23065547936130315, "Avg policy loss": 0.35303604090586305, "Total num played games": 23310, "Total num trained steps": 46080, "Timestamp in ms": 1701573907104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974025974025974, "Avg loss": 0.6449285268317908, "Avg value loss": 0.2946992428624071, "Avg policy loss": 0.35022928402759135, "Total num played games": 23408, "Total num trained steps": 46208, "Timestamp in ms": 1701573958911, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 221.77226594090462, "Avg game time in secs": 2.8508128953399137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 23424, "Total num trained steps": 46308, "Timestamp in ms": 1701573999877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9715768870734405, "Avg loss": 0.5931864229496568, "Avg value loss": 0.2561567446682602, "Avg policy loss": 0.3370296753710136, "Total num played games": 23502, "Total num trained steps": 46336, "Timestamp in ms": 1701574010643, "logtype": "training_step"}
{"Total num played games": 23502, "Total num trained steps": 46353, "Timestamp in ms": 1701574034846, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15625}
{"Avg objective": 21.5390625, "Games time in secs": 39.0768613871187, "Avg game time in secs": 2.5080231421015924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 23552, "Total num trained steps": 46362, "Timestamp in ms": 1701574038954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9691473131039159, "Avg loss": 0.7149272102396935, "Avg value loss": 0.3390212960075587, "Avg policy loss": 0.3759059119038284, "Total num played games": 23596, "Total num trained steps": 46464, "Timestamp in ms": 1701574080332, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9745719613493813, "Avg loss": 0.550093054305762, "Avg value loss": 0.20271094550844282, "Avg policy loss": 0.34738210949581116, "Total num played games": 23596, "Total num trained steps": 46592, "Timestamp in ms": 1701574134017, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 138.31799497455359, "Avg game time in secs": 3.2023770251107635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.75}, "Total num played games": 23680, "Total num trained steps": 46696, "Timestamp in ms": 1701574177273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9719736619956103, "Avg loss": 0.6986407542135566, "Avg value loss": 0.362708835338708, "Avg policy loss": 0.33593191555701196, "Total num played games": 23692, "Total num trained steps": 46720, "Timestamp in ms": 1701574186884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9773763295627216, "Avg loss": 0.5729752625338733, "Avg value loss": 0.2277234906796366, "Avg policy loss": 0.3452517647529021, "Total num played games": 23692, "Total num trained steps": 46848, "Timestamp in ms": 1701574238087, "logtype": "training_step"}
{"Total num played games": 23786, "Total num trained steps": 46958, "Timestamp in ms": 1701574300582, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0625}
{"Avg objective": 19.5078125, "Games time in secs": 126.79798259958625, "Avg game time in secs": 2.971793968041311, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.68}, "Total num played games": 23808, "Total num trained steps": 46965, "Timestamp in ms": 1701574304071, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9671691792294808, "Avg loss": 0.656068860553205, "Avg value loss": 0.3164733633166179, "Avg policy loss": 0.3395954999141395, "Total num played games": 23878, "Total num trained steps": 46976, "Timestamp in ms": 1701574308736, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9724874371859296, "Avg loss": 0.6170609055552632, "Avg value loss": 0.27360757399583235, "Avg policy loss": 0.34345333534292877, "Total num played games": 23880, "Total num trained steps": 47104, "Timestamp in ms": 1701574361298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977889447236181, "Avg loss": 0.49753417796455324, "Avg value loss": 0.172829651623033, "Avg policy loss": 0.32470452622510493, "Total num played games": 23880, "Total num trained steps": 47232, "Timestamp in ms": 1701574412778, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 119.50293705798686, "Avg game time in secs": 3.001831181507441, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.73, "agent_stopped_0": 0.41}, "Total num played games": 23936, "Total num trained steps": 47258, "Timestamp in ms": 1701574423574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.6210642668884248, "Avg value loss": 0.27798724931199104, "Avg policy loss": 0.34307701350189745, "Total num played games": 23976, "Total num trained steps": 47360, "Timestamp in ms": 1701574465232, "logtype": "training_step"}
{"Avg objective": 19.2109375, "Games time in secs": 79.91988775134087, "Avg game time in secs": 3.4067030040896498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.75, "agent_stopped_0": 0.36}, "Total num played games": 24064, "Total num trained steps": 47457, "Timestamp in ms": 1701574503494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727484214024593, "Avg loss": 0.5875261907931417, "Avg value loss": 0.25693104846868664, "Avg policy loss": 0.330595143022947, "Total num played games": 24072, "Total num trained steps": 47488, "Timestamp in ms": 1701574516149, "logtype": "training_step"}
{"Total num played games": 24072, "Total num trained steps": 47558, "Timestamp in ms": 1701574562740, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.08203125}
{"Ratio train steps to played games": 1.9703715964578332, "Avg loss": 0.6292648292146623, "Avg value loss": 0.2926405660691671, "Avg policy loss": 0.3366242707706988, "Total num played games": 24166, "Total num trained steps": 47616, "Timestamp in ms": 1701574587676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9756682942977737, "Avg loss": 0.5117388835642487, "Avg value loss": 0.19013343995902687, "Avg policy loss": 0.3216054420918226, "Total num played games": 24166, "Total num trained steps": 47744, "Timestamp in ms": 1701574641300, "logtype": "training_step"}
{"Avg objective": 19.6953125, "Games time in secs": 172.5721096303314, "Avg game time in secs": 2.5339616013516206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.5, "agent_stopped_0": 0.58}, "Total num played games": 24192, "Total num trained steps": 47828, "Timestamp in ms": 1701574676066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9734520570533431, "Avg loss": 0.6019166873302311, "Avg value loss": 0.2907967934734188, "Avg policy loss": 0.3111198904225603, "Total num played games": 24258, "Total num trained steps": 47872, "Timestamp in ms": 1701574693774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978565539983512, "Avg loss": 0.5635365524794906, "Avg value loss": 0.23100502690067515, "Avg policy loss": 0.33253152552060783, "Total num played games": 24260, "Total num trained steps": 48000, "Timestamp in ms": 1701574745052, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 76.67299677804112, "Avg game time in secs": 3.2773307121533435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.74}, "Total num played games": 24320, "Total num trained steps": 48020, "Timestamp in ms": 1701574752739, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9760223353588438, "Avg loss": 0.6490848558023572, "Avg value loss": 0.32101451663766056, "Avg policy loss": 0.32807033718563616, "Total num played games": 24356, "Total num trained steps": 48128, "Timestamp in ms": 1701574797608, "logtype": "training_step"}
{"Total num played games": 24356, "Total num trained steps": 48158, "Timestamp in ms": 1701574826258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.734375}
{"Avg objective": 20.796875, "Games time in secs": 80.26780506595969, "Avg game time in secs": 3.1742259942693636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.79, "agent_stopped_0": 0.31}, "Total num played games": 24448, "Total num trained steps": 48174, "Timestamp in ms": 1701574833007, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9736605316973415, "Avg loss": 0.7557477164082229, "Avg value loss": 0.42754740989767015, "Avg policy loss": 0.3282003061613068, "Total num played games": 24450, "Total num trained steps": 48256, "Timestamp in ms": 1701574867173, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788957055214724, "Avg loss": 0.4864964063744992, "Avg value loss": 0.1822898169630207, "Avg policy loss": 0.30420658900402486, "Total num played games": 24450, "Total num trained steps": 48384, "Timestamp in ms": 1701574920165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9763708954615824, "Avg loss": 0.7077735981438309, "Avg value loss": 0.3785622659488581, "Avg policy loss": 0.32921132689807564, "Total num played games": 24546, "Total num trained steps": 48512, "Timestamp in ms": 1701574972451, "logtype": "training_step"}
{"Avg objective": 20.4296875, "Games time in secs": 170.00406000763178, "Avg game time in secs": 2.7492885644896887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.6, "agent_stopped_0": 0.5}, "Total num played games": 24576, "Total num trained steps": 48587, "Timestamp in ms": 1701575003011, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9738657576495415, "Avg loss": 0.601117683807388, "Avg value loss": 0.28428935311967507, "Avg policy loss": 0.31682833132799715, "Total num played games": 24642, "Total num trained steps": 48640, "Timestamp in ms": 1701575024491, "logtype": "training_step"}
{"Total num played games": 24642, "Total num trained steps": 48762, "Timestamp in ms": 1701575094742, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.21875}
{"Ratio train steps to played games": 1.9785783836416748, "Avg loss": 0.5158928255550563, "Avg value loss": 0.20201278186868876, "Avg policy loss": 0.3138800434535369, "Total num played games": 24646, "Total num trained steps": 48768, "Timestamp in ms": 1701575097308, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 96.56923966296017, "Avg game time in secs": 2.830739331446239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 24704, "Total num trained steps": 48774, "Timestamp in ms": 1701575099581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767141009055627, "Avg loss": 0.648329691728577, "Avg value loss": 0.32300529873464257, "Avg policy loss": 0.3253243911312893, "Total num played games": 24736, "Total num trained steps": 48896, "Timestamp in ms": 1701575149505, "logtype": "training_step"}
{"Avg objective": 18.859375, "Games time in secs": 83.44898838549852, "Avg game time in secs": 3.201262621616479, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.77, "agent_stopped_0": 0.36}, "Total num played games": 24832, "Total num trained steps": 48977, "Timestamp in ms": 1701575183030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9740678102601272, "Avg loss": 0.6381836947984993, "Avg value loss": 0.3112882311688736, "Avg policy loss": 0.3268954590894282, "Total num played games": 24834, "Total num trained steps": 49024, "Timestamp in ms": 1701575202636, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792220343078037, "Avg loss": 0.529788423795253, "Avg value loss": 0.21838332572951913, "Avg policy loss": 0.3114050996955484, "Total num played games": 24834, "Total num trained steps": 49152, "Timestamp in ms": 1701575254584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767348576012835, "Avg loss": 0.6253836858086288, "Avg value loss": 0.30348156369291246, "Avg policy loss": 0.32190212118439376, "Total num played games": 24930, "Total num trained steps": 49280, "Timestamp in ms": 1701575307462, "logtype": "training_step"}
{"Avg objective": 20.34375, "Games time in secs": 154.91902874410152, "Avg game time in secs": 2.5577561008685734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 24960, "Total num trained steps": 49354, "Timestamp in ms": 1701575337949, "logtype": "played_game"}
{"Total num played games": 25024, "Total num trained steps": 49362, "Timestamp in ms": 1701575359002, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3671875}
{"Avg objective": 20.25, "Games time in secs": 26.05365593917668, "Avg game time in secs": 2.9845629154879134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.76, "agent_stopped_0": 0.36}, "Total num played games": 25088, "Total num trained steps": 49373, "Timestamp in ms": 1701575364003, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967035592005733, "Avg loss": 0.6807516424451023, "Avg value loss": 0.36408368014963344, "Avg policy loss": 0.31666796118952334, "Total num played games": 25118, "Total num trained steps": 49408, "Timestamp in ms": 1701575379158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9721315391352814, "Avg loss": 0.5777651548851281, "Avg value loss": 0.2526615038514137, "Avg policy loss": 0.3251036509172991, "Total num played games": 25118, "Total num trained steps": 49536, "Timestamp in ms": 1701575431263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97722748626483, "Avg loss": 0.47685725544579327, "Avg value loss": 0.1748513380298391, "Avg policy loss": 0.30200591846369207, "Total num played games": 25118, "Total num trained steps": 49664, "Timestamp in ms": 1701575482914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9747759181407154, "Avg loss": 0.579878679709509, "Avg value loss": 0.2588782829698175, "Avg policy loss": 0.32100040174555033, "Total num played games": 25214, "Total num trained steps": 49792, "Timestamp in ms": 1701575535753, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 223.11088537238538, "Avg game time in secs": 3.254171519074589, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.8, "agent_stopped_0": 0.33}, "Total num played games": 25216, "Total num trained steps": 49918, "Timestamp in ms": 1701575587114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9796557741116751, "Avg loss": 0.4802868498954922, "Avg value loss": 0.17189707065699622, "Avg policy loss": 0.3083897785982117, "Total num played games": 25216, "Total num trained steps": 49920, "Timestamp in ms": 1701575587597, "logtype": "training_step"}
{"Total num played games": 25312, "Total num trained steps": 49965, "Timestamp in ms": 1701575626702, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1171875}
{"Avg objective": 21.328125, "Games time in secs": 42.96226016059518, "Avg game time in secs": 2.474250142709934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 25344, "Total num trained steps": 49972, "Timestamp in ms": 1701575630076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9699283633787295, "Avg loss": 0.8240758385509253, "Avg value loss": 0.4806719636544585, "Avg policy loss": 0.34340387617703527, "Total num played games": 25406, "Total num trained steps": 50048, "Timestamp in ms": 1701575660100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9749665433362198, "Avg loss": 0.502028780290857, "Avg value loss": 0.18535697023617104, "Avg policy loss": 0.31667180825024843, "Total num played games": 25406, "Total num trained steps": 50176, "Timestamp in ms": 1701575712200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798488664987406, "Avg loss": 0.47122313431464136, "Avg value loss": 0.1623128786450252, "Avg policy loss": 0.3089102581143379, "Total num played games": 25408, "Total num trained steps": 50304, "Timestamp in ms": 1701575763041, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 135.06335363723338, "Avg game time in secs": 2.822399351571221, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.71}, "Total num played games": 25472, "Total num trained steps": 50309, "Timestamp in ms": 1701575765139, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775703866363423, "Avg loss": 0.6483332803472877, "Avg value loss": 0.3154684262117371, "Avg policy loss": 0.33286485471762717, "Total num played games": 25502, "Total num trained steps": 50432, "Timestamp in ms": 1701575814312, "logtype": "training_step"}
{"Avg objective": 19.703125, "Games time in secs": 82.33638413436711, "Avg game time in secs": 3.3313405090302695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.81, "agent_stopped_0": 0.32}, "Total num played games": 25600, "Total num trained steps": 50513, "Timestamp in ms": 1701575847476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975, "Avg loss": 0.6145963161252439, "Avg value loss": 0.28940528706880286, "Avg policy loss": 0.32519102981314063, "Total num played games": 25600, "Total num trained steps": 50560, "Timestamp in ms": 1701575866162, "logtype": "training_step"}
{"Total num played games": 25600, "Total num trained steps": 50568, "Timestamp in ms": 1701575887055, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.82421875}
{"Ratio train steps to played games": 1.9727562855141278, "Avg loss": 0.64901760709472, "Avg value loss": 0.3045185258379206, "Avg policy loss": 0.34449908416718245, "Total num played games": 25694, "Total num trained steps": 50688, "Timestamp in ms": 1701575937274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776990737137075, "Avg loss": 0.49755803938023746, "Avg value loss": 0.17268626962322742, "Avg policy loss": 0.32487177196890116, "Total num played games": 25694, "Total num trained steps": 50816, "Timestamp in ms": 1701575989381, "logtype": "training_step"}
{"Avg objective": 21.1328125, "Games time in secs": 169.25410647690296, "Avg game time in secs": 2.470456528084469, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 25728, "Total num trained steps": 50884, "Timestamp in ms": 1701576016730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753392787902289, "Avg loss": 0.64442129409872, "Avg value loss": 0.3193954128655605, "Avg policy loss": 0.3250258805928752, "Total num played games": 25790, "Total num trained steps": 50944, "Timestamp in ms": 1701576042261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980110111662531, "Avg loss": 0.49986255122348666, "Avg value loss": 0.1782186117488891, "Avg policy loss": 0.32164393994025886, "Total num played games": 25792, "Total num trained steps": 51072, "Timestamp in ms": 1701576093870, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 78.90104811266065, "Avg game time in secs": 2.5605340245965635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 25856, "Total num trained steps": 51077, "Timestamp in ms": 1701576095631, "logtype": "played_game"}
{"Total num played games": 25888, "Total num trained steps": 51171, "Timestamp in ms": 1701576151349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8671875}
{"Ratio train steps to played games": 1.9705950273266106, "Avg loss": 0.7396011829841882, "Avg value loss": 0.3993192402413115, "Avg policy loss": 0.3402819449547678, "Total num played games": 25982, "Total num trained steps": 51200, "Timestamp in ms": 1701576163511, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755215148949272, "Avg loss": 0.5534166097640991, "Avg value loss": 0.22724038467276841, "Avg policy loss": 0.32617622590623796, "Total num played games": 25982, "Total num trained steps": 51328, "Timestamp in ms": 1701576215823, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980295566502463, "Avg loss": 0.4793617823161185, "Avg value loss": 0.16602865437744185, "Avg policy loss": 0.3133331259014085, "Total num played games": 25982, "Total num trained steps": 51456, "Timestamp in ms": 1701576268186, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 172.55529296398163, "Avg game time in secs": 2.695567198446952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.73}, "Total num played games": 25984, "Total num trained steps": 51456, "Timestamp in ms": 1701576268187, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780658025922233, "Avg loss": 0.6017264586407691, "Avg value loss": 0.28000404115300626, "Avg policy loss": 0.32172241783700883, "Total num played games": 26078, "Total num trained steps": 51584, "Timestamp in ms": 1701576319839, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 79.0352327786386, "Avg game time in secs": 2.4339300504361745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 26112, "Total num trained steps": 51651, "Timestamp in ms": 1701576347222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755119193154034, "Avg loss": 0.6074519392568618, "Avg value loss": 0.2965703153749928, "Avg policy loss": 0.3108816232997924, "Total num played games": 26176, "Total num trained steps": 51712, "Timestamp in ms": 1701576371537, "logtype": "training_step"}
{"Total num played games": 26176, "Total num trained steps": 51774, "Timestamp in ms": 1701576418263, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.578125}
{"Avg objective": 20.3359375, "Games time in secs": 75.2428884729743, "Avg game time in secs": 2.6027733669470763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 26240, "Total num trained steps": 51782, "Timestamp in ms": 1701576422465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9733536353254664, "Avg loss": 0.6070262216962874, "Avg value loss": 0.2874059763853438, "Avg policy loss": 0.3196202488616109, "Total num played games": 26270, "Total num trained steps": 51840, "Timestamp in ms": 1701576445871, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978226113437381, "Avg loss": 0.45705287135206163, "Avg value loss": 0.15697121631819755, "Avg policy loss": 0.30008165386971086, "Total num played games": 26270, "Total num trained steps": 51968, "Timestamp in ms": 1701576497803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758780247288175, "Avg loss": 0.553973616566509, "Avg value loss": 0.249716785736382, "Avg policy loss": 0.3042568298988044, "Total num played games": 26366, "Total num trained steps": 52096, "Timestamp in ms": 1701576548785, "logtype": "training_step"}
{"Avg objective": 19.5078125, "Games time in secs": 177.40103727951646, "Avg game time in secs": 3.143634187639691, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.75, "agent_stopped_0": 0.38}, "Total num played games": 26368, "Total num trained steps": 52223, "Timestamp in ms": 1701576599867, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9804323094425484, "Avg loss": 0.47130942437797785, "Avg value loss": 0.1724916304810904, "Avg policy loss": 0.29881779477000237, "Total num played games": 26370, "Total num trained steps": 52224, "Timestamp in ms": 1701576600270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785336356764929, "Avg loss": 0.57527347933501, "Avg value loss": 0.25428995705442503, "Avg policy loss": 0.3209835198940709, "Total num played games": 26460, "Total num trained steps": 52352, "Timestamp in ms": 1701576652377, "logtype": "training_step"}
{"Total num played games": 26460, "Total num trained steps": 52378, "Timestamp in ms": 1701576681449, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.62109375}
{"Avg objective": 20.046875, "Games time in secs": 84.83678492717445, "Avg game time in secs": 2.555246676056413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 26496, "Total num trained steps": 52384, "Timestamp in ms": 1701576684703, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9763500790841304, "Avg loss": 0.5681425391230732, "Avg value loss": 0.24584172933828086, "Avg policy loss": 0.3223008115310222, "Total num played games": 26554, "Total num trained steps": 52480, "Timestamp in ms": 1701576724193, "logtype": "training_step"}
{"Avg objective": 20.09375, "Games time in secs": 89.68827967345715, "Avg game time in secs": 2.498860982232145, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.69}, "Total num played games": 26624, "Total num trained steps": 52606, "Timestamp in ms": 1701576774392, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755163349605709, "Avg loss": 0.48957790434360504, "Avg value loss": 0.17971756192855537, "Avg policy loss": 0.30986034392844886, "Total num played games": 26630, "Total num trained steps": 52608, "Timestamp in ms": 1701576774993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788367729831144, "Avg loss": 0.5847965280991048, "Avg value loss": 0.25962045922642574, "Avg policy loss": 0.32517606718465686, "Total num played games": 26650, "Total num trained steps": 52736, "Timestamp in ms": 1701576827522, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764824646676138, "Avg loss": 0.5693693347275257, "Avg value loss": 0.2388414983288385, "Avg policy loss": 0.33052783843595535, "Total num played games": 26746, "Total num trained steps": 52864, "Timestamp in ms": 1701576878423, "logtype": "training_step"}
{"Total num played games": 26746, "Total num trained steps": 52980, "Timestamp in ms": 1701576944379, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.98828125}
{"Avg objective": 20.359375, "Games time in secs": 171.78661438822746, "Avg game time in secs": 3.0721900608041324, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.77}, "Total num played games": 26752, "Total num trained steps": 52982, "Timestamp in ms": 1701576946179, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9751024972046216, "Avg loss": 0.4717195047996938, "Avg value loss": 0.15191126201534644, "Avg policy loss": 0.31980824400670826, "Total num played games": 26830, "Total num trained steps": 52992, "Timestamp in ms": 1701576950297, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791356184798807, "Avg loss": 0.5695978268049657, "Avg value loss": 0.2446806826046668, "Avg policy loss": 0.32491714460775256, "Total num played games": 26840, "Total num trained steps": 53120, "Timestamp in ms": 1701577001818, "logtype": "training_step"}
{"Avg objective": 20.2578125, "Games time in secs": 78.1930960342288, "Avg game time in secs": 2.3953752323432127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 26880, "Total num trained steps": 53176, "Timestamp in ms": 1701577024372, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768339768339769, "Avg loss": 0.5904285018332303, "Avg value loss": 0.2657401961623691, "Avg policy loss": 0.32468830805737525, "Total num played games": 26936, "Total num trained steps": 53248, "Timestamp in ms": 1701577051786, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 78.0356016587466, "Avg game time in secs": 2.96064369600208, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.78}, "Total num played games": 27008, "Total num trained steps": 53371, "Timestamp in ms": 1701577102408, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974840905727394, "Avg loss": 0.5216163136065006, "Avg value loss": 0.19726309174438938, "Avg policy loss": 0.32435321749653667, "Total num played games": 27028, "Total num trained steps": 53376, "Timestamp in ms": 1701577104431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792468185853802, "Avg loss": 0.5991296730935574, "Avg value loss": 0.2643845349084586, "Avg policy loss": 0.3347451443551108, "Total num played games": 27032, "Total num trained steps": 53504, "Timestamp in ms": 1701577155821, "logtype": "training_step"}
{"Total num played games": 27128, "Total num trained steps": 53582, "Timestamp in ms": 1701577203904, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.81640625}
{"Avg objective": 20.859375, "Games time in secs": 103.81938188709319, "Avg game time in secs": 2.775689261208754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.64, "agent_stopped_0": 0.44}, "Total num played games": 27136, "Total num trained steps": 53587, "Timestamp in ms": 1701577206227, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9701711850708985, "Avg loss": 0.775693308794871, "Avg value loss": 0.4305717790266499, "Avg policy loss": 0.3451215277891606, "Total num played games": 27222, "Total num trained steps": 53632, "Timestamp in ms": 1701577224095, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97483652927779, "Avg loss": 0.5765180899761617, "Avg value loss": 0.22941094916313887, "Avg policy loss": 0.34710713755339384, "Total num played games": 27222, "Total num trained steps": 53760, "Timestamp in ms": 1701577276789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795753434721917, "Avg loss": 0.4890841559972614, "Avg value loss": 0.16134966036770493, "Avg policy loss": 0.3277344958623871, "Total num played games": 27222, "Total num trained steps": 53888, "Timestamp in ms": 1701577329490, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 144.12294373475015, "Avg game time in secs": 2.510928599629551, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 27264, "Total num trained steps": 53940, "Timestamp in ms": 1701577350350, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773043414598432, "Avg loss": 0.5910213936585933, "Avg value loss": 0.26038669020636007, "Avg policy loss": 0.33063470432534814, "Total num played games": 27318, "Total num trained steps": 54016, "Timestamp in ms": 1701577381724, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 79.72382206656039, "Avg game time in secs": 2.8939371967571788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 27392, "Total num trained steps": 54134, "Timestamp in ms": 1701577430075, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750492449113592, "Avg loss": 0.5381677374243736, "Avg value loss": 0.22931814787443727, "Avg policy loss": 0.3088495887350291, "Total num played games": 27414, "Total num trained steps": 54144, "Timestamp in ms": 1701577434212, "logtype": "training_step"}
{"Total num played games": 27414, "Total num trained steps": 54183, "Timestamp in ms": 1701577467445, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3515625}
{"Ratio train steps to played games": 1.9729533226697689, "Avg loss": 0.6616187654435635, "Avg value loss": 0.33030595630407333, "Avg policy loss": 0.33131280774250627, "Total num played games": 27508, "Total num trained steps": 54272, "Timestamp in ms": 1701577505267, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776065144685182, "Avg loss": 0.4980432658921927, "Avg value loss": 0.18527631007600576, "Avg policy loss": 0.31276695511769503, "Total num played games": 27508, "Total num trained steps": 54400, "Timestamp in ms": 1701577558046, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 170.34464689344168, "Avg game time in secs": 2.7289995149330935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 27520, "Total num trained steps": 54508, "Timestamp in ms": 1701577600420, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755090210854287, "Avg loss": 0.4919749724213034, "Avg value loss": 0.19604858115781099, "Avg policy loss": 0.29592638765461743, "Total num played games": 27602, "Total num trained steps": 54528, "Timestamp in ms": 1701577608512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801463662053473, "Avg loss": 0.5309237230103463, "Avg value loss": 0.21960068121552467, "Avg policy loss": 0.3113230431918055, "Total num played games": 27602, "Total num trained steps": 54656, "Timestamp in ms": 1701577659074, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 76.56225267611444, "Avg game time in secs": 2.1770755353791174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.39}, "Total num played games": 27648, "Total num trained steps": 54699, "Timestamp in ms": 1701577676982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779045418441765, "Avg loss": 0.5485526288393885, "Avg value loss": 0.2551904490101151, "Avg policy loss": 0.2933621749980375, "Total num played games": 27698, "Total num trained steps": 54784, "Timestamp in ms": 1701577711324, "logtype": "training_step"}
{"Total num played games": 27698, "Total num trained steps": 54786, "Timestamp in ms": 1701577730534, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.76953125}
{"Avg objective": 19.9921875, "Games time in secs": 58.53716993518174, "Avg game time in secs": 2.6115130640391726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 27776, "Total num trained steps": 54796, "Timestamp in ms": 1701577735519, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757843983880252, "Avg loss": 0.5916941268369555, "Avg value loss": 0.27399220096413046, "Avg policy loss": 0.3177019226131961, "Total num played games": 27792, "Total num trained steps": 54912, "Timestamp in ms": 1701577783502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980426021876799, "Avg loss": 0.4437852306291461, "Avg value loss": 0.15639510611072183, "Avg policy loss": 0.287390124052763, "Total num played games": 27792, "Total num trained steps": 55040, "Timestamp in ms": 1701577835971, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9781985083189904, "Avg loss": 0.5658936079125851, "Avg value loss": 0.2745806546881795, "Avg policy loss": 0.29131295334082097, "Total num played games": 27888, "Total num trained steps": 55168, "Timestamp in ms": 1701577887999, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 194.89334849268198, "Avg game time in secs": 2.644389014560147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 27904, "Total num trained steps": 55270, "Timestamp in ms": 1701577930413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758093332380475, "Avg loss": 0.5399375546257943, "Avg value loss": 0.25481629912974313, "Avg policy loss": 0.28512125567067415, "Total num played games": 27986, "Total num trained steps": 55296, "Timestamp in ms": 1701577941418, "logtype": "training_step"}
{"Total num played games": 27986, "Total num trained steps": 55387, "Timestamp in ms": 1701577993175, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.76171875}
{"Avg objective": 20.7734375, "Games time in secs": 66.71017847582698, "Avg game time in secs": 2.5661622797924792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.7}, "Total num played games": 28032, "Total num trained steps": 55395, "Timestamp in ms": 1701577997123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737891737891737, "Avg loss": 0.5875972437206656, "Avg value loss": 0.28309061093023047, "Avg policy loss": 0.3045066357590258, "Total num played games": 28080, "Total num trained steps": 55424, "Timestamp in ms": 1701578008946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783475783475784, "Avg loss": 0.5011944368015975, "Avg value loss": 0.19902967661619186, "Avg policy loss": 0.3021647637942806, "Total num played games": 28080, "Total num trained steps": 55552, "Timestamp in ms": 1701578060667, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 106.80864841118455, "Avg game time in secs": 2.8667816349770874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.73}, "Total num played games": 28160, "Total num trained steps": 55659, "Timestamp in ms": 1701578103932, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761499148211243, "Avg loss": 0.49322002148255706, "Avg value loss": 0.2126084718038328, "Avg policy loss": 0.28061155462637544, "Total num played games": 28176, "Total num trained steps": 55680, "Timestamp in ms": 1701578112190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9806927881885292, "Avg loss": 0.5078364997170866, "Avg value loss": 0.2093059621984139, "Avg policy loss": 0.2985305371694267, "Total num played games": 28176, "Total num trained steps": 55808, "Timestamp in ms": 1701578164260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978494623655914, "Avg loss": 0.5162846182938665, "Avg value loss": 0.2341804807074368, "Avg policy loss": 0.282104141660966, "Total num played games": 28272, "Total num trained steps": 55936, "Timestamp in ms": 1701578216861, "logtype": "training_step"}
{"Total num played games": 28272, "Total num trained steps": 55988, "Timestamp in ms": 1701578251573, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.42578125}
{"Avg objective": 19.921875, "Games time in secs": 150.62579739838839, "Avg game time in secs": 2.7517554492806084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.67, "agent_stopped_0": 0.44}, "Total num played games": 28288, "Total num trained steps": 55994, "Timestamp in ms": 1701578254558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764506803920185, "Avg loss": 0.6452965913340449, "Avg value loss": 0.33545210654847324, "Avg policy loss": 0.309844484901987, "Total num played games": 28366, "Total num trained steps": 56064, "Timestamp in ms": 1701578283454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809631248677995, "Avg loss": 0.46688611060380936, "Avg value loss": 0.1764053148799576, "Avg policy loss": 0.2904807988088578, "Total num played games": 28366, "Total num trained steps": 56192, "Timestamp in ms": 1701578335673, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 95.69994231685996, "Avg game time in secs": 2.46995259092364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.68}, "Total num played games": 28416, "Total num trained steps": 56227, "Timestamp in ms": 1701578350258, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787435879418172, "Avg loss": 0.5259434769395739, "Avg value loss": 0.23422477504936978, "Avg policy loss": 0.2917186996201053, "Total num played games": 28462, "Total num trained steps": 56320, "Timestamp in ms": 1701578387551, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 80.82184632122517, "Avg game time in secs": 2.8153187675052322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.76}, "Total num played games": 28544, "Total num trained steps": 56424, "Timestamp in ms": 1701578431080, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9766090062329296, "Avg loss": 0.608749269740656, "Avg value loss": 0.32363132358295843, "Avg policy loss": 0.28511794353835285, "Total num played games": 28558, "Total num trained steps": 56448, "Timestamp in ms": 1701578441218, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9810911128230269, "Avg loss": 0.5358239884953946, "Avg value loss": 0.23316973313922063, "Avg policy loss": 0.30265425401739776, "Total num played games": 28558, "Total num trained steps": 56576, "Timestamp in ms": 1701578493370, "logtype": "training_step"}
{"Total num played games": 28558, "Total num trained steps": 56588, "Timestamp in ms": 1701578515127, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4609375}
{"Ratio train steps to played games": 1.9790590534692167, "Avg loss": 0.6317120050080121, "Avg value loss": 0.325379375834018, "Avg policy loss": 0.3063326287083328, "Total num played games": 28652, "Total num trained steps": 56704, "Timestamp in ms": 1701578563676, "logtype": "training_step"}
{"Avg objective": 19.9765625, "Games time in secs": 170.53779109939933, "Avg game time in secs": 2.8019480695802486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.71, "agent_stopped_0": 0.41}, "Total num played games": 28672, "Total num trained steps": 56798, "Timestamp in ms": 1701578601618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769027410602478, "Avg loss": 0.5024273204617202, "Avg value loss": 0.20588070148369297, "Avg policy loss": 0.29654661868698895, "Total num played games": 28748, "Total num trained steps": 56832, "Timestamp in ms": 1701578615356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813552247112842, "Avg loss": 0.4588039123918861, "Avg value loss": 0.16209258744493127, "Avg policy loss": 0.29671132611110806, "Total num played games": 28748, "Total num trained steps": 56960, "Timestamp in ms": 1701578667226, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 78.74046975746751, "Avg game time in secs": 2.552290972424089, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 28800, "Total num trained steps": 56992, "Timestamp in ms": 1701578680358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791984468173625, "Avg loss": 0.585142815252766, "Avg value loss": 0.2738047298626043, "Avg policy loss": 0.31133808312006295, "Total num played games": 28844, "Total num trained steps": 57088, "Timestamp in ms": 1701578719299, "logtype": "training_step"}
{"Avg objective": 20.1484375, "Games time in secs": 78.1694113239646, "Avg game time in secs": 2.5486999759305036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 28928, "Total num trained steps": 57187, "Timestamp in ms": 1701578758528, "logtype": "played_game"}
{"Total num played games": 28942, "Total num trained steps": 57190, "Timestamp in ms": 1701578776793, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.81640625}
{"Ratio train steps to played games": 1.9705193552830969, "Avg loss": 0.598715060390532, "Avg value loss": 0.2971102790324949, "Avg policy loss": 0.3016047840937972, "Total num played games": 29036, "Total num trained steps": 57216, "Timestamp in ms": 1701578787873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9749276759884282, "Avg loss": 0.588240786222741, "Avg value loss": 0.25281154847471043, "Avg policy loss": 0.3354292334988713, "Total num played games": 29036, "Total num trained steps": 57344, "Timestamp in ms": 1701578842070, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979301556688249, "Avg loss": 0.5290211485698819, "Avg value loss": 0.23010581132257357, "Avg policy loss": 0.29891533486079425, "Total num played games": 29036, "Total num trained steps": 57472, "Timestamp in ms": 1701578896265, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 177.34887643158436, "Avg game time in secs": 2.8203410608839476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 29056, "Total num trained steps": 57566, "Timestamp in ms": 1701578935877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9770714628955859, "Avg loss": 0.5739221828989685, "Avg value loss": 0.26238093082793057, "Avg policy loss": 0.3115412484621629, "Total num played games": 29134, "Total num trained steps": 57600, "Timestamp in ms": 1701578950401, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814649550353538, "Avg loss": 0.5241466958541423, "Avg value loss": 0.2064899422111921, "Avg policy loss": 0.31765675300266594, "Total num played games": 29134, "Total num trained steps": 57728, "Timestamp in ms": 1701579002023, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 81.0102347265929, "Avg game time in secs": 2.7847689548507333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.72}, "Total num played games": 29184, "Total num trained steps": 57765, "Timestamp in ms": 1701579016887, "logtype": "played_game"}
{"Total num played games": 29230, "Total num trained steps": 57792, "Timestamp in ms": 1701579043124, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.578125}
{"Avg objective": 20.3046875, "Games time in secs": 31.88022029772401, "Avg game time in secs": 2.9481383532547625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.75, "agent_stopped_0": 0.32}, "Total num played games": 29312, "Total num trained steps": 57804, "Timestamp in ms": 1701579048768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972991406356568, "Avg loss": 0.7207242522854358, "Avg value loss": 0.3908146083704196, "Avg policy loss": 0.3299096419941634, "Total num played games": 29324, "Total num trained steps": 57856, "Timestamp in ms": 1701579071350, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9773564315918701, "Avg loss": 0.4936791309155524, "Avg value loss": 0.16684564587194473, "Avg policy loss": 0.3268334869062528, "Total num played games": 29324, "Total num trained steps": 57984, "Timestamp in ms": 1701579125929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817214568271724, "Avg loss": 0.44717997102998197, "Avg value loss": 0.13594889279920608, "Avg policy loss": 0.31123107951134443, "Total num played games": 29324, "Total num trained steps": 58112, "Timestamp in ms": 1701579179294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794711440418735, "Avg loss": 0.6075269726570696, "Avg value loss": 0.272427384625189, "Avg policy loss": 0.3350995940854773, "Total num played games": 29422, "Total num trained steps": 58240, "Timestamp in ms": 1701579230856, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 220.62299255654216, "Avg game time in secs": 2.5753367246652488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.52, "agent_stopped_0": 0.6}, "Total num played games": 29440, "Total num trained steps": 58337, "Timestamp in ms": 1701579269391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775037267922482, "Avg loss": 0.5606416913215071, "Avg value loss": 0.231292198470328, "Avg policy loss": 0.3293494931422174, "Total num played games": 29516, "Total num trained steps": 58368, "Timestamp in ms": 1701579282362, "logtype": "training_step"}
{"Total num played games": 29516, "Total num trained steps": 58396, "Timestamp in ms": 1701579311502, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.41015625}
{"Avg objective": 20.53125, "Games time in secs": 46.18185870908201, "Avg game time in secs": 2.724252983025508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.63}, "Total num played games": 29568, "Total num trained steps": 58405, "Timestamp in ms": 1701579315573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975548801080716, "Avg loss": 0.6436742492951453, "Avg value loss": 0.30092856066767126, "Avg policy loss": 0.34274568501859903, "Total num played games": 29610, "Total num trained steps": 58496, "Timestamp in ms": 1701579353413, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979871664978048, "Avg loss": 0.4679497345350683, "Avg value loss": 0.14713853620924056, "Avg policy loss": 0.32081119786016643, "Total num played games": 29610, "Total num trained steps": 58624, "Timestamp in ms": 1701579406873, "logtype": "training_step"}
{"Avg objective": 20.9453125, "Games time in secs": 129.57558914087713, "Avg game time in secs": 2.682715077258763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 29696, "Total num trained steps": 58719, "Timestamp in ms": 1701579445149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776491180826714, "Avg loss": 0.5747131437528878, "Avg value loss": 0.25407650094712153, "Avg policy loss": 0.3206366441445425, "Total num played games": 29708, "Total num trained steps": 58752, "Timestamp in ms": 1701579459342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981957721825771, "Avg loss": 0.49647364718839526, "Avg value loss": 0.17174159485148266, "Avg policy loss": 0.32473204866982996, "Total num played games": 29708, "Total num trained steps": 58880, "Timestamp in ms": 1701579510208, "logtype": "training_step"}
{"Total num played games": 29804, "Total num trained steps": 58999, "Timestamp in ms": 1701579574214, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.65625}
{"Avg objective": 20.6015625, "Games time in secs": 131.8048682846129, "Avg game time in secs": 2.5242413535015658, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 29824, "Total num trained steps": 59004, "Timestamp in ms": 1701579576953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976155391828533, "Avg loss": 0.5960892043076456, "Avg value loss": 0.2754507142235525, "Avg policy loss": 0.32063848699908704, "Total num played games": 29856, "Total num trained steps": 59008, "Timestamp in ms": 1701579578550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 0.6652141478843987, "Avg value loss": 0.3430361321079545, "Avg policy loss": 0.32217801234219223, "Total num played games": 29898, "Total num trained steps": 59136, "Timestamp in ms": 1701579630525, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822061676366312, "Avg loss": 0.42866540467366576, "Avg value loss": 0.1351515575661324, "Avg policy loss": 0.2935138448374346, "Total num played games": 29898, "Total num trained steps": 59264, "Timestamp in ms": 1701579683032, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 117.66360095329583, "Avg game time in secs": 2.728223678903305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 29952, "Total num trained steps": 59293, "Timestamp in ms": 1701579694617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802614030408108, "Avg loss": 0.5746569775510579, "Avg value loss": 0.2623561058426276, "Avg policy loss": 0.3123008724069223, "Total num played games": 29992, "Total num trained steps": 59392, "Timestamp in ms": 1701579733792, "logtype": "training_step"}
{"Avg objective": 19.1328125, "Games time in secs": 78.46022021584213, "Avg game time in secs": 3.335346904103062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.84, "agent_stopped_0": 0.34}, "Total num played games": 30080, "Total num trained steps": 59488, "Timestamp in ms": 1701579773078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781972879553311, "Avg loss": 0.5201467329170555, "Avg value loss": 0.22151777718681842, "Avg policy loss": 0.29862895712722093, "Total num played games": 30088, "Total num trained steps": 59520, "Timestamp in ms": 1701579786250, "logtype": "training_step"}
{"Total num played games": 30088, "Total num trained steps": 59602, "Timestamp in ms": 1701579834171, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5625}
{"Ratio train steps to played games": 1.9762772513418594, "Avg loss": 0.6416899661999196, "Avg value loss": 0.33761802909430116, "Avg policy loss": 0.30407194199506193, "Total num played games": 30182, "Total num trained steps": 59648, "Timestamp in ms": 1701579853279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98051818964946, "Avg loss": 0.44465778791345656, "Avg value loss": 0.15328070253599435, "Avg policy loss": 0.29137708770576864, "Total num played games": 30182, "Total num trained steps": 59776, "Timestamp in ms": 1701579905108, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 164.98193525150418, "Avg game time in secs": 2.203920842919615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.43, "agent_stopped_0": 0.58}, "Total num played games": 30208, "Total num trained steps": 59858, "Timestamp in ms": 1701579938060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785969084423305, "Avg loss": 0.49900404177606106, "Avg value loss": 0.20946945156902075, "Avg policy loss": 0.28953458648175, "Total num played games": 30276, "Total num trained steps": 59904, "Timestamp in ms": 1701579956316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982824679614216, "Avg loss": 0.4306506849825382, "Avg value loss": 0.1563004847848788, "Avg policy loss": 0.2743501979857683, "Total num played games": 30276, "Total num trained steps": 60032, "Timestamp in ms": 1701580009227, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 78.10650409571826, "Avg game time in secs": 2.6334778498712694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.64}, "Total num played games": 30336, "Total num trained steps": 60050, "Timestamp in ms": 1701580016166, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807717634663506, "Avg loss": 0.5527610925491899, "Avg value loss": 0.25704275449970737, "Avg policy loss": 0.2957183385733515, "Total num played games": 30372, "Total num trained steps": 60160, "Timestamp in ms": 1701580061329, "logtype": "training_step"}
{"Total num played games": 30372, "Total num trained steps": 60203, "Timestamp in ms": 1701580093838, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.41796875}
{"Avg objective": 19.5546875, "Games time in secs": 83.55942311137915, "Avg game time in secs": 3.076714667477063, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.77, "agent_stopped_0": 0.34}, "Total num played games": 30464, "Total num trained steps": 60214, "Timestamp in ms": 1701580099726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978861681874877, "Avg loss": 0.5116200011689216, "Avg value loss": 0.22451670421287417, "Avg policy loss": 0.28710329008754343, "Total num played games": 30466, "Total num trained steps": 60288, "Timestamp in ms": 1701580128740, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830302632442722, "Avg loss": 0.40798868890851736, "Avg value loss": 0.1385192991583608, "Avg policy loss": 0.26946939225308597, "Total num played games": 30466, "Total num trained steps": 60416, "Timestamp in ms": 1701580181752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981151832460733, "Avg loss": 0.5471765140537173, "Avg value loss": 0.2594848960870877, "Avg policy loss": 0.28769161575473845, "Total num played games": 30560, "Total num trained steps": 60544, "Timestamp in ms": 1701580233134, "logtype": "training_step"}
{"Avg objective": 19.8671875, "Games time in secs": 162.01168409734964, "Avg game time in secs": 2.6699082628183533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 30592, "Total num trained steps": 60614, "Timestamp in ms": 1701580261738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979252299862987, "Avg loss": 0.5681099637877196, "Avg value loss": 0.27387414360418916, "Avg policy loss": 0.2942358204163611, "Total num played games": 30654, "Total num trained steps": 60672, "Timestamp in ms": 1701580284481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830397912589692, "Avg loss": 0.4270616238936782, "Avg value loss": 0.1420323311467655, "Avg policy loss": 0.2850292935036123, "Total num played games": 30658, "Total num trained steps": 60800, "Timestamp in ms": 1701580337434, "logtype": "training_step"}
{"Avg objective": 19.8203125, "Games time in secs": 77.33919468149543, "Avg game time in secs": 2.725624939586851, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.56}, "Total num played games": 30720, "Total num trained steps": 60803, "Timestamp in ms": 1701580339077, "logtype": "played_game"}
{"Total num played games": 30748, "Total num trained steps": 60803, "Timestamp in ms": 1701580353900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.71875}
{"Ratio train steps to played games": 1.9754879709487063, "Avg loss": 0.7085780503693968, "Avg value loss": 0.40181185852270573, "Avg policy loss": 0.3067662016255781, "Total num played games": 30842, "Total num trained steps": 60928, "Timestamp in ms": 1701580406854, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796381557616238, "Avg loss": 0.42262224527075887, "Avg value loss": 0.14468672702787444, "Avg policy loss": 0.277935515739955, "Total num played games": 30842, "Total num trained steps": 61056, "Timestamp in ms": 1701580458649, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 169.74351956695318, "Avg game time in secs": 2.862433139991481, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 30848, "Total num trained steps": 61176, "Timestamp in ms": 1701580508821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97852800413918, "Avg loss": 0.40786297782324255, "Avg value loss": 0.14100056269671768, "Avg policy loss": 0.26686241605784744, "Total num played games": 30924, "Total num trained steps": 61184, "Timestamp in ms": 1701580511540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817699915960953, "Avg loss": 0.537910045357421, "Avg value loss": 0.2454616844188422, "Avg policy loss": 0.2924483602400869, "Total num played games": 30938, "Total num trained steps": 61312, "Timestamp in ms": 1701580566241, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 83.96779844723642, "Avg game time in secs": 2.447645249776542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 30976, "Total num trained steps": 61372, "Timestamp in ms": 1701580592789, "logtype": "played_game"}
{"Total num played games": 31038, "Total num trained steps": 61405, "Timestamp in ms": 1701580622557, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4453125}
{"Avg objective": 20.0234375, "Games time in secs": 34.46060802973807, "Avg game time in secs": 2.877656646887772, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 31104, "Total num trained steps": 61415, "Timestamp in ms": 1701580627249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97349993575742, "Avg loss": 0.6188466146122664, "Avg value loss": 0.3275544563657604, "Avg policy loss": 0.2912921563256532, "Total num played games": 31132, "Total num trained steps": 61440, "Timestamp in ms": 1701580638177, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97764358216626, "Avg loss": 0.4799856666941196, "Avg value loss": 0.18767626961925998, "Avg policy loss": 0.29230939771514386, "Total num played games": 31132, "Total num trained steps": 61568, "Timestamp in ms": 1701580691271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817551072851085, "Avg loss": 0.40047672227956355, "Avg value loss": 0.13149899512063712, "Avg policy loss": 0.2689777258783579, "Total num played games": 31132, "Total num trained steps": 61696, "Timestamp in ms": 1701580744088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797617522736006, "Avg loss": 0.5846404121257365, "Avg value loss": 0.2904363928246312, "Avg policy loss": 0.2942040206398815, "Total num played games": 31228, "Total num trained steps": 61824, "Timestamp in ms": 1701580797797, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 222.5191219020635, "Avg game time in secs": 2.8884036400995683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.72, "agent_stopped_0": 0.42}, "Total num played games": 31232, "Total num trained steps": 61948, "Timestamp in ms": 1701580849769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810693271936557, "Avg loss": 0.421642359578982, "Avg value loss": 0.14195628796005622, "Avg policy loss": 0.27968607214279473, "Total num played games": 31272, "Total num trained steps": 61952, "Timestamp in ms": 1701580851207, "logtype": "training_step"}
{"Total num played games": 31326, "Total num trained steps": 62005, "Timestamp in ms": 1701580889472, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.33984375}
{"Avg objective": 21.2421875, "Games time in secs": 43.01590692065656, "Avg game time in secs": 2.435941606236156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 31360, "Total num trained steps": 62011, "Timestamp in ms": 1701580892805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758115849777211, "Avg loss": 0.6885163120459765, "Avg value loss": 0.3825493836775422, "Avg policy loss": 0.30596693081315607, "Total num played games": 31420, "Total num trained steps": 62080, "Timestamp in ms": 1701580921746, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979885423297263, "Avg loss": 0.4358235609252006, "Avg value loss": 0.15345780027564615, "Avg policy loss": 0.2823657625121996, "Total num played games": 31420, "Total num trained steps": 62208, "Timestamp in ms": 1701580973540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811530638189676, "Avg loss": 0.37840587086975574, "Avg value loss": 0.11581202025990933, "Avg policy loss": 0.26259385142475367, "Total num played games": 31464, "Total num trained steps": 62336, "Timestamp in ms": 1701581026279, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 134.6361781898886, "Avg game time in secs": 2.8290513484244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 31488, "Total num trained steps": 62338, "Timestamp in ms": 1701581027441, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821031922320238, "Avg loss": 0.5071259003598243, "Avg value loss": 0.2390629051369615, "Avg policy loss": 0.2680629923706874, "Total num played games": 31514, "Total num trained steps": 62464, "Timestamp in ms": 1701581079933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801328693451439, "Avg loss": 0.5127691754605621, "Avg value loss": 0.24975399021059275, "Avg policy loss": 0.2630151844350621, "Total num played games": 31610, "Total num trained steps": 62592, "Timestamp in ms": 1701581132279, "logtype": "training_step"}
{"Total num played games": 31610, "Total num trained steps": 62608, "Timestamp in ms": 1701581154621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.49609375}
{"Avg objective": 20.640625, "Games time in secs": 129.6412019431591, "Avg game time in secs": 2.877138990617823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.68}, "Total num played games": 31616, "Total num trained steps": 62612, "Timestamp in ms": 1701581157082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978299268231138, "Avg loss": 0.6631696664262563, "Avg value loss": 0.37332414521370083, "Avg policy loss": 0.28984551248140633, "Total num played games": 31704, "Total num trained steps": 62720, "Timestamp in ms": 1701581202340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823366136765077, "Avg loss": 0.411495252745226, "Avg value loss": 0.13857485936023295, "Avg policy loss": 0.2729203945491463, "Total num played games": 31704, "Total num trained steps": 62848, "Timestamp in ms": 1701581253531, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 117.73470772989094, "Avg game time in secs": 2.389333834478748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 31744, "Total num trained steps": 62903, "Timestamp in ms": 1701581274817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802528142884095, "Avg loss": 0.6176010256167501, "Avg value loss": 0.33871911180904135, "Avg policy loss": 0.27888191444799304, "Total num played games": 31802, "Total num trained steps": 62976, "Timestamp in ms": 1701581304289, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 79.6207976732403, "Avg game time in secs": 2.6727670050022425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.69, "agent_stopped_0": 0.42}, "Total num played games": 31872, "Total num trained steps": 63102, "Timestamp in ms": 1701581354438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791745075900138, "Avg loss": 0.47943808254785836, "Avg value loss": 0.20093612762866542, "Avg policy loss": 0.27850195672363043, "Total num played games": 31884, "Total num trained steps": 63104, "Timestamp in ms": 1701581355245, "logtype": "training_step"}
{"Total num played games": 31898, "Total num trained steps": 63208, "Timestamp in ms": 1701581414707, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.83984375}
{"Ratio train steps to played games": 1.9764941235308828, "Avg loss": 0.6595576617401093, "Avg value loss": 0.3499152411823161, "Avg policy loss": 0.30964242736808956, "Total num played games": 31992, "Total num trained steps": 63232, "Timestamp in ms": 1701581425085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804951237809452, "Avg loss": 0.5441805708687752, "Avg value loss": 0.2324088925961405, "Avg policy loss": 0.31177167722489685, "Total num played games": 31992, "Total num trained steps": 63360, "Timestamp in ms": 1701581478776, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 171.9742853231728, "Avg game time in secs": 2.699642943814979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.63}, "Total num played games": 32000, "Total num trained steps": 63477, "Timestamp in ms": 1701581526413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786511251012904, "Avg loss": 0.45654289657250047, "Avg value loss": 0.17636103433324024, "Avg policy loss": 0.2801818634616211, "Total num played games": 32084, "Total num trained steps": 63488, "Timestamp in ms": 1701581530632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825479930191972, "Avg loss": 0.5658334088511765, "Avg value loss": 0.27474229724612087, "Avg policy loss": 0.2910911054350436, "Total num played games": 32088, "Total num trained steps": 63616, "Timestamp in ms": 1701581582876, "logtype": "training_step"}
{"Avg objective": 19.484375, "Games time in secs": 78.55572378821671, "Avg game time in secs": 2.57669685719884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.65}, "Total num played games": 32128, "Total num trained steps": 63671, "Timestamp in ms": 1701581604968, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806114839671887, "Avg loss": 0.5857848152518272, "Avg value loss": 0.2900437598582357, "Avg policy loss": 0.29574105283245444, "Total num played games": 32184, "Total num trained steps": 63744, "Timestamp in ms": 1701581634178, "logtype": "training_step"}
{"Total num played games": 32184, "Total num trained steps": 63811, "Timestamp in ms": 1701581675493, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.75}
{"Avg objective": 19.71875, "Games time in secs": 75.03007178008556, "Avg game time in secs": 2.5325718879321357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 32256, "Total num trained steps": 63821, "Timestamp in ms": 1701581679998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788090959786853, "Avg loss": 0.5552741563878953, "Avg value loss": 0.2521619026665576, "Avg policy loss": 0.30311225063633174, "Total num played games": 32278, "Total num trained steps": 63872, "Timestamp in ms": 1701581700783, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827746452692236, "Avg loss": 0.4342753356322646, "Avg value loss": 0.1535554020665586, "Avg policy loss": 0.28071993275079876, "Total num played games": 32278, "Total num trained steps": 64000, "Timestamp in ms": 1701581753482, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808488293074689, "Avg loss": 0.5597413524519652, "Avg value loss": 0.269198976107873, "Avg policy loss": 0.29054237878881395, "Total num played games": 32374, "Total num trained steps": 64128, "Timestamp in ms": 1701581806023, "logtype": "training_step"}
{"Avg objective": 19.9375, "Games time in secs": 172.97715156897902, "Avg game time in secs": 2.863158411884797, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.77, "agent_stopped_0": 0.34}, "Total num played games": 32384, "Total num trained steps": 64240, "Timestamp in ms": 1701581852976, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979056301589257, "Avg loss": 0.4454296133480966, "Avg value loss": 0.16869425203185529, "Avg policy loss": 0.27673536050133407, "Total num played games": 32468, "Total num trained steps": 64256, "Timestamp in ms": 1701581859371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9829986448195145, "Avg loss": 0.45047870674170554, "Avg value loss": 0.1644531082129106, "Avg policy loss": 0.286025597830303, "Total num played games": 32468, "Total num trained steps": 64384, "Timestamp in ms": 1701581911452, "logtype": "training_step"}
{"Total num played games": 32468, "Total num trained steps": 64411, "Timestamp in ms": 1701581938217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.98046875}
{"Avg objective": 20.578125, "Games time in secs": 88.95414780452847, "Avg game time in secs": 2.5215245582076022, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 32512, "Total num trained steps": 64420, "Timestamp in ms": 1701581941930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812050856826977, "Avg loss": 0.501384683419019, "Avg value loss": 0.21607040474191308, "Avg policy loss": 0.2853142770472914, "Total num played games": 32562, "Total num trained steps": 64512, "Timestamp in ms": 1701581982298, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 87.1724477186799, "Avg game time in secs": 2.7062841322331224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 32640, "Total num trained steps": 64624, "Timestamp in ms": 1701582029103, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793006307795946, "Avg loss": 0.42587016127072275, "Avg value loss": 0.16358575806953013, "Avg policy loss": 0.2622844041325152, "Total num played games": 32658, "Total num trained steps": 64640, "Timestamp in ms": 1701582036024, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983220037969257, "Avg loss": 0.4654971903655678, "Avg value loss": 0.17869852483272552, "Avg policy loss": 0.286798661807552, "Total num played games": 32658, "Total num trained steps": 64768, "Timestamp in ms": 1701582087611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813152592049825, "Avg loss": 0.5522857538890094, "Avg value loss": 0.25962828507181257, "Avg policy loss": 0.29265747079625726, "Total num played games": 32754, "Total num trained steps": 64896, "Timestamp in ms": 1701582139426, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 153.1665294468403, "Avg game time in secs": 2.860691861831583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.69}, "Total num played games": 32768, "Total num trained steps": 65002, "Timestamp in ms": 1701582182269, "logtype": "played_game"}
{"Total num played games": 32850, "Total num trained steps": 65014, "Timestamp in ms": 1701582204569, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1015625}
{"Avg objective": 19.859375, "Games time in secs": 25.96858846768737, "Avg game time in secs": 2.4055183298769407, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 32896, "Total num trained steps": 65022, "Timestamp in ms": 1701582208238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975572704624172, "Avg loss": 0.4830890828743577, "Avg value loss": 0.19878304534358904, "Avg policy loss": 0.2843060402665287, "Total num played games": 32914, "Total num trained steps": 65024, "Timestamp in ms": 1701582208681, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776590577950461, "Avg loss": 0.6873397289309651, "Avg value loss": 0.354986984282732, "Avg policy loss": 0.3323527454631403, "Total num played games": 32944, "Total num trained steps": 65152, "Timestamp in ms": 1701582261116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815444390480816, "Avg loss": 0.5288559400942177, "Avg value loss": 0.2251965767936781, "Avg policy loss": 0.3036593634169549, "Total num played games": 32944, "Total num trained steps": 65280, "Timestamp in ms": 1701582313538, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 149.3686376605183, "Avg game time in secs": 2.7307688405708177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.28, "agent_stopped_more": 0.72, "played_steps": 0.8}, "Total num played games": 33024, "Total num trained steps": 65388, "Timestamp in ms": 1701582357607, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9796610169491526, "Avg loss": 0.510026496136561, "Avg value loss": 0.21075185557128862, "Avg policy loss": 0.2992746422532946, "Total num played games": 33040, "Total num trained steps": 65408, "Timestamp in ms": 1701582365657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835351089588378, "Avg loss": 0.49944819253869355, "Avg value loss": 0.19210539275081828, "Avg policy loss": 0.3073427998460829, "Total num played games": 33040, "Total num trained steps": 65536, "Timestamp in ms": 1701582418741, "logtype": "training_step"}
{"Total num played games": 33134, "Total num trained steps": 65616, "Timestamp in ms": 1701582465275, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.00390625}
{"Avg objective": 19.28125, "Games time in secs": 110.4425067063421, "Avg game time in secs": 2.741514848486986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 33152, "Total num trained steps": 65622, "Timestamp in ms": 1701582468050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761646803900326, "Avg loss": 0.6832633290905505, "Avg value loss": 0.3657572770025581, "Avg policy loss": 0.31750605546403676, "Total num played games": 33228, "Total num trained steps": 65664, "Timestamp in ms": 1701582484876, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800168532562898, "Avg loss": 0.47682031337171793, "Avg value loss": 0.1661437414586544, "Avg policy loss": 0.3106765727279708, "Total num played games": 33228, "Total num trained steps": 65792, "Timestamp in ms": 1701582538087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838690261225473, "Avg loss": 0.43307663686573505, "Avg value loss": 0.14645372709492221, "Avg policy loss": 0.2866229088976979, "Total num played games": 33228, "Total num trained steps": 65920, "Timestamp in ms": 1701582591146, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 136.08762178756297, "Avg game time in secs": 2.3915846876770956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 33280, "Total num trained steps": 65953, "Timestamp in ms": 1701582604137, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982113918732369, "Avg loss": 0.5698536091949791, "Avg value loss": 0.2648001293418929, "Avg policy loss": 0.30505348194856197, "Total num played games": 33322, "Total num trained steps": 66048, "Timestamp in ms": 1701582643069, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 77.81512752920389, "Avg game time in secs": 2.705186452352791, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.67, "agent_stopped_0": 0.43}, "Total num played games": 33408, "Total num trained steps": 66144, "Timestamp in ms": 1701582681953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980250164581962, "Avg loss": 0.5471652699634433, "Avg value loss": 0.25719113426748663, "Avg policy loss": 0.28997413674369454, "Total num played games": 33418, "Total num trained steps": 66176, "Timestamp in ms": 1701582695130, "logtype": "training_step"}
{"Total num played games": 33418, "Total num trained steps": 66218, "Timestamp in ms": 1701582725232, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4140625}
{"Ratio train steps to played games": 1.9785151587491048, "Avg loss": 0.5392960098106414, "Avg value loss": 0.23614057555096224, "Avg policy loss": 0.3031554351327941, "Total num played games": 33512, "Total num trained steps": 66304, "Timestamp in ms": 1701582760503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823346860825972, "Avg loss": 0.4070344208739698, "Avg value loss": 0.12826980085810646, "Avg policy loss": 0.27876461890991777, "Total num played games": 33512, "Total num trained steps": 66432, "Timestamp in ms": 1701582812788, "logtype": "training_step"}
{"Avg objective": 20.015625, "Games time in secs": 165.38859810493886, "Avg game time in secs": 2.4375695669441484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 33536, "Total num trained steps": 66518, "Timestamp in ms": 1701582847341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980480837895739, "Avg loss": 0.46735848765820265, "Avg value loss": 0.18100158113520592, "Avg policy loss": 0.2863569043111056, "Total num played games": 33608, "Total num trained steps": 66560, "Timestamp in ms": 1701582864704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842894548916925, "Avg loss": 0.4377072933129966, "Avg value loss": 0.1410055258893408, "Avg policy loss": 0.29670176620129496, "Total num played games": 33608, "Total num trained steps": 66688, "Timestamp in ms": 1701582917415, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 79.63611605204642, "Avg game time in secs": 2.5180393864720827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.7}, "Total num played games": 33664, "Total num trained steps": 66712, "Timestamp in ms": 1701582926978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824353192499407, "Avg loss": 0.5036412340123206, "Avg value loss": 0.21600436716107652, "Avg policy loss": 0.28763686679303646, "Total num played games": 33704, "Total num trained steps": 66816, "Timestamp in ms": 1701582968669, "logtype": "training_step"}
{"Total num played games": 33704, "Total num trained steps": 66818, "Timestamp in ms": 1701582983801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.55078125}
{"Avg objective": 19.96875, "Games time in secs": 63.74097801186144, "Avg game time in secs": 2.7492632720823167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.75}, "Total num played games": 33792, "Total num trained steps": 66833, "Timestamp in ms": 1701582990719, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980708917687437, "Avg loss": 0.5410612048581243, "Avg value loss": 0.2344188541173935, "Avg policy loss": 0.3066423521377146, "Total num played games": 33798, "Total num trained steps": 66944, "Timestamp in ms": 1701583036288, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.41051785671152174, "Avg value loss": 0.1257627425948158, "Avg policy loss": 0.2847551148151979, "Total num played games": 33798, "Total num trained steps": 67072, "Timestamp in ms": 1701583088463, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982534812367241, "Avg loss": 0.5195077443495393, "Avg value loss": 0.2210627692984417, "Avg policy loss": 0.2984449788928032, "Total num played games": 33896, "Total num trained steps": 67200, "Timestamp in ms": 1701583141324, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 185.59356953762472, "Avg game time in secs": 2.502521929476643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.63, "agent_stopped_0": 0.47}, "Total num played games": 33920, "Total num trained steps": 67286, "Timestamp in ms": 1701583176313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808178876140041, "Avg loss": 0.5152947271708399, "Avg value loss": 0.22728204092709348, "Avg policy loss": 0.2880126853706315, "Total num played games": 33990, "Total num trained steps": 67328, "Timestamp in ms": 1701583193310, "logtype": "training_step"}
{"Total num played games": 33990, "Total num trained steps": 67421, "Timestamp in ms": 1701583243226, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.265625}
{"Avg objective": 19.5078125, "Games time in secs": 70.42055803351104, "Avg game time in secs": 2.3385417625977425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 34048, "Total num trained steps": 67429, "Timestamp in ms": 1701583246733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791104330477642, "Avg loss": 0.6115546002984047, "Avg value loss": 0.3178647288004868, "Avg policy loss": 0.29368987085763365, "Total num played games": 34084, "Total num trained steps": 67456, "Timestamp in ms": 1701583257843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828658608144585, "Avg loss": 0.4615532534662634, "Avg value loss": 0.1574502808507532, "Avg policy loss": 0.3041029720334336, "Total num played games": 34084, "Total num trained steps": 67584, "Timestamp in ms": 1701583310578, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 97.54800956137478, "Avg game time in secs": 2.384730336329085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 34176, "Total num trained steps": 67668, "Timestamp in ms": 1701583344281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981157469717362, "Avg loss": 0.528900928562507, "Avg value loss": 0.24059399374527857, "Avg policy loss": 0.28830693510826677, "Total num played games": 34178, "Total num trained steps": 67712, "Timestamp in ms": 1701583362612, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849025689039732, "Avg loss": 0.42028020485304296, "Avg value loss": 0.13855118869105354, "Avg policy loss": 0.2817290173843503, "Total num played games": 34178, "Total num trained steps": 67840, "Timestamp in ms": 1701583414807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983048374861411, "Avg loss": 0.5439469455741346, "Avg value loss": 0.2465718071325682, "Avg policy loss": 0.2973751398967579, "Total num played games": 34274, "Total num trained steps": 67968, "Timestamp in ms": 1701583466597, "logtype": "training_step"}
{"Total num played games": 34274, "Total num trained steps": 68026, "Timestamp in ms": 1701583504126, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.31640625}
{"Avg objective": 20.25, "Games time in secs": 162.73655707202852, "Avg game time in secs": 2.191759870009264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 34304, "Total num trained steps": 68031, "Timestamp in ms": 1701583507018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813780260707634, "Avg loss": 0.5573702522087842, "Avg value loss": 0.27037815205403604, "Avg policy loss": 0.2869920978555456, "Total num played games": 34368, "Total num trained steps": 68096, "Timestamp in ms": 1701583533391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851024208566108, "Avg loss": 0.4253049904946238, "Avg value loss": 0.14863589050946757, "Avg policy loss": 0.27666910144034773, "Total num played games": 34368, "Total num trained steps": 68224, "Timestamp in ms": 1701583587302, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 83.75754536688328, "Avg game time in secs": 2.382424972791341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 34432, "Total num trained steps": 68233, "Timestamp in ms": 1701583590776, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832869080779945, "Avg loss": 0.5423569621052593, "Avg value loss": 0.24953705060761422, "Avg policy loss": 0.2928199163870886, "Total num played games": 34464, "Total num trained steps": 68352, "Timestamp in ms": 1701583639575, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815961571850222, "Avg loss": 0.5345018794760108, "Avg value loss": 0.2545064613223076, "Avg policy loss": 0.2799954187357798, "Total num played games": 34558, "Total num trained steps": 68480, "Timestamp in ms": 1701583693147, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852711383760635, "Avg loss": 0.39101821440272033, "Avg value loss": 0.127099908713717, "Avg policy loss": 0.2639183085411787, "Total num played games": 34558, "Total num trained steps": 68608, "Timestamp in ms": 1701583743861, "logtype": "training_step"}
{"Avg objective": 20.34375, "Games time in secs": 153.25428680330515, "Avg game time in secs": 2.6024458027095534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.66, "agent_stopped_0": 0.42}, "Total num played games": 34560, "Total num trained steps": 68608, "Timestamp in ms": 1701583744030, "logtype": "played_game"}
{"Total num played games": 34656, "Total num trained steps": 68630, "Timestamp in ms": 1701583767206, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.27734375}
{"Avg objective": 20.3515625, "Games time in secs": 26.320903377607465, "Avg game time in secs": 2.200928810867481, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.58}, "Total num played games": 34688, "Total num trained steps": 68637, "Timestamp in ms": 1701583770351, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780143884892087, "Avg loss": 0.709444893989712, "Avg value loss": 0.40300574828870595, "Avg policy loss": 0.30643915163818747, "Total num played games": 34750, "Total num trained steps": 68736, "Timestamp in ms": 1701583812476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816978417266187, "Avg loss": 0.41183261340484023, "Avg value loss": 0.13261172553757206, "Avg policy loss": 0.27922088792547584, "Total num played games": 34750, "Total num trained steps": 68864, "Timestamp in ms": 1701583864230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985267034990792, "Avg loss": 0.36861095926724374, "Avg value loss": 0.10979627160122618, "Avg policy loss": 0.25881468993611634, "Total num played games": 34750, "Total num trained steps": 68992, "Timestamp in ms": 1701583915654, "logtype": "training_step"}
{"Avg objective": 21.2578125, "Games time in secs": 147.1371341496706, "Avg game time in secs": 2.4575713261583587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.64, "agent_stopped_0": 0.42}, "Total num played games": 34816, "Total num trained steps": 68996, "Timestamp in ms": 1701583917489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834710743801653, "Avg loss": 0.4830031858291477, "Avg value loss": 0.21334372804267332, "Avg policy loss": 0.2696594543522224, "Total num played games": 34848, "Total num trained steps": 69120, "Timestamp in ms": 1701583968015, "logtype": "training_step"}
{"Total num played games": 34942, "Total num trained steps": 69234, "Timestamp in ms": 1701584028274, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.19140625}
{"Avg objective": 20.3046875, "Games time in secs": 111.83118298836052, "Avg game time in secs": 2.4416453576704953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 34944, "Total num trained steps": 69235, "Timestamp in ms": 1701584029320, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765941656676371, "Avg loss": 0.5246301428414881, "Avg value loss": 0.2692418966325931, "Avg policy loss": 0.2553882380016148, "Total num played games": 35034, "Total num trained steps": 69248, "Timestamp in ms": 1701584034504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801347185751799, "Avg loss": 0.5222452930174768, "Avg value loss": 0.24228683701949194, "Avg policy loss": 0.2799584538443014, "Total num played games": 35036, "Total num trained steps": 69376, "Timestamp in ms": 1701584090890, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983788103664802, "Avg loss": 0.4460145803168416, "Avg value loss": 0.18682055501267314, "Avg policy loss": 0.2591940249549225, "Total num played games": 35036, "Total num trained steps": 69504, "Timestamp in ms": 1701584145617, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 145.20503819733858, "Avg game time in secs": 2.2031975561840227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 35072, "Total num trained steps": 69565, "Timestamp in ms": 1701584174525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820107024934532, "Avg loss": 0.460305814165622, "Avg value loss": 0.20350381528260186, "Avg policy loss": 0.2568019990576431, "Total num played games": 35132, "Total num trained steps": 69632, "Timestamp in ms": 1701584205145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822686974312345, "Avg loss": 0.37993310508318245, "Avg value loss": 0.14001982408808544, "Avg policy loss": 0.23991328268311918, "Total num played games": 35190, "Total num trained steps": 69760, "Timestamp in ms": 1701584262971, "logtype": "training_step"}
{"Avg objective": 20.0234375, "Games time in secs": 88.60175991989672, "Avg game time in secs": 2.213308539838181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 35200, "Total num trained steps": 69760, "Timestamp in ms": 1701584263127, "logtype": "played_game"}
{"Total num played games": 35226, "Total num trained steps": 69835, "Timestamp in ms": 1701584310337, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.75}
{"Ratio train steps to played games": 1.9787089467723669, "Avg loss": 0.6177235112991184, "Avg value loss": 0.3401160403736867, "Avg policy loss": 0.27760747028514743, "Total num played games": 35320, "Total num trained steps": 69888, "Timestamp in ms": 1701584334431, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823329558323897, "Avg loss": 0.42463088198564947, "Avg value loss": 0.15702247765148059, "Avg policy loss": 0.2676084025297314, "Total num played games": 35320, "Total num trained steps": 70016, "Timestamp in ms": 1701584393419, "logtype": "training_step"}
{"Avg objective": 19.6875, "Games time in secs": 181.24196216464043, "Avg game time in secs": 2.3124198714940576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 35328, "Total num trained steps": 70132, "Timestamp in ms": 1701584444369, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805737519765079, "Avg loss": 0.45015083090402186, "Avg value loss": 0.19468862423673272, "Avg policy loss": 0.25546220573596656, "Total num played games": 35416, "Total num trained steps": 70144, "Timestamp in ms": 1701584449436, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984187937655297, "Avg loss": 0.4937812630087137, "Avg value loss": 0.22860061540268362, "Avg policy loss": 0.2651806464418769, "Total num played games": 35416, "Total num trained steps": 70272, "Timestamp in ms": 1701584505117, "logtype": "training_step"}
{"Avg objective": 20.984375, "Games time in secs": 84.60057364217937, "Avg game time in secs": 2.1454388566926355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 35456, "Total num trained steps": 70326, "Timestamp in ms": 1701584528970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98242847488173, "Avg loss": 0.5221982472576201, "Avg value loss": 0.25734295893926173, "Avg policy loss": 0.26485529204364866, "Total num played games": 35512, "Total num trained steps": 70400, "Timestamp in ms": 1701584560378, "logtype": "training_step"}
{"Total num played games": 35512, "Total num trained steps": 70437, "Timestamp in ms": 1701584590914, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8359375}
{"Avg objective": 20.2109375, "Games time in secs": 65.75037802383304, "Avg game time in secs": 2.288727351115085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.65}, "Total num played games": 35584, "Total num trained steps": 70443, "Timestamp in ms": 1701584594720, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807897545357525, "Avg loss": 0.579295864328742, "Avg value loss": 0.31413461215561256, "Avg policy loss": 0.26516125223133713, "Total num played games": 35606, "Total num trained steps": 70528, "Timestamp in ms": 1701584633659, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984384654271752, "Avg loss": 0.3702310228254646, "Avg value loss": 0.12340565037447959, "Avg policy loss": 0.24682537524495274, "Total num played games": 35606, "Total num trained steps": 70656, "Timestamp in ms": 1701584692341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827450980392156, "Avg loss": 0.4985349935013801, "Avg value loss": 0.2406332883401774, "Avg policy loss": 0.2579016995150596, "Total num played games": 35700, "Total num trained steps": 70784, "Timestamp in ms": 1701584753176, "logtype": "training_step"}
{"Avg objective": 20.6015625, "Games time in secs": 210.7749450672418, "Avg game time in secs": 2.365263353975024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 35712, "Total num trained steps": 70892, "Timestamp in ms": 1701584805495, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811141532100351, "Avg loss": 0.48342200252227485, "Avg value loss": 0.22440302575705573, "Avg policy loss": 0.25901897775474936, "Total num played games": 35794, "Total num trained steps": 70912, "Timestamp in ms": 1701584814133, "logtype": "training_step"}
{"Total num played games": 35794, "Total num trained steps": 71037, "Timestamp in ms": 1701584882776, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1953125}
{"Ratio train steps to played games": 1.9843575418994412, "Avg loss": 0.4356547959614545, "Avg value loss": 0.17352971766376868, "Avg policy loss": 0.26212507765740156, "Total num played games": 35798, "Total num trained steps": 71040, "Timestamp in ms": 1701584885107, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 80.69083911180496, "Avg game time in secs": 2.108288396295393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 35840, "Total num trained steps": 71042, "Timestamp in ms": 1701584886186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830305394560857, "Avg loss": 0.5054653964471072, "Avg value loss": 0.2454014185932465, "Avg policy loss": 0.2600639780284837, "Total num played games": 35888, "Total num trained steps": 71168, "Timestamp in ms": 1701584945460, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 107.65100246109068, "Avg game time in secs": 2.1928246130701154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 35968, "Total num trained steps": 71273, "Timestamp in ms": 1701584993837, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981435162025457, "Avg loss": 0.44702745834365487, "Avg value loss": 0.19908823654986918, "Avg policy loss": 0.24793921876698732, "Total num played games": 35982, "Total num trained steps": 71296, "Timestamp in ms": 1701585003731, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984992496248124, "Avg loss": 0.415305437752977, "Avg value loss": 0.15551078628050163, "Avg policy loss": 0.25979465153068304, "Total num played games": 35982, "Total num trained steps": 71424, "Timestamp in ms": 1701585062542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832584954820112, "Avg loss": 0.5776460429187864, "Avg value loss": 0.3170619246084243, "Avg policy loss": 0.2605841230833903, "Total num played games": 36078, "Total num trained steps": 71552, "Timestamp in ms": 1701585123610, "logtype": "training_step"}
{"Total num played games": 36078, "Total num trained steps": 71637, "Timestamp in ms": 1701585173462, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.94140625}
{"Avg objective": 20.7578125, "Games time in secs": 182.20018958859146, "Avg game time in secs": 2.1207414633827284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 36096, "Total num trained steps": 71640, "Timestamp in ms": 1701585176038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981643259980095, "Avg loss": 0.5128297384362668, "Avg value loss": 0.25178544607479125, "Avg policy loss": 0.2610442922450602, "Total num played games": 36172, "Total num trained steps": 71680, "Timestamp in ms": 1701585194735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985181908658631, "Avg loss": 0.42911279504187405, "Avg value loss": 0.15442007238743827, "Avg policy loss": 0.2746927241096273, "Total num played games": 36172, "Total num trained steps": 71808, "Timestamp in ms": 1701585256309, "logtype": "training_step"}
{"Avg objective": 20.640625, "Games time in secs": 93.67149301990867, "Avg game time in secs": 2.206808491042466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 36224, "Total num trained steps": 71838, "Timestamp in ms": 1701585269709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835658743726907, "Avg loss": 0.514261340489611, "Avg value loss": 0.24751110427314416, "Avg policy loss": 0.2667502388358116, "Total num played games": 36266, "Total num trained steps": 71936, "Timestamp in ms": 1701585315941, "logtype": "training_step"}
{"Avg objective": 19.75, "Games time in secs": 88.89578999392688, "Avg game time in secs": 2.381623249981203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 36352, "Total num trained steps": 72029, "Timestamp in ms": 1701585358605, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981958195819582, "Avg loss": 0.46683799906168133, "Avg value loss": 0.20333275917801075, "Avg policy loss": 0.2635052372934297, "Total num played games": 36360, "Total num trained steps": 72064, "Timestamp in ms": 1701585373913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854510451045104, "Avg loss": 0.4019247971009463, "Avg value loss": 0.14256309246411547, "Avg policy loss": 0.25936170760542154, "Total num played games": 36360, "Total num trained steps": 72192, "Timestamp in ms": 1701585436769, "logtype": "training_step"}
{"Total num played games": 36454, "Total num trained steps": 72237, "Timestamp in ms": 1701585470034, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Avg objective": 19.828125, "Games time in secs": 114.0234755538404, "Avg game time in secs": 1.9260441092046676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 36480, "Total num trained steps": 72241, "Timestamp in ms": 1701585472629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787676480245158, "Avg loss": 0.643020705319941, "Avg value loss": 0.3610463243094273, "Avg policy loss": 0.2819743806030601, "Total num played games": 36548, "Total num trained steps": 72320, "Timestamp in ms": 1701585507436, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822698916493378, "Avg loss": 0.3826098721474409, "Avg value loss": 0.12003837595693767, "Avg policy loss": 0.26257149467710406, "Total num played games": 36548, "Total num trained steps": 72448, "Timestamp in ms": 1701585571056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98577213527416, "Avg loss": 0.34100729681085795, "Avg value loss": 0.09721968235680833, "Avg policy loss": 0.24378761171828955, "Total num played games": 36548, "Total num trained steps": 72576, "Timestamp in ms": 1701585625539, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 158.8628275822848, "Avg game time in secs": 1.8602427226578584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 36608, "Total num trained steps": 72588, "Timestamp in ms": 1701585631492, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840628752319616, "Avg loss": 0.47608239273540676, "Avg value loss": 0.2208185464842245, "Avg policy loss": 0.2552638436900452, "Total num played games": 36644, "Total num trained steps": 72704, "Timestamp in ms": 1701585681898, "logtype": "training_step"}
{"Avg objective": 19.9921875, "Games time in secs": 86.8828106559813, "Avg game time in secs": 2.3671422978222836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.7}, "Total num played games": 36736, "Total num trained steps": 72786, "Timestamp in ms": 1701585718375, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823353293413173, "Avg loss": 0.4271178203634918, "Avg value loss": 0.17889683606335893, "Avg policy loss": 0.24822098319418728, "Total num played games": 36740, "Total num trained steps": 72832, "Timestamp in ms": 1701585739605, "logtype": "training_step"}
{"Total num played games": 36740, "Total num trained steps": 72838, "Timestamp in ms": 1701585752887, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.19140625}
{"Ratio train steps to played games": 1.9807786284411142, "Avg loss": 0.5586359249427915, "Avg value loss": 0.2885520350537263, "Avg policy loss": 0.27008388203103095, "Total num played games": 36834, "Total num trained steps": 72960, "Timestamp in ms": 1701585806569, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842536786664495, "Avg loss": 0.35086073516868055, "Avg value loss": 0.10770951630547643, "Avg policy loss": 0.2431512187467888, "Total num played games": 36834, "Total num trained steps": 73088, "Timestamp in ms": 1701585863420, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 177.71873197704554, "Avg game time in secs": 1.933467812545132, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.54, "agent_stopped_0": 0.53}, "Total num played games": 36864, "Total num trained steps": 73161, "Timestamp in ms": 1701585896094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825616030327646, "Avg loss": 0.5217832780908793, "Avg value loss": 0.2722491026506759, "Avg policy loss": 0.24953417980577797, "Total num played games": 36930, "Total num trained steps": 73216, "Timestamp in ms": 1701585921930, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860276198212836, "Avg loss": 0.39268183428794146, "Avg value loss": 0.13463613856583834, "Avg policy loss": 0.2580456966534257, "Total num played games": 36930, "Total num trained steps": 73344, "Timestamp in ms": 1701585982334, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 90.45247519761324, "Avg game time in secs": 1.862850165052805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 36992, "Total num trained steps": 73354, "Timestamp in ms": 1701585986546, "logtype": "played_game"}
{"Total num played games": 37024, "Total num trained steps": 73441, "Timestamp in ms": 1701586038561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.05859375}
{"Ratio train steps to played games": 1.979416994450132, "Avg loss": 0.569123261841014, "Avg value loss": 0.31091129285050556, "Avg policy loss": 0.25821197335608304, "Total num played games": 37118, "Total num trained steps": 73472, "Timestamp in ms": 1701586053133, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982865456112937, "Avg loss": 0.44306290289387107, "Avg value loss": 0.18180484260665253, "Avg policy loss": 0.2612580623244867, "Total num played games": 37118, "Total num trained steps": 73600, "Timestamp in ms": 1701586113355, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 186.48306822031736, "Avg game time in secs": 2.079893362359144, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.69, "agent_stopped_0": 0.42}, "Total num played games": 37120, "Total num trained steps": 73727, "Timestamp in ms": 1701586173030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860998868595443, "Avg loss": 0.3449103560997173, "Avg value loss": 0.10961988975759596, "Avg policy loss": 0.23529046727344394, "Total num played games": 37122, "Total num trained steps": 73728, "Timestamp in ms": 1701586173167, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984736106632269, "Avg loss": 0.47930792439728975, "Avg value loss": 0.23390002344967797, "Avg policy loss": 0.24540790356695652, "Total num played games": 37212, "Total num trained steps": 73856, "Timestamp in ms": 1701586231996, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 87.54929512180388, "Avg game time in secs": 1.7283556307083927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 37248, "Total num trained steps": 73917, "Timestamp in ms": 1701586260579, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983166246716346, "Avg loss": 0.446902398718521, "Avg value loss": 0.20541427817079239, "Avg policy loss": 0.24148811784107238, "Total num played games": 37306, "Total num trained steps": 73984, "Timestamp in ms": 1701586292586, "logtype": "training_step"}
{"Total num played games": 37306, "Total num trained steps": 74044, "Timestamp in ms": 1701586328831, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.21875}
{"Avg objective": 20.25, "Games time in secs": 71.50206157565117, "Avg game time in secs": 1.8867498079343932, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 37376, "Total num trained steps": 74051, "Timestamp in ms": 1701586332081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816042780748664, "Avg loss": 0.46618892485275865, "Avg value loss": 0.2162005482823588, "Avg policy loss": 0.24998838047031313, "Total num played games": 37400, "Total num trained steps": 74112, "Timestamp in ms": 1701586360806, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850267379679145, "Avg loss": 0.34951940458267927, "Avg value loss": 0.11488529649795964, "Avg policy loss": 0.2346341070951894, "Total num played games": 37400, "Total num trained steps": 74240, "Timestamp in ms": 1701586421632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833582248773203, "Avg loss": 0.43391427653841674, "Avg value loss": 0.18874896815395914, "Avg policy loss": 0.2451653074240312, "Total num played games": 37496, "Total num trained steps": 74368, "Timestamp in ms": 1701586480071, "logtype": "training_step"}
{"Avg objective": 19.96875, "Games time in secs": 202.58896054886281, "Avg game time in secs": 1.955013476894237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 37504, "Total num trained steps": 74484, "Timestamp in ms": 1701586534671, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981803671189146, "Avg loss": 0.44038004986941814, "Avg value loss": 0.2040479122661054, "Avg policy loss": 0.23633213550783694, "Total num played games": 37590, "Total num trained steps": 74496, "Timestamp in ms": 1701586540014, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851822293163075, "Avg loss": 0.42792721558362246, "Avg value loss": 0.1933924820041284, "Avg policy loss": 0.2345347317168489, "Total num played games": 37590, "Total num trained steps": 74624, "Timestamp in ms": 1701586598992, "logtype": "training_step"}
{"Total num played games": 37590, "Total num trained steps": 74647, "Timestamp in ms": 1701586625882, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.44921875}
{"Avg objective": 20.59375, "Games time in secs": 94.29112523049116, "Avg game time in secs": 2.038146008766489, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 37632, "Total num trained steps": 74652, "Timestamp in ms": 1701586628962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836535399639104, "Avg loss": 0.4900700133293867, "Avg value loss": 0.23982344061369076, "Avg policy loss": 0.25024656869936734, "Total num played games": 37684, "Total num trained steps": 74752, "Timestamp in ms": 1701586675419, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 95.39569271914661, "Avg game time in secs": 1.9955983963009203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 37760, "Total num trained steps": 74863, "Timestamp in ms": 1701586724358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821059876118376, "Avg loss": 0.3959286432946101, "Avg value loss": 0.16517452482366934, "Avg policy loss": 0.23075411457102746, "Total num played games": 37778, "Total num trained steps": 74880, "Timestamp in ms": 1701586731846, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854942029752767, "Avg loss": 0.3994317250326276, "Avg value loss": 0.16040001256624237, "Avg policy loss": 0.23903170716948807, "Total num played games": 37778, "Total num trained steps": 75008, "Timestamp in ms": 1701586788000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838411575223107, "Avg loss": 0.48427708074450493, "Avg value loss": 0.24338168202666566, "Avg policy loss": 0.24089539982378483, "Total num played games": 37874, "Total num trained steps": 75136, "Timestamp in ms": 1701586843917, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 166.5236734636128, "Avg game time in secs": 2.0519067647255724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 37888, "Total num trained steps": 75240, "Timestamp in ms": 1701586890882, "logtype": "played_game"}
{"Total num played games": 37968, "Total num trained steps": 75247, "Timestamp in ms": 1701586904679, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1171875}
{"Avg objective": 20.5, "Games time in secs": 16.83629783242941, "Avg game time in secs": 1.9704830705013592, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 38016, "Total num trained steps": 75253, "Timestamp in ms": 1701586907718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773790131890074, "Avg loss": 0.464350406662561, "Avg value loss": 0.23860784893622622, "Avg policy loss": 0.22574255836661905, "Total num played games": 38062, "Total num trained steps": 75264, "Timestamp in ms": 1701586912489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807682202721875, "Avg loss": 0.521358841098845, "Avg value loss": 0.26533070782897994, "Avg policy loss": 0.25602813123259693, "Total num played games": 38062, "Total num trained steps": 75392, "Timestamp in ms": 1701586970613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841048815091167, "Avg loss": 0.3319497685879469, "Avg value loss": 0.10317741171456873, "Avg policy loss": 0.2287723554763943, "Total num played games": 38062, "Total num trained steps": 75520, "Timestamp in ms": 1701587030013, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 165.72637410275638, "Avg game time in secs": 1.9605884294142015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 38144, "Total num trained steps": 75617, "Timestamp in ms": 1701587073445, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825977565782578, "Avg loss": 0.41583553864620626, "Avg value loss": 0.1866276290093083, "Avg policy loss": 0.22920790768694133, "Total num played games": 38156, "Total num trained steps": 75648, "Timestamp in ms": 1701587087160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859524059125695, "Avg loss": 0.3690191158093512, "Avg value loss": 0.12866121984552592, "Avg policy loss": 0.2403578950325027, "Total num played games": 38156, "Total num trained steps": 75776, "Timestamp in ms": 1701587145054, "logtype": "training_step"}
{"Total num played games": 38254, "Total num trained steps": 75848, "Timestamp in ms": 1701587188385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1484375}
{"Avg objective": 19.9765625, "Games time in secs": 117.03561872057617, "Avg game time in secs": 1.8909989946696442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 38272, "Total num trained steps": 75850, "Timestamp in ms": 1701587190482, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793470324397622, "Avg loss": 0.6728658005595207, "Avg value loss": 0.4074958255223464, "Avg policy loss": 0.26536997442599386, "Total num played games": 38348, "Total num trained steps": 75904, "Timestamp in ms": 1701587214274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982684885782831, "Avg loss": 0.3965795000549406, "Avg value loss": 0.14266212860820815, "Avg policy loss": 0.2539173678960651, "Total num played games": 38348, "Total num trained steps": 76032, "Timestamp in ms": 1701587273518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860227391258995, "Avg loss": 0.32234952552244067, "Avg value loss": 0.09288325111265294, "Avg policy loss": 0.2294662749627605, "Total num played games": 38348, "Total num trained steps": 76160, "Timestamp in ms": 1701587330876, "logtype": "training_step"}
{"Avg objective": 19.9375, "Games time in secs": 152.25594168901443, "Avg game time in secs": 1.8913416245486587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 38400, "Total num trained steps": 76189, "Timestamp in ms": 1701587342738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.4334792917361483, "Avg value loss": 0.192047078802716, "Avg policy loss": 0.24143221625126898, "Total num played games": 38442, "Total num trained steps": 76288, "Timestamp in ms": 1701587389751, "logtype": "training_step"}
{"Avg objective": 19.875, "Games time in secs": 91.0765552315861, "Avg game time in secs": 2.0492697686713655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 38528, "Total num trained steps": 76379, "Timestamp in ms": 1701587433815, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827711468604048, "Avg loss": 0.4309843733208254, "Avg value loss": 0.18746078765252605, "Avg policy loss": 0.24352358584292233, "Total num played games": 38540, "Total num trained steps": 76416, "Timestamp in ms": 1701587450685, "logtype": "training_step"}
{"Total num played games": 38540, "Total num trained steps": 76448, "Timestamp in ms": 1701587478678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9375}
{"Ratio train steps to played games": 1.9812600300253662, "Avg loss": 0.4854210016783327, "Avg value loss": 0.22200117958709598, "Avg policy loss": 0.26341982546728104, "Total num played games": 38634, "Total num trained steps": 76544, "Timestamp in ms": 1701587523119, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984547289951856, "Avg loss": 0.35197763820178807, "Avg value loss": 0.11129606334725395, "Avg policy loss": 0.2406815733993426, "Total num played games": 38634, "Total num trained steps": 76672, "Timestamp in ms": 1701587580385, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 187.38683365285397, "Avg game time in secs": 1.8987544593401253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 38656, "Total num trained steps": 76761, "Timestamp in ms": 1701587621202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830613509605453, "Avg loss": 0.4401908637955785, "Avg value loss": 0.19658860709751025, "Avg policy loss": 0.24360225652344525, "Total num played games": 38728, "Total num trained steps": 76800, "Timestamp in ms": 1701587640808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863664532121463, "Avg loss": 0.3689191120211035, "Avg value loss": 0.12574575387407094, "Avg policy loss": 0.2431733600096777, "Total num played games": 38728, "Total num trained steps": 76928, "Timestamp in ms": 1701587701299, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 92.26400786824524, "Avg game time in secs": 2.018240170466015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 38784, "Total num trained steps": 76949, "Timestamp in ms": 1701587713466, "logtype": "played_game"}
{"Total num played games": 38822, "Total num trained steps": 77050, "Timestamp in ms": 1701587772538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.91796875}
{"Ratio train steps to played games": 1.9827089337175792, "Avg loss": 0.4675719639053568, "Avg value loss": 0.21965743793407455, "Avg policy loss": 0.24791452731005847, "Total num played games": 38862, "Total num trained steps": 77056, "Timestamp in ms": 1701587775428, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 63.94289047643542, "Avg game time in secs": 2.0753194696444552, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.67, "agent_stopped_0": 0.41}, "Total num played games": 38912, "Total num trained steps": 77060, "Timestamp in ms": 1701587777409, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833487511563368, "Avg loss": 0.46906590834259987, "Avg value loss": 0.2106974016642198, "Avg policy loss": 0.25836851040367037, "Total num played games": 38916, "Total num trained steps": 77184, "Timestamp in ms": 1701587834132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866378867303938, "Avg loss": 0.32854358095210046, "Avg value loss": 0.09691952570574358, "Avg policy loss": 0.23162405309267342, "Total num played games": 38916, "Total num trained steps": 77312, "Timestamp in ms": 1701587895260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851320174314278, "Avg loss": 0.5201195448171347, "Avg value loss": 0.26619922535610385, "Avg policy loss": 0.2539203204214573, "Total num played games": 39010, "Total num trained steps": 77440, "Timestamp in ms": 1701587953096, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 210.53922649659216, "Avg game time in secs": 1.7971657985763159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 39040, "Total num trained steps": 77513, "Timestamp in ms": 1701587987949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836333878887071, "Avg loss": 0.4734537214972079, "Avg value loss": 0.22359154440346174, "Avg policy loss": 0.249862176948227, "Total num played games": 39104, "Total num trained steps": 77568, "Timestamp in ms": 1701588013679, "logtype": "training_step"}
{"Total num played games": 39104, "Total num trained steps": 77650, "Timestamp in ms": 1701588063323, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2109375}
{"Avg objective": 20.75, "Games time in secs": 78.70454378798604, "Avg game time in secs": 1.934518729482079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 39168, "Total num trained steps": 77657, "Timestamp in ms": 1701588066658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821164345119648, "Avg loss": 0.4899639303330332, "Avg value loss": 0.22915977757656947, "Avg policy loss": 0.26080415199976414, "Total num played games": 39198, "Total num trained steps": 77696, "Timestamp in ms": 1701588084127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854074187458544, "Avg loss": 0.36515247146598995, "Avg value loss": 0.11427765706321225, "Avg policy loss": 0.25087481341324747, "Total num played games": 39198, "Total num trained steps": 77824, "Timestamp in ms": 1701588142100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839153008245953, "Avg loss": 0.43717626680154353, "Avg value loss": 0.18852090337895788, "Avg policy loss": 0.24865536682773381, "Total num played games": 39292, "Total num trained steps": 77952, "Timestamp in ms": 1701588200944, "logtype": "training_step"}
{"Avg objective": 20.1796875, "Games time in secs": 194.8317735120654, "Avg game time in secs": 2.110532577687991, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 39296, "Total num trained steps": 78075, "Timestamp in ms": 1701588261490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826316591336144, "Avg loss": 0.350216303486377, "Avg value loss": 0.10137451282935217, "Avg policy loss": 0.24884179153013974, "Total num played games": 39382, "Total num trained steps": 78080, "Timestamp in ms": 1701588263877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856548011983954, "Avg loss": 0.4862597845494747, "Avg value loss": 0.21496415365254506, "Avg policy loss": 0.2712956303730607, "Total num played games": 39386, "Total num trained steps": 78208, "Timestamp in ms": 1701588322056, "logtype": "training_step"}
{"Total num played games": 39386, "Total num trained steps": 78250, "Timestamp in ms": 1701588350719, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.296875}
{"Avg objective": 20.7890625, "Games time in secs": 92.07944820448756, "Avg game time in secs": 1.7750990644854028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.5}, "Total num played games": 39424, "Total num trained steps": 78255, "Timestamp in ms": 1701588353570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98419452887538, "Avg loss": 0.4728535411413759, "Avg value loss": 0.2086209477565717, "Avg policy loss": 0.2642325960332528, "Total num played games": 39480, "Total num trained steps": 78336, "Timestamp in ms": 1701588390100, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 90.01988830603659, "Avg game time in secs": 1.812460849105264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 39552, "Total num trained steps": 78453, "Timestamp in ms": 1701588443590, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826906554808712, "Avg loss": 0.3877551641780883, "Avg value loss": 0.13417195237707347, "Avg policy loss": 0.2535832148278132, "Total num played games": 39574, "Total num trained steps": 78464, "Timestamp in ms": 1701588448152, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859503714560065, "Avg loss": 0.41547613544389606, "Avg value loss": 0.15308506062137894, "Avg policy loss": 0.262391074327752, "Total num played games": 39574, "Total num trained steps": 78592, "Timestamp in ms": 1701588505800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843710612553567, "Avg loss": 0.42938078357838094, "Avg value loss": 0.17835640028351918, "Avg policy loss": 0.2510243826545775, "Total num played games": 39670, "Total num trained steps": 78720, "Timestamp in ms": 1701588564717, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 171.83594402857125, "Avg game time in secs": 1.915629547496792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.68}, "Total num played games": 39680, "Total num trained steps": 78832, "Timestamp in ms": 1701588615426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828739563424203, "Avg loss": 0.40893175546079874, "Avg value loss": 0.1658884481585119, "Avg policy loss": 0.2430433080298826, "Total num played games": 39764, "Total num trained steps": 78848, "Timestamp in ms": 1701588621547, "logtype": "training_step"}
{"Total num played games": 39764, "Total num trained steps": 78853, "Timestamp in ms": 1701588635745, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.33203125}
{"Avg objective": 21.1640625, "Games time in secs": 23.197780776768923, "Avg game time in secs": 1.8613716119871242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 39808, "Total num trained steps": 78858, "Timestamp in ms": 1701588638624, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981434091023132, "Avg loss": 0.5694237339776009, "Avg value loss": 0.28734775295015424, "Avg policy loss": 0.2820759832393378, "Total num played games": 39858, "Total num trained steps": 78976, "Timestamp in ms": 1701588692719, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846454914948066, "Avg loss": 0.34510394278913736, "Avg value loss": 0.09588311373954639, "Avg policy loss": 0.24922083073761314, "Total num played games": 39858, "Total num trained steps": 79104, "Timestamp in ms": 1701588753467, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 165.78147025220096, "Avg game time in secs": 2.063618734362535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 39936, "Total num trained steps": 79212, "Timestamp in ms": 1701588804406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830805426240177, "Avg loss": 0.3961765624117106, "Avg value loss": 0.1587843183078803, "Avg policy loss": 0.23739224788732827, "Total num played games": 39954, "Total num trained steps": 79232, "Timestamp in ms": 1701588813025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98628422686089, "Avg loss": 0.41682190261781216, "Avg value loss": 0.1494614826515317, "Avg policy loss": 0.2673604207811877, "Total num played games": 39954, "Total num trained steps": 79360, "Timestamp in ms": 1701588872548, "logtype": "training_step"}
{"Total num played games": 40048, "Total num trained steps": 79454, "Timestamp in ms": 1701588926936, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.41796875}
{"Avg objective": 20.8359375, "Games time in secs": 124.80009855143726, "Avg game time in secs": 1.9753270479559433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 40064, "Total num trained steps": 79459, "Timestamp in ms": 1701588929206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801703950974041, "Avg loss": 0.5911426472011954, "Avg value loss": 0.32189632987137884, "Avg policy loss": 0.26924632024019957, "Total num played games": 40142, "Total num trained steps": 79488, "Timestamp in ms": 1701588942544, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833590752827464, "Avg loss": 0.42607908020727336, "Avg value loss": 0.1484660553978756, "Avg policy loss": 0.27761302480939776, "Total num played games": 40142, "Total num trained steps": 79616, "Timestamp in ms": 1701589000553, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865477554680884, "Avg loss": 0.3455632139230147, "Avg value loss": 0.09517788179800846, "Avg policy loss": 0.2503853316884488, "Total num played games": 40142, "Total num trained steps": 79744, "Timestamp in ms": 1701589058198, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 143.76342990994453, "Avg game time in secs": 2.0126293900830206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.66}, "Total num played games": 40192, "Total num trained steps": 79777, "Timestamp in ms": 1701589072969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850879809126156, "Avg loss": 0.47182123828679323, "Avg value loss": 0.20193216518964618, "Avg policy loss": 0.26988906564656645, "Total num played games": 40236, "Total num trained steps": 79872, "Timestamp in ms": 1701589116029, "logtype": "training_step"}
{"Avg objective": 19.84375, "Games time in secs": 87.53419024683535, "Avg game time in secs": 2.1388658529904205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 40320, "Total num trained steps": 79968, "Timestamp in ms": 1701589160504, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983635011157947, "Avg loss": 0.4425822503399104, "Avg value loss": 0.1904338279273361, "Avg policy loss": 0.25214842159766704, "Total num played games": 40330, "Total num trained steps": 80000, "Timestamp in ms": 1701589175457, "logtype": "training_step"}
{"Total num played games": 40330, "Total num trained steps": 80054, "Timestamp in ms": 1701589213236, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.73828125}
{"Ratio train steps to played games": 1.9821887987334257, "Avg loss": 0.5107663266826421, "Avg value loss": 0.24066506925737485, "Avg policy loss": 0.2701012579491362, "Total num played games": 40424, "Total num trained steps": 80128, "Timestamp in ms": 1701589248009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98535523451415, "Avg loss": 0.3574642960447818, "Avg value loss": 0.10441610385896638, "Avg policy loss": 0.25304818991571665, "Total num played games": 40424, "Total num trained steps": 80256, "Timestamp in ms": 1701589303608, "logtype": "training_step"}
{"Avg objective": 20.46875, "Games time in secs": 181.5024639889598, "Avg game time in secs": 1.862622703993111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 40448, "Total num trained steps": 80339, "Timestamp in ms": 1701589342006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839083863961695, "Avg loss": 0.4206139015732333, "Avg value loss": 0.1710683437413536, "Avg policy loss": 0.249545558122918, "Total num played games": 40518, "Total num trained steps": 80384, "Timestamp in ms": 1701589362325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870674761834246, "Avg loss": 0.3844037102535367, "Avg value loss": 0.12216291500953957, "Avg policy loss": 0.26224079402163625, "Total num played games": 40518, "Total num trained steps": 80512, "Timestamp in ms": 1701589418118, "logtype": "training_step"}
{"Avg objective": 20.2890625, "Games time in secs": 84.26728297956288, "Avg game time in secs": 1.8999249793268973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 40576, "Total num trained steps": 80530, "Timestamp in ms": 1701589426274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985522233712513, "Avg loss": 0.5163861596956849, "Avg value loss": 0.25154207897139713, "Avg policy loss": 0.26484407554380596, "Total num played games": 40614, "Total num trained steps": 80640, "Timestamp in ms": 1701589477089, "logtype": "training_step"}
{"Total num played games": 40614, "Total num trained steps": 80657, "Timestamp in ms": 1701589498198, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.36328125}
{"Avg objective": 20.0234375, "Games time in secs": 76.61759257130325, "Avg game time in secs": 2.1610360863705864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.72, "agent_stopped_0": 0.34}, "Total num played games": 40704, "Total num trained steps": 80665, "Timestamp in ms": 1701589502891, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840817529723886, "Avg loss": 0.517817439045757, "Avg value loss": 0.23556172801181674, "Avg policy loss": 0.2822557110339403, "Total num played games": 40708, "Total num trained steps": 80768, "Timestamp in ms": 1701589550399, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872260980642626, "Avg loss": 0.37732454435899854, "Avg value loss": 0.11281034373678267, "Avg policy loss": 0.26451419945806265, "Total num played games": 40708, "Total num trained steps": 80896, "Timestamp in ms": 1701589610138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857850105386992, "Avg loss": 0.5284840357489884, "Avg value loss": 0.2492580316029489, "Avg policy loss": 0.27922600717283785, "Total num played games": 40802, "Total num trained steps": 81024, "Timestamp in ms": 1701589667373, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 196.82519781775773, "Avg game time in secs": 1.7091252830432495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 40832, "Total num trained steps": 81096, "Timestamp in ms": 1701589699717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843505477308294, "Avg loss": 0.4756959609221667, "Avg value loss": 0.20693555785692297, "Avg policy loss": 0.268760402337648, "Total num played games": 40896, "Total num trained steps": 81152, "Timestamp in ms": 1701589725852, "logtype": "training_step"}
{"Total num played games": 40896, "Total num trained steps": 81257, "Timestamp in ms": 1701589785453, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.55859375}
{"Avg objective": 21.28125, "Games time in secs": 88.91158626973629, "Avg game time in secs": 2.0170277597062523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 40960, "Total num trained steps": 81262, "Timestamp in ms": 1701589788631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828982678702123, "Avg loss": 0.48245469434186816, "Avg value loss": 0.2108644281688612, "Avg policy loss": 0.2715902649797499, "Total num played games": 40990, "Total num trained steps": 81280, "Timestamp in ms": 1701589796020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860453769212003, "Avg loss": 0.4313258135225624, "Avg value loss": 0.15496620410704054, "Avg policy loss": 0.27635960606858134, "Total num played games": 40990, "Total num trained steps": 81408, "Timestamp in ms": 1701589852481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846168824846655, "Avg loss": 0.5532279759645462, "Avg value loss": 0.2813590058067348, "Avg policy loss": 0.2718689696630463, "Total num played games": 41084, "Total num trained steps": 81536, "Timestamp in ms": 1701589910542, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 177.81792384386063, "Avg game time in secs": 1.9505965379503323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 41088, "Total num trained steps": 81658, "Timestamp in ms": 1701589966449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835802769006559, "Avg loss": 0.3790099141187966, "Avg value loss": 0.10930927452864125, "Avg policy loss": 0.26970063790213317, "Total num played games": 41170, "Total num trained steps": 81664, "Timestamp in ms": 1701589968519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862790810627033, "Avg loss": 0.47397488402202725, "Avg value loss": 0.19718590180855244, "Avg policy loss": 0.27678898128215224, "Total num played games": 41178, "Total num trained steps": 81792, "Timestamp in ms": 1701590031067, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 89.83166339807212, "Avg game time in secs": 1.7033181676524691, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 41216, "Total num trained steps": 81848, "Timestamp in ms": 1701590056281, "logtype": "played_game"}
{"Total num played games": 41274, "Total num trained steps": 81857, "Timestamp in ms": 1701590071088, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.34765625}
{"Avg objective": 19.8671875, "Games time in secs": 18.201441194862127, "Avg game time in secs": 1.8724701406317763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 41344, "Total num trained steps": 81863, "Timestamp in ms": 1701590074483, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802746083929608, "Avg loss": 0.6530195588711649, "Avg value loss": 0.36713441539905034, "Avg policy loss": 0.28588514297734946, "Total num played games": 41368, "Total num trained steps": 81920, "Timestamp in ms": 1701590100035, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833687874685748, "Avg loss": 0.3944457380566746, "Avg value loss": 0.11896477855043486, "Avg policy loss": 0.2754809594480321, "Total num played games": 41368, "Total num trained steps": 82048, "Timestamp in ms": 1701590158206, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864629665441886, "Avg loss": 0.3428994251880795, "Avg value loss": 0.08727270551025867, "Avg policy loss": 0.2556267234031111, "Total num played games": 41368, "Total num trained steps": 82176, "Timestamp in ms": 1701590213197, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850465486469537, "Avg loss": 0.44204774405807257, "Avg value loss": 0.18152308373828419, "Avg policy loss": 0.2605246618622914, "Total num played games": 41462, "Total num trained steps": 82304, "Timestamp in ms": 1701590270666, "logtype": "training_step"}
{"Avg objective": 19.9609375, "Games time in secs": 246.8468541316688, "Avg game time in secs": 1.8709629905497422, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 41472, "Total num trained steps": 82415, "Timestamp in ms": 1701590321330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836365386466455, "Avg loss": 0.41441811295226216, "Avg value loss": 0.16110175487119704, "Avg policy loss": 0.2533163580810651, "Total num played games": 41556, "Total num trained steps": 82432, "Timestamp in ms": 1701590329941, "logtype": "training_step"}
{"Total num played games": 41556, "Total num trained steps": 82459, "Timestamp in ms": 1701590354526, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.35546875}
{"Avg objective": 19.9453125, "Games time in secs": 35.81160839088261, "Avg game time in secs": 1.7465301119082142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 41600, "Total num trained steps": 82462, "Timestamp in ms": 1701590357142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822328931572628, "Avg loss": 0.5117129960563034, "Avg value loss": 0.23948342783842236, "Avg policy loss": 0.27222956833429635, "Total num played games": 41650, "Total num trained steps": 82560, "Timestamp in ms": 1701590402258, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853061224489796, "Avg loss": 0.3566675172187388, "Avg value loss": 0.11300744628533721, "Avg policy loss": 0.2436600694200024, "Total num played games": 41650, "Total num trained steps": 82688, "Timestamp in ms": 1701590458965, "logtype": "training_step"}
{"Avg objective": 19.7890625, "Games time in secs": 150.73586660064757, "Avg game time in secs": 1.7979543990368256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.6, "agent_stopped_0": 0.46}, "Total num played games": 41728, "Total num trained steps": 82795, "Timestamp in ms": 1701590507878, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98390187811422, "Avg loss": 0.43233072210568935, "Avg value loss": 0.17653969005914405, "Avg policy loss": 0.25579103536438197, "Total num played games": 41744, "Total num trained steps": 82816, "Timestamp in ms": 1701590517972, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869681870448448, "Avg loss": 0.38821159303188324, "Avg value loss": 0.12756427278509364, "Avg policy loss": 0.260647319839336, "Total num played games": 41744, "Total num trained steps": 82944, "Timestamp in ms": 1701590579733, "logtype": "training_step"}
{"Total num played games": 41838, "Total num trained steps": 83061, "Timestamp in ms": 1701590644134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0390625}
{"Avg objective": 21.65625, "Games time in secs": 138.3337543606758, "Avg game time in secs": 1.9663830437057186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 41856, "Total num trained steps": 83062, "Timestamp in ms": 1701590646212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981112277019937, "Avg loss": 0.511346792569384, "Avg value loss": 0.23659583649714477, "Avg policy loss": 0.27475095773115754, "Total num played games": 41932, "Total num trained steps": 83072, "Timestamp in ms": 1701590650740, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841409901745684, "Avg loss": 0.5007718498818576, "Avg value loss": 0.2170897001051344, "Avg policy loss": 0.2836821504170075, "Total num played games": 41932, "Total num trained steps": 83200, "Timestamp in ms": 1701590708563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872173995993514, "Avg loss": 0.38064712146297097, "Avg value loss": 0.12966894608689472, "Avg policy loss": 0.25097817787900567, "Total num played games": 41932, "Total num trained steps": 83328, "Timestamp in ms": 1701590769923, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 136.24744052812457, "Avg game time in secs": 1.654948662398965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 41984, "Total num trained steps": 83357, "Timestamp in ms": 1701590782459, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858183029553134, "Avg loss": 0.5068804782349616, "Avg value loss": 0.22852238442283124, "Avg policy loss": 0.27835809416137636, "Total num played games": 42026, "Total num trained steps": 83456, "Timestamp in ms": 1701590827472, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 87.82555883191526, "Avg game time in secs": 1.9005515411117813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 42112, "Total num trained steps": 83547, "Timestamp in ms": 1701590870285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843312283367363, "Avg loss": 0.4944547894410789, "Avg value loss": 0.2164823655039072, "Avg policy loss": 0.2779724224237725, "Total num played games": 42122, "Total num trained steps": 83584, "Timestamp in ms": 1701590886513, "logtype": "training_step"}
{"Total num played games": 42122, "Total num trained steps": 83661, "Timestamp in ms": 1701590933499, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.953125}
{"Ratio train steps to played games": 1.9829211673299223, "Avg loss": 0.5066626381594688, "Avg value loss": 0.21828573290258646, "Avg policy loss": 0.28837690444197506, "Total num played games": 42216, "Total num trained steps": 83712, "Timestamp in ms": 1701590959313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859768808034868, "Avg loss": 0.39590789494104683, "Avg value loss": 0.1176145767676644, "Avg policy loss": 0.27829331951215863, "Total num played games": 42216, "Total num trained steps": 83840, "Timestamp in ms": 1701591021935, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 186.8732969071716, "Avg game time in secs": 1.8468721905519487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 42240, "Total num trained steps": 83924, "Timestamp in ms": 1701591057158, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984589931458284, "Avg loss": 0.4678991436958313, "Avg value loss": 0.2003735214821063, "Avg policy loss": 0.26752562168985605, "Total num played games": 42310, "Total num trained steps": 83968, "Timestamp in ms": 1701591077120, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987615220987946, "Avg loss": 0.38886436517350376, "Avg value loss": 0.11481579288374633, "Avg policy loss": 0.2740485717076808, "Total num played games": 42310, "Total num trained steps": 84096, "Timestamp in ms": 1701591137553, "logtype": "training_step"}
{"Avg objective": 19.7578125, "Games time in secs": 88.1870183609426, "Avg game time in secs": 1.7750679248420056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 42368, "Total num trained steps": 84113, "Timestamp in ms": 1701591145345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862277143665692, "Avg loss": 0.4774681990966201, "Avg value loss": 0.19223909842548892, "Avg policy loss": 0.2852291021263227, "Total num played games": 42404, "Total num trained steps": 84224, "Timestamp in ms": 1701591192517, "logtype": "training_step"}
{"Total num played games": 42404, "Total num trained steps": 84264, "Timestamp in ms": 1701591221870, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.296875}
{"Avg objective": 20.9375, "Games time in secs": 80.89831913262606, "Avg game time in secs": 1.9418190974829486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 42496, "Total num trained steps": 84273, "Timestamp in ms": 1701591226244, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848463457103864, "Avg loss": 0.4940604434814304, "Avg value loss": 0.21111189349903725, "Avg policy loss": 0.28294855018612, "Total num played games": 42498, "Total num trained steps": 84352, "Timestamp in ms": 1701591261442, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878347216339591, "Avg loss": 0.35074218292720616, "Avg value loss": 0.08935158848180436, "Avg policy loss": 0.26139059325214475, "Total num played games": 42498, "Total num trained steps": 84480, "Timestamp in ms": 1701591320607, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863830586467577, "Avg loss": 0.4403816012199968, "Avg value loss": 0.1695246849267278, "Avg policy loss": 0.2708569166716188, "Total num played games": 42594, "Total num trained steps": 84608, "Timestamp in ms": 1701591377273, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 183.9015062060207, "Avg game time in secs": 1.6824534916086122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 42624, "Total num trained steps": 84680, "Timestamp in ms": 1701591410146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985007496251874, "Avg loss": 0.46286802645772696, "Avg value loss": 0.20269807346630841, "Avg policy loss": 0.2601699507795274, "Total num played games": 42688, "Total num trained steps": 84736, "Timestamp in ms": 1701591434785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879825712143928, "Avg loss": 0.38286487641744316, "Avg value loss": 0.1275637627695687, "Avg policy loss": 0.25530111347325146, "Total num played games": 42688, "Total num trained steps": 84864, "Timestamp in ms": 1701591493834, "logtype": "training_step"}
{"Total num played games": 42688, "Total num trained steps": 84864, "Timestamp in ms": 1701591503863, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.15234375}
{"Avg objective": 20.828125, "Games time in secs": 96.71979219652712, "Avg game time in secs": 1.6892554324440425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 42752, "Total num trained steps": 84870, "Timestamp in ms": 1701591506866, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986629891075686, "Avg loss": 0.4693615201395005, "Avg value loss": 0.20593334108707495, "Avg policy loss": 0.26342817838303745, "Total num played games": 42782, "Total num trained steps": 84992, "Timestamp in ms": 1701591563000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852364959417856, "Avg loss": 0.46860109141562134, "Avg value loss": 0.20614119427045807, "Avg policy loss": 0.26245989568997175, "Total num played games": 42876, "Total num trained steps": 85120, "Timestamp in ms": 1701591618376, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 165.76792387664318, "Avg game time in secs": 1.9246384978177957, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.7, "agent_stopped_0": 0.37}, "Total num played games": 42880, "Total num trained steps": 85243, "Timestamp in ms": 1701591672634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983964811022156, "Avg loss": 0.34291968680918217, "Avg value loss": 0.08416825003223494, "Avg policy loss": 0.25875143927987665, "Total num played games": 42962, "Total num trained steps": 85248, "Timestamp in ms": 1701591674510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868745636490575, "Avg loss": 0.4392829374410212, "Avg value loss": 0.17350632589659654, "Avg policy loss": 0.2657766086049378, "Total num played games": 42970, "Total num trained steps": 85376, "Timestamp in ms": 1701591729926, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 82.84864698164165, "Avg game time in secs": 1.6147043207893148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 43008, "Total num trained steps": 85434, "Timestamp in ms": 1701591755482, "logtype": "played_game"}
{"Total num played games": 43066, "Total num trained steps": 85464, "Timestamp in ms": 1701591780794, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4609375}
{"Avg objective": 20.328125, "Games time in secs": 29.050277585163713, "Avg game time in secs": 1.894502226045006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.69, "agent_stopped_0": 0.37}, "Total num played games": 43136, "Total num trained steps": 85470, "Timestamp in ms": 1701591784533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810936051899908, "Avg loss": 0.598070819163695, "Avg value loss": 0.32511653294204734, "Avg policy loss": 0.2729542813031003, "Total num played games": 43160, "Total num trained steps": 85504, "Timestamp in ms": 1701591799457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840593141797962, "Avg loss": 0.40913288248702884, "Avg value loss": 0.12648887687828392, "Avg policy loss": 0.2826440056087449, "Total num played games": 43160, "Total num trained steps": 85632, "Timestamp in ms": 1701591858759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870018535681186, "Avg loss": 0.35596698825247586, "Avg value loss": 0.10020274456473999, "Avg policy loss": 0.25576424377504736, "Total num played games": 43160, "Total num trained steps": 85760, "Timestamp in ms": 1701591917480, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855742555945997, "Avg loss": 0.4724416583776474, "Avg value loss": 0.21054973822901957, "Avg policy loss": 0.2618919244268909, "Total num played games": 43256, "Total num trained steps": 85888, "Timestamp in ms": 1701591975871, "logtype": "training_step"}
{"Avg objective": 20.46875, "Games time in secs": 242.4774261917919, "Avg game time in secs": 1.8033732054027496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 43264, "Total num trained steps": 86003, "Timestamp in ms": 1701592027010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842214532871971, "Avg loss": 0.40428729145787656, "Avg value loss": 0.15671474605915137, "Avg policy loss": 0.24757254624273628, "Total num played games": 43350, "Total num trained steps": 86016, "Timestamp in ms": 1701592032068, "logtype": "training_step"}
{"Total num played games": 43350, "Total num trained steps": 86066, "Timestamp in ms": 1701592066779, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4453125}
{"Avg objective": 20.6953125, "Games time in secs": 42.235202779993415, "Avg game time in secs": 1.685689085017657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 43392, "Total num trained steps": 86070, "Timestamp in ms": 1701592069246, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828745051100267, "Avg loss": 0.6579108557198197, "Avg value loss": 0.36587059654993936, "Avg policy loss": 0.2920402567833662, "Total num played games": 43444, "Total num trained steps": 86144, "Timestamp in ms": 1701592104476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858208268115274, "Avg loss": 0.36910763941705227, "Avg value loss": 0.09978791276807897, "Avg policy loss": 0.26931972918100655, "Total num played games": 43444, "Total num trained steps": 86272, "Timestamp in ms": 1701592167210, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 149.41854749061167, "Avg game time in secs": 1.7397257656557485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 43520, "Total num trained steps": 86381, "Timestamp in ms": 1701592218664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843821773082224, "Avg loss": 0.3842376278480515, "Avg value loss": 0.12575231160735711, "Avg policy loss": 0.25848531967494637, "Total num played games": 43540, "Total num trained steps": 86400, "Timestamp in ms": 1701592227859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873220027560863, "Avg loss": 0.3809561771340668, "Avg value loss": 0.10983135373680852, "Avg policy loss": 0.27112482429947704, "Total num played games": 43540, "Total num trained steps": 86528, "Timestamp in ms": 1701592287173, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985974240271348, "Avg loss": 0.4653969733044505, "Avg value loss": 0.19020151856238954, "Avg policy loss": 0.2751954559935257, "Total num played games": 43634, "Total num trained steps": 86656, "Timestamp in ms": 1701592343401, "logtype": "training_step"}
{"Total num played games": 43634, "Total num trained steps": 86669, "Timestamp in ms": 1701592361833, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3203125}
{"Avg objective": 20.3046875, "Games time in secs": 145.26496285386384, "Avg game time in secs": 1.90795327082742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 43648, "Total num trained steps": 86672, "Timestamp in ms": 1701592363930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846322722283205, "Avg loss": 0.5127870764117688, "Avg value loss": 0.22290524357231334, "Avg policy loss": 0.2898818318499252, "Total num played games": 43728, "Total num trained steps": 86784, "Timestamp in ms": 1701592412969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875365898280277, "Avg loss": 0.39632434910163283, "Avg value loss": 0.12476019252790138, "Avg policy loss": 0.2715641555842012, "Total num played games": 43728, "Total num trained steps": 86912, "Timestamp in ms": 1701592467682, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 119.14378832653165, "Avg game time in secs": 1.7070144713070476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 43776, "Total num trained steps": 86949, "Timestamp in ms": 1701592483074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861263234757212, "Avg loss": 0.5143629158847034, "Avg value loss": 0.2280495563754812, "Avg policy loss": 0.28631336300168186, "Total num played games": 43824, "Total num trained steps": 87040, "Timestamp in ms": 1701592527244, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 92.46796545013785, "Avg game time in secs": 1.8936790523002855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 43904, "Total num trained steps": 87143, "Timestamp in ms": 1701592575542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846994535519125, "Avg loss": 0.45739321131259203, "Avg value loss": 0.1743362258421257, "Avg policy loss": 0.28305698779877275, "Total num played games": 43920, "Total num trained steps": 87168, "Timestamp in ms": 1701592586613, "logtype": "training_step"}
{"Total num played games": 43920, "Total num trained steps": 87273, "Timestamp in ms": 1701592647906, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.28125}
{"Ratio train steps to played games": 1.983368928068342, "Avg loss": 0.48333520675078034, "Avg value loss": 0.19813802832504734, "Avg policy loss": 0.2851971792988479, "Total num played games": 44014, "Total num trained steps": 87296, "Timestamp in ms": 1701592659777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862770936520198, "Avg loss": 0.4682418324518949, "Avg value loss": 0.17766155302524567, "Avg policy loss": 0.29058027418795973, "Total num played games": 44014, "Total num trained steps": 87424, "Timestamp in ms": 1701592719013, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 184.40361176989973, "Avg game time in secs": 1.693865596971591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 44032, "Total num trained steps": 87519, "Timestamp in ms": 1701592759945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849460415344156, "Avg loss": 0.42952675686683506, "Avg value loss": 0.1548534738831222, "Avg policy loss": 0.27467327914200723, "Total num played games": 44108, "Total num trained steps": 87552, "Timestamp in ms": 1701592773577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878480094313957, "Avg loss": 0.3893201523460448, "Avg value loss": 0.10651096879155375, "Avg policy loss": 0.2828091820701957, "Total num played games": 44108, "Total num trained steps": 87680, "Timestamp in ms": 1701592833975, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 86.34895447641611, "Avg game time in secs": 1.6869240340020042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 44160, "Total num trained steps": 87709, "Timestamp in ms": 1701592846294, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986426567731427, "Avg loss": 0.4532202628906816, "Avg value loss": 0.17084546844125725, "Avg policy loss": 0.28237479575909674, "Total num played games": 44204, "Total num trained steps": 87808, "Timestamp in ms": 1701592889536, "logtype": "training_step"}
{"Total num played games": 44204, "Total num trained steps": 87875, "Timestamp in ms": 1701592932105, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.359375}
{"Avg objective": 19.9375, "Games time in secs": 89.432353829965, "Avg game time in secs": 1.7795341399905737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.66, "agent_stopped_0": 0.36}, "Total num played games": 44288, "Total num trained steps": 87882, "Timestamp in ms": 1701592935727, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851009074901802, "Avg loss": 0.47243098728358746, "Avg value loss": 0.1852018912031781, "Avg policy loss": 0.28722909779753536, "Total num played games": 44298, "Total num trained steps": 87936, "Timestamp in ms": 1701592961384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879904284617815, "Avg loss": 0.4184692215640098, "Avg value loss": 0.13373796452651732, "Avg policy loss": 0.28473125759046525, "Total num played games": 44298, "Total num trained steps": 88064, "Timestamp in ms": 1701593019796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865747623552732, "Avg loss": 0.5426483459305018, "Avg value loss": 0.24569487044936977, "Avg policy loss": 0.29695347126107663, "Total num played games": 44394, "Total num trained steps": 88192, "Timestamp in ms": 1701593080291, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 186.66263130120933, "Avg game time in secs": 1.7765411380241858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 44416, "Total num trained steps": 88280, "Timestamp in ms": 1701593122390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852544506383745, "Avg loss": 0.4528779436368495, "Avg value loss": 0.16085777172702365, "Avg policy loss": 0.29202017141506076, "Total num played games": 44488, "Total num trained steps": 88320, "Timestamp in ms": 1701593141374, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881316310016184, "Avg loss": 0.390083005419001, "Avg value loss": 0.10479585159919225, "Avg policy loss": 0.28528715413995087, "Total num played games": 44488, "Total num trained steps": 88448, "Timestamp in ms": 1701593200608, "logtype": "training_step"}
{"Avg objective": 19.21875, "Games time in secs": 87.5876794140786, "Avg game time in secs": 1.6864405200467445, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 44544, "Total num trained steps": 88469, "Timestamp in ms": 1701593209978, "logtype": "played_game"}
{"Total num played games": 44582, "Total num trained steps": 88475, "Timestamp in ms": 1701593223635, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3046875}
{"Avg objective": 21.1875, "Games time in secs": 17.45941980369389, "Avg game time in secs": 1.756564540672116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.66, "agent_stopped_0": 0.37}, "Total num played games": 44672, "Total num trained steps": 88482, "Timestamp in ms": 1701593227437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826304951204226, "Avg loss": 0.6077924997080117, "Avg value loss": 0.30035081852111034, "Avg policy loss": 0.3074416812742129, "Total num played games": 44676, "Total num trained steps": 88576, "Timestamp in ms": 1701593270289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985473184707673, "Avg loss": 0.3837987151928246, "Avg value loss": 0.09445923983003013, "Avg policy loss": 0.28933947428595275, "Total num played games": 44676, "Total num trained steps": 88704, "Timestamp in ms": 1701593330182, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988360641060077, "Avg loss": 0.35247192485257983, "Avg value loss": 0.07529769977554679, "Avg policy loss": 0.2771742265904322, "Total num played games": 44676, "Total num trained steps": 88832, "Timestamp in ms": 1701593389122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870448961358051, "Avg loss": 0.48921065661124885, "Avg value loss": 0.19903125273413025, "Avg policy loss": 0.29017940477933735, "Total num played games": 44770, "Total num trained steps": 88960, "Timestamp in ms": 1701593449230, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 256.14708332158625, "Avg game time in secs": 1.7195307041401975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 44800, "Total num trained steps": 89030, "Timestamp in ms": 1701593483585, "logtype": "played_game"}
{"Total num played games": 44864, "Total num trained steps": 89079, "Timestamp in ms": 1701593517377, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2734375}
{"Avg objective": 21.1328125, "Games time in secs": 36.78857228718698, "Avg game time in secs": 1.7782471211976372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.6, "agent_stopped_0": 0.44}, "Total num played games": 44928, "Total num trained steps": 89082, "Timestamp in ms": 1701593520373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815828106232483, "Avg loss": 0.5131708381231874, "Avg value loss": 0.23151754477294162, "Avg policy loss": 0.2816532973665744, "Total num played games": 44958, "Total num trained steps": 89088, "Timestamp in ms": 1701593522812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844299123626497, "Avg loss": 0.5102836438454688, "Avg value loss": 0.20395576930604875, "Avg policy loss": 0.30632787453942, "Total num played games": 44958, "Total num trained steps": 89216, "Timestamp in ms": 1701593582521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872770141020508, "Avg loss": 0.35950210120063275, "Avg value loss": 0.0842717404011637, "Avg policy loss": 0.2752303635934368, "Total num played games": 44958, "Total num trained steps": 89344, "Timestamp in ms": 1701593640222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859495693864868, "Avg loss": 0.4681672391016036, "Avg value loss": 0.1864359523751773, "Avg policy loss": 0.2817312857368961, "Total num played games": 45052, "Total num trained steps": 89472, "Timestamp in ms": 1701593700401, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 235.29055272229016, "Avg game time in secs": 1.8612770324543817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.73, "agent_stopped_0": 0.36}, "Total num played games": 45056, "Total num trained steps": 89594, "Timestamp in ms": 1701593755664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984671953218447, "Avg loss": 0.3672741064801812, "Avg value loss": 0.09370120349922217, "Avg policy loss": 0.2735729038249701, "Total num played games": 45144, "Total num trained steps": 89600, "Timestamp in ms": 1701593757792, "logtype": "training_step"}
{"Total num played games": 45148, "Total num trained steps": 89682, "Timestamp in ms": 1701593805607, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.81640625}
{"Avg objective": 20.3828125, "Games time in secs": 52.42075148411095, "Avg game time in secs": 1.633015637373319, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 45184, "Total num trained steps": 89687, "Timestamp in ms": 1701593808085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832898634012643, "Avg loss": 0.5304930270649493, "Avg value loss": 0.23828713508555666, "Avg policy loss": 0.292205887963064, "Total num played games": 45242, "Total num trained steps": 89728, "Timestamp in ms": 1701593827052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986119092878299, "Avg loss": 0.3800496163312346, "Avg value loss": 0.0983025649911724, "Avg policy loss": 0.2817470502341166, "Total num played games": 45242, "Total num trained steps": 89856, "Timestamp in ms": 1701593885688, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 133.0521750394255, "Avg game time in secs": 1.7679495107295224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 45312, "Total num trained steps": 89977, "Timestamp in ms": 1701593941137, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848023645667903, "Avg loss": 0.3954570109490305, "Avg value loss": 0.13448614429216832, "Avg policy loss": 0.2609708645613864, "Total num played games": 45336, "Total num trained steps": 89984, "Timestamp in ms": 1701593944013, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876477854243868, "Avg loss": 0.45620389259420335, "Avg value loss": 0.18085154111031443, "Avg policy loss": 0.2753523514838889, "Total num played games": 45336, "Total num trained steps": 90112, "Timestamp in ms": 1701594001707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862651875330164, "Avg loss": 0.49693796364590526, "Avg value loss": 0.2127317389822565, "Avg policy loss": 0.28420622553676367, "Total num played games": 45432, "Total num trained steps": 90240, "Timestamp in ms": 1701594057018, "logtype": "training_step"}
{"Total num played games": 45432, "Total num trained steps": 90282, "Timestamp in ms": 1701594087032, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.46875}
{"Avg objective": 20.4609375, "Games time in secs": 147.936627227813, "Avg game time in secs": 1.7458560944942292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 45440, "Total num trained steps": 90285, "Timestamp in ms": 1701594089074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849756183279883, "Avg loss": 0.5237213645596057, "Avg value loss": 0.24149575096089393, "Avg policy loss": 0.2822256119688973, "Total num played games": 45526, "Total num trained steps": 90368, "Timestamp in ms": 1701594128778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877652330536397, "Avg loss": 0.35875082190614194, "Avg value loss": 0.08406165597261861, "Avg policy loss": 0.2746891629649326, "Total num played games": 45526, "Total num trained steps": 90496, "Timestamp in ms": 1701594186621, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 118.42248621955514, "Avg game time in secs": 1.7070662627666024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.58}, "Total num played games": 45568, "Total num trained steps": 90544, "Timestamp in ms": 1701594207497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864971503726436, "Avg loss": 0.4947307661641389, "Avg value loss": 0.21702595430542715, "Avg policy loss": 0.27770481223706156, "Total num played games": 45620, "Total num trained steps": 90624, "Timestamp in ms": 1701594244922, "logtype": "training_step"}
{"Avg objective": 19.6875, "Games time in secs": 88.7854687999934, "Avg game time in secs": 1.722982392529957, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 45696, "Total num trained steps": 90733, "Timestamp in ms": 1701594296282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852124075775475, "Avg loss": 0.4189355280250311, "Avg value loss": 0.14623265163390897, "Avg policy loss": 0.27270287775900215, "Total num played games": 45714, "Total num trained steps": 90752, "Timestamp in ms": 1701594304183, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880124250776567, "Avg loss": 0.38602198101580143, "Avg value loss": 0.11491490650223568, "Avg policy loss": 0.2711070730583742, "Total num played games": 45714, "Total num trained steps": 90880, "Timestamp in ms": 1701594362148, "logtype": "training_step"}
{"Total num played games": 45714, "Total num trained steps": 90887, "Timestamp in ms": 1701594375725, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3125}
{"Ratio train steps to played games": 1.9867272092210968, "Avg loss": 0.4808868404943496, "Avg value loss": 0.20240599525277503, "Avg policy loss": 0.2784808451542631, "Total num played games": 45808, "Total num trained steps": 91008, "Timestamp in ms": 1701594429301, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 176.74475019052625, "Avg game time in secs": 1.6837221775349462, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 45824, "Total num trained steps": 91108, "Timestamp in ms": 1701594473027, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985447257200122, "Avg loss": 0.4503018422983587, "Avg value loss": 0.1818918273493182, "Avg policy loss": 0.2684100129408762, "Total num played games": 45902, "Total num trained steps": 91136, "Timestamp in ms": 1701594485535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882358067186614, "Avg loss": 0.3804160300642252, "Avg value loss": 0.10604543698718771, "Avg policy loss": 0.2743705912726, "Total num played games": 45902, "Total num trained steps": 91264, "Timestamp in ms": 1701594544549, "logtype": "training_step"}
{"Avg objective": 19.8828125, "Games time in secs": 86.61484958417714, "Avg game time in secs": 1.6791111169877695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.52}, "Total num played games": 45952, "Total num trained steps": 91295, "Timestamp in ms": 1701594559642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869553874249934, "Avg loss": 0.4885986838489771, "Avg value loss": 0.20211409687181003, "Avg policy loss": 0.2864845875883475, "Total num played games": 45996, "Total num trained steps": 91392, "Timestamp in ms": 1701594604678, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 89.99502517655492, "Avg game time in secs": 1.8960261601750972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.71, "agent_stopped_0": 0.34}, "Total num played games": 46080, "Total num trained steps": 91486, "Timestamp in ms": 1701594649637, "logtype": "played_game"}
{"Total num played games": 46090, "Total num trained steps": 91488, "Timestamp in ms": 1701594664415, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.63671875}
{"Ratio train steps to played games": 1.981638662740343, "Avg loss": 0.56082056555897, "Avg value loss": 0.27307914674747735, "Avg policy loss": 0.28774141799658537, "Total num played games": 46184, "Total num trained steps": 91520, "Timestamp in ms": 1701594680720, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844101853455742, "Avg loss": 0.4632392378989607, "Avg value loss": 0.1614892645739019, "Avg policy loss": 0.30174997355788946, "Total num played games": 46184, "Total num trained steps": 91648, "Timestamp in ms": 1701594738119, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871817079508054, "Avg loss": 0.39219734678044915, "Avg value loss": 0.11803347922977991, "Avg policy loss": 0.2741638709558174, "Total num played games": 46184, "Total num trained steps": 91776, "Timestamp in ms": 1701594793923, "logtype": "training_step"}
{"Avg objective": 19.78125, "Games time in secs": 183.56284023448825, "Avg game time in secs": 1.6891385233902838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 46208, "Total num trained steps": 91861, "Timestamp in ms": 1701594833200, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858896235792385, "Avg loss": 0.5147577836178243, "Avg value loss": 0.22996449886704795, "Avg policy loss": 0.28479328472167253, "Total num played games": 46278, "Total num trained steps": 91904, "Timestamp in ms": 1701594852131, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988677125199879, "Avg loss": 0.4233591260854155, "Avg value loss": 0.13235764595447108, "Avg policy loss": 0.2910014771623537, "Total num played games": 46278, "Total num trained steps": 92032, "Timestamp in ms": 1701594911079, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 85.43304749019444, "Avg game time in secs": 1.806734395766398, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.72}, "Total num played games": 46336, "Total num trained steps": 92050, "Timestamp in ms": 1701594918633, "logtype": "played_game"}
{"Total num played games": 46374, "Total num trained steps": 92088, "Timestamp in ms": 1701594948646, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.82421875}
{"Avg objective": 21.2578125, "Games time in secs": 34.0695656593889, "Avg game time in secs": 1.8555564389826031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 46464, "Total num trained steps": 92096, "Timestamp in ms": 1701594952703, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832788155289662, "Avg loss": 0.6541618711780757, "Avg value loss": 0.3501291859720368, "Avg policy loss": 0.30403268605004996, "Total num played games": 46468, "Total num trained steps": 92160, "Timestamp in ms": 1701594981231, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860333993285701, "Avg loss": 0.4219662226969376, "Avg value loss": 0.132855015079258, "Avg policy loss": 0.28911120735574514, "Total num played games": 46468, "Total num trained steps": 92288, "Timestamp in ms": 1701595042506, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888095033141087, "Avg loss": 0.34917912841774523, "Avg value loss": 0.08119781283312477, "Avg policy loss": 0.26798131386749446, "Total num played games": 46468, "Total num trained steps": 92416, "Timestamp in ms": 1701595101820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987543490399897, "Avg loss": 0.4634448355063796, "Avg value loss": 0.1866946415102575, "Avg policy loss": 0.2767501971684396, "Total num played games": 46562, "Total num trained steps": 92544, "Timestamp in ms": 1701595160869, "logtype": "training_step"}
{"Avg objective": 19.7265625, "Games time in secs": 241.5498871523887, "Avg game time in secs": 1.6921290603786474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 46592, "Total num trained steps": 92616, "Timestamp in ms": 1701595194253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861974366668096, "Avg loss": 0.46453476836904883, "Avg value loss": 0.18212073532049544, "Avg policy loss": 0.28241402853745967, "Total num played games": 46658, "Total num trained steps": 92672, "Timestamp in ms": 1701595218996, "logtype": "training_step"}
{"Total num played games": 46658, "Total num trained steps": 92691, "Timestamp in ms": 1701595237918, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.87890625}
{"Avg objective": 20.859375, "Games time in secs": 46.65505073033273, "Avg game time in secs": 1.8019273632089607, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 46720, "Total num trained steps": 92697, "Timestamp in ms": 1701595240908, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849418206707734, "Avg loss": 0.5362025445792824, "Avg value loss": 0.23915373341878876, "Avg policy loss": 0.2970488155260682, "Total num played games": 46752, "Total num trained steps": 92800, "Timestamp in ms": 1701595290464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987658281998631, "Avg loss": 0.3558844373328611, "Avg value loss": 0.08269665302941576, "Avg policy loss": 0.2731877857586369, "Total num played games": 46752, "Total num trained steps": 92928, "Timestamp in ms": 1701595348764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986423600734321, "Avg loss": 0.4541167486459017, "Avg value loss": 0.17262085917172953, "Avg policy loss": 0.28149589023087174, "Total num played games": 46846, "Total num trained steps": 93056, "Timestamp in ms": 1701595407113, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 221.62471377290785, "Avg game time in secs": 1.7518045653559966, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 46848, "Total num trained steps": 93181, "Timestamp in ms": 1701595462533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885192377456733, "Avg loss": 0.36784308729693294, "Avg value loss": 0.0866552916704677, "Avg policy loss": 0.2811877984786406, "Total num played games": 46854, "Total num trained steps": 93184, "Timestamp in ms": 1701595463503, "logtype": "training_step"}
{"Total num played games": 46940, "Total num trained steps": 93295, "Timestamp in ms": 1701595523607, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2578125}
{"Avg objective": 19.6875, "Games time in secs": 63.77784669212997, "Avg game time in secs": 1.8011193087004358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 46976, "Total num trained steps": 93299, "Timestamp in ms": 1701595526311, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983905260024663, "Avg loss": 0.5279865982010961, "Avg value loss": 0.23964074745890684, "Avg policy loss": 0.2883458548458293, "Total num played games": 47034, "Total num trained steps": 93312, "Timestamp in ms": 1701595532168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866479567972106, "Avg loss": 0.40321997785940766, "Avg value loss": 0.11759516195161268, "Avg policy loss": 0.2856248185271397, "Total num played games": 47034, "Total num trained steps": 93440, "Timestamp in ms": 1701595593674, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 121.29475848563015, "Avg game time in secs": 1.7575253404938849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.66}, "Total num played games": 47104, "Total num trained steps": 93561, "Timestamp in ms": 1701595647606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854014598540146, "Avg loss": 0.4260425476823002, "Avg value loss": 0.1550776299845893, "Avg policy loss": 0.2709649163298309, "Total num played games": 47128, "Total num trained steps": 93568, "Timestamp in ms": 1701595650339, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988117467323035, "Avg loss": 0.4674643196631223, "Avg value loss": 0.17762663011671975, "Avg policy loss": 0.28983768459875137, "Total num played games": 47128, "Total num trained steps": 93696, "Timestamp in ms": 1701595707957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867652041334913, "Avg loss": 0.4862899680156261, "Avg value loss": 0.20000364366569556, "Avg policy loss": 0.2862863198388368, "Total num played games": 47224, "Total num trained steps": 93824, "Timestamp in ms": 1701595766356, "logtype": "training_step"}
{"Total num played games": 47224, "Total num trained steps": 93895, "Timestamp in ms": 1701595812284, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48828125}
{"Avg objective": 20.734375, "Games time in secs": 166.48008069582283, "Avg game time in secs": 1.8535607547237305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 47232, "Total num trained steps": 93898, "Timestamp in ms": 1701595814086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855234794370007, "Avg loss": 0.508625142974779, "Avg value loss": 0.22657495227758773, "Avg policy loss": 0.28205019317101687, "Total num played games": 47318, "Total num trained steps": 93952, "Timestamp in ms": 1701595841601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98824971469631, "Avg loss": 0.3687370721017942, "Avg value loss": 0.09686311794212088, "Avg policy loss": 0.2718739517731592, "Total num played games": 47318, "Total num trained steps": 94080, "Timestamp in ms": 1701595903823, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 113.64946585707366, "Avg game time in secs": 1.6246447449084371, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.56}, "Total num played games": 47360, "Total num trained steps": 94129, "Timestamp in ms": 1701595927736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870075086475998, "Avg loss": 0.4996147593483329, "Avg value loss": 0.2117632939480245, "Avg policy loss": 0.2878514643525705, "Total num played games": 47412, "Total num trained steps": 94208, "Timestamp in ms": 1701595963851, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 87.68580095656216, "Avg game time in secs": 1.8388653024012456, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 47488, "Total num trained steps": 94318, "Timestamp in ms": 1701596015422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856030309408546, "Avg loss": 0.4267326795961708, "Avg value loss": 0.15591012357617728, "Avg policy loss": 0.2708225545939058, "Total num played games": 47510, "Total num trained steps": 94336, "Timestamp in ms": 1701596023270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882972005893496, "Avg loss": 0.4154446921311319, "Avg value loss": 0.14397308637853712, "Avg policy loss": 0.27147160610184073, "Total num played games": 47510, "Total num trained steps": 94464, "Timestamp in ms": 1701596081746, "logtype": "training_step"}
{"Total num played games": 47510, "Total num trained steps": 94497, "Timestamp in ms": 1701596107671, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.58203125}
{"Ratio train steps to played games": 1.9870599109318545, "Avg loss": 0.46702752890996635, "Avg value loss": 0.19508557286462747, "Avg policy loss": 0.27194195601623505, "Total num played games": 47604, "Total num trained steps": 94592, "Timestamp in ms": 1701596153578, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 186.32039523683488, "Avg game time in secs": 1.6764317151682917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 47616, "Total num trained steps": 94700, "Timestamp in ms": 1701596201742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858274980083022, "Avg loss": 0.39711319166235626, "Avg value loss": 0.14177033491432667, "Avg policy loss": 0.2553428536048159, "Total num played games": 47698, "Total num trained steps": 94720, "Timestamp in ms": 1701596211512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885110486812865, "Avg loss": 0.4036845925729722, "Avg value loss": 0.14104584296001121, "Avg policy loss": 0.2626387501368299, "Total num played games": 47698, "Total num trained steps": 94848, "Timestamp in ms": 1701596271785, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 88.47688026539981, "Avg game time in secs": 1.6332587908545975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 47744, "Total num trained steps": 94889, "Timestamp in ms": 1701596290219, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872782055574154, "Avg loss": 0.5026460776571184, "Avg value loss": 0.23389765017782338, "Avg policy loss": 0.26874842413235456, "Total num played games": 47792, "Total num trained steps": 94976, "Timestamp in ms": 1701596329332, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 87.27640662156045, "Avg game time in secs": 1.877046206529485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 47872, "Total num trained steps": 95078, "Timestamp in ms": 1701596377496, "logtype": "played_game"}
{"Total num played games": 47886, "Total num trained steps": 95099, "Timestamp in ms": 1701596398384, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.40625}
{"Ratio train steps to played games": 1.985324509947185, "Avg loss": 0.45503090880811214, "Avg value loss": 0.19396295794285834, "Avg policy loss": 0.26106795051600784, "Total num played games": 47902, "Total num trained steps": 95104, "Timestamp in ms": 1701596400710, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848270112546895, "Avg loss": 0.544257074361667, "Avg value loss": 0.2577980166533962, "Avg policy loss": 0.28645905549637973, "Total num played games": 47980, "Total num trained steps": 95232, "Timestamp in ms": 1701596457784, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874947894956232, "Avg loss": 0.33860679261852056, "Avg value loss": 0.08822624990716577, "Avg policy loss": 0.2503805417800322, "Total num played games": 47980, "Total num trained steps": 95360, "Timestamp in ms": 1701596517185, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 182.67970993369818, "Avg game time in secs": 1.7758124035026412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.65, "agent_stopped_0": 0.39}, "Total num played games": 48000, "Total num trained steps": 95452, "Timestamp in ms": 1701596560176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862711652868494, "Avg loss": 0.4360050812829286, "Avg value loss": 0.18548258146620356, "Avg policy loss": 0.250522498623468, "Total num played games": 48074, "Total num trained steps": 95488, "Timestamp in ms": 1701596576978, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988933727170612, "Avg loss": 0.36108467262238264, "Avg value loss": 0.10333389285369776, "Avg policy loss": 0.2577507799724117, "Total num played games": 48074, "Total num trained steps": 95616, "Timestamp in ms": 1701596635161, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 86.24898432195187, "Avg game time in secs": 1.818790795019595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.67}, "Total num played games": 48128, "Total num trained steps": 95641, "Timestamp in ms": 1701596646425, "logtype": "played_game"}
{"Total num played games": 48170, "Total num trained steps": 95700, "Timestamp in ms": 1701596683841, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.265625}
{"Avg objective": 21.5390625, "Games time in secs": 40.91446933336556, "Avg game time in secs": 1.7834361777786398, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 48256, "Total num trained steps": 95707, "Timestamp in ms": 1701596687339, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837560086192607, "Avg loss": 0.5654181863646954, "Avg value loss": 0.2956025089370087, "Avg policy loss": 0.2698156770784408, "Total num played games": 48264, "Total num trained steps": 95744, "Timestamp in ms": 1701596704129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864080888446876, "Avg loss": 0.35469500557519495, "Avg value loss": 0.1003334658453241, "Avg policy loss": 0.2543615405447781, "Total num played games": 48264, "Total num trained steps": 95872, "Timestamp in ms": 1701596761518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890394496933532, "Avg loss": 0.3076690954621881, "Avg value loss": 0.0670003651175648, "Avg policy loss": 0.24066873046103865, "Total num played games": 48264, "Total num trained steps": 96000, "Timestamp in ms": 1701596820040, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878406882005046, "Avg loss": 0.42525766883045435, "Avg value loss": 0.18154224209138192, "Avg policy loss": 0.24371542991138995, "Total num played games": 48358, "Total num trained steps": 96128, "Timestamp in ms": 1701596875648, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 224.02556020580232, "Avg game time in secs": 1.6419181268429384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.52, "agent_stopped_0": 0.49}, "Total num played games": 48384, "Total num trained steps": 96207, "Timestamp in ms": 1701596911365, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865233004499112, "Avg loss": 0.44682563038077205, "Avg value loss": 0.19832065218361095, "Avg policy loss": 0.24850497813895345, "Total num played games": 48454, "Total num trained steps": 96256, "Timestamp in ms": 1701596934585, "logtype": "training_step"}
{"Total num played games": 48454, "Total num trained steps": 96301, "Timestamp in ms": 1701596967830, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.421875}
{"Avg objective": 19.9921875, "Games time in secs": 59.372520150616765, "Avg game time in secs": 1.7282608005189104, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 48512, "Total num trained steps": 96306, "Timestamp in ms": 1701596970738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853135041608305, "Avg loss": 0.4804185687098652, "Avg value loss": 0.21905234025325626, "Avg policy loss": 0.26136623008642346, "Total num played games": 48548, "Total num trained steps": 96384, "Timestamp in ms": 1701597007990, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879706682046634, "Avg loss": 0.3404490906978026, "Avg value loss": 0.09402487915940583, "Avg policy loss": 0.24642421200405806, "Total num played games": 48548, "Total num trained steps": 96512, "Timestamp in ms": 1701597066326, "logtype": "training_step"}
{"Avg objective": 20.5390625, "Games time in secs": 130.53476547263563, "Avg game time in secs": 1.810901197270141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 48640, "Total num trained steps": 96590, "Timestamp in ms": 1701597101273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867604128119731, "Avg loss": 0.4149694078369066, "Avg value loss": 0.1671096325153485, "Avg policy loss": 0.24785977392457426, "Total num played games": 48642, "Total num trained steps": 96640, "Timestamp in ms": 1701597122989, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893918835574196, "Avg loss": 0.3353432647418231, "Avg value loss": 0.08911727866507135, "Avg policy loss": 0.24622598639689386, "Total num played games": 48642, "Total num trained steps": 96768, "Timestamp in ms": 1701597179942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881607025607353, "Avg loss": 0.47897141007706523, "Avg value loss": 0.21613154822262004, "Avg policy loss": 0.26283986086491495, "Total num played games": 48736, "Total num trained steps": 96896, "Timestamp in ms": 1701597239900, "logtype": "training_step"}
{"Total num played games": 48736, "Total num trained steps": 96904, "Timestamp in ms": 1701597257018, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48046875}
{"Avg objective": 19.9296875, "Games time in secs": 158.39914988726377, "Avg game time in secs": 1.740267561195651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 48768, "Total num trained steps": 96910, "Timestamp in ms": 1701597259672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869752201515463, "Avg loss": 0.4609920885413885, "Avg value loss": 0.19198584405239671, "Avg policy loss": 0.2690062462352216, "Total num played games": 48830, "Total num trained steps": 97024, "Timestamp in ms": 1701597310616, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889243745649592, "Avg loss": 0.3539719330146909, "Avg value loss": 0.09540716648916714, "Avg policy loss": 0.25856476894114166, "Total num played games": 48844, "Total num trained steps": 97152, "Timestamp in ms": 1701597370767, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 111.96307306364179, "Avg game time in secs": 1.728854556218721, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.63}, "Total num played games": 48896, "Total num trained steps": 97154, "Timestamp in ms": 1701597371635, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883901561605757, "Avg loss": 0.5074996999464929, "Avg value loss": 0.23950780800078064, "Avg policy loss": 0.2679918920621276, "Total num played games": 48924, "Total num trained steps": 97280, "Timestamp in ms": 1701597427417, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871883797788568, "Avg loss": 0.4360526103992015, "Avg value loss": 0.16985536544234492, "Avg policy loss": 0.26619724289048463, "Total num played games": 49018, "Total num trained steps": 97408, "Timestamp in ms": 1701597482886, "logtype": "training_step"}
{"Total num played games": 49018, "Total num trained steps": 97506, "Timestamp in ms": 1701597541658, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.6484375}
{"Avg objective": 20.3671875, "Games time in secs": 171.88739214092493, "Avg game time in secs": 1.8532074144750368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.75, "agent_stopped_0": 0.33}, "Total num played games": 49024, "Total num trained steps": 97509, "Timestamp in ms": 1701597543523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985970842156703, "Avg loss": 0.41614502924494445, "Avg value loss": 0.1539672423095908, "Avg policy loss": 0.2621777856256813, "Total num played games": 49112, "Total num trained steps": 97536, "Timestamp in ms": 1701597555900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885974914481186, "Avg loss": 0.3780475148232654, "Avg value loss": 0.11629012960474938, "Avg policy loss": 0.2617573847528547, "Total num played games": 49112, "Total num trained steps": 97664, "Timestamp in ms": 1701597614516, "logtype": "training_step"}
{"Avg objective": 20.1640625, "Games time in secs": 94.41074953228235, "Avg game time in secs": 1.6111415849154582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.58}, "Total num played games": 49152, "Total num trained steps": 97716, "Timestamp in ms": 1701597637934, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873999105800106, "Avg loss": 0.41430473350919783, "Avg value loss": 0.14971221206360497, "Avg policy loss": 0.26459251972846687, "Total num played games": 49206, "Total num trained steps": 97792, "Timestamp in ms": 1701597671630, "logtype": "training_step"}
{"Avg objective": 19.2109375, "Games time in secs": 85.95611160062253, "Avg game time in secs": 1.6859147518698592, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.63}, "Total num played games": 49280, "Total num trained steps": 97906, "Timestamp in ms": 1701597723890, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986206896551724, "Avg loss": 0.41126305074431, "Avg value loss": 0.14696288632694632, "Avg policy loss": 0.2643001605756581, "Total num played games": 49300, "Total num trained steps": 97920, "Timestamp in ms": 1701597730085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888032454361055, "Avg loss": 0.41112620406784117, "Avg value loss": 0.13405923784011975, "Avg policy loss": 0.2770669686142355, "Total num played games": 49300, "Total num trained steps": 98048, "Timestamp in ms": 1701597788786, "logtype": "training_step"}
{"Total num played games": 49394, "Total num trained steps": 98108, "Timestamp in ms": 1701597828942, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.234375}
{"Avg objective": 21.0390625, "Games time in secs": 107.23241545632482, "Avg game time in secs": 1.78462211144506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.63, "agent_stopped_0": 0.42}, "Total num played games": 49408, "Total num trained steps": 98112, "Timestamp in ms": 1701597831122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838142580019398, "Avg loss": 0.6279470048611984, "Avg value loss": 0.3352170227735769, "Avg policy loss": 0.2927299845032394, "Total num played games": 49488, "Total num trained steps": 98176, "Timestamp in ms": 1701597860146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864007436146136, "Avg loss": 0.3951201089657843, "Avg value loss": 0.10148047350230627, "Avg policy loss": 0.29363963892683387, "Total num played games": 49488, "Total num trained steps": 98304, "Timestamp in ms": 1701597918037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890074361461365, "Avg loss": 0.36104164796415716, "Avg value loss": 0.08480600075563416, "Avg policy loss": 0.27623564819805324, "Total num played games": 49488, "Total num trained steps": 98432, "Timestamp in ms": 1701597976698, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 162.83037368021905, "Avg game time in secs": 1.629347404683358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 49536, "Total num trained steps": 98469, "Timestamp in ms": 1701597993953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877979912064863, "Avg loss": 0.4874929301440716, "Avg value loss": 0.20406129941693507, "Avg policy loss": 0.28343163488898426, "Total num played games": 49582, "Total num trained steps": 98560, "Timestamp in ms": 1701598037151, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 88.80092058330774, "Avg game time in secs": 1.8410093989223242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.72, "agent_stopped_0": 0.32}, "Total num played games": 49664, "Total num trained steps": 98659, "Timestamp in ms": 1701598082754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866333843304613, "Avg loss": 0.49512489838525653, "Avg value loss": 0.21582539164228365, "Avg policy loss": 0.2792995070340112, "Total num played games": 49676, "Total num trained steps": 98688, "Timestamp in ms": 1701598096351, "logtype": "training_step"}
{"Total num played games": 49676, "Total num trained steps": 98708, "Timestamp in ms": 1701598114906, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.59375}
{"Ratio train steps to played games": 1.9854530841872613, "Avg loss": 0.6505746187176555, "Avg value loss": 0.3431585499783978, "Avg policy loss": 0.30741607083473355, "Total num played games": 49770, "Total num trained steps": 98816, "Timestamp in ms": 1701598168311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988024914607193, "Avg loss": 0.3759034420363605, "Avg value loss": 0.0969138054351788, "Avg policy loss": 0.2789896372705698, "Total num played games": 49770, "Total num trained steps": 98944, "Timestamp in ms": 1701598229442, "logtype": "training_step"}
{"Avg objective": 20.703125, "Games time in secs": 185.1859365440905, "Avg game time in secs": 1.7851410787407076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.65, "agent_stopped_0": 0.4}, "Total num played games": 49792, "Total num trained steps": 99032, "Timestamp in ms": 1701598267940, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868442162682496, "Avg loss": 0.4401710848324001, "Avg value loss": 0.16776831905008294, "Avg policy loss": 0.2724027623189613, "Total num played games": 49864, "Total num trained steps": 99072, "Timestamp in ms": 1701598285185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894111984598106, "Avg loss": 0.3623141080606729, "Avg value loss": 0.09035790144116618, "Avg policy loss": 0.2719562068814412, "Total num played games": 49864, "Total num trained steps": 99200, "Timestamp in ms": 1701598342087, "logtype": "training_step"}
{"Avg objective": 19.609375, "Games time in secs": 82.73389177396894, "Avg game time in secs": 1.6574153262627078, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.51}, "Total num played games": 49920, "Total num trained steps": 99221, "Timestamp in ms": 1701598350674, "logtype": "played_game"}
{"Total num played games": 49958, "Total num trained steps": 99308, "Timestamp in ms": 1701598400450, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.078125}
{"Avg objective": 20.0625, "Games time in secs": 53.44527484849095, "Avg game time in secs": 1.8616929595445981, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.71, "agent_stopped_0": 0.35}, "Total num played games": 50048, "Total num trained steps": 99313, "Timestamp in ms": 1701598404120, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844761448093982, "Avg loss": 0.5140706712845713, "Avg value loss": 0.22855318771325983, "Avg policy loss": 0.28551748069003224, "Total num played games": 50052, "Total num trained steps": 99328, "Timestamp in ms": 1701598410724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987053464397027, "Avg loss": 0.4174931792076677, "Avg value loss": 0.12414782989071682, "Avg policy loss": 0.29334534809459, "Total num played games": 50052, "Total num trained steps": 99456, "Timestamp in ms": 1701598469322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896108047630465, "Avg loss": 0.3442867042031139, "Avg value loss": 0.06877496937522665, "Avg policy loss": 0.27551173605024815, "Total num played games": 50052, "Total num trained steps": 99584, "Timestamp in ms": 1701598526688, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884337733817254, "Avg loss": 0.4851415909361094, "Avg value loss": 0.2023459869378712, "Avg policy loss": 0.2827956054825336, "Total num played games": 50146, "Total num trained steps": 99712, "Timestamp in ms": 1701598584888, "logtype": "training_step"}
{"Avg objective": 19.8984375, "Games time in secs": 213.13494547270238, "Avg game time in secs": 1.7080590811820002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 50176, "Total num trained steps": 99783, "Timestamp in ms": 1701598617255, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872611464968153, "Avg loss": 0.4686582023277879, "Avg value loss": 0.1873700508440379, "Avg policy loss": 0.2812881543068215, "Total num played games": 50240, "Total num trained steps": 99840, "Timestamp in ms": 1701598641686, "logtype": "training_step"}
{"Total num played games": 50240, "Total num trained steps": 99912, "Timestamp in ms": 1701598684945, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.76171875}
{"Avg objective": 20.6484375, "Games time in secs": 70.96761909127235, "Avg game time in secs": 1.7761475455772597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 50304, "Total num trained steps": 99918, "Timestamp in ms": 1701598688223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860928994317957, "Avg loss": 0.4532236075028777, "Avg value loss": 0.17340993901598267, "Avg policy loss": 0.27981367090251297, "Total num played games": 50334, "Total num trained steps": 99968, "Timestamp in ms": 1701598711625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886359121071244, "Avg loss": 0.36706437508109957, "Avg value loss": 0.09840086285839789, "Avg policy loss": 0.2686635125428438, "Total num played games": 50334, "Total num trained steps": 100096, "Timestamp in ms": 1701598769931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987467280082494, "Avg loss": 0.46775750746019185, "Avg value loss": 0.20007062540389597, "Avg policy loss": 0.267686884268187, "Total num played games": 50428, "Total num trained steps": 100224, "Timestamp in ms": 1701598826752, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 195.033257920295, "Avg game time in secs": 1.7995099091349402, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 50432, "Total num trained steps": 100347, "Timestamp in ms": 1701598883256, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863816310372129, "Avg loss": 0.3820971534587443, "Avg value loss": 0.11946164252003655, "Avg policy loss": 0.26263551181182265, "Total num played games": 50522, "Total num trained steps": 100352, "Timestamp in ms": 1701598885456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888365464550097, "Avg loss": 0.4621350655797869, "Avg value loss": 0.18612759039388038, "Avg policy loss": 0.2760074733523652, "Total num played games": 50522, "Total num trained steps": 100480, "Timestamp in ms": 1701598942132, "logtype": "training_step"}
{"Total num played games": 50522, "Total num trained steps": 100514, "Timestamp in ms": 1701598967008, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5}
{"Avg objective": 19.484375, "Games time in secs": 86.33701091073453, "Avg game time in secs": 1.6988209992123302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 50560, "Total num trained steps": 100518, "Timestamp in ms": 1701598969593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876718824087245, "Avg loss": 0.4625321802450344, "Avg value loss": 0.18274319788906723, "Avg policy loss": 0.2797889810753986, "Total num played games": 50616, "Total num trained steps": 100608, "Timestamp in ms": 1701599009889, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 92.58318442851305, "Avg game time in secs": 1.7023967665154487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 50688, "Total num trained steps": 100725, "Timestamp in ms": 1701599062176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864918162098206, "Avg loss": 0.3830493662972003, "Avg value loss": 0.1186587093397975, "Avg policy loss": 0.2643906574230641, "Total num played games": 50710, "Total num trained steps": 100736, "Timestamp in ms": 1701599067360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890356931571682, "Avg loss": 0.4131084531545639, "Avg value loss": 0.14445185297518037, "Avg policy loss": 0.2686565995682031, "Total num played games": 50710, "Total num trained steps": 100864, "Timestamp in ms": 1701599124281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878552869852768, "Avg loss": 0.44750860752537847, "Avg value loss": 0.18192399173858576, "Avg policy loss": 0.26558461657259613, "Total num played games": 50804, "Total num trained steps": 100992, "Timestamp in ms": 1701599181431, "logtype": "training_step"}
{"Avg objective": 19.25, "Games time in secs": 166.79723989404738, "Avg game time in secs": 1.7430528142285766, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 50816, "Total num trained steps": 101099, "Timestamp in ms": 1701599228974, "logtype": "played_game"}
{"Total num played games": 50898, "Total num trained steps": 101114, "Timestamp in ms": 1701599246525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2265625}
{"Avg objective": 20.1015625, "Games time in secs": 20.195201152935624, "Avg game time in secs": 1.6630828322231537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.61}, "Total num played games": 50944, "Total num trained steps": 101118, "Timestamp in ms": 1701599249169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834451374995097, "Avg loss": 0.4112445405917242, "Avg value loss": 0.15972343366593122, "Avg policy loss": 0.2515211086720228, "Total num played games": 50980, "Total num trained steps": 101120, "Timestamp in ms": 1701599250129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855663633511138, "Avg loss": 0.5780183768365532, "Avg value loss": 0.2942035185988061, "Avg policy loss": 0.2838148559676483, "Total num played games": 50992, "Total num trained steps": 101248, "Timestamp in ms": 1701599311795, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988076561029181, "Avg loss": 0.34469973866362125, "Avg value loss": 0.09317659612861462, "Avg policy loss": 0.2515231443103403, "Total num played games": 50992, "Total num trained steps": 101376, "Timestamp in ms": 1701599369291, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 165.3319890666753, "Avg game time in secs": 1.7915532813203754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.7, "agent_stopped_0": 0.37}, "Total num played games": 51072, "Total num trained steps": 101478, "Timestamp in ms": 1701599414501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869044356575187, "Avg loss": 0.4243158071767539, "Avg value loss": 0.16825251551927067, "Avg policy loss": 0.25606329506263137, "Total num played games": 51086, "Total num trained steps": 101504, "Timestamp in ms": 1701599425071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894295893199703, "Avg loss": 0.384912311215885, "Avg value loss": 0.11906704228022136, "Avg policy loss": 0.2658452690811828, "Total num played games": 51086, "Total num trained steps": 101632, "Timestamp in ms": 1701599486022, "logtype": "training_step"}
{"Total num played games": 51180, "Total num trained steps": 101714, "Timestamp in ms": 1701599536767, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1875}
{"Avg objective": 20.1328125, "Games time in secs": 124.3691178560257, "Avg game time in secs": 1.7294301818037638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 51200, "Total num trained steps": 101718, "Timestamp in ms": 1701599538871, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984631587159184, "Avg loss": 0.5593615090474486, "Avg value loss": 0.2781688688264694, "Avg policy loss": 0.2811926385620609, "Total num played games": 51274, "Total num trained steps": 101760, "Timestamp in ms": 1701599558905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987108476030737, "Avg loss": 0.387771378736943, "Avg value loss": 0.10528497205814347, "Avg policy loss": 0.28248640859965235, "Total num played games": 51274, "Total num trained steps": 101888, "Timestamp in ms": 1701599618868, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896243710262511, "Avg loss": 0.33398149511776865, "Avg value loss": 0.06604804808739573, "Avg policy loss": 0.26793344982434064, "Total num played games": 51274, "Total num trained steps": 102016, "Timestamp in ms": 1701599676875, "logtype": "training_step"}
{"Avg objective": 20.6015625, "Games time in secs": 149.1974536292255, "Avg game time in secs": 1.6611130560922902, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.61}, "Total num played games": 51328, "Total num trained steps": 102041, "Timestamp in ms": 1701599688068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884753153714374, "Avg loss": 0.4474292865488678, "Avg value loss": 0.17954945113160647, "Avg policy loss": 0.2678798343986273, "Total num played games": 51368, "Total num trained steps": 102144, "Timestamp in ms": 1701599735024, "logtype": "training_step"}
{"Avg objective": 20.0234375, "Games time in secs": 84.96085368841887, "Avg game time in secs": 1.7400280674046371, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.65, "agent_stopped_0": 0.36}, "Total num played games": 51456, "Total num trained steps": 102231, "Timestamp in ms": 1701599773029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987330457424896, "Avg loss": 0.4236812711460516, "Avg value loss": 0.16732663958100602, "Avg policy loss": 0.25635462848003954, "Total num played games": 51462, "Total num trained steps": 102272, "Timestamp in ms": 1701599791416, "logtype": "training_step"}
{"Total num played games": 51462, "Total num trained steps": 102314, "Timestamp in ms": 1701599822816, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.59375}
{"Ratio train steps to played games": 1.9861703778415702, "Avg loss": 0.4722155106719583, "Avg value loss": 0.20727261487627402, "Avg policy loss": 0.2649428974837065, "Total num played games": 51556, "Total num trained steps": 102400, "Timestamp in ms": 1701599862019, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886725114438668, "Avg loss": 0.32470814196858555, "Avg value loss": 0.07757059030700475, "Avg policy loss": 0.24713755038101226, "Total num played games": 51556, "Total num trained steps": 102528, "Timestamp in ms": 1701599925061, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 185.24971134774387, "Avg game time in secs": 1.603162477418664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.58, "agent_stopped_0": 0.45}, "Total num played games": 51584, "Total num trained steps": 102604, "Timestamp in ms": 1701599958279, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875314617618587, "Avg loss": 0.424699621507898, "Avg value loss": 0.18525496975053102, "Avg policy loss": 0.23944465338718146, "Total num played games": 51650, "Total num trained steps": 102656, "Timestamp in ms": 1701599982020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900096805421104, "Avg loss": 0.34178388374857605, "Avg value loss": 0.10069985038717277, "Avg policy loss": 0.24108403560239822, "Total num played games": 51650, "Total num trained steps": 102784, "Timestamp in ms": 1701600040315, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 86.038703661412, "Avg game time in secs": 1.7521342417603591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 51712, "Total num trained steps": 102794, "Timestamp in ms": 1701600044318, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888682745825603, "Avg loss": 0.4507360802963376, "Avg value loss": 0.19927760798600502, "Avg policy loss": 0.2514584718737751, "Total num played games": 51744, "Total num trained steps": 102912, "Timestamp in ms": 1701600096895, "logtype": "training_step"}
{"Total num played games": 51744, "Total num trained steps": 102915, "Timestamp in ms": 1701600108322, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.41796875}
{"Ratio train steps to played games": 1.9877310081407462, "Avg loss": 0.5040883866604418, "Avg value loss": 0.2406793899135664, "Avg policy loss": 0.2634089944185689, "Total num played games": 51838, "Total num trained steps": 103040, "Timestamp in ms": 1701600167597, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 181.76250970363617, "Avg game time in secs": 1.8592916875786614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.78, "agent_stopped_0": 0.3}, "Total num played games": 51840, "Total num trained steps": 103165, "Timestamp in ms": 1701600226081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899699097291876, "Avg loss": 0.3139324252260849, "Avg value loss": 0.06800073946942575, "Avg policy loss": 0.24593168415594846, "Total num played games": 51842, "Total num trained steps": 103168, "Timestamp in ms": 1701600226909, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989062620349688, "Avg loss": 0.4265112087596208, "Avg value loss": 0.1844986762444023, "Avg policy loss": 0.24201253207866102, "Total num played games": 51932, "Total num trained steps": 103296, "Timestamp in ms": 1701600287195, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 89.41744785569608, "Avg game time in secs": 1.6620996198034845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 51968, "Total num trained steps": 103357, "Timestamp in ms": 1701600315498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878526947028523, "Avg loss": 0.4727113589178771, "Avg value loss": 0.218658872297965, "Avg policy loss": 0.2540524899959564, "Total num played games": 52028, "Total num trained steps": 103424, "Timestamp in ms": 1701600347173, "logtype": "training_step"}
{"Total num played games": 52028, "Total num trained steps": 103515, "Timestamp in ms": 1701600398891, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.765625}
{"Avg objective": 20.703125, "Games time in secs": 86.42094181105494, "Avg game time in secs": 1.6932873663899954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 52096, "Total num trained steps": 103521, "Timestamp in ms": 1701600401919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867042707493956, "Avg loss": 0.4476535585708916, "Avg value loss": 0.18116226745769382, "Avg policy loss": 0.266491289017722, "Total num played games": 52122, "Total num trained steps": 103552, "Timestamp in ms": 1701600416048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891792333371705, "Avg loss": 0.37952248530928046, "Avg value loss": 0.12410269150859676, "Avg policy loss": 0.2554197933059186, "Total num played games": 52122, "Total num trained steps": 103680, "Timestamp in ms": 1701600477231, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987973495729442, "Avg loss": 0.4442155850119889, "Avg value loss": 0.18657585149048828, "Avg policy loss": 0.2576397341908887, "Total num played games": 52218, "Total num trained steps": 103808, "Timestamp in ms": 1701600535140, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 184.96240769326687, "Avg game time in secs": 1.8350835965393344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 52224, "Total num trained steps": 103928, "Timestamp in ms": 1701600586882, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867721833543601, "Avg loss": 0.3480676820036024, "Avg value loss": 0.10616852817474864, "Avg policy loss": 0.24189915333408862, "Total num played games": 52314, "Total num trained steps": 103936, "Timestamp in ms": 1701600590684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892189471269641, "Avg loss": 0.4536567517789081, "Avg value loss": 0.19547551797586493, "Avg policy loss": 0.2581812316784635, "Total num played games": 52314, "Total num trained steps": 104064, "Timestamp in ms": 1701600647782, "logtype": "training_step"}
{"Total num played games": 52314, "Total num trained steps": 104115, "Timestamp in ms": 1701600680058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9453125}
{"Avg objective": 21.9140625, "Games time in secs": 95.86292357183993, "Avg game time in secs": 1.7436542062932858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 52352, "Total num trained steps": 104120, "Timestamp in ms": 1701600682745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880934208517784, "Avg loss": 0.43638802552595735, "Avg value loss": 0.18215867443359457, "Avg policy loss": 0.254229350714013, "Total num played games": 52408, "Total num trained steps": 104192, "Timestamp in ms": 1701600716544, "logtype": "training_step"}
{"Avg objective": 20.9453125, "Games time in secs": 87.7555689048022, "Avg game time in secs": 1.8999149779992877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.71, "agent_stopped_0": 0.31}, "Total num played games": 52480, "Total num trained steps": 104310, "Timestamp in ms": 1701600770501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868962364772207, "Avg loss": 0.3610629814211279, "Avg value loss": 0.10891338394139893, "Avg policy loss": 0.25214959937147796, "Total num played games": 52504, "Total num trained steps": 104320, "Timestamp in ms": 1701600775132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893150998019198, "Avg loss": 0.4091458725742996, "Avg value loss": 0.1516889080812689, "Avg policy loss": 0.2574569648131728, "Total num played games": 52504, "Total num trained steps": 104448, "Timestamp in ms": 1701600833133, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882124795619605, "Avg loss": 0.41484181059058756, "Avg value loss": 0.15855105998343788, "Avg policy loss": 0.2562907477840781, "Total num played games": 52598, "Total num trained steps": 104576, "Timestamp in ms": 1701600891431, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 171.49666473083198, "Avg game time in secs": 1.7430275466613239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 52608, "Total num trained steps": 104687, "Timestamp in ms": 1701600941998, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870948151522052, "Avg loss": 0.37803270877338946, "Avg value loss": 0.12501094557228498, "Avg policy loss": 0.25302176468539983, "Total num played games": 52692, "Total num trained steps": 104704, "Timestamp in ms": 1701600949875, "logtype": "training_step"}
{"Total num played games": 52692, "Total num trained steps": 104719, "Timestamp in ms": 1701600967917, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.65234375}
{"Avg objective": 19.9921875, "Games time in secs": 28.55743560194969, "Avg game time in secs": 1.6286501368886093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.55}, "Total num played games": 52736, "Total num trained steps": 104724, "Timestamp in ms": 1701600970555, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985981131360588, "Avg loss": 0.5535405988339335, "Avg value loss": 0.27200298121897504, "Avg policy loss": 0.2815376177895814, "Total num played games": 52786, "Total num trained steps": 104832, "Timestamp in ms": 1701601019705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884060167468647, "Avg loss": 0.32946007000282407, "Avg value loss": 0.07192267963546328, "Avg policy loss": 0.2575373915024102, "Total num played games": 52786, "Total num trained steps": 104960, "Timestamp in ms": 1701601077742, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 153.8808828536421, "Avg game time in secs": 1.7449549733864842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 52864, "Total num trained steps": 105067, "Timestamp in ms": 1701601124436, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872168223592148, "Avg loss": 0.3798161535523832, "Avg value loss": 0.12353079763124697, "Avg policy loss": 0.2562853560084477, "Total num played games": 52882, "Total num trained steps": 105088, "Timestamp in ms": 1701601134135, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.38063098583370447, "Avg value loss": 0.11147553153568879, "Avg policy loss": 0.2691554556367919, "Total num played games": 52882, "Total num trained steps": 105216, "Timestamp in ms": 1701601189857, "logtype": "training_step"}
{"Total num played games": 52976, "Total num trained steps": 105322, "Timestamp in ms": 1701601249345, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.05859375}
{"Avg objective": 20.1015625, "Games time in secs": 127.14247956126928, "Avg game time in secs": 1.8455666574445786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.72, "agent_stopped_0": 0.34}, "Total num played games": 52992, "Total num trained steps": 105325, "Timestamp in ms": 1701601251579, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850009421518748, "Avg loss": 0.5080755265662447, "Avg value loss": 0.23280793335288763, "Avg policy loss": 0.2752675929805264, "Total num played games": 53070, "Total num trained steps": 105344, "Timestamp in ms": 1701601261139, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873940079140757, "Avg loss": 0.4176456821151078, "Avg value loss": 0.13504794117761776, "Avg policy loss": 0.28259774297475815, "Total num played games": 53070, "Total num trained steps": 105472, "Timestamp in ms": 1701601317804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989824759751272, "Avg loss": 0.34889615792781115, "Avg value loss": 0.08703609969234094, "Avg policy loss": 0.2618600612040609, "Total num played games": 53070, "Total num trained steps": 105600, "Timestamp in ms": 1701601377232, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 140.3425242435187, "Avg game time in secs": 1.710862772204564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 53120, "Total num trained steps": 105633, "Timestamp in ms": 1701601391922, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886953577608908, "Avg loss": 0.48014636314474046, "Avg value loss": 0.2093493490247056, "Avg policy loss": 0.27079701295588166, "Total num played games": 53164, "Total num trained steps": 105728, "Timestamp in ms": 1701601432764, "logtype": "training_step"}
{"Avg objective": 19.5859375, "Games time in secs": 82.69973921962082, "Avg game time in secs": 1.7488828678469872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.71}, "Total num played games": 53248, "Total num trained steps": 105822, "Timestamp in ms": 1701601474621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987532857679309, "Avg loss": 0.42454677529167384, "Avg value loss": 0.15681838797172531, "Avg policy loss": 0.26772838621400297, "Total num played games": 53260, "Total num trained steps": 105856, "Timestamp in ms": 1701601490949, "logtype": "training_step"}
{"Total num played games": 53260, "Total num trained steps": 105924, "Timestamp in ms": 1701601533621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.90625}
{"Ratio train steps to played games": 1.9864302582749185, "Avg loss": 0.4935744304675609, "Avg value loss": 0.20661163193290122, "Avg policy loss": 0.28696279937867075, "Total num played games": 53354, "Total num trained steps": 105984, "Timestamp in ms": 1701601562214, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888105858979646, "Avg loss": 0.33775889209937304, "Avg value loss": 0.07704370794817805, "Avg policy loss": 0.2607151825213805, "Total num played games": 53354, "Total num trained steps": 106112, "Timestamp in ms": 1701601621053, "logtype": "training_step"}
{"Avg objective": 20.671875, "Games time in secs": 185.29900220036507, "Avg game time in secs": 1.5731041994295083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.53, "agent_stopped_0": 0.48}, "Total num played games": 53376, "Total num trained steps": 106200, "Timestamp in ms": 1701601659925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877263882652298, "Avg loss": 0.4169881729176268, "Avg value loss": 0.15500041327322833, "Avg policy loss": 0.26198775914963335, "Total num played games": 53448, "Total num trained steps": 106240, "Timestamp in ms": 1701601677029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990102529561443, "Avg loss": 0.3498528904747218, "Avg value loss": 0.0883499245683197, "Avg policy loss": 0.26150296826381236, "Total num played games": 53448, "Total num trained steps": 106368, "Timestamp in ms": 1701601735158, "logtype": "training_step"}
{"Avg objective": 19.8828125, "Games time in secs": 83.91319064982235, "Avg game time in secs": 1.6953439575154334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.6, "agent_stopped_0": 0.41}, "Total num played games": 53504, "Total num trained steps": 106389, "Timestamp in ms": 1701601743838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989017967203317, "Avg loss": 0.5073736030608416, "Avg value loss": 0.22629500829498284, "Avg policy loss": 0.28107859392184764, "Total num played games": 53542, "Total num trained steps": 106496, "Timestamp in ms": 1701601789721, "logtype": "training_step"}
{"Total num played games": 53542, "Total num trained steps": 106524, "Timestamp in ms": 1701601812327, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.80859375}
{"Avg objective": 20.6640625, "Games time in secs": 72.12353562004864, "Avg game time in secs": 1.8649594523885753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 53632, "Total num trained steps": 106530, "Timestamp in ms": 1701601815962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879185621597435, "Avg loss": 0.4498936057789251, "Avg value loss": 0.17264667691779323, "Avg policy loss": 0.27724692958872765, "Total num played games": 53636, "Total num trained steps": 106624, "Timestamp in ms": 1701601857997, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903050190170781, "Avg loss": 0.33471170626580715, "Avg value loss": 0.06863025549682789, "Avg policy loss": 0.26608145295176655, "Total num played games": 53636, "Total num trained steps": 106752, "Timestamp in ms": 1701601914869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892052856876978, "Avg loss": 0.4895851637702435, "Avg value loss": 0.21001580986194313, "Avg policy loss": 0.2795693592634052, "Total num played games": 53730, "Total num trained steps": 106880, "Timestamp in ms": 1701601973316, "logtype": "training_step"}
{"Avg objective": 19.9609375, "Games time in secs": 189.092076074332, "Avg game time in secs": 1.687673131484189, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 53760, "Total num trained steps": 106953, "Timestamp in ms": 1701602005054, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881093935790726, "Avg loss": 0.47336544829886407, "Avg value loss": 0.19616111286450177, "Avg policy loss": 0.2772043403238058, "Total num played games": 53824, "Total num trained steps": 107008, "Timestamp in ms": 1701602030787, "logtype": "training_step"}
{"Total num played games": 53824, "Total num trained steps": 107127, "Timestamp in ms": 1701602099670, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.82421875}
{"Avg objective": 19.3828125, "Games time in secs": 97.8163834773004, "Avg game time in secs": 1.813015271560289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.75, "agent_stopped_0": 0.31}, "Total num played games": 53888, "Total num trained steps": 107134, "Timestamp in ms": 1701602102870, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872384626799229, "Avg loss": 0.38984290254302323, "Avg value loss": 0.12153477035462856, "Avg policy loss": 0.26830813218839467, "Total num played games": 53912, "Total num trained steps": 107136, "Timestamp in ms": 1701602103545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893912978968062, "Avg loss": 0.47027421509847045, "Avg value loss": 0.1851736505923327, "Avg policy loss": 0.2851005676202476, "Total num played games": 53918, "Total num trained steps": 107264, "Timestamp in ms": 1701602164711, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882988965415094, "Avg loss": 0.4595494456589222, "Avg value loss": 0.1808749413175974, "Avg policy loss": 0.2786745069315657, "Total num played games": 54012, "Total num trained steps": 107392, "Timestamp in ms": 1701602223998, "logtype": "training_step"}
{"Avg objective": 19.4921875, "Games time in secs": 180.58106270618737, "Avg game time in secs": 1.7816250283067347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.71, "agent_stopped_0": 0.35}, "Total num played games": 54016, "Total num trained steps": 107515, "Timestamp in ms": 1701602283451, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871918086718663, "Avg loss": 0.35333687206730247, "Avg value loss": 0.08222933445358649, "Avg policy loss": 0.2711075395345688, "Total num played games": 54106, "Total num trained steps": 107520, "Timestamp in ms": 1701602285488, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895760174472332, "Avg loss": 0.46173150441609323, "Avg value loss": 0.1834763857186772, "Avg policy loss": 0.2782551166601479, "Total num played games": 54106, "Total num trained steps": 107648, "Timestamp in ms": 1701602343564, "logtype": "training_step"}
{"Avg objective": 19.78125, "Games time in secs": 85.36708354577422, "Avg game time in secs": 1.6547884391620755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 54144, "Total num trained steps": 107705, "Timestamp in ms": 1701602368819, "logtype": "played_game"}
{"Total num played games": 54206, "Total num trained steps": 107729, "Timestamp in ms": 1701602389991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1171875}
{"Avg objective": 22.0, "Games time in secs": 24.203650657087564, "Avg game time in secs": 1.667717861942947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.6, "agent_stopped_0": 0.41}, "Total num played games": 54272, "Total num trained steps": 107733, "Timestamp in ms": 1701602393023, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848250460405157, "Avg loss": 0.5838606137549505, "Avg value loss": 0.30455293820705265, "Avg policy loss": 0.27930767729412764, "Total num played games": 54300, "Total num trained steps": 107776, "Timestamp in ms": 1701602412563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871639042357274, "Avg loss": 0.39365440350957215, "Avg value loss": 0.11180763019365259, "Avg policy loss": 0.2818467696197331, "Total num played games": 54300, "Total num trained steps": 107904, "Timestamp in ms": 1701602471134, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895395948434622, "Avg loss": 0.32597552821971476, "Avg value loss": 0.06627976897289045, "Avg policy loss": 0.2596957547357306, "Total num played games": 54300, "Total num trained steps": 108032, "Timestamp in ms": 1701602532503, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988454608964224, "Avg loss": 0.4228767774766311, "Avg value loss": 0.15689861369901337, "Avg policy loss": 0.2659781649708748, "Total num played games": 54394, "Total num trained steps": 108160, "Timestamp in ms": 1701602591748, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 252.07896984741092, "Avg game time in secs": 1.7792054219607962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.7}, "Total num played games": 54400, "Total num trained steps": 108279, "Timestamp in ms": 1701602645102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873733666128321, "Avg loss": 0.3598981605609879, "Avg value loss": 0.09937772707780823, "Avg policy loss": 0.260520429816097, "Total num played games": 54488, "Total num trained steps": 108288, "Timestamp in ms": 1701602648769, "logtype": "training_step"}
{"Total num played games": 54488, "Total num trained steps": 108330, "Timestamp in ms": 1701602679287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1171875}
{"Avg objective": 19.7109375, "Games time in secs": 36.62749115563929, "Avg game time in secs": 1.656959489613655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 54528, "Total num trained steps": 108335, "Timestamp in ms": 1701602681729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862958484482063, "Avg loss": 0.5608662716113031, "Avg value loss": 0.28147968009579927, "Avg policy loss": 0.27938659384381026, "Total num played games": 54582, "Total num trained steps": 108416, "Timestamp in ms": 1701602721484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886409439009196, "Avg loss": 0.335937264142558, "Avg value loss": 0.0784873842203524, "Avg policy loss": 0.2574498796602711, "Total num played games": 54582, "Total num trained steps": 108544, "Timestamp in ms": 1701602781600, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 152.635483764112, "Avg game time in secs": 1.5975013001880143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.55}, "Total num played games": 54656, "Total num trained steps": 108657, "Timestamp in ms": 1701602834365, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875630989831004, "Avg loss": 0.3877958774100989, "Avg value loss": 0.13642568307113834, "Avg policy loss": 0.2513701942516491, "Total num played games": 54676, "Total num trained steps": 108672, "Timestamp in ms": 1701602840514, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899041627039287, "Avg loss": 0.3991707901004702, "Avg value loss": 0.1359081328555476, "Avg policy loss": 0.26326265663374215, "Total num played games": 54676, "Total num trained steps": 108800, "Timestamp in ms": 1701602898922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888259996348365, "Avg loss": 0.436022064415738, "Avg value loss": 0.17235714368871413, "Avg policy loss": 0.26366491965018213, "Total num played games": 54770, "Total num trained steps": 108928, "Timestamp in ms": 1701602957038, "logtype": "training_step"}
{"Total num played games": 54770, "Total num trained steps": 108934, "Timestamp in ms": 1701602971997, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.71484375}
{"Avg objective": 21.1953125, "Games time in secs": 139.67973625659943, "Avg game time in secs": 1.695284669607645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 54784, "Total num trained steps": 108937, "Timestamp in ms": 1701602974045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987733304170312, "Avg loss": 0.4253419756423682, "Avg value loss": 0.1588866022939328, "Avg policy loss": 0.2664553764043376, "Total num played games": 54864, "Total num trained steps": 109056, "Timestamp in ms": 1701603030581, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900845727617382, "Avg loss": 0.3112194755813107, "Avg value loss": 0.06196847723913379, "Avg policy loss": 0.24925099581014365, "Total num played games": 54864, "Total num trained steps": 109184, "Timestamp in ms": 1701603091803, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 135.67156153172255, "Avg game time in secs": 1.552507630069158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.48, "agent_stopped_0": 0.53}, "Total num played games": 54912, "Total num trained steps": 109221, "Timestamp in ms": 1701603109717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890097892936425, "Avg loss": 0.41979699849616736, "Avg value loss": 0.15511754507315345, "Avg policy loss": 0.2646794547326863, "Total num played games": 54958, "Total num trained steps": 109312, "Timestamp in ms": 1701603151285, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 83.04292664676905, "Avg game time in secs": 1.8252966281143017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 55040, "Total num trained steps": 109410, "Timestamp in ms": 1701603192760, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879386761607207, "Avg loss": 0.44335135247092694, "Avg value loss": 0.1790285670722369, "Avg policy loss": 0.26432278868742287, "Total num played games": 55052, "Total num trained steps": 109440, "Timestamp in ms": 1701603205593, "logtype": "training_step"}
{"Total num played games": 55052, "Total num trained steps": 109536, "Timestamp in ms": 1701603260638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.2578125}
{"Ratio train steps to played games": 1.9868712145939869, "Avg loss": 0.4254490432795137, "Avg value loss": 0.16061954773613252, "Avg policy loss": 0.2648294965038076, "Total num played games": 55146, "Total num trained steps": 109568, "Timestamp in ms": 1701603276528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891923258259891, "Avg loss": 0.36197752377483994, "Avg value loss": 0.09361598020768724, "Avg policy loss": 0.2683615433052182, "Total num played games": 55146, "Total num trained steps": 109696, "Timestamp in ms": 1701603337792, "logtype": "training_step"}
{"Avg objective": 20.296875, "Games time in secs": 183.8467086609453, "Avg game time in secs": 1.6297208715695888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.53, "agent_stopped_0": 0.53}, "Total num played games": 55168, "Total num trained steps": 109784, "Timestamp in ms": 1701603376607, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881064446053585, "Avg loss": 0.3985420261742547, "Avg value loss": 0.14268772784271277, "Avg policy loss": 0.25585429498460144, "Total num played games": 55240, "Total num trained steps": 109824, "Timestamp in ms": 1701603394497, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904417089065893, "Avg loss": 0.3390596993267536, "Avg value loss": 0.08145110687473789, "Avg policy loss": 0.25760859285946935, "Total num played games": 55240, "Total num trained steps": 109952, "Timestamp in ms": 1701603451325, "logtype": "training_step"}
{"Avg objective": 20.5546875, "Games time in secs": 83.95088066905737, "Avg game time in secs": 1.6004939115955494, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 55296, "Total num trained steps": 109973, "Timestamp in ms": 1701603460558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893017203990169, "Avg loss": 0.4418454604456201, "Avg value loss": 0.17697480641072616, "Avg policy loss": 0.2648706530453637, "Total num played games": 55336, "Total num trained steps": 110080, "Timestamp in ms": 1701603511644, "logtype": "training_step"}
{"Total num played games": 55336, "Total num trained steps": 110135, "Timestamp in ms": 1701603547516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.91015625}
{"Avg objective": 21.0625, "Games time in secs": 90.36721594259143, "Avg game time in secs": 1.740119579655584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.63, "agent_stopped_0": 0.38}, "Total num played games": 55424, "Total num trained steps": 110141, "Timestamp in ms": 1701603550925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988237416561429, "Avg loss": 0.47697447845712304, "Avg value loss": 0.20962912606773898, "Avg policy loss": 0.2673453517490998, "Total num played games": 55430, "Total num trained steps": 110208, "Timestamp in ms": 1701603581795, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905466353959949, "Avg loss": 0.3284932920942083, "Avg value loss": 0.07338012152467854, "Avg policy loss": 0.2551131701329723, "Total num played games": 55430, "Total num trained steps": 110336, "Timestamp in ms": 1701603639285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894103663148794, "Avg loss": 0.42030442180112004, "Avg value loss": 0.1675365065166261, "Avg policy loss": 0.2527679125778377, "Total num played games": 55526, "Total num trained steps": 110464, "Timestamp in ms": 1701603696302, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 181.531400103122, "Avg game time in secs": 1.5526737481850432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 55552, "Total num trained steps": 110544, "Timestamp in ms": 1701603732457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882780194886915, "Avg loss": 0.41983632557094097, "Avg value loss": 0.17489779915194958, "Avg policy loss": 0.24493853084277362, "Total num played games": 55622, "Total num trained steps": 110592, "Timestamp in ms": 1701603752635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905612886987163, "Avg loss": 0.3241473603993654, "Avg value loss": 0.0853554978093598, "Avg policy loss": 0.2387918618042022, "Total num played games": 55622, "Total num trained steps": 110720, "Timestamp in ms": 1701603807281, "logtype": "training_step"}
{"Avg objective": 19.3203125, "Games time in secs": 82.29226385988295, "Avg game time in secs": 1.5924708805105183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 55680, "Total num trained steps": 110737, "Timestamp in ms": 1701603814749, "logtype": "played_game"}
{"Total num played games": 55716, "Total num trained steps": 110739, "Timestamp in ms": 1701603826886, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3671875}
{"Avg objective": 20.234375, "Games time in secs": 16.018133463338017, "Avg game time in secs": 1.774015652554226, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 55808, "Total num trained steps": 110746, "Timestamp in ms": 1701603830768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861673535208744, "Avg loss": 0.5402363429311663, "Avg value loss": 0.2786079841607716, "Avg policy loss": 0.2616283615352586, "Total num played games": 55810, "Total num trained steps": 110848, "Timestamp in ms": 1701603876572, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884608493101594, "Avg loss": 0.3118679380277172, "Avg value loss": 0.06696138085681014, "Avg policy loss": 0.2449065549299121, "Total num played games": 55810, "Total num trained steps": 110976, "Timestamp in ms": 1701603936262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907364271635908, "Avg loss": 0.28630897600669414, "Avg value loss": 0.05117827435606159, "Avg policy loss": 0.23513070109765977, "Total num played games": 55810, "Total num trained steps": 111104, "Timestamp in ms": 1701603993950, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896254427074016, "Avg loss": 0.43056134518701583, "Avg value loss": 0.1765109948173631, "Avg policy loss": 0.2540503485361114, "Total num played games": 55906, "Total num trained steps": 111232, "Timestamp in ms": 1701604051684, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 253.97728257253766, "Avg game time in secs": 1.614023097223253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.57, "agent_stopped_0": 0.46}, "Total num played games": 55936, "Total num trained steps": 111304, "Timestamp in ms": 1701604084745, "logtype": "played_game"}
{"Total num played games": 56000, "Total num trained steps": 111341, "Timestamp in ms": 1701604112924, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.66015625}
{"Avg objective": 19.9765625, "Games time in secs": 31.213816536590457, "Avg game time in secs": 1.6873364294879138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.64}, "Total num played games": 56064, "Total num trained steps": 111347, "Timestamp in ms": 1701604115959, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852390630013905, "Avg loss": 0.4665857448708266, "Avg value loss": 0.20604799984721467, "Avg policy loss": 0.2605377429863438, "Total num played games": 56094, "Total num trained steps": 111360, "Timestamp in ms": 1701604121732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987520946981852, "Avg loss": 0.4388264187145978, "Avg value loss": 0.1557815378473606, "Avg policy loss": 0.28304487897548825, "Total num played games": 56094, "Total num trained steps": 111488, "Timestamp in ms": 1701604179223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898028309623133, "Avg loss": 0.3114502840908244, "Avg value loss": 0.05928836247767322, "Avg policy loss": 0.25216192356310785, "Total num played games": 56094, "Total num trained steps": 111616, "Timestamp in ms": 1701604237167, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988681260010678, "Avg loss": 0.41785704728681594, "Avg value loss": 0.15622872789390385, "Avg policy loss": 0.2616283184615895, "Total num played games": 56190, "Total num trained steps": 111744, "Timestamp in ms": 1701604294291, "logtype": "training_step"}
{"Avg objective": 20.4921875, "Games time in secs": 237.63533762656152, "Avg game time in secs": 1.6799271666677669, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 56192, "Total num trained steps": 111870, "Timestamp in ms": 1701604353594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904455198918227, "Avg loss": 0.3453784658340737, "Avg value loss": 0.08177982640336268, "Avg policy loss": 0.26359863905236125, "Total num played games": 56204, "Total num trained steps": 111872, "Timestamp in ms": 1701604354305, "logtype": "training_step"}
{"Total num played games": 56286, "Total num trained steps": 111941, "Timestamp in ms": 1701604396660, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.27734375}
{"Avg objective": 19.5390625, "Games time in secs": 45.74636792950332, "Avg game time in secs": 1.6743048629141413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 56320, "Total num trained steps": 111946, "Timestamp in ms": 1701604399341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865200425682867, "Avg loss": 0.5399853456765413, "Avg value loss": 0.26130304631078616, "Avg policy loss": 0.2786822997732088, "Total num played games": 56380, "Total num trained steps": 112000, "Timestamp in ms": 1701604422564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887903511883647, "Avg loss": 0.34751368849538267, "Avg value loss": 0.08274373583844863, "Avg policy loss": 0.2647699551889673, "Total num played games": 56380, "Total num trained steps": 112128, "Timestamp in ms": 1701604482583, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 139.6519677080214, "Avg game time in secs": 1.7130359623552067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.62, "agent_stopped_0": 0.4}, "Total num played games": 56448, "Total num trained steps": 112254, "Timestamp in ms": 1701604538993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878873738268108, "Avg loss": 0.31870942120440304, "Avg value loss": 0.057426675368333235, "Avg policy loss": 0.261282745632343, "Total num played games": 56468, "Total num trained steps": 112256, "Timestamp in ms": 1701604539729, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989995396111485, "Avg loss": 0.44912789936643094, "Avg value loss": 0.18447772270883434, "Avg policy loss": 0.2646501724375412, "Total num played games": 56474, "Total num trained steps": 112384, "Timestamp in ms": 1701604597314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889690284259651, "Avg loss": 0.3974436459830031, "Avg value loss": 0.14164087563403882, "Avg policy loss": 0.2558027724735439, "Total num played games": 56568, "Total num trained steps": 112512, "Timestamp in ms": 1701604655927, "logtype": "training_step"}
{"Total num played games": 56568, "Total num trained steps": 112541, "Timestamp in ms": 1701604680373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4296875}
{"Avg objective": 20.875, "Games time in secs": 143.53896288201213, "Avg game time in secs": 1.8364700405072654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.74, "agent_stopped_0": 0.34}, "Total num played games": 56576, "Total num trained steps": 112545, "Timestamp in ms": 1701604682532, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879284176343934, "Avg loss": 0.442458817968145, "Avg value loss": 0.16894210569444112, "Avg policy loss": 0.2735167134087533, "Total num played games": 56662, "Total num trained steps": 112640, "Timestamp in ms": 1701604724721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990187427199887, "Avg loss": 0.31439209810923785, "Avg value loss": 0.059911360760452226, "Avg policy loss": 0.254480738658458, "Total num played games": 56662, "Total num trained steps": 112768, "Timestamp in ms": 1701604784884, "logtype": "training_step"}
{"Avg objective": 20.2265625, "Games time in secs": 126.03151127509773, "Avg game time in secs": 1.4973878103191964, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 56704, "Total num trained steps": 112816, "Timestamp in ms": 1701604808564, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989146521953626, "Avg loss": 0.4221737377811223, "Avg value loss": 0.16209263427299447, "Avg policy loss": 0.2600811024894938, "Total num played games": 56756, "Total num trained steps": 112896, "Timestamp in ms": 1701604844656, "logtype": "training_step"}
{"Avg objective": 19.21875, "Games time in secs": 84.83529132604599, "Avg game time in secs": 1.6963336311309831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.63, "agent_stopped_0": 0.4}, "Total num played games": 56832, "Total num trained steps": 113005, "Timestamp in ms": 1701604893399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988109058927001, "Avg loss": 0.40677296300418675, "Avg value loss": 0.14738122333073989, "Avg policy loss": 0.25939174031373113, "Total num played games": 56850, "Total num trained steps": 113024, "Timestamp in ms": 1701604901681, "logtype": "training_step"}
{"Total num played games": 56850, "Total num trained steps": 113143, "Timestamp in ms": 1701604963719, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5390625}
{"Ratio train steps to played games": 1.9870750210733352, "Avg loss": 0.4011446216609329, "Avg value loss": 0.13098999342764728, "Avg policy loss": 0.2701546289026737, "Total num played games": 56944, "Total num trained steps": 113152, "Timestamp in ms": 1701604967946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893228434953638, "Avg loss": 0.42816032585687935, "Avg value loss": 0.1552925489959307, "Avg policy loss": 0.27286778087727726, "Total num played games": 56944, "Total num trained steps": 113280, "Timestamp in ms": 1701605028258, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 180.09921685233712, "Avg game time in secs": 1.6847743237158284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.67, "agent_stopped_0": 0.35}, "Total num played games": 56960, "Total num trained steps": 113380, "Timestamp in ms": 1701605073499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882885094147762, "Avg loss": 0.4037595211993903, "Avg value loss": 0.13986881241726223, "Avg policy loss": 0.26389070705045015, "Total num played games": 57038, "Total num trained steps": 113408, "Timestamp in ms": 1701605086144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905326273712263, "Avg loss": 0.38582948956172913, "Avg value loss": 0.11369926910265349, "Avg policy loss": 0.27213022019714117, "Total num played games": 57038, "Total num trained steps": 113536, "Timestamp in ms": 1701605145769, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 86.37677557393909, "Avg game time in secs": 1.6948955832485808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.56}, "Total num played games": 57088, "Total num trained steps": 113566, "Timestamp in ms": 1701605159875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989498004620878, "Avg loss": 0.5611776277655736, "Avg value loss": 0.2799532666685991, "Avg policy loss": 0.2812243611551821, "Total num played games": 57132, "Total num trained steps": 113664, "Timestamp in ms": 1701605202753, "logtype": "training_step"}
{"Total num played games": 57132, "Total num trained steps": 113744, "Timestamp in ms": 1701605249671, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.171875}
{"Avg objective": 20.7734375, "Games time in secs": 93.38658275455236, "Avg game time in secs": 1.919134132025647, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.82}, "Total num played games": 57216, "Total num trained steps": 113750, "Timestamp in ms": 1701605253262, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884493062593926, "Avg loss": 0.4671367919072509, "Avg value loss": 0.19428515352774411, "Avg policy loss": 0.27285163337364793, "Total num played games": 57226, "Total num trained steps": 113792, "Timestamp in ms": 1701605272598, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906860517946388, "Avg loss": 0.35381613101344556, "Avg value loss": 0.08261951632448472, "Avg policy loss": 0.271196611574851, "Total num played games": 57226, "Total num trained steps": 113920, "Timestamp in ms": 1701605332437, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989672016748081, "Avg loss": 0.44707144144922495, "Avg value loss": 0.166521788778482, "Avg policy loss": 0.2805496514774859, "Total num played games": 57320, "Total num trained steps": 114048, "Timestamp in ms": 1701605391783, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 176.56839727051556, "Avg game time in secs": 1.5376322263618931, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 57344, "Total num trained steps": 114132, "Timestamp in ms": 1701605429831, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885746133481956, "Avg loss": 0.4734971944708377, "Avg value loss": 0.20010272145736963, "Avg policy loss": 0.27339447010308504, "Total num played games": 57416, "Total num trained steps": 114176, "Timestamp in ms": 1701605449529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990803957085133, "Avg loss": 0.3559589490760118, "Avg value loss": 0.08349048279342242, "Avg policy loss": 0.2724684664281085, "Total num played games": 57416, "Total num trained steps": 114304, "Timestamp in ms": 1701605508028, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 87.1682836972177, "Avg game time in secs": 1.6636425607284764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 57472, "Total num trained steps": 114324, "Timestamp in ms": 1701605516999, "logtype": "played_game"}
{"Total num played games": 57510, "Total num trained steps": 114346, "Timestamp in ms": 1701605537934, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.171875}
{"Avg objective": 21.109375, "Games time in secs": 24.75808958336711, "Avg game time in secs": 1.8452157151768915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.72, "agent_stopped_0": 0.29}, "Total num played games": 57600, "Total num trained steps": 114354, "Timestamp in ms": 1701605541757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865113533782377, "Avg loss": 0.621423730859533, "Avg value loss": 0.31974274304229766, "Avg policy loss": 0.3016809810651466, "Total num played games": 57604, "Total num trained steps": 114432, "Timestamp in ms": 1701605575859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887507811957503, "Avg loss": 0.35770475561730564, "Avg value loss": 0.0739596652565524, "Avg policy loss": 0.28374509199056774, "Total num played games": 57604, "Total num trained steps": 114560, "Timestamp in ms": 1701605632908, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909728491077008, "Avg loss": 0.3347629464697093, "Avg value loss": 0.05949805103591643, "Avg policy loss": 0.27526489610318094, "Total num played games": 57604, "Total num trained steps": 114688, "Timestamp in ms": 1701605689867, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989947658497695, "Avg loss": 0.4661498870700598, "Avg value loss": 0.189496933540795, "Avg policy loss": 0.276652954868041, "Total num played games": 57698, "Total num trained steps": 114816, "Timestamp in ms": 1701605746720, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 239.5610491875559, "Avg game time in secs": 1.7304714674100978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.63, "agent_stopped_0": 0.38}, "Total num played games": 57728, "Total num trained steps": 114889, "Timestamp in ms": 1701605781319, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889258028792913, "Avg loss": 0.455027530901134, "Avg value loss": 0.18161259099724703, "Avg policy loss": 0.2734149399911985, "Total num played games": 57792, "Total num trained steps": 114944, "Timestamp in ms": 1701605805669, "logtype": "training_step"}
{"Total num played games": 57792, "Total num trained steps": 114946, "Timestamp in ms": 1701605824890, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.41015625}
{"Avg objective": 21.1328125, "Games time in secs": 46.51076443679631, "Avg game time in secs": 1.699860469205305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 57856, "Total num trained steps": 114952, "Timestamp in ms": 1701605827829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879072660055972, "Avg loss": 0.4997545669320971, "Avg value loss": 0.21699012248427607, "Avg policy loss": 0.28276444354560226, "Total num played games": 57886, "Total num trained steps": 115072, "Timestamp in ms": 1701605882866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901185087931452, "Avg loss": 0.3524208137532696, "Avg value loss": 0.0935176873463206, "Avg policy loss": 0.25890312576666474, "Total num played games": 57886, "Total num trained steps": 115200, "Timestamp in ms": 1701605942832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98909968954812, "Avg loss": 0.4326493850676343, "Avg value loss": 0.16191024659201503, "Avg policy loss": 0.27073913847561926, "Total num played games": 57980, "Total num trained steps": 115328, "Timestamp in ms": 1701605999376, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 226.94062343984842, "Avg game time in secs": 1.7896131211018655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.71, "agent_stopped_0": 0.31}, "Total num played games": 57984, "Total num trained steps": 115451, "Timestamp in ms": 1701606054771, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988152638104422, "Avg loss": 0.348650635802187, "Avg value loss": 0.08269522050977685, "Avg policy loss": 0.26595541276037693, "Total num played games": 58072, "Total num trained steps": 115456, "Timestamp in ms": 1701606056807, "logtype": "training_step"}
{"Total num played games": 58074, "Total num trained steps": 115546, "Timestamp in ms": 1701606108842, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.71875}
{"Avg objective": 21.28125, "Games time in secs": 56.522610396146774, "Avg game time in secs": 1.6871708912221948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 58112, "Total num trained steps": 115551, "Timestamp in ms": 1701606111294, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987071929583276, "Avg loss": 0.5167913818731904, "Avg value loss": 0.2338862861506641, "Avg policy loss": 0.2829050925793126, "Total num played games": 58168, "Total num trained steps": 115584, "Timestamp in ms": 1701606126058, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892724522073992, "Avg loss": 0.365501455264166, "Avg value loss": 0.0862239915295504, "Avg policy loss": 0.27927746437489986, "Total num played games": 58168, "Total num trained steps": 115712, "Timestamp in ms": 1701606187672, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 128.2359163314104, "Avg game time in secs": 1.7418441729678307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 58240, "Total num trained steps": 115830, "Timestamp in ms": 1701606239530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988191679253055, "Avg loss": 0.36688771669287235, "Avg value loss": 0.10449301687185653, "Avg policy loss": 0.262394699617289, "Total num played games": 58264, "Total num trained steps": 115840, "Timestamp in ms": 1701606243652, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903885761362077, "Avg loss": 0.4116850432474166, "Avg value loss": 0.14529821506584994, "Avg policy loss": 0.26638683036435395, "Total num played games": 58264, "Total num trained steps": 115968, "Timestamp in ms": 1701606298029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893759210391035, "Avg loss": 0.4575535284820944, "Avg value loss": 0.17815187203814276, "Avg policy loss": 0.27940165845211595, "Total num played games": 58358, "Total num trained steps": 116096, "Timestamp in ms": 1701606356416, "logtype": "training_step"}
{"Total num played games": 58358, "Total num trained steps": 116149, "Timestamp in ms": 1701606396124, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6796875}
{"Avg objective": 19.65625, "Games time in secs": 158.45603211596608, "Avg game time in secs": 1.8114004255476175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 58368, "Total num trained steps": 116151, "Timestamp in ms": 1701606397986, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988366522959009, "Avg loss": 0.464991245418787, "Avg value loss": 0.1760130800830666, "Avg policy loss": 0.2889781629201025, "Total num played games": 58452, "Total num trained steps": 116224, "Timestamp in ms": 1701606433260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905563539314308, "Avg loss": 0.33590355631895363, "Avg value loss": 0.06555174096138217, "Avg policy loss": 0.2703518148045987, "Total num played games": 58452, "Total num trained steps": 116352, "Timestamp in ms": 1701606490863, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 112.67738503217697, "Avg game time in secs": 1.6377038501668721, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.6}, "Total num played games": 58496, "Total num trained steps": 116396, "Timestamp in ms": 1701606510663, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895466812421003, "Avg loss": 0.469599005067721, "Avg value loss": 0.1925534550100565, "Avg policy loss": 0.2770455511054024, "Total num played games": 58546, "Total num trained steps": 116480, "Timestamp in ms": 1701606550845, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 89.08637110702693, "Avg game time in secs": 1.7983343974046875, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 58624, "Total num trained steps": 116586, "Timestamp in ms": 1701606599750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885402455661665, "Avg loss": 0.4084684607805684, "Avg value loss": 0.13136065113940276, "Avg policy loss": 0.27710780990310013, "Total num played games": 58640, "Total num trained steps": 116608, "Timestamp in ms": 1701606610190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990706002728513, "Avg loss": 0.35472785122692585, "Avg value loss": 0.09047845471650362, "Avg policy loss": 0.26424940035212785, "Total num played games": 58640, "Total num trained steps": 116736, "Timestamp in ms": 1701606668563, "logtype": "training_step"}
{"Total num played games": 58640, "Total num trained steps": 116753, "Timestamp in ms": 1701606690507, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.41015625}
{"Ratio train steps to played games": 1.9897163482820854, "Avg loss": 0.4574013454839587, "Avg value loss": 0.17764593299943954, "Avg policy loss": 0.2797554130665958, "Total num played games": 58734, "Total num trained steps": 116864, "Timestamp in ms": 1701606741693, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 184.1923144236207, "Avg game time in secs": 1.6963493281509727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.64, "agent_stopped_0": 0.38}, "Total num played games": 58752, "Total num trained steps": 116960, "Timestamp in ms": 1701606783942, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887128578228055, "Avg loss": 0.4148649370763451, "Avg value loss": 0.1519933195086196, "Avg policy loss": 0.26287161954678595, "Total num played games": 58828, "Total num trained steps": 116992, "Timestamp in ms": 1701606799112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908886924593732, "Avg loss": 0.36113376973662525, "Avg value loss": 0.09163718513445929, "Avg policy loss": 0.2694965838454664, "Total num played games": 58828, "Total num trained steps": 117120, "Timestamp in ms": 1701606855716, "logtype": "training_step"}
{"Avg objective": 19.75, "Games time in secs": 85.01195503026247, "Avg game time in secs": 1.6604575861565536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 58880, "Total num trained steps": 117149, "Timestamp in ms": 1701606868954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898849326227894, "Avg loss": 0.44346043723635375, "Avg value loss": 0.17179515049792826, "Avg policy loss": 0.2716652831295505, "Total num played games": 58922, "Total num trained steps": 117248, "Timestamp in ms": 1701606914385, "logtype": "training_step"}
{"Avg objective": 19.7734375, "Games time in secs": 85.8559463750571, "Avg game time in secs": 1.7278388494596584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.63, "agent_stopped_0": 0.4}, "Total num played games": 59008, "Total num trained steps": 117337, "Timestamp in ms": 1701606954810, "logtype": "played_game"}
{"Total num played games": 59016, "Total num trained steps": 117356, "Timestamp in ms": 1701606973509, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.91796875}
{"Ratio train steps to played games": 1.9857215361191, "Avg loss": 0.5225357606541365, "Avg value loss": 0.2554644923075102, "Avg policy loss": 0.2670712665421888, "Total num played games": 59110, "Total num trained steps": 117376, "Timestamp in ms": 1701606982639, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878869903569616, "Avg loss": 0.45167262689210474, "Avg value loss": 0.16906593207386322, "Avg policy loss": 0.28260669438168406, "Total num played games": 59110, "Total num trained steps": 117504, "Timestamp in ms": 1701607041229, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900524445948231, "Avg loss": 0.3667796903755516, "Avg value loss": 0.11095728102372959, "Avg policy loss": 0.2558224069653079, "Total num played games": 59110, "Total num trained steps": 117632, "Timestamp in ms": 1701607100703, "logtype": "training_step"}
{"Avg objective": 19.6953125, "Games time in secs": 182.18906238861382, "Avg game time in secs": 1.640744506381452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 59136, "Total num trained steps": 117712, "Timestamp in ms": 1701607137000, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890379028444023, "Avg loss": 0.41704345610924065, "Avg value loss": 0.15999089839169756, "Avg policy loss": 0.25705255568027496, "Total num played games": 59204, "Total num trained steps": 117760, "Timestamp in ms": 1701607158079, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991199918924397, "Avg loss": 0.3425681934459135, "Avg value loss": 0.08022534890915267, "Avg policy loss": 0.2623428449733183, "Total num played games": 59204, "Total num trained steps": 117888, "Timestamp in ms": 1701607216098, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 84.66934864223003, "Avg game time in secs": 1.6561987172317458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.63, "agent_stopped_0": 0.39}, "Total num played games": 59264, "Total num trained steps": 117901, "Timestamp in ms": 1701607221670, "logtype": "played_game"}
{"Total num played games": 59300, "Total num trained steps": 117956, "Timestamp in ms": 1701607256638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.85546875}
{"Avg objective": 21.1875, "Games time in secs": 38.97368425130844, "Avg game time in secs": 1.845823362164083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.7, "agent_stopped_0": 0.32}, "Total num played games": 59392, "Total num trained steps": 117963, "Timestamp in ms": 1701607260644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986985217362023, "Avg loss": 0.603194162948057, "Avg value loss": 0.33387651582597755, "Avg policy loss": 0.2693176467437297, "Total num played games": 59394, "Total num trained steps": 118016, "Timestamp in ms": 1701607283799, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891571539212716, "Avg loss": 0.351818609633483, "Avg value loss": 0.0835411459847819, "Avg policy loss": 0.2682774671120569, "Total num played games": 59394, "Total num trained steps": 118144, "Timestamp in ms": 1701607341914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912954170454928, "Avg loss": 0.30196862504817545, "Avg value loss": 0.05457497795578092, "Avg policy loss": 0.247393645811826, "Total num played games": 59394, "Total num trained steps": 118272, "Timestamp in ms": 1701607401676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903173749327596, "Avg loss": 0.46251305704936385, "Avg value loss": 0.19517333304975182, "Avg policy loss": 0.26733972900547087, "Total num played games": 59488, "Total num trained steps": 118400, "Timestamp in ms": 1701607458898, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 228.97049029543996, "Avg game time in secs": 1.5819173539348412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 59520, "Total num trained steps": 118468, "Timestamp in ms": 1701607489614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892588614393125, "Avg loss": 0.4438471340108663, "Avg value loss": 0.18021640920778736, "Avg policy loss": 0.2636307227658108, "Total num played games": 59584, "Total num trained steps": 118528, "Timestamp in ms": 1701607517285, "logtype": "training_step"}
{"Total num played games": 59584, "Total num trained steps": 118559, "Timestamp in ms": 1701607541001, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.546875}
{"Avg objective": 21.625, "Games time in secs": 54.38846827484667, "Avg game time in secs": 1.7037721653177869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 59648, "Total num trained steps": 118565, "Timestamp in ms": 1701607544003, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882536278025402, "Avg loss": 0.47882625414058566, "Avg value loss": 0.1986057119211182, "Avg policy loss": 0.2802205386105925, "Total num played games": 59678, "Total num trained steps": 118656, "Timestamp in ms": 1701607584763, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904152283923724, "Avg loss": 0.3419673873577267, "Avg value loss": 0.08463475634925999, "Avg policy loss": 0.2573326308047399, "Total num played games": 59678, "Total num trained steps": 118784, "Timestamp in ms": 1701607646353, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894264873184768, "Avg loss": 0.44637953280471265, "Avg value loss": 0.19012453820323572, "Avg policy loss": 0.2562549961730838, "Total num played games": 59772, "Total num trained steps": 118912, "Timestamp in ms": 1701607706381, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 216.89495921321213, "Avg game time in secs": 1.7991973419266287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.75, "agent_stopped_0": 0.33}, "Total num played games": 59776, "Total num trained steps": 119035, "Timestamp in ms": 1701607760898, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885737195549764, "Avg loss": 0.32767258561216295, "Avg value loss": 0.07590539954253472, "Avg policy loss": 0.2517671873793006, "Total num played games": 59860, "Total num trained steps": 119040, "Timestamp in ms": 1701607762783, "logtype": "training_step"}
{"Total num played games": 59868, "Total num trained steps": 119160, "Timestamp in ms": 1701607832367, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.09765625}
{"Avg objective": 20.46875, "Games time in secs": 73.90891144797206, "Avg game time in secs": 1.7273033879027935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 59904, "Total num trained steps": 119164, "Timestamp in ms": 1701607834807, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987392014942797, "Avg loss": 0.4391658082604408, "Avg value loss": 0.1813058409607038, "Avg policy loss": 0.25785996625199914, "Total num played games": 59962, "Total num trained steps": 119168, "Timestamp in ms": 1701607836186, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895267002434875, "Avg loss": 0.4340998320840299, "Avg value loss": 0.17301543059875257, "Avg policy loss": 0.2610844048904255, "Total num played games": 59962, "Total num trained steps": 119296, "Timestamp in ms": 1701607894728, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 117.11910999007523, "Avg game time in secs": 1.6832756315270672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 60032, "Total num trained steps": 119418, "Timestamp in ms": 1701607951926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884778047887042, "Avg loss": 0.326697526848875, "Avg value loss": 0.08935425785603002, "Avg policy loss": 0.23734327114652842, "Total num played games": 60058, "Total num trained steps": 119424, "Timestamp in ms": 1701607954301, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906090778913716, "Avg loss": 0.36636955849826336, "Avg value loss": 0.1224735117284581, "Avg policy loss": 0.24389604839961976, "Total num played games": 60058, "Total num trained steps": 119552, "Timestamp in ms": 1701608013518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896096555393004, "Avg loss": 0.4156653161626309, "Avg value loss": 0.17552679445361719, "Avg policy loss": 0.24013852840289474, "Total num played games": 60152, "Total num trained steps": 119680, "Timestamp in ms": 1701608073001, "logtype": "training_step"}
{"Total num played games": 60152, "Total num trained steps": 119763, "Timestamp in ms": 1701608123287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.59375}
{"Avg objective": 20.125, "Games time in secs": 173.13598616048694, "Avg game time in secs": 1.744770633013104, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.72, "agent_stopped_0": 0.32}, "Total num played games": 60160, "Total num trained steps": 119766, "Timestamp in ms": 1701608125063, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886465491484913, "Avg loss": 0.4170242549153045, "Avg value loss": 0.17716717833536677, "Avg policy loss": 0.23985707922838628, "Total num played games": 60246, "Total num trained steps": 119808, "Timestamp in ms": 1701608143957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99077117153006, "Avg loss": 0.3184451851993799, "Avg value loss": 0.0807058532955125, "Avg policy loss": 0.23773933271877468, "Total num played games": 60246, "Total num trained steps": 119936, "Timestamp in ms": 1701608199856, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 97.93105054274201, "Avg game time in secs": 1.583678635477554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.56}, "Total num played games": 60288, "Total num trained steps": 119984, "Timestamp in ms": 1701608222994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897252328394817, "Avg loss": 0.4304354531923309, "Avg value loss": 0.18167808357975446, "Avg policy loss": 0.24875736725516617, "Total num played games": 60342, "Total num trained steps": 120064, "Timestamp in ms": 1701608259878, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 88.83917980641127, "Avg game time in secs": 1.6773941712162923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 60416, "Total num trained steps": 120177, "Timestamp in ms": 1701608311833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886826168966545, "Avg loss": 0.3720442403573543, "Avg value loss": 0.1298952432407532, "Avg policy loss": 0.24214900098741055, "Total num played games": 60438, "Total num trained steps": 120192, "Timestamp in ms": 1701608318670, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908004897580993, "Avg loss": 0.37387880706228316, "Avg value loss": 0.12108636711491272, "Avg policy loss": 0.25279243860859424, "Total num played games": 60438, "Total num trained steps": 120320, "Timestamp in ms": 1701608377392, "logtype": "training_step"}
{"Total num played games": 60438, "Total num trained steps": 120364, "Timestamp in ms": 1701608407708, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.38671875}
{"Ratio train steps to played games": 1.989757822050418, "Avg loss": 0.41931147838477045, "Avg value loss": 0.16655968985287473, "Avg policy loss": 0.25275178952142596, "Total num played games": 60534, "Total num trained steps": 120448, "Timestamp in ms": 1701608446164, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 185.88945395871997, "Avg game time in secs": 1.8027305897703627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.72, "agent_stopped_0": 0.32}, "Total num played games": 60544, "Total num trained steps": 120560, "Timestamp in ms": 1701608497723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887840601702185, "Avg loss": 0.35507074068300426, "Avg value loss": 0.108342703897506, "Avg policy loss": 0.24672803620342165, "Total num played games": 60628, "Total num trained steps": 120576, "Timestamp in ms": 1701608505375, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908952959028832, "Avg loss": 0.35443684412166476, "Avg value loss": 0.09741582282003947, "Avg policy loss": 0.2570210200501606, "Total num played games": 60628, "Total num trained steps": 120704, "Timestamp in ms": 1701608560391, "logtype": "training_step"}
{"Avg objective": 20.34375, "Games time in secs": 82.73143228143454, "Avg game time in secs": 1.6937814286939101, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 60672, "Total num trained steps": 120749, "Timestamp in ms": 1701608580454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899212805902309, "Avg loss": 0.44111552252434194, "Avg value loss": 0.18507346755359322, "Avg policy loss": 0.2560420536901802, "Total num played games": 60722, "Total num trained steps": 120832, "Timestamp in ms": 1701608616960, "logtype": "training_step"}
{"Avg objective": 19.890625, "Games time in secs": 82.94316870905459, "Avg game time in secs": 1.8174511544057168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.75}, "Total num played games": 60800, "Total num trained steps": 120938, "Timestamp in ms": 1701608663398, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988950276243094, "Avg loss": 0.3634794754907489, "Avg value loss": 0.11145399408997037, "Avg policy loss": 0.2520254811970517, "Total num played games": 60816, "Total num trained steps": 120960, "Timestamp in ms": 1701608672959, "logtype": "training_step"}
{"Total num played games": 60816, "Total num trained steps": 120966, "Timestamp in ms": 1701608687170, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.59765625}
{"Ratio train steps to played games": 1.9879822689213593, "Avg loss": 0.47687852708622813, "Avg value loss": 0.2013789945631288, "Avg policy loss": 0.27549953246489167, "Total num played games": 60910, "Total num trained steps": 121088, "Timestamp in ms": 1701608744449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900837300935807, "Avg loss": 0.31733318709302694, "Avg value loss": 0.06313313983264379, "Avg policy loss": 0.25420004583429545, "Total num played games": 60910, "Total num trained steps": 121216, "Timestamp in ms": 1701608800538, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 181.30044917203486, "Avg game time in secs": 1.7147321182565065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 60928, "Total num trained steps": 121312, "Timestamp in ms": 1701608844698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891154678381746, "Avg loss": 0.3828772223787382, "Avg value loss": 0.1335990634688642, "Avg policy loss": 0.24927815655246377, "Total num played games": 61004, "Total num trained steps": 121344, "Timestamp in ms": 1701608858129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912136909055145, "Avg loss": 0.3887360541848466, "Avg value loss": 0.13169981085229665, "Avg policy loss": 0.2570362454280257, "Total num played games": 61004, "Total num trained steps": 121472, "Timestamp in ms": 1701608916671, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 85.05830185301602, "Avg game time in secs": 1.8306356568500632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.73}, "Total num played games": 61056, "Total num trained steps": 121501, "Timestamp in ms": 1701608929757, "logtype": "played_game"}
{"Total num played games": 61100, "Total num trained steps": 121568, "Timestamp in ms": 1701608969695, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.25}
{"Avg objective": 19.5546875, "Games time in secs": 43.40630903840065, "Avg game time in secs": 1.903695797736873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 61184, "Total num trained steps": 121575, "Timestamp in ms": 1701608973163, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987122920547766, "Avg loss": 0.6185492370277643, "Avg value loss": 0.3420203107234556, "Avg policy loss": 0.2765289241215214, "Total num played games": 61194, "Total num trained steps": 121600, "Timestamp in ms": 1701608985086, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892146288851849, "Avg loss": 0.3814609721302986, "Avg value loss": 0.1110418560274411, "Avg policy loss": 0.2704191153170541, "Total num played games": 61194, "Total num trained steps": 121728, "Timestamp in ms": 1701609040161, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912899957512173, "Avg loss": 0.33295989024918526, "Avg value loss": 0.08102703944314271, "Avg policy loss": 0.25193284987472, "Total num played games": 61194, "Total num trained steps": 121856, "Timestamp in ms": 1701609099108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903406865944393, "Avg loss": 0.4639210799941793, "Avg value loss": 0.1956579012912698, "Avg policy loss": 0.2682631785282865, "Total num played games": 61288, "Total num trained steps": 121984, "Timestamp in ms": 1701609156443, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 220.98653882741928, "Avg game time in secs": 1.707305674237432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.72, "agent_stopped_0": 0.36}, "Total num played games": 61312, "Total num trained steps": 122068, "Timestamp in ms": 1701609194150, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893617021276595, "Avg loss": 0.42505772039294243, "Avg value loss": 0.16336261859396473, "Avg policy loss": 0.261695102090016, "Total num played games": 61382, "Total num trained steps": 122112, "Timestamp in ms": 1701609212827, "logtype": "training_step"}
{"Total num played games": 61382, "Total num trained steps": 122172, "Timestamp in ms": 1701609248136, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.40234375}
{"Avg objective": 20.0234375, "Games time in secs": 56.90106651186943, "Avg game time in secs": 1.8080916189937852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.75, "agent_stopped_0": 0.3}, "Total num played games": 61440, "Total num trained steps": 122175, "Timestamp in ms": 1701609251051, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988418244518186, "Avg loss": 0.4960112529806793, "Avg value loss": 0.21829728898592293, "Avg policy loss": 0.27771396411117166, "Total num played games": 61476, "Total num trained steps": 122240, "Timestamp in ms": 1701609283038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905003578632312, "Avg loss": 0.3404762155842036, "Avg value loss": 0.07141265523387119, "Avg policy loss": 0.2690635600592941, "Total num played games": 61476, "Total num trained steps": 122368, "Timestamp in ms": 1701609342704, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 129.1372532080859, "Avg game time in secs": 1.7625805617572041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.74, "agent_stopped_0": 0.34}, "Total num played games": 61568, "Total num trained steps": 122446, "Timestamp in ms": 1701609380188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895241188890693, "Avg loss": 0.4616110709030181, "Avg value loss": 0.1932436883507762, "Avg policy loss": 0.2683673781575635, "Total num played games": 61570, "Total num trained steps": 122496, "Timestamp in ms": 1701609404090, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916030534351146, "Avg loss": 0.34401231387164444, "Avg value loss": 0.07308528016437776, "Avg policy loss": 0.2709270325722173, "Total num played games": 61570, "Total num trained steps": 122624, "Timestamp in ms": 1701609463885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905782765219084, "Avg loss": 0.4536173426313326, "Avg value loss": 0.17189890547888353, "Avg policy loss": 0.28171843744348735, "Total num played games": 61666, "Total num trained steps": 122752, "Timestamp in ms": 1701609523304, "logtype": "training_step"}
{"Total num played games": 61666, "Total num trained steps": 122774, "Timestamp in ms": 1701609544537, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.01953125}
{"Avg objective": 20.3125, "Games time in secs": 166.71280832588673, "Avg game time in secs": 1.61223275536031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 61696, "Total num trained steps": 122777, "Timestamp in ms": 1701609546901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.44352344213984907, "Avg value loss": 0.1604402205266524, "Avg policy loss": 0.2830832211766392, "Total num played games": 61760, "Total num trained steps": 122880, "Timestamp in ms": 1701609592774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917098445595856, "Avg loss": 0.3317947218893096, "Avg value loss": 0.061065002519171685, "Avg policy loss": 0.2707297190790996, "Total num played games": 61760, "Total num trained steps": 123008, "Timestamp in ms": 1701609651031, "logtype": "training_step"}
{"Avg objective": 20.9921875, "Games time in secs": 106.2788439951837, "Avg game time in secs": 1.6820748357422417, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 61824, "Total num trained steps": 123013, "Timestamp in ms": 1701609653180, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907524169819253, "Avg loss": 0.4828797560185194, "Avg value loss": 0.20490330446045846, "Avg policy loss": 0.27797645959071815, "Total num played games": 61854, "Total num trained steps": 123136, "Timestamp in ms": 1701609709932, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989797895008717, "Avg loss": 0.4433914707042277, "Avg value loss": 0.17295674062916078, "Avg policy loss": 0.2704347266117111, "Total num played games": 61948, "Total num trained steps": 123264, "Timestamp in ms": 1701609765961, "logtype": "training_step"}
{"Total num played games": 61948, "Total num trained steps": 123375, "Timestamp in ms": 1701609826835, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.71875}
{"Avg objective": 19.8203125, "Games time in secs": 175.12178258411586, "Avg game time in secs": 1.722150667803362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.67, "agent_stopped_0": 0.34}, "Total num played games": 61952, "Total num trained steps": 123376, "Timestamp in ms": 1701609828302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888462654330936, "Avg loss": 0.39530141244176775, "Avg value loss": 0.12472275871550664, "Avg policy loss": 0.27057865518145263, "Total num played games": 62042, "Total num trained steps": 123392, "Timestamp in ms": 1701609835580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909093839657006, "Avg loss": 0.4069507943931967, "Avg value loss": 0.14112162703531794, "Avg policy loss": 0.2658291665138677, "Total num played games": 62042, "Total num trained steps": 123520, "Timestamp in ms": 1701609890654, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 88.54539863951504, "Avg game time in secs": 1.5482891502324492, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.54}, "Total num played games": 62080, "Total num trained steps": 123577, "Timestamp in ms": 1701609916848, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899575125531093, "Avg loss": 0.41639400040730834, "Avg value loss": 0.1500502462440636, "Avg policy loss": 0.2663437551818788, "Total num played games": 62136, "Total num trained steps": 123648, "Timestamp in ms": 1701609947088, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 81.75331541337073, "Avg game time in secs": 1.7051543313427828, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 62208, "Total num trained steps": 123764, "Timestamp in ms": 1701609998601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889445944208768, "Avg loss": 0.37048443336971104, "Avg value loss": 0.10605190505157225, "Avg policy loss": 0.26443252654280514, "Total num played games": 62232, "Total num trained steps": 123776, "Timestamp in ms": 1701610002945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910014140635044, "Avg loss": 0.4008467502426356, "Avg value loss": 0.12796682145562954, "Avg policy loss": 0.2728799271862954, "Total num played games": 62232, "Total num trained steps": 123904, "Timestamp in ms": 1701610058271, "logtype": "training_step"}
{"Total num played games": 62326, "Total num trained steps": 123975, "Timestamp in ms": 1701610097616, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.62109375}
{"Avg objective": 20.6640625, "Games time in secs": 100.69310531392694, "Avg game time in secs": 1.7583497319719754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.68, "agent_stopped_0": 0.36}, "Total num played games": 62336, "Total num trained steps": 123978, "Timestamp in ms": 1701610099294, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987055430951618, "Avg loss": 0.5897289152489975, "Avg value loss": 0.30748573230812326, "Avg policy loss": 0.2822431803215295, "Total num played games": 62420, "Total num trained steps": 124032, "Timestamp in ms": 1701610123612, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891060557513618, "Avg loss": 0.37018079473637044, "Avg value loss": 0.09462906114640646, "Avg policy loss": 0.27555173530709, "Total num played games": 62420, "Total num trained steps": 124160, "Timestamp in ms": 1701610181707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911406600448573, "Avg loss": 0.31427248381078243, "Avg value loss": 0.0553620211139787, "Avg policy loss": 0.25891046319156885, "Total num played games": 62420, "Total num trained steps": 124288, "Timestamp in ms": 1701610239991, "logtype": "training_step"}
{"Avg objective": 19.7734375, "Games time in secs": 161.04731385968626, "Avg game time in secs": 1.4491653577570105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.46}, "Total num played games": 62464, "Total num trained steps": 124332, "Timestamp in ms": 1701610260342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902101929167866, "Avg loss": 0.43197549902834, "Avg value loss": 0.1668603667349089, "Avg policy loss": 0.26511513558216393, "Total num played games": 62514, "Total num trained steps": 124416, "Timestamp in ms": 1701610296351, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 82.68250309489667, "Avg game time in secs": 1.6955180563381873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.68, "agent_stopped_0": 0.35}, "Total num played games": 62592, "Total num trained steps": 124521, "Timestamp in ms": 1701610343025, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892665474060822, "Avg loss": 0.40174958552233875, "Avg value loss": 0.14176853818935342, "Avg policy loss": 0.25998104421887547, "Total num played games": 62608, "Total num trained steps": 124544, "Timestamp in ms": 1701610352776, "logtype": "training_step"}
{"Total num played games": 62608, "Total num trained steps": 124577, "Timestamp in ms": 1701610377540, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9140625}
{"Ratio train steps to played games": 1.9883257312366431, "Avg loss": 0.5031277637463063, "Avg value loss": 0.22339323163032532, "Avg policy loss": 0.2797345343278721, "Total num played games": 62702, "Total num trained steps": 124672, "Timestamp in ms": 1701610423226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903671334247712, "Avg loss": 0.3207525071920827, "Avg value loss": 0.06314838631078601, "Avg policy loss": 0.2576041214633733, "Total num played games": 62702, "Total num trained steps": 124800, "Timestamp in ms": 1701610482972, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 185.54547589458525, "Avg game time in secs": 1.6233490055019502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 62720, "Total num trained steps": 124896, "Timestamp in ms": 1701610528570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894260780941462, "Avg loss": 0.4016433919314295, "Avg value loss": 0.1368317998421844, "Avg policy loss": 0.2648115953197703, "Total num played games": 62796, "Total num trained steps": 124928, "Timestamp in ms": 1701610544577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991464424485636, "Avg loss": 0.34578404494095594, "Avg value loss": 0.08039847321924753, "Avg policy loss": 0.2653855716343969, "Total num played games": 62796, "Total num trained steps": 125056, "Timestamp in ms": 1701610603858, "logtype": "training_step"}
{"Avg objective": 19.453125, "Games time in secs": 88.97966822423041, "Avg game time in secs": 1.7475537207501475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.7}, "Total num played games": 62848, "Total num trained steps": 125084, "Timestamp in ms": 1701610617550, "logtype": "played_game"}
{"Total num played games": 62890, "Total num trained steps": 125178, "Timestamp in ms": 1701610669004, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.85546875}
{"Ratio train steps to played games": 1.9888627625432937, "Avg loss": 0.4297819777857512, "Avg value loss": 0.1679288039158564, "Avg policy loss": 0.2618531706975773, "Total num played games": 62940, "Total num trained steps": 125184, "Timestamp in ms": 1701610671714, "logtype": "training_step"}
{"Avg objective": 21.25, "Games time in secs": 54.874760909006, "Avg game time in secs": 1.781875889049843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.74}, "Total num played games": 62976, "Total num trained steps": 125185, "Timestamp in ms": 1701610672425, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895846564206783, "Avg loss": 0.4754044454311952, "Avg value loss": 0.2083815826335922, "Avg policy loss": 0.26702286256477237, "Total num played games": 62984, "Total num trained steps": 125312, "Timestamp in ms": 1701610730219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991601041534358, "Avg loss": 0.32835410069674253, "Avg value loss": 0.07756351053831168, "Avg policy loss": 0.2507905892562121, "Total num played games": 62984, "Total num trained steps": 125440, "Timestamp in ms": 1701610786084, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906623545451663, "Avg loss": 0.4394328431226313, "Avg value loss": 0.17707691084069666, "Avg policy loss": 0.26235593308229, "Total num played games": 63078, "Total num trained steps": 125568, "Timestamp in ms": 1701610841353, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 204.41661051474512, "Avg game time in secs": 1.6758096127887256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.61, "agent_stopped_0": 0.41}, "Total num played games": 63104, "Total num trained steps": 125648, "Timestamp in ms": 1701610876842, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897422908883682, "Avg loss": 0.4629647923866287, "Avg value loss": 0.20107628297409974, "Avg policy loss": 0.26188850752077997, "Total num played games": 63172, "Total num trained steps": 125696, "Timestamp in ms": 1701610899917, "logtype": "training_step"}
{"Total num played games": 63172, "Total num trained steps": 125781, "Timestamp in ms": 1701610951813, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.30859375}
{"Avg objective": 21.046875, "Games time in secs": 77.9467048086226, "Avg game time in secs": 1.73189693778113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.72}, "Total num played games": 63232, "Total num trained steps": 125786, "Timestamp in ms": 1701610954789, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888091549963645, "Avg loss": 0.44139131531119347, "Avg value loss": 0.175195386109408, "Avg policy loss": 0.2661959286779165, "Total num played games": 63266, "Total num trained steps": 125824, "Timestamp in ms": 1701610970835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990832358612841, "Avg loss": 0.3511633883463219, "Avg value loss": 0.09440811167587526, "Avg policy loss": 0.2567552758846432, "Total num played games": 63266, "Total num trained steps": 125952, "Timestamp in ms": 1701611028149, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 108.06260577216744, "Avg game time in secs": 2.0129788767226273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.82, "played_steps": 0.9, "agent_stopped_0": 0.18}, "Total num played games": 63360, "Total num trained steps": 126028, "Timestamp in ms": 1701611062851, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898361794135286, "Avg loss": 0.4303364861989394, "Avg value loss": 0.17588225391227752, "Avg policy loss": 0.25445423054043204, "Total num played games": 63362, "Total num trained steps": 126080, "Timestamp in ms": 1701611086549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918563176667403, "Avg loss": 0.3216178050497547, "Avg value loss": 0.06802543281810358, "Avg policy loss": 0.2535923697287217, "Total num played games": 63362, "Total num trained steps": 126208, "Timestamp in ms": 1701611144196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909228441754916, "Avg loss": 0.4263681066222489, "Avg value loss": 0.16436434598290361, "Avg policy loss": 0.26200376299675554, "Total num played games": 63456, "Total num trained steps": 126336, "Timestamp in ms": 1701611201325, "logtype": "training_step"}
{"Total num played games": 63456, "Total num trained steps": 126383, "Timestamp in ms": 1701611235768, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.83984375}
{"Avg objective": 19.9921875, "Games time in secs": 175.067653702572, "Avg game time in secs": 1.5775470039516222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 63488, "Total num trained steps": 126386, "Timestamp in ms": 1701611237919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899921321793863, "Avg loss": 0.43042851134669036, "Avg value loss": 0.17668416199740022, "Avg policy loss": 0.2537443443434313, "Total num played games": 63550, "Total num trained steps": 126464, "Timestamp in ms": 1701611272568, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916144866429628, "Avg loss": 0.3250200927723199, "Avg value loss": 0.07438951040967368, "Avg policy loss": 0.2506305822171271, "Total num played games": 63562, "Total num trained steps": 126592, "Timestamp in ms": 1701611330088, "logtype": "training_step"}
{"Avg objective": 20.0546875, "Games time in secs": 93.19750900380313, "Avg game time in secs": 1.6856576596037485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 63616, "Total num trained steps": 126594, "Timestamp in ms": 1701611331117, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910753566714852, "Avg loss": 0.4713580508250743, "Avg value loss": 0.20884863974060863, "Avg policy loss": 0.2625094131799415, "Total num played games": 63644, "Total num trained steps": 126720, "Timestamp in ms": 1701611389387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901314757287647, "Avg loss": 0.49472085817251354, "Avg value loss": 0.2311621377884876, "Avg policy loss": 0.263558721751906, "Total num played games": 63738, "Total num trained steps": 126848, "Timestamp in ms": 1701611446495, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 170.3956326805055, "Avg game time in secs": 1.814240758496453, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.75, "agent_stopped_0": 0.31}, "Total num played games": 63744, "Total num trained steps": 126967, "Timestamp in ms": 1701611501513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989159382147445, "Avg loss": 0.3637538579059765, "Avg value loss": 0.10436310328077525, "Avg policy loss": 0.2593907527625561, "Total num played games": 63834, "Total num trained steps": 126976, "Timestamp in ms": 1701611505288, "logtype": "training_step"}
{"Total num played games": 63834, "Total num trained steps": 126986, "Timestamp in ms": 1701611520214, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.78125}
{"Avg objective": 20.46875, "Games time in secs": 21.352749979123473, "Avg game time in secs": 1.574183582852129, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 63872, "Total num trained steps": 126990, "Timestamp in ms": 1701611522866, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882367663621574, "Avg loss": 0.6098854450974613, "Avg value loss": 0.3254673440824263, "Avg policy loss": 0.2844180987449363, "Total num played games": 63928, "Total num trained steps": 127104, "Timestamp in ms": 1701611575684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902233762983357, "Avg loss": 0.3372443813132122, "Avg value loss": 0.0740641295851674, "Avg policy loss": 0.26318025041837245, "Total num played games": 63928, "Total num trained steps": 127232, "Timestamp in ms": 1701611635354, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 163.7794152572751, "Avg game time in secs": 1.673017798064393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 64000, "Total num trained steps": 127349, "Timestamp in ms": 1701611686645, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989254029738848, "Avg loss": 0.330193615751341, "Avg value loss": 0.08131550677353516, "Avg policy loss": 0.24887810996733606, "Total num played games": 64024, "Total num trained steps": 127360, "Timestamp in ms": 1701611691572, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912532800199925, "Avg loss": 0.3834628410404548, "Avg value loss": 0.12098389115999453, "Avg policy loss": 0.26247894729021937, "Total num played games": 64024, "Total num trained steps": 127488, "Timestamp in ms": 1701611751900, "logtype": "training_step"}
{"Total num played games": 64120, "Total num trained steps": 127586, "Timestamp in ms": 1701611804049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.109375}
{"Avg objective": 19.6484375, "Games time in secs": 119.1217344161123, "Avg game time in secs": 1.7418569242290687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.73, "agent_stopped_0": 0.31}, "Total num played games": 64128, "Total num trained steps": 127587, "Timestamp in ms": 1701611805767, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873547824461955, "Avg loss": 0.5101518728770316, "Avg value loss": 0.2391634401283227, "Avg policy loss": 0.27098843874409795, "Total num played games": 64214, "Total num trained steps": 127616, "Timestamp in ms": 1701611818436, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893325443049803, "Avg loss": 0.3840462862281129, "Avg value loss": 0.11339179429342039, "Avg policy loss": 0.27065449045039713, "Total num played games": 64214, "Total num trained steps": 127744, "Timestamp in ms": 1701611878230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913414520198087, "Avg loss": 0.3262907142052427, "Avg value loss": 0.0687938183255028, "Avg policy loss": 0.25749689573422074, "Total num played games": 64214, "Total num trained steps": 127872, "Timestamp in ms": 1701611936866, "logtype": "training_step"}
{"Avg objective": 19.4375, "Games time in secs": 152.48943002708256, "Avg game time in secs": 1.656082936853636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 64256, "Total num trained steps": 127920, "Timestamp in ms": 1701611958257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903591976364485, "Avg loss": 0.4034208068624139, "Avg value loss": 0.13893614942207932, "Avg policy loss": 0.26448465895373374, "Total num played games": 64310, "Total num trained steps": 128000, "Timestamp in ms": 1701611992678, "logtype": "training_step"}
{"Avg objective": 20.5, "Games time in secs": 85.7123205754906, "Avg game time in secs": 1.8003612272295868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 64384, "Total num trained steps": 128113, "Timestamp in ms": 1701612043969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894416495869822, "Avg loss": 0.3699325865600258, "Avg value loss": 0.10603798521333374, "Avg policy loss": 0.26389460312202573, "Total num played games": 64404, "Total num trained steps": 128128, "Timestamp in ms": 1701612050621, "logtype": "training_step"}
{"Total num played games": 64404, "Total num trained steps": 128188, "Timestamp in ms": 1701612090602, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.16015625}
{"Ratio train steps to played games": 1.9885267760240628, "Avg loss": 0.48266913276165724, "Avg value loss": 0.20314178755506873, "Avg policy loss": 0.2795273456722498, "Total num played games": 64498, "Total num trained steps": 128256, "Timestamp in ms": 1701612122567, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905113336847655, "Avg loss": 0.3293999624438584, "Avg value loss": 0.0669408508692868, "Avg policy loss": 0.2624591112835333, "Total num played games": 64498, "Total num trained steps": 128384, "Timestamp in ms": 1701612180926, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 184.84655830450356, "Avg game time in secs": 1.6880036914662924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 64512, "Total num trained steps": 128488, "Timestamp in ms": 1701612228816, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895191503854848, "Avg loss": 0.3868229998042807, "Avg value loss": 0.13295888682478108, "Avg policy loss": 0.25386411347426474, "Total num played games": 64594, "Total num trained steps": 128512, "Timestamp in ms": 1701612239330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915162398984425, "Avg loss": 0.34162688825745136, "Avg value loss": 0.0848015199881047, "Avg policy loss": 0.25682536989916116, "Total num played games": 64594, "Total num trained steps": 128640, "Timestamp in ms": 1701612298387, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 88.54972023144364, "Avg game time in secs": 1.6068891580653144, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 64640, "Total num trained steps": 128681, "Timestamp in ms": 1701612317366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906010388325501, "Avg loss": 0.41974559507798404, "Avg value loss": 0.16175125478184782, "Avg policy loss": 0.25799433945212513, "Total num played games": 64688, "Total num trained steps": 128768, "Timestamp in ms": 1701612355117, "logtype": "training_step"}
{"Total num played games": 64688, "Total num trained steps": 128789, "Timestamp in ms": 1701612377107, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.015625}
{"Avg objective": 20.28125, "Games time in secs": 63.09889559075236, "Avg game time in secs": 1.8134899514261633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.73, "agent_stopped_0": 0.29}, "Total num played games": 64768, "Total num trained steps": 128795, "Timestamp in ms": 1701612380465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98967305733074, "Avg loss": 0.5057293992722407, "Avg value loss": 0.24113407704862766, "Avg policy loss": 0.26459532079752535, "Total num played games": 64782, "Total num trained steps": 128896, "Timestamp in ms": 1701612427301, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916643512086691, "Avg loss": 0.3035450769821182, "Avg value loss": 0.062291442416608334, "Avg policy loss": 0.24125363386701792, "Total num played games": 64782, "Total num trained steps": 129024, "Timestamp in ms": 1701612483192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990690218564074, "Avg loss": 0.43581944587640464, "Avg value loss": 0.17610275599872693, "Avg policy loss": 0.25971669517457485, "Total num played games": 64878, "Total num trained steps": 129152, "Timestamp in ms": 1701612542002, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 203.19108106940985, "Avg game time in secs": 1.735468611223041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 64896, "Total num trained steps": 129248, "Timestamp in ms": 1701612583656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897802130148372, "Avg loss": 0.4147118499968201, "Avg value loss": 0.16191631615220103, "Avg policy loss": 0.25279553153086454, "Total num played games": 64972, "Total num trained steps": 129280, "Timestamp in ms": 1701612597094, "logtype": "training_step"}
{"Total num played games": 64972, "Total num trained steps": 129389, "Timestamp in ms": 1701612660524, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.375}
{"Avg objective": 20.3671875, "Games time in secs": 79.63260315172374, "Avg game time in secs": 1.698456700949464, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 65024, "Total num trained steps": 129395, "Timestamp in ms": 1701612663289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888728368118527, "Avg loss": 0.3938978568185121, "Avg value loss": 0.1339213592291344, "Avg policy loss": 0.259976495988667, "Total num played games": 65066, "Total num trained steps": 129408, "Timestamp in ms": 1701612669038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908400700826854, "Avg loss": 0.3863190929405391, "Avg value loss": 0.12029488003463484, "Avg policy loss": 0.26602420897688717, "Total num played games": 65066, "Total num trained steps": 129536, "Timestamp in ms": 1701612727845, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 104.38256079144776, "Avg game time in secs": 1.8808729732991196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.76, "agent_stopped_0": 0.29}, "Total num played games": 65152, "Total num trained steps": 129627, "Timestamp in ms": 1701612767671, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899324739103745, "Avg loss": 0.3968295162776485, "Avg value loss": 0.14008792326785624, "Avg policy loss": 0.2567415931262076, "Total num played games": 65160, "Total num trained steps": 129664, "Timestamp in ms": 1701612783871, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918815224063844, "Avg loss": 0.33784537902101874, "Avg value loss": 0.08259849617024884, "Avg policy loss": 0.25524688430596143, "Total num played games": 65160, "Total num trained steps": 129792, "Timestamp in ms": 1701612843032, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909890581420295, "Avg loss": 0.4417183786863461, "Avg value loss": 0.1752398000098765, "Avg policy loss": 0.2664785753004253, "Total num played games": 65254, "Total num trained steps": 129920, "Timestamp in ms": 1701612903268, "logtype": "training_step"}
{"Total num played games": 65254, "Total num trained steps": 129990, "Timestamp in ms": 1701612944084, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.26171875}
{"Avg objective": 19.578125, "Games time in secs": 178.63266859948635, "Avg game time in secs": 1.6287528520188062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 65280, "Total num trained steps": 129994, "Timestamp in ms": 1701612946304, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900838587255922, "Avg loss": 0.41488266945816576, "Avg value loss": 0.15265785504016094, "Avg policy loss": 0.2622248132247478, "Total num played games": 65348, "Total num trained steps": 130048, "Timestamp in ms": 1701612970901, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920272999938788, "Avg loss": 0.3159170077415183, "Avg value loss": 0.06060987515957095, "Avg policy loss": 0.2553071352886036, "Total num played games": 65348, "Total num trained steps": 130176, "Timestamp in ms": 1701613026685, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 86.16546561941504, "Avg game time in secs": 1.665477597649442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.61, "agent_stopped_0": 0.41}, "Total num played games": 65408, "Total num trained steps": 130190, "Timestamp in ms": 1701613032470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991137190183674, "Avg loss": 0.46112028206698596, "Avg value loss": 0.19980707604554482, "Avg policy loss": 0.26131320383865386, "Total num played games": 65442, "Total num trained steps": 130304, "Timestamp in ms": 1701613083828, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 84.7593471519649, "Avg game time in secs": 1.8923816764290677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.81, "agent_stopped_0": 0.26}, "Total num played games": 65536, "Total num trained steps": 130379, "Timestamp in ms": 1701613117229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990234375, "Avg loss": 0.3812635854119435, "Avg value loss": 0.13121297891484573, "Avg policy loss": 0.2500506091164425, "Total num played games": 65536, "Total num trained steps": 130432, "Timestamp in ms": 1701613143344, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921875, "Avg loss": 0.3077092181192711, "Avg value loss": 0.06417023265385069, "Avg policy loss": 0.24353898724075407, "Total num played games": 65536, "Total num trained steps": 130560, "Timestamp in ms": 1701613203424, "logtype": "training_step"}
{"Total num played games": 65630, "Total num trained steps": 130592, "Timestamp in ms": 1701613230207, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.82421875}
{"Avg objective": 21.4453125, "Games time in secs": 115.7074777316302, "Avg game time in secs": 1.7314122674870305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.7}, "Total num played games": 65664, "Total num trained steps": 130596, "Timestamp in ms": 1701613232937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884364919968351, "Avg loss": 0.6387546079931781, "Avg value loss": 0.3484707268944476, "Avg policy loss": 0.2902838859008625, "Total num played games": 65724, "Total num trained steps": 130688, "Timestamp in ms": 1701613276448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903840301868418, "Avg loss": 0.31839779880829155, "Avg value loss": 0.06277346549904905, "Avg policy loss": 0.25562433479353786, "Total num played games": 65724, "Total num trained steps": 130816, "Timestamp in ms": 1701613335422, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 157.59118515625596, "Avg game time in secs": 1.7848130398633657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.75, "agent_stopped_0": 0.31}, "Total num played games": 65792, "Total num trained steps": 130942, "Timestamp in ms": 1701613390528, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896070744826329, "Avg loss": 0.30370683583896607, "Avg value loss": 0.0582279697409831, "Avg policy loss": 0.24547886615619063, "Total num played games": 65814, "Total num trained steps": 130944, "Timestamp in ms": 1701613391242, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914309155550154, "Avg loss": 0.4561158809810877, "Avg value loss": 0.1892890634771902, "Avg policy loss": 0.2668268147390336, "Total num played games": 65818, "Total num trained steps": 131072, "Timestamp in ms": 1701613447656, "logtype": "training_step"}
{"Total num played games": 65912, "Total num trained steps": 131195, "Timestamp in ms": 1701613514180, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.26171875}
{"Avg objective": 21.2109375, "Games time in secs": 125.5937973279506, "Avg game time in secs": 1.8522675843414618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.76, "agent_stopped_0": 0.29}, "Total num played games": 65920, "Total num trained steps": 131197, "Timestamp in ms": 1701613516122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890088232618781, "Avg loss": 0.41327757970429957, "Avg value loss": 0.14972273079911247, "Avg policy loss": 0.2635548508260399, "Total num played games": 65958, "Total num trained steps": 131200, "Timestamp in ms": 1701613517085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.4586028640624136, "Avg value loss": 0.17678698818781413, "Avg policy loss": 0.2818158727604896, "Total num played games": 66006, "Total num trained steps": 131328, "Timestamp in ms": 1701613573168, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915765233463625, "Avg loss": 0.3485287524526939, "Avg value loss": 0.08667549979873002, "Avg policy loss": 0.26185325463302433, "Total num played games": 66006, "Total num trained steps": 131456, "Timestamp in ms": 1701613633164, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 139.99765296839178, "Avg game time in secs": 1.662952087193844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.61, "agent_stopped_0": 0.41}, "Total num played games": 66048, "Total num trained steps": 131504, "Timestamp in ms": 1701613656120, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906807866868381, "Avg loss": 0.40693101356737316, "Avg value loss": 0.13776196572871413, "Avg policy loss": 0.2691690484061837, "Total num played games": 66100, "Total num trained steps": 131584, "Timestamp in ms": 1701613693958, "logtype": "training_step"}
{"Avg objective": 19.59375, "Games time in secs": 90.61426694691181, "Avg game time in secs": 1.747836775466567, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.68, "agent_stopped_0": 0.37}, "Total num played games": 66176, "Total num trained steps": 131695, "Timestamp in ms": 1701613746735, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989607250755287, "Avg loss": 0.3759841291466728, "Avg value loss": 0.10690660285763443, "Avg policy loss": 0.26907752419356257, "Total num played games": 66200, "Total num trained steps": 131712, "Timestamp in ms": 1701613754364, "logtype": "training_step"}
{"Total num played games": 66200, "Total num trained steps": 131799, "Timestamp in ms": 1701613806528, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3359375}
{"Ratio train steps to played games": 1.9887169276254262, "Avg loss": 0.46554680867120624, "Avg value loss": 0.18635967848240398, "Avg policy loss": 0.2791871337685734, "Total num played games": 66294, "Total num trained steps": 131840, "Timestamp in ms": 1701613826765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906326364376867, "Avg loss": 0.36108883540146053, "Avg value loss": 0.08408823673380539, "Avg policy loss": 0.27700059674680233, "Total num played games": 66294, "Total num trained steps": 131968, "Timestamp in ms": 1701613887190, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 191.8068580571562, "Avg game time in secs": 1.6718316537153441, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 66304, "Total num trained steps": 132080, "Timestamp in ms": 1701613938542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897571850334397, "Avg loss": 0.3695869544753805, "Avg value loss": 0.10322502860799432, "Avg policy loss": 0.26636192249134183, "Total num played games": 66388, "Total num trained steps": 132096, "Timestamp in ms": 1701613946178, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991685244321263, "Avg loss": 0.3554125626105815, "Avg value loss": 0.09457832193584181, "Avg policy loss": 0.2608342395396903, "Total num played games": 66388, "Total num trained steps": 132224, "Timestamp in ms": 1701614006519, "logtype": "training_step"}
{"Avg objective": 20.203125, "Games time in secs": 88.74211149476469, "Avg game time in secs": 1.6130030086496845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.51}, "Total num played games": 66432, "Total num trained steps": 132269, "Timestamp in ms": 1701614027284, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907945007671248, "Avg loss": 0.39980742731131613, "Avg value loss": 0.1393573388340883, "Avg policy loss": 0.2604500885354355, "Total num played games": 66482, "Total num trained steps": 132352, "Timestamp in ms": 1701614066636, "logtype": "training_step"}
{"Total num played games": 66482, "Total num trained steps": 132400, "Timestamp in ms": 1701614099900, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.24609375}
{"Avg objective": 20.5859375, "Games time in secs": 75.85796656273305, "Avg game time in secs": 1.686262467119377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.66}, "Total num played games": 66560, "Total num trained steps": 132407, "Timestamp in ms": 1701614103142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899062725306416, "Avg loss": 0.40665248478762805, "Avg value loss": 0.1549234909180086, "Avg policy loss": 0.25172899349126965, "Total num played games": 66576, "Total num trained steps": 132480, "Timestamp in ms": 1701614136069, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918138668589283, "Avg loss": 0.32384275807999074, "Avg value loss": 0.08515820716274902, "Avg policy loss": 0.23868455085903406, "Total num played games": 66576, "Total num trained steps": 132608, "Timestamp in ms": 1701614193428, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908807295416366, "Avg loss": 0.449483715579845, "Avg value loss": 0.1924612811417319, "Avg policy loss": 0.2570224325172603, "Total num played games": 66672, "Total num trained steps": 132736, "Timestamp in ms": 1701614252590, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 193.34741044603288, "Avg game time in secs": 1.6931097730703186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 66688, "Total num trained steps": 132835, "Timestamp in ms": 1701614296490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899949075876944, "Avg loss": 0.3911928201559931, "Avg value loss": 0.13714585060370155, "Avg policy loss": 0.25404696888290346, "Total num played games": 66766, "Total num trained steps": 132864, "Timestamp in ms": 1701614309700, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919120510439445, "Avg loss": 0.3441205999115482, "Avg value loss": 0.0867794357764069, "Avg policy loss": 0.25734116311650723, "Total num played games": 66766, "Total num trained steps": 132992, "Timestamp in ms": 1701614368654, "logtype": "training_step"}
{"Total num played games": 66766, "Total num trained steps": 133003, "Timestamp in ms": 1701614385400, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3828125}
{"Avg objective": 19.921875, "Games time in secs": 91.6964698433876, "Avg game time in secs": 1.7368968057271559, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.63, "agent_stopped_0": 0.39}, "Total num played games": 66816, "Total num trained steps": 133008, "Timestamp in ms": 1701614388186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991011067903081, "Avg loss": 0.41842629946768284, "Avg value loss": 0.16054049105150625, "Avg policy loss": 0.2578858083579689, "Total num played games": 66860, "Total num trained steps": 133120, "Timestamp in ms": 1701614439052, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 92.67233432456851, "Avg game time in secs": 1.7410956116655143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 66944, "Total num trained steps": 133214, "Timestamp in ms": 1701614480859, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901275502583864, "Avg loss": 0.4106919525656849, "Avg value loss": 0.15391137555707246, "Avg policy loss": 0.25678057817276567, "Total num played games": 66954, "Total num trained steps": 133248, "Timestamp in ms": 1701614496282, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920542461988828, "Avg loss": 0.3387593552470207, "Avg value loss": 0.07968550783698447, "Avg policy loss": 0.2590738459257409, "Total num played games": 66954, "Total num trained steps": 133376, "Timestamp in ms": 1701614553867, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911705047130415, "Avg loss": 0.4324081380618736, "Avg value loss": 0.1651740395464003, "Avg policy loss": 0.26723409991245717, "Total num played games": 67048, "Total num trained steps": 133504, "Timestamp in ms": 1701614613284, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 170.0933321416378, "Avg game time in secs": 1.7307932002004236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 67072, "Total num trained steps": 133588, "Timestamp in ms": 1701614650952, "logtype": "played_game"}
{"Total num played games": 67144, "Total num trained steps": 133607, "Timestamp in ms": 1701614670513, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.23828125}
{"Avg objective": 20.75, "Games time in secs": 22.489317808300257, "Avg game time in secs": 1.7480323981144466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 67200, "Total num trained steps": 133611, "Timestamp in ms": 1701614673442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874475742883488, "Avg loss": 0.4735611524665728, "Avg value loss": 0.21307035759673454, "Avg policy loss": 0.2604907900094986, "Total num played games": 67238, "Total num trained steps": 133632, "Timestamp in ms": 1701614682107, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989351259704334, "Avg loss": 0.39402626850642264, "Avg value loss": 0.12641079351305962, "Avg policy loss": 0.2676154742948711, "Total num played games": 67238, "Total num trained steps": 133760, "Timestamp in ms": 1701614739595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991254945120319, "Avg loss": 0.30619511706754565, "Avg value loss": 0.0548526429629419, "Avg policy loss": 0.251342473202385, "Total num played games": 67238, "Total num trained steps": 133888, "Timestamp in ms": 1701614796312, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 159.24294881150126, "Avg game time in secs": 1.717932962535997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 67328, "Total num trained steps": 133969, "Timestamp in ms": 1701614832685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903169275551726, "Avg loss": 0.3954879392404109, "Avg value loss": 0.1484573987836484, "Avg policy loss": 0.24703054351266474, "Total num played games": 67334, "Total num trained steps": 134016, "Timestamp in ms": 1701614853907, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922178988326849, "Avg loss": 0.31172513228375465, "Avg value loss": 0.06640805650386028, "Avg policy loss": 0.24531707470305264, "Total num played games": 67334, "Total num trained steps": 134144, "Timestamp in ms": 1701614912823, "logtype": "training_step"}
{"Total num played games": 67428, "Total num trained steps": 134210, "Timestamp in ms": 1701614952698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.21875}
{"Avg objective": 20.09375, "Games time in secs": 122.45870020054281, "Avg game time in secs": 1.749915398148005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.7}, "Total num played games": 67456, "Total num trained steps": 134214, "Timestamp in ms": 1701614955146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885666893753147, "Avg loss": 0.5830566821387038, "Avg value loss": 0.30429406960320193, "Avg policy loss": 0.27876261237543076, "Total num played games": 67522, "Total num trained steps": 134272, "Timestamp in ms": 1701614982127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904623678208584, "Avg loss": 0.335582725238055, "Avg value loss": 0.07272555644158274, "Avg policy loss": 0.26285717135760933, "Total num played games": 67522, "Total num trained steps": 134400, "Timestamp in ms": 1701615039516, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923580462664021, "Avg loss": 0.28563759266398847, "Avg value loss": 0.04600669053616002, "Avg policy loss": 0.23963090300094336, "Total num played games": 67522, "Total num trained steps": 134528, "Timestamp in ms": 1701615100661, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 149.59169288910925, "Avg game time in secs": 1.6327024506172165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.63, "agent_stopped_0": 0.39}, "Total num played games": 67584, "Total num trained steps": 134537, "Timestamp in ms": 1701615104738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991481306199716, "Avg loss": 0.44219694461207837, "Avg value loss": 0.17827362773823552, "Avg policy loss": 0.2639233177760616, "Total num played games": 67616, "Total num trained steps": 134656, "Timestamp in ms": 1701615157877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990607000443066, "Avg loss": 0.4461055180290714, "Avg value loss": 0.18314286120585166, "Avg policy loss": 0.2629626542329788, "Total num played games": 67710, "Total num trained steps": 134784, "Timestamp in ms": 1701615217025, "logtype": "training_step"}
{"Total num played games": 67710, "Total num trained steps": 134811, "Timestamp in ms": 1701615241217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.46875}
{"Avg objective": 20.9765625, "Games time in secs": 137.86842581257224, "Avg game time in secs": 1.9178738371265354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.8, "agent_stopped_0": 0.28}, "Total num played games": 67712, "Total num trained steps": 134812, "Timestamp in ms": 1701615242606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989735118872043, "Avg loss": 0.4978787237778306, "Avg value loss": 0.2145190214505419, "Avg policy loss": 0.28335970523767173, "Total num played games": 67804, "Total num trained steps": 134912, "Timestamp in ms": 1701615289996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916229131024719, "Avg loss": 0.3138774352846667, "Avg value loss": 0.05592207290465012, "Avg policy loss": 0.25795536232180893, "Total num played games": 67804, "Total num trained steps": 135040, "Timestamp in ms": 1701615348952, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 135.10529146157205, "Avg game time in secs": 1.632698747824179, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.61, "agent_stopped_0": 0.4}, "Total num played games": 67840, "Total num trained steps": 135100, "Timestamp in ms": 1701615377712, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907361041562344, "Avg loss": 0.4172010690672323, "Avg value loss": 0.15818223296082579, "Avg policy loss": 0.2590188354952261, "Total num played games": 67898, "Total num trained steps": 135168, "Timestamp in ms": 1701615408946, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 90.3059394787997, "Avg game time in secs": 1.790210646649939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.74, "agent_stopped_0": 0.32}, "Total num played games": 67968, "Total num trained steps": 135290, "Timestamp in ms": 1701615468018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898811624897046, "Avg loss": 0.3458041975973174, "Avg value loss": 0.09271450797677971, "Avg policy loss": 0.25308968988247216, "Total num played games": 67992, "Total num trained steps": 135296, "Timestamp in ms": 1701615471177, "logtype": "training_step"}
{"Total num played games": 67992, "Total num trained steps": 135413, "Timestamp in ms": 1701615533942, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.328125}
{"Ratio train steps to played games": 1.9889992068854097, "Avg loss": 0.4500665998784825, "Avg value loss": 0.18071589316241443, "Avg policy loss": 0.2693507056683302, "Total num played games": 68086, "Total num trained steps": 135424, "Timestamp in ms": 1701615539293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908938695179625, "Avg loss": 0.42944298777729273, "Avg value loss": 0.15349076958955266, "Avg policy loss": 0.27595221903175116, "Total num played games": 68086, "Total num trained steps": 135552, "Timestamp in ms": 1701615594552, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 176.5392281729728, "Avg game time in secs": 1.8503885496465955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 68096, "Total num trained steps": 135663, "Timestamp in ms": 1701615644557, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899680267519286, "Avg loss": 0.3545115931192413, "Avg value loss": 0.10414797690464184, "Avg policy loss": 0.25036361161619425, "Total num played games": 68182, "Total num trained steps": 135680, "Timestamp in ms": 1701615651897, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918453550790531, "Avg loss": 0.3912446405738592, "Avg value loss": 0.12944085901835933, "Avg policy loss": 0.2618037819629535, "Total num played games": 68182, "Total num trained steps": 135808, "Timestamp in ms": 1701615709288, "logtype": "training_step"}
{"Avg objective": 20.125, "Games time in secs": 87.34876410476863, "Avg game time in secs": 1.706814173492603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 68224, "Total num trained steps": 135857, "Timestamp in ms": 1701615731906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909777960044526, "Avg loss": 0.4354264182038605, "Avg value loss": 0.17113548540510237, "Avg policy loss": 0.2642909321002662, "Total num played games": 68276, "Total num trained steps": 135936, "Timestamp in ms": 1701615766494, "logtype": "training_step"}
{"Total num played games": 68276, "Total num trained steps": 136016, "Timestamp in ms": 1701615813427, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.578125}
{"Avg objective": 20.6171875, "Games time in secs": 84.87571433186531, "Avg game time in secs": 1.8557416385156102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.78}, "Total num played games": 68352, "Total num trained steps": 136023, "Timestamp in ms": 1701615816782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901126224952466, "Avg loss": 0.432014552061446, "Avg value loss": 0.1700452191871591, "Avg policy loss": 0.2619693294400349, "Total num played games": 68370, "Total num trained steps": 136064, "Timestamp in ms": 1701615837052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919847886499926, "Avg loss": 0.32924117415677756, "Avg value loss": 0.07168841912061907, "Avg policy loss": 0.257552754948847, "Total num played games": 68370, "Total num trained steps": 136192, "Timestamp in ms": 1701615896129, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991119420425333, "Avg loss": 0.4336669216863811, "Avg value loss": 0.1691501575987786, "Avg policy loss": 0.264516765717417, "Total num played games": 68464, "Total num trained steps": 136320, "Timestamp in ms": 1701615955766, "logtype": "training_step"}
{"Avg objective": 19.90625, "Games time in secs": 182.3398682642728, "Avg game time in secs": 1.826563338181586, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.76, "agent_stopped_0": 0.32}, "Total num played games": 68480, "Total num trained steps": 136421, "Timestamp in ms": 1701615999122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902564252166048, "Avg loss": 0.37983015622012317, "Avg value loss": 0.11993904848350212, "Avg policy loss": 0.2598911065142602, "Total num played games": 68558, "Total num trained steps": 136448, "Timestamp in ms": 1701616012451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921088713206336, "Avg loss": 0.3386197879444808, "Avg value loss": 0.07502840302186087, "Avg policy loss": 0.26359138905536383, "Total num played games": 68558, "Total num trained steps": 136576, "Timestamp in ms": 1701616069686, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 85.09135547280312, "Avg game time in secs": 1.7437624497397337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 68608, "Total num trained steps": 136609, "Timestamp in ms": 1701616084213, "logtype": "played_game"}
{"Total num played games": 68652, "Total num trained steps": 136617, "Timestamp in ms": 1701616097619, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0}
{"Avg objective": 20.3046875, "Games time in secs": 17.12553631514311, "Avg game time in secs": 1.7642356792930514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.65}, "Total num played games": 68736, "Total num trained steps": 136625, "Timestamp in ms": 1701616101339, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885375149099584, "Avg loss": 0.5459588079247624, "Avg value loss": 0.2679415449965745, "Avg policy loss": 0.2780172604834661, "Total num played games": 68746, "Total num trained steps": 136704, "Timestamp in ms": 1701616137429, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903848951211707, "Avg loss": 0.3292937382357195, "Avg value loss": 0.06283935869578272, "Avg policy loss": 0.2664543781429529, "Total num played games": 68746, "Total num trained steps": 136832, "Timestamp in ms": 1701616194481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922613679341343, "Avg loss": 0.2950830135960132, "Avg value loss": 0.04510368390765507, "Avg policy loss": 0.24997932859696448, "Total num played games": 68746, "Total num trained steps": 136960, "Timestamp in ms": 1701616252875, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914003486345149, "Avg loss": 0.43618946545757353, "Avg value loss": 0.16294289121287875, "Avg policy loss": 0.2732465717708692, "Total num played games": 68840, "Total num trained steps": 137088, "Timestamp in ms": 1701616312781, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 249.01508379913867, "Avg game time in secs": 1.7256076780031435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 68864, "Total num trained steps": 137170, "Timestamp in ms": 1701616350354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904839271208077, "Avg loss": 0.38930688449181616, "Avg value loss": 0.1242388755781576, "Avg policy loss": 0.26506800996139646, "Total num played games": 68936, "Total num trained steps": 137216, "Timestamp in ms": 1701616372418, "logtype": "training_step"}
{"Total num played games": 68936, "Total num trained steps": 137219, "Timestamp in ms": 1701616387373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.78515625}
{"Avg objective": 20.3359375, "Games time in secs": 39.71489736624062, "Avg game time in secs": 1.7877909131348133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 68992, "Total num trained steps": 137223, "Timestamp in ms": 1701616390071, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896276981022745, "Avg loss": 0.4977970679756254, "Avg value loss": 0.21190863268566318, "Avg policy loss": 0.28588843427132815, "Total num played games": 69030, "Total num trained steps": 137344, "Timestamp in ms": 1701616445686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914819643633204, "Avg loss": 0.3106676039751619, "Avg value loss": 0.056384599301964045, "Avg policy loss": 0.25428300455678254, "Total num played games": 69030, "Total num trained steps": 137472, "Timestamp in ms": 1701616506925, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 156.28274231776595, "Avg game time in secs": 1.7505853837210452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.66, "agent_stopped_0": 0.35}, "Total num played games": 69120, "Total num trained steps": 137554, "Timestamp in ms": 1701616546354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906255425033275, "Avg loss": 0.3926701380405575, "Avg value loss": 0.14042109560978133, "Avg policy loss": 0.25224904192145914, "Total num played games": 69124, "Total num trained steps": 137600, "Timestamp in ms": 1701616567969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924772871940282, "Avg loss": 0.30796462995931506, "Avg value loss": 0.05835611984366551, "Avg policy loss": 0.2496085069142282, "Total num played games": 69124, "Total num trained steps": 137728, "Timestamp in ms": 1701616626963, "logtype": "training_step"}
{"Total num played games": 69220, "Total num trained steps": 137822, "Timestamp in ms": 1701616679864, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.81640625}
{"Avg objective": 21.1171875, "Games time in secs": 135.95405142381787, "Avg game time in secs": 1.6320968611398712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 69248, "Total num trained steps": 137826, "Timestamp in ms": 1701616682308, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888478518048303, "Avg loss": 0.563020727597177, "Avg value loss": 0.30153238205821253, "Avg policy loss": 0.26148834615014493, "Total num played games": 69314, "Total num trained steps": 137856, "Timestamp in ms": 1701616696231, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907089476873359, "Avg loss": 0.3580431864829734, "Avg value loss": 0.09585552482167259, "Avg policy loss": 0.26218766311649233, "Total num played games": 69314, "Total num trained steps": 137984, "Timestamp in ms": 1701616753537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925411893701128, "Avg loss": 0.29835278063546866, "Avg value loss": 0.05234571441542357, "Avg policy loss": 0.24600706691853702, "Total num played games": 69314, "Total num trained steps": 138112, "Timestamp in ms": 1701616813095, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 134.6984522640705, "Avg game time in secs": 1.6982970844983356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 69376, "Total num trained steps": 138122, "Timestamp in ms": 1701616817006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991701244813278, "Avg loss": 0.4352506035938859, "Avg value loss": 0.1730125031026546, "Avg policy loss": 0.2622380998218432, "Total num played games": 69408, "Total num trained steps": 138240, "Timestamp in ms": 1701616868656, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 84.76830479316413, "Avg game time in secs": 1.9353686360700522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.82, "agent_stopped_0": 0.26}, "Total num played games": 69504, "Total num trained steps": 138314, "Timestamp in ms": 1701616901775, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990777509208103, "Avg loss": 0.4352043673861772, "Avg value loss": 0.1734478385769762, "Avg policy loss": 0.26175653585232794, "Total num played games": 69504, "Total num trained steps": 138368, "Timestamp in ms": 1701616925776, "logtype": "training_step"}
{"Total num played games": 69504, "Total num trained steps": 138424, "Timestamp in ms": 1701616962625, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.64453125}
{"Ratio train steps to played games": 1.989942239719532, "Avg loss": 0.46775632188655436, "Avg value loss": 0.19547993890591897, "Avg policy loss": 0.2722763838246465, "Total num played games": 69598, "Total num trained steps": 138496, "Timestamp in ms": 1701616994916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917813730279605, "Avg loss": 0.31871407153084874, "Avg value loss": 0.05973585872561671, "Avg policy loss": 0.2589782134164125, "Total num played games": 69598, "Total num trained steps": 138624, "Timestamp in ms": 1701617052287, "logtype": "training_step"}
{"Avg objective": 20.203125, "Games time in secs": 181.039083795622, "Avg game time in secs": 1.594740688946331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 69632, "Total num trained steps": 138689, "Timestamp in ms": 1701617082814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909315272915111, "Avg loss": 0.43683725222945213, "Avg value loss": 0.17523217794951051, "Avg policy loss": 0.26160507183521986, "Total num played games": 69692, "Total num trained steps": 138752, "Timestamp in ms": 1701617111023, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 85.0185292121023, "Avg game time in secs": 1.8014325583353639, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.7, "agent_stopped_0": 0.31}, "Total num played games": 69760, "Total num trained steps": 138877, "Timestamp in ms": 1701617167833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900269387287213, "Avg loss": 0.3345266927499324, "Avg value loss": 0.07015522528672591, "Avg policy loss": 0.2643714686855674, "Total num played games": 69788, "Total num trained steps": 138880, "Timestamp in ms": 1701617169104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918467358285092, "Avg loss": 0.4676862845662981, "Avg value loss": 0.19964452585554682, "Avg policy loss": 0.2680417565861717, "Total num played games": 69788, "Total num trained steps": 139008, "Timestamp in ms": 1701617227377, "logtype": "training_step"}
{"Total num played games": 69788, "Total num trained steps": 139027, "Timestamp in ms": 1701617251094, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.68359375}
{"Ratio train steps to played games": 1.9910134226267135, "Avg loss": 0.48124218732118607, "Avg value loss": 0.2094186017056927, "Avg policy loss": 0.271823585848324, "Total num played games": 69882, "Total num trained steps": 139136, "Timestamp in ms": 1701617304517, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 190.73625851608813, "Avg game time in secs": 1.899697264219867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.83, "agent_stopped_0": 0.25}, "Total num played games": 69888, "Total num trained steps": 139255, "Timestamp in ms": 1701617358569, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901680576197553, "Avg loss": 0.31960941082797945, "Avg value loss": 0.07240215680212714, "Avg policy loss": 0.24720725452061743, "Total num played games": 69976, "Total num trained steps": 139264, "Timestamp in ms": 1701617362253, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919972562021264, "Avg loss": 0.4192105894908309, "Avg value loss": 0.15281023550778627, "Avg policy loss": 0.2664003550307825, "Total num played games": 69976, "Total num trained steps": 139392, "Timestamp in ms": 1701617421513, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 85.46761728823185, "Avg game time in secs": 1.822961173413205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.77}, "Total num played games": 70016, "Total num trained steps": 139445, "Timestamp in ms": 1701617444037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910948738440462, "Avg loss": 0.4425870650447905, "Avg value loss": 0.18390515065402724, "Avg policy loss": 0.25868191954214126, "Total num played games": 70072, "Total num trained steps": 139520, "Timestamp in ms": 1701617478192, "logtype": "training_step"}
{"Total num played games": 70072, "Total num trained steps": 139627, "Timestamp in ms": 1701617539722, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0859375}
{"Avg objective": 20.953125, "Games time in secs": 98.94280033558607, "Avg game time in secs": 1.8752033408818534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.26, "agent_stopped_more": 0.74, "played_steps": 0.78}, "Total num played games": 70144, "Total num trained steps": 139633, "Timestamp in ms": 1701617542980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902516888521506, "Avg loss": 0.4302804688923061, "Avg value loss": 0.17328218891634606, "Avg policy loss": 0.2569982777349651, "Total num played games": 70166, "Total num trained steps": 139648, "Timestamp in ms": 1701617549716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920759342131518, "Avg loss": 0.40161143068689853, "Avg value loss": 0.13482778272009455, "Avg policy loss": 0.2667836445616558, "Total num played games": 70166, "Total num trained steps": 139776, "Timestamp in ms": 1701617605972, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912325647594649, "Avg loss": 0.4680956844240427, "Avg value loss": 0.19971605777391233, "Avg policy loss": 0.26837963063735515, "Total num played games": 70260, "Total num trained steps": 139904, "Timestamp in ms": 1701617663775, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 168.42347980849445, "Avg game time in secs": 1.8610900449275505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 70272, "Total num trained steps": 140012, "Timestamp in ms": 1701617711404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990391448958126, "Avg loss": 0.3849307110067457, "Avg value loss": 0.126935954001965, "Avg policy loss": 0.25799475552048534, "Total num played games": 70354, "Total num trained steps": 140032, "Timestamp in ms": 1701617720501, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992210819569605, "Avg loss": 0.349266211502254, "Avg value loss": 0.09415651601739228, "Avg policy loss": 0.25510969245806336, "Total num played games": 70354, "Total num trained steps": 140160, "Timestamp in ms": 1701617777341, "logtype": "training_step"}
{"Avg objective": 19.828125, "Games time in secs": 84.0258061569184, "Avg game time in secs": 1.7891983433801215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.68}, "Total num played games": 70400, "Total num trained steps": 140201, "Timestamp in ms": 1701617795430, "logtype": "played_game"}
{"Total num played games": 70448, "Total num trained steps": 140228, "Timestamp in ms": 1701617820199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.4375}
{"Avg objective": 20.4140625, "Games time in secs": 28.128085024654865, "Avg game time in secs": 1.9447637441917323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.79, "agent_stopped_0": 0.24}, "Total num played games": 70528, "Total num trained steps": 140232, "Timestamp in ms": 1701617823558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887017663236086, "Avg loss": 0.5927462248364463, "Avg value loss": 0.31621959086623974, "Avg policy loss": 0.2765266296919435, "Total num played games": 70542, "Total num trained steps": 140288, "Timestamp in ms": 1701617848848, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905162881687506, "Avg loss": 0.32530211796984076, "Avg value loss": 0.062216487945988774, "Avg policy loss": 0.26308562979102135, "Total num played games": 70542, "Total num trained steps": 140416, "Timestamp in ms": 1701617905761, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923308100138923, "Avg loss": 0.28780793119221926, "Avg value loss": 0.04416667198529467, "Avg policy loss": 0.24364125810097903, "Total num played games": 70542, "Total num trained steps": 140544, "Timestamp in ms": 1701617962791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914915906902995, "Avg loss": 0.43875008495524526, "Avg value loss": 0.1804350063612219, "Avg policy loss": 0.2583150784485042, "Total num played games": 70636, "Total num trained steps": 140672, "Timestamp in ms": 1701618021385, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 240.47965245321393, "Avg game time in secs": 1.7646996433177264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.68, "agent_stopped_0": 0.37}, "Total num played games": 70656, "Total num trained steps": 140764, "Timestamp in ms": 1701618064038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906546020076348, "Avg loss": 0.38248746399767697, "Avg value loss": 0.12849888415075839, "Avg policy loss": 0.2539885777514428, "Total num played games": 70730, "Total num trained steps": 140800, "Timestamp in ms": 1701618081168, "logtype": "training_step"}
{"Total num played games": 70730, "Total num trained steps": 140829, "Timestamp in ms": 1701618105180, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.52734375}
{"Avg objective": 19.6953125, "Games time in secs": 43.862438237294555, "Avg game time in secs": 1.7042137919052038, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.67}, "Total num played games": 70784, "Total num trained steps": 140833, "Timestamp in ms": 1701618107900, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989833954591664, "Avg loss": 0.463749956805259, "Avg value loss": 0.20127746317302808, "Avg policy loss": 0.26247249729931355, "Total num played games": 70824, "Total num trained steps": 140928, "Timestamp in ms": 1701618153376, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916271320456342, "Avg loss": 0.3042287095449865, "Avg value loss": 0.05718181293923408, "Avg policy loss": 0.24704689509235322, "Total num played games": 70824, "Total num trained steps": 141056, "Timestamp in ms": 1701618215058, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 145.76281574368477, "Avg game time in secs": 1.878355340071721, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.7}, "Total num played games": 70912, "Total num trained steps": 141143, "Timestamp in ms": 1701618253663, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908062833131221, "Avg loss": 0.39359263808000833, "Avg value loss": 0.15580105372646358, "Avg policy loss": 0.23779158340767026, "Total num played games": 70918, "Total num trained steps": 141184, "Timestamp in ms": 1701618272979, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925970839561182, "Avg loss": 0.308971707127057, "Avg value loss": 0.07028191557037644, "Avg policy loss": 0.238689789082855, "Total num played games": 70918, "Total num trained steps": 141312, "Timestamp in ms": 1701618331631, "logtype": "training_step"}
{"Total num played games": 71012, "Total num trained steps": 141433, "Timestamp in ms": 1701618399010, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8046875}
{"Avg objective": 19.6953125, "Games time in secs": 147.6411124598235, "Avg game time in secs": 1.6251537899079267, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 71040, "Total num trained steps": 141437, "Timestamp in ms": 1701618401304, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98929676511955, "Avg loss": 0.406525366473943, "Avg value loss": 0.15877848039963283, "Avg policy loss": 0.247746889363043, "Total num played games": 71100, "Total num trained steps": 141440, "Timestamp in ms": 1701618402739, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909430990352432, "Avg loss": 0.45471499068662524, "Avg value loss": 0.19763155272812583, "Avg policy loss": 0.25708343647420406, "Total num played games": 71106, "Total num trained steps": 141568, "Timestamp in ms": 1701618460137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927432284195425, "Avg loss": 0.28800758672878146, "Avg value loss": 0.052197134180460125, "Avg policy loss": 0.23581045353785157, "Total num played games": 71106, "Total num trained steps": 141696, "Timestamp in ms": 1701618522552, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 125.24155355803668, "Avg game time in secs": 1.6699484295240836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 71168, "Total num trained steps": 141705, "Timestamp in ms": 1701618526546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919101123595506, "Avg loss": 0.41099089581985027, "Avg value loss": 0.16665859514614567, "Avg policy loss": 0.2443323004990816, "Total num played games": 71200, "Total num trained steps": 141824, "Timestamp in ms": 1701618581182, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910791931999887, "Avg loss": 0.41801158885937184, "Avg value loss": 0.1740756799990777, "Avg policy loss": 0.24393591040279716, "Total num played games": 71294, "Total num trained steps": 141952, "Timestamp in ms": 1701618640480, "logtype": "training_step"}
{"Total num played games": 71294, "Total num trained steps": 142037, "Timestamp in ms": 1701618701531, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.47265625}
{"Avg objective": 20.046875, "Games time in secs": 176.45233690924942, "Avg game time in secs": 1.8980370554490946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 71296, "Total num trained steps": 142038, "Timestamp in ms": 1701618702999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902504622625652, "Avg loss": 0.3875852390192449, "Avg value loss": 0.14732013450702652, "Avg policy loss": 0.24026510526891798, "Total num played games": 71388, "Total num trained steps": 142080, "Timestamp in ms": 1701618721631, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992043480697036, "Avg loss": 0.30119882279541343, "Avg value loss": 0.05874474695883691, "Avg policy loss": 0.2424540751380846, "Total num played games": 71388, "Total num trained steps": 142208, "Timestamp in ms": 1701618779378, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 104.70112163946033, "Avg game time in secs": 1.5909806310810382, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.59}, "Total num played games": 71424, "Total num trained steps": 142268, "Timestamp in ms": 1701618807700, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912005819646905, "Avg loss": 0.40513473306782544, "Avg value loss": 0.16816618910524994, "Avg policy loss": 0.23696854047011584, "Total num played games": 71482, "Total num trained steps": 142336, "Timestamp in ms": 1701618838511, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 86.41391284950078, "Avg game time in secs": 1.865427075768821, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.28, "agent_stopped_more": 0.72, "played_steps": 0.73}, "Total num played games": 71552, "Total num trained steps": 142458, "Timestamp in ms": 1701618894114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902626431964237, "Avg loss": 0.3095323636662215, "Avg value loss": 0.07705226526013575, "Avg policy loss": 0.23248009872622788, "Total num played games": 71580, "Total num trained steps": 142464, "Timestamp in ms": 1701618896426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920648225761386, "Avg loss": 0.46447451366111636, "Avg value loss": 0.21151268458925188, "Avg policy loss": 0.25296182557940483, "Total num played games": 71580, "Total num trained steps": 142592, "Timestamp in ms": 1701618955385, "logtype": "training_step"}
{"Total num played games": 71580, "Total num trained steps": 142637, "Timestamp in ms": 1701618987968, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.07421875}
{"Ratio train steps to played games": 1.9912381058682367, "Avg loss": 0.4290525094838813, "Avg value loss": 0.1745843334356323, "Avg policy loss": 0.2544681775616482, "Total num played games": 71674, "Total num trained steps": 142720, "Timestamp in ms": 1701619025891, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 187.00782633945346, "Avg game time in secs": 1.9106128259882098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.8, "agent_stopped_0": 0.24}, "Total num played games": 71680, "Total num trained steps": 142839, "Timestamp in ms": 1701619081122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903580883377456, "Avg loss": 0.314841594081372, "Avg value loss": 0.08029821066884324, "Avg policy loss": 0.23454338777810335, "Total num played games": 71770, "Total num trained steps": 142848, "Timestamp in ms": 1701619085036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921415633272954, "Avg loss": 0.37998023570980877, "Avg value loss": 0.1481753976258915, "Avg policy loss": 0.23180483852047473, "Total num played games": 71770, "Total num trained steps": 142976, "Timestamp in ms": 1701619142040, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 85.10501077212393, "Avg game time in secs": 1.6576243718445767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.57, "agent_stopped_0": 0.46}, "Total num played games": 71808, "Total num trained steps": 143031, "Timestamp in ms": 1701619166227, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913169319826338, "Avg loss": 0.39144279540050775, "Avg value loss": 0.15148374275304377, "Avg policy loss": 0.2399590532295406, "Total num played games": 71864, "Total num trained steps": 143104, "Timestamp in ms": 1701619198535, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 84.39047876931727, "Avg game time in secs": 1.7796786828548647, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.62, "agent_stopped_0": 0.38}, "Total num played games": 71936, "Total num trained steps": 143222, "Timestamp in ms": 1701619250618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904944550988077, "Avg loss": 0.30790233379229903, "Avg value loss": 0.08753218210767955, "Avg policy loss": 0.2203701518010348, "Total num played games": 71958, "Total num trained steps": 143232, "Timestamp in ms": 1701619255495, "logtype": "training_step"}
{"Total num played games": 71958, "Total num trained steps": 143238, "Timestamp in ms": 1701619270250, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9296875}
{"Ratio train steps to played games": 1.9896741242436018, "Avg loss": 0.47308225161395967, "Avg value loss": 0.24072741947020404, "Avg policy loss": 0.2323548316489905, "Total num played games": 72052, "Total num trained steps": 143360, "Timestamp in ms": 1701619330096, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914506189973908, "Avg loss": 0.25332676782272756, "Avg value loss": 0.050123516790336, "Avg policy loss": 0.20320324960630387, "Total num played games": 72052, "Total num trained steps": 143488, "Timestamp in ms": 1701619389836, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 186.63328802771866, "Avg game time in secs": 1.7834221447992604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 72064, "Total num trained steps": 143596, "Timestamp in ms": 1701619437251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905610689138993, "Avg loss": 0.3111456136684865, "Avg value loss": 0.11234148505900521, "Avg policy loss": 0.19880412647034973, "Total num played games": 72148, "Total num trained steps": 143616, "Timestamp in ms": 1701619446582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992349060265011, "Avg loss": 0.3143726629205048, "Avg value loss": 0.10195363793172874, "Avg policy loss": 0.21241902629844844, "Total num played games": 72148, "Total num trained steps": 143744, "Timestamp in ms": 1701619503682, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 85.78194246254861, "Avg game time in secs": 1.7107016988593386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.61, "agent_stopped_0": 0.4}, "Total num played games": 72192, "Total num trained steps": 143785, "Timestamp in ms": 1701619523034, "logtype": "played_game"}
{"Total num played games": 72242, "Total num trained steps": 143841, "Timestamp in ms": 1701619560126, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0703125}
{"Avg objective": 20.234375, "Games time in secs": 40.42391795665026, "Avg game time in secs": 1.7377910789655289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.74, "agent_stopped_0": 0.3}, "Total num played games": 72320, "Total num trained steps": 143848, "Timestamp in ms": 1701619563458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988940499889405, "Avg loss": 0.4286375135416165, "Avg value loss": 0.2057741268799873, "Avg policy loss": 0.22286338871344924, "Total num played games": 72336, "Total num trained steps": 143872, "Timestamp in ms": 1701619573711, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907100199071002, "Avg loss": 0.3165090975817293, "Avg value loss": 0.08558655221713707, "Avg policy loss": 0.23092254612129182, "Total num played games": 72336, "Total num trained steps": 144000, "Timestamp in ms": 1701619633809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924795399247954, "Avg loss": 0.2527522733435035, "Avg value loss": 0.048518496681936085, "Avg policy loss": 0.20423377444967628, "Total num played games": 72336, "Total num trained steps": 144128, "Timestamp in ms": 1701619690580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916471075521194, "Avg loss": 0.34849604207556695, "Avg value loss": 0.13192015537060797, "Avg policy loss": 0.21657588775269687, "Total num played games": 72430, "Total num trained steps": 144256, "Timestamp in ms": 1701619747529, "logtype": "training_step"}
{"Avg objective": 20.6875, "Games time in secs": 225.40397942252457, "Avg game time in secs": 1.7656321423855843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 72448, "Total num trained steps": 144352, "Timestamp in ms": 1701619788862, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990844410126303, "Avg loss": 0.35489303641952574, "Avg value loss": 0.13925673507037573, "Avg policy loss": 0.21563629992306232, "Total num played games": 72524, "Total num trained steps": 144384, "Timestamp in ms": 1701619802714, "logtype": "training_step"}
{"Total num played games": 72524, "Total num trained steps": 144444, "Timestamp in ms": 1701619841417, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.53515625}
{"Avg objective": 21.046875, "Games time in secs": 55.395173255354166, "Avg game time in secs": 1.660933783146902, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0546875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.64, "agent_stopped_0": 0.38}, "Total num played games": 72576, "Total num trained steps": 144447, "Timestamp in ms": 1701619844257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900162494147458, "Avg loss": 0.4274838491110131, "Avg value loss": 0.2056974766892381, "Avg policy loss": 0.22178636968601495, "Total num played games": 72618, "Total num trained steps": 144512, "Timestamp in ms": 1701619874961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917926684843978, "Avg loss": 0.27831372467335314, "Avg value loss": 0.06372697339975275, "Avg policy loss": 0.21458675048779696, "Total num played games": 72618, "Total num trained steps": 144640, "Timestamp in ms": 1701619934945, "logtype": "training_step"}
{"Avg objective": 20.5, "Games time in secs": 131.99616402760148, "Avg game time in secs": 1.9146525711403228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 72704, "Total num trained steps": 144731, "Timestamp in ms": 1701619976254, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909781054021345, "Avg loss": 0.3416481572203338, "Avg value loss": 0.13174922058533411, "Avg policy loss": 0.20989893714431673, "Total num played games": 72712, "Total num trained steps": 144768, "Timestamp in ms": 1701619993419, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927384750797668, "Avg loss": 0.27643716789316386, "Avg value loss": 0.06370145702385344, "Avg policy loss": 0.21273570996709168, "Total num played games": 72712, "Total num trained steps": 144896, "Timestamp in ms": 1701620052314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991923742548691, "Avg loss": 0.405795389553532, "Avg value loss": 0.1875081906473497, "Avg policy loss": 0.21828719589393586, "Total num played games": 72806, "Total num trained steps": 145024, "Timestamp in ms": 1701620113467, "logtype": "training_step"}
{"Total num played games": 72806, "Total num trained steps": 145046, "Timestamp in ms": 1701620137943, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.65625}
{"Avg objective": 20.640625, "Games time in secs": 164.0478324405849, "Avg game time in secs": 1.7832443616789533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 72832, "Total num trained steps": 145049, "Timestamp in ms": 1701620140302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991111111111111, "Avg loss": 0.38839737558737397, "Avg value loss": 0.16609154021716677, "Avg policy loss": 0.22230583697091788, "Total num played games": 72900, "Total num trained steps": 145152, "Timestamp in ms": 1701620185568, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928532235939644, "Avg loss": 0.2640406667487696, "Avg value loss": 0.052064908464672044, "Avg policy loss": 0.21197576052509248, "Total num played games": 72900, "Total num trained steps": 145280, "Timestamp in ms": 1701620247042, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 113.04309093765914, "Avg game time in secs": 1.6268997934821527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 72960, "Total num trained steps": 145293, "Timestamp in ms": 1701620253345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920541414362825, "Avg loss": 0.35050009086262435, "Avg value loss": 0.13332988537149504, "Avg policy loss": 0.21717020764481276, "Total num played games": 72994, "Total num trained steps": 145408, "Timestamp in ms": 1701620304957, "logtype": "training_step"}
{"Avg objective": 20.046875, "Games time in secs": 84.69580892659724, "Avg game time in secs": 1.843442519690143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 73088, "Total num trained steps": 145483, "Timestamp in ms": 1701620338041, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911889451361335, "Avg loss": 0.33536980336066335, "Avg value loss": 0.12608114824979566, "Avg policy loss": 0.20928865345194936, "Total num played games": 73090, "Total num trained steps": 145536, "Timestamp in ms": 1701620360534, "logtype": "training_step"}
{"Total num played games": 73090, "Total num trained steps": 145647, "Timestamp in ms": 1701620425137, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.96484375}
{"Ratio train steps to played games": 1.990380411018802, "Avg loss": 0.3031211436027661, "Avg value loss": 0.09101641381857917, "Avg policy loss": 0.2121047287946567, "Total num played games": 73184, "Total num trained steps": 145664, "Timestamp in ms": 1701620433113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921294271972017, "Avg loss": 0.3142999487463385, "Avg value loss": 0.09970591810997576, "Avg policy loss": 0.21459402865730226, "Total num played games": 73184, "Total num trained steps": 145792, "Timestamp in ms": 1701620490496, "logtype": "training_step"}
{"Avg objective": 20.1484375, "Games time in secs": 184.33732155896723, "Avg game time in secs": 1.5880669930047588, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.52, "agent_stopped_0": 0.5}, "Total num played games": 73216, "Total num trained steps": 145861, "Timestamp in ms": 1701620522378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913070771582193, "Avg loss": 0.3578751707682386, "Avg value loss": 0.1421887440228602, "Avg policy loss": 0.21568642789497972, "Total num played games": 73278, "Total num trained steps": 145920, "Timestamp in ms": 1701620549077, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926867870981826, "Avg loss": 0.27482586551923305, "Avg value loss": 0.05968058269354515, "Avg policy loss": 0.21514528337866068, "Total num played games": 73290, "Total num trained steps": 146048, "Timestamp in ms": 1701620605405, "logtype": "training_step"}
{"Avg objective": 20.2421875, "Games time in secs": 83.82920243777335, "Avg game time in secs": 1.7990050948574208, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.7, "agent_stopped_0": 0.33}, "Total num played games": 73344, "Total num trained steps": 146050, "Timestamp in ms": 1701620606208, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992258627269258, "Avg loss": 0.3727341676130891, "Avg value loss": 0.15253781474893913, "Avg policy loss": 0.2201963512925431, "Total num played games": 73372, "Total num trained steps": 146176, "Timestamp in ms": 1701620664351, "logtype": "training_step"}
{"Total num played games": 73468, "Total num trained steps": 146248, "Timestamp in ms": 1701620708951, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.26953125}
{"Avg objective": 20.7109375, "Games time in secs": 104.4135422501713, "Avg game time in secs": 1.8874202291190159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 73472, "Total num trained steps": 146250, "Timestamp in ms": 1701620710622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988852940376825, "Avg loss": 0.46184477722272277, "Avg value loss": 0.23499646424897946, "Avg policy loss": 0.22684830764774233, "Total num played games": 73562, "Total num trained steps": 146304, "Timestamp in ms": 1701620734940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990579375220902, "Avg loss": 0.29034147318452597, "Avg value loss": 0.06853197707096115, "Avg policy loss": 0.22180949652101845, "Total num played games": 73562, "Total num trained steps": 146432, "Timestamp in ms": 1701620791299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923329980152795, "Avg loss": 0.2453788659768179, "Avg value loss": 0.046995555341709405, "Avg policy loss": 0.1983833103440702, "Total num played games": 73562, "Total num trained steps": 146560, "Timestamp in ms": 1701620847286, "logtype": "training_step"}
{"Avg objective": 19.234375, "Games time in secs": 163.3036584071815, "Avg game time in secs": 1.586429394170409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.59}, "Total num played games": 73600, "Total num trained steps": 146616, "Timestamp in ms": 1701620873925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915281850765723, "Avg loss": 0.3379655674798414, "Avg value loss": 0.13724447126151063, "Avg policy loss": 0.20072109409375116, "Total num played games": 73656, "Total num trained steps": 146688, "Timestamp in ms": 1701620907400, "logtype": "training_step"}
{"Avg objective": 20.0234375, "Games time in secs": 90.99880907684565, "Avg game time in secs": 1.8364962790510617, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.71}, "Total num played games": 73728, "Total num trained steps": 146804, "Timestamp in ms": 1701620964924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907254237288137, "Avg loss": 0.2930396426236257, "Avg value loss": 0.0948188155743992, "Avg policy loss": 0.19822082936298102, "Total num played games": 73750, "Total num trained steps": 146816, "Timestamp in ms": 1701620970178, "logtype": "training_step"}
{"Total num played games": 73750, "Total num trained steps": 146848, "Timestamp in ms": 1701620995551, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3515625}
{"Ratio train steps to played games": 1.9899247061372622, "Avg loss": 0.44473835290409625, "Avg value loss": 0.22337626063381322, "Avg policy loss": 0.22136209532618523, "Total num played games": 73844, "Total num trained steps": 146944, "Timestamp in ms": 1701621040121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916580900276257, "Avg loss": 0.2483674973482266, "Avg value loss": 0.05025118953199126, "Avg policy loss": 0.198116309766192, "Total num played games": 73844, "Total num trained steps": 147072, "Timestamp in ms": 1701621096808, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 179.50774942338467, "Avg game time in secs": 1.7181876805407228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 73856, "Total num trained steps": 147179, "Timestamp in ms": 1701621144432, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908033540708683, "Avg loss": 0.30521490541286767, "Avg value loss": 0.11168750212527812, "Avg policy loss": 0.19352740223985165, "Total num played games": 73940, "Total num trained steps": 147200, "Timestamp in ms": 1701621154006, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925209629429268, "Avg loss": 0.3551060090539977, "Avg value loss": 0.1450834906718228, "Avg policy loss": 0.21002251689787954, "Total num played games": 73940, "Total num trained steps": 147328, "Timestamp in ms": 1701621211293, "logtype": "training_step"}
{"Avg objective": 19.75, "Games time in secs": 87.64001790620387, "Avg game time in secs": 1.6855854675523005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 73984, "Total num trained steps": 147374, "Timestamp in ms": 1701621232072, "logtype": "played_game"}
{"Total num played games": 74034, "Total num trained steps": 147451, "Timestamp in ms": 1701621278280, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3671875}
{"Ratio train steps to played games": 1.9903892878354301, "Avg loss": 0.41344679531175643, "Avg value loss": 0.2024819345679134, "Avg policy loss": 0.21096486144233495, "Total num played games": 74082, "Total num trained steps": 147456, "Timestamp in ms": 1701621280918, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 49.527135886251926, "Avg game time in secs": 1.8166659597191028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.66, "agent_stopped_0": 0.36}, "Total num played games": 74112, "Total num trained steps": 147457, "Timestamp in ms": 1701621281600, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990934599611483, "Avg loss": 0.40723790507763624, "Avg value loss": 0.17705872689839453, "Avg policy loss": 0.23017918050754815, "Total num played games": 74128, "Total num trained steps": 147584, "Timestamp in ms": 1701621339125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992661342542629, "Avg loss": 0.25425355311017483, "Avg value loss": 0.05214991503453348, "Avg policy loss": 0.20210363599471748, "Total num played games": 74128, "Total num trained steps": 147712, "Timestamp in ms": 1701621396359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991862251084584, "Avg loss": 0.4077116100816056, "Avg value loss": 0.18285589598235674, "Avg policy loss": 0.22485571331344545, "Total num played games": 74222, "Total num trained steps": 147840, "Timestamp in ms": 1701621454334, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 216.12116489000618, "Avg game time in secs": 1.721182726949337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 74240, "Total num trained steps": 147935, "Timestamp in ms": 1701621497721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910115988051347, "Avg loss": 0.36918198876082897, "Avg value loss": 0.15818633246817626, "Avg policy loss": 0.21099565597251058, "Total num played games": 74318, "Total num trained steps": 147968, "Timestamp in ms": 1701621513092, "logtype": "training_step"}
{"Total num played games": 74318, "Total num trained steps": 148054, "Timestamp in ms": 1701621562588, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.7109375}
{"Avg objective": 21.03125, "Games time in secs": 67.43818500451744, "Avg game time in secs": 1.6607367656251881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.65, "agent_stopped_0": 0.37}, "Total num played games": 74368, "Total num trained steps": 148059, "Timestamp in ms": 1701621565159, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902166317260657, "Avg loss": 0.37960239103995264, "Avg value loss": 0.1589483750576619, "Avg policy loss": 0.22065401496365666, "Total num played games": 74412, "Total num trained steps": 148096, "Timestamp in ms": 1701621582814, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919367843896145, "Avg loss": 0.27537904458586127, "Avg value loss": 0.06503053227788769, "Avg policy loss": 0.21034851390868425, "Total num played games": 74412, "Total num trained steps": 148224, "Timestamp in ms": 1701621641835, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 119.63805780559778, "Avg game time in secs": 1.8170049333857605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.71}, "Total num played games": 74496, "Total num trained steps": 148318, "Timestamp in ms": 1701621684797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911416530212331, "Avg loss": 0.3602524060988799, "Avg value loss": 0.14496223503374495, "Avg policy loss": 0.21529017109423876, "Total num played games": 74506, "Total num trained steps": 148352, "Timestamp in ms": 1701621699689, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928596354656, "Avg loss": 0.2907886995235458, "Avg value loss": 0.0717691607424058, "Avg policy loss": 0.21901953872293234, "Total num played games": 74506, "Total num trained steps": 148480, "Timestamp in ms": 1701621757804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992064343163539, "Avg loss": 0.346581470570527, "Avg value loss": 0.12494736287044361, "Avg policy loss": 0.2216341105522588, "Total num played games": 74600, "Total num trained steps": 148608, "Timestamp in ms": 1701621816427, "logtype": "training_step"}
{"Total num played games": 74600, "Total num trained steps": 148655, "Timestamp in ms": 1701621847619, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3515625}
{"Avg objective": 19.296875, "Games time in secs": 165.13349526934326, "Avg game time in secs": 1.817276923902682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.68, "agent_stopped_0": 0.36}, "Total num played games": 74624, "Total num trained steps": 148658, "Timestamp in ms": 1701621849931, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991271052561116, "Avg loss": 0.3849190321052447, "Avg value loss": 0.1606494695879519, "Avg policy loss": 0.22426956030540168, "Total num played games": 74694, "Total num trained steps": 148736, "Timestamp in ms": 1701621886360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929847109540257, "Avg loss": 0.26629878068342805, "Avg value loss": 0.05060922967095394, "Avg policy loss": 0.21568955038674176, "Total num played games": 74694, "Total num trained steps": 148864, "Timestamp in ms": 1701621944027, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 101.81424102373421, "Avg game time in secs": 1.6866418587305816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.64}, "Total num played games": 74752, "Total num trained steps": 148881, "Timestamp in ms": 1701621951746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921778895009894, "Avg loss": 0.35326859005726874, "Avg value loss": 0.1322467511636205, "Avg policy loss": 0.22102183871902525, "Total num played games": 74788, "Total num trained steps": 148992, "Timestamp in ms": 1701622001310, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 84.70391215197742, "Avg game time in secs": 1.8789725411916152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.76, "agent_stopped_0": 0.27}, "Total num played games": 74880, "Total num trained steps": 149071, "Timestamp in ms": 1701622036450, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913466160995674, "Avg loss": 0.3937972692074254, "Avg value loss": 0.169126204069471, "Avg policy loss": 0.22467106563271955, "Total num played games": 74884, "Total num trained steps": 149120, "Timestamp in ms": 1701622058032, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930559264996528, "Avg loss": 0.2755784043110907, "Avg value loss": 0.05498943028214853, "Avg policy loss": 0.22058897523675114, "Total num played games": 74884, "Total num trained steps": 149248, "Timestamp in ms": 1701622114591, "logtype": "training_step"}
{"Total num played games": 74978, "Total num trained steps": 149257, "Timestamp in ms": 1701622127651, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.890625}
{"Avg objective": 19.6796875, "Games time in secs": 93.60685336589813, "Avg game time in secs": 1.655588038120186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 75008, "Total num trained steps": 149261, "Timestamp in ms": 1701622130057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989769820971867, "Avg loss": 0.57433945836965, "Avg value loss": 0.32148352850344963, "Avg policy loss": 0.25285593036096543, "Total num played games": 75072, "Total num trained steps": 149376, "Timestamp in ms": 1701622180768, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914748508098892, "Avg loss": 0.2790633460972458, "Avg value loss": 0.047238118611858226, "Avg policy loss": 0.23182522715069354, "Total num played games": 75072, "Total num trained steps": 149504, "Timestamp in ms": 1701622238981, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931798806479113, "Avg loss": 0.26778735779225826, "Avg value loss": 0.042319571191910654, "Avg policy loss": 0.22546778619289398, "Total num played games": 75072, "Total num trained steps": 149632, "Timestamp in ms": 1701622295817, "logtype": "training_step"}
{"Avg objective": 19.8046875, "Games time in secs": 168.1290544718504, "Avg game time in secs": 1.7360042350483127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.74, "agent_stopped_0": 0.29}, "Total num played games": 75136, "Total num trained steps": 149638, "Timestamp in ms": 1701622298186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923901764095469, "Avg loss": 0.3901886122766882, "Avg value loss": 0.14636953105218709, "Avg policy loss": 0.24381908285431564, "Total num played games": 75166, "Total num trained steps": 149760, "Timestamp in ms": 1701622353207, "logtype": "training_step"}
{"Total num played games": 75262, "Total num trained steps": 149858, "Timestamp in ms": 1701622405268, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.17578125}
{"Avg objective": 21.2109375, "Games time in secs": 107.7973361518234, "Avg game time in secs": 1.9710473480517976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.76, "agent_stopped_0": 0.29}, "Total num played games": 75264, "Total num trained steps": 149858, "Timestamp in ms": 1701622405983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890652370083337, "Avg loss": 0.5261580707738176, "Avg value loss": 0.2813101290521445, "Avg policy loss": 0.2448479412123561, "Total num played games": 75356, "Total num trained steps": 149888, "Timestamp in ms": 1701622419159, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907638409682042, "Avg loss": 0.3685951145598665, "Avg value loss": 0.10862493739114143, "Avg policy loss": 0.25997017545159906, "Total num played games": 75356, "Total num trained steps": 150016, "Timestamp in ms": 1701622476008, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924624449280748, "Avg loss": 0.3132588961161673, "Avg value loss": 0.07211375499900896, "Avg policy loss": 0.24114514130633324, "Total num played games": 75356, "Total num trained steps": 150144, "Timestamp in ms": 1701622536937, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 159.77092106454074, "Avg game time in secs": 1.602311168637243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 75392, "Total num trained steps": 150205, "Timestamp in ms": 1701622565754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916766070245195, "Avg loss": 0.3797563072293997, "Avg value loss": 0.13506694366515148, "Avg policy loss": 0.24468936293851584, "Total num played games": 75450, "Total num trained steps": 150272, "Timestamp in ms": 1701622598214, "logtype": "training_step"}
{"Avg objective": 19.9921875, "Games time in secs": 87.32630448788404, "Avg game time in secs": 1.707786992410547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 75520, "Total num trained steps": 150393, "Timestamp in ms": 1701622653081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908927247696706, "Avg loss": 0.33426159829832613, "Avg value loss": 0.09178000393148977, "Avg policy loss": 0.24248159467242658, "Total num played games": 75544, "Total num trained steps": 150400, "Timestamp in ms": 1701622656501, "logtype": "training_step"}
{"Total num played games": 75544, "Total num trained steps": 150460, "Timestamp in ms": 1701622693808, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.125}
{"Ratio train steps to played games": 1.9901107908723128, "Avg loss": 0.49286308884620667, "Avg value loss": 0.21672726201359183, "Avg policy loss": 0.27613582683261484, "Total num played games": 75638, "Total num trained steps": 150528, "Timestamp in ms": 1701622727943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918030619529865, "Avg loss": 0.30888421763665974, "Avg value loss": 0.05656749816262163, "Avg policy loss": 0.25231671892106533, "Total num played games": 75638, "Total num trained steps": 150656, "Timestamp in ms": 1701622787404, "logtype": "training_step"}
{"Avg objective": 19.9375, "Games time in secs": 185.43251338787377, "Avg game time in secs": 1.758739326367504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 75648, "Total num trained steps": 150767, "Timestamp in ms": 1701622838514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910209686790261, "Avg loss": 0.3401819959981367, "Avg value loss": 0.09824771442799829, "Avg policy loss": 0.24193428142461926, "Total num played games": 75732, "Total num trained steps": 150784, "Timestamp in ms": 1701622846049, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927111392806212, "Avg loss": 0.34284270904026926, "Avg value loss": 0.09731745765020605, "Avg policy loss": 0.24552525090985, "Total num played games": 75732, "Total num trained steps": 150912, "Timestamp in ms": 1701622902328, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 84.78340329602361, "Avg game time in secs": 1.6841200666531222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 75776, "Total num trained steps": 150957, "Timestamp in ms": 1701622923297, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919288898267085, "Avg loss": 0.4482919868314639, "Avg value loss": 0.1857853992987657, "Avg policy loss": 0.2625065890606493, "Total num played games": 75826, "Total num trained steps": 151040, "Timestamp in ms": 1701622961986, "logtype": "training_step"}
{"Total num played games": 75826, "Total num trained steps": 151063, "Timestamp in ms": 1701622982435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.203125}
{"Avg objective": 19.4609375, "Games time in secs": 62.2569660525769, "Avg game time in secs": 1.8474138657329604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.75, "agent_stopped_0": 0.3}, "Total num played games": 75904, "Total num trained steps": 151069, "Timestamp in ms": 1701622985554, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911485774499473, "Avg loss": 0.4425111443269998, "Avg value loss": 0.17493705009110272, "Avg policy loss": 0.26757409516721964, "Total num played games": 75920, "Total num trained steps": 151168, "Timestamp in ms": 1701623032665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928345626975763, "Avg loss": 0.2934847844298929, "Avg value loss": 0.04730234851012938, "Avg policy loss": 0.24618243612349033, "Total num played games": 75920, "Total num trained steps": 151296, "Timestamp in ms": 1701623092274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919885287307935, "Avg loss": 0.43184534669853747, "Avg value loss": 0.16643833662965335, "Avg policy loss": 0.2654070147546008, "Total num played games": 76016, "Total num trained steps": 151424, "Timestamp in ms": 1701623149460, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 208.75970615260303, "Avg game time in secs": 1.7591885153233306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.71, "agent_stopped_0": 0.34}, "Total num played games": 76032, "Total num trained steps": 151524, "Timestamp in ms": 1701623194314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911709060332141, "Avg loss": 0.4019278755877167, "Avg value loss": 0.13992231443990022, "Avg policy loss": 0.26200556417461485, "Total num played games": 76112, "Total num trained steps": 151552, "Timestamp in ms": 1701623206949, "logtype": "training_step"}
{"Total num played games": 76112, "Total num trained steps": 151663, "Timestamp in ms": 1701623265984, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.796875}
{"Avg objective": 21.4609375, "Games time in secs": 74.24437577463686, "Avg game time in secs": 1.7285460151324514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.66}, "Total num played games": 76160, "Total num trained steps": 151669, "Timestamp in ms": 1701623268559, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99039445712936, "Avg loss": 0.40017612918745726, "Avg value loss": 0.13301722108735703, "Avg policy loss": 0.26715890946798027, "Total num played games": 76206, "Total num trained steps": 151680, "Timestamp in ms": 1701623273796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920741148990893, "Avg loss": 0.4215716412290931, "Avg value loss": 0.15753990242956206, "Avg policy loss": 0.26403173862490803, "Total num played games": 76206, "Total num trained steps": 151808, "Timestamp in ms": 1701623331458, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 106.13475990854204, "Avg game time in secs": 1.7305808627716033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 76288, "Total num trained steps": 151905, "Timestamp in ms": 1701623374693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99129750982962, "Avg loss": 0.4204770269570872, "Avg value loss": 0.16607622744049877, "Avg policy loss": 0.2544007991673425, "Total num played games": 76300, "Total num trained steps": 151936, "Timestamp in ms": 1701623389004, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929750982961991, "Avg loss": 0.33003581187222153, "Avg value loss": 0.07407777590560727, "Avg policy loss": 0.2559580384986475, "Total num played games": 76300, "Total num trained steps": 152064, "Timestamp in ms": 1701623446795, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921983401837842, "Avg loss": 0.40359016542788595, "Avg value loss": 0.14608104378567077, "Avg policy loss": 0.2575091200415045, "Total num played games": 76394, "Total num trained steps": 152192, "Timestamp in ms": 1701623504905, "logtype": "training_step"}
{"Total num played games": 76394, "Total num trained steps": 152266, "Timestamp in ms": 1701623550437, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.73046875}
{"Avg objective": 21.03125, "Games time in secs": 177.87866160832345, "Avg game time in secs": 1.7661459494556766, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 76416, "Total num trained steps": 152269, "Timestamp in ms": 1701623552572, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991423491266604, "Avg loss": 0.39436351193580776, "Avg value loss": 0.13780161034082994, "Avg policy loss": 0.2565619027009234, "Total num played games": 76488, "Total num trained steps": 152320, "Timestamp in ms": 1701623574071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930969563853154, "Avg loss": 0.2963726103771478, "Avg value loss": 0.05272640568728093, "Avg policy loss": 0.24364620517008007, "Total num played games": 76488, "Total num trained steps": 152448, "Timestamp in ms": 1701623627454, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 83.64895365014672, "Avg game time in secs": 1.5902481797384098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.58, "agent_stopped_0": 0.44}, "Total num played games": 76544, "Total num trained steps": 152470, "Timestamp in ms": 1701623636221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923219555509128, "Avg loss": 0.44120918156113476, "Avg value loss": 0.18066000560065731, "Avg policy loss": 0.26054917532019317, "Total num played games": 76582, "Total num trained steps": 152576, "Timestamp in ms": 1701623682761, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 82.39160244353116, "Avg game time in secs": 1.830861013615504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.73}, "Total num played games": 76672, "Total num trained steps": 152659, "Timestamp in ms": 1701623718613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99149690915256, "Avg loss": 0.401311281719245, "Avg value loss": 0.14495692324999254, "Avg policy loss": 0.2563543595606461, "Total num played games": 76678, "Total num trained steps": 152704, "Timestamp in ms": 1701623738782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931531860507576, "Avg loss": 0.2960883340565488, "Avg value loss": 0.05717339608236216, "Avg policy loss": 0.23891493922565132, "Total num played games": 76678, "Total num trained steps": 152832, "Timestamp in ms": 1701623794117, "logtype": "training_step"}
{"Total num played games": 76774, "Total num trained steps": 152869, "Timestamp in ms": 1701623821601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3359375}
{"Avg objective": 20.7265625, "Games time in secs": 105.30688855051994, "Avg game time in secs": 1.6297020086931298, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.61, "agent_stopped_0": 0.43}, "Total num played games": 76800, "Total num trained steps": 152874, "Timestamp in ms": 1701623823920, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899047718166207, "Avg loss": 0.5219960880931467, "Avg value loss": 0.2584996996447444, "Avg policy loss": 0.2634963868185878, "Total num played games": 76868, "Total num trained steps": 152960, "Timestamp in ms": 1701623861653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915699640942914, "Avg loss": 0.2986536957323551, "Avg value loss": 0.05156616511521861, "Avg policy loss": 0.24708753323648125, "Total num played games": 76868, "Total num trained steps": 153088, "Timestamp in ms": 1701623920360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932351563719624, "Avg loss": 0.275637318380177, "Avg value loss": 0.04119397631438915, "Avg policy loss": 0.23444334254600108, "Total num played games": 76868, "Total num trained steps": 153216, "Timestamp in ms": 1701623976348, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 157.68998640589416, "Avg game time in secs": 1.51653188461205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.52}, "Total num played games": 76928, "Total num trained steps": 153229, "Timestamp in ms": 1701623981610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992450819885138, "Avg loss": 0.3880423712544143, "Avg value loss": 0.146207043188042, "Avg policy loss": 0.24183533038012683, "Total num played games": 76962, "Total num trained steps": 153344, "Timestamp in ms": 1701624034576, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 88.61955098621547, "Avg game time in secs": 1.8528563285508426, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.68, "agent_stopped_0": 0.33}, "Total num played games": 77056, "Total num trained steps": 153419, "Timestamp in ms": 1701624070230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916943521594683, "Avg loss": 0.38449400989338756, "Avg value loss": 0.14596643550612498, "Avg policy loss": 0.23852757457643747, "Total num played games": 77056, "Total num trained steps": 153472, "Timestamp in ms": 1701624093895, "logtype": "training_step"}
{"Total num played games": 77056, "Total num trained steps": 153473, "Timestamp in ms": 1701624104312, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.71484375}
{"Ratio train steps to played games": 1.9909267660401815, "Avg loss": 0.46060014923568815, "Avg value loss": 0.20113072349340655, "Avg policy loss": 0.25946942542213947, "Total num played games": 77150, "Total num trained steps": 153600, "Timestamp in ms": 1701624162401, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925729099157485, "Avg loss": 0.27642620471306145, "Avg value loss": 0.04610438067174982, "Avg policy loss": 0.23032182676251978, "Total num played games": 77150, "Total num trained steps": 153728, "Timestamp in ms": 1701624218958, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 177.0718790963292, "Avg game time in secs": 1.6425345922616543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 77184, "Total num trained steps": 153793, "Timestamp in ms": 1701624247302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918181347418569, "Avg loss": 0.35465051291976124, "Avg value loss": 0.11180416110437363, "Avg policy loss": 0.2428463507676497, "Total num played games": 77244, "Total num trained steps": 153856, "Timestamp in ms": 1701624277203, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 87.36690766364336, "Avg game time in secs": 1.7531164023675956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 77312, "Total num trained steps": 153982, "Timestamp in ms": 1701624334669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911037550429296, "Avg loss": 0.30091849353630096, "Avg value loss": 0.054988417294225655, "Avg policy loss": 0.2459300725022331, "Total num played games": 77332, "Total num trained steps": 153984, "Timestamp in ms": 1701624335222, "logtype": "training_step"}
{"Total num played games": 77338, "Total num trained steps": 154075, "Timestamp in ms": 1701624384379, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.48046875}
{"Ratio train steps to played games": 1.99028825291869, "Avg loss": 0.5010688903275877, "Avg value loss": 0.24895838520023972, "Avg policy loss": 0.2521105073392391, "Total num played games": 77432, "Total num trained steps": 154112, "Timestamp in ms": 1701624400065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919413162516788, "Avg loss": 0.32091726234648377, "Avg value loss": 0.07612690338282846, "Avg policy loss": 0.24479035823605955, "Total num played games": 77432, "Total num trained steps": 154240, "Timestamp in ms": 1701624455359, "logtype": "training_step"}
{"Avg objective": 19.390625, "Games time in secs": 171.80105354823172, "Avg game time in secs": 1.6855872354353778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.63, "agent_stopped_0": 0.38}, "Total num played games": 77440, "Total num trained steps": 154356, "Timestamp in ms": 1701624506470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911771534710936, "Avg loss": 0.317090590368025, "Avg value loss": 0.08573672411148436, "Avg policy loss": 0.23135386570356786, "Total num played games": 77526, "Total num trained steps": 154368, "Timestamp in ms": 1701624512166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928282124706551, "Avg loss": 0.3670608075335622, "Avg value loss": 0.12508349629933946, "Avg policy loss": 0.24197731097228825, "Total num played games": 77526, "Total num trained steps": 154496, "Timestamp in ms": 1701624570881, "logtype": "training_step"}
{"Avg objective": 19.984375, "Games time in secs": 86.5114849936217, "Avg game time in secs": 1.6991634076985065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 77568, "Total num trained steps": 154544, "Timestamp in ms": 1701624592982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920639010564287, "Avg loss": 0.36087187519297004, "Avg value loss": 0.12568699072289746, "Avg policy loss": 0.23518488195259124, "Total num played games": 77620, "Total num trained steps": 154624, "Timestamp in ms": 1701624626936, "logtype": "training_step"}
{"Total num played games": 77620, "Total num trained steps": 154676, "Timestamp in ms": 1701624658961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.8828125}
{"Avg objective": 20.6875, "Games time in secs": 69.20002038031816, "Avg game time in secs": 1.6852075265342137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 77696, "Total num trained steps": 154683, "Timestamp in ms": 1701624662182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912885709138637, "Avg loss": 0.38772007217630744, "Avg value loss": 0.14907827001297846, "Avg policy loss": 0.23864180326927453, "Total num played games": 77714, "Total num trained steps": 154752, "Timestamp in ms": 1701624693713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929485034871453, "Avg loss": 0.28244910412468016, "Avg value loss": 0.05343317586812191, "Avg policy loss": 0.22901592822745442, "Total num played games": 77714, "Total num trained steps": 154880, "Timestamp in ms": 1701624751580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921346870582188, "Avg loss": 0.4056114157428965, "Avg value loss": 0.1602918569551548, "Avg policy loss": 0.2453195567941293, "Total num played games": 77810, "Total num trained steps": 155008, "Timestamp in ms": 1701624810597, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 196.76436133868992, "Avg game time in secs": 1.7524919456918724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.75, "agent_stopped_0": 0.33}, "Total num played games": 77824, "Total num trained steps": 155112, "Timestamp in ms": 1701624858946, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913739987677141, "Avg loss": 0.35938915703445673, "Avg value loss": 0.12070484076684806, "Avg policy loss": 0.23868431488517672, "Total num played games": 77904, "Total num trained steps": 155136, "Timestamp in ms": 1701624869064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993017046621483, "Avg loss": 0.333538246457465, "Avg value loss": 0.08430345536908135, "Avg policy loss": 0.24923479021526873, "Total num played games": 77904, "Total num trained steps": 155264, "Timestamp in ms": 1701624924066, "logtype": "training_step"}
{"Total num played games": 77904, "Total num trained steps": 155278, "Timestamp in ms": 1701624941017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.16796875}
{"Avg objective": 20.2890625, "Games time in secs": 84.59028692543507, "Avg game time in secs": 1.6315761841833591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 77952, "Total num trained steps": 155283, "Timestamp in ms": 1701624943537, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922562116977358, "Avg loss": 0.42859156185295433, "Avg value loss": 0.17502628223155625, "Avg policy loss": 0.25356528034899384, "Total num played games": 77998, "Total num trained steps": 155392, "Timestamp in ms": 1701624993149, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 93.44200150482357, "Avg game time in secs": 1.765336732249125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.71, "agent_stopped_0": 0.32}, "Total num played games": 78080, "Total num trained steps": 155489, "Timestamp in ms": 1701625036979, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914844030118322, "Avg loss": 0.37869156314991415, "Avg value loss": 0.1359930034086574, "Avg policy loss": 0.24269856116734445, "Total num played games": 78092, "Total num trained steps": 155520, "Timestamp in ms": 1701625051015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931363007734466, "Avg loss": 0.3287243414670229, "Avg value loss": 0.07579991096281447, "Avg policy loss": 0.2529244306497276, "Total num played games": 78092, "Total num trained steps": 155648, "Timestamp in ms": 1701625108683, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992377151919781, "Avg loss": 0.3891730793984607, "Avg value loss": 0.14179867034545168, "Avg policy loss": 0.24737440957687795, "Total num played games": 78186, "Total num trained steps": 155776, "Timestamp in ms": 1701625163587, "logtype": "training_step"}
{"Avg objective": 20.328125, "Games time in secs": 167.38096720166504, "Avg game time in secs": 1.5945831371791428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 78208, "Total num trained steps": 155864, "Timestamp in ms": 1701625204360, "logtype": "played_game"}
{"Total num played games": 78280, "Total num trained steps": 155880, "Timestamp in ms": 1701625221339, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.3984375}
{"Avg objective": 19.1796875, "Games time in secs": 19.992341538891196, "Avg game time in secs": 1.7224985970242415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.62, "agent_stopped_0": 0.38}, "Total num played games": 78336, "Total num trained steps": 155886, "Timestamp in ms": 1701625224353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892311225661572, "Avg loss": 0.4248548027826473, "Avg value loss": 0.18188219598960131, "Avg policy loss": 0.24297260865569115, "Total num played games": 78374, "Total num trained steps": 155904, "Timestamp in ms": 1701625232092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908515579146144, "Avg loss": 0.35575526754837483, "Avg value loss": 0.10702950524864718, "Avg policy loss": 0.24872576189227402, "Total num played games": 78374, "Total num trained steps": 156032, "Timestamp in ms": 1701625286796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924847525965244, "Avg loss": 0.27872162859421223, "Avg value loss": 0.04716225163429044, "Avg policy loss": 0.23155937902629375, "Total num played games": 78374, "Total num trained steps": 156160, "Timestamp in ms": 1701625341457, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 154.13045139051974, "Avg game time in secs": 1.8372028788580792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 78464, "Total num trained steps": 156243, "Timestamp in ms": 1701625378483, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917418565529899, "Avg loss": 0.39951047336217016, "Avg value loss": 0.1588795304269297, "Avg policy loss": 0.24063094099983573, "Total num played games": 78468, "Total num trained steps": 156288, "Timestamp in ms": 1701625399059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933603507162154, "Avg loss": 0.3043415527790785, "Avg value loss": 0.061045793670928106, "Avg policy loss": 0.24329575838055462, "Total num played games": 78468, "Total num trained steps": 156416, "Timestamp in ms": 1701625456545, "logtype": "training_step"}
{"Total num played games": 78562, "Total num trained steps": 156481, "Timestamp in ms": 1701625497178, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.25}
{"Avg objective": 19.96875, "Games time in secs": 121.2832085415721, "Avg game time in secs": 1.687453484220896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.6, "agent_stopped_0": 0.44}, "Total num played games": 78592, "Total num trained steps": 156485, "Timestamp in ms": 1701625499767, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902232506102522, "Avg loss": 0.5561907425289974, "Avg value loss": 0.2898460290452931, "Avg policy loss": 0.26634471176657826, "Total num played games": 78656, "Total num trained steps": 156544, "Timestamp in ms": 1701625527695, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918633034987796, "Avg loss": 0.3284816963132471, "Avg value loss": 0.05975337271229364, "Avg policy loss": 0.2687283226987347, "Total num played games": 78656, "Total num trained steps": 156672, "Timestamp in ms": 1701625585506, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9934906427990235, "Avg loss": 0.3189226114191115, "Avg value loss": 0.07278615090763196, "Avg policy loss": 0.2461364596383646, "Total num played games": 78656, "Total num trained steps": 156800, "Timestamp in ms": 1701625643879, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 146.45641563273966, "Avg game time in secs": 1.7846713594772154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.72, "agent_stopped_0": 0.31}, "Total num played games": 78720, "Total num trained steps": 156806, "Timestamp in ms": 1701625646223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992736507936508, "Avg loss": 0.41718420945107937, "Avg value loss": 0.15085201660986058, "Avg policy loss": 0.26633219176437706, "Total num played games": 78750, "Total num trained steps": 156928, "Timestamp in ms": 1701625703741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919841712749227, "Avg loss": 0.4099108026130125, "Avg value loss": 0.14827979102847166, "Avg policy loss": 0.26163101324345917, "Total num played games": 78844, "Total num trained steps": 157056, "Timestamp in ms": 1701625761758, "logtype": "training_step"}
{"Total num played games": 78844, "Total num trained steps": 157084, "Timestamp in ms": 1701625783516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.23046875}
{"Avg objective": 19.7734375, "Games time in secs": 139.08040863275528, "Avg game time in secs": 1.838396467093844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.75}, "Total num played games": 78848, "Total num trained steps": 157086, "Timestamp in ms": 1701625785304, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912336263903316, "Avg loss": 0.4308113674633205, "Avg value loss": 0.1542010883858893, "Avg policy loss": 0.27661028038710356, "Total num played games": 78938, "Total num trained steps": 157184, "Timestamp in ms": 1701625830580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992842483974765, "Avg loss": 0.3030179882189259, "Avg value loss": 0.04722442336787935, "Avg policy loss": 0.2557935658842325, "Total num played games": 78938, "Total num trained steps": 157312, "Timestamp in ms": 1701625889417, "logtype": "training_step"}
{"Avg objective": 19.8828125, "Games time in secs": 130.5938357245177, "Avg game time in secs": 1.651666812831536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 78976, "Total num trained steps": 157369, "Timestamp in ms": 1701625915898, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921044640145764, "Avg loss": 0.3634497014572844, "Avg value loss": 0.1068354202870978, "Avg policy loss": 0.2566142806317657, "Total num played games": 79032, "Total num trained steps": 157440, "Timestamp in ms": 1701625950603, "logtype": "training_step"}
{"Avg objective": 20.8125, "Games time in secs": 88.70363629236817, "Avg game time in secs": 1.739999808210996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.7}, "Total num played games": 79104, "Total num trained steps": 157558, "Timestamp in ms": 1701626004601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912925892225255, "Avg loss": 0.3395130295539275, "Avg value loss": 0.08989568898687139, "Avg policy loss": 0.24961734132375568, "Total num played games": 79128, "Total num trained steps": 157568, "Timestamp in ms": 1701626009150, "logtype": "training_step"}
{"Total num played games": 79128, "Total num trained steps": 157684, "Timestamp in ms": 1701626071283, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.5078125}
{"Ratio train steps to played games": 1.99055817828381, "Avg loss": 0.38714927749242634, "Avg value loss": 0.12364224257180467, "Avg policy loss": 0.2635070354444906, "Total num played games": 79222, "Total num trained steps": 157696, "Timestamp in ms": 1701626078360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921738910908586, "Avg loss": 0.377835062565282, "Avg value loss": 0.11849162238650024, "Avg policy loss": 0.25934343761764467, "Total num played games": 79222, "Total num trained steps": 157824, "Timestamp in ms": 1701626137407, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 182.23216048814356, "Avg game time in secs": 1.7590853120200336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 79232, "Total num trained steps": 157935, "Timestamp in ms": 1701626186834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913638770518671, "Avg loss": 0.368581373244524, "Avg value loss": 0.12275647287606262, "Avg policy loss": 0.2458248999901116, "Total num played games": 79318, "Total num trained steps": 157952, "Timestamp in ms": 1701626194734, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929776343326862, "Avg loss": 0.3967435361118987, "Avg value loss": 0.1297867166576907, "Avg policy loss": 0.2669568199198693, "Total num played games": 79318, "Total num trained steps": 158080, "Timestamp in ms": 1701626255004, "logtype": "training_step"}
{"Avg objective": 19.921875, "Games time in secs": 90.2148782107979, "Avg game time in secs": 1.700915559544228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 79360, "Total num trained steps": 158129, "Timestamp in ms": 1701626277049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992230393391427, "Avg loss": 0.37648137053474784, "Avg value loss": 0.12069426331436262, "Avg policy loss": 0.25578710553236306, "Total num played games": 79412, "Total num trained steps": 158208, "Timestamp in ms": 1701626311306, "logtype": "training_step"}
{"Total num played games": 79412, "Total num trained steps": 158286, "Timestamp in ms": 1701626355142, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.38671875}
{"Avg objective": 20.5078125, "Games time in secs": 81.30544761568308, "Avg game time in secs": 1.6490874376322608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.55, "agent_stopped_0": 0.46}, "Total num played games": 79488, "Total num trained steps": 158293, "Timestamp in ms": 1701626358354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914974970442483, "Avg loss": 0.436425574705936, "Avg value loss": 0.17498185917793307, "Avg policy loss": 0.26144371496047825, "Total num played games": 79506, "Total num trained steps": 158336, "Timestamp in ms": 1701626378335, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931074384323195, "Avg loss": 0.32078694889787585, "Avg value loss": 0.06262439020792954, "Avg policy loss": 0.2581625598249957, "Total num played games": 79506, "Total num trained steps": 158464, "Timestamp in ms": 1701626437328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992311750961031, "Avg loss": 0.4389795084716752, "Avg value loss": 0.17890369024826214, "Avg policy loss": 0.2600758181652054, "Total num played games": 79602, "Total num trained steps": 158592, "Timestamp in ms": 1701626493772, "logtype": "training_step"}
{"Avg objective": 20.6015625, "Games time in secs": 182.77422082796693, "Avg game time in secs": 1.7374122683977475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 79616, "Total num trained steps": 158696, "Timestamp in ms": 1701626541129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991567958241317, "Avg loss": 0.36907453543972224, "Avg value loss": 0.12173448342946358, "Avg policy loss": 0.24734005564823747, "Total num played games": 79696, "Total num trained steps": 158720, "Timestamp in ms": 1701626551500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993174061433447, "Avg loss": 0.346681633265689, "Avg value loss": 0.09147805123939179, "Avg policy loss": 0.2552035810658708, "Total num played games": 79696, "Total num trained steps": 158848, "Timestamp in ms": 1701626610354, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 84.88470530696213, "Avg game time in secs": 1.6930978667951422, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 79744, "Total num trained steps": 158886, "Timestamp in ms": 1701626626014, "logtype": "played_game"}
{"Total num played games": 79798, "Total num trained steps": 158890, "Timestamp in ms": 1701626638937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.1328125}
{"Avg objective": 20.265625, "Games time in secs": 16.083950888365507, "Avg game time in secs": 1.7614076803729404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.68, "agent_stopped_0": 0.34}, "Total num played games": 79872, "Total num trained steps": 158895, "Timestamp in ms": 1701626642098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898863465678667, "Avg loss": 0.6023345745634288, "Avg value loss": 0.32387369342905004, "Avg policy loss": 0.27846088458318263, "Total num played games": 79892, "Total num trained steps": 158976, "Timestamp in ms": 1701626679717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914885094878085, "Avg loss": 0.30987989832647145, "Avg value loss": 0.05450107483193278, "Avg policy loss": 0.2553788247751072, "Total num played games": 79892, "Total num trained steps": 159104, "Timestamp in ms": 1701626738184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930906724077504, "Avg loss": 0.2895034484099597, "Avg value loss": 0.04166451809578575, "Avg policy loss": 0.24783893232233822, "Total num played games": 79892, "Total num trained steps": 159232, "Timestamp in ms": 1701626795655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992298844826724, "Avg loss": 0.42676901596132666, "Avg value loss": 0.17951279153930955, "Avg policy loss": 0.2472562266048044, "Total num played games": 79988, "Total num trained steps": 159360, "Timestamp in ms": 1701626852404, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 258.3227668236941, "Avg game time in secs": 1.724295547552174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.69}, "Total num played games": 80000, "Total num trained steps": 159467, "Timestamp in ms": 1701626900421, "logtype": "played_game"}
{"Total num played games": 80084, "Total num trained steps": 159469, "Timestamp in ms": 1701626910490, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.9296875}
{"Avg objective": 20.859375, "Games time in secs": 15.520684212446213, "Avg game time in secs": 1.8426261591812363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.7}, "Total num played games": 80128, "Total num trained steps": 159469, "Timestamp in ms": 1701626915941, "logtype": "played_game"}
{"Total num played games": 80128, "Total num trained steps": 159469, "Timestamp in ms": 1701626924591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.78515625}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701627371645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.359375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1701627626632, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.21484375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702309598623, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.21875}
