{"Avg objective": 17.056406249999995, "Games time in secs": 214.50099222548306, "Avg game time in secs": 83.70268474792829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 7.53, "agent_stopped_0": 0.15, "reached_maximum_moves": 0.42}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1700735417666, "logtype": "played_game"}
{"Avg objective": 15.457109375000002, "Games time in secs": 138.17094623111188, "Avg game time in secs": 89.79732720030006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"reached_maximum_moves": 0.45, "played_steps": 7.89, "agent_stopped_more": 0.43, "agent_stopped_0": 0.12}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1700735555837, "logtype": "played_game"}
{"Ratio train steps to played games": 0.4155844155844156, "Avg loss": 65.12456043064594, "Avg value loss": 64.27371184527874, "Avg policy loss": 0.8508487273938954, "Total num played games": 308, "Total num trained steps": 128, "Timestamp in ms": 1700735627332, "logtype": "training_step"}
{"Ratio train steps to played games": 0.7111111111111111, "Avg loss": 13.694934584200382, "Avg value loss": 12.880354583263397, "Avg policy loss": 0.8145800135098398, "Total num played games": 360, "Total num trained steps": 256, "Timestamp in ms": 1700735700911, "logtype": "training_step"}
{"Avg objective": 15.497109374999996, "Games time in secs": 179.4672424402088, "Avg game time in secs": 99.52675201065722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.1, "reached_maximum_moves": 0.51, "played_steps": 8.78, "agent_stopped_more": 0.39}, "Total num played games": 384, "Total num trained steps": 321, "Timestamp in ms": 1700735735304, "logtype": "played_game"}
{"Ratio train steps to played games": 0.9230769230769231, "Avg loss": 8.211918253451586, "Avg value loss": 7.425620622932911, "Avg policy loss": 0.7862977432087064, "Total num played games": 416, "Total num trained steps": 384, "Timestamp in ms": 1700735770989, "logtype": "training_step"}
{"Avg objective": 15.388828124999993, "Games time in secs": 160.87801801599562, "Avg game time in secs": 106.47580305984593, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.23, "played_steps": 9.13, "agent_stopped_0": 0.19, "reached_maximum_moves": 0.58}, "Total num played games": 512, "Total num trained steps": 503, "Timestamp in ms": 1700735896182, "logtype": "played_game"}
{"Total num played games": 566, "Total num trained steps": 503, "Timestamp in ms": 1700736077648, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.2448828125}
{"Ratio train steps to played games": 0.9045936395759717, "Avg loss": 6.281728882342577, "Avg value loss": 5.524587908759713, "Avg policy loss": 0.7571409679949284, "Total num played games": 566, "Total num trained steps": 512, "Timestamp in ms": 1700736082869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.08843537414966, "Avg loss": 6.171293161809444, "Avg value loss": 5.468374768272042, "Avg policy loss": 0.7029183912090957, "Total num played games": 588, "Total num trained steps": 640, "Timestamp in ms": 1700736135971, "logtype": "training_step"}
{"Ratio train steps to played games": 1.2190476190476192, "Avg loss": 3.9644966013729572, "Avg value loss": 3.267808310687542, "Avg policy loss": 0.6966883218847215, "Total num played games": 630, "Total num trained steps": 768, "Timestamp in ms": 1700736194499, "logtype": "training_step"}
{"Avg objective": 16.989765624999997, "Games time in secs": 315.21974939480424, "Avg game time in secs": 86.53634539351333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "reached_maximum_moves": 0.48, "played_steps": 7.95, "agent_stopped_more": 0.2}, "Total num played games": 640, "Total num trained steps": 805, "Timestamp in ms": 1700736211402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.3575757575757577, "Avg loss": 3.999458894133568, "Avg value loss": 3.305888487957418, "Avg policy loss": 0.6935704289935529, "Total num played games": 660, "Total num trained steps": 896, "Timestamp in ms": 1700736251876, "logtype": "training_step"}
{"Avg objective": 16.247500000000002, "Games time in secs": 191.82790431566536, "Avg game time in secs": 112.40569355308253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"reached_maximum_moves": 0.55, "played_steps": 9.49, "agent_stopped_more": 0.26, "agent_stopped_0": 0.19}, "Total num played games": 768, "Total num trained steps": 1002, "Timestamp in ms": 1700736403230, "logtype": "played_game"}
{"Total num played games": 786, "Total num trained steps": 1002, "Timestamp in ms": 1700736536393, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.0729296875}
{"Ratio train steps to played games": 1.3027989821882953, "Avg loss": 3.7293290589004755, "Avg value loss": 3.054158117622137, "Avg policy loss": 0.6751709673553705, "Total num played games": 786, "Total num trained steps": 1024, "Timestamp in ms": 1700736545505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.44, "Avg loss": 3.774254409596324, "Avg value loss": 3.1189536321908236, "Avg policy loss": 0.6553007992915809, "Total num played games": 800, "Total num trained steps": 1152, "Timestamp in ms": 1700736593895, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5384615384615385, "Avg loss": 2.7753142323344946, "Avg value loss": 2.1152847772464156, "Avg policy loss": 0.6600294653326273, "Total num played games": 832, "Total num trained steps": 1280, "Timestamp in ms": 1700736641901, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5963718820861679, "Avg loss": 2.804704879410565, "Avg value loss": 2.1468523582443595, "Avg policy loss": 0.6578525197692215, "Total num played games": 882, "Total num trained steps": 1408, "Timestamp in ms": 1700736691169, "logtype": "training_step"}
{"Avg objective": 16.301484375, "Games time in secs": 310.80040159262717, "Avg game time in secs": 75.81592298885516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"reached_maximum_moves": 0.42, "played_steps": 6.97, "agent_stopped_more": 0.23, "agent_stopped_0": 0.34}, "Total num played games": 896, "Total num trained steps": 1467, "Timestamp in ms": 1700736714031, "logtype": "played_game"}
{"Total num played games": 1004, "Total num trained steps": 1506, "Timestamp in ms": 1700736980937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 20.855937499999996}
{"Ratio train steps to played games": 1.5088408644400786, "Avg loss": 3.5873185377568007, "Avg value loss": 2.942744540050626, "Avg policy loss": 0.6445740088820457, "Total num played games": 1018, "Total num trained steps": 1536, "Timestamp in ms": 1700736992670, "logtype": "training_step"}
{"Avg objective": 16.000937500000006, "Games time in secs": 284.9058242402971, "Avg game time in secs": 97.23417782889737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"reached_maximum_moves": 0.53, "played_steps": 8.3, "agent_stopped_more": 0.15, "agent_stopped_0": 0.32}, "Total num played games": 1024, "Total num trained steps": 1553, "Timestamp in ms": 1700736998937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.609284332688588, "Avg loss": 3.3216820526868105, "Avg value loss": 2.685433829203248, "Avg policy loss": 0.6362482365220785, "Total num played games": 1034, "Total num trained steps": 1664, "Timestamp in ms": 1700737051808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5774647887323943, "Avg loss": 3.3032811917364597, "Avg value loss": 2.677222319878638, "Avg policy loss": 0.6260588769800961, "Total num played games": 1134, "Total num trained steps": 1792, "Timestamp in ms": 1700737113236, "logtype": "training_step"}
{"Avg objective": 18.341953124999993, "Games time in secs": 132.35194408893585, "Avg game time in secs": 42.02697409236862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.19, "played_steps": 4.18, "agent_stopped_0": 0.57, "reached_maximum_moves": 0.24}, "Total num played games": 1152, "Total num trained steps": 1830, "Timestamp in ms": 1700737131289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6216216216216217, "Avg loss": 2.741310380399227, "Avg value loss": 2.1230640169233084, "Avg policy loss": 0.6182463560253382, "Total num played games": 1184, "Total num trained steps": 1920, "Timestamp in ms": 1700737173245, "logtype": "training_step"}
{"Avg objective": 18.2078125, "Games time in secs": 94.53059507161379, "Avg game time in secs": 61.96593282365939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.17, "played_steps": 5.3, "agent_stopped_0": 0.53, "reached_maximum_moves": 0.3}, "Total num played games": 1280, "Total num trained steps": 2008, "Timestamp in ms": 1700737225820, "logtype": "played_game"}
{"Total num played games": 1348, "Total num trained steps": 2008, "Timestamp in ms": 1700737479489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.0381640625}
{"Ratio train steps to played games": 1.4670487106017192, "Avg loss": 3.32535333186388, "Avg value loss": 2.724256679415703, "Avg policy loss": 0.6010966370813549, "Total num played games": 1396, "Total num trained steps": 2048, "Timestamp in ms": 1700737499590, "logtype": "training_step"}
{"Avg objective": 17.8240625, "Games time in secs": 304.3650789167732, "Avg game time in secs": 59.83672535767255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2421875, "Avg reasons for ending game": {"reached_maximum_moves": 0.32, "played_steps": 5.22, "agent_stopped_0": 0.55, "agent_stopped_more": 0.13}, "Total num played games": 1408, "Total num trained steps": 2112, "Timestamp in ms": 1700737530185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.532394366197183, "Avg loss": 2.83069808781147, "Avg value loss": 2.234582334756851, "Avg policy loss": 0.596115758176893, "Total num played games": 1420, "Total num trained steps": 2176, "Timestamp in ms": 1700737561613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5970873786407767, "Avg loss": 2.230032427236438, "Avg value loss": 1.6425094809383154, "Avg policy loss": 0.5875229388475418, "Total num played games": 1442, "Total num trained steps": 2304, "Timestamp in ms": 1700737625442, "logtype": "training_step"}
{"Ratio train steps to played games": 1.623497997329773, "Avg loss": 2.1725416285917163, "Avg value loss": 1.5897568222135305, "Avg policy loss": 0.582784810103476, "Total num played games": 1498, "Total num trained steps": 2432, "Timestamp in ms": 1700737691889, "logtype": "training_step"}
{"Avg objective": 17.9503125, "Games time in secs": 208.54167656227946, "Avg game time in secs": 29.619291821014485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.12, "played_steps": 2.5, "agent_stopped_0": 0.74, "reached_maximum_moves": 0.13}, "Total num played games": 1536, "Total num trained steps": 2511, "Timestamp in ms": 1700737738727, "logtype": "played_game"}
{"Total num played games": 1600, "Total num trained steps": 2511, "Timestamp in ms": 1700737943165, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.38984375}
{"Ratio train steps to played games": 1.5705521472392638, "Avg loss": 2.6154025066643953, "Avg value loss": 2.0470317755825818, "Avg policy loss": 0.5683707429561764, "Total num played games": 1630, "Total num trained steps": 2560, "Timestamp in ms": 1700737967961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6251511487303507, "Avg loss": 2.424898308701813, "Avg value loss": 1.8825856549665332, "Avg policy loss": 0.5423126653768122, "Total num played games": 1654, "Total num trained steps": 2688, "Timestamp in ms": 1700738026634, "logtype": "training_step"}
{"Avg objective": 18.57453125000001, "Games time in secs": 310.60963158868253, "Avg game time in secs": 52.71819428488379, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "reached_maximum_moves": 0.38, "played_steps": 5.62, "agent_stopped_more": 0.11}, "Total num played games": 1664, "Total num trained steps": 2735, "Timestamp in ms": 1700738049337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6662721893491124, "Avg loss": 2.3781139384955168, "Avg value loss": 1.8471508733928204, "Avg policy loss": 0.5309630606789142, "Total num played games": 1690, "Total num trained steps": 2816, "Timestamp in ms": 1700738090565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.663276836158192, "Avg loss": 2.0741671146824956, "Avg value loss": 1.5582702499814332, "Avg policy loss": 0.5158968674950302, "Total num played games": 1770, "Total num trained steps": 2944, "Timestamp in ms": 1700738152750, "logtype": "training_step"}
{"Avg objective": 18.746015624999995, "Games time in secs": 177.79812722839415, "Avg game time in secs": 39.42244124534773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"reached_maximum_moves": 0.23, "played_steps": 3.59, "agent_stopped_0": 0.7, "agent_stopped_more": 0.08}, "Total num played games": 1792, "Total num trained steps": 3014, "Timestamp in ms": 1700738227135, "logtype": "played_game"}
{"Total num played games": 1798, "Total num trained steps": 3014, "Timestamp in ms": 1700738364485, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.469609375}
{"Ratio train steps to played games": 1.6605405405405405, "Avg loss": 2.001919336616993, "Avg value loss": 1.512578517664224, "Avg policy loss": 0.48934081150218844, "Total num played games": 1850, "Total num trained steps": 3072, "Timestamp in ms": 1700738394060, "logtype": "training_step"}
{"Ratio train steps to played games": 1.714898177920686, "Avg loss": 1.5916961403563619, "Avg value loss": 1.1210292908363044, "Avg policy loss": 0.4706668450962752, "Total num played games": 1866, "Total num trained steps": 3200, "Timestamp in ms": 1700738455257, "logtype": "training_step"}
{"Avg objective": 18.791874999999997, "Games time in secs": 255.83713173121214, "Avg game time in secs": 25.008314541206346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"reached_maximum_moves": 0.13, "played_steps": 2.12, "agent_stopped_0": 0.83, "agent_stopped_more": 0.04}, "Total num played games": 1920, "Total num trained steps": 3257, "Timestamp in ms": 1700738482973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.707905544147844, "Avg loss": 1.7236525723710656, "Avg value loss": 1.260789831634611, "Avg policy loss": 0.46286273188889027, "Total num played games": 1948, "Total num trained steps": 3328, "Timestamp in ms": 1700738516521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7108910891089109, "Avg loss": 1.5235287453979254, "Avg value loss": 1.0741639104671776, "Avg policy loss": 0.4493648339994252, "Total num played games": 2020, "Total num trained steps": 3456, "Timestamp in ms": 1700738574616, "logtype": "training_step"}
{"Avg objective": 20.5678125, "Games time in secs": 143.80809919722378, "Avg game time in secs": 31.061728140950436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.13, "played_steps": 2.59, "reached_maximum_moves": 0.14}, "Total num played games": 2048, "Total num trained steps": 3517, "Timestamp in ms": 1700738626781, "logtype": "played_game"}
{"Total num played games": 2066, "Total num trained steps": 3517, "Timestamp in ms": 1700738827827, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.0769921875}
{"Ratio train steps to played games": 1.6900943396226416, "Avg loss": 2.138365442864597, "Avg value loss": 1.703389042057097, "Avg policy loss": 0.43497638404369354, "Total num played games": 2120, "Total num trained steps": 3584, "Timestamp in ms": 1700738855910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.736202057998129, "Avg loss": 1.4774231668561697, "Avg value loss": 1.0575972138904035, "Avg policy loss": 0.41982595529407263, "Total num played games": 2138, "Total num trained steps": 3712, "Timestamp in ms": 1700738913603, "logtype": "training_step"}
{"Avg objective": 19.658125, "Games time in secs": 339.0399672854692, "Avg game time in secs": 32.74136924104823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "reached_maximum_moves": 0.17, "played_steps": 2.89, "agent_stopped_more": 0.06}, "Total num played games": 2176, "Total num trained steps": 3825, "Timestamp in ms": 1700738965821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7277227722772277, "Avg loss": 1.4764556884765625, "Avg value loss": 1.064740162808448, "Avg policy loss": 0.4117155163548887, "Total num played games": 2222, "Total num trained steps": 3840, "Timestamp in ms": 1700738971962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7604259094942325, "Avg loss": 1.5580377792939544, "Avg value loss": 1.1676358892582357, "Avg policy loss": 0.39040189422667027, "Total num played games": 2254, "Total num trained steps": 3968, "Timestamp in ms": 1700739031561, "logtype": "training_step"}
{"Avg objective": 19.954765625, "Games time in secs": 91.20927323587239, "Avg game time in secs": 23.37438031262718, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.03, "played_steps": 1.38, "reached_maximum_moves": 0.09}, "Total num played games": 2304, "Total num trained steps": 4020, "Timestamp in ms": 1700739057030, "logtype": "played_game"}
{"Total num played games": 2350, "Total num trained steps": 4020, "Timestamp in ms": 1700739238961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3205078125}
{"Ratio train steps to played games": 1.68559670781893, "Avg loss": 2.071283657103777, "Avg value loss": 1.6945395660586655, "Avg policy loss": 0.3767440980300307, "Total num played games": 2430, "Total num trained steps": 4096, "Timestamp in ms": 1700739272449, "logtype": "training_step"}
{"Avg objective": 19.9584375, "Games time in secs": 221.92399100400507, "Avg game time in secs": 21.362657378209406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "reached_maximum_moves": 0.09, "played_steps": 1.61, "agent_stopped_more": 0.06}, "Total num played games": 2432, "Total num trained steps": 4109, "Timestamp in ms": 1700739278954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7297297297297298, "Avg loss": 1.2913068565540016, "Avg value loss": 0.9386366619728506, "Avg policy loss": 0.35267019225284457, "Total num played games": 2442, "Total num trained steps": 4224, "Timestamp in ms": 1700739335245, "logtype": "training_step"}
{"Ratio train steps to played games": 1.780278232405892, "Avg loss": 1.1151846358552575, "Avg value loss": 0.7635730674955994, "Avg policy loss": 0.3516115699894726, "Total num played games": 2444, "Total num trained steps": 4352, "Timestamp in ms": 1700739399315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.768957345971564, "Avg loss": 1.2292083925567567, "Avg value loss": 0.891663467977196, "Avg policy loss": 0.3375449285376817, "Total num played games": 2532, "Total num trained steps": 4480, "Timestamp in ms": 1700739456668, "logtype": "training_step"}
{"Total num played games": 2552, "Total num trained steps": 4520, "Timestamp in ms": 1700739700239, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.37109375}
{"Avg objective": 18.70046875, "Games time in secs": 431.71449487656355, "Avg game time in secs": 23.119142066148925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.08, "played_steps": 1.84, "agent_stopped_0": 0.81, "reached_maximum_moves": 0.11}, "Total num played games": 2560, "Total num trained steps": 4545, "Timestamp in ms": 1700739710669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.746398786959818, "Avg loss": 1.4187727249227464, "Avg value loss": 1.101604909170419, "Avg policy loss": 0.31716781575232744, "Total num played games": 2638, "Total num trained steps": 4608, "Timestamp in ms": 1700739741800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7885196374622356, "Avg loss": 1.055293912999332, "Avg value loss": 0.7534974052105099, "Avg policy loss": 0.301796511746943, "Total num played games": 2648, "Total num trained steps": 4736, "Timestamp in ms": 1700739805652, "logtype": "training_step"}
{"Avg objective": 20.281953125, "Games time in secs": 130.65171150304377, "Avg game time in secs": 13.882994887389941, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.01, "played_steps": 0.57, "reached_maximum_moves": 0.04}, "Total num played games": 2688, "Total num trained steps": 4814, "Timestamp in ms": 1700739841321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.772594752186589, "Avg loss": 1.1092385780066252, "Avg value loss": 0.8161526338662952, "Avg policy loss": 0.29308594204485416, "Total num played games": 2744, "Total num trained steps": 4864, "Timestamp in ms": 1700739865235, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8152727272727274, "Avg loss": 0.9907108857296407, "Avg value loss": 0.7099294310901314, "Avg policy loss": 0.2807814503321424, "Total num played games": 2750, "Total num trained steps": 4992, "Timestamp in ms": 1700739930513, "logtype": "training_step"}
{"Avg objective": 22.563828125, "Games time in secs": 99.22293953597546, "Avg game time in secs": 14.715866260696203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.01, "played_steps": 0.62, "reached_maximum_moves": 0.04}, "Total num played games": 2816, "Total num trained steps": 5019, "Timestamp in ms": 1700739940544, "logtype": "played_game"}
{"Total num played games": 2862, "Total num trained steps": 5023, "Timestamp in ms": 1700740117429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.6172265625}
{"Avg objective": 20.400234375, "Games time in secs": 221.9514734186232, "Avg game time in secs": 15.75302699788881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.04, "played_steps": 0.91, "reached_maximum_moves": 0.06}, "Total num played games": 2944, "Total num trained steps": 5119, "Timestamp in ms": 1700740162496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7391304347826086, "Avg loss": 2.6936591141857207, "Avg value loss": 2.4415354032535106, "Avg policy loss": 0.252123688114807, "Total num played games": 2944, "Total num trained steps": 5120, "Timestamp in ms": 1700740162940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7750338294993233, "Avg loss": 1.2233131104148924, "Avg value loss": 0.9808014300651848, "Avg policy loss": 0.2425116813974455, "Total num played games": 2956, "Total num trained steps": 5248, "Timestamp in ms": 1700740226116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8186738836265224, "Avg loss": 0.9286629962734878, "Avg value loss": 0.6892021363601089, "Avg policy loss": 0.23946086317300797, "Total num played games": 2956, "Total num trained steps": 5376, "Timestamp in ms": 1700740288485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7995421844342707, "Avg loss": 1.1476234230212867, "Avg value loss": 0.9188517390284687, "Avg policy loss": 0.22877168306149542, "Total num played games": 3058, "Total num trained steps": 5504, "Timestamp in ms": 1700740348221, "logtype": "training_step"}
{"Total num played games": 3066, "Total num trained steps": 5526, "Timestamp in ms": 1700740519405, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.371289062499997}
{"Avg objective": 19.875546874999998, "Games time in secs": 367.4100235402584, "Avg game time in secs": 19.9715073506959, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "reached_maximum_moves": 0.09, "played_steps": 1.3, "agent_stopped_more": 0.04}, "Total num played games": 3072, "Total num trained steps": 5553, "Timestamp in ms": 1700740529906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7913486005089059, "Avg loss": 1.2061464451253414, "Avg value loss": 0.9970291384961456, "Avg policy loss": 0.2091173002263531, "Total num played games": 3144, "Total num trained steps": 5632, "Timestamp in ms": 1700740567585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.823622545915136, "Avg loss": 0.833085872232914, "Avg value loss": 0.6351308948360384, "Avg policy loss": 0.1979549729730934, "Total num played games": 3158, "Total num trained steps": 5760, "Timestamp in ms": 1700740629807, "logtype": "training_step"}
{"Avg objective": 20.37515625, "Games time in secs": 132.34703041054308, "Avg game time in secs": 14.20439317682758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.94, "agent_stopped_more": 0.02, "played_steps": 0.65, "reached_maximum_moves": 0.04}, "Total num played games": 3200, "Total num trained steps": 5835, "Timestamp in ms": 1700740662253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8116923076923077, "Avg loss": 1.0211946973577142, "Avg value loss": 0.8294086719397455, "Avg policy loss": 0.19178602017927915, "Total num played games": 3250, "Total num trained steps": 5888, "Timestamp in ms": 1700740686840, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8428308823529411, "Avg loss": 0.7875345577485859, "Avg value loss": 0.6066034424584359, "Avg policy loss": 0.1809311129618436, "Total num played games": 3264, "Total num trained steps": 6016, "Timestamp in ms": 1700740750328, "logtype": "training_step"}
{"Avg objective": 20.237812500000004, "Games time in secs": 99.51973328925669, "Avg game time in secs": 20.351399060193216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.02, "played_steps": 1.18, "reached_maximum_moves": 0.08}, "Total num played games": 3328, "Total num trained steps": 6026, "Timestamp in ms": 1700740761773, "logtype": "played_game"}
{"Total num played games": 3360, "Total num trained steps": 6026, "Timestamp in ms": 1700740928519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.530546875}
{"Ratio train steps to played games": 1.7808695652173914, "Avg loss": 1.4667294276878238, "Avg value loss": 1.3018116161692888, "Avg policy loss": 0.16491782281082124, "Total num played games": 3450, "Total num trained steps": 6144, "Timestamp in ms": 1700740983826, "logtype": "training_step"}
{"Avg objective": 20.474453124999997, "Games time in secs": 270.1012483164668, "Avg game time in secs": 17.768203395826276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "agent_stopped_more": 0.04, "played_steps": 1.0, "reached_maximum_moves": 0.06}, "Total num played games": 3456, "Total num trained steps": 6242, "Timestamp in ms": 1700741031875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.814525462962963, "Avg loss": 0.7791511383838952, "Avg value loss": 0.6205068393610418, "Avg policy loss": 0.15864429785870016, "Total num played games": 3456, "Total num trained steps": 6272, "Timestamp in ms": 1700741047456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8518518518518519, "Avg loss": 0.6827762289904058, "Avg value loss": 0.5236318793613464, "Avg policy loss": 0.15914435079321265, "Total num played games": 3456, "Total num trained steps": 6400, "Timestamp in ms": 1700741112417, "logtype": "training_step"}
{"Total num played games": 3564, "Total num trained steps": 6526, "Timestamp in ms": 1700741296269, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.451757812500002}
{"Ratio train steps to played games": 1.8316498316498318, "Avg loss": 0.8866432316135615, "Avg value loss": 0.7362555880099535, "Avg policy loss": 0.1503876395872794, "Total num played games": 3564, "Total num trained steps": 6528, "Timestamp in ms": 1700741297443, "logtype": "training_step"}
{"Avg objective": 20.1603125, "Games time in secs": 275.3467497844249, "Avg game time in secs": 12.344018765550572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "reached_maximum_moves": 0.02, "played_steps": 0.33}, "Total num played games": 3584, "Total num trained steps": 6555, "Timestamp in ms": 1700741307221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8245614035087718, "Avg loss": 0.9012530366890132, "Avg value loss": 0.7634666659869254, "Avg policy loss": 0.1377863686066121, "Total num played games": 3648, "Total num trained steps": 6656, "Timestamp in ms": 1700741355241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.853551912568306, "Avg loss": 0.7203000148292631, "Avg value loss": 0.5824359215330333, "Avg policy loss": 0.13786408939631656, "Total num played games": 3660, "Total num trained steps": 6784, "Timestamp in ms": 1700741418467, "logtype": "training_step"}
{"Avg objective": 19.995, "Games time in secs": 134.77827200852334, "Avg game time in secs": 13.998476763284998, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "reached_maximum_moves": 0.04, "played_steps": 0.59, "agent_stopped_more": 0.01}, "Total num played games": 3712, "Total num trained steps": 6840, "Timestamp in ms": 1700741442000, "logtype": "played_game"}
{"Ratio train steps to played games": 1.840969632392115, "Avg loss": 0.971349966712296, "Avg value loss": 0.8390520513057709, "Avg policy loss": 0.13229791284538805, "Total num played games": 3754, "Total num trained steps": 6912, "Timestamp in ms": 1700741476741, "logtype": "training_step"}
{"Avg objective": 19.932421875, "Games time in secs": 97.36613462679088, "Avg game time in secs": 14.930737393835443, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.94, "agent_stopped_more": 0.02, "played_steps": 0.79, "reached_maximum_moves": 0.04}, "Total num played games": 3840, "Total num trained steps": 7031, "Timestamp in ms": 1700741539366, "logtype": "played_game"}
{"Total num played games": 3864, "Total num trained steps": 7031, "Timestamp in ms": 1700741689473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.580234375}
{"Ratio train steps to played games": 1.821687370600414, "Avg loss": 0.8019426655955613, "Avg value loss": 0.6735090874135494, "Avg policy loss": 0.12843358085956424, "Total num played games": 3864, "Total num trained steps": 7040, "Timestamp in ms": 1700741694335, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8116784630940344, "Avg loss": 1.2958376100286841, "Avg value loss": 1.1786731933243573, "Avg policy loss": 0.11716439679730684, "Total num played games": 3956, "Total num trained steps": 7168, "Timestamp in ms": 1700741755898, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8421717171717171, "Avg loss": 0.5717966048978269, "Avg value loss": 0.457994140451774, "Avg policy loss": 0.1138024662504904, "Total num played games": 3960, "Total num trained steps": 7296, "Timestamp in ms": 1700741818059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8747474747474748, "Avg loss": 0.5517725623212755, "Avg value loss": 0.4287514854222536, "Avg policy loss": 0.1230210778885521, "Total num played games": 3960, "Total num trained steps": 7424, "Timestamp in ms": 1700741879863, "logtype": "training_step"}
{"Avg objective": 20.789687500000003, "Games time in secs": 343.4754019808024, "Avg game time in secs": 14.031942175352015, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.02, "played_steps": 0.6, "reached_maximum_moves": 0.03}, "Total num played games": 3968, "Total num trained steps": 7432, "Timestamp in ms": 1700741882842, "logtype": "played_game"}
{"Total num played games": 4076, "Total num trained steps": 7531, "Timestamp in ms": 1700742086788, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.5669921875}
{"Ratio train steps to played games": 1.8491674828599411, "Avg loss": 0.7175601159688085, "Avg value loss": 0.6069595436565578, "Avg policy loss": 0.11060057260328904, "Total num played games": 4082, "Total num trained steps": 7552, "Timestamp in ms": 1700742096803, "logtype": "training_step"}
{"Avg objective": 19.565390625000003, "Games time in secs": 214.58579773642123, "Avg game time in secs": 12.511559343634872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.97, "agent_stopped_more": 0.01, "played_steps": 0.36, "reached_maximum_moves": 0.02}, "Total num played games": 4096, "Total num trained steps": 7553, "Timestamp in ms": 1700742097428, "logtype": "played_game"}
{"Ratio train steps to played games": 1.843254920787326, "Avg loss": 0.7669542701914907, "Avg value loss": 0.6618861244060099, "Avg policy loss": 0.10506813979009166, "Total num played games": 4166, "Total num trained steps": 7680, "Timestamp in ms": 1700742157549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8715244487056568, "Avg loss": 0.5001203438732773, "Avg value loss": 0.3901559015503153, "Avg policy loss": 0.10996444127522409, "Total num played games": 4172, "Total num trained steps": 7808, "Timestamp in ms": 1700742219424, "logtype": "training_step"}
{"Avg objective": 20.534843749999997, "Games time in secs": 144.9978162869811, "Avg game time in secs": 13.688611804318498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.93, "agent_stopped_more": 0.03, "played_steps": 0.61, "reached_maximum_moves": 0.04}, "Total num played games": 4224, "Total num trained steps": 7861, "Timestamp in ms": 1700742242426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8565746373420684, "Avg loss": 0.8882045992650092, "Avg value loss": 0.7784004407003522, "Avg policy loss": 0.10980416019447148, "Total num played games": 4274, "Total num trained steps": 7936, "Timestamp in ms": 1700742276319, "logtype": "training_step"}
{"Total num played games": 4282, "Total num trained steps": 8033, "Timestamp in ms": 1700742466294, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6151953125}
{"Avg objective": 21.63046875, "Games time in secs": 235.7561661861837, "Avg game time in secs": 11.787976039166097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.03, "played_steps": 0.38, "reached_maximum_moves": 0.02}, "Total num played games": 4352, "Total num trained steps": 8061, "Timestamp in ms": 1700742478182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8469995419147962, "Avg loss": 0.5581064443103969, "Avg value loss": 0.44542600749991834, "Avg policy loss": 0.11268043535528705, "Total num played games": 4366, "Total num trained steps": 8064, "Timestamp in ms": 1700742479410, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8720292504570384, "Avg loss": 0.7114530706312507, "Avg value loss": 0.603959665633738, "Avg policy loss": 0.10749340400798246, "Total num played games": 4376, "Total num trained steps": 8192, "Timestamp in ms": 1700742541033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8652466367713005, "Avg loss": 0.7218831887003034, "Avg value loss": 0.6111787722911686, "Avg policy loss": 0.1107044123345986, "Total num played games": 4460, "Total num trained steps": 8320, "Timestamp in ms": 1700742596444, "logtype": "training_step"}
{"Avg objective": 20.249062499999997, "Games time in secs": 172.99682395160198, "Avg game time in secs": 14.118870436461293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "agent_stopped_more": 0.09, "played_steps": 1.05, "reached_maximum_moves": 0.05}, "Total num played games": 4480, "Total num trained steps": 8445, "Timestamp in ms": 1700742651179, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8815144766146994, "Avg loss": 0.5301010617986321, "Avg value loss": 0.41889382200315595, "Avg policy loss": 0.1112072411342524, "Total num played games": 4490, "Total num trained steps": 8448, "Timestamp in ms": 1700742652082, "logtype": "training_step"}
{"Total num played games": 4574, "Total num trained steps": 8533, "Timestamp in ms": 1700742767498, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.375078125}
{"Avg objective": 20.663984375000002, "Games time in secs": 125.97568428330123, "Avg game time in secs": 16.79524460392713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.83, "agent_stopped_more": 0.09, "played_steps": 1.52, "reached_maximum_moves": 0.08}, "Total num played games": 4608, "Total num trained steps": 8554, "Timestamp in ms": 1700742777155, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8443010752688171, "Avg loss": 0.9333260841667652, "Avg value loss": 0.8113898555748165, "Avg policy loss": 0.12193622684571892, "Total num played games": 4650, "Total num trained steps": 8576, "Timestamp in ms": 1700742786785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8675965665236052, "Avg loss": 0.6992122074589133, "Avg value loss": 0.5641441089101136, "Avg policy loss": 0.13506809854879975, "Total num played games": 4660, "Total num trained steps": 8704, "Timestamp in ms": 1700742846980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.891220556745182, "Avg loss": 0.5888364624697715, "Avg value loss": 0.4507775267120451, "Avg policy loss": 0.13805892976233736, "Total num played games": 4670, "Total num trained steps": 8832, "Timestamp in ms": 1700742910399, "logtype": "training_step"}
{"Avg objective": 20.8159375, "Games time in secs": 140.64660560525954, "Avg game time in secs": 13.566096992784878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0078125, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.11, "played_steps": 1.08, "reached_maximum_moves": 0.05}, "Total num played games": 4736, "Total num trained steps": 8852, "Timestamp in ms": 1700742917801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.881352372952541, "Avg loss": 0.767289100214839, "Avg value loss": 0.6170078578870744, "Avg policy loss": 0.15028123644879088, "Total num played games": 4762, "Total num trained steps": 8960, "Timestamp in ms": 1700742969755, "logtype": "training_step"}
{"Total num played games": 4854, "Total num trained steps": 9034, "Timestamp in ms": 1700743043717, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.871875000000003}
{"Avg objective": 21.53140625, "Games time in secs": 132.84095431677997, "Avg game time in secs": 10.929778156292741, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.13, "played_steps": 0.74, "reached_maximum_moves": 0.03}, "Total num played games": 4864, "Total num trained steps": 9051, "Timestamp in ms": 1700743050643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.843952922077922, "Avg loss": 0.9543708665296435, "Avg value loss": 0.7954968760022894, "Avg policy loss": 0.15887398325139657, "Total num played games": 4928, "Total num trained steps": 9088, "Timestamp in ms": 1700743066709, "logtype": "training_step"}
{"Ratio train steps to played games": 1.862368633791431, "Avg loss": 0.690441008657217, "Avg value loss": 0.5119492530357093, "Avg policy loss": 0.17849176027812064, "Total num played games": 4948, "Total num trained steps": 9216, "Timestamp in ms": 1700743126410, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8874747474747475, "Avg loss": 0.5492534413933754, "Avg value loss": 0.37254492728970945, "Avg policy loss": 0.17670850962167606, "Total num played games": 4950, "Total num trained steps": 9344, "Timestamp in ms": 1700743188825, "logtype": "training_step"}
{"Avg objective": 19.579296875, "Games time in secs": 167.26221474260092, "Avg game time in secs": 15.724344854068477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.1, "played_steps": 1.32, "agent_stopped_0": 0.84, "reached_maximum_moves": 0.06}, "Total num played games": 4992, "Total num trained steps": 9408, "Timestamp in ms": 1700743217905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8776764472640761, "Avg loss": 0.8442053974140435, "Avg value loss": 0.6656971409684047, "Avg policy loss": 0.17850825481582433, "Total num played games": 5044, "Total num trained steps": 9472, "Timestamp in ms": 1700743248237, "logtype": "training_step"}
{"Total num played games": 5052, "Total num trained steps": 9535, "Timestamp in ms": 1700743313829, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.96453125}
{"Avg objective": 21.187499999999996, "Games time in secs": 105.88790871575475, "Avg game time in secs": 9.91326182235207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9453125, "Avg reasons for ending game": {"agent_stopped_0": 0.85, "agent_stopped_more": 0.12, "played_steps": 0.61, "reached_maximum_moves": 0.02}, "Total num played games": 5120, "Total num trained steps": 9557, "Timestamp in ms": 1700743323793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8655266226195102, "Avg loss": 0.8963591014035046, "Avg value loss": 0.6960861452389508, "Avg policy loss": 0.20027296448824927, "Total num played games": 5146, "Total num trained steps": 9600, "Timestamp in ms": 1700743344656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8894716394716395, "Avg loss": 0.6719792482908815, "Avg value loss": 0.4474053313024342, "Avg policy loss": 0.22457391256466508, "Total num played games": 5148, "Total num trained steps": 9728, "Timestamp in ms": 1700743407187, "logtype": "training_step"}
{"Ratio train steps to played games": 1.879481311975591, "Avg loss": 0.8717672866769135, "Avg value loss": 0.6519689239794388, "Avg policy loss": 0.21979835152160376, "Total num played games": 5244, "Total num trained steps": 9856, "Timestamp in ms": 1700743465108, "logtype": "training_step"}
{"Avg objective": 20.618828124999993, "Games time in secs": 163.0809694081545, "Avg game time in secs": 9.442812540946761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.23, "played_steps": 0.59, "reached_maximum_moves": 0.01}, "Total num played games": 5248, "Total num trained steps": 9900, "Timestamp in ms": 1700743486874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9000761324704987, "Avg loss": 0.6582233109511435, "Avg value loss": 0.42438024387229234, "Avg policy loss": 0.23384306684602052, "Total num played games": 5254, "Total num trained steps": 9984, "Timestamp in ms": 1700743528203, "logtype": "training_step"}
{"Total num played games": 5360, "Total num trained steps": 10039, "Timestamp in ms": 1700743626082, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.58828125}
{"Avg objective": 20.92640625, "Games time in secs": 145.42325575649738, "Avg game time in secs": 10.101126829380519, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"reached_maximum_moves": 0.03, "played_steps": 0.75, "agent_stopped_more": 0.08, "agent_stopped_0": 0.89}, "Total num played games": 5376, "Total num trained steps": 10052, "Timestamp in ms": 1700743632298, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8545487894350696, "Avg loss": 1.0653621363453567, "Avg value loss": 0.830143295112066, "Avg policy loss": 0.23521884065121412, "Total num played games": 5452, "Total num trained steps": 10112, "Timestamp in ms": 1700743659786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8768328445747802, "Avg loss": 0.6237690825946629, "Avg value loss": 0.3857440195279196, "Avg policy loss": 0.2380250614369288, "Total num played games": 5456, "Total num trained steps": 10240, "Timestamp in ms": 1700743723445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.900293255131965, "Avg loss": 0.5675610976759344, "Avg value loss": 0.3231464499840513, "Avg policy loss": 0.24441465025302023, "Total num played games": 5456, "Total num trained steps": 10368, "Timestamp in ms": 1700743785868, "logtype": "training_step"}
{"Avg objective": 21.073984375, "Games time in secs": 176.46426144987345, "Avg game time in secs": 7.540610887779621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.32}, "Total num played games": 5504, "Total num trained steps": 10420, "Timestamp in ms": 1700743808762, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8889488840892728, "Avg loss": 0.8291057946626097, "Avg value loss": 0.5837543776724488, "Avg policy loss": 0.24535141757223755, "Total num played games": 5556, "Total num trained steps": 10496, "Timestamp in ms": 1700743844273, "logtype": "training_step"}
{"Total num played games": 5560, "Total num trained steps": 10540, "Timestamp in ms": 1700743941720, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.180078125}
{"Avg objective": 20.336328125, "Games time in secs": 143.2535722143948, "Avg game time in secs": 8.669663752007182, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.55}, "Total num played games": 5632, "Total num trained steps": 10564, "Timestamp in ms": 1700743952016, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8783592644978784, "Avg loss": 0.9675820688717067, "Avg value loss": 0.7022726347204298, "Avg policy loss": 0.26530943706166, "Total num played games": 5656, "Total num trained steps": 10624, "Timestamp in ms": 1700743980766, "logtype": "training_step"}
{"Ratio train steps to played games": 1.900990099009901, "Avg loss": 0.6556489288341254, "Avg value loss": 0.3926920099183917, "Avg policy loss": 0.2629569177515805, "Total num played games": 5656, "Total num trained steps": 10752, "Timestamp in ms": 1700744044070, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8893713094824591, "Avg loss": 0.8684706923086196, "Avg value loss": 0.6056497993413359, "Avg policy loss": 0.26282089413143694, "Total num played games": 5758, "Total num trained steps": 10880, "Timestamp in ms": 1700744103793, "logtype": "training_step"}
{"Avg objective": 20.440312499999994, "Games time in secs": 177.75147579982877, "Avg game time in secs": 8.313507988714264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.23, "played_steps": 0.46, "agent_stopped_0": 0.77}, "Total num played games": 5760, "Total num trained steps": 10933, "Timestamp in ms": 1700744129767, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9102742103436308, "Avg loss": 0.6713526146486402, "Avg value loss": 0.40420423715841025, "Avg policy loss": 0.2671483758604154, "Total num played games": 5762, "Total num trained steps": 11008, "Timestamp in ms": 1700744166064, "logtype": "training_step"}
{"Total num played games": 5862, "Total num trained steps": 11041, "Timestamp in ms": 1700744243812, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.185000000000002}
{"Avg objective": 21.807656249999994, "Games time in secs": 120.2776279002428, "Avg game time in secs": 7.911395836476004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"reached_maximum_moves": 0.01, "played_steps": 0.45, "agent_stopped_0": 0.81, "agent_stopped_more": 0.18}, "Total num played games": 5888, "Total num trained steps": 11056, "Timestamp in ms": 1700744250045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8701713134027544, "Avg loss": 1.4990934059023857, "Avg value loss": 1.210647720261477, "Avg policy loss": 0.2884456650353968, "Total num played games": 5954, "Total num trained steps": 11136, "Timestamp in ms": 1700744288285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8905673044645854, "Avg loss": 0.69208940025419, "Avg value loss": 0.39893311727792025, "Avg policy loss": 0.2931562807643786, "Total num played games": 5958, "Total num trained steps": 11264, "Timestamp in ms": 1700744349804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9120510238335011, "Avg loss": 0.6023848021868616, "Avg value loss": 0.31938194669783115, "Avg policy loss": 0.283002857118845, "Total num played games": 5958, "Total num trained steps": 11392, "Timestamp in ms": 1700744414734, "logtype": "training_step"}
{"Avg objective": 21.177812499999998, "Games time in secs": 179.05172074213624, "Avg game time in secs": 9.217654974825564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.24, "played_steps": 0.67, "reached_maximum_moves": 0.02}, "Total num played games": 6016, "Total num trained steps": 11426, "Timestamp in ms": 1700744429097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9020805812417436, "Avg loss": 0.9645990584976971, "Avg value loss": 0.6701173770707101, "Avg policy loss": 0.29448167979717255, "Total num played games": 6056, "Total num trained steps": 11520, "Timestamp in ms": 1700744472966, "logtype": "training_step"}
{"Total num played games": 6062, "Total num trained steps": 11541, "Timestamp in ms": 1700744554148, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.519687500000003}
{"Avg objective": 21.555546874999997, "Games time in secs": 135.44572871364653, "Avg game time in secs": 8.021596615682938, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.24, "played_steps": 0.63, "reached_maximum_moves": 0.02}, "Total num played games": 6144, "Total num trained steps": 11565, "Timestamp in ms": 1700744564543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8925901852453688, "Avg loss": 1.0904762940481305, "Avg value loss": 0.7871927368687466, "Avg policy loss": 0.3032835585763678, "Total num played games": 6154, "Total num trained steps": 11648, "Timestamp in ms": 1700744603641, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9123091912958752, "Avg loss": 0.6397835912648588, "Avg value loss": 0.34650857793167233, "Avg policy loss": 0.29327501403167844, "Total num played games": 6158, "Total num trained steps": 11776, "Timestamp in ms": 1700744666221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9020453819111538, "Avg loss": 0.9522371320053935, "Avg value loss": 0.6561904770787805, "Avg policy loss": 0.29604665213264525, "Total num played games": 6258, "Total num trained steps": 11904, "Timestamp in ms": 1700744727027, "logtype": "training_step"}
{"Avg objective": 21.879453124999994, "Games time in secs": 218.75423101335764, "Avg game time in secs": 7.963927688906551, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.62, "reached_maximum_moves": 0.01}, "Total num played games": 6272, "Total num trained steps": 12020, "Timestamp in ms": 1700744783297, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8994316387748658, "Avg loss": 0.7166956651490182, "Avg value loss": 0.4172744626412168, "Avg policy loss": 0.2994212039047852, "Total num played games": 6334, "Total num trained steps": 12032, "Timestamp in ms": 1700744788061, "logtype": "training_step"}
{"Total num played games": 6362, "Total num trained steps": 12044, "Timestamp in ms": 1700744859190, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2764453125}
{"Avg objective": 21.274999999999995, "Games time in secs": 82.07589751109481, "Avg game time in secs": 6.282343391110771, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.4}, "Total num played games": 6400, "Total num trained steps": 12058, "Timestamp in ms": 1700744865373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8827810467637038, "Avg loss": 1.1916267895139754, "Avg value loss": 0.8830739569384605, "Avg policy loss": 0.30855283536948264, "Total num played games": 6458, "Total num trained steps": 12160, "Timestamp in ms": 1700744914881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9026014245896563, "Avg loss": 0.6205891084391624, "Avg value loss": 0.33044885471463203, "Avg policy loss": 0.29014025814831257, "Total num played games": 6458, "Total num trained steps": 12288, "Timestamp in ms": 1700744978618, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9207920792079207, "Avg loss": 0.5289835496805608, "Avg value loss": 0.25495106808375567, "Avg policy loss": 0.27403248008340597, "Total num played games": 6464, "Total num trained steps": 12416, "Timestamp in ms": 1700745040398, "logtype": "training_step"}
{"Avg objective": 21.211562499999996, "Games time in secs": 177.97163050994277, "Avg game time in secs": 5.79800066378084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.19, "played_steps": 0.25}, "Total num played games": 6528, "Total num trained steps": 12423, "Timestamp in ms": 1700745043345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9108775137111518, "Avg loss": 1.0112793957814574, "Avg value loss": 0.7197589854476973, "Avg policy loss": 0.29152041557244956, "Total num played games": 6564, "Total num trained steps": 12544, "Timestamp in ms": 1700745103213, "logtype": "training_step"}
{"Total num played games": 6564, "Total num trained steps": 12545, "Timestamp in ms": 1700745169765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.151640625000002}
{"Avg objective": 20.895312499999996, "Games time in secs": 145.02776589989662, "Avg game time in secs": 6.412429069940117, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.41, "agent_stopped_0": 0.7}, "Total num played games": 6656, "Total num trained steps": 12587, "Timestamp in ms": 1700745188373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9027027027027028, "Avg loss": 0.9716543578542769, "Avg value loss": 0.6762827157508582, "Avg policy loss": 0.29537163383793086, "Total num played games": 6660, "Total num trained steps": 12672, "Timestamp in ms": 1700745229979, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9217717717717717, "Avg loss": 0.609454303747043, "Avg value loss": 0.3280343859223649, "Avg policy loss": 0.2814199198037386, "Total num played games": 6660, "Total num trained steps": 12800, "Timestamp in ms": 1700745291985, "logtype": "training_step"}
{"Ratio train steps to played games": 1.911712511091393, "Avg loss": 0.9917526675853878, "Avg value loss": 0.700420536333695, "Avg policy loss": 0.29133213439490646, "Total num played games": 6762, "Total num trained steps": 12928, "Timestamp in ms": 1700745350907, "logtype": "training_step"}
{"Avg objective": 21.415546874999993, "Games time in secs": 208.3740438800305, "Avg game time in secs": 6.333870367336203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.48, "agent_stopped_0": 0.71}, "Total num played games": 6784, "Total num trained steps": 13024, "Timestamp in ms": 1700745396747, "logtype": "played_game"}
{"Total num played games": 6864, "Total num trained steps": 13048, "Timestamp in ms": 1700745474281, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.076171875000004}
{"Ratio train steps to played games": 1.9019522144522145, "Avg loss": 0.9365227359812707, "Avg value loss": 0.654332471662201, "Avg policy loss": 0.28219028073363006, "Total num played games": 6864, "Total num trained steps": 13056, "Timestamp in ms": 1700745478037, "logtype": "training_step"}
{"Avg objective": 21.01249999999999, "Games time in secs": 85.29672171920538, "Avg game time in secs": 5.440686364410794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.8, "agent_stopped_more": 0.2, "played_steps": 0.23}, "Total num played games": 6912, "Total num trained steps": 13067, "Timestamp in ms": 1700745482044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8941091954022988, "Avg loss": 1.0327047579921782, "Avg value loss": 0.7198700252920389, "Avg policy loss": 0.31283474795054644, "Total num played games": 6960, "Total num trained steps": 13184, "Timestamp in ms": 1700745539577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9125, "Avg loss": 0.5870491557288915, "Avg value loss": 0.2944172475254163, "Avg policy loss": 0.29263191076461226, "Total num played games": 6960, "Total num trained steps": 13312, "Timestamp in ms": 1700745604906, "logtype": "training_step"}
{"Avg objective": 21.922656249999992, "Games time in secs": 183.02911573462188, "Avg game time in secs": 6.15866500249831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 7040, "Total num trained steps": 13431, "Timestamp in ms": 1700745665073, "logtype": "played_game"}
{"Ratio train steps to played games": 1.90530195633683, "Avg loss": 0.8272377154789865, "Avg value loss": 0.5440138960257173, "Avg policy loss": 0.28322382213082165, "Total num played games": 7054, "Total num trained steps": 13440, "Timestamp in ms": 1700745669861, "logtype": "training_step"}
{"Total num played games": 7060, "Total num trained steps": 13550, "Timestamp in ms": 1700745786017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.7659765625}
{"Ratio train steps to played games": 1.9054775280898877, "Avg loss": 0.9760020263493061, "Avg value loss": 0.6781230615451932, "Avg policy loss": 0.2978789614280686, "Total num played games": 7120, "Total num trained steps": 13568, "Timestamp in ms": 1700745794753, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9139183901621017, "Avg loss": 0.8359893229790032, "Avg value loss": 0.5338788054650649, "Avg policy loss": 0.3021105247316882, "Total num played games": 7156, "Total num trained steps": 13696, "Timestamp in ms": 1700745858883, "logtype": "training_step"}
{"Avg objective": 20.692187499999992, "Games time in secs": 247.3084517326206, "Avg game time in secs": 6.979654591981671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.3, "played_steps": 0.6, "reached_maximum_moves": 0.02}, "Total num played games": 7168, "Total num trained steps": 13811, "Timestamp in ms": 1700745912382, "logtype": "played_game"}
{"Ratio train steps to played games": 1.909919867366676, "Avg loss": 0.6254670075140893, "Avg value loss": 0.34375198814086616, "Avg policy loss": 0.2817150306655094, "Total num played games": 7238, "Total num trained steps": 13824, "Timestamp in ms": 1700745917252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9222926426012676, "Avg loss": 0.8544231080450118, "Avg value loss": 0.5427658429834992, "Avg policy loss": 0.3116572655271739, "Total num played games": 7258, "Total num trained steps": 13952, "Timestamp in ms": 1700745979281, "logtype": "training_step"}
{"Avg objective": 22.66999999999999, "Games time in secs": 97.38122848793864, "Avg game time in secs": 5.1216652438452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.38}, "Total num played games": 7296, "Total num trained steps": 14016, "Timestamp in ms": 1700746009763, "logtype": "played_game"}
{"Total num played games": 7356, "Total num trained steps": 14051, "Timestamp in ms": 1700746089123, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.370234375000003}
{"Avg objective": 21.799609374999996, "Games time in secs": 87.89118419773877, "Avg game time in secs": 5.631556994660059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.44}, "Total num played games": 7424, "Total num trained steps": 14070, "Timestamp in ms": 1700746097655, "logtype": "played_game"}
{"Ratio train steps to played games": 1.891456206340677, "Avg loss": 1.3082880163565278, "Avg value loss": 1.0029744042549282, "Avg policy loss": 0.30531360453460366, "Total num played games": 7444, "Total num trained steps": 14080, "Timestamp in ms": 1700746101981, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9066022544283414, "Avg loss": 1.0447889659553766, "Avg value loss": 0.7195930478628725, "Avg policy loss": 0.32519592565950006, "Total num played games": 7452, "Total num trained steps": 14208, "Timestamp in ms": 1700746164143, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9236446591519056, "Avg loss": 0.6326858759857714, "Avg value loss": 0.31770748004782945, "Avg policy loss": 0.31497839326038957, "Total num played games": 7452, "Total num trained steps": 14336, "Timestamp in ms": 1700746227211, "logtype": "training_step"}
{"Avg objective": 20.99351562499999, "Games time in secs": 173.86630787327886, "Avg game time in secs": 5.774621144111734, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.55, "agent_stopped_0": 0.6}, "Total num played games": 7552, "Total num trained steps": 14428, "Timestamp in ms": 1700746271521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9152542372881356, "Avg loss": 0.9463973108213395, "Avg value loss": 0.6495710373856127, "Avg policy loss": 0.2968262785580009, "Total num played games": 7552, "Total num trained steps": 14464, "Timestamp in ms": 1700746287617, "logtype": "training_step"}
{"Total num played games": 7552, "Total num trained steps": 14551, "Timestamp in ms": 1700746365671, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.758046875}
{"Ratio train steps to played games": 1.9078190376569037, "Avg loss": 0.9398980429396033, "Avg value loss": 0.6451035827631131, "Avg policy loss": 0.2947944563347846, "Total num played games": 7648, "Total num trained steps": 14592, "Timestamp in ms": 1700746384196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.924555439330544, "Avg loss": 0.7224590161349624, "Avg value loss": 0.43210735730826855, "Avg policy loss": 0.29035165754612535, "Total num played games": 7648, "Total num trained steps": 14720, "Timestamp in ms": 1700746445853, "logtype": "training_step"}
{"Avg objective": 22.16249999999999, "Games time in secs": 206.6894493419677, "Avg game time in secs": 4.208064250764437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.25}, "Total num played games": 7680, "Total num trained steps": 14796, "Timestamp in ms": 1700746478211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9158709677419354, "Avg loss": 0.8391206716187298, "Avg value loss": 0.5586220704717562, "Avg policy loss": 0.28049860382452607, "Total num played games": 7750, "Total num trained steps": 14848, "Timestamp in ms": 1700746501385, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9323870967741936, "Avg loss": 0.6101775076240301, "Avg value loss": 0.32410077715758234, "Avg policy loss": 0.2860767289530486, "Total num played games": 7750, "Total num trained steps": 14976, "Timestamp in ms": 1700746560400, "logtype": "training_step"}
{"Avg objective": 22.58515624999999, "Games time in secs": 94.10212520696223, "Avg game time in secs": 4.818235988394008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.46}, "Total num played games": 7808, "Total num trained steps": 15006, "Timestamp in ms": 1700746572313, "logtype": "played_game"}
{"Total num played games": 7850, "Total num trained steps": 15051, "Timestamp in ms": 1700746645717, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.372421875000004}
{"Avg objective": 20.73257812499999, "Games time in secs": 81.69981513172388, "Avg game time in secs": 4.790454719972331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.48}, "Total num played games": 7936, "Total num trained steps": 15071, "Timestamp in ms": 1700746654013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9011832829808661, "Avg loss": 1.3409149395301938, "Avg value loss": 1.0364812158513814, "Avg policy loss": 0.30443373252637684, "Total num played games": 7944, "Total num trained steps": 15104, "Timestamp in ms": 1700746668865, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9168134910646866, "Avg loss": 0.74106813268736, "Avg value loss": 0.4257372213760391, "Avg policy loss": 0.3153309094486758, "Total num played games": 7946, "Total num trained steps": 15232, "Timestamp in ms": 1700746728615, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9330480745028946, "Avg loss": 0.5473547242581844, "Avg value loss": 0.2599034596933052, "Avg policy loss": 0.287451267009601, "Total num played games": 7946, "Total num trained steps": 15360, "Timestamp in ms": 1700746786791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9254102436598708, "Avg loss": 0.9068761239759624, "Avg value loss": 0.6101859562331811, "Avg policy loss": 0.2966901750769466, "Total num played games": 8044, "Total num trained steps": 15488, "Timestamp in ms": 1700746843788, "logtype": "training_step"}
{"Total num played games": 8044, "Total num trained steps": 15554, "Timestamp in ms": 1700746926349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.336523437500006}
{"Avg objective": 21.016093749999992, "Games time in secs": 275.9407197609544, "Avg game time in secs": 4.612693043090985, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.43, "agent_stopped_0": 0.72}, "Total num played games": 8064, "Total num trained steps": 15561, "Timestamp in ms": 1700746929954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9184275184275184, "Avg loss": 0.996828316245228, "Avg value loss": 0.7003114122198895, "Avg policy loss": 0.29651690542232245, "Total num played games": 8140, "Total num trained steps": 15616, "Timestamp in ms": 1700746953812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.934029484029484, "Avg loss": 0.6107328801881522, "Avg value loss": 0.32536613778211176, "Avg policy loss": 0.28536674135830253, "Total num played games": 8140, "Total num trained steps": 15744, "Timestamp in ms": 1700747011793, "logtype": "training_step"}
{"Avg objective": 21.094531249999992, "Games time in secs": 97.56937840394676, "Avg game time in secs": 4.076706536274287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.32}, "Total num played games": 8192, "Total num trained steps": 15781, "Timestamp in ms": 1700747027523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9262135922330097, "Avg loss": 0.9875914882868528, "Avg value loss": 0.6986932893050835, "Avg policy loss": 0.2888981973519549, "Total num played games": 8240, "Total num trained steps": 15872, "Timestamp in ms": 1700747068924, "logtype": "training_step"}
{"Avg objective": 21.501718749999995, "Games time in secs": 91.85807545110583, "Avg game time in secs": 4.52374616326415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.51}, "Total num played games": 8320, "Total num trained steps": 15984, "Timestamp in ms": 1700747119381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9178853991848477, "Avg loss": 0.931911536725238, "Avg value loss": 0.6480202303500846, "Avg policy loss": 0.283891310216859, "Total num played games": 8342, "Total num trained steps": 16000, "Timestamp in ms": 1700747126599, "logtype": "training_step"}
{"Total num played games": 8342, "Total num trained steps": 16054, "Timestamp in ms": 1700747203990, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7907421875}
{"Ratio train steps to played games": 1.911234889784309, "Avg loss": 1.1292319386266172, "Avg value loss": 0.8191972440108657, "Avg policy loss": 0.3100346925202757, "Total num played games": 8438, "Total num trained steps": 16128, "Timestamp in ms": 1700747239142, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9265228727186536, "Avg loss": 0.6209678102750331, "Avg value loss": 0.3174215513281524, "Avg policy loss": 0.30354626139160246, "Total num played games": 8438, "Total num trained steps": 16256, "Timestamp in ms": 1700747300152, "logtype": "training_step"}
{"Avg objective": 22.177343749999995, "Games time in secs": 236.23153091035783, "Avg game time in secs": 4.29480639329995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.48}, "Total num played games": 8448, "Total num trained steps": 16372, "Timestamp in ms": 1700747355613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9215341308937368, "Avg loss": 0.7143589337356389, "Avg value loss": 0.4331906521692872, "Avg policy loss": 0.28116827411577106, "Total num played games": 8526, "Total num trained steps": 16384, "Timestamp in ms": 1700747360085, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9339423752635279, "Avg loss": 1.1749471579678357, "Avg value loss": 0.871473116800189, "Avg policy loss": 0.30347403220366687, "Total num played games": 8538, "Total num trained steps": 16512, "Timestamp in ms": 1700747419292, "logtype": "training_step"}
{"Total num played games": 8538, "Total num trained steps": 16556, "Timestamp in ms": 1700747470184, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.740273437500004}
{"Avg objective": 22.31171874999999, "Games time in secs": 118.3124798387289, "Avg game time in secs": 3.5403298117016675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.31}, "Total num played games": 8576, "Total num trained steps": 16564, "Timestamp in ms": 1700747473926, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9271484827426453, "Avg loss": 0.824016627157107, "Avg value loss": 0.5348487145965919, "Avg policy loss": 0.28916791058145463, "Total num played games": 8634, "Total num trained steps": 16640, "Timestamp in ms": 1700747508540, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9340253748558247, "Avg loss": 0.5740491684991866, "Avg value loss": 0.302105353330262, "Avg policy loss": 0.2719438171479851, "Total num played games": 8668, "Total num trained steps": 16768, "Timestamp in ms": 1700747567133, "logtype": "training_step"}
{"Avg objective": 21.05624999999999, "Games time in secs": 94.71550345607102, "Avg game time in secs": 3.411895425320836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 8704, "Total num trained steps": 16771, "Timestamp in ms": 1700747568641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.934951901053596, "Avg loss": 1.0344590218737721, "Avg value loss": 0.7430699543328956, "Avg policy loss": 0.29138905880972743, "Total num played games": 8732, "Total num trained steps": 16896, "Timestamp in ms": 1700747626612, "logtype": "training_step"}
{"Avg objective": 21.13984374999999, "Games time in secs": 94.33934962376952, "Avg game time in secs": 3.962526481365785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.46}, "Total num played games": 8832, "Total num trained steps": 16977, "Timestamp in ms": 1700747662981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9265504753282028, "Avg loss": 0.7724865113850683, "Avg value loss": 0.48809741204604506, "Avg policy loss": 0.28438909817487, "Total num played games": 8836, "Total num trained steps": 17024, "Timestamp in ms": 1700747685249, "logtype": "training_step"}
{"Total num played games": 8836, "Total num trained steps": 17059, "Timestamp in ms": 1700747747040, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.017460937500005}
{"Ratio train steps to played games": 1.9201746529332737, "Avg loss": 0.8859326138626784, "Avg value loss": 0.5849296294618398, "Avg policy loss": 0.3010029844008386, "Total num played games": 8932, "Total num trained steps": 17152, "Timestamp in ms": 1700747788564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9346171070309002, "Avg loss": 0.545553190400824, "Avg value loss": 0.2635043798945844, "Avg policy loss": 0.28204881155397743, "Total num played games": 8932, "Total num trained steps": 17280, "Timestamp in ms": 1700747849393, "logtype": "training_step"}
{"Avg objective": 20.884531249999988, "Games time in secs": 223.36015317961574, "Avg game time in secs": 3.420223585824715, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.4, "agent_stopped_0": 0.67}, "Total num played games": 8960, "Total num trained steps": 17357, "Timestamp in ms": 1700747886341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.927685492801772, "Avg loss": 0.865714154439047, "Avg value loss": 0.58284519193694, "Avg policy loss": 0.28286896809004247, "Total num played games": 9030, "Total num trained steps": 17408, "Timestamp in ms": 1700747910905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.941860465116279, "Avg loss": 0.5895386873744428, "Avg value loss": 0.30805219314061105, "Avg policy loss": 0.28148649691138417, "Total num played games": 9030, "Total num trained steps": 17536, "Timestamp in ms": 1700747971345, "logtype": "training_step"}
{"Avg objective": 21.349765624999993, "Games time in secs": 94.52890752628446, "Avg game time in secs": 3.1326060669962317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.36}, "Total num played games": 9088, "Total num trained steps": 17559, "Timestamp in ms": 1700747980871, "logtype": "played_game"}
{"Total num played games": 9128, "Total num trained steps": 17561, "Timestamp in ms": 1700748002801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.632695312500005}
{"Avg objective": 21.922656249999992, "Games time in secs": 29.330364665016532, "Avg game time in secs": 3.385086993817822, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 9216, "Total num trained steps": 17579, "Timestamp in ms": 1700748010201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9148959236773635, "Avg loss": 1.4381664041429758, "Avg value loss": 1.1235978592885658, "Avg policy loss": 0.3145685519557446, "Total num played games": 9224, "Total num trained steps": 17664, "Timestamp in ms": 1700748049638, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9288811795316565, "Avg loss": 0.6105660132598132, "Avg value loss": 0.3000703767174855, "Avg policy loss": 0.3104956343304366, "Total num played games": 9224, "Total num trained steps": 17792, "Timestamp in ms": 1700748108888, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9426496097137902, "Avg loss": 0.5143627866636962, "Avg value loss": 0.23401899845339358, "Avg policy loss": 0.28034379181917757, "Total num played games": 9224, "Total num trained steps": 17920, "Timestamp in ms": 1700748168502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.936065222055353, "Avg loss": 0.9742817946244031, "Avg value loss": 0.690649441909045, "Avg policy loss": 0.2836323572555557, "Total num played games": 9322, "Total num trained steps": 18048, "Timestamp in ms": 1700748228057, "logtype": "training_step"}
{"Total num played games": 9322, "Total num trained steps": 18061, "Timestamp in ms": 1700748256265, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4125}
{"Avg objective": 20.609921874999987, "Games time in secs": 249.14775019325316, "Avg game time in secs": 3.354671195615083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.39, "agent_stopped_0": 0.72}, "Total num played games": 9344, "Total num trained steps": 18068, "Timestamp in ms": 1700748259349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9298152473985983, "Avg loss": 1.000463584670797, "Avg value loss": 0.7200858318246901, "Avg policy loss": 0.2803777571534738, "Total num played games": 9418, "Total num trained steps": 18176, "Timestamp in ms": 1700748309625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9434062433637715, "Avg loss": 0.5119213804136962, "Avg value loss": 0.25580024090595543, "Avg policy loss": 0.256121139973402, "Total num played games": 9418, "Total num trained steps": 18304, "Timestamp in ms": 1700748370666, "logtype": "training_step"}
{"Avg objective": 21.282499999999995, "Games time in secs": 123.81858548335731, "Avg game time in secs": 2.6099228598031914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.19, "played_steps": 0.2}, "Total num played games": 9472, "Total num trained steps": 18334, "Timestamp in ms": 1700748383168, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9364362260979198, "Avg loss": 0.7755376559216529, "Avg value loss": 0.5130539080128074, "Avg policy loss": 0.262483753147535, "Total num played games": 9518, "Total num trained steps": 18432, "Timestamp in ms": 1700748430868, "logtype": "training_step"}
{"Avg objective": 22.16531249999999, "Games time in secs": 98.67302676476538, "Avg game time in secs": 3.3531856379122473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.41, "agent_stopped_0": 0.62}, "Total num played games": 9600, "Total num trained steps": 18539, "Timestamp in ms": 1700748481841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9300124792013311, "Avg loss": 0.863089838065207, "Avg value loss": 0.606575426645577, "Avg policy loss": 0.25651441130321473, "Total num played games": 9616, "Total num trained steps": 18560, "Timestamp in ms": 1700748491662, "logtype": "training_step"}
{"Total num played games": 9616, "Total num trained steps": 18562, "Timestamp in ms": 1700748516293, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.36140625}
{"Ratio train steps to played games": 1.9242174629324547, "Avg loss": 1.2856016412843019, "Avg value loss": 1.0018444280140102, "Avg policy loss": 0.2837572149001062, "Total num played games": 9712, "Total num trained steps": 18688, "Timestamp in ms": 1700748574529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9372940691927512, "Avg loss": 0.5557625575456768, "Avg value loss": 0.28813022561371326, "Avg policy loss": 0.2676323326304555, "Total num played games": 9712, "Total num trained steps": 18816, "Timestamp in ms": 1700748636441, "logtype": "training_step"}
{"Avg objective": 22.625312499999986, "Games time in secs": 201.67306582443416, "Avg game time in secs": 3.8707589912228286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.62, "agent_stopped_0": 0.55}, "Total num played games": 9728, "Total num trained steps": 18918, "Timestamp in ms": 1700748683514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9305951895637994, "Avg loss": 0.7700158469378948, "Avg value loss": 0.5242355206282809, "Avg policy loss": 0.24578032037243247, "Total num played games": 9812, "Total num trained steps": 18944, "Timestamp in ms": 1700748695520, "logtype": "training_step"}
{"Total num played games": 9812, "Total num trained steps": 19063, "Timestamp in ms": 1700748774449, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.898984375}
{"Ratio train steps to played games": 1.937715911400122, "Avg loss": 0.6166250938549638, "Avg value loss": 0.3553996334085241, "Avg policy loss": 0.2612254599807784, "Total num played games": 9838, "Total num trained steps": 19072, "Timestamp in ms": 1700748778143, "logtype": "training_step"}
{"Avg objective": 22.62312499999999, "Games time in secs": 94.95172588340938, "Avg game time in secs": 2.7985412637499394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.38}, "Total num played games": 9856, "Total num trained steps": 19072, "Timestamp in ms": 1700748778470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9378280177634235, "Avg loss": 0.9591376441530883, "Avg value loss": 0.6969392669852823, "Avg policy loss": 0.26219838752876967, "Total num played games": 9908, "Total num trained steps": 19200, "Timestamp in ms": 1700748836183, "logtype": "training_step"}
{"Avg objective": 20.604296874999996, "Games time in secs": 113.17906819283962, "Avg game time in secs": 2.9196604649623623, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 0.34, "agent_stopped_0": 0.7}, "Total num played games": 9984, "Total num trained steps": 19318, "Timestamp in ms": 1700748891649, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9312549960031975, "Avg loss": 0.6472573571372777, "Avg value loss": 0.39649030822329223, "Avg policy loss": 0.25076704821549356, "Total num played games": 10008, "Total num trained steps": 19328, "Timestamp in ms": 1700748896064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9439448441247003, "Avg loss": 0.6594913532026112, "Avg value loss": 0.4028268802212551, "Avg policy loss": 0.2566644741455093, "Total num played games": 10008, "Total num trained steps": 19456, "Timestamp in ms": 1700748954851, "logtype": "training_step"}
{"Total num played games": 10108, "Total num trained steps": 19564, "Timestamp in ms": 1700749025352, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1872265625}
{"Avg objective": 21.05648437499999, "Games time in secs": 135.74867387861013, "Avg game time in secs": 3.2082880898960866, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.52}, "Total num played games": 10112, "Total num trained steps": 19567, "Timestamp in ms": 1700749027398, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9195255832189766, "Avg loss": 1.0120191399473697, "Avg value loss": 0.7546334873186424, "Avg policy loss": 0.2573856571689248, "Total num played games": 10202, "Total num trained steps": 19584, "Timestamp in ms": 1700749034645, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9316934535476284, "Avg loss": 0.7517229216173291, "Avg value loss": 0.4767490263329819, "Avg policy loss": 0.2749738892307505, "Total num played games": 10204, "Total num trained steps": 19712, "Timestamp in ms": 1700749094997, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9442375539004313, "Avg loss": 0.4905803494621068, "Avg value loss": 0.23388208879623562, "Avg policy loss": 0.25669826311059296, "Total num played games": 10204, "Total num trained steps": 19840, "Timestamp in ms": 1700749156022, "logtype": "training_step"}
{"Avg objective": 22.198203124999996, "Games time in secs": 158.75873815454543, "Avg game time in secs": 2.607210046291584, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.35}, "Total num played games": 10240, "Total num trained steps": 19904, "Timestamp in ms": 1700749186157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9382644146767618, "Avg loss": 0.8991424331907183, "Avg value loss": 0.6472950355382636, "Avg policy loss": 0.25184739113319665, "Total num played games": 10302, "Total num trained steps": 19968, "Timestamp in ms": 1700749214785, "logtype": "training_step"}
{"Total num played games": 10302, "Total num trained steps": 20064, "Timestamp in ms": 1700749280507, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.164218750000003}
{"Avg objective": 20.820859374999987, "Games time in secs": 99.26996966265142, "Avg game time in secs": 2.8949742487748154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 10368, "Total num trained steps": 20073, "Timestamp in ms": 1700749285427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9325831890748222, "Avg loss": 0.6841872856020927, "Avg value loss": 0.4308701424160972, "Avg policy loss": 0.25331714330241084, "Total num played games": 10398, "Total num trained steps": 20096, "Timestamp in ms": 1700749295281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9449894210425083, "Avg loss": 0.6031658865977079, "Avg value loss": 0.34645400452427566, "Avg policy loss": 0.2567118783481419, "Total num played games": 10398, "Total num trained steps": 20224, "Timestamp in ms": 1700749356195, "logtype": "training_step"}
{"Avg objective": 20.71843749999999, "Games time in secs": 106.47824304178357, "Avg game time in secs": 3.172025977561134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.52, "agent_stopped_0": 0.57}, "Total num played games": 10496, "Total num trained steps": 20304, "Timestamp in ms": 1700749391906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9389291158536586, "Avg loss": 0.7623329046182334, "Avg value loss": 0.5039293688023463, "Avg policy loss": 0.2584035398904234, "Total num played games": 10496, "Total num trained steps": 20352, "Timestamp in ms": 1700749414017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.951124237804878, "Avg loss": 0.49624907737597823, "Avg value loss": 0.24326539621688426, "Avg policy loss": 0.2529836822068319, "Total num played games": 10496, "Total num trained steps": 20480, "Timestamp in ms": 1700749472211, "logtype": "training_step"}
{"Total num played games": 10594, "Total num trained steps": 20564, "Timestamp in ms": 1700749531545, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.274179687500002}
{"Avg objective": 21.93257812499999, "Games time in secs": 143.0954300556332, "Avg game time in secs": 2.712467869670945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 10624, "Total num trained steps": 20571, "Timestamp in ms": 1700749535001, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9277829747427502, "Avg loss": 1.2622033199295402, "Avg value loss": 0.9841882304754108, "Avg policy loss": 0.27801509213168174, "Total num played games": 10690, "Total num trained steps": 20608, "Timestamp in ms": 1700749551842, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9396632366697848, "Avg loss": 0.6172523743007332, "Avg value loss": 0.34077994560357183, "Avg policy loss": 0.2764724288135767, "Total num played games": 10690, "Total num trained steps": 20736, "Timestamp in ms": 1700749611098, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9516370439663238, "Avg loss": 0.449331869604066, "Avg value loss": 0.19905650056898594, "Avg policy loss": 0.2502753722947091, "Total num played games": 10690, "Total num trained steps": 20864, "Timestamp in ms": 1700749669809, "logtype": "training_step"}
{"Avg objective": 21.392578124999993, "Games time in secs": 140.62070310860872, "Avg game time in secs": 3.017020629515173, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.43}, "Total num played games": 10752, "Total num trained steps": 20879, "Timestamp in ms": 1700749675626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9458657767890248, "Avg loss": 0.80148462112993, "Avg value loss": 0.5394854780752212, "Avg policy loss": 0.2619991406099871, "Total num played games": 10788, "Total num trained steps": 20992, "Timestamp in ms": 1700749729324, "logtype": "training_step"}
{"Avg objective": 21.072734374999985, "Games time in secs": 94.04781787469983, "Avg game time in secs": 3.011817624763353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 10880, "Total num trained steps": 21067, "Timestamp in ms": 1700749769674, "logtype": "played_game"}
{"Total num played games": 10884, "Total num trained steps": 21067, "Timestamp in ms": 1700749793324, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.948164062500002}
{"Ratio train steps to played games": 1.9234972677595628, "Avg loss": 1.313524466007948, "Avg value loss": 1.049742535687983, "Avg policy loss": 0.26378191995900124, "Total num played games": 10980, "Total num trained steps": 21120, "Timestamp in ms": 1700749819260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.935063752276867, "Avg loss": 0.6261113716755062, "Avg value loss": 0.33952452009543777, "Avg policy loss": 0.2865868486696854, "Total num played games": 10980, "Total num trained steps": 21248, "Timestamp in ms": 1700749878781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9467213114754098, "Avg loss": 0.4633128405548632, "Avg value loss": 0.21379015676211566, "Avg policy loss": 0.24952268705237657, "Total num played games": 10980, "Total num trained steps": 21376, "Timestamp in ms": 1700749938560, "logtype": "training_step"}
{"Avg objective": 20.993749999999984, "Games time in secs": 205.93468678742647, "Avg game time in secs": 2.65970861070673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.4, "agent_stopped_0": 0.65}, "Total num played games": 11008, "Total num trained steps": 21454, "Timestamp in ms": 1700749975609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.941144610940603, "Avg loss": 0.7425251957029104, "Avg value loss": 0.4895744221867062, "Avg policy loss": 0.2529507636791095, "Total num played games": 11078, "Total num trained steps": 21504, "Timestamp in ms": 1700750000036, "logtype": "training_step"}
{"Total num played games": 11078, "Total num trained steps": 21567, "Timestamp in ms": 1700750069600, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3769921875}
{"Avg objective": 20.979765624999995, "Games time in secs": 97.66868851706386, "Avg game time in secs": 2.4437933327571955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 11136, "Total num trained steps": 21575, "Timestamp in ms": 1700750073278, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9358331841775551, "Avg loss": 0.7678635132033378, "Avg value loss": 0.49732750200200826, "Avg policy loss": 0.27053601352963597, "Total num played games": 11174, "Total num trained steps": 21632, "Timestamp in ms": 1700750099470, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9473778414175764, "Avg loss": 0.5112945754081011, "Avg value loss": 0.254712731402833, "Avg policy loss": 0.2565818402217701, "Total num played games": 11174, "Total num trained steps": 21760, "Timestamp in ms": 1700750160504, "logtype": "training_step"}
{"Avg objective": 21.46640624999999, "Games time in secs": 130.80506763607264, "Avg game time in secs": 2.9126083725568606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 11264, "Total num trained steps": 21850, "Timestamp in ms": 1700750204083, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9414582224587547, "Avg loss": 0.9453553752973676, "Avg value loss": 0.6898270152742043, "Avg policy loss": 0.2555283645633608, "Total num played games": 11274, "Total num trained steps": 21888, "Timestamp in ms": 1700750221496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9528117793152386, "Avg loss": 0.5746360409539193, "Avg value loss": 0.3056376908207312, "Avg policy loss": 0.2689983512973413, "Total num played games": 11274, "Total num trained steps": 22016, "Timestamp in ms": 1700750280809, "logtype": "training_step"}
{"Total num played games": 11376, "Total num trained steps": 22067, "Timestamp in ms": 1700750333353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2809375}
{"Avg objective": 22.05937499999998, "Games time in secs": 131.8372249621898, "Avg game time in secs": 2.7197421082964865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 11392, "Total num trained steps": 22072, "Timestamp in ms": 1700750335920, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9302649930264992, "Avg loss": 1.3323028152808547, "Avg value loss": 1.0341688428306952, "Avg policy loss": 0.2981339683756232, "Total num played games": 11472, "Total num trained steps": 22144, "Timestamp in ms": 1700750369432, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9414225941422594, "Avg loss": 0.5792200588621199, "Avg value loss": 0.2844971548765898, "Avg policy loss": 0.29472290293779224, "Total num played games": 11472, "Total num trained steps": 22272, "Timestamp in ms": 1700750431968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9524930264993026, "Avg loss": 0.47488420573063195, "Avg value loss": 0.20474600477609783, "Avg policy loss": 0.27013820223510265, "Total num played games": 11472, "Total num trained steps": 22400, "Timestamp in ms": 1700750498802, "logtype": "training_step"}
{"Avg objective": 21.65828124999999, "Games time in secs": 181.57708036713302, "Avg game time in secs": 2.5880943153897533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.43}, "Total num played games": 11520, "Total num trained steps": 22439, "Timestamp in ms": 1700750517498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.947104580812446, "Avg loss": 0.8354682144708931, "Avg value loss": 0.5445300952997059, "Avg policy loss": 0.29093812161590904, "Total num played games": 11570, "Total num trained steps": 22528, "Timestamp in ms": 1700750559271, "logtype": "training_step"}
{"Total num played games": 11570, "Total num trained steps": 22567, "Timestamp in ms": 1700750600313, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.657382812500003}
{"Avg objective": 21.094062499999993, "Games time in secs": 87.1200026422739, "Avg game time in secs": 2.668321492325049, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 11648, "Total num trained steps": 22577, "Timestamp in ms": 1700750604618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9420538316475227, "Avg loss": 0.8206833240110427, "Avg value loss": 0.5358939948491752, "Avg policy loss": 0.2847893264843151, "Total num played games": 11666, "Total num trained steps": 22656, "Timestamp in ms": 1700750641661, "logtype": "training_step"}
{"Ratio train steps to played games": 1.953025887193554, "Avg loss": 0.4716962289530784, "Avg value loss": 0.19227023364510387, "Avg policy loss": 0.27942599367816, "Total num played games": 11666, "Total num trained steps": 22784, "Timestamp in ms": 1700750700560, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9472208057113718, "Avg loss": 0.8920328214298934, "Avg value loss": 0.6140417351853102, "Avg policy loss": 0.27799109532497823, "Total num played games": 11766, "Total num trained steps": 22912, "Timestamp in ms": 1700750758361, "logtype": "training_step"}
{"Avg objective": 21.25703124999999, "Games time in secs": 203.62999590858817, "Avg game time in secs": 2.549751878992538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 11776, "Total num trained steps": 23025, "Timestamp in ms": 1700750808248, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9420094403236683, "Avg loss": 0.5768223989289254, "Avg value loss": 0.306416385108605, "Avg policy loss": 0.2704060112591833, "Total num played games": 11864, "Total num trained steps": 23040, "Timestamp in ms": 1700750814869, "logtype": "training_step"}
{"Total num played games": 11864, "Total num trained steps": 23067, "Timestamp in ms": 1700750868608, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3278125}
{"Avg objective": 21.056171874999993, "Games time in secs": 63.60224139690399, "Avg game time in secs": 2.2710523825662676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.42}, "Total num played games": 11904, "Total num trained steps": 23072, "Timestamp in ms": 1700750871850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9370401337792642, "Avg loss": 1.0398707534186542, "Avg value loss": 0.7416521783452481, "Avg policy loss": 0.29821857321076095, "Total num played games": 11960, "Total num trained steps": 23168, "Timestamp in ms": 1700750916564, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9477424749163879, "Avg loss": 0.5028955233283341, "Avg value loss": 0.22804397123400122, "Avg policy loss": 0.2748515505809337, "Total num played games": 11960, "Total num trained steps": 23296, "Timestamp in ms": 1700750976557, "logtype": "training_step"}
{"Avg objective": 21.436484374999992, "Games time in secs": 162.5669518020004, "Avg game time in secs": 2.2939394616551, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 12032, "Total num trained steps": 23417, "Timestamp in ms": 1700751034417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9428500331785004, "Avg loss": 0.5786585849709809, "Avg value loss": 0.31644525000592694, "Avg policy loss": 0.26221333479043096, "Total num played games": 12056, "Total num trained steps": 23424, "Timestamp in ms": 1700751037674, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9532260739757836, "Avg loss": 0.8525292463600636, "Avg value loss": 0.5733678881078959, "Avg policy loss": 0.2791613530134782, "Total num played games": 12058, "Total num trained steps": 23552, "Timestamp in ms": 1700751098419, "logtype": "training_step"}
{"Total num played games": 12058, "Total num trained steps": 23567, "Timestamp in ms": 1700751124609, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2991796875}
{"Ratio train steps to played games": 1.9483297679776206, "Avg loss": 0.8958408480975777, "Avg value loss": 0.6127149187959731, "Avg policy loss": 0.28312593046575785, "Total num played games": 12154, "Total num trained steps": 23680, "Timestamp in ms": 1700751180460, "logtype": "training_step"}
{"Avg objective": 20.86351562499999, "Games time in secs": 203.42238761298358, "Avg game time in secs": 2.3439095765643287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.53}, "Total num played games": 12160, "Total num trained steps": 23800, "Timestamp in ms": 1700751237840, "logtype": "played_game"}
{"Ratio train steps to played games": 1.943111328762651, "Avg loss": 0.5079293707385659, "Avg value loss": 0.24682677118107677, "Avg policy loss": 0.2611025986261666, "Total num played games": 12252, "Total num trained steps": 23808, "Timestamp in ms": 1700751241420, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9529210182767625, "Avg loss": 0.899864315520972, "Avg value loss": 0.6157297206809744, "Avg policy loss": 0.28413459088187665, "Total num played games": 12256, "Total num trained steps": 23936, "Timestamp in ms": 1700751301582, "logtype": "training_step"}
{"Avg objective": 21.180937499999988, "Games time in secs": 96.93920855410397, "Avg game time in secs": 2.213292446525884, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 12288, "Total num trained steps": 24006, "Timestamp in ms": 1700751334779, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9477901894123362, "Avg loss": 0.8501488664187491, "Avg value loss": 0.5723833295051008, "Avg policy loss": 0.27776553644798696, "Total num played games": 12354, "Total num trained steps": 24064, "Timestamp in ms": 1700751360453, "logtype": "training_step"}
{"Total num played games": 12354, "Total num trained steps": 24067, "Timestamp in ms": 1700751386255, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.541289062500002}
{"Avg objective": 21.786874999999988, "Games time in secs": 55.33938383124769, "Avg game time in secs": 2.166834671923425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 12416, "Total num trained steps": 24075, "Timestamp in ms": 1700751390119, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9430522088353415, "Avg loss": 1.0627979505807161, "Avg value loss": 0.756549482117407, "Avg policy loss": 0.30624847393482924, "Total num played games": 12450, "Total num trained steps": 24192, "Timestamp in ms": 1700751444701, "logtype": "training_step"}
{"Ratio train steps to played games": 1.953413654618474, "Avg loss": 0.4923057781998068, "Avg value loss": 0.21174168132711202, "Avg policy loss": 0.28056409780401736, "Total num played games": 12450, "Total num trained steps": 24320, "Timestamp in ms": 1700751507144, "logtype": "training_step"}
{"Avg objective": 20.76289062499999, "Games time in secs": 155.5064614918083, "Avg game time in secs": 2.32840732987097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 12544, "Total num trained steps": 24402, "Timestamp in ms": 1700751545626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9483583041122092, "Avg loss": 0.7674106226768345, "Avg value loss": 0.4826826309436001, "Avg policy loss": 0.2847279906272888, "Total num played games": 12548, "Total num trained steps": 24448, "Timestamp in ms": 1700751568474, "logtype": "training_step"}
{"Total num played games": 12548, "Total num trained steps": 24568, "Timestamp in ms": 1700751652243, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2150390625}
{"Ratio train steps to played games": 1.9529561347743165, "Avg loss": 0.5191241684369743, "Avg value loss": 0.23323939787223935, "Avg policy loss": 0.2858847730094567, "Total num played games": 12584, "Total num trained steps": 24576, "Timestamp in ms": 1700751655499, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9538120847832965, "Avg loss": 1.072578136343509, "Avg value loss": 0.7578256527194753, "Avg policy loss": 0.3147524764062837, "Total num played games": 12644, "Total num trained steps": 24704, "Timestamp in ms": 1700751715325, "logtype": "training_step"}
{"Avg objective": 22.87726562499999, "Games time in secs": 205.72743125259876, "Avg game time in secs": 2.254803397532669, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 12672, "Total num trained steps": 24783, "Timestamp in ms": 1700751751353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9487521582169205, "Avg loss": 0.855026587145403, "Avg value loss": 0.5605822682846338, "Avg policy loss": 0.294444315135479, "Total num played games": 12742, "Total num trained steps": 24832, "Timestamp in ms": 1700751772980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9587976769737874, "Avg loss": 0.5121917885262519, "Avg value loss": 0.21278360282303765, "Avg policy loss": 0.2994081878568977, "Total num played games": 12742, "Total num trained steps": 24960, "Timestamp in ms": 1700751834370, "logtype": "training_step"}
{"Avg objective": 21.115078124999986, "Games time in secs": 91.16918070055544, "Avg game time in secs": 2.374776368116727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 12800, "Total num trained steps": 24980, "Timestamp in ms": 1700751842523, "logtype": "played_game"}
{"Total num played games": 12842, "Total num trained steps": 25069, "Timestamp in ms": 1700751907886, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.726679687500003}
{"Avg objective": 21.499296874999985, "Games time in secs": 70.74192191287875, "Avg game time in secs": 2.713070202822564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.68}, "Total num played games": 12928, "Total num trained steps": 25082, "Timestamp in ms": 1700751913265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9390941412892255, "Avg loss": 1.2472848978359252, "Avg value loss": 0.937695236178115, "Avg policy loss": 0.30958967248443514, "Total num played games": 12938, "Total num trained steps": 25088, "Timestamp in ms": 1700751915849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9489874787447827, "Avg loss": 0.9202153240330517, "Avg value loss": 0.5970579034183174, "Avg policy loss": 0.32315742189530283, "Total num played games": 12938, "Total num trained steps": 25216, "Timestamp in ms": 1700751980449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9588808162003402, "Avg loss": 0.507502025924623, "Avg value loss": 0.2115929126739502, "Avg policy loss": 0.29590911022387445, "Total num played games": 12938, "Total num trained steps": 25344, "Timestamp in ms": 1700752043152, "logtype": "training_step"}
{"Ratio train steps to played games": 1.954273438698788, "Avg loss": 0.6880379794165492, "Avg value loss": 0.3928960148477927, "Avg policy loss": 0.29514196945820004, "Total num played games": 13034, "Total num trained steps": 25472, "Timestamp in ms": 1700752107165, "logtype": "training_step"}
{"Avg objective": 20.185624999999984, "Games time in secs": 236.0808577351272, "Avg game time in secs": 2.1740011207584757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 13056, "Total num trained steps": 25561, "Timestamp in ms": 1700752149346, "logtype": "played_game"}
{"Total num played games": 13138, "Total num trained steps": 25573, "Timestamp in ms": 1700752182896, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.796015625000003}
{"Avg objective": 20.62859374999999, "Games time in secs": 36.730983428657055, "Avg game time in secs": 2.005279908713419, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 13184, "Total num trained steps": 25578, "Timestamp in ms": 1700752186077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9346281741233373, "Avg loss": 1.0403867603745311, "Avg value loss": 0.7554244963685051, "Avg policy loss": 0.2849622663343325, "Total num played games": 13232, "Total num trained steps": 25600, "Timestamp in ms": 1700752195624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9440834214901013, "Avg loss": 0.7037544592749327, "Avg value loss": 0.38879852648824453, "Avg policy loss": 0.3149559269659221, "Total num played games": 13234, "Total num trained steps": 25728, "Timestamp in ms": 1700752257635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9536799153695028, "Avg loss": 0.46437056246213615, "Avg value loss": 0.1812752551632002, "Avg policy loss": 0.2830953028751537, "Total num played games": 13234, "Total num trained steps": 25856, "Timestamp in ms": 1700752317559, "logtype": "training_step"}
{"Avg objective": 21.38992187499999, "Games time in secs": 183.56629610061646, "Avg game time in secs": 2.484918859845493, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 13312, "Total num trained steps": 25966, "Timestamp in ms": 1700752369643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.948919891989199, "Avg loss": 0.7370618747081608, "Avg value loss": 0.4666809873888269, "Avg policy loss": 0.27038088196422905, "Total num played games": 13332, "Total num trained steps": 25984, "Timestamp in ms": 1700752377529, "logtype": "training_step"}
{"Total num played games": 13332, "Total num trained steps": 26076, "Timestamp in ms": 1700752440788, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1681640625}
{"Ratio train steps to played games": 1.9445189156985403, "Avg loss": 0.8531680291052908, "Avg value loss": 0.5520406258292496, "Avg policy loss": 0.30112740339245647, "Total num played games": 13428, "Total num trained steps": 26112, "Timestamp in ms": 1700752457994, "logtype": "training_step"}
{"Ratio train steps to played games": 1.954051236222818, "Avg loss": 0.5830058096908033, "Avg value loss": 0.27593047567643225, "Avg policy loss": 0.30707533343229443, "Total num played games": 13428, "Total num trained steps": 26240, "Timestamp in ms": 1700752520087, "logtype": "training_step"}
{"Avg objective": 20.311796874999985, "Games time in secs": 202.25269792601466, "Avg game time in secs": 2.46894663022249, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 13440, "Total num trained steps": 26349, "Timestamp in ms": 1700752571896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9490685984624483, "Avg loss": 0.6009190161712468, "Avg value loss": 0.31382825691252947, "Avg policy loss": 0.2870907604228705, "Total num played games": 13528, "Total num trained steps": 26368, "Timestamp in ms": 1700752580701, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9586043761088114, "Avg loss": 0.585998184978962, "Avg value loss": 0.28586436598561704, "Avg policy loss": 0.30013381561730057, "Total num played games": 13528, "Total num trained steps": 26496, "Timestamp in ms": 1700752640789, "logtype": "training_step"}
{"Avg objective": 21.969062499999993, "Games time in secs": 93.36463482677937, "Avg game time in secs": 2.0174007525201887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.43}, "Total num played games": 13568, "Total num trained steps": 26550, "Timestamp in ms": 1700752665261, "logtype": "played_game"}
{"Total num played games": 13626, "Total num trained steps": 26578, "Timestamp in ms": 1700752702063, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.7223828125}
{"Avg objective": 21.320468749999996, "Games time in secs": 40.60091504827142, "Avg game time in secs": 2.106217372987885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 13696, "Total num trained steps": 26586, "Timestamp in ms": 1700752705862, "logtype": "played_game"}
{"Ratio train steps to played games": 1.940241947238012, "Avg loss": 1.150301992194727, "Avg value loss": 0.8474634243175387, "Avg policy loss": 0.30283856473397464, "Total num played games": 13722, "Total num trained steps": 26624, "Timestamp in ms": 1700752723848, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9494971578487101, "Avg loss": 0.5773046682588756, "Avg value loss": 0.2714110466185957, "Avg policy loss": 0.30589362198952585, "Total num played games": 13722, "Total num trained steps": 26752, "Timestamp in ms": 1700752784015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9588981198076083, "Avg loss": 0.4671786418184638, "Avg value loss": 0.1803752956329845, "Avg policy loss": 0.28680334193632007, "Total num played games": 13722, "Total num trained steps": 26880, "Timestamp in ms": 1700752844361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9539140500651135, "Avg loss": 0.7045649164356291, "Avg value loss": 0.4241378998849541, "Avg policy loss": 0.28042702027596533, "Total num played games": 13822, "Total num trained steps": 27008, "Timestamp in ms": 1700752901589, "logtype": "training_step"}
{"Total num played games": 13822, "Total num trained steps": 27080, "Timestamp in ms": 1700752954528, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.535390625000005}
{"Avg objective": 21.560390624999993, "Games time in secs": 250.3268322441727, "Avg game time in secs": 2.5217613575223368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 13824, "Total num trained steps": 27081, "Timestamp in ms": 1700752956189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9496335680413852, "Avg loss": 0.8365128394216299, "Avg value loss": 0.5448981507215649, "Avg policy loss": 0.29161469056271017, "Total num played games": 13918, "Total num trained steps": 27136, "Timestamp in ms": 1700752980081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9589021411122287, "Avg loss": 0.5762003134004772, "Avg value loss": 0.2802481217077002, "Avg policy loss": 0.29595219041220844, "Total num played games": 13918, "Total num trained steps": 27264, "Timestamp in ms": 1700753040512, "logtype": "training_step"}
{"Avg objective": 22.101015624999985, "Games time in secs": 114.70843359082937, "Avg game time in secs": 2.1327327831677394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 13952, "Total num trained steps": 27329, "Timestamp in ms": 1700753070897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.954616811759669, "Avg loss": 0.8952886876650155, "Avg value loss": 0.601016876695212, "Avg policy loss": 0.2942718203412369, "Total num played games": 14014, "Total num trained steps": 27392, "Timestamp in ms": 1700753099433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9637505351791067, "Avg loss": 0.48930075904354453, "Avg value loss": 0.20126148033887148, "Avg policy loss": 0.2880392777733505, "Total num played games": 14014, "Total num trained steps": 27520, "Timestamp in ms": 1700753160353, "logtype": "training_step"}
{"Avg objective": 20.197109374999993, "Games time in secs": 91.18209191225469, "Avg game time in secs": 2.2700085244723596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 14080, "Total num trained steps": 27525, "Timestamp in ms": 1700753162080, "logtype": "played_game"}
{"Total num played games": 14112, "Total num trained steps": 27582, "Timestamp in ms": 1700753211512, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.976250000000004}
{"Avg objective": 21.435937499999987, "Games time in secs": 56.305272260680795, "Avg game time in secs": 2.6427238453907194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 14208, "Total num trained steps": 27598, "Timestamp in ms": 1700753218385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.945945945945946, "Avg loss": 1.2504683383740485, "Avg value loss": 0.9292553813429549, "Avg policy loss": 0.32121295121032745, "Total num played games": 14208, "Total num trained steps": 27648, "Timestamp in ms": 1700753241782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.954954954954955, "Avg loss": 0.5174963849131018, "Avg value loss": 0.2223627083003521, "Avg policy loss": 0.295133677078411, "Total num played games": 14208, "Total num trained steps": 27776, "Timestamp in ms": 1700753303614, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9639639639639639, "Avg loss": 0.4472845043055713, "Avg value loss": 0.17220360157079995, "Avg policy loss": 0.27508090157061815, "Total num played games": 14208, "Total num trained steps": 27904, "Timestamp in ms": 1700753364043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9593876695092969, "Avg loss": 0.982034987071529, "Avg value loss": 0.6683750171214342, "Avg policy loss": 0.31365997600369155, "Total num played games": 14306, "Total num trained steps": 28032, "Timestamp in ms": 1700753426676, "logtype": "training_step"}
{"Total num played games": 14306, "Total num trained steps": 28083, "Timestamp in ms": 1700753475941, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.341875}
{"Avg objective": 21.40281249999999, "Games time in secs": 260.70911586098373, "Avg game time in secs": 2.26180829416262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 14336, "Total num trained steps": 28090, "Timestamp in ms": 1700753479094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9552839883349535, "Avg loss": 0.827785556204617, "Avg value loss": 0.5178481095936149, "Avg policy loss": 0.3099374450976029, "Total num played games": 14402, "Total num trained steps": 28160, "Timestamp in ms": 1700753511087, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964102208026663, "Avg loss": 0.48622693261131644, "Avg value loss": 0.18918448395561427, "Avg policy loss": 0.2970424476079643, "Total num played games": 14402, "Total num trained steps": 28288, "Timestamp in ms": 1700753575067, "logtype": "training_step"}
{"Avg objective": 21.745546874999988, "Games time in secs": 101.0505152400583, "Avg game time in secs": 2.756545104595716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 14464, "Total num trained steps": 28300, "Timestamp in ms": 1700753580145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9596551724137932, "Avg loss": 0.9025200353935361, "Avg value loss": 0.5869580641738139, "Avg policy loss": 0.3155619683675468, "Total num played games": 14500, "Total num trained steps": 28416, "Timestamp in ms": 1700753636045, "logtype": "training_step"}
{"Avg objective": 21.57664062499999, "Games time in secs": 95.45312387496233, "Avg game time in secs": 2.6044416173535865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.6, "agent_stopped_0": 0.46}, "Total num played games": 14592, "Total num trained steps": 28503, "Timestamp in ms": 1700753675598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9552678449102616, "Avg loss": 0.8021820627618581, "Avg value loss": 0.4913066476001404, "Avg policy loss": 0.310875412193127, "Total num played games": 14598, "Total num trained steps": 28544, "Timestamp in ms": 1700753694759, "logtype": "training_step"}
{"Total num played games": 14598, "Total num trained steps": 28583, "Timestamp in ms": 1700753751734, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.96328125}
{"Ratio train steps to played games": 1.9512045732952226, "Avg loss": 0.9006872961763293, "Avg value loss": 0.5704984943149611, "Avg policy loss": 0.33018880046438426, "Total num played games": 14694, "Total num trained steps": 28672, "Timestamp in ms": 1700753793354, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959915611814346, "Avg loss": 0.4853043507318944, "Avg value loss": 0.18557393120136112, "Avg policy loss": 0.29973041894845665, "Total num played games": 14694, "Total num trained steps": 28800, "Timestamp in ms": 1700753853407, "logtype": "training_step"}
{"Avg objective": 21.484140624999988, "Games time in secs": 217.51070571504533, "Avg game time in secs": 2.296983884909423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.52, "agent_stopped_0": 0.61}, "Total num played games": 14720, "Total num trained steps": 28882, "Timestamp in ms": 1700753893109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9553873191834528, "Avg loss": 0.7755504101514816, "Avg value loss": 0.47879293881123886, "Avg policy loss": 0.2967574738431722, "Total num played games": 14794, "Total num trained steps": 28928, "Timestamp in ms": 1700753914480, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9639718804920914, "Avg loss": 0.47310217982158065, "Avg value loss": 0.1859580448945053, "Avg policy loss": 0.28714413847774267, "Total num played games": 14794, "Total num trained steps": 29056, "Timestamp in ms": 1700753976597, "logtype": "training_step"}
{"Avg objective": 20.822656249999987, "Games time in secs": 96.74647143483162, "Avg game time in secs": 2.2057662021252327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.49, "agent_stopped_0": 0.54}, "Total num played games": 14848, "Total num trained steps": 29082, "Timestamp in ms": 1700753989856, "logtype": "played_game"}
{"Total num played games": 14890, "Total num trained steps": 29083, "Timestamp in ms": 1700754006566, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.781406250000003}
{"Avg objective": 21.85289062499999, "Games time in secs": 21.77308459021151, "Avg game time in secs": 2.4543230956915068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 14976, "Total num trained steps": 29093, "Timestamp in ms": 1700754011629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9473508608034165, "Avg loss": 1.5769860995933414, "Avg value loss": 1.2446057255729102, "Avg policy loss": 0.3323803497478366, "Total num played games": 14986, "Total num trained steps": 29184, "Timestamp in ms": 1700754054946, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9558921660216202, "Avg loss": 0.5303605548106134, "Avg value loss": 0.22670974675565958, "Avg policy loss": 0.30365080980118364, "Total num played games": 14986, "Total num trained steps": 29312, "Timestamp in ms": 1700754116281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964433471239824, "Avg loss": 0.45259686978533864, "Avg value loss": 0.164680645451881, "Avg policy loss": 0.28791622549761087, "Total num played games": 14986, "Total num trained steps": 29440, "Timestamp in ms": 1700754179424, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9604826946028377, "Avg loss": 0.7504355073906481, "Avg value loss": 0.45325213903561234, "Avg policy loss": 0.2971833609044552, "Total num played games": 15082, "Total num trained steps": 29568, "Timestamp in ms": 1700754246153, "logtype": "training_step"}
{"Total num played games": 15082, "Total num trained steps": 29586, "Timestamp in ms": 1700754270897, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.795859375000003}
{"Avg objective": 21.200312499999985, "Games time in secs": 261.6293510608375, "Avg game time in secs": 2.317091150514898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 15104, "Total num trained steps": 29589, "Timestamp in ms": 1700754273258, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9565160100144947, "Avg loss": 0.962634070077911, "Avg value loss": 0.6458104901248589, "Avg policy loss": 0.31682358880061656, "Total num played games": 15178, "Total num trained steps": 29696, "Timestamp in ms": 1700754324719, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9648833838450388, "Avg loss": 0.46618592296727, "Avg value loss": 0.17790109885390848, "Avg policy loss": 0.28828482527751476, "Total num played games": 15178, "Total num trained steps": 29824, "Timestamp in ms": 1700754386193, "logtype": "training_step"}
{"Avg objective": 23.16960937499999, "Games time in secs": 125.03466260433197, "Avg game time in secs": 2.0626826123625506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 15232, "Total num trained steps": 29849, "Timestamp in ms": 1700754398293, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9609139714547597, "Avg loss": 0.9341562658082694, "Avg value loss": 0.6342071239487268, "Avg policy loss": 0.2999491549562663, "Total num played games": 15274, "Total num trained steps": 29952, "Timestamp in ms": 1700754447088, "logtype": "training_step"}
{"Avg objective": 23.096718749999994, "Games time in secs": 93.17624698206782, "Avg game time in secs": 2.453158466320019, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 15360, "Total num trained steps": 30044, "Timestamp in ms": 1700754491470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9568045797553995, "Avg loss": 0.8312104707583785, "Avg value loss": 0.5347915875026956, "Avg policy loss": 0.29641888034529984, "Total num played games": 15372, "Total num trained steps": 30080, "Timestamp in ms": 1700754508943, "logtype": "training_step"}
{"Total num played games": 15372, "Total num trained steps": 30089, "Timestamp in ms": 1700754537158, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.522656250000004}
{"Ratio train steps to played games": 1.9529350918024309, "Avg loss": 0.9139173827134073, "Avg value loss": 0.5833696345798671, "Avg policy loss": 0.3305477611720562, "Total num played games": 15468, "Total num trained steps": 30208, "Timestamp in ms": 1700754594828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9612102404965088, "Avg loss": 0.49371926533058286, "Avg value loss": 0.18518253875663504, "Avg policy loss": 0.30853672709781677, "Total num played games": 15468, "Total num trained steps": 30336, "Timestamp in ms": 1700754656080, "logtype": "training_step"}
{"Avg objective": 20.49296874999999, "Games time in secs": 212.6793652419001, "Avg game time in secs": 2.1493113016040297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 15488, "Total num trained steps": 30427, "Timestamp in ms": 1700754704149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9568345323741008, "Avg loss": 0.7447841265238822, "Avg value loss": 0.4437788021750748, "Avg policy loss": 0.3010053342441097, "Total num played games": 15568, "Total num trained steps": 30464, "Timestamp in ms": 1700754722726, "logtype": "training_step"}
{"Total num played games": 15568, "Total num trained steps": 30590, "Timestamp in ms": 1700754808631, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.748984375000003}
{"Ratio train steps to played games": 1.9650565262076054, "Avg loss": 0.5530186938121915, "Avg value loss": 0.24593335553072393, "Avg policy loss": 0.30708533886354417, "Total num played games": 15568, "Total num trained steps": 30592, "Timestamp in ms": 1700754809921, "logtype": "training_step"}
{"Avg objective": 20.38414062499999, "Games time in secs": 108.0398408472538, "Avg game time in secs": 2.192460290098097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 15616, "Total num trained steps": 30596, "Timestamp in ms": 1700754812189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9611848825331972, "Avg loss": 0.6858745131175965, "Avg value loss": 0.37035273131914437, "Avg policy loss": 0.31552177865523845, "Total num played games": 15664, "Total num trained steps": 30720, "Timestamp in ms": 1700754871728, "logtype": "training_step"}
{"Avg objective": 20.402499999999993, "Games time in secs": 110.29106023907661, "Avg game time in secs": 2.2401606633211486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 15744, "Total num trained steps": 30823, "Timestamp in ms": 1700754922480, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9572969543147207, "Avg loss": 0.6774109359830618, "Avg value loss": 0.37214380578370765, "Avg policy loss": 0.3052671292098239, "Total num played games": 15760, "Total num trained steps": 30848, "Timestamp in ms": 1700754934716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9654822335025381, "Avg loss": 0.6239678969141096, "Avg value loss": 0.30134475883096457, "Avg policy loss": 0.32262313656974584, "Total num played games": 15760, "Total num trained steps": 30976, "Timestamp in ms": 1700754996648, "logtype": "training_step"}
{"Total num played games": 15856, "Total num trained steps": 31091, "Timestamp in ms": 1700755077617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.639570312500005}
{"Avg objective": 21.03757812499998, "Games time in secs": 157.52389555051923, "Avg game time in secs": 2.702946502031409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.66, "agent_stopped_0": 0.45}, "Total num played games": 15872, "Total num trained steps": 31094, "Timestamp in ms": 1700755080004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9498495486459377, "Avg loss": 0.9032587285619229, "Avg value loss": 0.5618555137771182, "Avg policy loss": 0.34140321100130677, "Total num played games": 15950, "Total num trained steps": 31104, "Timestamp in ms": 1700755084887, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9578109327983952, "Avg loss": 0.6880088078323752, "Avg value loss": 0.3487373345415108, "Avg policy loss": 0.3392714731162414, "Total num played games": 15952, "Total num trained steps": 31232, "Timestamp in ms": 1700755150673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9658976930792378, "Avg loss": 0.4682385672349483, "Avg value loss": 0.16112372127827257, "Avg policy loss": 0.30711484351195395, "Total num played games": 15952, "Total num trained steps": 31360, "Timestamp in ms": 1700755215717, "logtype": "training_step"}
{"Avg objective": 20.94195312499999, "Games time in secs": 153.63166979700327, "Avg game time in secs": 2.01333268849703, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 16000, "Total num trained steps": 31397, "Timestamp in ms": 1700755233636, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9621136590229311, "Avg loss": 0.7592057061847299, "Avg value loss": 0.43584906274918467, "Avg policy loss": 0.32335663633421063, "Total num played games": 16048, "Total num trained steps": 31488, "Timestamp in ms": 1700755277564, "logtype": "training_step"}
{"Avg objective": 21.13546874999999, "Games time in secs": 93.6612705886364, "Avg game time in secs": 2.1957000891998177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 16128, "Total num trained steps": 31591, "Timestamp in ms": 1700755327297, "logtype": "played_game"}
{"Total num played games": 16144, "Total num trained steps": 31594, "Timestamp in ms": 1700755370374, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.229453125}
{"Ratio train steps to played games": 1.9467980295566503, "Avg loss": 1.0519783839117736, "Avg value loss": 0.7311373493284918, "Avg policy loss": 0.3208410191582516, "Total num played games": 16240, "Total num trained steps": 31616, "Timestamp in ms": 1700755381548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9546798029556651, "Avg loss": 0.9016425055451691, "Avg value loss": 0.5319722983986139, "Avg policy loss": 0.36967020330484957, "Total num played games": 16240, "Total num trained steps": 31744, "Timestamp in ms": 1700755442317, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9625615763546798, "Avg loss": 0.47768904734402895, "Avg value loss": 0.15628965047653764, "Avg policy loss": 0.32139939453918487, "Total num played games": 16240, "Total num trained steps": 31872, "Timestamp in ms": 1700755502664, "logtype": "training_step"}
{"Avg objective": 20.028671874999986, "Games time in secs": 224.07998250611126, "Avg game time in secs": 2.2905192982725566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 16256, "Total num trained steps": 31971, "Timestamp in ms": 1700755551381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9588638589618022, "Avg loss": 0.6924995831213892, "Avg value loss": 0.3744243420660496, "Avg policy loss": 0.31807524035684764, "Total num played games": 16336, "Total num trained steps": 32000, "Timestamp in ms": 1700755564574, "logtype": "training_step"}
{"Total num played games": 16336, "Total num trained steps": 32095, "Timestamp in ms": 1700755634229, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.869375}
{"Avg objective": 19.835937499999982, "Games time in secs": 86.13329297676682, "Avg game time in secs": 2.106091071618721, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 16384, "Total num trained steps": 32099, "Timestamp in ms": 1700755637514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955209347614411, "Avg loss": 0.7983049612957984, "Avg value loss": 0.4606655006064102, "Avg policy loss": 0.3376394642982632, "Total num played games": 16432, "Total num trained steps": 32128, "Timestamp in ms": 1700755651740, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9629381694255112, "Avg loss": 0.5451262560673058, "Avg value loss": 0.22060252499068156, "Avg policy loss": 0.32452373090200126, "Total num played games": 16432, "Total num trained steps": 32256, "Timestamp in ms": 1700755715930, "logtype": "training_step"}
{"Avg objective": 22.26429687499999, "Games time in secs": 129.9153264760971, "Avg game time in secs": 2.1669497294642497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 16512, "Total num trained steps": 32359, "Timestamp in ms": 1700755767429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9591046581972171, "Avg loss": 0.9826659681275487, "Avg value loss": 0.6718531892984174, "Avg policy loss": 0.3108127876184881, "Total num played games": 16530, "Total num trained steps": 32384, "Timestamp in ms": 1700755778862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9668481548699335, "Avg loss": 0.7048662181477994, "Avg value loss": 0.37156988779315725, "Avg policy loss": 0.3332963332068175, "Total num played games": 16530, "Total num trained steps": 32512, "Timestamp in ms": 1700755839604, "logtype": "training_step"}
{"Total num played games": 16630, "Total num trained steps": 32595, "Timestamp in ms": 1700755920845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.598242187500002}
{"Avg objective": 21.016171874999984, "Games time in secs": 155.6159864012152, "Avg game time in secs": 2.6378913437511073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 16640, "Total num trained steps": 32597, "Timestamp in ms": 1700755923046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9513930407748417, "Avg loss": 1.1371304544154555, "Avg value loss": 0.7972707634908147, "Avg policy loss": 0.3398596888873726, "Total num played games": 16726, "Total num trained steps": 32640, "Timestamp in ms": 1700755943295, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959105584120531, "Avg loss": 0.6158099882304668, "Avg value loss": 0.27359652100130916, "Avg policy loss": 0.34221346385311335, "Total num played games": 16726, "Total num trained steps": 32768, "Timestamp in ms": 1700756005244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9667583403085018, "Avg loss": 0.4579215489793569, "Avg value loss": 0.14476988022215664, "Avg policy loss": 0.31315166980493814, "Total num played games": 16726, "Total num trained steps": 32896, "Timestamp in ms": 1700756067751, "logtype": "training_step"}
{"Avg objective": 19.93257812499998, "Games time in secs": 168.51889601536095, "Avg game time in secs": 2.1408434720506193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 16768, "Total num trained steps": 32944, "Timestamp in ms": 1700756091565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9631435025561765, "Avg loss": 0.782476658700034, "Avg value loss": 0.46361770608928055, "Avg policy loss": 0.31885895086452365, "Total num played games": 16822, "Total num trained steps": 33024, "Timestamp in ms": 1700756130407, "logtype": "training_step"}
{"Total num played games": 16822, "Total num trained steps": 33095, "Timestamp in ms": 1700756184454, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5723046875}
{"Avg objective": 21.41140624999999, "Games time in secs": 96.66106014885008, "Avg game time in secs": 2.2304746526206145, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 16896, "Total num trained steps": 33102, "Timestamp in ms": 1700756188226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9595696890885448, "Avg loss": 0.901093766791746, "Avg value loss": 0.5860802209936082, "Avg policy loss": 0.31501354940701276, "Total num played games": 16918, "Total num trained steps": 33152, "Timestamp in ms": 1700756215065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9671355952240217, "Avg loss": 0.5113817711826414, "Avg value loss": 0.2050368085037917, "Avg policy loss": 0.30634496407583356, "Total num played games": 16918, "Total num trained steps": 33280, "Timestamp in ms": 1700756281987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9635594216527565, "Avg loss": 0.8468061662279069, "Avg value loss": 0.5328692437615246, "Avg policy loss": 0.3139369332930073, "Total num played games": 17014, "Total num trained steps": 33408, "Timestamp in ms": 1700756343209, "logtype": "training_step"}
{"Avg objective": 19.926484374999987, "Games time in secs": 206.78297374770045, "Avg game time in secs": 2.3934086977969855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 17024, "Total num trained steps": 33519, "Timestamp in ms": 1700756395009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9599649327878435, "Avg loss": 0.6675720564089715, "Avg value loss": 0.36558671726379544, "Avg policy loss": 0.30198535008821636, "Total num played games": 17110, "Total num trained steps": 33536, "Timestamp in ms": 1700756402849, "logtype": "training_step"}
{"Total num played games": 17110, "Total num trained steps": 33595, "Timestamp in ms": 1700756452464, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.325351562500003}
{"Avg objective": 21.30062499999999, "Games time in secs": 60.297702392563224, "Avg game time in secs": 2.1058366470970213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.49}, "Total num played games": 17152, "Total num trained steps": 33599, "Timestamp in ms": 1700756455307, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9565267929791934, "Avg loss": 1.1062370692379773, "Avg value loss": 0.7638905453495681, "Avg policy loss": 0.3423465096857399, "Total num played games": 17206, "Total num trained steps": 33664, "Timestamp in ms": 1700756486239, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9639660583517378, "Avg loss": 0.5086239313241094, "Avg value loss": 0.19866217719390988, "Avg policy loss": 0.3099617558764294, "Total num played games": 17206, "Total num trained steps": 33792, "Timestamp in ms": 1700756547673, "logtype": "training_step"}
{"Avg objective": 21.93390624999999, "Games time in secs": 147.8984309192747, "Avg game time in secs": 2.3465879050345393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 17280, "Total num trained steps": 33907, "Timestamp in ms": 1700756603205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9604669980349092, "Avg loss": 0.5163873261772096, "Avg value loss": 0.2183423056267202, "Avg policy loss": 0.2980450210161507, "Total num played games": 17302, "Total num trained steps": 33920, "Timestamp in ms": 1700756609175, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967864986706739, "Avg loss": 0.5663106034044176, "Avg value loss": 0.26014638249762356, "Avg policy loss": 0.30616421659942716, "Total num played games": 17302, "Total num trained steps": 34048, "Timestamp in ms": 1700756678075, "logtype": "training_step"}
{"Total num played games": 17398, "Total num trained steps": 34099, "Timestamp in ms": 1700756718571, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.845859375000003}
{"Avg objective": 20.958515624999986, "Games time in secs": 117.62283390387893, "Avg game time in secs": 2.5218310958880465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 17408, "Total num trained steps": 34102, "Timestamp in ms": 1700756720828, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9535269235166344, "Avg loss": 1.1998784942552447, "Avg value loss": 0.8733828807598911, "Avg policy loss": 0.3264956211205572, "Total num played games": 17494, "Total num trained steps": 34176, "Timestamp in ms": 1700756756397, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9608437178461187, "Avg loss": 0.5044376391451806, "Avg value loss": 0.18490499426843598, "Avg policy loss": 0.31953263946343213, "Total num played games": 17494, "Total num trained steps": 34304, "Timestamp in ms": 1700756817317, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9682176746313023, "Avg loss": 0.43574959924444556, "Avg value loss": 0.13023195473942906, "Avg policy loss": 0.30551764369010925, "Total num played games": 17494, "Total num trained steps": 34432, "Timestamp in ms": 1700756877888, "logtype": "training_step"}
{"Avg objective": 20.711093749999993, "Games time in secs": 181.08451114967465, "Avg game time in secs": 2.144752640815568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.42}, "Total num played games": 17536, "Total num trained steps": 34480, "Timestamp in ms": 1700756901913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9646958499147242, "Avg loss": 0.7453848044387996, "Avg value loss": 0.4385457737953402, "Avg policy loss": 0.30683903535827994, "Total num played games": 17590, "Total num trained steps": 34560, "Timestamp in ms": 1700756938825, "logtype": "training_step"}
{"Total num played games": 17590, "Total num trained steps": 34599, "Timestamp in ms": 1700756974745, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.1406640625}
{"Avg objective": 22.738515624999987, "Games time in secs": 77.54869917966425, "Avg game time in secs": 2.3598347519000527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 17664, "Total num trained steps": 34607, "Timestamp in ms": 1700756979462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.961268800180934, "Avg loss": 0.7906025154516101, "Avg value loss": 0.47610729990992695, "Avg policy loss": 0.31449521775357425, "Total num played games": 17686, "Total num trained steps": 34688, "Timestamp in ms": 1700757018725, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9685061630668326, "Avg loss": 0.46041042683646083, "Avg value loss": 0.16281802026787773, "Avg policy loss": 0.2975924088386819, "Total num played games": 17686, "Total num trained steps": 34816, "Timestamp in ms": 1700757083387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965077044202002, "Avg loss": 0.8944586531724781, "Avg value loss": 0.5869800530490465, "Avg policy loss": 0.30747858970426023, "Total num played games": 17782, "Total num trained steps": 34944, "Timestamp in ms": 1700757146282, "logtype": "training_step"}
{"Avg objective": 20.125937499999985, "Games time in secs": 222.56864794529974, "Avg game time in secs": 2.603397364306147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 17792, "Total num trained steps": 35055, "Timestamp in ms": 1700757202031, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9617406868777267, "Avg loss": 0.6421806658618152, "Avg value loss": 0.3469568517175503, "Avg policy loss": 0.2952238159487024, "Total num played games": 17878, "Total num trained steps": 35072, "Timestamp in ms": 1700757210148, "logtype": "training_step"}
{"Total num played games": 17878, "Total num trained steps": 35102, "Timestamp in ms": 1700757246237, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.342578125000003}
{"Avg objective": 22.08593749999999, "Games time in secs": 47.445937698706985, "Avg game time in secs": 2.1679916543798754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 17920, "Total num trained steps": 35108, "Timestamp in ms": 1700757249477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9583843329253365, "Avg loss": 0.8734381308313459, "Avg value loss": 0.544495266629383, "Avg policy loss": 0.32894285721704364, "Total num played games": 17974, "Total num trained steps": 35200, "Timestamp in ms": 1700757296679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9654500945810616, "Avg loss": 0.46355377440340817, "Avg value loss": 0.16146282403497025, "Avg policy loss": 0.3020909467013553, "Total num played games": 17974, "Total num trained steps": 35328, "Timestamp in ms": 1700757358733, "logtype": "training_step"}
{"Avg objective": 21.700234374999987, "Games time in secs": 163.74589796736836, "Avg game time in secs": 2.4808339398296084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 18048, "Total num trained steps": 35443, "Timestamp in ms": 1700757413223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9619300575475875, "Avg loss": 0.6418223243672401, "Avg value loss": 0.34556951001286507, "Avg policy loss": 0.2962528206408024, "Total num played games": 18072, "Total num trained steps": 35456, "Timestamp in ms": 1700757419337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.969012837538734, "Avg loss": 0.6851175001356751, "Avg value loss": 0.3709819400100969, "Avg policy loss": 0.31413556111510843, "Total num played games": 18072, "Total num trained steps": 35584, "Timestamp in ms": 1700757482598, "logtype": "training_step"}
{"Total num played games": 18072, "Total num trained steps": 35602, "Timestamp in ms": 1700757510817, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5776953125}
{"Ratio train steps to played games": 1.9655988551298986, "Avg loss": 0.8630906753242016, "Avg value loss": 0.5452393275918439, "Avg policy loss": 0.3178513562306762, "Total num played games": 18168, "Total num trained steps": 35712, "Timestamp in ms": 1700757565560, "logtype": "training_step"}
{"Avg objective": 21.380546874999983, "Games time in secs": 208.6096716504544, "Avg game time in secs": 2.367041404286283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 18176, "Total num trained steps": 35826, "Timestamp in ms": 1700757621833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.962545175774833, "Avg loss": 0.5723460593726486, "Avg value loss": 0.2677518821437843, "Avg policy loss": 0.30459417682141066, "Total num played games": 18262, "Total num trained steps": 35840, "Timestamp in ms": 1700757628117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9693385895751205, "Avg loss": 0.7389879878610373, "Avg value loss": 0.4221077805850655, "Avg policy loss": 0.31688020599540323, "Total num played games": 18264, "Total num trained steps": 35968, "Timestamp in ms": 1700757690938, "logtype": "training_step"}
{"Avg objective": 21.722499999999982, "Games time in secs": 97.13570658490062, "Avg game time in secs": 2.0865399423782947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 18304, "Total num trained steps": 36020, "Timestamp in ms": 1700757718969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9660130718954247, "Avg loss": 0.8762117871083319, "Avg value loss": 0.5583571666502394, "Avg policy loss": 0.3178546446142718, "Total num played games": 18360, "Total num trained steps": 36096, "Timestamp in ms": 1700757760253, "logtype": "training_step"}
{"Total num played games": 18360, "Total num trained steps": 36106, "Timestamp in ms": 1700757782921, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.451992187500004}
{"Avg objective": 21.05546874999999, "Games time in secs": 67.90416965261102, "Avg game time in secs": 2.433872650595731, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 18432, "Total num trained steps": 36112, "Timestamp in ms": 1700757786873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9626679670567837, "Avg loss": 0.9106287087779492, "Avg value loss": 0.5740687381476164, "Avg policy loss": 0.3365599748212844, "Total num played games": 18456, "Total num trained steps": 36224, "Timestamp in ms": 1700757842357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9696575639358473, "Avg loss": 0.46963493060320616, "Avg value loss": 0.15599331544945017, "Avg policy loss": 0.31364161195233464, "Total num played games": 18456, "Total num trained steps": 36352, "Timestamp in ms": 1700757902764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966310909874946, "Avg loss": 0.9369343244470656, "Avg value loss": 0.6128969832207076, "Avg policy loss": 0.32403732917737216, "Total num played games": 18552, "Total num trained steps": 36480, "Timestamp in ms": 1700757964442, "logtype": "training_step"}
{"Avg objective": 21.184687499999985, "Games time in secs": 234.4813360888511, "Avg game time in secs": 2.5626502954110038, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.64, "agent_stopped_0": 0.42}, "Total num played games": 18560, "Total num trained steps": 36595, "Timestamp in ms": 1700758021355, "logtype": "played_game"}
{"Ratio train steps to played games": 1.963105963105963, "Avg loss": 0.5865857463795692, "Avg value loss": 0.27828641585074365, "Avg policy loss": 0.30829933553468436, "Total num played games": 18648, "Total num trained steps": 36608, "Timestamp in ms": 1700758027456, "logtype": "training_step"}
{"Total num played games": 18648, "Total num trained steps": 36610, "Timestamp in ms": 1700758048089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.692187500000003}
{"Avg objective": 20.85468749999998, "Games time in secs": 30.036035442724824, "Avg game time in secs": 2.1934892037388636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 18688, "Total num trained steps": 36615, "Timestamp in ms": 1700758051391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9598804950917628, "Avg loss": 1.3502206127159297, "Avg value loss": 0.9901154109975323, "Avg policy loss": 0.36010520718991756, "Total num played games": 18744, "Total num trained steps": 36736, "Timestamp in ms": 1700758110757, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966709346991037, "Avg loss": 0.48372665513306856, "Avg value loss": 0.16418001154670492, "Avg policy loss": 0.3195466452743858, "Total num played games": 18744, "Total num trained steps": 36864, "Timestamp in ms": 1700758171840, "logtype": "training_step"}
{"Avg objective": 21.31015624999999, "Games time in secs": 179.4061258174479, "Avg game time in secs": 2.275972907373216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 18816, "Total num trained steps": 36982, "Timestamp in ms": 1700758230797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9634819532908705, "Avg loss": 0.523297710577026, "Avg value loss": 0.2251695561571978, "Avg policy loss": 0.298128153081052, "Total num played games": 18840, "Total num trained steps": 36992, "Timestamp in ms": 1700758235493, "logtype": "training_step"}
{"Total num played games": 18840, "Total num trained steps": 37111, "Timestamp in ms": 1700758313267, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.136171875000002}
{"Ratio train steps to played games": 1.9613230476593047, "Avg loss": 0.6292225569486618, "Avg value loss": 0.32058649620739743, "Avg policy loss": 0.3086360639426857, "Total num played games": 18926, "Total num trained steps": 37120, "Timestamp in ms": 1700758319266, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966994085340093, "Avg loss": 0.6576271504163742, "Avg value loss": 0.3412771719158627, "Avg policy loss": 0.31634997483342886, "Total num played games": 18936, "Total num trained steps": 37248, "Timestamp in ms": 1700758380347, "logtype": "training_step"}
{"Avg objective": 20.325234374999983, "Games time in secs": 203.92048295028508, "Avg game time in secs": 2.7536657747405116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.63, "agent_stopped_0": 0.47}, "Total num played games": 18944, "Total num trained steps": 37363, "Timestamp in ms": 1700758434718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9637978142076502, "Avg loss": 0.5899306545034051, "Avg value loss": 0.296039026172366, "Avg policy loss": 0.2938916268758476, "Total num played games": 19032, "Total num trained steps": 37376, "Timestamp in ms": 1700758440980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705758722152165, "Avg loss": 0.6825841888785362, "Avg value loss": 0.3767808244447224, "Avg policy loss": 0.3058033643756062, "Total num played games": 19032, "Total num trained steps": 37504, "Timestamp in ms": 1700758502211, "logtype": "training_step"}
{"Avg objective": 20.672421874999987, "Games time in secs": 93.67996796779335, "Avg game time in secs": 2.0483083074213937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 19072, "Total num trained steps": 37556, "Timestamp in ms": 1700758528398, "logtype": "played_game"}
{"Total num played games": 19128, "Total num trained steps": 37611, "Timestamp in ms": 1700758573435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.49703125}
{"Avg objective": 21.815234374999985, "Games time in secs": 50.03536712564528, "Avg game time in secs": 2.4947851073375205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 19200, "Total num trained steps": 37620, "Timestamp in ms": 1700758578433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957553058676654, "Avg loss": 0.913130935980007, "Avg value loss": 0.6069319287198596, "Avg policy loss": 0.3061990109272301, "Total num played games": 19224, "Total num trained steps": 37632, "Timestamp in ms": 1700758583905, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9641593841032043, "Avg loss": 0.6669799939263612, "Avg value loss": 0.3478715345845558, "Avg policy loss": 0.3191084550926462, "Total num played games": 19224, "Total num trained steps": 37760, "Timestamp in ms": 1700758650022, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970869746150645, "Avg loss": 0.43568541342392564, "Avg value loss": 0.1378099208814092, "Avg policy loss": 0.297875490388833, "Total num played games": 19224, "Total num trained steps": 37888, "Timestamp in ms": 1700758718959, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674464341165512, "Avg loss": 0.7545851685572416, "Avg value loss": 0.4476918060099706, "Avg policy loss": 0.30689336475916207, "Total num played games": 19322, "Total num trained steps": 38016, "Timestamp in ms": 1700758783063, "logtype": "training_step"}
{"Total num played games": 19322, "Total num trained steps": 38114, "Timestamp in ms": 1700758869034, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.597500000000004}
{"Avg objective": 20.42203124999998, "Games time in secs": 292.687845505774, "Avg game time in secs": 2.718128754684585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.76, "agent_stopped_0": 0.38}, "Total num played games": 19328, "Total num trained steps": 38117, "Timestamp in ms": 1700758871121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9643629622000205, "Avg loss": 0.7735606881324202, "Avg value loss": 0.47031171998241916, "Avg policy loss": 0.30324897239916027, "Total num played games": 19418, "Total num trained steps": 38144, "Timestamp in ms": 1700758884273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970954784220826, "Avg loss": 0.6212285903748125, "Avg value loss": 0.3075962944421917, "Avg policy loss": 0.31363229104317725, "Total num played games": 19418, "Total num trained steps": 38272, "Timestamp in ms": 1700758948761, "logtype": "training_step"}
{"Avg objective": 21.84453124999998, "Games time in secs": 104.3605244755745, "Avg game time in secs": 2.0873227173578925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.41}, "Total num played games": 19456, "Total num trained steps": 38327, "Timestamp in ms": 1700758975482, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9678179768371427, "Avg loss": 0.8368290623184294, "Avg value loss": 0.5349562104092911, "Avg policy loss": 0.3018728441093117, "Total num played games": 19514, "Total num trained steps": 38400, "Timestamp in ms": 1700759010186, "logtype": "training_step"}
{"Avg objective": 21.723749999999985, "Games time in secs": 93.45443398691714, "Avg game time in secs": 2.441698557100608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 19584, "Total num trained steps": 38523, "Timestamp in ms": 1700759068937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.965112720595736, "Avg loss": 0.5163783789612353, "Avg value loss": 0.2255335422232747, "Avg policy loss": 0.29084483184851706, "Total num played games": 19606, "Total num trained steps": 38528, "Timestamp in ms": 1700759071219, "logtype": "training_step"}
{"Total num played games": 19610, "Total num trained steps": 38616, "Timestamp in ms": 1700759138284, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.375625000000003}
{"Ratio train steps to played games": 1.9615853039683344, "Avg loss": 0.9959983492735773, "Avg value loss": 0.6810690962010995, "Avg policy loss": 0.3149292485322803, "Total num played games": 19706, "Total num trained steps": 38656, "Timestamp in ms": 1700759158992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9680807875773876, "Avg loss": 0.5124705107882619, "Avg value loss": 0.21570006909314543, "Avg policy loss": 0.2967704444890842, "Total num played games": 19706, "Total num trained steps": 38784, "Timestamp in ms": 1700759225032, "logtype": "training_step"}
{"Avg objective": 21.33468749999999, "Games time in secs": 217.02704997360706, "Avg game time in secs": 2.457599227433093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 19712, "Total num trained steps": 38905, "Timestamp in ms": 1700759285964, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9661950480040424, "Avg loss": 0.46842867136001587, "Avg value loss": 0.1892056260840036, "Avg policy loss": 0.2792230462655425, "Total num played games": 19790, "Total num trained steps": 38912, "Timestamp in ms": 1700759288864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9713189254696022, "Avg loss": 0.8478057200554758, "Avg value loss": 0.549784800154157, "Avg policy loss": 0.2980209196684882, "Total num played games": 19804, "Total num trained steps": 39040, "Timestamp in ms": 1700759352637, "logtype": "training_step"}
{"Avg objective": 21.37812499999999, "Games time in secs": 97.1231477688998, "Avg game time in secs": 2.267152251355583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 19840, "Total num trained steps": 39101, "Timestamp in ms": 1700759383087, "logtype": "played_game"}
{"Total num played games": 19904, "Total num trained steps": 39119, "Timestamp in ms": 1700759410953, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.050625}
{"Avg objective": 21.20921874999999, "Games time in secs": 31.562754912301898, "Avg game time in secs": 2.449374591888045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.61}, "Total num played games": 19968, "Total num trained steps": 39127, "Timestamp in ms": 1700759414650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.95835, "Avg loss": 1.0732216802425683, "Avg value loss": 0.7712342362501658, "Avg policy loss": 0.3019874389283359, "Total num played games": 20000, "Total num trained steps": 39168, "Timestamp in ms": 1700759435497, "logtype": "training_step"}
{"Ratio train steps to played games": 1.96475, "Avg loss": 0.6038500107824802, "Avg value loss": 0.2931164789479226, "Avg policy loss": 0.310733534861356, "Total num played games": 20000, "Total num trained steps": 39296, "Timestamp in ms": 1700759499792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712, "Avg loss": 0.4178285726811737, "Avg value loss": 0.13796589442063123, "Avg policy loss": 0.27986267814412713, "Total num played games": 20000, "Total num trained steps": 39424, "Timestamp in ms": 1700759564677, "logtype": "training_step"}
{"Avg objective": 22.177968749999987, "Games time in secs": 187.27319147251546, "Avg game time in secs": 2.6866012873360887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.73, "agent_stopped_0": 0.38}, "Total num played games": 20096, "Total num trained steps": 39504, "Timestamp in ms": 1700759601923, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679072544531795, "Avg loss": 1.0367888705804944, "Avg value loss": 0.7454182837973349, "Avg policy loss": 0.29137059405911714, "Total num played games": 20098, "Total num trained steps": 39552, "Timestamp in ms": 1700759625538, "logtype": "training_step"}
{"Total num played games": 20098, "Total num trained steps": 39622, "Timestamp in ms": 1700759679217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.557226562500002}
{"Ratio train steps to played games": 1.9648905615529366, "Avg loss": 0.8400687761604786, "Avg value loss": 0.5266384232090786, "Avg policy loss": 0.3134303486440331, "Total num played games": 20194, "Total num trained steps": 39680, "Timestamp in ms": 1700759708803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712785976032485, "Avg loss": 0.47973922407254577, "Avg value loss": 0.1873321948805824, "Avg policy loss": 0.292407026165165, "Total num played games": 20194, "Total num trained steps": 39808, "Timestamp in ms": 1700759775895, "logtype": "training_step"}
{"Avg objective": 21.159609374999985, "Games time in secs": 210.95401393808424, "Avg game time in secs": 2.130712790778489, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 20224, "Total num trained steps": 39882, "Timestamp in ms": 1700759812877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967678360268033, "Avg loss": 0.6904150699265301, "Avg value loss": 0.39841759466798976, "Avg policy loss": 0.2919974736869335, "Total num played games": 20296, "Total num trained steps": 39936, "Timestamp in ms": 1700759839613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9739850216791486, "Avg loss": 0.4639347216580063, "Avg value loss": 0.1805263582500629, "Avg policy loss": 0.2834083620691672, "Total num played games": 20296, "Total num trained steps": 40064, "Timestamp in ms": 1700759904245, "logtype": "training_step"}
{"Avg objective": 22.53671874999999, "Games time in secs": 102.45534137636423, "Avg game time in secs": 2.309685333617381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 20352, "Total num trained steps": 40088, "Timestamp in ms": 1700759915333, "logtype": "played_game"}
{"Total num played games": 20392, "Total num trained steps": 40125, "Timestamp in ms": 1700759952852, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.360625000000002}
{"Avg objective": 21.027968749999985, "Games time in secs": 42.50802051834762, "Avg game time in secs": 2.3955147447413765, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 20480, "Total num trained steps": 40135, "Timestamp in ms": 1700759957841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9616848887153455, "Avg loss": 1.2556199836544693, "Avg value loss": 0.9312640197458677, "Avg policy loss": 0.3243559510447085, "Total num played games": 20488, "Total num trained steps": 40192, "Timestamp in ms": 1700759987273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9679324482623974, "Avg loss": 0.5265445290133357, "Avg value loss": 0.2135359017411247, "Avg policy loss": 0.313008630881086, "Total num played games": 20488, "Total num trained steps": 40320, "Timestamp in ms": 1700760052996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742288168684108, "Avg loss": 0.4336654949001968, "Avg value loss": 0.139634070743341, "Avg policy loss": 0.29403142572846264, "Total num played games": 20488, "Total num trained steps": 40448, "Timestamp in ms": 1700760117495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9704739704739704, "Avg loss": 0.7530883809085935, "Avg value loss": 0.4472852360922843, "Avg policy loss": 0.30580314551480114, "Total num played games": 20592, "Total num trained steps": 40576, "Timestamp in ms": 1700760183376, "logtype": "training_step"}
{"Total num played games": 20592, "Total num trained steps": 40627, "Timestamp in ms": 1700760232510, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.272617187500003}
{"Avg objective": 21.358124999999983, "Games time in secs": 277.0778639577329, "Avg game time in secs": 2.4331650038802763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 20608, "Total num trained steps": 40632, "Timestamp in ms": 1700760234919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967469064191802, "Avg loss": 0.8880347851663828, "Avg value loss": 0.5818573486758396, "Avg policy loss": 0.30617743683978915, "Total num played games": 20688, "Total num trained steps": 40704, "Timestamp in ms": 1700760271969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737045630317092, "Avg loss": 0.4536265847273171, "Avg value loss": 0.16072509106015787, "Avg policy loss": 0.2929014932597056, "Total num played games": 20688, "Total num trained steps": 40832, "Timestamp in ms": 1700760333790, "logtype": "training_step"}
{"Avg objective": 22.412265624999986, "Games time in secs": 117.88956236094236, "Avg game time in secs": 2.1790094026946463, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 20736, "Total num trained steps": 40872, "Timestamp in ms": 1700760352809, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9705089964399114, "Avg loss": 0.870938720414415, "Avg value loss": 0.5625140581396408, "Avg policy loss": 0.3084246611688286, "Total num played games": 20786, "Total num trained steps": 40960, "Timestamp in ms": 1700760396957, "logtype": "training_step"}
{"Avg objective": 22.321093749999996, "Games time in secs": 98.0096140652895, "Avg game time in secs": 2.4206710034777643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 20864, "Total num trained steps": 41069, "Timestamp in ms": 1700760450818, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9673913043478262, "Avg loss": 0.7027888728771359, "Avg value loss": 0.4087928571389057, "Avg policy loss": 0.29399601579643786, "Total num played games": 20884, "Total num trained steps": 41088, "Timestamp in ms": 1700760459636, "logtype": "training_step"}
{"Total num played games": 20884, "Total num trained steps": 41130, "Timestamp in ms": 1700760497078, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.15421875}
{"Ratio train steps to played games": 1.9645376549094375, "Avg loss": 1.1028247657231987, "Avg value loss": 0.786631744587794, "Avg policy loss": 0.3161930087953806, "Total num played games": 20980, "Total num trained steps": 41216, "Timestamp in ms": 1700760536653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705910390848427, "Avg loss": 0.4659368796274066, "Avg value loss": 0.18524360453011468, "Avg policy loss": 0.28069327177945524, "Total num played games": 20980, "Total num trained steps": 41344, "Timestamp in ms": 1700760597380, "logtype": "training_step"}
{"Avg objective": 20.092265624999982, "Games time in secs": 197.6690445765853, "Avg game time in secs": 2.423295138796675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 20992, "Total num trained steps": 41454, "Timestamp in ms": 1700760648489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9675016604990987, "Avg loss": 0.6746325101703405, "Avg value loss": 0.41161114076385275, "Avg policy loss": 0.26302136306185275, "Total num played games": 21078, "Total num trained steps": 41472, "Timestamp in ms": 1700760656689, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9735743429167854, "Avg loss": 0.5746790058910847, "Avg value loss": 0.2939838905003853, "Avg policy loss": 0.2806951148668304, "Total num played games": 21078, "Total num trained steps": 41600, "Timestamp in ms": 1700760719913, "logtype": "training_step"}
{"Total num played games": 21078, "Total num trained steps": 41632, "Timestamp in ms": 1700760767549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0421875}
{"Avg objective": 22.110234374999987, "Games time in secs": 122.20950865000486, "Avg game time in secs": 2.1268155984580517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 21120, "Total num trained steps": 41639, "Timestamp in ms": 1700760770699, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706715783508075, "Avg loss": 0.767824815120548, "Avg value loss": 0.4899042196921073, "Avg policy loss": 0.27792059583589435, "Total num played games": 21174, "Total num trained steps": 41728, "Timestamp in ms": 1700760812611, "logtype": "training_step"}
{"Avg objective": 20.24398437499999, "Games time in secs": 97.09462665580213, "Avg game time in secs": 2.3757288416236406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 21248, "Total num trained steps": 41847, "Timestamp in ms": 1700760867793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9676100037608124, "Avg loss": 0.5840636470820755, "Avg value loss": 0.3160329215461388, "Avg policy loss": 0.2680307248374447, "Total num played games": 21272, "Total num trained steps": 41856, "Timestamp in ms": 1700760872029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9736743136517487, "Avg loss": 0.6524033828172833, "Avg value loss": 0.3665303008747287, "Avg policy loss": 0.28587309073191136, "Total num played games": 21272, "Total num trained steps": 41984, "Timestamp in ms": 1700760932914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970566214319139, "Avg loss": 0.8049450605176389, "Avg value loss": 0.5217917118570767, "Avg policy loss": 0.28315334068611264, "Total num played games": 21370, "Total num trained steps": 42112, "Timestamp in ms": 1700760991674, "logtype": "training_step"}
{"Total num played games": 21370, "Total num trained steps": 42134, "Timestamp in ms": 1700761024065, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.20671875}
{"Avg objective": 21.496874999999985, "Games time in secs": 157.97568021155894, "Avg game time in secs": 2.5757049347739667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 21376, "Total num trained steps": 42137, "Timestamp in ms": 1700761025769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9677163887077238, "Avg loss": 0.8423434528522193, "Avg value loss": 0.5326547018485144, "Avg policy loss": 0.30968875263351947, "Total num played games": 21466, "Total num trained steps": 42240, "Timestamp in ms": 1700761072126, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9736793068107705, "Avg loss": 0.4387599884066731, "Avg value loss": 0.15407695609610528, "Avg policy loss": 0.28468303254339844, "Total num played games": 21466, "Total num trained steps": 42368, "Timestamp in ms": 1700761131509, "logtype": "training_step"}
{"Avg objective": 21.997890624999986, "Games time in secs": 132.25789878889918, "Avg game time in secs": 2.003225374399335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 21504, "Total num trained steps": 42426, "Timestamp in ms": 1700761158027, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706918938972362, "Avg loss": 0.927859689341858, "Avg value loss": 0.6276356522575952, "Avg policy loss": 0.30022404063493013, "Total num played games": 21564, "Total num trained steps": 42496, "Timestamp in ms": 1700761190005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971644000370062, "Avg loss": 0.46502086240798235, "Avg value loss": 0.17221842578146607, "Avg policy loss": 0.2928024334833026, "Total num played games": 21618, "Total num trained steps": 42624, "Timestamp in ms": 1700761249727, "logtype": "training_step"}
{"Avg objective": 21.85984374999999, "Games time in secs": 91.9502670634538, "Avg game time in secs": 2.076718786425772, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.55, "agent_stopped_0": 0.47}, "Total num played games": 21632, "Total num trained steps": 42624, "Timestamp in ms": 1700761249978, "logtype": "played_game"}
{"Total num played games": 21668, "Total num trained steps": 42637, "Timestamp in ms": 1700761276505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.73640625}
{"Avg objective": 20.85656249999998, "Games time in secs": 32.97085187397897, "Avg game time in secs": 2.568557915845304, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.71}, "Total num played games": 21760, "Total num trained steps": 42651, "Timestamp in ms": 1700761282949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9642988421246095, "Avg loss": 1.2267121474724263, "Avg value loss": 0.9108223831281066, "Avg policy loss": 0.31588977482169867, "Total num played games": 21764, "Total num trained steps": 42752, "Timestamp in ms": 1700761330180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9701801139496415, "Avg loss": 0.4641775037162006, "Avg value loss": 0.17566534137586132, "Avg policy loss": 0.2885121600702405, "Total num played games": 21764, "Total num trained steps": 42880, "Timestamp in ms": 1700761391445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9760613857746738, "Avg loss": 0.38890139875002205, "Avg value loss": 0.11465931456768885, "Avg policy loss": 0.2742420829599723, "Total num played games": 21764, "Total num trained steps": 43008, "Timestamp in ms": 1700761454529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727430714351046, "Avg loss": 0.7096189658623189, "Avg value loss": 0.41885260422714055, "Avg policy loss": 0.290766368387267, "Total num played games": 21866, "Total num trained steps": 43136, "Timestamp in ms": 1700761513982, "logtype": "training_step"}
{"Total num played games": 21866, "Total num trained steps": 43137, "Timestamp in ms": 1700761538395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6676171875}
{"Avg objective": 20.537421874999982, "Games time in secs": 258.1963607445359, "Avg game time in secs": 2.2763778240332613, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 21888, "Total num trained steps": 43144, "Timestamp in ms": 1700761541145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969902558965486, "Avg loss": 0.8751791892573237, "Avg value loss": 0.5745781877776608, "Avg policy loss": 0.3006009951932356, "Total num played games": 21962, "Total num trained steps": 43264, "Timestamp in ms": 1700761596835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757308077588562, "Avg loss": 0.3900809260085225, "Avg value loss": 0.12422309629619122, "Avg policy loss": 0.26585783204063773, "Total num played games": 21962, "Total num trained steps": 43392, "Timestamp in ms": 1700761656152, "logtype": "training_step"}
{"Avg objective": 21.85078124999999, "Games time in secs": 126.89681628905237, "Avg game time in secs": 2.1256595558224944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 22016, "Total num trained steps": 43420, "Timestamp in ms": 1700761668042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9725772822046959, "Avg loss": 1.1552896599750966, "Avg value loss": 0.8502217469504103, "Avg policy loss": 0.30506791546940804, "Total num played games": 22062, "Total num trained steps": 43520, "Timestamp in ms": 1700761715751, "logtype": "training_step"}
{"Avg objective": 22.71796874999999, "Games time in secs": 95.9950043503195, "Avg game time in secs": 2.22464611986652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 22144, "Total num trained steps": 43621, "Timestamp in ms": 1700761764037, "logtype": "played_game"}
{"Total num played games": 22160, "Total num trained steps": 43638, "Timestamp in ms": 1700761799870, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.919453125}
{"Ratio train steps to played games": 1.9611790079079798, "Avg loss": 0.9141948700416833, "Avg value loss": 0.6329307893756777, "Avg policy loss": 0.2812640756601468, "Total num played games": 22256, "Total num trained steps": 43648, "Timestamp in ms": 1700761805209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9669302659956867, "Avg loss": 1.0335756987333298, "Avg value loss": 0.7180615222314373, "Avg policy loss": 0.3155141700990498, "Total num played games": 22256, "Total num trained steps": 43776, "Timestamp in ms": 1700761867852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726815240833933, "Avg loss": 0.43284613685682416, "Avg value loss": 0.1558502071420662, "Avg policy loss": 0.27699592837598175, "Total num played games": 22256, "Total num trained steps": 43904, "Timestamp in ms": 1700761929585, "logtype": "training_step"}
{"Avg objective": 22.704687499999984, "Games time in secs": 213.1003199853003, "Avg game time in secs": 2.078442647078191, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 22272, "Total num trained steps": 44005, "Timestamp in ms": 1700761977138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9697593271897647, "Avg loss": 0.5645356604363769, "Avg value loss": 0.3044292697450146, "Avg policy loss": 0.2601063877809793, "Total num played games": 22354, "Total num trained steps": 44032, "Timestamp in ms": 1700761989895, "logtype": "training_step"}
{"Total num played games": 22354, "Total num trained steps": 44138, "Timestamp in ms": 1700762056013, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.863828125}
{"Avg objective": 20.53742187499999, "Games time in secs": 81.93934350088239, "Avg game time in secs": 2.13927204949141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 22400, "Total num trained steps": 44145, "Timestamp in ms": 1700762059077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9670378619153674, "Avg loss": 0.6375723539385945, "Avg value loss": 0.3666151860379614, "Avg policy loss": 0.2709571698214859, "Total num played games": 22450, "Total num trained steps": 44160, "Timestamp in ms": 1700762065820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972694877505568, "Avg loss": 0.6228975446429104, "Avg value loss": 0.336161136161536, "Avg policy loss": 0.28673641046043485, "Total num played games": 22450, "Total num trained steps": 44288, "Timestamp in ms": 1700762126088, "logtype": "training_step"}
{"Avg objective": 21.930937499999988, "Games time in secs": 118.66858766973019, "Avg game time in secs": 2.1400715815107105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.58, "agent_stopped_0": 0.47}, "Total num played games": 22528, "Total num trained steps": 44398, "Timestamp in ms": 1700762177746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9697977647684939, "Avg loss": 0.5983110284432769, "Avg value loss": 0.3339716152404435, "Avg policy loss": 0.26433941547293216, "Total num played games": 22548, "Total num trained steps": 44416, "Timestamp in ms": 1700762185713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755188930282066, "Avg loss": 0.49000213551335037, "Avg value loss": 0.20916469517396763, "Avg policy loss": 0.2808374419109896, "Total num played games": 22548, "Total num trained steps": 44544, "Timestamp in ms": 1700762245660, "logtype": "training_step"}
{"Avg objective": 21.70218749999998, "Games time in secs": 90.63465939462185, "Avg game time in secs": 2.2551823908579536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 22656, "Total num trained steps": 44595, "Timestamp in ms": 1700762268381, "logtype": "played_game"}
{"Total num played games": 22664, "Total num trained steps": 44639, "Timestamp in ms": 1700762311938, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.325781250000006}
{"Ratio train steps to played games": 1.9626977152899825, "Avg loss": 1.1261452161706984, "Avg value loss": 0.8297473830753006, "Avg policy loss": 0.29639782092999667, "Total num played games": 22760, "Total num trained steps": 44672, "Timestamp in ms": 1700762327114, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968365553602812, "Avg loss": 0.6527037238702178, "Avg value loss": 0.3419878339045681, "Avg policy loss": 0.3107158918865025, "Total num played games": 22760, "Total num trained steps": 44800, "Timestamp in ms": 1700762387404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9739455184534271, "Avg loss": 0.40821690927259624, "Avg value loss": 0.13133183174068108, "Avg policy loss": 0.2768850789871067, "Total num played games": 22760, "Total num trained steps": 44928, "Timestamp in ms": 1700762450642, "logtype": "training_step"}
{"Avg objective": 20.26820312499999, "Games time in secs": 222.41592397727072, "Avg game time in secs": 2.0785288486949867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 22784, "Total num trained steps": 45014, "Timestamp in ms": 1700762490797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.971254812740637, "Avg loss": 0.6456575472839177, "Avg value loss": 0.3766857719165273, "Avg policy loss": 0.26897176913917065, "Total num played games": 22856, "Total num trained steps": 45056, "Timestamp in ms": 1700762509353, "logtype": "training_step"}
{"Total num played games": 22856, "Total num trained steps": 45139, "Timestamp in ms": 1700762559813, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0117578125}
{"Avg objective": 21.09265624999999, "Games time in secs": 72.43171023204923, "Avg game time in secs": 2.172690573541331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 22912, "Total num trained steps": 45147, "Timestamp in ms": 1700762563229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9686301847333565, "Avg loss": 0.7613687580451369, "Avg value loss": 0.4715232318267226, "Avg policy loss": 0.28984552703332156, "Total num played games": 22952, "Total num trained steps": 45184, "Timestamp in ms": 1700762579863, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9741634715928895, "Avg loss": 0.4906214342918247, "Avg value loss": 0.2013662178069353, "Avg policy loss": 0.2892552186967805, "Total num played games": 22952, "Total num trained steps": 45312, "Timestamp in ms": 1700762638648, "logtype": "training_step"}
{"Avg objective": 22.15445312499999, "Games time in secs": 116.06795430742204, "Avg game time in secs": 2.182513885811204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 23040, "Total num trained steps": 45402, "Timestamp in ms": 1700762679297, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9713232104121474, "Avg loss": 0.8633627686649561, "Avg value loss": 0.5794432701659389, "Avg policy loss": 0.28391950263176113, "Total num played games": 23050, "Total num trained steps": 45440, "Timestamp in ms": 1700762697486, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976876355748373, "Avg loss": 0.456512970617041, "Avg value loss": 0.18279256694950163, "Avg policy loss": 0.27372040529735386, "Total num played games": 23050, "Total num trained steps": 45568, "Timestamp in ms": 1700762757946, "logtype": "training_step"}
{"Total num played games": 23150, "Total num trained steps": 45640, "Timestamp in ms": 1700762808038, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0302734375}
{"Avg objective": 20.57976562499998, "Games time in secs": 131.23644350096583, "Avg game time in secs": 2.407517215688131, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 23168, "Total num trained steps": 45645, "Timestamp in ms": 1700762810534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9657145315323066, "Avg loss": 1.6806633381638676, "Avg value loss": 1.380399919464253, "Avg policy loss": 0.30026341148186475, "Total num played games": 23246, "Total num trained steps": 45696, "Timestamp in ms": 1700762833881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712208552008947, "Avg loss": 0.6491643455810845, "Avg value loss": 0.3478563572280109, "Avg policy loss": 0.30130798590835184, "Total num played games": 23246, "Total num trained steps": 45824, "Timestamp in ms": 1700762893843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976727178869483, "Avg loss": 0.4163270383141935, "Avg value loss": 0.14454932225635275, "Avg policy loss": 0.2717777128564194, "Total num played games": 23246, "Total num trained steps": 45952, "Timestamp in ms": 1700762955339, "logtype": "training_step"}
{"Avg objective": 22.187499999999986, "Games time in secs": 160.5305069256574, "Avg game time in secs": 2.0155466786236502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 23296, "Total num trained steps": 45987, "Timestamp in ms": 1700762971064, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973954763536669, "Avg loss": 0.7719325693324208, "Avg value loss": 0.4830133046489209, "Avg policy loss": 0.28891925362404436, "Total num played games": 23344, "Total num trained steps": 46080, "Timestamp in ms": 1700763017395, "logtype": "training_step"}
{"Total num played games": 23344, "Total num trained steps": 46140, "Timestamp in ms": 1700763064507, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.201796875}
{"Avg objective": 22.412812499999987, "Games time in secs": 97.29378780350089, "Avg game time in secs": 2.1617535330733517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 23424, "Total num trained steps": 46149, "Timestamp in ms": 1700763068358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.971288395904437, "Avg loss": 0.808425854658708, "Avg value loss": 0.5174704629462212, "Avg policy loss": 0.29095538426190615, "Total num played games": 23440, "Total num trained steps": 46208, "Timestamp in ms": 1700763095999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9767491467576792, "Avg loss": 0.4397574190516025, "Avg value loss": 0.16033540247008204, "Avg policy loss": 0.2794220168143511, "Total num played games": 23440, "Total num trained steps": 46336, "Timestamp in ms": 1700763156433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973957005692922, "Avg loss": 0.7897293544374406, "Avg value loss": 0.5015483587048948, "Avg policy loss": 0.2881809937534854, "Total num played games": 23538, "Total num trained steps": 46464, "Timestamp in ms": 1700763215301, "logtype": "training_step"}
{"Avg objective": 20.573124999999983, "Games time in secs": 196.67305634729564, "Avg game time in secs": 2.2506575255683856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.57, "agent_stopped_0": 0.55}, "Total num played games": 23552, "Total num trained steps": 46569, "Timestamp in ms": 1700763265031, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710212369912852, "Avg loss": 0.5553273435216397, "Avg value loss": 0.27841655898373574, "Avg policy loss": 0.2769107843050733, "Total num played games": 23638, "Total num trained steps": 46592, "Timestamp in ms": 1700763276158, "logtype": "training_step"}
{"Total num played games": 23638, "Total num trained steps": 46640, "Timestamp in ms": 1700763315273, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.363867187500002}
{"Avg objective": 22.38281249999999, "Games time in secs": 52.99425673298538, "Avg game time in secs": 2.0528367997903842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 23680, "Total num trained steps": 46644, "Timestamp in ms": 1700763318026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684418976995028, "Avg loss": 0.8876020943280309, "Avg value loss": 0.5779404575005174, "Avg policy loss": 0.3096616343827918, "Total num played games": 23734, "Total num trained steps": 46720, "Timestamp in ms": 1700763353163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738771382826326, "Avg loss": 0.4298326028510928, "Avg value loss": 0.1501911958330311, "Avg policy loss": 0.27964141056872904, "Total num played games": 23734, "Total num trained steps": 46848, "Timestamp in ms": 1700763412517, "logtype": "training_step"}
{"Avg objective": 20.717187499999994, "Games time in secs": 148.1473605670035, "Avg game time in secs": 2.2531809974170756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 23808, "Total num trained steps": 46965, "Timestamp in ms": 1700763466173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9711312520980195, "Avg loss": 0.47338390722870827, "Avg value loss": 0.2194817919516936, "Avg policy loss": 0.2539021137636155, "Total num played games": 23832, "Total num trained steps": 46976, "Timestamp in ms": 1700763470948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976460221550856, "Avg loss": 0.5624585540499538, "Avg value loss": 0.2818083105958067, "Avg policy loss": 0.2806502445600927, "Total num played games": 23832, "Total num trained steps": 47104, "Timestamp in ms": 1700763529623, "logtype": "training_step"}
{"Total num played games": 23832, "Total num trained steps": 47140, "Timestamp in ms": 1700763563787, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.212187500000002}
{"Ratio train steps to played games": 1.9738799732530925, "Avg loss": 0.8568592187948525, "Avg value loss": 0.5800003650947474, "Avg policy loss": 0.2768588656326756, "Total num played games": 23928, "Total num trained steps": 47232, "Timestamp in ms": 1700763606246, "logtype": "training_step"}
{"Avg objective": 20.913359374999978, "Games time in secs": 194.97586268931627, "Avg game time in secs": 2.3228071982593974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 23936, "Total num trained steps": 47348, "Timestamp in ms": 1700763661149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970992175794906, "Avg loss": 0.5717105257790536, "Avg value loss": 0.30140762421069667, "Avg policy loss": 0.2703029017429799, "Total num played games": 24028, "Total num trained steps": 47360, "Timestamp in ms": 1700763666185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9761548064918852, "Avg loss": 0.8273686082102358, "Avg value loss": 0.5334150352864526, "Avg policy loss": 0.2939535769401118, "Total num played games": 24030, "Total num trained steps": 47488, "Timestamp in ms": 1700763727110, "logtype": "training_step"}
{"Avg objective": 20.842968749999983, "Games time in secs": 95.46409852802753, "Avg game time in secs": 2.1967815867537865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 24064, "Total num trained steps": 47553, "Timestamp in ms": 1700763756614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732697886448405, "Avg loss": 0.7656567089725286, "Avg value loss": 0.48080191091867164, "Avg policy loss": 0.28485480474773794, "Total num played games": 24130, "Total num trained steps": 47616, "Timestamp in ms": 1700763784512, "logtype": "training_step"}
{"Total num played games": 24130, "Total num trained steps": 47643, "Timestamp in ms": 1700763816117, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.634296875000004}
{"Avg objective": 21.65624999999999, "Games time in secs": 62.950440937653184, "Avg game time in secs": 2.156389418145409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 24192, "Total num trained steps": 47652, "Timestamp in ms": 1700763819564, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9707752001981342, "Avg loss": 0.7868829427752644, "Avg value loss": 0.485575478291139, "Avg policy loss": 0.30130746052600443, "Total num played games": 24226, "Total num trained steps": 47744, "Timestamp in ms": 1700763861868, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9760587798233302, "Avg loss": 0.42163385869935155, "Avg value loss": 0.14686031691962853, "Avg policy loss": 0.27477354335132986, "Total num played games": 24226, "Total num trained steps": 47872, "Timestamp in ms": 1700763924067, "logtype": "training_step"}
{"Avg objective": 20.646328124999982, "Games time in secs": 143.56855497136712, "Avg game time in secs": 2.337619069076027, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.64, "agent_stopped_0": 0.42}, "Total num played games": 24320, "Total num trained steps": 47950, "Timestamp in ms": 1700763963133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9733185331359975, "Avg loss": 0.7368877218104899, "Avg value loss": 0.4545095697976649, "Avg policy loss": 0.2823781503830105, "Total num played games": 24324, "Total num trained steps": 48000, "Timestamp in ms": 1700763987190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978580825522118, "Avg loss": 0.4255957549903542, "Avg value loss": 0.1497523387079127, "Avg policy loss": 0.2758434162242338, "Total num played games": 24324, "Total num trained steps": 48128, "Timestamp in ms": 1700764048180, "logtype": "training_step"}
{"Total num played games": 24422, "Total num trained steps": 48145, "Timestamp in ms": 1700764071110, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.192500000000003}
{"Avg objective": 20.936874999999983, "Games time in secs": 110.38020232692361, "Avg game time in secs": 2.1166051390900975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.48, "agent_stopped_0": 0.54}, "Total num played games": 24448, "Total num trained steps": 48148, "Timestamp in ms": 1700764073513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9681458520270823, "Avg loss": 1.1177784400060773, "Avg value loss": 0.8091651405557059, "Avg policy loss": 0.3086133007891476, "Total num played games": 24518, "Total num trained steps": 48256, "Timestamp in ms": 1700764122219, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9733665062403132, "Avg loss": 0.40263747656717896, "Avg value loss": 0.129252084356267, "Avg policy loss": 0.273385391687043, "Total num played games": 24518, "Total num trained steps": 48384, "Timestamp in ms": 1700764181942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785871604535443, "Avg loss": 0.35529848700389266, "Avg value loss": 0.10299424402182922, "Avg policy loss": 0.2523042418761179, "Total num played games": 24518, "Total num trained steps": 48512, "Timestamp in ms": 1700764242549, "logtype": "training_step"}
{"Avg objective": 21.53093749999999, "Games time in secs": 177.13583182357252, "Avg game time in secs": 2.0381820326001616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 24576, "Total num trained steps": 48531, "Timestamp in ms": 1700764250649, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9759099772505688, "Avg loss": 0.9258079938590527, "Avg value loss": 0.6368447522399947, "Avg policy loss": 0.28896324476227164, "Total num played games": 24616, "Total num trained steps": 48640, "Timestamp in ms": 1700764300030, "logtype": "training_step"}
{"Total num played games": 24616, "Total num trained steps": 48645, "Timestamp in ms": 1700764319903, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.010195312500002}
{"Avg objective": 21.756406249999987, "Games time in secs": 74.44409090466797, "Avg game time in secs": 2.3711934165185085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 24704, "Total num trained steps": 48656, "Timestamp in ms": 1700764325093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973454192295241, "Avg loss": 0.8188677527941763, "Avg value loss": 0.5133058346109465, "Avg policy loss": 0.3055619251681492, "Total num played games": 24712, "Total num trained steps": 48768, "Timestamp in ms": 1700764380487, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786338620912918, "Avg loss": 0.39605349325574934, "Avg value loss": 0.12015203793998808, "Avg policy loss": 0.275901454500854, "Total num played games": 24712, "Total num trained steps": 48896, "Timestamp in ms": 1700764446381, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9759774284562677, "Avg loss": 0.8195626630913466, "Avg value loss": 0.5259803754743189, "Avg policy loss": 0.29358229227364063, "Total num played games": 24810, "Total num trained steps": 49024, "Timestamp in ms": 1700764505768, "logtype": "training_step"}
{"Avg objective": 22.04703124999998, "Games time in secs": 220.93205751478672, "Avg game time in secs": 2.555542198359035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 24832, "Total num trained steps": 49113, "Timestamp in ms": 1700764546025, "logtype": "played_game"}
{"Total num played games": 24910, "Total num trained steps": 49148, "Timestamp in ms": 1700764577333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.524882812500003}
{"Ratio train steps to played games": 1.9730250481695568, "Avg loss": 0.7593816323205829, "Avg value loss": 0.46635090245399624, "Avg policy loss": 0.29303073429036885, "Total num played games": 24912, "Total num trained steps": 49152, "Timestamp in ms": 1700764579457, "logtype": "training_step"}
{"Avg objective": 21.970937499999987, "Games time in secs": 34.695511139929295, "Avg game time in secs": 2.0907685938000213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 24960, "Total num trained steps": 49155, "Timestamp in ms": 1700764580721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706870351115733, "Avg loss": 1.0267845171038061, "Avg value loss": 0.70793782628607, "Avg policy loss": 0.31884667940903455, "Total num played games": 25006, "Total num trained steps": 49280, "Timestamp in ms": 1700764639808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758058066064144, "Avg loss": 0.412357586203143, "Avg value loss": 0.13106765906559303, "Avg policy loss": 0.2812899270793423, "Total num played games": 25006, "Total num trained steps": 49408, "Timestamp in ms": 1700764700393, "logtype": "training_step"}
{"Avg objective": 21.48906249999999, "Games time in secs": 166.11965763382614, "Avg game time in secs": 2.263397427086602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 25088, "Total num trained steps": 49510, "Timestamp in ms": 1700764746841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730343344220505, "Avg loss": 0.6271983154583722, "Avg value loss": 0.35488645592704415, "Avg policy loss": 0.2723118542926386, "Total num played games": 25106, "Total num trained steps": 49536, "Timestamp in ms": 1700764759470, "logtype": "training_step"}
{"Total num played games": 25106, "Total num trained steps": 49652, "Timestamp in ms": 1700764838378, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8715625}
{"Ratio train steps to played games": 1.9712233071366199, "Avg loss": 0.5336889177560806, "Avg value loss": 0.24521134776296094, "Avg policy loss": 0.28847757109906524, "Total num played games": 25194, "Total num trained steps": 49664, "Timestamp in ms": 1700764843515, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757162129989683, "Avg loss": 0.579387521604076, "Avg value loss": 0.2898494891705923, "Avg policy loss": 0.28953803749755025, "Total num played games": 25202, "Total num trained steps": 49792, "Timestamp in ms": 1700764903987, "logtype": "training_step"}
{"Avg objective": 20.944374999999983, "Games time in secs": 206.30541528202593, "Avg game time in secs": 2.256341753862216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 25216, "Total num trained steps": 49897, "Timestamp in ms": 1700764953146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731225296442687, "Avg loss": 0.6352368302177638, "Avg value loss": 0.3614110295311548, "Avg policy loss": 0.27382580004632473, "Total num played games": 25300, "Total num trained steps": 49920, "Timestamp in ms": 1700764963877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9781818181818183, "Avg loss": 0.5425249203108251, "Avg value loss": 0.2465715852449648, "Avg policy loss": 0.29595333233010024, "Total num played games": 25300, "Total num trained steps": 50048, "Timestamp in ms": 1700765025407, "logtype": "training_step"}
{"Avg objective": 21.91945312499999, "Games time in secs": 93.74190158769488, "Avg game time in secs": 2.245358593252604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 25344, "Total num trained steps": 50095, "Timestamp in ms": 1700765046888, "logtype": "played_game"}
{"Total num played games": 25404, "Total num trained steps": 50153, "Timestamp in ms": 1700765096899, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.174648437500004}
{"Avg objective": 22.253671874999988, "Games time in secs": 53.86461623199284, "Avg game time in secs": 2.305169994389871, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 25472, "Total num trained steps": 50160, "Timestamp in ms": 1700765100753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9676862745098038, "Avg loss": 0.9389085164293647, "Avg value loss": 0.6505715267267078, "Avg policy loss": 0.2883369855117053, "Total num played games": 25500, "Total num trained steps": 50176, "Timestamp in ms": 1700765107750, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726666666666666, "Avg loss": 0.579016120173037, "Avg value loss": 0.28673293587053195, "Avg policy loss": 0.2922831840114668, "Total num played games": 25500, "Total num trained steps": 50304, "Timestamp in ms": 1700765167694, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776862745098038, "Avg loss": 0.38389136153273284, "Avg value loss": 0.11293230636510998, "Avg policy loss": 0.2709590564481914, "Total num played games": 25500, "Total num trained steps": 50432, "Timestamp in ms": 1700765228954, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975115243378389, "Avg loss": 0.7078857242595404, "Avg value loss": 0.4297572264622431, "Avg policy loss": 0.2781285010278225, "Total num played games": 25598, "Total num trained steps": 50560, "Timestamp in ms": 1700765290273, "logtype": "training_step"}
{"Total num played games": 25598, "Total num trained steps": 50655, "Timestamp in ms": 1700765350676, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3153125}
{"Avg objective": 20.869609374999982, "Games time in secs": 251.55229463614523, "Avg game time in secs": 2.361924007520429, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 25600, "Total num trained steps": 50658, "Timestamp in ms": 1700765352306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727173659220052, "Avg loss": 0.770058071706444, "Avg value loss": 0.48988861159887165, "Avg policy loss": 0.2801694590598345, "Total num played games": 25694, "Total num trained steps": 50688, "Timestamp in ms": 1700765365216, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776990737137075, "Avg loss": 0.6482630255632102, "Avg value loss": 0.35244235378922895, "Avg policy loss": 0.29582066915463656, "Total num played games": 25694, "Total num trained steps": 50816, "Timestamp in ms": 1700765424018, "logtype": "training_step"}
{"Avg objective": 22.07867187499999, "Games time in secs": 101.57825503125787, "Avg game time in secs": 2.10434059544059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 25728, "Total num trained steps": 50882, "Timestamp in ms": 1700765453884, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9751861042183623, "Avg loss": 0.654629357624799, "Avg value loss": 0.37608127255225554, "Avg policy loss": 0.27854808687698096, "Total num played games": 25792, "Total num trained steps": 50944, "Timestamp in ms": 1700765485500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980110111662531, "Avg loss": 0.4132515962701291, "Avg value loss": 0.14454414567444474, "Avg policy loss": 0.2687074524583295, "Total num played games": 25792, "Total num trained steps": 51072, "Timestamp in ms": 1700765547831, "logtype": "training_step"}
{"Avg objective": 21.801328124999987, "Games time in secs": 97.51754066720605, "Avg game time in secs": 2.293546141954721, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 25856, "Total num trained steps": 51082, "Timestamp in ms": 1700765551402, "logtype": "played_game"}
{"Total num played games": 25890, "Total num trained steps": 51155, "Timestamp in ms": 1700765607966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.207734375}
{"Avg objective": 21.06015624999998, "Games time in secs": 61.88096802122891, "Avg game time in secs": 2.9624868494429393, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.75, "agent_stopped_0": 0.34}, "Total num played games": 25984, "Total num trained steps": 51166, "Timestamp in ms": 1700765613283, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9702916955283614, "Avg loss": 1.2222699192352593, "Avg value loss": 0.9111695398460142, "Avg policy loss": 0.31110037851613015, "Total num played games": 25986, "Total num trained steps": 51200, "Timestamp in ms": 1700765629604, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9751789425075041, "Avg loss": 0.5229698037728667, "Avg value loss": 0.21445250371471047, "Avg policy loss": 0.3085173030849546, "Total num played games": 25986, "Total num trained steps": 51328, "Timestamp in ms": 1700765688077, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801431540060033, "Avg loss": 0.39635665994137526, "Avg value loss": 0.11580790329026058, "Avg policy loss": 0.2805487588047981, "Total num played games": 25986, "Total num trained steps": 51456, "Timestamp in ms": 1700765748948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9775724582119307, "Avg loss": 0.7993112488184124, "Avg value loss": 0.5083642693352886, "Avg policy loss": 0.29094698175322264, "Total num played games": 26084, "Total num trained steps": 51584, "Timestamp in ms": 1700765810464, "logtype": "training_step"}
{"Avg objective": 22.104921874999988, "Games time in secs": 233.4913984183222, "Avg game time in secs": 2.303579179337248, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 26112, "Total num trained steps": 51657, "Timestamp in ms": 1700765846774, "logtype": "played_game"}
{"Total num played games": 26180, "Total num trained steps": 51657, "Timestamp in ms": 1700765863060, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7721875}
{"Avg objective": 22.478671874999986, "Games time in secs": 20.28666278347373, "Avg game time in secs": 2.1834870485326974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 26240, "Total num trained steps": 51667, "Timestamp in ms": 1700765867061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679936063327752, "Avg loss": 1.2320735163521022, "Avg value loss": 0.9422829382820055, "Avg policy loss": 0.289790564449504, "Total num played games": 26276, "Total num trained steps": 51712, "Timestamp in ms": 1700765887108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9729030293804233, "Avg loss": 0.5728131870273501, "Avg value loss": 0.27168201515451074, "Avg policy loss": 0.3011311748996377, "Total num played games": 26276, "Total num trained steps": 51840, "Timestamp in ms": 1700765947081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777743948850661, "Avg loss": 0.40559891052544117, "Avg value loss": 0.12596188607858494, "Avg policy loss": 0.2796370229916647, "Total num played games": 26276, "Total num trained steps": 51968, "Timestamp in ms": 1700766008076, "logtype": "training_step"}
{"Avg objective": 21.042031249999983, "Games time in secs": 178.44777780771255, "Avg game time in secs": 2.605846395381377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.71}, "Total num played games": 26368, "Total num trained steps": 52052, "Timestamp in ms": 1700766045509, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9752407674224615, "Avg loss": 0.7416792295407504, "Avg value loss": 0.46439988375641406, "Avg policy loss": 0.2772793472977355, "Total num played games": 26374, "Total num trained steps": 52096, "Timestamp in ms": 1700766065737, "logtype": "training_step"}
{"Total num played games": 26374, "Total num trained steps": 52157, "Timestamp in ms": 1700766112608, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.64703125}
{"Ratio train steps to played games": 1.972912731394031, "Avg loss": 0.8112781725358218, "Avg value loss": 0.5049442359013483, "Avg policy loss": 0.3063339334912598, "Total num played games": 26470, "Total num trained steps": 52224, "Timestamp in ms": 1700766143073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777483944087646, "Avg loss": 0.4440003503113985, "Avg value loss": 0.15128895337693393, "Avg policy loss": 0.29271139681804925, "Total num played games": 26470, "Total num trained steps": 52352, "Timestamp in ms": 1700766202919, "logtype": "training_step"}
{"Avg objective": 21.794531249999988, "Games time in secs": 195.3412359841168, "Avg game time in secs": 2.24905879572907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.5, "agent_stopped_0": 0.56}, "Total num played games": 26496, "Total num trained steps": 52432, "Timestamp in ms": 1700766240850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975271002710027, "Avg loss": 0.8203768800012767, "Avg value loss": 0.5338040856877342, "Avg policy loss": 0.286572796641849, "Total num played games": 26568, "Total num trained steps": 52480, "Timestamp in ms": 1700766262933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9800888286660645, "Avg loss": 0.44942611712031066, "Avg value loss": 0.1588324080221355, "Avg policy loss": 0.29059370642062277, "Total num played games": 26568, "Total num trained steps": 52608, "Timestamp in ms": 1700766324373, "logtype": "training_step"}
{"Avg objective": 21.58640624999999, "Games time in secs": 93.31104126013815, "Avg game time in secs": 2.238114159263205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 26624, "Total num trained steps": 52630, "Timestamp in ms": 1700766334162, "logtype": "played_game"}
{"Total num played games": 26666, "Total num trained steps": 52660, "Timestamp in ms": 1700766365387, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.616132812500002}
{"Avg objective": 22.267812499999984, "Games time in secs": 36.33945946954191, "Avg game time in secs": 2.4740799578576116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 26752, "Total num trained steps": 52671, "Timestamp in ms": 1700766370501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9705178985128167, "Avg loss": 1.2055147632490844, "Avg value loss": 0.8806758823338896, "Avg policy loss": 0.32483887777198106, "Total num played games": 26762, "Total num trained steps": 52736, "Timestamp in ms": 1700766400205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9753007996412824, "Avg loss": 0.44597730226814747, "Avg value loss": 0.15807213797234, "Avg policy loss": 0.28790516045410186, "Total num played games": 26762, "Total num trained steps": 52864, "Timestamp in ms": 1700766461902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801210671848144, "Avg loss": 0.36783073865808547, "Avg value loss": 0.10154804898775183, "Avg policy loss": 0.2662826899904758, "Total num played games": 26762, "Total num trained steps": 52992, "Timestamp in ms": 1700766526426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777719860004468, "Avg loss": 0.7023287839256227, "Avg value loss": 0.4058101199916564, "Avg policy loss": 0.29651866760104895, "Total num played games": 26858, "Total num trained steps": 53120, "Timestamp in ms": 1700766583897, "logtype": "training_step"}
{"Total num played games": 26858, "Total num trained steps": 53162, "Timestamp in ms": 1700766619772, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0864453125}
{"Avg objective": 21.450781249999984, "Games time in secs": 251.81791483610868, "Avg game time in secs": 2.381263284027227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.53}, "Total num played games": 26880, "Total num trained steps": 53166, "Timestamp in ms": 1700766622319, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754767381464717, "Avg loss": 0.6335859519895166, "Avg value loss": 0.34228592773433775, "Avg policy loss": 0.2913000202970579, "Total num played games": 26954, "Total num trained steps": 53248, "Timestamp in ms": 1700766659798, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802626697336203, "Avg loss": 0.3935189167968929, "Avg value loss": 0.11715648724930361, "Avg policy loss": 0.27636242925655097, "Total num played games": 26954, "Total num trained steps": 53376, "Timestamp in ms": 1700766719879, "logtype": "training_step"}
{"Avg objective": 19.944531249999986, "Games time in secs": 109.79000889882445, "Avg game time in secs": 2.1435637131216936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 27008, "Total num trained steps": 53404, "Timestamp in ms": 1700766732109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776373179566793, "Avg loss": 0.8113027501385659, "Avg value loss": 0.5068841351894662, "Avg policy loss": 0.30441861611325294, "Total num played games": 27054, "Total num trained steps": 53504, "Timestamp in ms": 1700766779439, "logtype": "training_step"}
{"Avg objective": 22.073906249999986, "Games time in secs": 94.68976104073226, "Avg game time in secs": 2.3652750195469707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 27136, "Total num trained steps": 53605, "Timestamp in ms": 1700766826799, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975213612256924, "Avg loss": 0.6378815919160843, "Avg value loss": 0.34424771211342886, "Avg policy loss": 0.29363388114143163, "Total num played games": 27152, "Total num trained steps": 53632, "Timestamp in ms": 1700766838853, "logtype": "training_step"}
{"Total num played games": 27152, "Total num trained steps": 53663, "Timestamp in ms": 1700766883044, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.182773437500003}
{"Ratio train steps to played games": 1.9729521432765706, "Avg loss": 0.8239912474527955, "Avg value loss": 0.4984235264128074, "Avg policy loss": 0.3255677216220647, "Total num played games": 27248, "Total num trained steps": 53760, "Timestamp in ms": 1700766927849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776497357604228, "Avg loss": 0.4184391484595835, "Avg value loss": 0.12373258476145566, "Avg policy loss": 0.29470656637568027, "Total num played games": 27248, "Total num trained steps": 53888, "Timestamp in ms": 1700766987801, "logtype": "training_step"}
{"Avg objective": 20.870312499999986, "Games time in secs": 208.2905723489821, "Avg game time in secs": 2.396300813765265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 27264, "Total num trained steps": 53989, "Timestamp in ms": 1700767035090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9752431799897607, "Avg loss": 0.5758389395195991, "Avg value loss": 0.29764278887887485, "Avg policy loss": 0.2781961433356628, "Total num played games": 27346, "Total num trained steps": 54016, "Timestamp in ms": 1700767046708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979960506106926, "Avg loss": 0.502950060646981, "Avg value loss": 0.21765089803375304, "Avg policy loss": 0.2852991627296433, "Total num played games": 27346, "Total num trained steps": 54144, "Timestamp in ms": 1700767106488, "logtype": "training_step"}
{"Total num played games": 27346, "Total num trained steps": 54165, "Timestamp in ms": 1700767132345, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4925390625}
{"Avg objective": 21.150781249999984, "Games time in secs": 100.56696205027401, "Avg game time in secs": 2.2944956975843525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 27392, "Total num trained steps": 54173, "Timestamp in ms": 1700767135657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776619779899425, "Avg loss": 0.8703091028146446, "Avg value loss": 0.5769950262329075, "Avg policy loss": 0.29331407276913524, "Total num played games": 27442, "Total num trained steps": 54272, "Timestamp in ms": 1700767181116, "logtype": "training_step"}
{"Avg objective": 21.65054687499999, "Games time in secs": 96.34758937172592, "Avg game time in secs": 2.28687621957215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 27520, "Total num trained steps": 54381, "Timestamp in ms": 1700767232005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.7274759409483522, "Avg value loss": 0.459413260105066, "Avg policy loss": 0.26806268747895956, "Total num played games": 27540, "Total num trained steps": 54400, "Timestamp in ms": 1700767240682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979920116194626, "Avg loss": 0.5513510475866497, "Avg value loss": 0.26999286602949724, "Avg policy loss": 0.28135818103328347, "Total num played games": 27540, "Total num trained steps": 54528, "Timestamp in ms": 1700767300992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9773878437047756, "Avg loss": 0.78001509886235, "Avg value loss": 0.49972449900815263, "Avg policy loss": 0.2802905988646671, "Total num played games": 27640, "Total num trained steps": 54656, "Timestamp in ms": 1700767360327, "logtype": "training_step"}
{"Total num played games": 27640, "Total num trained steps": 54668, "Timestamp in ms": 1700767397545, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.975}
{"Avg objective": 21.68078124999998, "Games time in secs": 167.92746712639928, "Avg game time in secs": 2.504803774470929, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 27648, "Total num trained steps": 54672, "Timestamp in ms": 1700767399932, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9751586385924431, "Avg loss": 0.7625569649972022, "Avg value loss": 0.4814190295874141, "Avg policy loss": 0.28113793721422553, "Total num played games": 27736, "Total num trained steps": 54784, "Timestamp in ms": 1700767452281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797735794635132, "Avg loss": 0.35318917874246836, "Avg value loss": 0.09800161037128419, "Avg policy loss": 0.2551875681383535, "Total num played games": 27736, "Total num trained steps": 54912, "Timestamp in ms": 1700767512321, "logtype": "training_step"}
{"Avg objective": 22.833593749999988, "Games time in secs": 137.36825703643262, "Avg game time in secs": 1.9121138379559852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.51}, "Total num played games": 27776, "Total num trained steps": 54967, "Timestamp in ms": 1700767537301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774017388805059, "Avg loss": 0.773916688747704, "Avg value loss": 0.5088146667112596, "Avg policy loss": 0.26510202535428107, "Total num played games": 27834, "Total num trained steps": 55040, "Timestamp in ms": 1700767571492, "logtype": "training_step"}
{"Avg objective": 21.17851562499999, "Games time in secs": 91.04779348149896, "Avg game time in secs": 2.208565054592327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 27904, "Total num trained steps": 55164, "Timestamp in ms": 1700767628349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975046541601031, "Avg loss": 0.41635065944865346, "Avg value loss": 0.15984003368066624, "Avg policy loss": 0.25651062303222716, "Total num played games": 27928, "Total num trained steps": 55168, "Timestamp in ms": 1700767631576, "logtype": "training_step"}
{"Total num played games": 27932, "Total num trained steps": 55168, "Timestamp in ms": 1700767644324, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.537031250000002}
{"Ratio train steps to played games": 1.972848579991437, "Avg loss": 1.0431633677799255, "Avg value loss": 0.7581067190039903, "Avg policy loss": 0.2850566569250077, "Total num played games": 28028, "Total num trained steps": 55296, "Timestamp in ms": 1700767702802, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977415441701156, "Avg loss": 0.37094671628437936, "Avg value loss": 0.11723357799928635, "Avg policy loss": 0.25371314107906073, "Total num played games": 28028, "Total num trained steps": 55424, "Timestamp in ms": 1700767762710, "logtype": "training_step"}
{"Avg objective": 21.47914062499999, "Games time in secs": 191.82225709222257, "Avg game time in secs": 2.1858138585084816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 28032, "Total num trained steps": 55548, "Timestamp in ms": 1700767820171, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780658025922233, "Avg loss": 0.336371892131865, "Avg value loss": 0.09699197026202455, "Avg policy loss": 0.23937992204446346, "Total num played games": 28078, "Total num trained steps": 55552, "Timestamp in ms": 1700767821484, "logtype": "training_step"}
{"Total num played games": 28130, "Total num trained steps": 55668, "Timestamp in ms": 1700767910886, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.791914062500002}
{"Avg objective": 21.45523437499998, "Games time in secs": 93.81418990902603, "Avg game time in secs": 2.3859933023341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 28160, "Total num trained steps": 55676, "Timestamp in ms": 1700767913985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737327188940093, "Avg loss": 0.8546718219295144, "Avg value loss": 0.5805489346385002, "Avg policy loss": 0.2741228846134618, "Total num played games": 28210, "Total num trained steps": 55680, "Timestamp in ms": 1700767915664, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9771487281230071, "Avg loss": 0.7182257999666035, "Avg value loss": 0.42870842397678643, "Avg policy loss": 0.2895173745928332, "Total num played games": 28226, "Total num trained steps": 55808, "Timestamp in ms": 1700767974665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816835541699143, "Avg loss": 0.3489097508136183, "Avg value loss": 0.0900971572555136, "Avg policy loss": 0.25881259283050895, "Total num played games": 28226, "Total num trained steps": 55936, "Timestamp in ms": 1700768037970, "logtype": "training_step"}
{"Avg objective": 21.012890624999983, "Games time in secs": 128.98750226385891, "Avg game time in secs": 2.48484008583182, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 28288, "Total num trained steps": 55949, "Timestamp in ms": 1700768042973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793461375511934, "Avg loss": 0.7777595908846706, "Avg value loss": 0.5089818110573106, "Avg policy loss": 0.2687777717364952, "Total num played games": 28324, "Total num trained steps": 56064, "Timestamp in ms": 1700768099781, "logtype": "training_step"}
{"Avg objective": 21.491249999999983, "Games time in secs": 96.56055428646505, "Avg game time in secs": 2.427563621546142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.65}, "Total num played games": 28416, "Total num trained steps": 56145, "Timestamp in ms": 1700768139534, "logtype": "played_game"}
{"Total num played games": 28422, "Total num trained steps": 56171, "Timestamp in ms": 1700768168470, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.98640625}
{"Ratio train steps to played games": 1.970404656708044, "Avg loss": 0.8743649139069021, "Avg value loss": 0.6075040733849164, "Avg policy loss": 0.2668608493404463, "Total num played games": 28518, "Total num trained steps": 56192, "Timestamp in ms": 1700768179676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748930500035065, "Avg loss": 0.6445161025039852, "Avg value loss": 0.342865057871677, "Avg policy loss": 0.3016510450979695, "Total num played games": 28518, "Total num trained steps": 56320, "Timestamp in ms": 1700768244948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793463777263482, "Avg loss": 0.3732656096108258, "Avg value loss": 0.10696723719593138, "Avg policy loss": 0.26629836892243475, "Total num played games": 28518, "Total num trained steps": 56448, "Timestamp in ms": 1700768309621, "logtype": "training_step"}
{"Avg objective": 20.728671874999986, "Games time in secs": 209.6193842291832, "Avg game time in secs": 2.231550543787307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 28544, "Total num trained steps": 56529, "Timestamp in ms": 1700768349154, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977075761811574, "Avg loss": 0.5245664289686829, "Avg value loss": 0.2602387166407425, "Avg policy loss": 0.2643277127062902, "Total num played games": 28616, "Total num trained steps": 56576, "Timestamp in ms": 1700768371998, "logtype": "training_step"}
{"Total num played games": 28616, "Total num trained steps": 56673, "Timestamp in ms": 1700768443181, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.894687500000003}
{"Avg objective": 21.783359374999986, "Games time in secs": 97.64813140034676, "Avg game time in secs": 2.31484043673845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 28672, "Total num trained steps": 56680, "Timestamp in ms": 1700768446802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9748885483421565, "Avg loss": 0.5615304039092734, "Avg value loss": 0.2877540440240409, "Avg policy loss": 0.27377635973971337, "Total num played games": 28712, "Total num trained steps": 56704, "Timestamp in ms": 1700768458774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979346614655893, "Avg loss": 0.5184057042934, "Avg value loss": 0.22913321142550558, "Avg policy loss": 0.289272494148463, "Total num played games": 28712, "Total num trained steps": 56832, "Timestamp in ms": 1700768521077, "logtype": "training_step"}
{"Avg objective": 23.03054687499998, "Games time in secs": 117.37999489344656, "Avg game time in secs": 2.525764388949028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 28800, "Total num trained steps": 56922, "Timestamp in ms": 1700768564182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9770565775772302, "Avg loss": 1.0619871322996914, "Avg value loss": 0.7817411738797091, "Avg policy loss": 0.2802459691883996, "Total num played games": 28810, "Total num trained steps": 56960, "Timestamp in ms": 1700768583379, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814994793474487, "Avg loss": 0.583706290461123, "Avg value loss": 0.27779043751070276, "Avg policy loss": 0.3059158507967368, "Total num played games": 28810, "Total num trained steps": 57088, "Timestamp in ms": 1700768651144, "logtype": "training_step"}
{"Total num played games": 28908, "Total num trained steps": 57173, "Timestamp in ms": 1700768709132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.727968750000002}
{"Avg objective": 20.570312499999986, "Games time in secs": 147.40794837102294, "Avg game time in secs": 2.254263742812327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 28928, "Total num trained steps": 57179, "Timestamp in ms": 1700768711590, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972693421597021, "Avg loss": 1.0784315187484026, "Avg value loss": 0.7740362471085973, "Avg policy loss": 0.3043952689040452, "Total num played games": 29004, "Total num trained steps": 57216, "Timestamp in ms": 1700768731530, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770721279823473, "Avg loss": 0.49569091224111617, "Avg value loss": 0.19287983188405633, "Avg policy loss": 0.3028110797749832, "Total num played games": 29004, "Total num trained steps": 57344, "Timestamp in ms": 1700768796272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814853123707075, "Avg loss": 0.37674418184906244, "Avg value loss": 0.11027813167311251, "Avg policy loss": 0.26646605075802654, "Total num played games": 29004, "Total num trained steps": 57472, "Timestamp in ms": 1700768860957, "logtype": "training_step"}
{"Avg objective": 21.19039062499999, "Games time in secs": 164.01866368576884, "Avg game time in secs": 2.1715584573103115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 29056, "Total num trained steps": 57503, "Timestamp in ms": 1700768875609, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792454126864134, "Avg loss": 0.547286361688748, "Avg value loss": 0.26503792649600655, "Avg policy loss": 0.2822484408970922, "Total num played games": 29102, "Total num trained steps": 57600, "Timestamp in ms": 1700768923796, "logtype": "training_step"}
{"Total num played games": 29102, "Total num trained steps": 57673, "Timestamp in ms": 1700768973677, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.006171875}
{"Avg objective": 21.27468749999999, "Games time in secs": 102.37178034335375, "Avg game time in secs": 2.2523740856413497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 29184, "Total num trained steps": 57680, "Timestamp in ms": 1700768977981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97708747174464, "Avg loss": 0.6283047925680876, "Avg value loss": 0.3489104888867587, "Avg policy loss": 0.2793943115975708, "Total num played games": 29198, "Total num trained steps": 57728, "Timestamp in ms": 1700769004284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814713336529899, "Avg loss": 0.4216887929942459, "Avg value loss": 0.14314169524004683, "Avg policy loss": 0.27854709955863655, "Total num played games": 29198, "Total num trained steps": 57856, "Timestamp in ms": 1700769069544, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792121791370836, "Avg loss": 0.7173634029459208, "Avg value loss": 0.4275316995626781, "Avg policy loss": 0.28983170131687075, "Total num played games": 29296, "Total num trained steps": 57984, "Timestamp in ms": 1700769132524, "logtype": "training_step"}
{"Avg objective": 20.73234374999998, "Games time in secs": 205.14317223615944, "Avg game time in secs": 2.420683550531976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 29312, "Total num trained steps": 58084, "Timestamp in ms": 1700769183124, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769680887255903, "Avg loss": 0.6398113905452192, "Avg value loss": 0.35182214560336433, "Avg policy loss": 0.28798924351576716, "Total num played games": 29394, "Total num trained steps": 58112, "Timestamp in ms": 1700769196098, "logtype": "training_step"}
{"Total num played games": 29394, "Total num trained steps": 58176, "Timestamp in ms": 1700769243533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.227187500000003}
{"Avg objective": 21.34648437499998, "Games time in secs": 63.84942462667823, "Avg game time in secs": 2.078376251971349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 29440, "Total num trained steps": 58185, "Timestamp in ms": 1700769246974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9749067480501865, "Avg loss": 0.9723780532367527, "Avg value loss": 0.6657320983940735, "Avg policy loss": 0.30664594646077603, "Total num played games": 29490, "Total num trained steps": 58240, "Timestamp in ms": 1700769274825, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792132926415733, "Avg loss": 0.4611544036306441, "Avg value loss": 0.16714136896189302, "Avg policy loss": 0.2940130326896906, "Total num played games": 29490, "Total num trained steps": 58368, "Timestamp in ms": 1700769344791, "logtype": "training_step"}
{"Avg objective": 22.59406249999999, "Games time in secs": 152.05719459056854, "Avg game time in secs": 2.3655450535879936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 29568, "Total num trained steps": 58477, "Timestamp in ms": 1700769399031, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976850287259209, "Avg loss": 0.6295834823977202, "Avg value loss": 0.3548925125505775, "Avg policy loss": 0.27469097124412656, "Total num played games": 29590, "Total num trained steps": 58496, "Timestamp in ms": 1700769408000, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812098681987158, "Avg loss": 0.5679088740143925, "Avg value loss": 0.270687929878477, "Avg policy loss": 0.29722094803582877, "Total num played games": 29590, "Total num trained steps": 58624, "Timestamp in ms": 1700769469489, "logtype": "training_step"}
{"Total num played games": 29686, "Total num trained steps": 58678, "Timestamp in ms": 1700769524045, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.235468750000003}
{"Avg objective": 21.174531249999987, "Games time in secs": 127.0109088961035, "Avg game time in secs": 2.4139998683094746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 29696, "Total num trained steps": 58683, "Timestamp in ms": 1700769526042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727016318581694, "Avg loss": 1.278211232740432, "Avg value loss": 0.9747903987881728, "Avg policy loss": 0.30342083133291453, "Total num played games": 29782, "Total num trained steps": 58752, "Timestamp in ms": 1700769559502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9769995299173997, "Avg loss": 0.44726139889098704, "Avg value loss": 0.16318277339451015, "Avg policy loss": 0.28407862572930753, "Total num played games": 29782, "Total num trained steps": 58880, "Timestamp in ms": 1700769628306, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812974279766302, "Avg loss": 0.354082225356251, "Avg value loss": 0.09917897239211015, "Avg policy loss": 0.25490325212012976, "Total num played games": 29782, "Total num trained steps": 59008, "Timestamp in ms": 1700769695276, "logtype": "training_step"}
{"Avg objective": 20.88874999999998, "Games time in secs": 195.00497747212648, "Avg game time in secs": 1.9798189369757893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 29824, "Total num trained steps": 59058, "Timestamp in ms": 1700769721047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789840037480757, "Avg loss": 0.7620170849841088, "Avg value loss": 0.4849394664634019, "Avg policy loss": 0.27707761886995286, "Total num played games": 29882, "Total num trained steps": 59136, "Timestamp in ms": 1700769760341, "logtype": "training_step"}
{"Total num played games": 29882, "Total num trained steps": 59181, "Timestamp in ms": 1700769817821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.48703125}
{"Avg objective": 21.780468749999983, "Games time in secs": 100.68207654356956, "Avg game time in secs": 2.2553475398017326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 29952, "Total num trained steps": 59190, "Timestamp in ms": 1700769821729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769164053639336, "Avg loss": 0.6977689492050558, "Avg value loss": 0.4079676881665364, "Avg policy loss": 0.28980125521775335, "Total num played games": 29978, "Total num trained steps": 59264, "Timestamp in ms": 1700769861061, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811528454199747, "Avg loss": 0.39237000490538776, "Avg value loss": 0.11860576248727739, "Avg policy loss": 0.2737642442807555, "Total num played games": 29978, "Total num trained steps": 59392, "Timestamp in ms": 1700769927685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789865673626812, "Avg loss": 0.6640769994119182, "Avg value loss": 0.39442625441006385, "Avg policy loss": 0.2696507411310449, "Total num played games": 30076, "Total num trained steps": 59520, "Timestamp in ms": 1700769989183, "logtype": "training_step"}
{"Avg objective": 21.85843749999998, "Games time in secs": 229.4277576636523, "Avg game time in secs": 2.57100791814446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 30080, "Total num trained steps": 59643, "Timestamp in ms": 1700770051157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777188328912467, "Avg loss": 0.38531999941915274, "Avg value loss": 0.12421166017884389, "Avg policy loss": 0.2611083382507786, "Total num played games": 30158, "Total num trained steps": 59648, "Timestamp in ms": 1700770053333, "logtype": "training_step"}
{"Total num played games": 30172, "Total num trained steps": 59683, "Timestamp in ms": 1700770094022, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.226992187500002}
{"Avg objective": 22.918749999999985, "Games time in secs": 45.980104960501194, "Avg game time in secs": 2.168072368207504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 30208, "Total num trained steps": 59687, "Timestamp in ms": 1700770097138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9748909739659046, "Avg loss": 0.9203247718978673, "Avg value loss": 0.6400464010657743, "Avg policy loss": 0.28027837781701237, "Total num played games": 30268, "Total num trained steps": 59776, "Timestamp in ms": 1700770142568, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790868243689705, "Avg loss": 0.41686026891693473, "Avg value loss": 0.1618204855476506, "Avg policy loss": 0.2550397802842781, "Total num played games": 30268, "Total num trained steps": 59904, "Timestamp in ms": 1700770206077, "logtype": "training_step"}
{"Avg objective": 21.15984374999999, "Games time in secs": 176.8305943608284, "Avg game time in secs": 2.265157530651777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 30336, "Total num trained steps": 60031, "Timestamp in ms": 1700770273968, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779571663920923, "Avg loss": 0.35641864605713636, "Avg value loss": 0.10878155694808811, "Avg policy loss": 0.24763708736281842, "Total num played games": 30350, "Total num trained steps": 60032, "Timestamp in ms": 1700770274450, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811631429888692, "Avg loss": 0.7997839322779328, "Avg value loss": 0.5297550835530274, "Avg policy loss": 0.2700288377236575, "Total num played games": 30366, "Total num trained steps": 60160, "Timestamp in ms": 1700770335708, "logtype": "training_step"}
{"Total num played games": 30366, "Total num trained steps": 60184, "Timestamp in ms": 1700770384393, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.02546875}
{"Ratio train steps to played games": 1.9790887006762523, "Avg loss": 0.6610245006158948, "Avg value loss": 0.39884952444117516, "Avg policy loss": 0.2621749823447317, "Total num played games": 30462, "Total num trained steps": 60288, "Timestamp in ms": 1700770434180, "logtype": "training_step"}
{"Avg objective": 20.170234374999982, "Games time in secs": 220.69759826362133, "Avg game time in secs": 2.4745768395951018, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.69, "agent_stopped_0": 0.41}, "Total num played games": 30464, "Total num trained steps": 60415, "Timestamp in ms": 1700770494666, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825424952418456, "Avg loss": 0.32865234930068254, "Avg value loss": 0.08583987739984877, "Avg policy loss": 0.2428124729776755, "Total num played games": 30474, "Total num trained steps": 60416, "Timestamp in ms": 1700770495135, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809894640403114, "Avg loss": 0.7370025243144482, "Avg value loss": 0.47256552416365594, "Avg policy loss": 0.26443699619267136, "Total num played games": 30562, "Total num trained steps": 60544, "Timestamp in ms": 1700770558859, "logtype": "training_step"}
{"Avg objective": 21.30781249999998, "Games time in secs": 100.84694019332528, "Avg game time in secs": 2.0857596880814526, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 30592, "Total num trained steps": 60616, "Timestamp in ms": 1700770595513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978994063539696, "Avg loss": 0.7941186052048579, "Avg value loss": 0.5349686676636338, "Avg policy loss": 0.2591499269474298, "Total num played games": 30658, "Total num trained steps": 60672, "Timestamp in ms": 1700770622328, "logtype": "training_step"}
{"Total num played games": 30658, "Total num trained steps": 60684, "Timestamp in ms": 1700770655799, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4426953125}
{"Avg objective": 21.495312499999994, "Games time in secs": 63.857561660930514, "Avg game time in secs": 2.206623203557683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.45}, "Total num played games": 30720, "Total num trained steps": 60691, "Timestamp in ms": 1700770659371, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769786044091826, "Avg loss": 0.7204674556851387, "Avg value loss": 0.4486882031778805, "Avg policy loss": 0.2717792507028207, "Total num played games": 30754, "Total num trained steps": 60800, "Timestamp in ms": 1700770712986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811406646289913, "Avg loss": 0.3579284860752523, "Avg value loss": 0.11415385210420936, "Avg policy loss": 0.24377463199198246, "Total num played games": 30754, "Total num trained steps": 60928, "Timestamp in ms": 1700770776274, "logtype": "training_step"}
{"Avg objective": 21.792187499999986, "Games time in secs": 153.97676960751414, "Avg game time in secs": 2.4454252622672357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.68, "agent_stopped_0": 0.42}, "Total num played games": 30848, "Total num trained steps": 61005, "Timestamp in ms": 1700770813348, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791247974068071, "Avg loss": 0.7391780795296654, "Avg value loss": 0.4900902964582201, "Avg policy loss": 0.2490877746604383, "Total num played games": 30850, "Total num trained steps": 61056, "Timestamp in ms": 1700770837420, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832414910858995, "Avg loss": 0.36430412344634533, "Avg value loss": 0.12334585405187681, "Avg policy loss": 0.2409582685213536, "Total num played games": 30850, "Total num trained steps": 61184, "Timestamp in ms": 1700770900480, "logtype": "training_step"}
{"Total num played games": 30850, "Total num trained steps": 61184, "Timestamp in ms": 1700770915429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.823437500000004}
{"Ratio train steps to played games": 1.9812576746590835, "Avg loss": 0.7402870154473931, "Avg value loss": 0.4801835585385561, "Avg policy loss": 0.26010345737449825, "Total num played games": 30946, "Total num trained steps": 61312, "Timestamp in ms": 1700770977842, "logtype": "training_step"}
{"Avg objective": 20.559609374999987, "Games time in secs": 199.14997807331383, "Avg game time in secs": 2.1245660070417216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 30976, "Total num trained steps": 61384, "Timestamp in ms": 1700771012498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789989048508665, "Avg loss": 0.6454121391288936, "Avg value loss": 0.39480935386382043, "Avg policy loss": 0.250602787360549, "Total num played games": 31046, "Total num trained steps": 61440, "Timestamp in ms": 1700771042340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831218192359725, "Avg loss": 0.36263862205669284, "Avg value loss": 0.1207512179389596, "Avg policy loss": 0.24188740563113242, "Total num played games": 31046, "Total num trained steps": 61568, "Timestamp in ms": 1700771109388, "logtype": "training_step"}
{"Avg objective": 21.58882812499999, "Games time in secs": 105.25193896144629, "Avg game time in secs": 2.069069483244675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 31104, "Total num trained steps": 61585, "Timestamp in ms": 1700771117750, "logtype": "played_game"}
{"Total num played games": 31142, "Total num trained steps": 61687, "Timestamp in ms": 1700771192875, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9097265625}
{"Ratio train steps to played games": 1.9755363432596862, "Avg loss": 0.74901665863581, "Avg value loss": 0.4961487115942873, "Avg policy loss": 0.2528679483802989, "Total num played games": 31230, "Total num trained steps": 61696, "Timestamp in ms": 1700771197763, "logtype": "training_step"}
{"Avg objective": 21.51484374999998, "Games time in secs": 80.01333319954574, "Avg game time in secs": 2.3852032126305858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.72, "agent_stopped_0": 0.38}, "Total num played games": 31232, "Total num trained steps": 61696, "Timestamp in ms": 1700771197763, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9790959728535757, "Avg loss": 0.7188775190152228, "Avg value loss": 0.44242239999584854, "Avg policy loss": 0.27645511529408395, "Total num played games": 31238, "Total num trained steps": 61824, "Timestamp in ms": 1700771263620, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831935463217876, "Avg loss": 0.3325426591327414, "Avg value loss": 0.08777368153096177, "Avg policy loss": 0.2447689773980528, "Total num played games": 31238, "Total num trained steps": 61952, "Timestamp in ms": 1700771326571, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9812344418203869, "Avg loss": 0.6895066604483873, "Avg value loss": 0.4313547917699907, "Avg policy loss": 0.2581518670776859, "Total num played games": 31334, "Total num trained steps": 62080, "Timestamp in ms": 1700771391188, "logtype": "training_step"}
{"Avg objective": 20.712968749999977, "Games time in secs": 232.64426689781249, "Avg game time in secs": 2.1450537099444773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 31360, "Total num trained steps": 62160, "Timestamp in ms": 1700771430408, "logtype": "played_game"}
{"Total num played games": 31430, "Total num trained steps": 62188, "Timestamp in ms": 1700771461365, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1325}
{"Avg objective": 20.432031249999984, "Games time in secs": 34.43294164724648, "Avg game time in secs": 2.047761872468982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.48}, "Total num played games": 31488, "Total num trained steps": 62194, "Timestamp in ms": 1700771464841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732284463617331, "Avg loss": 0.675173758296296, "Avg value loss": 0.423193525231909, "Avg policy loss": 0.25198023475240916, "Total num played games": 31526, "Total num trained steps": 62208, "Timestamp in ms": 1700771471534, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977256867347586, "Avg loss": 0.5624857326038182, "Avg value loss": 0.2908106536488049, "Avg policy loss": 0.27167507470585406, "Total num played games": 31526, "Total num trained steps": 62336, "Timestamp in ms": 1700771533315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813170081837215, "Avg loss": 0.3341991992201656, "Avg value loss": 0.09609115158673376, "Avg policy loss": 0.23810804774984717, "Total num played games": 31526, "Total num trained steps": 62464, "Timestamp in ms": 1700771596996, "logtype": "training_step"}
{"Avg objective": 21.488281249999986, "Games time in secs": 173.1961132735014, "Avg game time in secs": 2.226549313549185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 31616, "Total num trained steps": 62548, "Timestamp in ms": 1700771638037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793814432989691, "Avg loss": 0.670242459513247, "Avg value loss": 0.4338688613206614, "Avg policy loss": 0.23637360031716526, "Total num played games": 31622, "Total num trained steps": 62592, "Timestamp in ms": 1700771659048, "logtype": "training_step"}
{"Total num played games": 31622, "Total num trained steps": 62691, "Timestamp in ms": 1700771721701, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9005859375}
{"Ratio train steps to played games": 1.977394539378271, "Avg loss": 0.8038370844442397, "Avg value loss": 0.5523638829472475, "Avg policy loss": 0.25147319538518786, "Total num played games": 31718, "Total num trained steps": 62720, "Timestamp in ms": 1700771736741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814301027807555, "Avg loss": 0.5659510067198426, "Avg value loss": 0.3065521760727279, "Avg policy loss": 0.25939883186947554, "Total num played games": 31718, "Total num trained steps": 62848, "Timestamp in ms": 1700771800776, "logtype": "training_step"}
{"Avg objective": 22.19195312499998, "Games time in secs": 200.77460610680282, "Avg game time in secs": 2.091833507089177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 31744, "Total num trained steps": 62927, "Timestamp in ms": 1700771838812, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9794744452127995, "Avg loss": 0.8307243615854532, "Avg value loss": 0.5829891333705746, "Avg policy loss": 0.24773522710893303, "Total num played games": 31814, "Total num trained steps": 62976, "Timestamp in ms": 1700771862469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835292638461055, "Avg loss": 0.4032484784256667, "Avg value loss": 0.16204632818698883, "Avg policy loss": 0.2412021477939561, "Total num played games": 31814, "Total num trained steps": 63104, "Timestamp in ms": 1700771923896, "logtype": "training_step"}
{"Avg objective": 21.604453124999985, "Games time in secs": 93.1134924236685, "Avg game time in secs": 2.023028665134916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 31872, "Total num trained steps": 63121, "Timestamp in ms": 1700771931926, "logtype": "played_game"}
{"Total num played games": 31910, "Total num trained steps": 63192, "Timestamp in ms": 1700771981333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.440546875000003}
{"Avg objective": 21.030859374999988, "Games time in secs": 54.04739195294678, "Avg game time in secs": 2.198157361766789, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.62}, "Total num played games": 32000, "Total num trained steps": 63200, "Timestamp in ms": 1700771985973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975629569455727, "Avg loss": 0.9883455510716885, "Avg value loss": 0.723427064716816, "Avg policy loss": 0.2649184772744775, "Total num played games": 32006, "Total num trained steps": 63232, "Timestamp in ms": 1700772002048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795975754546022, "Avg loss": 0.44165267678909004, "Avg value loss": 0.1805947600514628, "Avg policy loss": 0.261057915748097, "Total num played games": 32006, "Total num trained steps": 63360, "Timestamp in ms": 1700772066545, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836280697369244, "Avg loss": 0.32285332202445716, "Avg value loss": 0.0909981969743967, "Avg policy loss": 0.23185512190684676, "Total num played games": 32006, "Total num trained steps": 63488, "Timestamp in ms": 1700772128785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816833842128216, "Avg loss": 0.776273116003722, "Avg value loss": 0.5184434900584165, "Avg policy loss": 0.25782962143421173, "Total num played games": 32102, "Total num trained steps": 63616, "Timestamp in ms": 1700772195884, "logtype": "training_step"}
{"Avg objective": 21.810703124999986, "Games time in secs": 253.15551687590778, "Avg game time in secs": 2.228805697421194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 32128, "Total num trained steps": 63695, "Timestamp in ms": 1700772239129, "logtype": "played_game"}
{"Total num played games": 32198, "Total num trained steps": 63695, "Timestamp in ms": 1700772254881, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.696015625}
{"Avg objective": 21.202343749999986, "Games time in secs": 19.003511730581522, "Avg game time in secs": 2.5791537830227753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 32256, "Total num trained steps": 63699, "Timestamp in ms": 1700772258133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9738651142627113, "Avg loss": 0.9919528015889227, "Avg value loss": 0.7264985323417932, "Avg policy loss": 0.2654542711097747, "Total num played games": 32294, "Total num trained steps": 63744, "Timestamp in ms": 1700772279076, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777977333250758, "Avg loss": 0.4665593837853521, "Avg value loss": 0.19041437708074227, "Avg policy loss": 0.27614500699564815, "Total num played games": 32294, "Total num trained steps": 63872, "Timestamp in ms": 1700772342669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817922833962964, "Avg loss": 0.3418124697636813, "Avg value loss": 0.09568317414959893, "Avg policy loss": 0.24612929311115295, "Total num played games": 32294, "Total num trained steps": 64000, "Timestamp in ms": 1700772403900, "logtype": "training_step"}
{"Avg objective": 21.263593749999988, "Games time in secs": 185.83418315462768, "Avg game time in secs": 2.2579213264980353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 32384, "Total num trained steps": 64084, "Timestamp in ms": 1700772443967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9798394566224142, "Avg loss": 0.5913564185611904, "Avg value loss": 0.3429531375586521, "Avg policy loss": 0.2484032812062651, "Total num played games": 32390, "Total num trained steps": 64128, "Timestamp in ms": 1700772464500, "logtype": "training_step"}
{"Total num played games": 32390, "Total num trained steps": 64197, "Timestamp in ms": 1700772511594, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.77234375}
{"Ratio train steps to played games": 1.9779289540109586, "Avg loss": 0.6437964588403702, "Avg value loss": 0.38108561985427514, "Avg policy loss": 0.26271084416657686, "Total num played games": 32486, "Total num trained steps": 64256, "Timestamp in ms": 1700772540960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818691128486117, "Avg loss": 0.4170519970357418, "Avg value loss": 0.16257726663025096, "Avg policy loss": 0.25447473116219044, "Total num played games": 32486, "Total num trained steps": 64384, "Timestamp in ms": 1700772602260, "logtype": "training_step"}
{"Avg objective": 20.717656249999983, "Games time in secs": 196.17428670823574, "Avg game time in secs": 2.2192509203741793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.52, "agent_stopped_0": 0.56}, "Total num played games": 32512, "Total num trained steps": 64463, "Timestamp in ms": 1700772640141, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9799889509545148, "Avg loss": 0.5599480464588851, "Avg value loss": 0.30887201105360873, "Avg policy loss": 0.2510760307777673, "Total num played games": 32582, "Total num trained steps": 64512, "Timestamp in ms": 1700772663184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839175004603768, "Avg loss": 0.369537980761379, "Avg value loss": 0.11892388615524396, "Avg policy loss": 0.2506140929181129, "Total num played games": 32582, "Total num trained steps": 64640, "Timestamp in ms": 1700772728461, "logtype": "training_step"}
{"Avg objective": 20.348124999999985, "Games time in secs": 97.67434351891279, "Avg game time in secs": 1.9651447154174093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 32640, "Total num trained steps": 64658, "Timestamp in ms": 1700772737816, "logtype": "played_game"}
{"Total num played games": 32678, "Total num trained steps": 64698, "Timestamp in ms": 1700772775046, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.363398437500003}
{"Avg objective": 20.054453124999984, "Games time in secs": 41.92794984020293, "Avg game time in secs": 2.24002669705078, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 32768, "Total num trained steps": 64708, "Timestamp in ms": 1700772779744, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761701348630012, "Avg loss": 0.9726916023064405, "Avg value loss": 0.6933880603173748, "Avg policy loss": 0.27930354326963425, "Total num played games": 32774, "Total num trained steps": 64768, "Timestamp in ms": 1700772812893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801061817294197, "Avg loss": 0.37748054624535143, "Avg value loss": 0.122192426584661, "Avg policy loss": 0.2552881195442751, "Total num played games": 32774, "Total num trained steps": 64896, "Timestamp in ms": 1700772876554, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983981204613413, "Avg loss": 0.3198569944361225, "Avg value loss": 0.08517339642276056, "Avg policy loss": 0.2346835982752964, "Total num played games": 32774, "Total num trained steps": 65024, "Timestamp in ms": 1700772939673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818701709557704, "Avg loss": 0.6645401164423674, "Avg value loss": 0.4096925492049195, "Avg policy loss": 0.25484756485093385, "Total num played games": 32874, "Total num trained steps": 65152, "Timestamp in ms": 1700773005313, "logtype": "training_step"}
{"Total num played games": 32874, "Total num trained steps": 65201, "Timestamp in ms": 1700773047933, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.513164062500003}
{"Avg objective": 21.635624999999987, "Games time in secs": 270.51324427872896, "Avg game time in secs": 2.033077041283832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 32896, "Total num trained steps": 65206, "Timestamp in ms": 1700773050257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9799514710342736, "Avg loss": 0.8298823080258444, "Avg value loss": 0.5669677100959234, "Avg policy loss": 0.2629145954269916, "Total num played games": 32970, "Total num trained steps": 65280, "Timestamp in ms": 1700773086853, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983833788292387, "Avg loss": 0.3411418027244508, "Avg value loss": 0.09880112603423186, "Avg policy loss": 0.2423406777670607, "Total num played games": 32970, "Total num trained steps": 65408, "Timestamp in ms": 1700773152188, "logtype": "training_step"}
{"Avg objective": 21.156015624999984, "Games time in secs": 115.07789581269026, "Avg game time in secs": 1.9997461646562442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.46}, "Total num played games": 33024, "Total num trained steps": 65435, "Timestamp in ms": 1700773165335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819452005080747, "Avg loss": 0.5957258399575949, "Avg value loss": 0.34151874599047005, "Avg policy loss": 0.25420708872843534, "Total num played games": 33066, "Total num trained steps": 65536, "Timestamp in ms": 1700773218445, "logtype": "training_step"}
{"Avg objective": 20.185390624999986, "Games time in secs": 99.64572625793517, "Avg game time in secs": 2.2708210786950076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.58}, "Total num played games": 33152, "Total num trained steps": 65629, "Timestamp in ms": 1700773264981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800675471925697, "Avg loss": 0.4956084191799164, "Avg value loss": 0.25567348118056543, "Avg policy loss": 0.23993493081070483, "Total num played games": 33162, "Total num trained steps": 65664, "Timestamp in ms": 1700773283025, "logtype": "training_step"}
{"Total num played games": 33162, "Total num trained steps": 65702, "Timestamp in ms": 1700773319999, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1691796875}
{"Ratio train steps to played games": 1.9782007336580671, "Avg loss": 0.9399633633438498, "Avg value loss": 0.6577502733562142, "Avg policy loss": 0.2822130824206397, "Total num played games": 33258, "Total num trained steps": 65792, "Timestamp in ms": 1700773365470, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820494317156774, "Avg loss": 0.3886734258849174, "Avg value loss": 0.12406141392420977, "Avg policy loss": 0.26461201370693743, "Total num played games": 33258, "Total num trained steps": 65920, "Timestamp in ms": 1700773430653, "logtype": "training_step"}
{"Avg objective": 21.654687499999984, "Games time in secs": 210.59805979765952, "Avg game time in secs": 2.3886623470607447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.62, "agent_stopped_0": 0.5}, "Total num played games": 33280, "Total num trained steps": 66007, "Timestamp in ms": 1700773475579, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980182286982071, "Avg loss": 0.7429771099705249, "Avg value loss": 0.4877753213222604, "Avg policy loss": 0.2552017882699147, "Total num played games": 33354, "Total num trained steps": 66048, "Timestamp in ms": 1700773494730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840498890687774, "Avg loss": 0.4346022051759064, "Avg value loss": 0.16898447717539966, "Avg policy loss": 0.265617725555785, "Total num played games": 33354, "Total num trained steps": 66176, "Timestamp in ms": 1700773556363, "logtype": "training_step"}
{"Avg objective": 21.531953124999987, "Games time in secs": 92.70935488678515, "Avg game time in secs": 2.086427612171974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 33408, "Total num trained steps": 66201, "Timestamp in ms": 1700773568289, "logtype": "played_game"}
{"Total num played games": 33450, "Total num trained steps": 66203, "Timestamp in ms": 1700773586578, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1686328125}
{"Avg objective": 21.666484374999985, "Games time in secs": 23.33221146464348, "Avg game time in secs": 2.1664974685554625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.57, "agent_stopped_0": 0.51}, "Total num played games": 33536, "Total num trained steps": 66211, "Timestamp in ms": 1700773591621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764800572348418, "Avg loss": 1.3304362120106816, "Avg value loss": 1.032214262872003, "Avg policy loss": 0.2982219571713358, "Total num played games": 33546, "Total num trained steps": 66304, "Timestamp in ms": 1700773638139, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980325523162225, "Avg loss": 0.3842930265236646, "Avg value loss": 0.12384731305064633, "Avg policy loss": 0.2604457156267017, "Total num played games": 33546, "Total num trained steps": 66432, "Timestamp in ms": 1700773702642, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841411792762178, "Avg loss": 0.3412900057155639, "Avg value loss": 0.09027796017471701, "Avg policy loss": 0.25101204332895577, "Total num played games": 33546, "Total num trained steps": 66560, "Timestamp in ms": 1700773763764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98228404969978, "Avg loss": 0.6649912036955357, "Avg value loss": 0.3987140326644294, "Avg policy loss": 0.26627716689836234, "Total num played games": 33642, "Total num trained steps": 66688, "Timestamp in ms": 1700773824899, "logtype": "training_step"}
{"Total num played games": 33642, "Total num trained steps": 66707, "Timestamp in ms": 1700773852949, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.90109375}
{"Avg objective": 21.191796874999987, "Games time in secs": 263.96806259825826, "Avg game time in secs": 2.331750606535934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 33664, "Total num trained steps": 66711, "Timestamp in ms": 1700773855589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9804374888849368, "Avg loss": 0.7452543524559587, "Avg value loss": 0.4611126577947289, "Avg policy loss": 0.2841416889568791, "Total num played games": 33738, "Total num trained steps": 66816, "Timestamp in ms": 1700773909086, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842314304345248, "Avg loss": 0.3620020253583789, "Avg value loss": 0.09645367955090478, "Avg policy loss": 0.26554834621492773, "Total num played games": 33738, "Total num trained steps": 66944, "Timestamp in ms": 1700773976653, "logtype": "training_step"}
{"Avg objective": 20.557421874999992, "Games time in secs": 133.17932905256748, "Avg game time in secs": 2.247685431255377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 33792, "Total num trained steps": 66969, "Timestamp in ms": 1700773988769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982355027487143, "Avg loss": 0.6723789741517976, "Avg value loss": 0.40589546237606555, "Avg policy loss": 0.2664835067698732, "Total num played games": 33834, "Total num trained steps": 67072, "Timestamp in ms": 1700774038366, "logtype": "training_step"}
{"Avg objective": 20.981796874999986, "Games time in secs": 93.9521912932396, "Avg game time in secs": 2.3333910554647446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 33920, "Total num trained steps": 67163, "Timestamp in ms": 1700774082721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805481874447393, "Avg loss": 0.6339284437708557, "Avg value loss": 0.37263601925224066, "Avg policy loss": 0.2612924230052158, "Total num played games": 33930, "Total num trained steps": 67200, "Timestamp in ms": 1700774101039, "logtype": "training_step"}
{"Total num played games": 33930, "Total num trained steps": 67208, "Timestamp in ms": 1700774121320, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3646484375}
{"Ratio train steps to played games": 1.978722153647211, "Avg loss": 1.0001352592371404, "Avg value loss": 0.7007164515089244, "Avg policy loss": 0.2994188073789701, "Total num played games": 34026, "Total num trained steps": 67328, "Timestamp in ms": 1700774180241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824545935461118, "Avg loss": 0.3711113852914423, "Avg value loss": 0.10305648043868132, "Avg policy loss": 0.26805490476544946, "Total num played games": 34026, "Total num trained steps": 67456, "Timestamp in ms": 1700774246312, "logtype": "training_step"}
{"Avg objective": 22.584140624999982, "Games time in secs": 208.21953705884516, "Avg game time in secs": 2.209479423123412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 34048, "Total num trained steps": 67543, "Timestamp in ms": 1700774290941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806576402321083, "Avg loss": 0.6343765304191038, "Avg value loss": 0.3730546262522694, "Avg policy loss": 0.26132191286887974, "Total num played games": 34122, "Total num trained steps": 67584, "Timestamp in ms": 1700774310783, "logtype": "training_step"}
{"Total num played games": 34122, "Total num trained steps": 67711, "Timestamp in ms": 1700774409208, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.182460937500004}
{"Ratio train steps to played games": 1.984379579157142, "Avg loss": 0.4055310229305178, "Avg value loss": 0.14302153207245283, "Avg policy loss": 0.2625094879185781, "Total num played games": 34122, "Total num trained steps": 67712, "Timestamp in ms": 1700774410159, "logtype": "training_step"}
{"Avg objective": 20.585859374999988, "Games time in secs": 121.63574500009418, "Avg game time in secs": 2.0394816321349936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 34176, "Total num trained steps": 67716, "Timestamp in ms": 1700774412577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825530422584605, "Avg loss": 0.6324301939457655, "Avg value loss": 0.35244864312699065, "Avg policy loss": 0.27998154796659946, "Total num played games": 34218, "Total num trained steps": 67840, "Timestamp in ms": 1700774475909, "logtype": "training_step"}
{"Avg objective": 21.446249999999992, "Games time in secs": 110.90889540873468, "Avg game time in secs": 2.1659699437441304, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 34304, "Total num trained steps": 67930, "Timestamp in ms": 1700774523486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806504254575126, "Avg loss": 0.6687354382593185, "Avg value loss": 0.4008019319444429, "Avg policy loss": 0.26793350954540074, "Total num played games": 34316, "Total num trained steps": 67968, "Timestamp in ms": 1700774544626, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843804639235343, "Avg loss": 0.4517912643495947, "Avg value loss": 0.1810088295605965, "Avg policy loss": 0.2707824344979599, "Total num played games": 34316, "Total num trained steps": 68096, "Timestamp in ms": 1700774609476, "logtype": "training_step"}
{"Total num played games": 34412, "Total num trained steps": 68213, "Timestamp in ms": 1700774690293, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.058906250000003}
{"Avg objective": 21.511328124999984, "Games time in secs": 169.72566298395395, "Avg game time in secs": 2.2240819005819503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 34432, "Total num trained steps": 68218, "Timestamp in ms": 1700774693212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773926149208743, "Avg loss": 0.6858975022332743, "Avg value loss": 0.4066367487539537, "Avg policy loss": 0.2792607578448951, "Total num played games": 34500, "Total num trained steps": 68224, "Timestamp in ms": 1700774695956, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807580850817201, "Avg loss": 0.7907136352732778, "Avg value loss": 0.49227317719487473, "Avg policy loss": 0.2984404453309253, "Total num played games": 34508, "Total num trained steps": 68352, "Timestamp in ms": 1700774764389, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984467369885244, "Avg loss": 0.36741209286265075, "Avg value loss": 0.09535383409820497, "Avg policy loss": 0.272058259928599, "Total num played games": 34508, "Total num trained steps": 68480, "Timestamp in ms": 1700774830217, "logtype": "training_step"}
{"Avg objective": 21.885390624999985, "Games time in secs": 151.38990146294236, "Avg game time in secs": 2.126445061076083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 34560, "Total num trained steps": 68508, "Timestamp in ms": 1700774844602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826320656571494, "Avg loss": 0.810896355425939, "Avg value loss": 0.521084545616759, "Avg policy loss": 0.2898118175799027, "Total num played games": 34604, "Total num trained steps": 68608, "Timestamp in ms": 1700774895451, "logtype": "training_step"}
{"Avg objective": 21.831249999999994, "Games time in secs": 99.51455560699105, "Avg game time in secs": 2.0840292101493105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 34688, "Total num trained steps": 68702, "Timestamp in ms": 1700774944116, "logtype": "played_game"}
{"Total num played games": 34700, "Total num trained steps": 68716, "Timestamp in ms": 1700774969553, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.874531250000004}
{"Ratio train steps to played games": 1.9753707322680767, "Avg loss": 0.8417383579071611, "Avg value loss": 0.5615979167050682, "Avg policy loss": 0.28014044172596186, "Total num played games": 34796, "Total num trained steps": 68736, "Timestamp in ms": 1700774981009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790780549488447, "Avg loss": 0.6450228614266962, "Avg value loss": 0.33456142497016117, "Avg policy loss": 0.31046144221909344, "Total num played games": 34796, "Total num trained steps": 68864, "Timestamp in ms": 1700775047286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827278997585929, "Avg loss": 0.3853425963316113, "Avg value loss": 0.09395791729912162, "Avg policy loss": 0.2913846776355058, "Total num played games": 34796, "Total num trained steps": 68992, "Timestamp in ms": 1700775117820, "logtype": "training_step"}
{"Avg objective": 21.923984374999982, "Games time in secs": 223.22594599239528, "Avg game time in secs": 2.4755461085005663, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 34816, "Total num trained steps": 69083, "Timestamp in ms": 1700775167342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980969849822309, "Avg loss": 0.48479058942757547, "Avg value loss": 0.2098790644959081, "Avg policy loss": 0.2749115227488801, "Total num played games": 34892, "Total num trained steps": 69120, "Timestamp in ms": 1700775186601, "logtype": "training_step"}
{"Total num played games": 34892, "Total num trained steps": 69217, "Timestamp in ms": 1700775272144, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.045625}
{"Avg objective": 21.097421874999984, "Games time in secs": 108.53257911838591, "Avg game time in secs": 2.06148789045983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 34944, "Total num trained steps": 69222, "Timestamp in ms": 1700775275875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791928661255287, "Avg loss": 0.6885151341557503, "Avg value loss": 0.4085584109998308, "Avg policy loss": 0.2799567214678973, "Total num played games": 34988, "Total num trained steps": 69248, "Timestamp in ms": 1700775290227, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828226820624213, "Avg loss": 0.500857018167153, "Avg value loss": 0.20876803761348128, "Avg policy loss": 0.29208898125216365, "Total num played games": 34988, "Total num trained steps": 69376, "Timestamp in ms": 1700775360476, "logtype": "training_step"}
{"Avg objective": 21.259062499999988, "Games time in secs": 136.90277945436537, "Avg game time in secs": 2.399354827022762, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 35072, "Total num trained steps": 69471, "Timestamp in ms": 1700775412778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810739938433475, "Avg loss": 0.7337062451988459, "Avg value loss": 0.4566605397267267, "Avg policy loss": 0.27704570535570383, "Total num played games": 35084, "Total num trained steps": 69504, "Timestamp in ms": 1700775430088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847223805723406, "Avg loss": 0.4823054682929069, "Avg value loss": 0.20018129603704438, "Avg policy loss": 0.28212417173199356, "Total num played games": 35084, "Total num trained steps": 69632, "Timestamp in ms": 1700775495735, "logtype": "training_step"}
{"Total num played games": 35180, "Total num trained steps": 69717, "Timestamp in ms": 1700775573228, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4375}
{"Avg objective": 22.460937499999986, "Games time in secs": 163.16894038580358, "Avg game time in secs": 2.3067855011468055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 35200, "Total num trained steps": 69721, "Timestamp in ms": 1700775575947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775201269985259, "Avg loss": 1.087613296462223, "Avg value loss": 0.7955265147029422, "Avg policy loss": 0.2920867846114561, "Total num played games": 35276, "Total num trained steps": 69760, "Timestamp in ms": 1700775595682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811486563102392, "Avg loss": 0.4591946345753968, "Avg value loss": 0.16647395811742172, "Avg policy loss": 0.29272067837882787, "Total num played games": 35276, "Total num trained steps": 69888, "Timestamp in ms": 1700775659241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847771856219527, "Avg loss": 0.3446276797913015, "Avg value loss": 0.08285104791866615, "Avg policy loss": 0.26177662890404463, "Total num played games": 35276, "Total num trained steps": 70016, "Timestamp in ms": 1700775722386, "logtype": "training_step"}
{"Avg objective": 21.845312499999988, "Games time in secs": 160.87405175715685, "Avg game time in secs": 2.1915341990825254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 35328, "Total num trained steps": 70047, "Timestamp in ms": 1700775736822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829253123763215, "Avg loss": 0.7239711633883417, "Avg value loss": 0.45107229144196026, "Avg policy loss": 0.2728988758753985, "Total num played games": 35374, "Total num trained steps": 70144, "Timestamp in ms": 1700775786463, "logtype": "training_step"}
{"Total num played games": 35374, "Total num trained steps": 70221, "Timestamp in ms": 1700775859195, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9977734375}
{"Avg objective": 21.28257812499999, "Games time in secs": 126.60804588347673, "Avg game time in secs": 2.359869538777275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 35456, "Total num trained steps": 70227, "Timestamp in ms": 1700775863430, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981167183535382, "Avg loss": 0.5480729511473328, "Avg value loss": 0.2748647677653935, "Avg policy loss": 0.27320819115266204, "Total num played games": 35470, "Total num trained steps": 70272, "Timestamp in ms": 1700775884340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984747674090781, "Avg loss": 0.3933472048956901, "Avg value loss": 0.11976514296839014, "Avg policy loss": 0.2735820629168302, "Total num played games": 35470, "Total num trained steps": 70400, "Timestamp in ms": 1700775945801, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98301748861272, "Avg loss": 0.7992124920710921, "Avg value loss": 0.5147796137607656, "Avg policy loss": 0.2844328792998567, "Total num played games": 35566, "Total num trained steps": 70528, "Timestamp in ms": 1700776007801, "logtype": "training_step"}
{"Avg objective": 23.075859374999986, "Games time in secs": 197.69611868448555, "Avg game time in secs": 2.2323385474592214, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 35584, "Total num trained steps": 70623, "Timestamp in ms": 1700776061126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810463746985925, "Avg loss": 0.5640809051692486, "Avg value loss": 0.2904229379782919, "Avg policy loss": 0.27365796850062907, "Total num played games": 35666, "Total num trained steps": 70656, "Timestamp in ms": 1700776079261, "logtype": "training_step"}
{"Total num played games": 35666, "Total num trained steps": 70725, "Timestamp in ms": 1700776136404, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.802890625000003}
{"Avg objective": 20.34421874999999, "Games time in secs": 78.29237420856953, "Avg game time in secs": 1.998779703862965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 35712, "Total num trained steps": 70729, "Timestamp in ms": 1700776139418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979279682344388, "Avg loss": 0.743373017758131, "Avg value loss": 0.44718187890248373, "Avg policy loss": 0.2961911446182057, "Total num played games": 35762, "Total num trained steps": 70784, "Timestamp in ms": 1700776165693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98285890050892, "Avg loss": 0.39242856833152473, "Avg value loss": 0.11386182921705768, "Avg policy loss": 0.27856674033682793, "Total num played games": 35762, "Total num trained steps": 70912, "Timestamp in ms": 1700776235893, "logtype": "training_step"}
{"Avg objective": 21.60874999999999, "Games time in secs": 150.17067122459412, "Avg game time in secs": 2.0753067284385907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 35840, "Total num trained steps": 71021, "Timestamp in ms": 1700776289589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980788534463529, "Avg loss": 0.6497694996651262, "Avg value loss": 0.38818780914880335, "Avg policy loss": 0.26158168085385114, "Total num played games": 35864, "Total num trained steps": 71040, "Timestamp in ms": 1700776298987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843854561677448, "Avg loss": 0.547387937316671, "Avg value loss": 0.26134254067437723, "Avg policy loss": 0.28604539670050144, "Total num played games": 35864, "Total num trained steps": 71168, "Timestamp in ms": 1700776362066, "logtype": "training_step"}
{"Total num played games": 35960, "Total num trained steps": 71228, "Timestamp in ms": 1700776410601, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8494921875}
{"Avg objective": 22.55757812499999, "Games time in secs": 122.72392357513309, "Avg game time in secs": 2.2396000956505304, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 35968, "Total num trained steps": 71229, "Timestamp in ms": 1700776412313, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977368537830042, "Avg loss": 1.3906040079891682, "Avg value loss": 1.0888439557165839, "Avg policy loss": 0.30176005186513066, "Total num played games": 36056, "Total num trained steps": 71296, "Timestamp in ms": 1700776445184, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980890836476592, "Avg loss": 0.4549828669987619, "Avg value loss": 0.1730124334571883, "Avg policy loss": 0.2819704363355413, "Total num played games": 36056, "Total num trained steps": 71424, "Timestamp in ms": 1700776510293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984440869758154, "Avg loss": 0.3550920016132295, "Avg value loss": 0.09815695040742867, "Avg policy loss": 0.2569350525736809, "Total num played games": 36056, "Total num trained steps": 71552, "Timestamp in ms": 1700776576134, "logtype": "training_step"}
{"Avg objective": 22.560156249999984, "Games time in secs": 190.40393812395632, "Avg game time in secs": 1.890989414343494, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 36096, "Total num trained steps": 71607, "Timestamp in ms": 1700776602717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982629861149527, "Avg loss": 0.7626975205494091, "Avg value loss": 0.5012789535103366, "Avg policy loss": 0.26141855702735484, "Total num played games": 36154, "Total num trained steps": 71680, "Timestamp in ms": 1700776637859, "logtype": "training_step"}
{"Total num played games": 36154, "Total num trained steps": 71730, "Timestamp in ms": 1700776686938, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.893203125}
{"Avg objective": 21.75507812499999, "Games time in secs": 87.37418294511735, "Avg game time in secs": 2.1949045911605936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 36224, "Total num trained steps": 71736, "Timestamp in ms": 1700776690092, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808827586206896, "Avg loss": 0.7176180672831833, "Avg value loss": 0.4481872035539709, "Avg policy loss": 0.26943085878156126, "Total num played games": 36250, "Total num trained steps": 71808, "Timestamp in ms": 1700776729225, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844137931034482, "Avg loss": 0.34683205955661833, "Avg value loss": 0.09685406659264117, "Avg policy loss": 0.2499779900535941, "Total num played games": 36250, "Total num trained steps": 71936, "Timestamp in ms": 1700776792305, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826125233850556, "Avg loss": 0.6155559092294425, "Avg value loss": 0.35717650078004226, "Avg policy loss": 0.2583794058300555, "Total num played games": 36348, "Total num trained steps": 72064, "Timestamp in ms": 1700776853801, "logtype": "training_step"}
{"Avg objective": 21.19640624999999, "Games time in secs": 225.4053323660046, "Avg game time in secs": 2.299357876967406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 36352, "Total num trained steps": 72187, "Timestamp in ms": 1700776915497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982288977977923, "Avg loss": 0.3573958236956969, "Avg value loss": 0.1045400555303786, "Avg policy loss": 0.2528557676123455, "Total num played games": 36418, "Total num trained steps": 72192, "Timestamp in ms": 1700776917441, "logtype": "training_step"}
{"Total num played games": 36444, "Total num trained steps": 72230, "Timestamp in ms": 1700776959789, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.899453125}
{"Avg objective": 22.67398437499999, "Games time in secs": 47.45646061003208, "Avg game time in secs": 2.0634380826813867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 36480, "Total num trained steps": 72237, "Timestamp in ms": 1700776962954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791735084838533, "Avg loss": 1.1345260629896075, "Avg value loss": 0.8452336991904303, "Avg policy loss": 0.2892923541367054, "Total num played games": 36540, "Total num trained steps": 72320, "Timestamp in ms": 1700777003820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982703886152162, "Avg loss": 0.35882223886437714, "Avg value loss": 0.10488194110803306, "Avg policy loss": 0.2539403005503118, "Total num played games": 36540, "Total num trained steps": 72448, "Timestamp in ms": 1700777069994, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982950819672131, "Avg loss": 0.3527248820755631, "Avg value loss": 0.11014283099211752, "Avg policy loss": 0.24258205003570765, "Total num played games": 36600, "Total num trained steps": 72576, "Timestamp in ms": 1700777138001, "logtype": "training_step"}
{"Avg objective": 22.10132812499999, "Games time in secs": 175.4671943280846, "Avg game time in secs": 2.257943052536575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 36608, "Total num trained steps": 72577, "Timestamp in ms": 1700777138421, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842521834061135, "Avg loss": 0.7382349902763963, "Avg value loss": 0.46974062646040693, "Avg policy loss": 0.2684943658532575, "Total num played games": 36640, "Total num trained steps": 72704, "Timestamp in ms": 1700777200953, "logtype": "training_step"}
{"Total num played games": 36640, "Total num trained steps": 72733, "Timestamp in ms": 1700777230333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.155625}
{"Avg objective": 21.650781249999984, "Games time in secs": 105.669428948313, "Avg game time in secs": 2.5116343012050493, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.66, "agent_stopped_0": 0.45}, "Total num played games": 36736, "Total num trained steps": 72760, "Timestamp in ms": 1700777244091, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825511759581882, "Avg loss": 0.6299252362223342, "Avg value loss": 0.35668520830222405, "Avg policy loss": 0.27324002841487527, "Total num played games": 36736, "Total num trained steps": 72832, "Timestamp in ms": 1700777279789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860354965156795, "Avg loss": 0.33889000804629177, "Avg value loss": 0.08851173979928717, "Avg policy loss": 0.2503782649291679, "Total num played games": 36736, "Total num trained steps": 72960, "Timestamp in ms": 1700777345522, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984226529836564, "Avg loss": 0.7711580495815724, "Avg value loss": 0.49409817828563973, "Avg policy loss": 0.2770598673960194, "Total num played games": 36834, "Total num trained steps": 73088, "Timestamp in ms": 1700777408451, "logtype": "training_step"}
{"Avg objective": 22.050546874999988, "Games time in secs": 200.8342575840652, "Avg game time in secs": 2.0933523231651634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 36864, "Total num trained steps": 73161, "Timestamp in ms": 1700777444927, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982454240225279, "Avg loss": 0.8300948771648109, "Avg value loss": 0.5591301063250285, "Avg policy loss": 0.2709647680167109, "Total num played games": 36932, "Total num trained steps": 73216, "Timestamp in ms": 1700777471653, "logtype": "training_step"}
{"Total num played games": 36932, "Total num trained steps": 73234, "Timestamp in ms": 1700777499714, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9624609375}
{"Avg objective": 21.574140624999988, "Games time in secs": 58.1518777217716, "Avg game time in secs": 2.168924892670475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 36992, "Total num trained steps": 73240, "Timestamp in ms": 1700777503079, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807443016095927, "Avg loss": 0.8664150414988399, "Avg value loss": 0.5638802806497552, "Avg policy loss": 0.30253476451616734, "Total num played games": 37028, "Total num trained steps": 73344, "Timestamp in ms": 1700777553900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842011450793993, "Avg loss": 0.39797468576580286, "Avg value loss": 0.12496734887827188, "Avg policy loss": 0.2730073358397931, "Total num played games": 37028, "Total num trained steps": 73472, "Timestamp in ms": 1700777623751, "logtype": "training_step"}
{"Avg objective": 22.219531249999985, "Games time in secs": 159.79389610886574, "Avg game time in secs": 2.451940320985159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 37120, "Total num trained steps": 73553, "Timestamp in ms": 1700777662873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825180476241784, "Avg loss": 0.603940543718636, "Avg value loss": 0.33627629705006257, "Avg policy loss": 0.26766425324603915, "Total num played games": 37124, "Total num trained steps": 73600, "Timestamp in ms": 1700777687473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859659519448336, "Avg loss": 0.40128430631011724, "Avg value loss": 0.13067918369779363, "Avg policy loss": 0.27060512197203934, "Total num played games": 37124, "Total num trained steps": 73728, "Timestamp in ms": 1700777753166, "logtype": "training_step"}
{"Total num played games": 37220, "Total num trained steps": 73737, "Timestamp in ms": 1700777777963, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.270664062500003}
{"Avg objective": 21.828124999999982, "Games time in secs": 117.79624604992568, "Avg game time in secs": 2.15535338614427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 37248, "Total num trained steps": 73743, "Timestamp in ms": 1700777780669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792046307214064, "Avg loss": 1.074948152527213, "Avg value loss": 0.7747443771804683, "Avg policy loss": 0.30020377424079925, "Total num played games": 37316, "Total num trained steps": 73856, "Timestamp in ms": 1700777839480, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982634794726123, "Avg loss": 0.3964005105663091, "Avg value loss": 0.12192236672854051, "Avg policy loss": 0.27447814168408513, "Total num played games": 37316, "Total num trained steps": 73984, "Timestamp in ms": 1700777908708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860649587308392, "Avg loss": 0.33833749836776406, "Avg value loss": 0.08082444488536566, "Avg policy loss": 0.2575130531331524, "Total num played games": 37316, "Total num trained steps": 74112, "Timestamp in ms": 1700777972089, "logtype": "training_step"}
{"Avg objective": 21.169062499999992, "Games time in secs": 197.68780464679003, "Avg game time in secs": 2.0905725498014363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 37376, "Total num trained steps": 74124, "Timestamp in ms": 1700777978357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843633058911578, "Avg loss": 0.6394907245412469, "Avg value loss": 0.3673221431381535, "Avg policy loss": 0.27216857695020735, "Total num played games": 37412, "Total num trained steps": 74240, "Timestamp in ms": 1700778034880, "logtype": "training_step"}
{"Total num played games": 37412, "Total num trained steps": 74240, "Timestamp in ms": 1700778054787, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0906640625}
{"Avg objective": 21.055156249999992, "Games time in secs": 81.35967283882201, "Avg game time in secs": 2.283008026133757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 37504, "Total num trained steps": 74250, "Timestamp in ms": 1700778059717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827236856137358, "Avg loss": 0.6285528207663447, "Avg value loss": 0.36182055389508605, "Avg policy loss": 0.266732269898057, "Total num played games": 37508, "Total num trained steps": 74368, "Timestamp in ms": 1700778118849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861096299456116, "Avg loss": 0.32082213170360774, "Avg value loss": 0.0756371469469741, "Avg policy loss": 0.24518498533871025, "Total num played games": 37508, "Total num trained steps": 74496, "Timestamp in ms": 1700778183347, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984364197202574, "Avg loss": 0.7166983389761299, "Avg value loss": 0.44247883913340047, "Avg policy loss": 0.27421949326526374, "Total num played games": 37606, "Total num trained steps": 74624, "Timestamp in ms": 1700778247217, "logtype": "training_step"}
{"Avg objective": 20.566093749999986, "Games time in secs": 225.18613886274397, "Avg game time in secs": 2.0693898189929314, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.44, "agent_stopped_0": 0.6}, "Total num played games": 37632, "Total num trained steps": 74703, "Timestamp in ms": 1700778284903, "logtype": "played_game"}
{"Total num played games": 37704, "Total num trained steps": 74742, "Timestamp in ms": 1700778321638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9476171875}
{"Avg objective": 21.40859374999999, "Games time in secs": 40.12451025657356, "Avg game time in secs": 2.005452669938677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 37760, "Total num trained steps": 74747, "Timestamp in ms": 1700778325028, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775396825396825, "Avg loss": 0.6107144535053521, "Avg value loss": 0.3528523439890705, "Avg policy loss": 0.25786211097147316, "Total num played games": 37800, "Total num trained steps": 74752, "Timestamp in ms": 1700778327074, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980952380952381, "Avg loss": 0.6152267910074443, "Avg value loss": 0.33692844363395125, "Avg policy loss": 0.27829834923613816, "Total num played games": 37800, "Total num trained steps": 74880, "Timestamp in ms": 1700778389510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843386243386243, "Avg loss": 0.3170183834154159, "Avg value loss": 0.0776387580554001, "Avg policy loss": 0.23937962483614683, "Total num played games": 37800, "Total num trained steps": 75008, "Timestamp in ms": 1700778449952, "logtype": "training_step"}
{"Avg objective": 21.297265624999987, "Games time in secs": 166.447302127257, "Avg game time in secs": 2.0996712623309577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.53, "agent_stopped_0": 0.54}, "Total num played games": 37888, "Total num trained steps": 75095, "Timestamp in ms": 1700778491475, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982689465906692, "Avg loss": 0.8794134195195511, "Avg value loss": 0.6305278592626564, "Avg policy loss": 0.24888556450605392, "Total num played games": 37896, "Total num trained steps": 75136, "Timestamp in ms": 1700778511132, "logtype": "training_step"}
{"Total num played games": 37896, "Total num trained steps": 75244, "Timestamp in ms": 1700778581249, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4153515625}
{"Ratio train steps to played games": 1.9810486418193305, "Avg loss": 0.5896073740441352, "Avg value loss": 0.3282361008459702, "Avg policy loss": 0.26137127936817706, "Total num played games": 37992, "Total num trained steps": 75264, "Timestamp in ms": 1700778591278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844177721625604, "Avg loss": 0.5176653838716447, "Avg value loss": 0.2536058878758922, "Avg policy loss": 0.2640594992553815, "Total num played games": 37992, "Total num trained steps": 75392, "Timestamp in ms": 1700778652586, "logtype": "training_step"}
{"Avg objective": 21.627031249999984, "Games time in secs": 202.00263480469584, "Avg game time in secs": 2.0551957373390906, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.45, "agent_stopped_0": 0.63}, "Total num played games": 38016, "Total num trained steps": 75476, "Timestamp in ms": 1700778693478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982646363875033, "Avg loss": 0.5727574854390696, "Avg value loss": 0.32954750416683964, "Avg policy loss": 0.24320998415350914, "Total num played games": 38090, "Total num trained steps": 75520, "Timestamp in ms": 1700778718637, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986033079548438, "Avg loss": 0.3562688761157915, "Avg value loss": 0.11597024690127, "Avg policy loss": 0.24029862962197512, "Total num played games": 38090, "Total num trained steps": 75648, "Timestamp in ms": 1700778782134, "logtype": "training_step"}
{"Avg objective": 20.81296874999999, "Games time in secs": 102.0874253809452, "Avg game time in secs": 1.9285052438644925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 38144, "Total num trained steps": 75673, "Timestamp in ms": 1700778795566, "logtype": "played_game"}
{"Total num played games": 38186, "Total num trained steps": 75745, "Timestamp in ms": 1700778851557, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.512148437500002}
{"Avg objective": 20.719609374999983, "Games time in secs": 60.24290576763451, "Avg game time in secs": 2.2556156864302466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 38272, "Total num trained steps": 75752, "Timestamp in ms": 1700778855809, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979415913484144, "Avg loss": 1.1577101489529014, "Avg value loss": 0.8953017289750278, "Avg policy loss": 0.26240843581035733, "Total num played games": 38282, "Total num trained steps": 75776, "Timestamp in ms": 1700778866987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827595214461105, "Avg loss": 0.5148418485186994, "Avg value loss": 0.25335459067719057, "Avg policy loss": 0.2614872594131157, "Total num played games": 38282, "Total num trained steps": 75904, "Timestamp in ms": 1700778927749, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861031294080769, "Avg loss": 0.32712241052649915, "Avg value loss": 0.08895113109610975, "Avg policy loss": 0.23817127791699022, "Total num played games": 38282, "Total num trained steps": 76032, "Timestamp in ms": 1700778988877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844702694251914, "Avg loss": 0.7813098229235038, "Avg value loss": 0.5264289270853624, "Avg policy loss": 0.2548808997962624, "Total num played games": 38378, "Total num trained steps": 76160, "Timestamp in ms": 1700779049871, "logtype": "training_step"}
{"Avg objective": 22.222187499999983, "Games time in secs": 235.9438868649304, "Avg game time in secs": 2.197153474786319, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 38400, "Total num trained steps": 76245, "Timestamp in ms": 1700779091753, "logtype": "played_game"}
{"Total num played games": 38458, "Total num trained steps": 76245, "Timestamp in ms": 1700779112960, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.94}
{"Avg objective": 22.74414062499999, "Games time in secs": 25.430116947740316, "Avg game time in secs": 2.0720656424964545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 38528, "Total num trained steps": 76252, "Timestamp in ms": 1700779117183, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787311303626083, "Avg loss": 1.1595588303171098, "Avg value loss": 0.8936799257644452, "Avg policy loss": 0.26587892265524715, "Total num played games": 38554, "Total num trained steps": 76288, "Timestamp in ms": 1700779134743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820511490377133, "Avg loss": 0.5243159658275545, "Avg value loss": 0.24744250997900963, "Avg policy loss": 0.27687345910817385, "Total num played games": 38554, "Total num trained steps": 76416, "Timestamp in ms": 1700779196315, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853711677128183, "Avg loss": 0.3458161596208811, "Avg value loss": 0.09405701808282174, "Avg policy loss": 0.25175914261490107, "Total num played games": 38554, "Total num trained steps": 76544, "Timestamp in ms": 1700779258630, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983751617076326, "Avg loss": 0.5778854424133897, "Avg value loss": 0.3271316491882317, "Avg policy loss": 0.2507537993369624, "Total num played games": 38650, "Total num trained steps": 76672, "Timestamp in ms": 1700779319865, "logtype": "training_step"}
{"Total num played games": 38650, "Total num trained steps": 76746, "Timestamp in ms": 1700779385617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0264453125}
{"Avg objective": 21.533906249999983, "Games time in secs": 270.2016796171665, "Avg game time in secs": 2.226220277705579, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 38656, "Total num trained steps": 76749, "Timestamp in ms": 1700779387385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821400918804521, "Avg loss": 0.5999307478778064, "Avg value loss": 0.33770653716055676, "Avg policy loss": 0.2622242105426267, "Total num played games": 38746, "Total num trained steps": 76800, "Timestamp in ms": 1700779412049, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854436587002529, "Avg loss": 0.3578463136218488, "Avg value loss": 0.11166776256868616, "Avg policy loss": 0.24617855111137033, "Total num played games": 38746, "Total num trained steps": 76928, "Timestamp in ms": 1700779472972, "logtype": "training_step"}
{"Avg objective": 20.809374999999992, "Games time in secs": 112.36616849340498, "Avg game time in secs": 1.9048941650544293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.31}, "Total num played games": 38784, "Total num trained steps": 76983, "Timestamp in ms": 1700779499751, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838319345038875, "Avg loss": 0.539195635705255, "Avg value loss": 0.28059017925988883, "Avg policy loss": 0.2586054604034871, "Total num played games": 38842, "Total num trained steps": 77056, "Timestamp in ms": 1700779535117, "logtype": "training_step"}
{"Avg objective": 21.418749999999996, "Games time in secs": 95.12976229563355, "Avg game time in secs": 1.940159426536411, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.4}, "Total num played games": 38912, "Total num trained steps": 77178, "Timestamp in ms": 1700779594881, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822281575838512, "Avg loss": 0.41703707352280617, "Avg value loss": 0.17098440087283961, "Avg policy loss": 0.2460526735521853, "Total num played games": 38938, "Total num trained steps": 77184, "Timestamp in ms": 1700779597835, "logtype": "training_step"}
{"Total num played games": 38938, "Total num trained steps": 77246, "Timestamp in ms": 1700779655346, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1984765625}
{"Ratio train steps to played games": 1.980632269303684, "Avg loss": 0.8467910084873438, "Avg value loss": 0.5555163575918414, "Avg policy loss": 0.29127464443445206, "Total num played games": 39034, "Total num trained steps": 77312, "Timestamp in ms": 1700779689162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983911461802531, "Avg loss": 0.3811938966391608, "Avg value loss": 0.10621169750811532, "Avg policy loss": 0.27498219546396285, "Total num played games": 39034, "Total num trained steps": 77440, "Timestamp in ms": 1700779758424, "logtype": "training_step"}
{"Avg objective": 20.623203124999986, "Games time in secs": 219.72336844913661, "Avg game time in secs": 2.255582408281043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 39040, "Total num trained steps": 77558, "Timestamp in ms": 1700779814605, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822898032200358, "Avg loss": 0.38659931800793856, "Avg value loss": 0.13312567814136855, "Avg policy loss": 0.253473638324067, "Total num played games": 39130, "Total num trained steps": 77568, "Timestamp in ms": 1700779819661, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855609506772298, "Avg loss": 0.5067862067371607, "Avg value loss": 0.22754866592003964, "Avg policy loss": 0.2792375386925414, "Total num played games": 39130, "Total num trained steps": 77696, "Timestamp in ms": 1700779881558, "logtype": "training_step"}
{"Avg objective": 21.149218749999985, "Games time in secs": 93.69209765270352, "Avg game time in secs": 1.9196677190921037, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 39168, "Total num trained steps": 77749, "Timestamp in ms": 1700779908297, "logtype": "played_game"}
{"Total num played games": 39210, "Total num trained steps": 77749, "Timestamp in ms": 1700779921609, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8245703125}
{"Avg objective": 21.655468749999986, "Games time in secs": 18.111792791634798, "Avg game time in secs": 2.183766738540726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.53, "agent_stopped_0": 0.49}, "Total num played games": 39296, "Total num trained steps": 77756, "Timestamp in ms": 1700779926409, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9799521701521396, "Avg loss": 1.0567905789939687, "Avg value loss": 0.7595285869610962, "Avg policy loss": 0.29726198373828083, "Total num played games": 39306, "Total num trained steps": 77824, "Timestamp in ms": 1700779958584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831832290235587, "Avg loss": 0.3971267486922443, "Avg value loss": 0.11093378587975167, "Avg policy loss": 0.28619296138640493, "Total num played games": 39306, "Total num trained steps": 77952, "Timestamp in ms": 1700780019526, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864397293034142, "Avg loss": 0.33690611575730145, "Avg value loss": 0.06907017476623878, "Avg policy loss": 0.2678359402343631, "Total num played games": 39306, "Total num trained steps": 78080, "Timestamp in ms": 1700780085299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848484848484849, "Avg loss": 0.7386705598328263, "Avg value loss": 0.4652470317669213, "Avg policy loss": 0.2734235260868445, "Total num played games": 39402, "Total num trained steps": 78208, "Timestamp in ms": 1700780147568, "logtype": "training_step"}
{"Total num played games": 39402, "Total num trained steps": 78251, "Timestamp in ms": 1700780188834, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5587890625}
{"Avg objective": 21.413281249999986, "Games time in secs": 264.87210340052843, "Avg game time in secs": 2.018359783643973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.42, "agent_stopped_0": 0.59}, "Total num played games": 39424, "Total num trained steps": 78254, "Timestamp in ms": 1700780191281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832902931794014, "Avg loss": 0.6421334736514837, "Avg value loss": 0.365694570238702, "Avg policy loss": 0.27643889910541475, "Total num played games": 39498, "Total num trained steps": 78336, "Timestamp in ms": 1700780230970, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865309635930932, "Avg loss": 0.34760843869298697, "Avg value loss": 0.08458730709389783, "Avg policy loss": 0.2630211311625317, "Total num played games": 39498, "Total num trained steps": 78464, "Timestamp in ms": 1700780294259, "logtype": "training_step"}
{"Avg objective": 22.058281249999993, "Games time in secs": 115.56424814648926, "Avg game time in secs": 2.005405000221799, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.5}, "Total num played games": 39552, "Total num trained steps": 78489, "Timestamp in ms": 1700780306846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849219578724049, "Avg loss": 1.114507339661941, "Avg value loss": 0.8168535765144043, "Avg policy loss": 0.29765376436989754, "Total num played games": 39594, "Total num trained steps": 78592, "Timestamp in ms": 1700780358503, "logtype": "training_step"}
{"Avg objective": 21.749453124999988, "Games time in secs": 96.23761034011841, "Avg game time in secs": 2.2760101666935952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 39680, "Total num trained steps": 78684, "Timestamp in ms": 1700780403083, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833711262282692, "Avg loss": 0.777043636655435, "Avg value loss": 0.4813482673780527, "Avg policy loss": 0.2956953722750768, "Total num played games": 39690, "Total num trained steps": 78720, "Timestamp in ms": 1700780419948, "logtype": "training_step"}
{"Total num played games": 39690, "Total num trained steps": 78752, "Timestamp in ms": 1700780459439, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.03203125}
{"Ratio train steps to played games": 1.981802644146182, "Avg loss": 0.9284082052763551, "Avg value loss": 0.6060671589220874, "Avg policy loss": 0.32234105153474957, "Total num played games": 39786, "Total num trained steps": 78848, "Timestamp in ms": 1700780506600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849947217614237, "Avg loss": 0.3893839870579541, "Avg value loss": 0.10417876153951511, "Avg policy loss": 0.2852052275557071, "Total num played games": 39786, "Total num trained steps": 78976, "Timestamp in ms": 1700780569424, "logtype": "training_step"}
{"Avg objective": 21.141953124999986, "Games time in secs": 210.32085874676704, "Avg game time in secs": 2.09973990812432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 39808, "Total num trained steps": 79063, "Timestamp in ms": 1700780613405, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834511809839026, "Avg loss": 0.6092355526052415, "Avg value loss": 0.33367708677542396, "Avg policy loss": 0.2755584625992924, "Total num played games": 39882, "Total num trained steps": 79104, "Timestamp in ms": 1700780632787, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866606489142973, "Avg loss": 0.4183288854546845, "Avg value loss": 0.13294153870083392, "Avg policy loss": 0.2853873483836651, "Total num played games": 39882, "Total num trained steps": 79232, "Timestamp in ms": 1700780693380, "logtype": "training_step"}
{"Avg objective": 21.298281249999988, "Games time in secs": 91.99620207957923, "Avg game time in secs": 2.1739354178716894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 39936, "Total num trained steps": 79255, "Timestamp in ms": 1700780705401, "logtype": "played_game"}
{"Total num played games": 39978, "Total num trained steps": 79255, "Timestamp in ms": 1700780745629, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8585546875}
{"Avg objective": 22.318828124999992, "Games time in secs": 45.48435983993113, "Avg game time in secs": 2.3953395954013104, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 40064, "Total num trained steps": 79265, "Timestamp in ms": 1700780750891, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803114238658481, "Avg loss": 1.0927695934660733, "Avg value loss": 0.7957224137498997, "Avg policy loss": 0.29704716487322, "Total num played games": 40074, "Total num trained steps": 79360, "Timestamp in ms": 1700780796925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835304686330288, "Avg loss": 0.4010875904932618, "Avg value loss": 0.12549701367970556, "Avg policy loss": 0.27559057786129415, "Total num played games": 40074, "Total num trained steps": 79488, "Timestamp in ms": 1700780858164, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986724559564805, "Avg loss": 0.3339628118555993, "Avg value loss": 0.07121092398301698, "Avg policy loss": 0.26275188953150064, "Total num played games": 40074, "Total num trained steps": 79616, "Timestamp in ms": 1700780919476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851630570077172, "Avg loss": 0.8066708229016513, "Avg value loss": 0.5294827142788563, "Avg policy loss": 0.2771881149383262, "Total num played games": 40170, "Total num trained steps": 79744, "Timestamp in ms": 1700780979815, "logtype": "training_step"}
{"Total num played games": 40170, "Total num trained steps": 79758, "Timestamp in ms": 1700781006937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4004296875}
{"Avg objective": 20.177499999999988, "Games time in secs": 258.481856290251, "Avg game time in secs": 2.252387772736256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 40192, "Total num trained steps": 79762, "Timestamp in ms": 1700781009373, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98358416530075, "Avg loss": 0.8139073369093239, "Avg value loss": 0.5350985113764182, "Avg policy loss": 0.2788088251836598, "Total num played games": 40266, "Total num trained steps": 79872, "Timestamp in ms": 1700781062607, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867630258779119, "Avg loss": 0.3450494378339499, "Avg value loss": 0.09065837456728332, "Avg policy loss": 0.2543910638196394, "Total num played games": 40266, "Total num trained steps": 80000, "Timestamp in ms": 1700781123012, "logtype": "training_step"}
{"Avg objective": 21.79078124999998, "Games time in secs": 126.81534118950367, "Avg game time in secs": 1.977408055725391, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 40320, "Total num trained steps": 80025, "Timestamp in ms": 1700781136189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851104945000495, "Avg loss": 0.6730836124625057, "Avg value loss": 0.40717315883375704, "Avg policy loss": 0.2659104492049664, "Total num played games": 40364, "Total num trained steps": 80128, "Timestamp in ms": 1700781187866, "logtype": "training_step"}
{"Avg objective": 20.596249999999994, "Games time in secs": 99.09984179213643, "Avg game time in secs": 2.0305192749365233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 40448, "Total num trained steps": 80222, "Timestamp in ms": 1700781235289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835640138408304, "Avg loss": 0.49112214683555067, "Avg value loss": 0.23462344010476954, "Avg policy loss": 0.2564987011719495, "Total num played games": 40460, "Total num trained steps": 80256, "Timestamp in ms": 1700781251172, "logtype": "training_step"}
{"Total num played games": 40460, "Total num trained steps": 80261, "Timestamp in ms": 1700781267657, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.762109375}
{"Ratio train steps to played games": 1.9820495117861723, "Avg loss": 0.6559698071796447, "Avg value loss": 0.39267211919650435, "Avg policy loss": 0.26329769007861614, "Total num played games": 40556, "Total num trained steps": 80384, "Timestamp in ms": 1700781328291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851809843179802, "Avg loss": 0.31537978746928275, "Avg value loss": 0.07840863548335619, "Avg policy loss": 0.2369711510837078, "Total num played games": 40556, "Total num trained steps": 80512, "Timestamp in ms": 1700781389306, "logtype": "training_step"}
{"Avg objective": 20.283749999999987, "Games time in secs": 198.60078677721322, "Avg game time in secs": 2.0573594063462224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.43}, "Total num played games": 40576, "Total num trained steps": 80603, "Timestamp in ms": 1700781433890, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836416412476632, "Avg loss": 0.5906022732378915, "Avg value loss": 0.36138165861484595, "Avg policy loss": 0.22922060533892363, "Total num played games": 40652, "Total num trained steps": 80640, "Timestamp in ms": 1700781451151, "logtype": "training_step"}
{"Total num played games": 40652, "Total num trained steps": 80763, "Timestamp in ms": 1700781538916, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.520000000000003}
{"Ratio train steps to played games": 1.9848373144598448, "Avg loss": 0.3739753132686019, "Avg value loss": 0.13622684264555573, "Avg policy loss": 0.23774847202003002, "Total num played games": 40692, "Total num trained steps": 80768, "Timestamp in ms": 1700781541882, "logtype": "training_step"}
{"Avg objective": 22.69921874999999, "Games time in secs": 108.27447689883411, "Avg game time in secs": 1.950567203661194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.45}, "Total num played games": 40704, "Total num trained steps": 80768, "Timestamp in ms": 1700781542168, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852508098556985, "Avg loss": 0.5995965402107686, "Avg value loss": 0.35223400371614844, "Avg policy loss": 0.24736253882292658, "Total num played games": 40748, "Total num trained steps": 80896, "Timestamp in ms": 1700781602900, "logtype": "training_step"}
{"Avg objective": 22.10757812499999, "Games time in secs": 108.06782346591353, "Avg game time in secs": 2.043217291968176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 40832, "Total num trained steps": 80991, "Timestamp in ms": 1700781650236, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837185388306728, "Avg loss": 0.6019389921566471, "Avg value loss": 0.37480747915105894, "Avg policy loss": 0.2271315063117072, "Total num played games": 40844, "Total num trained steps": 81024, "Timestamp in ms": 1700781665988, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868768974635198, "Avg loss": 0.35751584789250046, "Avg value loss": 0.12756151234498248, "Avg policy loss": 0.2299543370027095, "Total num played games": 40844, "Total num trained steps": 81152, "Timestamp in ms": 1700781733700, "logtype": "training_step"}
{"Total num played games": 40942, "Total num trained steps": 81265, "Timestamp in ms": 1700781803600, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.27734375}
{"Avg objective": 20.434140624999984, "Games time in secs": 155.8094113431871, "Avg game time in secs": 2.1698501411883626, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 40960, "Total num trained steps": 81269, "Timestamp in ms": 1700781806046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806998732819963, "Avg loss": 0.6630839153658599, "Avg value loss": 0.4201355942641385, "Avg policy loss": 0.24294832115992904, "Total num played games": 41036, "Total num trained steps": 81280, "Timestamp in ms": 1700781811180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837224036259078, "Avg loss": 0.6100154384039342, "Avg value loss": 0.3558488163398579, "Avg policy loss": 0.2541666233446449, "Total num played games": 41038, "Total num trained steps": 81408, "Timestamp in ms": 1700781872732, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868170963497247, "Avg loss": 0.3216957877157256, "Avg value loss": 0.09896643666434102, "Avg policy loss": 0.2227293528849259, "Total num played games": 41038, "Total num trained steps": 81536, "Timestamp in ms": 1700781933699, "logtype": "training_step"}
{"Avg objective": 22.276406249999987, "Games time in secs": 143.38210189156234, "Avg game time in secs": 2.1427033804211533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 41088, "Total num trained steps": 81569, "Timestamp in ms": 1700781949428, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852919725774298, "Avg loss": 0.4802199680125341, "Avg value loss": 0.245835325185908, "Avg policy loss": 0.23438464279752225, "Total num played games": 41134, "Total num trained steps": 81664, "Timestamp in ms": 1700781996093, "logtype": "training_step"}
{"Avg objective": 21.34710937499999, "Games time in secs": 94.8195357453078, "Avg game time in secs": 2.1603927561227465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 41216, "Total num trained steps": 81762, "Timestamp in ms": 1700782044247, "logtype": "played_game"}
{"Total num played games": 41230, "Total num trained steps": 81767, "Timestamp in ms": 1700782069952, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.793281250000003}
{"Ratio train steps to played games": 1.9791656584232686, "Avg loss": 0.9591971454210579, "Avg value loss": 0.7276431854988914, "Avg policy loss": 0.23155395255889744, "Total num played games": 41326, "Total num trained steps": 81792, "Timestamp in ms": 1700782082541, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982262982141993, "Avg loss": 0.7658224466722459, "Avg value loss": 0.4962420896627009, "Avg policy loss": 0.26958034955896437, "Total num played games": 41326, "Total num trained steps": 81920, "Timestamp in ms": 1700782146962, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853845037022697, "Avg loss": 0.31558941409457475, "Avg value loss": 0.08886360749602318, "Avg policy loss": 0.22672580706421286, "Total num played games": 41326, "Total num trained steps": 82048, "Timestamp in ms": 1700782213467, "logtype": "training_step"}
{"Avg objective": 22.462812499999984, "Games time in secs": 216.50773027539253, "Avg game time in secs": 2.081016094816732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 41344, "Total num trained steps": 82143, "Timestamp in ms": 1700782260755, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838491622809136, "Avg loss": 0.5775409076595679, "Avg value loss": 0.35301479132613167, "Avg policy loss": 0.2245261196512729, "Total num played games": 41422, "Total num trained steps": 82176, "Timestamp in ms": 1700782276132, "logtype": "training_step"}
{"Total num played games": 41422, "Total num trained steps": 82270, "Timestamp in ms": 1700782350901, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1252734375}
{"Avg objective": 21.18406249999999, "Games time in secs": 92.96915736608207, "Avg game time in secs": 2.0365037401934387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 41472, "Total num trained steps": 82274, "Timestamp in ms": 1700782353725, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823690929235511, "Avg loss": 0.6082250403705984, "Avg value loss": 0.36936665972461924, "Avg policy loss": 0.23885838221758604, "Total num played games": 41518, "Total num trained steps": 82304, "Timestamp in ms": 1700782368124, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985428007129438, "Avg loss": 0.3925643404945731, "Avg value loss": 0.15747736126650125, "Avg policy loss": 0.2350869805086404, "Total num played games": 41518, "Total num trained steps": 82432, "Timestamp in ms": 1700782429034, "logtype": "training_step"}
{"Avg objective": 21.261484374999995, "Games time in secs": 122.45237540267408, "Avg game time in secs": 1.9957859576243209, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 41600, "Total num trained steps": 82531, "Timestamp in ms": 1700782476177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839477099053204, "Avg loss": 0.44601345516275615, "Avg value loss": 0.21825132353114896, "Avg policy loss": 0.22776212985627353, "Total num played games": 41614, "Total num trained steps": 82560, "Timestamp in ms": 1700782490991, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870235978276543, "Avg loss": 0.33055106189567596, "Avg value loss": 0.10164460047963075, "Avg policy loss": 0.22890645975712687, "Total num played games": 41614, "Total num trained steps": 82688, "Timestamp in ms": 1700782555270, "logtype": "training_step"}
{"Total num played games": 41712, "Total num trained steps": 82771, "Timestamp in ms": 1700782610728, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2510546875}
{"Avg objective": 22.03023437499999, "Games time in secs": 136.81326968967915, "Avg game time in secs": 2.203797670910717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.47, "agent_stopped_0": 0.6}, "Total num played games": 41728, "Total num trained steps": 82775, "Timestamp in ms": 1700782612991, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808649062380406, "Avg loss": 0.9747719934675843, "Avg value loss": 0.7337755478802137, "Avg policy loss": 0.24099644820671529, "Total num played games": 41808, "Total num trained steps": 82816, "Timestamp in ms": 1700782632902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839265212399542, "Avg loss": 0.390724343014881, "Avg value loss": 0.1552171208895743, "Avg policy loss": 0.2355072199134156, "Total num played games": 41808, "Total num trained steps": 82944, "Timestamp in ms": 1700782694328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869881362418675, "Avg loss": 0.284577936748974, "Avg value loss": 0.0668936369183939, "Avg policy loss": 0.21768429945223033, "Total num played games": 41808, "Total num trained steps": 83072, "Timestamp in ms": 1700782755167, "logtype": "training_step"}
{"Avg objective": 22.373124999999987, "Games time in secs": 159.07802149280906, "Avg game time in secs": 1.810295679984847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.37, "agent_stopped_0": 0.65}, "Total num played games": 41856, "Total num trained steps": 83107, "Timestamp in ms": 1700782772069, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854906452844596, "Avg loss": 0.6179875759407878, "Avg value loss": 0.3880473591561895, "Avg policy loss": 0.22994022129569203, "Total num played games": 41904, "Total num trained steps": 83200, "Timestamp in ms": 1700782815967, "logtype": "training_step"}
{"Total num played games": 41904, "Total num trained steps": 83271, "Timestamp in ms": 1700782864533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.075703125}
{"Avg objective": 20.885703124999992, "Games time in secs": 96.20381517149508, "Avg game time in secs": 1.8769077323086094, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 41984, "Total num trained steps": 83277, "Timestamp in ms": 1700782868273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984, "Avg loss": 0.5369533665943891, "Avg value loss": 0.3045168120006565, "Avg policy loss": 0.23243656184058636, "Total num played games": 42000, "Total num trained steps": 83328, "Timestamp in ms": 1700782892621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870238095238095, "Avg loss": 0.3149303538957611, "Avg value loss": 0.0912904308643192, "Avg policy loss": 0.22363992303144187, "Total num played games": 42000, "Total num trained steps": 83456, "Timestamp in ms": 1700782955239, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854624922799182, "Avg loss": 0.669025210198015, "Avg value loss": 0.42067889546160586, "Avg policy loss": 0.24834631069097668, "Total num played games": 42098, "Total num trained steps": 83584, "Timestamp in ms": 1700783026160, "logtype": "training_step"}
{"Avg objective": 20.763046874999983, "Games time in secs": 210.7328663188964, "Avg game time in secs": 2.1613589819753543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 42112, "Total num trained steps": 83687, "Timestamp in ms": 1700783079006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839550647011424, "Avg loss": 0.46239374054130167, "Avg value loss": 0.2287672732200008, "Avg policy loss": 0.23362646554596722, "Total num played games": 42194, "Total num trained steps": 83712, "Timestamp in ms": 1700783091457, "logtype": "training_step"}
{"Total num played games": 42194, "Total num trained steps": 83771, "Timestamp in ms": 1700783133521, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5337890625}
{"Avg objective": 21.49687499999999, "Games time in secs": 57.38757617585361, "Avg game time in secs": 1.9137446180393454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 42240, "Total num trained steps": 83777, "Timestamp in ms": 1700783136393, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824781272168361, "Avg loss": 0.6551890466362238, "Avg value loss": 0.40196621540235355, "Avg policy loss": 0.25322283199056983, "Total num played games": 42290, "Total num trained steps": 83840, "Timestamp in ms": 1700783167469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855284937337432, "Avg loss": 0.33021608949638903, "Avg value loss": 0.09305204122210853, "Avg policy loss": 0.23716404708102345, "Total num played games": 42290, "Total num trained steps": 83968, "Timestamp in ms": 1700783233064, "logtype": "training_step"}
{"Avg objective": 21.224999999999987, "Games time in secs": 147.78889755159616, "Avg game time in secs": 1.9716876164020505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 42368, "Total num trained steps": 84075, "Timestamp in ms": 1700783284182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838405284265157, "Avg loss": 0.4992044633254409, "Avg value loss": 0.2664019661024213, "Avg policy loss": 0.23280250350944698, "Total num played games": 42390, "Total num trained steps": 84096, "Timestamp in ms": 1700783293773, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868836989856098, "Avg loss": 0.3971022083424032, "Avg value loss": 0.15840747058973648, "Avg policy loss": 0.23869473696686327, "Total num played games": 42390, "Total num trained steps": 84224, "Timestamp in ms": 1700783357000, "logtype": "training_step"}
{"Total num played games": 42490, "Total num trained steps": 84275, "Timestamp in ms": 1700783401459, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.21765625}
{"Avg objective": 21.866171874999985, "Games time in secs": 119.11477236822248, "Avg game time in secs": 2.1802867291116854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 42496, "Total num trained steps": 84277, "Timestamp in ms": 1700783403297, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980744845723947, "Avg loss": 1.2837485960917547, "Avg value loss": 1.0187702602124773, "Avg policy loss": 0.26497833197936416, "Total num played games": 42586, "Total num trained steps": 84352, "Timestamp in ms": 1700783440056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837505283426478, "Avg loss": 0.38426075130701065, "Avg value loss": 0.13166567054577172, "Avg policy loss": 0.252595083671622, "Total num played games": 42586, "Total num trained steps": 84480, "Timestamp in ms": 1700783503908, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867562109613488, "Avg loss": 0.3121764858951792, "Avg value loss": 0.07434812351129949, "Avg policy loss": 0.23782836238387972, "Total num played games": 42586, "Total num trained steps": 84608, "Timestamp in ms": 1700783569316, "logtype": "training_step"}
{"Avg objective": 22.162187499999984, "Games time in secs": 194.11951385997236, "Avg game time in secs": 1.9896518288587686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 42624, "Total num trained steps": 84666, "Timestamp in ms": 1700783597417, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851005013353324, "Avg loss": 0.7353975584264845, "Avg value loss": 0.49246346569270827, "Avg policy loss": 0.2429341042879969, "Total num played games": 42686, "Total num trained steps": 84736, "Timestamp in ms": 1700783633927, "logtype": "training_step"}
{"Total num played games": 42686, "Total num trained steps": 84778, "Timestamp in ms": 1700783667768, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.054375}
{"Avg objective": 20.687187499999983, "Games time in secs": 74.00071107409894, "Avg game time in secs": 2.085847243273747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 42752, "Total num trained steps": 84787, "Timestamp in ms": 1700783671418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983614604272825, "Avg loss": 0.6239105856511742, "Avg value loss": 0.3716979674063623, "Avg policy loss": 0.2522126183612272, "Total num played games": 42782, "Total num trained steps": 84864, "Timestamp in ms": 1700783710232, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986629891075686, "Avg loss": 0.3293986766366288, "Avg value loss": 0.09392342693172395, "Avg policy loss": 0.2354752509854734, "Total num played games": 42782, "Total num trained steps": 84992, "Timestamp in ms": 1700783773014, "logtype": "training_step"}
{"Avg objective": 21.395859374999983, "Games time in secs": 136.58615469187498, "Avg game time in secs": 2.399951572151622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 42880, "Total num trained steps": 85064, "Timestamp in ms": 1700783808004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850746268656716, "Avg loss": 0.5264822707977146, "Avg value loss": 0.2837914042174816, "Avg policy loss": 0.2426908661145717, "Total num played games": 42880, "Total num trained steps": 85120, "Timestamp in ms": 1700783835273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988036380597015, "Avg loss": 0.33334467199165374, "Avg value loss": 0.09421795140951872, "Avg policy loss": 0.23912672023288906, "Total num played games": 42880, "Total num trained steps": 85248, "Timestamp in ms": 1700783898281, "logtype": "training_step"}
{"Total num played games": 42978, "Total num trained steps": 85278, "Timestamp in ms": 1700783923213, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.424101562500002}
{"Avg objective": 21.724218749999988, "Games time in secs": 117.72540272027254, "Avg game time in secs": 1.7384561219223542, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.36}, "Total num played games": 43008, "Total num trained steps": 85283, "Timestamp in ms": 1700783925733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98205413938803, "Avg loss": 1.2312286046799272, "Avg value loss": 0.9465466529363766, "Avg policy loss": 0.28468195744790137, "Total num played games": 43074, "Total num trained steps": 85376, "Timestamp in ms": 1700783969807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850257696057947, "Avg loss": 0.34198100108187646, "Avg value loss": 0.0929659022076521, "Avg policy loss": 0.24901509925257415, "Total num played games": 43074, "Total num trained steps": 85504, "Timestamp in ms": 1700784033329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879973998235594, "Avg loss": 0.3048997597070411, "Avg value loss": 0.06528959242859855, "Avg policy loss": 0.23961016512475908, "Total num played games": 43074, "Total num trained steps": 85632, "Timestamp in ms": 1700784095507, "logtype": "training_step"}
{"Avg objective": 22.394218749999997, "Games time in secs": 174.45212466083467, "Avg game time in secs": 1.7555832582438597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 43136, "Total num trained steps": 85644, "Timestamp in ms": 1700784100185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864495506346707, "Avg loss": 0.5379554727114737, "Avg value loss": 0.2843856029212475, "Avg policy loss": 0.2535698744468391, "Total num played games": 43172, "Total num trained steps": 85760, "Timestamp in ms": 1700784157466, "logtype": "training_step"}
{"Total num played games": 43172, "Total num trained steps": 85780, "Timestamp in ms": 1700784178331, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4725390625}
{"Avg objective": 22.27328124999999, "Games time in secs": 82.32894620113075, "Avg game time in secs": 1.9833922306861496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.54}, "Total num played games": 43264, "Total num trained steps": 85787, "Timestamp in ms": 1700784182514, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850004622353703, "Avg loss": 0.5996770510682836, "Avg value loss": 0.35014029117883183, "Avg policy loss": 0.24953675630968064, "Total num played games": 43268, "Total num trained steps": 85888, "Timestamp in ms": 1700784232658, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987981880373486, "Avg loss": 0.31919039227068424, "Avg value loss": 0.07437777615268715, "Avg policy loss": 0.24481261579785496, "Total num played games": 43268, "Total num trained steps": 86016, "Timestamp in ms": 1700784297413, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864179310980954, "Avg loss": 0.6668629350606352, "Avg value loss": 0.4056987510994077, "Avg policy loss": 0.2611641905969009, "Total num played games": 43366, "Total num trained steps": 86144, "Timestamp in ms": 1700784359277, "logtype": "training_step"}
{"Avg objective": 21.470312499999984, "Games time in secs": 217.32793532684445, "Avg game time in secs": 1.8897016891278327, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.4, "agent_stopped_0": 0.65}, "Total num played games": 43392, "Total num trained steps": 86225, "Timestamp in ms": 1700784399842, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849753807924164, "Avg loss": 0.6304504995932803, "Avg value loss": 0.38332081853877753, "Avg policy loss": 0.24712967791128904, "Total num played games": 43462, "Total num trained steps": 86272, "Timestamp in ms": 1700784423651, "logtype": "training_step"}
{"Total num played games": 43462, "Total num trained steps": 86284, "Timestamp in ms": 1700784440608, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.860156250000003}
{"Avg objective": 21.730703124999987, "Games time in secs": 43.94376426003873, "Avg game time in secs": 1.9519240464287577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 43520, "Total num trained steps": 86292, "Timestamp in ms": 1700784443786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835391891271408, "Avg loss": 0.7358236396685243, "Avg value loss": 0.4687099286238663, "Avg policy loss": 0.2671137059805915, "Total num played games": 43558, "Total num trained steps": 86400, "Timestamp in ms": 1700784497494, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865007576105422, "Avg loss": 0.334275157074444, "Avg value loss": 0.08647028703126125, "Avg policy loss": 0.2478048710618168, "Total num played games": 43558, "Total num trained steps": 86528, "Timestamp in ms": 1700784562241, "logtype": "training_step"}
{"Avg objective": 21.303593749999987, "Games time in secs": 160.09905160404742, "Avg game time in secs": 2.050828395425924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.53, "agent_stopped_0": 0.49}, "Total num played games": 43648, "Total num trained steps": 86613, "Timestamp in ms": 1700784603885, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849505222649808, "Avg loss": 0.5490887215128168, "Avg value loss": 0.3007954669301398, "Avg policy loss": 0.24829325231257826, "Total num played games": 43656, "Total num trained steps": 86656, "Timestamp in ms": 1700784623409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987882536192047, "Avg loss": 0.3538720440119505, "Avg value loss": 0.10717554306029342, "Avg policy loss": 0.24669650057330728, "Total num played games": 43656, "Total num trained steps": 86784, "Timestamp in ms": 1700784688934, "logtype": "training_step"}
{"Total num played games": 43656, "Total num trained steps": 86785, "Timestamp in ms": 1700784710490, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.641640625}
{"Ratio train steps to played games": 1.9864463338818796, "Avg loss": 0.7013488600496203, "Avg value loss": 0.44452970899874344, "Avg policy loss": 0.25681915623135865, "Total num played games": 43752, "Total num trained steps": 86912, "Timestamp in ms": 1700784773126, "logtype": "training_step"}
{"Avg objective": 21.678281249999984, "Games time in secs": 209.98830388486385, "Avg game time in secs": 2.081121866693138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 43776, "Total num trained steps": 86995, "Timestamp in ms": 1700784813874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849486887115166, "Avg loss": 0.5609041013522074, "Avg value loss": 0.3121996395639144, "Avg policy loss": 0.2487044626614079, "Total num played games": 43850, "Total num trained steps": 87040, "Timestamp in ms": 1700784834944, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878677309007982, "Avg loss": 0.36007810512091964, "Avg value loss": 0.11447531095473096, "Avg policy loss": 0.2456027956213802, "Total num played games": 43850, "Total num trained steps": 87168, "Timestamp in ms": 1700784896058, "logtype": "training_step"}
{"Avg objective": 20.84531249999999, "Games time in secs": 93.88547913916409, "Avg game time in secs": 1.7995311475970084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.34}, "Total num played games": 43904, "Total num trained steps": 87192, "Timestamp in ms": 1700784907759, "logtype": "played_game"}
{"Total num played games": 43946, "Total num trained steps": 87287, "Timestamp in ms": 1700784980947, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.2725390625}
{"Avg objective": 21.73515624999998, "Games time in secs": 77.25075528398156, "Avg game time in secs": 2.062058858515229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.57, "agent_stopped_0": 0.46}, "Total num played games": 44032, "Total num trained steps": 87293, "Timestamp in ms": 1700784985010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821980018165304, "Avg loss": 0.7496674824506044, "Avg value loss": 0.4954585410596337, "Avg policy loss": 0.25420893949922174, "Total num played games": 44040, "Total num trained steps": 87296, "Timestamp in ms": 1700784986191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849915989282958, "Avg loss": 0.6460689709056169, "Avg value loss": 0.3862378794583492, "Avg policy loss": 0.25983108836226165, "Total num played games": 44042, "Total num trained steps": 87424, "Timestamp in ms": 1700785049633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878979156259933, "Avg loss": 0.2967120457906276, "Avg value loss": 0.069117544015171, "Avg policy loss": 0.227594499476254, "Total num played games": 44042, "Total num trained steps": 87552, "Timestamp in ms": 1700785115449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864068871771636, "Avg loss": 0.6106516411527991, "Avg value loss": 0.3626897174399346, "Avg policy loss": 0.2479619279038161, "Total num played games": 44140, "Total num trained steps": 87680, "Timestamp in ms": 1700785185579, "logtype": "training_step"}
{"Avg objective": 21.565624999999983, "Games time in secs": 248.9616644065827, "Avg game time in secs": 2.1092073438194348, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 44160, "Total num trained steps": 87771, "Timestamp in ms": 1700785233972, "logtype": "played_game"}
{"Total num played games": 44236, "Total num trained steps": 87787, "Timestamp in ms": 1700785253825, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.348203124999998}
{"Avg objective": 21.505624999999984, "Games time in secs": 23.07217881269753, "Avg game time in secs": 1.9049948817264521, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 44288, "Total num trained steps": 87793, "Timestamp in ms": 1700785257044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806685915365876, "Avg loss": 0.7786244290182367, "Avg value loss": 0.533305367018329, "Avg policy loss": 0.24531907495111227, "Total num played games": 44332, "Total num trained steps": 87808, "Timestamp in ms": 1700785264093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835784534873229, "Avg loss": 0.6665355693548918, "Avg value loss": 0.4002670366317034, "Avg policy loss": 0.2662685309769586, "Total num played games": 44332, "Total num trained steps": 87936, "Timestamp in ms": 1700785329173, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864657583686727, "Avg loss": 0.3129785433411598, "Avg value loss": 0.07688112548203208, "Avg policy loss": 0.2360974147450179, "Total num played games": 44332, "Total num trained steps": 88064, "Timestamp in ms": 1700785388968, "logtype": "training_step"}
{"Avg objective": 20.89015624999999, "Games time in secs": 178.1405920945108, "Avg game time in secs": 1.933803871870623, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.45, "agent_stopped_0": 0.58}, "Total num played games": 44416, "Total num trained steps": 88157, "Timestamp in ms": 1700785435185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850319618258756, "Avg loss": 0.5369406186509877, "Avg value loss": 0.30726321702240966, "Avg policy loss": 0.22967740159947425, "Total num played games": 44428, "Total num trained steps": 88192, "Timestamp in ms": 1700785451286, "logtype": "training_step"}
{"Total num played games": 44428, "Total num trained steps": 88287, "Timestamp in ms": 1700785516349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4126953125}
{"Ratio train steps to played games": 1.983649267810619, "Avg loss": 0.5927302977070212, "Avg value loss": 0.35508615092840046, "Avg policy loss": 0.23764415213372558, "Total num played games": 44524, "Total num trained steps": 88320, "Timestamp in ms": 1700785533927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865241218219387, "Avg loss": 0.40195761038921773, "Avg value loss": 0.16814594448078424, "Avg policy loss": 0.23381166637409478, "Total num played games": 44524, "Total num trained steps": 88448, "Timestamp in ms": 1700785598383, "logtype": "training_step"}
{"Avg objective": 21.93406249999999, "Games time in secs": 209.2328307852149, "Avg game time in secs": 1.93833339685807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 44544, "Total num trained steps": 88539, "Timestamp in ms": 1700785644418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851187808157778, "Avg loss": 0.3699588190065697, "Avg value loss": 0.1465547104307916, "Avg policy loss": 0.22340410866308957, "Total num played games": 44620, "Total num trained steps": 88576, "Timestamp in ms": 1700785663866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987987449574182, "Avg loss": 0.31353923596907407, "Avg value loss": 0.08760663020075299, "Avg policy loss": 0.2259326056810096, "Total num played games": 44620, "Total num trained steps": 88704, "Timestamp in ms": 1700785729479, "logtype": "training_step"}
{"Avg objective": 19.84664062499999, "Games time in secs": 99.44535032846034, "Avg game time in secs": 1.9748692568973638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 44672, "Total num trained steps": 88732, "Timestamp in ms": 1700785743863, "logtype": "played_game"}
{"Total num played games": 44716, "Total num trained steps": 88790, "Timestamp in ms": 1700785786089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1235546875}
{"Avg objective": 21.159062499999987, "Games time in secs": 45.997835928574204, "Avg game time in secs": 1.9655485268303892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 44800, "Total num trained steps": 88795, "Timestamp in ms": 1700785789861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823038471837902, "Avg loss": 0.9751763726817444, "Avg value loss": 0.7308355559653137, "Avg policy loss": 0.2443408117396757, "Total num played games": 44812, "Total num trained steps": 88832, "Timestamp in ms": 1700785808403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851825403909666, "Avg loss": 0.38147000782191753, "Avg value loss": 0.1309582870453596, "Avg policy loss": 0.25051171833183616, "Total num played games": 44812, "Total num trained steps": 88960, "Timestamp in ms": 1700785871345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988038918146925, "Avg loss": 0.30819063633680344, "Avg value loss": 0.0735284982365556, "Avg policy loss": 0.23466213943902403, "Total num played games": 44812, "Total num trained steps": 89088, "Timestamp in ms": 1700785938326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986639351563196, "Avg loss": 0.6382725510047749, "Avg value loss": 0.39847434690454975, "Avg policy loss": 0.23979820508975536, "Total num played games": 44908, "Total num trained steps": 89216, "Timestamp in ms": 1700786000621, "logtype": "training_step"}
{"Total num played games": 44908, "Total num trained steps": 89291, "Timestamp in ms": 1700786048087, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.563984375000004}
{"Avg objective": 21.547343749999982, "Games time in secs": 260.59347686357796, "Avg game time in secs": 1.848076895257691, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 44928, "Total num trained steps": 89294, "Timestamp in ms": 1700786050455, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985245755932806, "Avg loss": 0.4677544863661751, "Avg value loss": 0.22982874960871413, "Avg policy loss": 0.23792573320679367, "Total num played games": 45004, "Total num trained steps": 89344, "Timestamp in ms": 1700786076624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880677273131278, "Avg loss": 0.32538708322681487, "Avg value loss": 0.08709125488530844, "Avg policy loss": 0.23829582799226046, "Total num played games": 45004, "Total num trained steps": 89472, "Timestamp in ms": 1700786138749, "logtype": "training_step"}
{"Avg objective": 20.740937499999994, "Games time in secs": 101.88180802762508, "Avg game time in secs": 1.8171398381819017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 45056, "Total num trained steps": 89501, "Timestamp in ms": 1700786152337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866962305986697, "Avg loss": 0.780633250833489, "Avg value loss": 0.5230699590756558, "Avg policy loss": 0.25756331195589155, "Total num played games": 45100, "Total num trained steps": 89600, "Timestamp in ms": 1700786204789, "logtype": "training_step"}
{"Avg objective": 21.83374999999999, "Games time in secs": 96.87163906544447, "Avg game time in secs": 1.9420343339297688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 45184, "Total num trained steps": 89694, "Timestamp in ms": 1700786249209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853084343747234, "Avg loss": 0.5528951672604308, "Avg value loss": 0.30200055209570564, "Avg policy loss": 0.25089461903553456, "Total num played games": 45196, "Total num trained steps": 89728, "Timestamp in ms": 1700786265268, "logtype": "training_step"}
{"Total num played games": 45196, "Total num trained steps": 89791, "Timestamp in ms": 1700786315097, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.520117187500002}
{"Ratio train steps to played games": 1.9839265212399542, "Avg loss": 0.5942888117861003, "Avg value loss": 0.3366814030450769, "Avg policy loss": 0.25760740716941655, "Total num played games": 45292, "Total num trained steps": 89856, "Timestamp in ms": 1700786346252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867526273955665, "Avg loss": 0.33643260004464537, "Avg value loss": 0.08893301617354155, "Avg policy loss": 0.24749958468601108, "Total num played games": 45292, "Total num trained steps": 89984, "Timestamp in ms": 1700786408708, "logtype": "training_step"}
{"Avg objective": 20.826015624999982, "Games time in secs": 206.80467742681503, "Avg game time in secs": 2.085777241154574, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.5}, "Total num played games": 45312, "Total num trained steps": 90074, "Timestamp in ms": 1700786456014, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985370582532828, "Avg loss": 0.6057850432116538, "Avg value loss": 0.3597571670834441, "Avg policy loss": 0.24602787848562002, "Total num played games": 45388, "Total num trained steps": 90112, "Timestamp in ms": 1700786475852, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881907112011985, "Avg loss": 0.35868522233795375, "Avg value loss": 0.1166290977562312, "Avg policy loss": 0.2420561230974272, "Total num played games": 45388, "Total num trained steps": 90240, "Timestamp in ms": 1700786543425, "logtype": "training_step"}
{"Avg objective": 21.87312499999999, "Games time in secs": 101.82311297766864, "Avg game time in secs": 1.796644141737488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.37, "agent_stopped_0": 0.65}, "Total num played games": 45440, "Total num trained steps": 90268, "Timestamp in ms": 1700786557837, "logtype": "played_game"}
{"Total num played games": 45486, "Total num trained steps": 90291, "Timestamp in ms": 1700786583349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3170703125}
{"Avg objective": 20.97656249999999, "Games time in secs": 29.24386960454285, "Avg game time in secs": 1.9455889962991932, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 45568, "Total num trained steps": 90297, "Timestamp in ms": 1700786587081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825369663463648, "Avg loss": 0.95490966970101, "Avg value loss": 0.6876752043899614, "Avg policy loss": 0.2672344541642815, "Total num played games": 45582, "Total num trained steps": 90368, "Timestamp in ms": 1700786625942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853231538765301, "Avg loss": 0.3424110497580841, "Avg value loss": 0.08948414109181613, "Avg policy loss": 0.25292690854985267, "Total num played games": 45582, "Total num trained steps": 90496, "Timestamp in ms": 1700786693018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881532183756747, "Avg loss": 0.28617354470770806, "Avg value loss": 0.06243653077399358, "Avg policy loss": 0.2237370137590915, "Total num played games": 45582, "Total num trained steps": 90624, "Timestamp in ms": 1700786759120, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867551118700468, "Avg loss": 0.6068534259684384, "Avg value loss": 0.37014383703353815, "Avg policy loss": 0.23670958681032062, "Total num played games": 45678, "Total num trained steps": 90752, "Timestamp in ms": 1700786822345, "logtype": "training_step"}
{"Total num played games": 45678, "Total num trained steps": 90791, "Timestamp in ms": 1700786860439, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.937890625}
{"Avg objective": 21.351796874999987, "Games time in secs": 275.40402632392943, "Avg game time in secs": 1.8589666740590474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 45696, "Total num trained steps": 90795, "Timestamp in ms": 1700786862485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854065626775026, "Avg loss": 0.5743720370810479, "Avg value loss": 0.33482518390519544, "Avg policy loss": 0.23954685498028994, "Total num played games": 45774, "Total num trained steps": 90880, "Timestamp in ms": 1700786903253, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882029099488794, "Avg loss": 0.3021197735797614, "Avg value loss": 0.08106756457709707, "Avg policy loss": 0.22105221066158265, "Total num played games": 45774, "Total num trained steps": 91008, "Timestamp in ms": 1700786966065, "logtype": "training_step"}
{"Avg objective": 20.628593749999986, "Games time in secs": 119.32761764153838, "Avg game time in secs": 1.7829218343395041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.44, "agent_stopped_0": 0.59}, "Total num played games": 45824, "Total num trained steps": 91040, "Timestamp in ms": 1700786981813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868323522999782, "Avg loss": 0.4885987591696903, "Avg value loss": 0.2528166890551802, "Avg policy loss": 0.2357820717152208, "Total num played games": 45870, "Total num trained steps": 91136, "Timestamp in ms": 1700787029472, "logtype": "training_step"}
{"Avg objective": 21.68460937499999, "Games time in secs": 95.09413233958185, "Avg game time in secs": 1.9155134201719193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 45952, "Total num trained steps": 91234, "Timestamp in ms": 1700787076907, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854457642605403, "Avg loss": 0.4843322476372123, "Avg value loss": 0.2444676323211752, "Avg policy loss": 0.23986461467575282, "Total num played games": 45966, "Total num trained steps": 91264, "Timestamp in ms": 1700787090960, "logtype": "training_step"}
{"Total num played games": 45966, "Total num trained steps": 91294, "Timestamp in ms": 1700787118247, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.717929687500003}
{"Ratio train steps to played games": 1.9841083756675786, "Avg loss": 0.706522585824132, "Avg value loss": 0.43346203345572576, "Avg policy loss": 0.2730605552205816, "Total num played games": 46062, "Total num trained steps": 91392, "Timestamp in ms": 1700787166359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986865529069515, "Avg loss": 0.32902837125584483, "Avg value loss": 0.08405979379313067, "Avg policy loss": 0.24496857915073633, "Total num played games": 46062, "Total num trained steps": 91520, "Timestamp in ms": 1700787230246, "logtype": "training_step"}
{"Avg objective": 20.65492187499999, "Games time in secs": 200.06127033755183, "Avg game time in secs": 1.9237623154185712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.5, "agent_stopped_0": 0.58}, "Total num played games": 46080, "Total num trained steps": 91615, "Timestamp in ms": 1700787276968, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855279691494432, "Avg loss": 0.5505264854291454, "Avg value loss": 0.311193479137728, "Avg policy loss": 0.2393330007325858, "Total num played games": 46158, "Total num trained steps": 91648, "Timestamp in ms": 1700787293713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883010529052385, "Avg loss": 0.40167890628799796, "Avg value loss": 0.15321820220560767, "Avg policy loss": 0.2484607056248933, "Total num played games": 46158, "Total num trained steps": 91776, "Timestamp in ms": 1700787354897, "logtype": "training_step"}
{"Total num played games": 46158, "Total num trained steps": 91794, "Timestamp in ms": 1700787377925, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7746875}
{"Avg objective": 21.217968749999994, "Games time in secs": 103.70895639061928, "Avg game time in secs": 1.7662372005579527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 46208, "Total num trained steps": 91798, "Timestamp in ms": 1700787380678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869416699096294, "Avg loss": 0.4935384268173948, "Avg value loss": 0.254252610495314, "Avg policy loss": 0.2392858152743429, "Total num played games": 46254, "Total num trained steps": 91904, "Timestamp in ms": 1700787432065, "logtype": "training_step"}
{"Avg objective": 20.851562499999986, "Games time in secs": 97.04709828831255, "Avg game time in secs": 1.9476855618995614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 46336, "Total num trained steps": 92002, "Timestamp in ms": 1700787477725, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855022437003798, "Avg loss": 0.47292897454462945, "Avg value loss": 0.24237671404262073, "Avg policy loss": 0.23055225820280612, "Total num played games": 46352, "Total num trained steps": 92032, "Timestamp in ms": 1700787491802, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882637210907836, "Avg loss": 0.34356345783453435, "Avg value loss": 0.11022901834803633, "Avg policy loss": 0.23333443759474903, "Total num played games": 46352, "Total num trained steps": 92160, "Timestamp in ms": 1700787552976, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869100930072339, "Avg loss": 0.8150930510601029, "Avg value loss": 0.5773872361169197, "Avg policy loss": 0.2377058033598587, "Total num played games": 46448, "Total num trained steps": 92288, "Timestamp in ms": 1700787618077, "logtype": "training_step"}
{"Total num played games": 46448, "Total num trained steps": 92298, "Timestamp in ms": 1700787636734, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.2013671875}
{"Avg objective": 21.302578124999986, "Games time in secs": 161.1809091474861, "Avg game time in secs": 1.8775104446394835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 46464, "Total num trained steps": 92301, "Timestamp in ms": 1700787638906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855620488140255, "Avg loss": 0.6796591461170465, "Avg value loss": 0.4247620261157863, "Avg policy loss": 0.2548971283249557, "Total num played games": 46544, "Total num trained steps": 92416, "Timestamp in ms": 1700787693367, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988312134754211, "Avg loss": 0.3132546617416665, "Avg value loss": 0.07939302339218557, "Avg policy loss": 0.23386163939721882, "Total num played games": 46544, "Total num trained steps": 92544, "Timestamp in ms": 1700787755587, "logtype": "training_step"}
{"Avg objective": 21.73562499999999, "Games time in secs": 133.487826410681, "Avg game time in secs": 1.7125308526447043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 46592, "Total num trained steps": 92580, "Timestamp in ms": 1700787772394, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869639794168097, "Avg loss": 0.5223464119480923, "Avg value loss": 0.2865106269309763, "Avg policy loss": 0.23583578201942146, "Total num played games": 46640, "Total num trained steps": 92672, "Timestamp in ms": 1700787815580, "logtype": "training_step"}
{"Avg objective": 19.907031249999992, "Games time in secs": 91.51035301201046, "Avg game time in secs": 1.9737766103935428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 46720, "Total num trained steps": 92773, "Timestamp in ms": 1700787863904, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855999657651489, "Avg loss": 0.41678157972637564, "Avg value loss": 0.18541813548654318, "Avg policy loss": 0.23136344261001796, "Total num played games": 46736, "Total num trained steps": 92800, "Timestamp in ms": 1700787876416, "logtype": "training_step"}
{"Total num played games": 46736, "Total num trained steps": 92801, "Timestamp in ms": 1700787887262, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.028671875}
{"Ratio train steps to played games": 1.9842842500854116, "Avg loss": 0.6093398585217074, "Avg value loss": 0.36515322007471696, "Avg policy loss": 0.24418664432596415, "Total num played games": 46832, "Total num trained steps": 92928, "Timestamp in ms": 1700787948653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869960710625214, "Avg loss": 0.2918797718593851, "Avg value loss": 0.07763669791165739, "Avg policy loss": 0.2142430734820664, "Total num played games": 46832, "Total num trained steps": 93056, "Timestamp in ms": 1700788010309, "logtype": "training_step"}
{"Avg objective": 21.166406249999984, "Games time in secs": 192.89291640929878, "Avg game time in secs": 1.808286045139539, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 46848, "Total num trained steps": 93155, "Timestamp in ms": 1700788056797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856801909307875, "Avg loss": 0.48588564328383654, "Avg value loss": 0.27578833828738425, "Avg policy loss": 0.2100973076885566, "Total num played games": 46928, "Total num trained steps": 93184, "Timestamp in ms": 1700788070247, "logtype": "training_step"}
{"Total num played games": 46928, "Total num trained steps": 93302, "Timestamp in ms": 1700788135828, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0669921875}
{"Avg objective": 21.47265624999999, "Games time in secs": 81.92573052085936, "Avg game time in secs": 1.7885459878889378, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 46976, "Total num trained steps": 93307, "Timestamp in ms": 1700788138723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844328186806175, "Avg loss": 0.3781508835963905, "Avg value loss": 0.1560455875878688, "Avg policy loss": 0.22210529551375657, "Total num played games": 47022, "Total num trained steps": 93312, "Timestamp in ms": 1700788141048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870491663831236, "Avg loss": 0.49943065899424255, "Avg value loss": 0.2642612421477679, "Avg policy loss": 0.23516941140405834, "Total num played games": 47024, "Total num trained steps": 93440, "Timestamp in ms": 1700788203986, "logtype": "training_step"}
{"Avg objective": 21.540624999999995, "Games time in secs": 112.97506746090949, "Avg game time in secs": 1.7283668673189823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 47104, "Total num trained steps": 93541, "Timestamp in ms": 1700788251699, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857173174872667, "Avg loss": 0.5270092866849154, "Avg value loss": 0.3063143545005005, "Avg policy loss": 0.22069493273738772, "Total num played games": 47120, "Total num trained steps": 93568, "Timestamp in ms": 1700788264005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884337860780985, "Avg loss": 0.4041462722234428, "Avg value loss": 0.17306227787048556, "Avg policy loss": 0.231083995080553, "Total num played games": 47120, "Total num trained steps": 93696, "Timestamp in ms": 1700788324462, "logtype": "training_step"}
{"Total num played games": 47216, "Total num trained steps": 93806, "Timestamp in ms": 1700788386885, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9297265625}
{"Avg objective": 22.121093749999986, "Games time in secs": 137.14632034488022, "Avg game time in secs": 1.77189868754067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 47232, "Total num trained steps": 93809, "Timestamp in ms": 1700788388845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830909705782889, "Avg loss": 0.8562265093205497, "Avg value loss": 0.6275283696013503, "Avg policy loss": 0.228698143735528, "Total num played games": 47312, "Total num trained steps": 93824, "Timestamp in ms": 1700788395655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857752789989855, "Avg loss": 0.4592676379252225, "Avg value loss": 0.2243440435267985, "Avg policy loss": 0.23492359451483935, "Total num played games": 47312, "Total num trained steps": 93952, "Timestamp in ms": 1700788457269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884807237064592, "Avg loss": 0.28538006567396224, "Avg value loss": 0.0709536250506062, "Avg policy loss": 0.2144264403032139, "Total num played games": 47312, "Total num trained steps": 94080, "Timestamp in ms": 1700788523798, "logtype": "training_step"}
{"Avg objective": 21.69585937499999, "Games time in secs": 151.64787144772708, "Avg game time in secs": 1.6272755361860618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 47360, "Total num trained steps": 94116, "Timestamp in ms": 1700788540495, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871751603104961, "Avg loss": 0.5558096033055335, "Avg value loss": 0.3393268858490046, "Avg policy loss": 0.21648271766025573, "Total num played games": 47408, "Total num trained steps": 94208, "Timestamp in ms": 1700788583660, "logtype": "training_step"}
{"Avg objective": 22.154296874999993, "Games time in secs": 91.84725080057979, "Avg game time in secs": 1.6684344327513827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 47488, "Total num trained steps": 94307, "Timestamp in ms": 1700788632342, "logtype": "played_game"}
{"Total num played games": 47504, "Total num trained steps": 94307, "Timestamp in ms": 1700788641764, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6659375}
{"Ratio train steps to played games": 1.981827731092437, "Avg loss": 0.7811331232078373, "Avg value loss": 0.565832509775646, "Avg policy loss": 0.21530062274541706, "Total num played games": 47600, "Total num trained steps": 94336, "Timestamp in ms": 1700788656453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845378151260504, "Avg loss": 0.5387811239343137, "Avg value loss": 0.2936653060023673, "Avg policy loss": 0.24511581903789192, "Total num played games": 47600, "Total num trained steps": 94464, "Timestamp in ms": 1700788717118, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872268907563024, "Avg loss": 0.28418263571802527, "Avg value loss": 0.07654131916933693, "Avg policy loss": 0.20764131483156234, "Total num played games": 47600, "Total num trained steps": 94592, "Timestamp in ms": 1700788778952, "logtype": "training_step"}
{"Avg objective": 22.94429687499999, "Games time in secs": 194.23590687476099, "Avg game time in secs": 1.7831032566027716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 47616, "Total num trained steps": 94691, "Timestamp in ms": 1700788826578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985910768198591, "Avg loss": 0.5297607737593353, "Avg value loss": 0.31842313933884725, "Avg policy loss": 0.21133763086982071, "Total num played games": 47696, "Total num trained steps": 94720, "Timestamp in ms": 1700788839825, "logtype": "training_step"}
{"Total num played games": 47696, "Total num trained steps": 94809, "Timestamp in ms": 1700788892913, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8156640625}
{"Avg objective": 20.51484374999999, "Games time in secs": 69.24555314704776, "Avg game time in secs": 1.7573334900516784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.47, "agent_stopped_0": 0.54}, "Total num played games": 47744, "Total num trained steps": 94814, "Timestamp in ms": 1700788895824, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845999330431872, "Avg loss": 0.6324748934712261, "Avg value loss": 0.40559455537004396, "Avg policy loss": 0.22688034747261554, "Total num played games": 47792, "Total num trained steps": 94848, "Timestamp in ms": 1700788911538, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872782055574154, "Avg loss": 0.3902229203376919, "Avg value loss": 0.15420665830606595, "Avg policy loss": 0.236016258248128, "Total num played games": 47792, "Total num trained steps": 94976, "Timestamp in ms": 1700788972665, "logtype": "training_step"}
{"Avg objective": 21.66093749999999, "Games time in secs": 129.6739744581282, "Avg game time in secs": 1.868063100744621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 47872, "Total num trained steps": 95077, "Timestamp in ms": 1700789025502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859672569328433, "Avg loss": 0.5686969794332981, "Avg value loss": 0.3447963026992511, "Avg policy loss": 0.22390067274682224, "Total num played games": 47888, "Total num trained steps": 95104, "Timestamp in ms": 1700789038415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886401603742065, "Avg loss": 0.39255195506848395, "Avg value loss": 0.15899503900436684, "Avg policy loss": 0.23355691588949412, "Total num played games": 47888, "Total num trained steps": 95232, "Timestamp in ms": 1700789106756, "logtype": "training_step"}
{"Total num played games": 47984, "Total num trained steps": 95312, "Timestamp in ms": 1700789154712, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.550273437500003}
{"Avg objective": 22.228593749999987, "Games time in secs": 131.43318372406065, "Avg game time in secs": 1.7638208426942583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 48000, "Total num trained steps": 95316, "Timestamp in ms": 1700789156935, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983361064891847, "Avg loss": 0.8034431851701811, "Avg value loss": 0.560366020858055, "Avg policy loss": 0.24307715718168765, "Total num played games": 48080, "Total num trained steps": 95360, "Timestamp in ms": 1700789178470, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860024958402662, "Avg loss": 0.3670378508977592, "Avg value loss": 0.13343138416530564, "Avg policy loss": 0.23360646539367735, "Total num played games": 48080, "Total num trained steps": 95488, "Timestamp in ms": 1700789246837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886647254575707, "Avg loss": 0.28925209818407893, "Avg value loss": 0.0677909993682988, "Avg policy loss": 0.22146109817549586, "Total num played games": 48080, "Total num trained steps": 95616, "Timestamp in ms": 1700789308729, "logtype": "training_step"}
{"Avg objective": 21.42265624999999, "Games time in secs": 169.94207532145083, "Avg game time in secs": 1.6520601706579328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.4}, "Total num played games": 48128, "Total num trained steps": 95651, "Timestamp in ms": 1700789326877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873796081036201, "Avg loss": 0.5191941530210897, "Avg value loss": 0.2852716660418082, "Avg policy loss": 0.23392248211894184, "Total num played games": 48176, "Total num trained steps": 95744, "Timestamp in ms": 1700789370858, "logtype": "training_step"}
{"Total num played games": 48176, "Total num trained steps": 95812, "Timestamp in ms": 1700789414303, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.702695312500005}
{"Avg objective": 21.07031249999999, "Games time in secs": 90.82852155715227, "Avg game time in secs": 1.7088201834703796, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 48256, "Total num trained steps": 95817, "Timestamp in ms": 1700789417706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986078886310905, "Avg loss": 0.5130989538738504, "Avg value loss": 0.2744203369074967, "Avg policy loss": 0.23867862147744745, "Total num played games": 48272, "Total num trained steps": 95872, "Timestamp in ms": 1700789444547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887098110705999, "Avg loss": 0.32294700876809657, "Avg value loss": 0.08721440390218049, "Avg policy loss": 0.23573260370176286, "Total num played games": 48272, "Total num trained steps": 96000, "Timestamp in ms": 1700789504944, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874090307641417, "Avg loss": 0.8010006702970713, "Avg value loss": 0.553811012126971, "Avg policy loss": 0.24718965566717088, "Total num played games": 48368, "Total num trained steps": 96128, "Timestamp in ms": 1700789570187, "logtype": "training_step"}
{"Avg objective": 22.151484374999992, "Games time in secs": 200.29968595132232, "Avg game time in secs": 1.7468714391288813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 48384, "Total num trained steps": 96227, "Timestamp in ms": 1700789618006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861340376361836, "Avg loss": 0.7274705008603632, "Avg value loss": 0.4883456581737846, "Avg policy loss": 0.2391248351195827, "Total num played games": 48464, "Total num trained steps": 96256, "Timestamp in ms": 1700789631642, "logtype": "training_step"}
{"Total num played games": 48464, "Total num trained steps": 96312, "Timestamp in ms": 1700789669300, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.1070703125}
{"Avg objective": 21.702656249999986, "Games time in secs": 53.999683210626245, "Avg game time in secs": 1.6651384174328996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 48512, "Total num trained steps": 96316, "Timestamp in ms": 1700789672005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984822899505766, "Avg loss": 0.7410064835567027, "Avg value loss": 0.4756483376258984, "Avg policy loss": 0.2653581448830664, "Total num played games": 48560, "Total num trained steps": 96384, "Timestamp in ms": 1700789707472, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874794069192752, "Avg loss": 0.32843188813421875, "Avg value loss": 0.09440065728267655, "Avg policy loss": 0.23403122962918133, "Total num played games": 48560, "Total num trained steps": 96512, "Timestamp in ms": 1700789767579, "logtype": "training_step"}
{"Avg objective": 21.210937499999993, "Games time in secs": 144.52788738906384, "Avg game time in secs": 1.798568708865787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.51}, "Total num played games": 48640, "Total num trained steps": 96613, "Timestamp in ms": 1700789816533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986188753699441, "Avg loss": 0.5274327136576176, "Avg value loss": 0.3033686346607283, "Avg policy loss": 0.2240640870295465, "Total num played games": 48656, "Total num trained steps": 96640, "Timestamp in ms": 1700789828924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888194672804997, "Avg loss": 0.38567346695344895, "Avg value loss": 0.15085119652212597, "Avg policy loss": 0.23482226906344295, "Total num played games": 48656, "Total num trained steps": 96768, "Timestamp in ms": 1700789889308, "logtype": "training_step"}
{"Total num played games": 48752, "Total num trained steps": 96812, "Timestamp in ms": 1700789921069, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.05703125}
{"Avg objective": 20.515624999999982, "Games time in secs": 106.53194271959364, "Avg game time in secs": 1.8074754031404154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 48768, "Total num trained steps": 96814, "Timestamp in ms": 1700789923066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836021945627251, "Avg loss": 0.8751675069797784, "Avg value loss": 0.6174453829298727, "Avg policy loss": 0.257722120732069, "Total num played games": 48848, "Total num trained steps": 96896, "Timestamp in ms": 1700789961639, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986222567965935, "Avg loss": 0.3296411271439865, "Avg value loss": 0.09104312639101408, "Avg policy loss": 0.23859799932688475, "Total num played games": 48848, "Total num trained steps": 97024, "Timestamp in ms": 1700790024652, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888634130363576, "Avg loss": 0.2808431702433154, "Avg value loss": 0.062143954244675115, "Avg policy loss": 0.2186992154456675, "Total num played games": 48848, "Total num trained steps": 97152, "Timestamp in ms": 1700790092537, "logtype": "training_step"}
{"Avg objective": 20.20078124999999, "Games time in secs": 186.7522462196648, "Avg game time in secs": 1.628879511365085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.43}, "Total num played games": 48896, "Total num trained steps": 97188, "Timestamp in ms": 1700790109818, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875776397515528, "Avg loss": 0.6407462503993884, "Avg value loss": 0.4002529317513108, "Avg policy loss": 0.24049331655260175, "Total num played games": 48944, "Total num trained steps": 97280, "Timestamp in ms": 1700790158989, "logtype": "training_step"}
{"Total num played games": 48944, "Total num trained steps": 97314, "Timestamp in ms": 1700790188485, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.153476562500003}
{"Avg objective": 22.102109374999987, "Games time in secs": 81.87259914726019, "Avg game time in secs": 1.7288429888722021, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 49024, "Total num trained steps": 97321, "Timestamp in ms": 1700790191691, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862969004893964, "Avg loss": 0.7554910506587476, "Avg value loss": 0.5046903368493076, "Avg policy loss": 0.25080071797128767, "Total num played games": 49040, "Total num trained steps": 97408, "Timestamp in ms": 1700790235900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888866231647635, "Avg loss": 0.29878568707499653, "Avg value loss": 0.07073780757491477, "Avg policy loss": 0.2280478784814477, "Total num played games": 49040, "Total num trained steps": 97536, "Timestamp in ms": 1700790300485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876261803972648, "Avg loss": 0.7185001987963915, "Avg value loss": 0.48422825505258515, "Avg policy loss": 0.23427194822579622, "Total num played games": 49136, "Total num trained steps": 97664, "Timestamp in ms": 1700790361620, "logtype": "training_step"}
{"Avg objective": 21.377578124999985, "Games time in secs": 216.567037621513, "Avg game time in secs": 1.7458510377036873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 49152, "Total num trained steps": 97763, "Timestamp in ms": 1700790408258, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863300292492687, "Avg loss": 0.5660208041081205, "Avg value loss": 0.33578613825375214, "Avg policy loss": 0.2302346653304994, "Total num played games": 49232, "Total num trained steps": 97792, "Timestamp in ms": 1700790421529, "logtype": "training_step"}
{"Total num played games": 49232, "Total num trained steps": 97815, "Timestamp in ms": 1700790443210, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.531406250000003}
{"Avg objective": 22.183281249999993, "Games time in secs": 37.33127558045089, "Avg game time in secs": 1.5799190944380825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.34}, "Total num played games": 49280, "Total num trained steps": 97819, "Timestamp in ms": 1700790445589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850591955887122, "Avg loss": 0.8560094598215073, "Avg value loss": 0.5950903472257778, "Avg policy loss": 0.26091911958064884, "Total num played games": 49328, "Total num trained steps": 97920, "Timestamp in ms": 1700790493244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876743431722348, "Avg loss": 0.3034352285321802, "Avg value loss": 0.07916838931851089, "Avg policy loss": 0.22426683991216123, "Total num played games": 49328, "Total num trained steps": 98048, "Timestamp in ms": 1700790555313, "logtype": "training_step"}
{"Avg objective": 21.626562499999984, "Games time in secs": 158.48796520009637, "Avg game time in secs": 1.7193273500015493, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 49408, "Total num trained steps": 98149, "Timestamp in ms": 1700790604077, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863229879011046, "Avg loss": 0.4633746495237574, "Avg value loss": 0.2500589171249885, "Avg policy loss": 0.21331572788767517, "Total num played games": 49426, "Total num trained steps": 98176, "Timestamp in ms": 1700790616623, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888924857362522, "Avg loss": 0.3657325542299077, "Avg value loss": 0.14186706562759355, "Avg policy loss": 0.22386548737995327, "Total num played games": 49426, "Total num trained steps": 98304, "Timestamp in ms": 1700790680497, "logtype": "training_step"}
{"Total num played games": 49426, "Total num trained steps": 98318, "Timestamp in ms": 1700790702134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.994257812500003}
{"Ratio train steps to played games": 1.9876418561447438, "Avg loss": 0.5973194949328899, "Avg value loss": 0.3661141798074823, "Avg policy loss": 0.23120531381573528, "Total num played games": 49522, "Total num trained steps": 98432, "Timestamp in ms": 1700790758587, "logtype": "training_step"}
{"Avg objective": 22.088281249999987, "Games time in secs": 205.1562065090984, "Avg game time in secs": 1.723803779183072, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 49536, "Total num trained steps": 98536, "Timestamp in ms": 1700790809234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862756952841596, "Avg loss": 0.4605037518776953, "Avg value loss": 0.24943676809198223, "Avg policy loss": 0.21106698724906892, "Total num played games": 49620, "Total num trained steps": 98560, "Timestamp in ms": 1700790820063, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988875453446191, "Avg loss": 0.3988969972124323, "Avg value loss": 0.17719843130907975, "Avg policy loss": 0.2216985656414181, "Total num played games": 49620, "Total num trained steps": 98688, "Timestamp in ms": 1700790883157, "logtype": "training_step"}
{"Avg objective": 21.42164062499999, "Games time in secs": 95.73009517975152, "Avg game time in secs": 1.7217664450581651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 49664, "Total num trained steps": 98733, "Timestamp in ms": 1700790904964, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875296673237057, "Avg loss": 0.6636136380257085, "Avg value loss": 0.4431777161953505, "Avg policy loss": 0.22043593239504844, "Total num played games": 49718, "Total num trained steps": 98816, "Timestamp in ms": 1700790945557, "logtype": "training_step"}
{"Total num played games": 49718, "Total num trained steps": 98821, "Timestamp in ms": 1700790958472, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4472265625}
{"Avg objective": 21.49453124999999, "Games time in secs": 56.50855436734855, "Avg game time in secs": 1.7239448372856714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 49792, "Total num trained steps": 98827, "Timestamp in ms": 1700790961473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862689203838277, "Avg loss": 0.6432640852872282, "Avg value loss": 0.4054631680774037, "Avg policy loss": 0.23780090746004134, "Total num played games": 49814, "Total num trained steps": 98944, "Timestamp in ms": 1700791019269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888184044646084, "Avg loss": 0.2748095653951168, "Avg value loss": 0.06800557288806885, "Avg policy loss": 0.20680399338016286, "Total num played games": 49814, "Total num trained steps": 99072, "Timestamp in ms": 1700791080764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874779612117326, "Avg loss": 0.6923189846565947, "Avg value loss": 0.47670057974755764, "Avg policy loss": 0.21561840339563787, "Total num played games": 49912, "Total num trained steps": 99200, "Timestamp in ms": 1700791143422, "logtype": "training_step"}
{"Avg objective": 22.001562499999984, "Games time in secs": 242.1165754236281, "Avg game time in secs": 1.70374674188497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 49920, "Total num trained steps": 99314, "Timestamp in ms": 1700791203590, "logtype": "played_game"}
{"Total num played games": 50010, "Total num trained steps": 99321, "Timestamp in ms": 1700791216885, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8997265625}
{"Avg objective": 22.496093749999986, "Games time in secs": 15.78933090902865, "Avg game time in secs": 1.7026140597008634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 50048, "Total num trained steps": 99326, "Timestamp in ms": 1700791219379, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838419749141167, "Avg loss": 0.3877007291885093, "Avg value loss": 0.18210575197008438, "Avg policy loss": 0.20559497666545212, "Total num played games": 50068, "Total num trained steps": 99328, "Timestamp in ms": 1700791219914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848920288987346, "Avg loss": 1.1531802746467292, "Avg value loss": 0.8750199424684979, "Avg policy loss": 0.2781603131443262, "Total num played games": 50106, "Total num trained steps": 99456, "Timestamp in ms": 1700791282580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874466131800583, "Avg loss": 0.3220724907005206, "Avg value loss": 0.082597174186958, "Avg policy loss": 0.23947531776502728, "Total num played games": 50106, "Total num trained steps": 99584, "Timestamp in ms": 1700791346714, "logtype": "training_step"}
{"Avg objective": 22.60484374999999, "Games time in secs": 186.68166981078684, "Avg game time in secs": 1.7311302517628064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 50176, "Total num trained steps": 99705, "Timestamp in ms": 1700791406061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862156886179834, "Avg loss": 0.3372464436106384, "Avg value loss": 0.11364028905518353, "Avg policy loss": 0.22360615525394678, "Total num played games": 50200, "Total num trained steps": 99712, "Timestamp in ms": 1700791409033, "logtype": "training_step"}
{"Total num played games": 50202, "Total num trained steps": 99824, "Timestamp in ms": 1700791475755, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.081562500000004}
{"Ratio train steps to played games": 1.984949699789256, "Avg loss": 0.681503476225771, "Avg value loss": 0.4509868021705188, "Avg policy loss": 0.2305166736477986, "Total num played games": 50298, "Total num trained steps": 99840, "Timestamp in ms": 1700791484859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874945325857887, "Avg loss": 0.5183410892495885, "Avg value loss": 0.2805995940580033, "Avg policy loss": 0.2377414988586679, "Total num played games": 50298, "Total num trained steps": 99968, "Timestamp in ms": 1700791548313, "logtype": "training_step"}
{"Avg objective": 20.764843749999983, "Games time in secs": 199.12719712033868, "Avg game time in secs": 1.76359769309056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 50304, "Total num trained steps": 100088, "Timestamp in ms": 1700791605188, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861695372648622, "Avg loss": 0.3854234324535355, "Avg value loss": 0.16917848962475546, "Avg policy loss": 0.21624494635034353, "Total num played games": 50396, "Total num trained steps": 100096, "Timestamp in ms": 1700791608483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887094213826495, "Avg loss": 0.6453788657672703, "Avg value loss": 0.4094965524272993, "Avg policy loss": 0.23588230600580573, "Total num played games": 50396, "Total num trained steps": 100224, "Timestamp in ms": 1700791674873, "logtype": "training_step"}
{"Avg objective": 21.13124999999999, "Games time in secs": 98.96504855714738, "Avg game time in secs": 1.690660136839142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.36}, "Total num played games": 50432, "Total num trained steps": 100285, "Timestamp in ms": 1700791704153, "logtype": "played_game"}
{"Total num played games": 50492, "Total num trained steps": 100324, "Timestamp in ms": 1700791748490, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.595468750000002}
{"Avg objective": 21.62656249999999, "Games time in secs": 47.58387392759323, "Avg game time in secs": 1.803678102325648, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 50560, "Total num trained steps": 100329, "Timestamp in ms": 1700791751737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836917846129516, "Avg loss": 0.7423065610928461, "Avg value loss": 0.5012675693142228, "Avg policy loss": 0.24103899369947612, "Total num played games": 50588, "Total num trained steps": 100352, "Timestamp in ms": 1700791762651, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862220289396695, "Avg loss": 0.4376825336366892, "Avg value loss": 0.18253230163827538, "Avg policy loss": 0.2551502314163372, "Total num played games": 50588, "Total num trained steps": 100480, "Timestamp in ms": 1700791826425, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887522732663874, "Avg loss": 0.3161078403936699, "Avg value loss": 0.07514993957011029, "Avg policy loss": 0.24095790006686002, "Total num played games": 50588, "Total num trained steps": 100608, "Timestamp in ms": 1700791892711, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875305816431221, "Avg loss": 0.6013457146473229, "Avg value loss": 0.3630437354731839, "Avg policy loss": 0.23830197809729725, "Total num played games": 50684, "Total num trained steps": 100736, "Timestamp in ms": 1700791957147, "logtype": "training_step"}
{"Total num played games": 50684, "Total num trained steps": 100827, "Timestamp in ms": 1700792015820, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.923515625}
{"Avg objective": 21.521874999999987, "Games time in secs": 265.63112688437104, "Avg game time in secs": 1.7979089915024815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 50688, "Total num trained steps": 100830, "Timestamp in ms": 1700792017369, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862741236707364, "Avg loss": 0.5700528377201408, "Avg value loss": 0.34032157363253646, "Avg policy loss": 0.2297312617301941, "Total num played games": 50780, "Total num trained steps": 100864, "Timestamp in ms": 1700792033701, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887948011027963, "Avg loss": 0.3615824173903093, "Avg value loss": 0.13632336899172515, "Avg policy loss": 0.22525904804933816, "Total num played games": 50780, "Total num trained steps": 100992, "Timestamp in ms": 1700792097825, "logtype": "training_step"}
{"Avg objective": 22.02031249999999, "Games time in secs": 109.88651244714856, "Avg game time in secs": 1.5225412630243227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.37}, "Total num played games": 50816, "Total num trained steps": 101053, "Timestamp in ms": 1700792127255, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875579841182482, "Avg loss": 0.5460467347875237, "Avg value loss": 0.3168905201309826, "Avg policy loss": 0.2291562129976228, "Total num played games": 50876, "Total num trained steps": 101120, "Timestamp in ms": 1700792160959, "logtype": "training_step"}
{"Avg objective": 20.744374999999994, "Games time in secs": 98.00960353948176, "Avg game time in secs": 1.7378421251196414, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 50944, "Total num trained steps": 101245, "Timestamp in ms": 1700792225265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862675089261193, "Avg loss": 0.3562478661770001, "Avg value loss": 0.12694134935736656, "Avg policy loss": 0.2293065182166174, "Total num played games": 50974, "Total num trained steps": 101248, "Timestamp in ms": 1700792226789, "logtype": "training_step"}
{"Total num played games": 50974, "Total num trained steps": 101329, "Timestamp in ms": 1700792281169, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.41453125}
{"Ratio train steps to played games": 1.9850205600156647, "Avg loss": 0.9805070778820664, "Avg value loss": 0.7347150769783184, "Avg policy loss": 0.24579202488530427, "Total num played games": 51070, "Total num trained steps": 101376, "Timestamp in ms": 1700792305050, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987546504797337, "Avg loss": 0.3786717840703204, "Avg value loss": 0.14070358633762226, "Avg policy loss": 0.2379681991878897, "Total num played games": 51070, "Total num trained steps": 101504, "Timestamp in ms": 1700792369184, "logtype": "training_step"}
{"Avg objective": 21.364843749999984, "Games time in secs": 208.84042406268418, "Avg game time in secs": 1.7520581514108926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 51072, "Total num trained steps": 101630, "Timestamp in ms": 1700792434106, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867850021503695, "Avg loss": 0.2911826578201726, "Avg value loss": 0.0711318455869332, "Avg policy loss": 0.22005081281531602, "Total num played games": 51150, "Total num trained steps": 101632, "Timestamp in ms": 1700792435551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888207012469217, "Avg loss": 0.8067132299765944, "Avg value loss": 0.5549998517381027, "Avg policy loss": 0.251713375444524, "Total num played games": 51166, "Total num trained steps": 101760, "Timestamp in ms": 1700792497701, "logtype": "training_step"}
{"Avg objective": 22.45624999999999, "Games time in secs": 94.49724639952183, "Avg game time in secs": 1.6984057692752685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 51200, "Total num trained steps": 101823, "Timestamp in ms": 1700792528603, "logtype": "played_game"}
{"Total num played games": 51262, "Total num trained steps": 101829, "Timestamp in ms": 1700792543929, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.196406250000003}
{"Avg objective": 22.235624999999988, "Games time in secs": 18.441393608227372, "Avg game time in secs": 1.7532581121486146, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 51328, "Total num trained steps": 101834, "Timestamp in ms": 1700792547045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838584057011566, "Avg loss": 0.921894658007659, "Avg value loss": 0.6675905457232147, "Avg policy loss": 0.25430411426350474, "Total num played games": 51358, "Total num trained steps": 101888, "Timestamp in ms": 1700792572926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986370185754897, "Avg loss": 0.4002337857382372, "Avg value loss": 0.1470621786720585, "Avg policy loss": 0.2531716040102765, "Total num played games": 51358, "Total num trained steps": 102016, "Timestamp in ms": 1700792638448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98886249464543, "Avg loss": 0.31202747637871653, "Avg value loss": 0.07368980083265342, "Avg policy loss": 0.23833767580799758, "Total num played games": 51358, "Total num trained steps": 102144, "Timestamp in ms": 1700792700336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876394449411126, "Avg loss": 0.5995031350757927, "Avg value loss": 0.35651976615190506, "Avg policy loss": 0.24298336950596422, "Total num played games": 51454, "Total num trained steps": 102272, "Timestamp in ms": 1700792761362, "logtype": "training_step"}
{"Total num played games": 51454, "Total num trained steps": 102329, "Timestamp in ms": 1700792803231, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.446054687500002}
{"Avg objective": 21.61999999999999, "Games time in secs": 257.9724709559232, "Avg game time in secs": 1.6744351069210097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.45, "agent_stopped_0": 0.57}, "Total num played games": 51456, "Total num trained steps": 102331, "Timestamp in ms": 1700792805017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864209505334627, "Avg loss": 0.5715213703224435, "Avg value loss": 0.32056147360708565, "Avg policy loss": 0.2509598931064829, "Total num played games": 51550, "Total num trained steps": 102400, "Timestamp in ms": 1700792837724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889039767216294, "Avg loss": 0.32268517441116273, "Avg value loss": 0.08679110734374262, "Avg policy loss": 0.23589406802784652, "Total num played games": 51550, "Total num trained steps": 102528, "Timestamp in ms": 1700792900609, "logtype": "training_step"}
{"Avg objective": 21.165468749999988, "Games time in secs": 126.50270550698042, "Avg game time in secs": 1.8316330726374872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.43}, "Total num played games": 51584, "Total num trained steps": 102591, "Timestamp in ms": 1700792931520, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876853967393409, "Avg loss": 0.5262683008331805, "Avg value loss": 0.2970850307610817, "Avg policy loss": 0.22918326512444764, "Total num played games": 51646, "Total num trained steps": 102656, "Timestamp in ms": 1700792964855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880082008432942, "Avg loss": 0.30149882554542273, "Avg value loss": 0.08193509158445522, "Avg policy loss": 0.21956373483408242, "Total num played games": 51692, "Total num trained steps": 102784, "Timestamp in ms": 1700793029699, "logtype": "training_step"}
{"Avg objective": 20.99531249999999, "Games time in secs": 98.34375127591193, "Avg game time in secs": 1.7135098482103785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.51}, "Total num played games": 51712, "Total num trained steps": 102784, "Timestamp in ms": 1700793029864, "logtype": "played_game"}
{"Total num played games": 51742, "Total num trained steps": 102832, "Timestamp in ms": 1700793068683, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.159101562500002}
{"Ratio train steps to played games": 1.9852617770747327, "Avg loss": 1.0163168739527464, "Avg value loss": 0.7608530266443267, "Avg policy loss": 0.25546384789049625, "Total num played games": 51838, "Total num trained steps": 102912, "Timestamp in ms": 1700793106497, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877310081407462, "Avg loss": 0.3259842072147876, "Avg value loss": 0.0925990300020203, "Avg policy loss": 0.23338517651427537, "Total num played games": 51838, "Total num trained steps": 103040, "Timestamp in ms": 1700793169058, "logtype": "training_step"}
{"Avg objective": 21.115312499999987, "Games time in secs": 203.97175488434732, "Avg game time in secs": 1.8591759478440508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 51840, "Total num trained steps": 103166, "Timestamp in ms": 1700793233836, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884931190008095, "Avg loss": 0.272370926104486, "Avg value loss": 0.06087656714953482, "Avg policy loss": 0.21149435709230602, "Total num played games": 51880, "Total num trained steps": 103168, "Timestamp in ms": 1700793234605, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889667655100705, "Avg loss": 0.8964973893016577, "Avg value loss": 0.6473641690681688, "Avg policy loss": 0.2491332235513255, "Total num played games": 51934, "Total num trained steps": 103296, "Timestamp in ms": 1700793302260, "logtype": "training_step"}
{"Total num played games": 51934, "Total num trained steps": 103332, "Timestamp in ms": 1700793330961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6380859375}
{"Avg objective": 21.83179687499999, "Games time in secs": 99.64039421826601, "Avg game time in secs": 1.679366053736885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.46}, "Total num played games": 51968, "Total num trained steps": 103336, "Timestamp in ms": 1700793333477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877570632327504, "Avg loss": 0.5213669179938734, "Avg value loss": 0.27855889697093517, "Avg policy loss": 0.24280802230350673, "Total num played games": 52030, "Total num trained steps": 103424, "Timestamp in ms": 1700793376213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988478377755588, "Avg loss": 0.29290198162198067, "Avg value loss": 0.07208491355413571, "Avg policy loss": 0.22081706603057683, "Total num played games": 52072, "Total num trained steps": 103552, "Timestamp in ms": 1700793436641, "logtype": "training_step"}
{"Avg objective": 21.07156249999999, "Games time in secs": 103.52208816818893, "Avg game time in secs": 1.7280466749798506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 52096, "Total num trained steps": 103552, "Timestamp in ms": 1700793436999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890265894179489, "Avg loss": 0.5773333779070526, "Avg value loss": 0.33863213227596134, "Avg policy loss": 0.23870124446693808, "Total num played games": 52126, "Total num trained steps": 103680, "Timestamp in ms": 1700793497814, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878212247711693, "Avg loss": 0.5754593203309923, "Avg value loss": 0.3428776991786435, "Avg policy loss": 0.23258161800913513, "Total num played games": 52222, "Total num trained steps": 103808, "Timestamp in ms": 1700793559724, "logtype": "training_step"}
{"Total num played games": 52222, "Total num trained steps": 103833, "Timestamp in ms": 1700793583302, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.405937500000004}
{"Avg objective": 22.217499999999987, "Games time in secs": 147.94612816348672, "Avg game time in secs": 1.9405633334245067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.61, "agent_stopped_0": 0.47}, "Total num played games": 52224, "Total num trained steps": 103835, "Timestamp in ms": 1700793584945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866011697694865, "Avg loss": 0.6874076263047755, "Avg value loss": 0.43051265040412545, "Avg policy loss": 0.2568949806736782, "Total num played games": 52318, "Total num trained steps": 103936, "Timestamp in ms": 1700793633339, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890668603539892, "Avg loss": 0.32146432832814753, "Avg value loss": 0.08235561728361063, "Avg policy loss": 0.23910871031694114, "Total num played games": 52318, "Total num trained steps": 104064, "Timestamp in ms": 1700793697558, "logtype": "training_step"}
{"Avg objective": 21.52265624999999, "Games time in secs": 143.58440392836928, "Avg game time in secs": 1.588389488766552, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 52352, "Total num trained steps": 104127, "Timestamp in ms": 1700793728530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878658373716946, "Avg loss": 0.765044684172608, "Avg value loss": 0.5313177494972479, "Avg policy loss": 0.23372692009434104, "Total num played games": 52414, "Total num trained steps": 104192, "Timestamp in ms": 1700793759112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879563991157863, "Avg loss": 0.3142597757978365, "Avg value loss": 0.0834791612578556, "Avg policy loss": 0.23078061325941235, "Total num played games": 52466, "Total num trained steps": 104320, "Timestamp in ms": 1700793820781, "logtype": "training_step"}
{"Avg objective": 22.138046874999986, "Games time in secs": 92.25355677492917, "Avg game time in secs": 1.71875117586751, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.48}, "Total num played games": 52480, "Total num trained steps": 104320, "Timestamp in ms": 1700793820783, "logtype": "played_game"}
{"Total num played games": 52512, "Total num trained steps": 104335, "Timestamp in ms": 1700793847429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7658984375}
{"Avg objective": 21.12343749999998, "Games time in secs": 30.713989099487662, "Avg game time in secs": 1.7708185889350716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 52608, "Total num trained steps": 104341, "Timestamp in ms": 1700793851497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853824513381995, "Avg loss": 1.0428081592544913, "Avg value loss": 0.7687873739050701, "Avg policy loss": 0.27402079349849373, "Total num played games": 52608, "Total num trained steps": 104448, "Timestamp in ms": 1700793906769, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878345498783454, "Avg loss": 0.31200745166279376, "Avg value loss": 0.07595355008379556, "Avg policy loss": 0.2360539004439488, "Total num played games": 52608, "Total num trained steps": 104576, "Timestamp in ms": 1700793970173, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902676399026764, "Avg loss": 0.2847079886123538, "Avg value loss": 0.06391324620926753, "Avg policy loss": 0.22079474187921733, "Total num played games": 52608, "Total num trained steps": 104704, "Timestamp in ms": 1700794032951, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890520643594414, "Avg loss": 0.6778051708824933, "Avg value loss": 0.43073545454535633, "Avg policy loss": 0.24706970911938697, "Total num played games": 52704, "Total num trained steps": 104832, "Timestamp in ms": 1700794100349, "logtype": "training_step"}
{"Total num played games": 52704, "Total num trained steps": 104835, "Timestamp in ms": 1700794113583, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.571054687500002}
{"Avg objective": 20.984374999999986, "Games time in secs": 264.81960741244256, "Avg game time in secs": 1.600448996076011, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 52736, "Total num trained steps": 104840, "Timestamp in ms": 1700794116317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878787878787878, "Avg loss": 0.5307589767035097, "Avg value loss": 0.2824668331304565, "Avg policy loss": 0.24829214659985155, "Total num played games": 52800, "Total num trained steps": 104960, "Timestamp in ms": 1700794179571, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902840909090909, "Avg loss": 0.2871099148178473, "Avg value loss": 0.06130778408260085, "Avg policy loss": 0.22580213128821924, "Total num played games": 52800, "Total num trained steps": 105088, "Timestamp in ms": 1700794240829, "logtype": "training_step"}
{"Avg objective": 20.052499999999984, "Games time in secs": 126.80407633259892, "Avg game time in secs": 1.7159911448688945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.54, "agent_stopped_0": 0.48}, "Total num played games": 52864, "Total num trained steps": 105092, "Timestamp in ms": 1700794243121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989091802782819, "Avg loss": 0.6792942441534251, "Avg value loss": 0.4345513009466231, "Avg policy loss": 0.24474294378887862, "Total num played games": 52896, "Total num trained steps": 105216, "Timestamp in ms": 1700794307005, "logtype": "training_step"}
{"Avg objective": 22.15546874999999, "Games time in secs": 99.40392543002963, "Avg game time in secs": 1.8358727064187406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 52992, "Total num trained steps": 105287, "Timestamp in ms": 1700794342525, "logtype": "played_game"}
{"Total num played games": 52996, "Total num trained steps": 105336, "Timestamp in ms": 1700794375609, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6621484375}
{"Ratio train steps to played games": 1.9841784072930009, "Avg loss": 0.6282788276439533, "Avg value loss": 0.39372201715013944, "Avg policy loss": 0.23455679859034717, "Total num played games": 53092, "Total num trained steps": 105344, "Timestamp in ms": 1700794380237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986589316657877, "Avg loss": 0.7795586835127324, "Avg value loss": 0.5197523515089415, "Avg policy loss": 0.2598063495242968, "Total num played games": 53092, "Total num trained steps": 105472, "Timestamp in ms": 1700794442750, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889813907933398, "Avg loss": 0.29192760156001896, "Avg value loss": 0.06937020205077715, "Avg policy loss": 0.22255740012042224, "Total num played games": 53092, "Total num trained steps": 105600, "Timestamp in ms": 1700794510601, "logtype": "training_step"}
{"Avg objective": 22.80515624999999, "Games time in secs": 207.31232228130102, "Avg game time in secs": 1.6019982053112471, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.45, "agent_stopped_0": 0.61}, "Total num played games": 53120, "Total num trained steps": 105676, "Timestamp in ms": 1700794549838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877979995487705, "Avg loss": 0.4564686637604609, "Avg value loss": 0.22654440929181874, "Avg policy loss": 0.2299242541193962, "Total num played games": 53188, "Total num trained steps": 105728, "Timestamp in ms": 1700794574281, "logtype": "training_step"}
{"Total num played games": 53188, "Total num trained steps": 105836, "Timestamp in ms": 1700794645378, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.508984375}
{"Avg objective": 22.69570312499999, "Games time in secs": 98.20679192431271, "Avg game time in secs": 1.5921477729425533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.44}, "Total num played games": 53248, "Total num trained steps": 105841, "Timestamp in ms": 1700794648045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866188724570228, "Avg loss": 0.497016912791878, "Avg value loss": 0.26138603771687485, "Avg policy loss": 0.23563086963258684, "Total num played games": 53284, "Total num trained steps": 105856, "Timestamp in ms": 1700794655426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890398618722318, "Avg loss": 0.4459598730318248, "Avg value loss": 0.20610443330951966, "Avg policy loss": 0.23985544592142105, "Total num played games": 53284, "Total num trained steps": 105984, "Timestamp in ms": 1700794723433, "logtype": "training_step"}
{"Avg objective": 21.468359374999984, "Games time in secs": 115.08898258395493, "Avg game time in secs": 1.7630904174002353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 53376, "Total num trained steps": 106064, "Timestamp in ms": 1700794763134, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98769294170538, "Avg loss": 0.5603093921672553, "Avg value loss": 0.32252313298522495, "Avg policy loss": 0.23778626532293856, "Total num played games": 53384, "Total num trained steps": 106112, "Timestamp in ms": 1700794786465, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990090663869324, "Avg loss": 0.36403192894067615, "Avg value loss": 0.1256816510867793, "Avg policy loss": 0.23835027893073857, "Total num played games": 53384, "Total num trained steps": 106240, "Timestamp in ms": 1700794848989, "logtype": "training_step"}
{"Total num played games": 53484, "Total num trained steps": 106337, "Timestamp in ms": 1700794905333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5116015625}
{"Avg objective": 19.852109374999984, "Games time in secs": 144.27987115457654, "Avg game time in secs": 1.6624703264678828, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 53504, "Total num trained steps": 106341, "Timestamp in ms": 1700794907414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851997013811125, "Avg loss": 0.9839985462604091, "Avg value loss": 0.7326472347485833, "Avg policy loss": 0.2513513119192794, "Total num played games": 53580, "Total num trained steps": 106368, "Timestamp in ms": 1700794919750, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875886524822695, "Avg loss": 0.4469543215818703, "Avg value loss": 0.18818103737430647, "Avg policy loss": 0.25877328496426344, "Total num played games": 53580, "Total num trained steps": 106496, "Timestamp in ms": 1700794979796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899776035834267, "Avg loss": 0.29959733691066504, "Avg value loss": 0.06782924721483141, "Avg policy loss": 0.23176809190772474, "Total num played games": 53580, "Total num trained steps": 106624, "Timestamp in ms": 1700795042432, "logtype": "training_step"}
{"Avg objective": 21.59429687499999, "Games time in secs": 149.76553026027977, "Avg game time in secs": 1.638252914242912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 53632, "Total num trained steps": 106653, "Timestamp in ms": 1700795057183, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887477178732442, "Avg loss": 0.6380927283316851, "Avg value loss": 0.39734603321994655, "Avg policy loss": 0.24074668751563877, "Total num played games": 53678, "Total num trained steps": 106752, "Timestamp in ms": 1700795107484, "logtype": "training_step"}
{"Total num played games": 53678, "Total num trained steps": 106839, "Timestamp in ms": 1700795165189, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.832734375}
{"Avg objective": 21.092968749999986, "Games time in secs": 111.33466289006174, "Avg game time in secs": 1.7936951737792697, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.57}, "Total num played games": 53760, "Total num trained steps": 106847, "Timestamp in ms": 1700795168517, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875590434038755, "Avg loss": 0.5682337204925716, "Avg value loss": 0.32530646439408883, "Avg policy loss": 0.2429272554581985, "Total num played games": 53774, "Total num trained steps": 106880, "Timestamp in ms": 1700795185157, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989939375906572, "Avg loss": 0.33606677839998156, "Avg value loss": 0.10270433028927073, "Avg policy loss": 0.2333624481689185, "Total num played games": 53774, "Total num trained steps": 107008, "Timestamp in ms": 1700795249489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988769259328012, "Avg loss": 0.6533003877848387, "Avg value loss": 0.41486551010166295, "Avg policy loss": 0.23843488632701337, "Total num played games": 53870, "Total num trained steps": 107136, "Timestamp in ms": 1700795311949, "logtype": "training_step"}
{"Avg objective": 21.211718749999985, "Games time in secs": 191.37169462442398, "Avg game time in secs": 1.7376027853169944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.49, "agent_stopped_0": 0.56}, "Total num played games": 53888, "Total num trained steps": 107232, "Timestamp in ms": 1700795359889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875481766973022, "Avg loss": 0.5190560525516048, "Avg value loss": 0.2831691223254893, "Avg policy loss": 0.23588692746125162, "Total num played games": 53968, "Total num trained steps": 107264, "Timestamp in ms": 1700795375426, "logtype": "training_step"}
{"Total num played games": 53968, "Total num trained steps": 107340, "Timestamp in ms": 1700795422077, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3123828125}
{"Avg objective": 20.994921874999992, "Games time in secs": 64.98351927474141, "Avg game time in secs": 1.6853179840109078, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 54016, "Total num trained steps": 107347, "Timestamp in ms": 1700795424873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863680082864752, "Avg loss": 0.6654520679730922, "Avg value loss": 0.41838097776053473, "Avg policy loss": 0.2470710831694305, "Total num played games": 54064, "Total num trained steps": 107392, "Timestamp in ms": 1700795446162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887540692512578, "Avg loss": 0.36647025297861546, "Avg value loss": 0.12365953484550118, "Avg policy loss": 0.2428107151063159, "Total num played games": 54064, "Total num trained steps": 107520, "Timestamp in ms": 1700795509773, "logtype": "training_step"}
{"Avg objective": 21.802343749999988, "Games time in secs": 134.63248264417052, "Avg game time in secs": 1.7868619468063116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 54144, "Total num trained steps": 107623, "Timestamp in ms": 1700795559505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987427073332841, "Avg loss": 0.5980204422958195, "Avg value loss": 0.359747350710677, "Avg policy loss": 0.2382730966201052, "Total num played games": 54164, "Total num trained steps": 107648, "Timestamp in ms": 1700795571519, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898087290451223, "Avg loss": 0.39252926141489297, "Avg value loss": 0.14619358960771933, "Avg policy loss": 0.24633567035198212, "Total num played games": 54164, "Total num trained steps": 107776, "Timestamp in ms": 1700795632328, "logtype": "training_step"}
{"Total num played games": 54260, "Total num trained steps": 107841, "Timestamp in ms": 1700795675471, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.637734375}
{"Avg objective": 22.113124999999986, "Games time in secs": 117.82565350830555, "Avg game time in secs": 1.6806744279892882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 54272, "Total num trained steps": 107845, "Timestamp in ms": 1700795677331, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985135035690632, "Avg loss": 1.2216470133280382, "Avg value loss": 0.959572997118812, "Avg policy loss": 0.2620740015991032, "Total num played games": 54356, "Total num trained steps": 107904, "Timestamp in ms": 1700795707372, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987471484288763, "Avg loss": 0.39177091559395194, "Avg value loss": 0.13727240628213622, "Avg policy loss": 0.25449851131998, "Total num played games": 54356, "Total num trained steps": 108032, "Timestamp in ms": 1700795771343, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98982633011995, "Avg loss": 0.2949269445380196, "Avg value loss": 0.06607489709858783, "Avg policy loss": 0.22885204455815256, "Total num played games": 54356, "Total num trained steps": 108160, "Timestamp in ms": 1700795835083, "logtype": "training_step"}
{"Avg objective": 21.773203124999988, "Games time in secs": 179.57702193781734, "Avg game time in secs": 1.6471311065397458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.52}, "Total num played games": 54400, "Total num trained steps": 108205, "Timestamp in ms": 1700795856908, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988668919415265, "Avg loss": 0.4779792196350172, "Avg value loss": 0.2427398338331841, "Avg policy loss": 0.23523938830476254, "Total num played games": 54452, "Total num trained steps": 108288, "Timestamp in ms": 1700795897565, "logtype": "training_step"}
{"Total num played games": 54452, "Total num trained steps": 108341, "Timestamp in ms": 1700795932688, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9919140625}
{"Avg objective": 21.589921874999987, "Games time in secs": 79.19500349648297, "Avg game time in secs": 1.848145191965159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 54528, "Total num trained steps": 108349, "Timestamp in ms": 1700795936108, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875339150839628, "Avg loss": 0.6896136566065252, "Avg value loss": 0.4394727622566279, "Avg policy loss": 0.25014089583419263, "Total num played games": 54548, "Total num trained steps": 108416, "Timestamp in ms": 1700795966388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898621397668108, "Avg loss": 0.3156583620002493, "Avg value loss": 0.08416451126686297, "Avg policy loss": 0.23149385128635913, "Total num played games": 54548, "Total num trained steps": 108544, "Timestamp in ms": 1700796025366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886359477363393, "Avg loss": 0.6201747205341235, "Avg value loss": 0.377241288049845, "Avg policy loss": 0.2429334237240255, "Total num played games": 54646, "Total num trained steps": 108672, "Timestamp in ms": 1700796084623, "logtype": "training_step"}
{"Avg objective": 23.48046874999999, "Games time in secs": 200.50576271116734, "Avg game time in secs": 1.8320714849542128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 54656, "Total num trained steps": 108784, "Timestamp in ms": 1700796136614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874141458424668, "Avg loss": 0.4987685780506581, "Avg value loss": 0.2674163648043759, "Avg policy loss": 0.23135220957919955, "Total num played games": 54744, "Total num trained steps": 108800, "Timestamp in ms": 1700796144072, "logtype": "training_step"}
{"Total num played games": 54744, "Total num trained steps": 108843, "Timestamp in ms": 1700796174029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.157578125}
{"Avg objective": 20.972656249999986, "Games time in secs": 39.79423675313592, "Avg game time in secs": 1.6198536235751817, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 54784, "Total num trained steps": 108847, "Timestamp in ms": 1700796176408, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986269146608315, "Avg loss": 0.8502071611583233, "Avg value loss": 0.5908626122400165, "Avg policy loss": 0.2593445547390729, "Total num played games": 54840, "Total num trained steps": 108928, "Timestamp in ms": 1700796213926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988603209336251, "Avg loss": 0.3081502828281373, "Avg value loss": 0.08301575825316831, "Avg policy loss": 0.22513452533166856, "Total num played games": 54840, "Total num trained steps": 109056, "Timestamp in ms": 1700796272201, "logtype": "training_step"}
{"Avg objective": 20.581718749999993, "Games time in secs": 148.5724542811513, "Avg game time in secs": 1.648581543006003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 54912, "Total num trained steps": 109174, "Timestamp in ms": 1700796324981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874763361001893, "Avg loss": 0.34109765861649066, "Avg value loss": 0.1255428702570498, "Avg policy loss": 0.215554786962457, "Total num played games": 54936, "Total num trained steps": 109184, "Timestamp in ms": 1700796329160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898063200815495, "Avg loss": 0.3744763978756964, "Avg value loss": 0.15609779668739066, "Avg policy loss": 0.21837860124651343, "Total num played games": 54936, "Total num trained steps": 109312, "Timestamp in ms": 1700796388364, "logtype": "training_step"}
{"Total num played games": 54936, "Total num trained steps": 109346, "Timestamp in ms": 1700796413001, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.998359375}
{"Ratio train steps to played games": 1.9886429713621165, "Avg loss": 0.4944958006963134, "Avg value loss": 0.2693282719119452, "Avg policy loss": 0.22516752581577748, "Total num played games": 55032, "Total num trained steps": 109440, "Timestamp in ms": 1700796458802, "logtype": "training_step"}
{"Avg objective": 19.845390624999986, "Games time in secs": 189.35489975474775, "Avg game time in secs": 1.7874352000362705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 55040, "Total num trained steps": 109556, "Timestamp in ms": 1700796514336, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987501813960238, "Avg loss": 0.3686719899997115, "Avg value loss": 0.15841943779378198, "Avg policy loss": 0.21025255089625716, "Total num played games": 55128, "Total num trained steps": 109568, "Timestamp in ms": 1700796519570, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898236830648672, "Avg loss": 0.4094489887356758, "Avg value loss": 0.19268629897851497, "Avg policy loss": 0.21676268859300762, "Total num played games": 55128, "Total num trained steps": 109696, "Timestamp in ms": 1700796580621, "logtype": "training_step"}
{"Avg objective": 20.479374999999987, "Games time in secs": 90.76913778670132, "Avg game time in secs": 1.6080201947479509, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 55168, "Total num trained steps": 109749, "Timestamp in ms": 1700796605105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988628544526129, "Avg loss": 0.5865985641721636, "Avg value loss": 0.3686163990350906, "Avg policy loss": 0.2179821661557071, "Total num played games": 55226, "Total num trained steps": 109824, "Timestamp in ms": 1700796639712, "logtype": "training_step"}
{"Total num played games": 55226, "Total num trained steps": 109847, "Timestamp in ms": 1700796660761, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.10828125}
{"Avg objective": 20.223203124999984, "Games time in secs": 58.7757395170629, "Avg game time in secs": 1.8279801361641148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 55296, "Total num trained steps": 109853, "Timestamp in ms": 1700796663881, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874914139040527, "Avg loss": 0.5789879562798887, "Avg value loss": 0.3326196544803679, "Avg policy loss": 0.24636829330120236, "Total num played games": 55322, "Total num trained steps": 109952, "Timestamp in ms": 1700796710525, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897870648205054, "Avg loss": 0.2783647128380835, "Avg value loss": 0.06465611141175032, "Avg policy loss": 0.21370860160095617, "Total num played games": 55322, "Total num trained steps": 110080, "Timestamp in ms": 1700796768623, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885781306387587, "Avg loss": 0.6165050693089142, "Avg value loss": 0.393506187654566, "Avg policy loss": 0.2229988812468946, "Total num played games": 55420, "Total num trained steps": 110208, "Timestamp in ms": 1700796826084, "logtype": "training_step"}
{"Avg objective": 22.35859374999999, "Games time in secs": 219.1875978372991, "Avg game time in secs": 1.8590456826786976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.58}, "Total num played games": 55424, "Total num trained steps": 110331, "Timestamp in ms": 1700796883068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875166624635228, "Avg loss": 0.30627268669195473, "Avg value loss": 0.08938989267335273, "Avg policy loss": 0.21688279806403443, "Total num played games": 55512, "Total num trained steps": 110336, "Timestamp in ms": 1700796884821, "logtype": "training_step"}
{"Total num played games": 55516, "Total num trained steps": 110349, "Timestamp in ms": 1700796900373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.042929687500003}
{"Avg objective": 20.995078124999992, "Games time in secs": 19.881069203838706, "Avg game time in secs": 1.591249150398653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.42}, "Total num played games": 55552, "Total num trained steps": 110355, "Timestamp in ms": 1700796902950, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863338847730705, "Avg loss": 0.9666665745899081, "Avg value loss": 0.721404954616446, "Avg policy loss": 0.24526161747053266, "Total num played games": 55612, "Total num trained steps": 110464, "Timestamp in ms": 1700796953125, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886175645544126, "Avg loss": 0.2937384267570451, "Avg value loss": 0.07854625198524445, "Avg policy loss": 0.2151921729091555, "Total num played games": 55612, "Total num trained steps": 110592, "Timestamp in ms": 1700797011957, "logtype": "training_step"}
{"Avg objective": 20.86796874999999, "Games time in secs": 166.94097117334604, "Avg game time in secs": 1.7019065949280048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.55, "agent_stopped_0": 0.45}, "Total num played games": 55680, "Total num trained steps": 110718, "Timestamp in ms": 1700797069891, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876490018670114, "Avg loss": 0.264495404320769, "Avg value loss": 0.0686792511260137, "Avg policy loss": 0.1958161515649408, "Total num played games": 55704, "Total num trained steps": 110720, "Timestamp in ms": 1700797070766, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898039778846843, "Avg loss": 0.6394919283920899, "Avg value loss": 0.4225985091761686, "Avg policy loss": 0.2168934265500866, "Total num played games": 55708, "Total num trained steps": 110848, "Timestamp in ms": 1700797131804, "logtype": "training_step"}
{"Total num played games": 55708, "Total num trained steps": 110853, "Timestamp in ms": 1700797144078, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.284648437500003}
{"Ratio train steps to played games": 1.9886567271163358, "Avg loss": 0.4228245437843725, "Avg value loss": 0.20689481988665648, "Avg policy loss": 0.21592972369398922, "Total num played games": 55804, "Total num trained steps": 110976, "Timestamp in ms": 1700797204367, "logtype": "training_step"}
{"Avg objective": 19.978671874999986, "Games time in secs": 192.62925178557634, "Avg game time in secs": 1.6670361660944764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 55808, "Total num trained steps": 111100, "Timestamp in ms": 1700797262520, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878157875903528, "Avg loss": 0.27514151227660477, "Avg value loss": 0.07338266106671654, "Avg policy loss": 0.20175884827040136, "Total num played games": 55890, "Total num trained steps": 111104, "Timestamp in ms": 1700797264186, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896787349742415, "Avg loss": 0.7507718214765191, "Avg value loss": 0.5172959953779355, "Avg policy loss": 0.23347582330461591, "Total num played games": 55904, "Total num trained steps": 111232, "Timestamp in ms": 1700797322666, "logtype": "training_step"}
{"Avg objective": 22.78203124999999, "Games time in secs": 91.65750409848988, "Avg game time in secs": 1.6765457062865607, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 55936, "Total num trained steps": 111301, "Timestamp in ms": 1700797354178, "logtype": "played_game"}
{"Total num played games": 56000, "Total num trained steps": 111355, "Timestamp in ms": 1700797390569, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.053984375000002}
{"Ratio train steps to played games": 1.987346967912339, "Avg loss": 0.5895769625203684, "Avg value loss": 0.3637323354196269, "Avg policy loss": 0.22584462771192193, "Total num played games": 56034, "Total num trained steps": 111360, "Timestamp in ms": 1700797393420, "logtype": "training_step"}
{"Avg objective": 21.191406249999986, "Games time in secs": 39.6317170150578, "Avg game time in secs": 1.768292832071893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 56064, "Total num trained steps": 111361, "Timestamp in ms": 1700797393810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874322589845979, "Avg loss": 0.631849511526525, "Avg value loss": 0.35952007872401737, "Avg policy loss": 0.27232943288981915, "Total num played games": 56096, "Total num trained steps": 111488, "Timestamp in ms": 1700797451121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897140616086708, "Avg loss": 0.3080131182214245, "Avg value loss": 0.06369276758050546, "Avg policy loss": 0.24432035046629608, "Total num played games": 56096, "Total num trained steps": 111616, "Timestamp in ms": 1700797511289, "logtype": "training_step"}
{"Avg objective": 21.126562499999984, "Games time in secs": 150.85378264263272, "Avg game time in secs": 1.8666893323534168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 56192, "Total num trained steps": 111689, "Timestamp in ms": 1700797544664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988380369408164, "Avg loss": 0.6173536527203396, "Avg value loss": 0.37152455138857476, "Avg policy loss": 0.24582910351455212, "Total num played games": 56198, "Total num trained steps": 111744, "Timestamp in ms": 1700797569337, "logtype": "training_step"}
{"Total num played games": 56198, "Total num trained steps": 111857, "Timestamp in ms": 1700797632816, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.703515625}
{"Ratio train steps to played games": 1.987281060148506, "Avg loss": 0.4423537290422246, "Avg value loss": 0.19870234082918614, "Avg policy loss": 0.2436513853026554, "Total num played games": 56294, "Total num trained steps": 111872, "Timestamp in ms": 1700797640394, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895370732227236, "Avg loss": 0.4424132585991174, "Avg value loss": 0.19486190169118345, "Avg policy loss": 0.24755135586019605, "Total num played games": 56294, "Total num trained steps": 112000, "Timestamp in ms": 1700797701845, "logtype": "training_step"}
{"Avg objective": 21.645781249999985, "Games time in secs": 194.83452462404966, "Avg game time in secs": 1.5784719813091215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 56320, "Total num trained steps": 112081, "Timestamp in ms": 1700797739499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988349411264009, "Avg loss": 0.48754478991031647, "Avg value loss": 0.25225120814866386, "Avg policy loss": 0.23529357626102865, "Total num played games": 56392, "Total num trained steps": 112128, "Timestamp in ms": 1700797760929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906192367711733, "Avg loss": 0.320053699077107, "Avg value loss": 0.0859668746998068, "Avg policy loss": 0.23408682795707136, "Total num played games": 56392, "Total num trained steps": 112256, "Timestamp in ms": 1700797820349, "logtype": "training_step"}
{"Avg objective": 21.313046874999984, "Games time in secs": 90.8898327127099, "Avg game time in secs": 1.6639943539630622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.48, "agent_stopped_0": 0.54}, "Total num played games": 56448, "Total num trained steps": 112277, "Timestamp in ms": 1700797830389, "logtype": "played_game"}
{"Total num played games": 56488, "Total num trained steps": 112360, "Timestamp in ms": 1700797879145, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0954296875}
{"Avg objective": 22.406015624999988, "Games time in secs": 52.38079129718244, "Avg game time in secs": 1.7587866099347593, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.52}, "Total num played games": 56576, "Total num trained steps": 112367, "Timestamp in ms": 1700797882770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986126820302559, "Avg loss": 0.8924926006002352, "Avg value loss": 0.6389800714096054, "Avg policy loss": 0.2535125262802467, "Total num played games": 56584, "Total num trained steps": 112384, "Timestamp in ms": 1700797890309, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884066167114378, "Avg loss": 0.4896266518626362, "Avg value loss": 0.23940760354162194, "Avg policy loss": 0.25021904706954956, "Total num played games": 56584, "Total num trained steps": 112512, "Timestamp in ms": 1700797950273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990651067439559, "Avg loss": 0.28746395639609545, "Avg value loss": 0.05922035494586453, "Avg policy loss": 0.2282436004607007, "Total num played games": 56584, "Total num trained steps": 112640, "Timestamp in ms": 1700798008249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891342693854512, "Avg loss": 0.6542899367632344, "Avg value loss": 0.390984024037607, "Avg policy loss": 0.2633059130748734, "Total num played games": 56692, "Total num trained steps": 112768, "Timestamp in ms": 1700798065255, "logtype": "training_step"}
{"Total num played games": 56692, "Total num trained steps": 112861, "Timestamp in ms": 1700798118769, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.780078125000003}
{"Avg objective": 22.12007812499998, "Games time in secs": 237.95016734488308, "Avg game time in secs": 1.7569976310624043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 56704, "Total num trained steps": 112864, "Timestamp in ms": 1700798120720, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880256392195534, "Avg loss": 0.6027241479605436, "Avg value loss": 0.3483320112864021, "Avg policy loss": 0.25439212773926556, "Total num played games": 56788, "Total num trained steps": 112896, "Timestamp in ms": 1700798135992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902620271888427, "Avg loss": 0.3902410832233727, "Avg value loss": 0.12971159469452687, "Avg policy loss": 0.2605294870445505, "Total num played games": 56788, "Total num trained steps": 113024, "Timestamp in ms": 1700798195531, "logtype": "training_step"}
{"Avg objective": 21.533593749999984, "Games time in secs": 96.12567655928433, "Avg game time in secs": 1.6365870227018604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.49}, "Total num played games": 56832, "Total num trained steps": 113070, "Timestamp in ms": 1700798216846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890834300179305, "Avg loss": 0.554608731996268, "Avg value loss": 0.2930841585912276, "Avg policy loss": 0.26152456807903945, "Total num played games": 56886, "Total num trained steps": 113152, "Timestamp in ms": 1700798254488, "logtype": "training_step"}
{"Avg objective": 21.304374999999993, "Games time in secs": 91.73571112193167, "Avg game time in secs": 1.7708799408428604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.56}, "Total num played games": 56960, "Total num trained steps": 113266, "Timestamp in ms": 1700798308582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878391183799529, "Avg loss": 0.4022142136236653, "Avg value loss": 0.1580961990111973, "Avg policy loss": 0.24411801027599722, "Total num played games": 56986, "Total num trained steps": 113280, "Timestamp in ms": 1700798314477, "logtype": "training_step"}
{"Total num played games": 56986, "Total num trained steps": 113361, "Timestamp in ms": 1700798362338, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9168359375}
{"Ratio train steps to played games": 1.9867383763708348, "Avg loss": 0.7344881060998887, "Avg value loss": 0.4648947640671395, "Avg policy loss": 0.2695933524519205, "Total num played games": 57082, "Total num trained steps": 113408, "Timestamp in ms": 1700798385795, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889807645142077, "Avg loss": 0.3781563169322908, "Avg value loss": 0.10205667611444369, "Avg policy loss": 0.2760996433207765, "Total num played games": 57082, "Total num trained steps": 113536, "Timestamp in ms": 1700798448230, "logtype": "training_step"}
{"Avg objective": 22.134374999999988, "Games time in secs": 194.45260247774422, "Avg game time in secs": 1.874255692877341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 57088, "Total num trained steps": 113656, "Timestamp in ms": 1700798503034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878799538283956, "Avg loss": 0.3572225522948429, "Avg value loss": 0.11190890037687495, "Avg policy loss": 0.24531364848371595, "Total num played games": 57178, "Total num trained steps": 113664, "Timestamp in ms": 1700798506492, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901185770750989, "Avg loss": 0.538213272113353, "Avg value loss": 0.27807626346475445, "Avg policy loss": 0.2601370095508173, "Total num played games": 57178, "Total num trained steps": 113792, "Timestamp in ms": 1700798563721, "logtype": "training_step"}
{"Avg objective": 21.176562499999985, "Games time in secs": 86.35478463768959, "Avg game time in secs": 1.582471104353317, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 57216, "Total num trained steps": 113849, "Timestamp in ms": 1700798589389, "logtype": "played_game"}
{"Total num played games": 57286, "Total num trained steps": 113864, "Timestamp in ms": 1700798605833, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.171484375}
{"Avg objective": 21.940078124999985, "Games time in secs": 19.191325845196843, "Avg game time in secs": 1.6621370013599517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 57344, "Total num trained steps": 113869, "Timestamp in ms": 1700798608581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852741277752606, "Avg loss": 1.0726636108011007, "Avg value loss": 0.7955220885341987, "Avg policy loss": 0.2771415306488052, "Total num played games": 57382, "Total num trained steps": 113920, "Timestamp in ms": 1700798631977, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875047924436235, "Avg loss": 0.40480771800503135, "Avg value loss": 0.13296174618881196, "Avg policy loss": 0.2718459704192355, "Total num played games": 57382, "Total num trained steps": 114048, "Timestamp in ms": 1700798691714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897528841797079, "Avg loss": 0.3027813546359539, "Avg value loss": 0.05600247730035335, "Avg policy loss": 0.24677887407597154, "Total num played games": 57382, "Total num trained steps": 114176, "Timestamp in ms": 1700798749857, "logtype": "training_step"}
{"Avg objective": 22.27617187499998, "Games time in secs": 178.9181499760598, "Avg game time in secs": 1.7615538445534185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 57472, "Total num trained steps": 114260, "Timestamp in ms": 1700798787499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885699373695198, "Avg loss": 0.5648980556288734, "Avg value loss": 0.31434168803389184, "Avg policy loss": 0.25055636290926486, "Total num played games": 57480, "Total num trained steps": 114304, "Timestamp in ms": 1700798806845, "logtype": "training_step"}
{"Total num played games": 57480, "Total num trained steps": 114365, "Timestamp in ms": 1700798844519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.538515625000002}
{"Ratio train steps to played games": 1.9874774211477004, "Avg loss": 0.5934122842736542, "Avg value loss": 0.32800803234567866, "Avg policy loss": 0.26540425000712276, "Total num played games": 57576, "Total num trained steps": 114432, "Timestamp in ms": 1700798876209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989700569681812, "Avg loss": 0.3199700319673866, "Avg value loss": 0.0776652175700292, "Avg policy loss": 0.2423048148630187, "Total num played games": 57576, "Total num trained steps": 114560, "Timestamp in ms": 1700798936671, "logtype": "training_step"}
{"Avg objective": 22.223203124999984, "Games time in secs": 187.4542368762195, "Avg game time in secs": 1.7193620081379777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 57600, "Total num trained steps": 114644, "Timestamp in ms": 1700798974953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885390297187642, "Avg loss": 0.5686462054727599, "Avg value loss": 0.326126866042614, "Avg policy loss": 0.2425193504896015, "Total num played games": 57674, "Total num trained steps": 114688, "Timestamp in ms": 1700798994724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990775739501335, "Avg loss": 0.31906795455142856, "Avg value loss": 0.08788193549844436, "Avg policy loss": 0.2311860171612352, "Total num played games": 57674, "Total num trained steps": 114816, "Timestamp in ms": 1700799054223, "logtype": "training_step"}
{"Avg objective": 21.657968749999984, "Games time in secs": 90.5662720091641, "Avg game time in secs": 1.6466887099086307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 57728, "Total num trained steps": 114841, "Timestamp in ms": 1700799065520, "logtype": "played_game"}
{"Total num played games": 57772, "Total num trained steps": 114866, "Timestamp in ms": 1700799086602, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.680507812500004}
{"Avg objective": 22.020781249999985, "Games time in secs": 24.43922564946115, "Avg game time in secs": 1.7496033750940114, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 57856, "Total num trained steps": 114874, "Timestamp in ms": 1700799089959, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862963987004907, "Avg loss": 0.900810255901888, "Avg value loss": 0.6362892519973684, "Avg policy loss": 0.264521008124575, "Total num played games": 57868, "Total num trained steps": 114944, "Timestamp in ms": 1700799124052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885083293011683, "Avg loss": 0.34348126454278827, "Avg value loss": 0.09304347599390894, "Avg policy loss": 0.25043778878170997, "Total num played games": 57868, "Total num trained steps": 115072, "Timestamp in ms": 1700799185364, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907202599018456, "Avg loss": 0.2863849417772144, "Avg value loss": 0.055673531896900386, "Avg policy loss": 0.23071141226682812, "Total num played games": 57868, "Total num trained steps": 115200, "Timestamp in ms": 1700799250265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895628471862816, "Avg loss": 0.5441069790394977, "Avg value loss": 0.2951386566273868, "Avg policy loss": 0.24896832834929228, "Total num played games": 57966, "Total num trained steps": 115328, "Timestamp in ms": 1700799313791, "logtype": "training_step"}
{"Total num played games": 57966, "Total num trained steps": 115366, "Timestamp in ms": 1700799342300, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.795390625000003}
{"Avg objective": 21.898281249999986, "Games time in secs": 254.6417244002223, "Avg game time in secs": 1.7139797452837229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 57984, "Total num trained steps": 115370, "Timestamp in ms": 1700799344601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988495057008026, "Avg loss": 0.6493633751524612, "Avg value loss": 0.39534153073327616, "Avg policy loss": 0.2540218506474048, "Total num played games": 58062, "Total num trained steps": 115456, "Timestamp in ms": 1700799385961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906995969825358, "Avg loss": 0.31473573960829526, "Avg value loss": 0.06707407446810976, "Avg policy loss": 0.24766166624613106, "Total num played games": 58062, "Total num trained steps": 115584, "Timestamp in ms": 1700799449251, "logtype": "training_step"}
{"Avg objective": 21.582812499999985, "Games time in secs": 121.44285432435572, "Avg game time in secs": 1.7487532234663377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.58}, "Total num played games": 58112, "Total num trained steps": 115618, "Timestamp in ms": 1700799466044, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895460797799174, "Avg loss": 0.554377340245992, "Avg value loss": 0.30507740390021354, "Avg policy loss": 0.24929993285331875, "Total num played games": 58160, "Total num trained steps": 115712, "Timestamp in ms": 1700799513037, "logtype": "training_step"}
{"Avg objective": 21.579453124999986, "Games time in secs": 97.81472899205983, "Avg game time in secs": 1.790551520723966, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 58240, "Total num trained steps": 115814, "Timestamp in ms": 1700799563859, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884475418840977, "Avg loss": 0.5379077998222783, "Avg value loss": 0.3002768747101072, "Avg policy loss": 0.23763091932050884, "Total num played games": 58256, "Total num trained steps": 115840, "Timestamp in ms": 1700799576101, "logtype": "training_step"}
{"Total num played games": 58256, "Total num trained steps": 115866, "Timestamp in ms": 1700799600697, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.29984375}
{"Ratio train steps to played games": 1.9873868933369894, "Avg loss": 0.8160990586038679, "Avg value loss": 0.55598808004288, "Avg policy loss": 0.26011098560411483, "Total num played games": 58352, "Total num trained steps": 115968, "Timestamp in ms": 1700799653649, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895804771044694, "Avg loss": 0.31501894432585686, "Avg value loss": 0.08914948417805135, "Avg policy loss": 0.2258694627089426, "Total num played games": 58352, "Total num trained steps": 116096, "Timestamp in ms": 1700799720476, "logtype": "training_step"}
{"Avg objective": 21.544062499999985, "Games time in secs": 206.54271076060832, "Avg game time in secs": 1.6947213628300233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 58368, "Total num trained steps": 116197, "Timestamp in ms": 1700799770402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884174508126604, "Avg loss": 0.5167571324855089, "Avg value loss": 0.29451817894005217, "Avg policy loss": 0.22223895497154444, "Total num played games": 58450, "Total num trained steps": 116224, "Timestamp in ms": 1700799783438, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906073567151412, "Avg loss": 0.3941796808503568, "Avg value loss": 0.16812447374104522, "Avg policy loss": 0.2260552062653005, "Total num played games": 58450, "Total num trained steps": 116352, "Timestamp in ms": 1700799843602, "logtype": "training_step"}
{"Total num played games": 58450, "Total num trained steps": 116368, "Timestamp in ms": 1700799861465, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.690859375000002}
{"Avg objective": 20.820078124999988, "Games time in secs": 93.64506979100406, "Avg game time in secs": 1.6671480042859912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 58496, "Total num trained steps": 116373, "Timestamp in ms": 1700799864047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895296006558945, "Avg loss": 0.6039619487710297, "Avg value loss": 0.3795658138114959, "Avg policy loss": 0.2243961424101144, "Total num played games": 58546, "Total num trained steps": 116480, "Timestamp in ms": 1700799914840, "logtype": "training_step"}
{"Avg objective": 20.88749999999998, "Games time in secs": 99.49215001426637, "Avg game time in secs": 1.7513255257508717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 58624, "Total num trained steps": 116586, "Timestamp in ms": 1700799963540, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882519438003001, "Avg loss": 0.5019579295767471, "Avg value loss": 0.2864573963161092, "Avg policy loss": 0.21550052938982844, "Total num played games": 58648, "Total num trained steps": 116608, "Timestamp in ms": 1700799973405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904344564179512, "Avg loss": 0.3881477153627202, "Avg value loss": 0.16150455991737545, "Avg policy loss": 0.22664315754082054, "Total num played games": 58648, "Total num trained steps": 116736, "Timestamp in ms": 1700800032893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989309910461989, "Avg loss": 0.48495041648857296, "Avg value loss": 0.25815366965252906, "Avg policy loss": 0.22679674881510437, "Total num played games": 58746, "Total num trained steps": 116864, "Timestamp in ms": 1700800092753, "logtype": "training_step"}
{"Total num played games": 58746, "Total num trained steps": 116869, "Timestamp in ms": 1700800105419, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.008125}
{"Avg objective": 20.671874999999982, "Games time in secs": 143.43364919163287, "Avg game time in secs": 1.819501238045632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 58752, "Total num trained steps": 116870, "Timestamp in ms": 1700800106973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882396927364807, "Avg loss": 0.7156256017042324, "Avg value loss": 0.45845362747786567, "Avg policy loss": 0.2571719711413607, "Total num played games": 58842, "Total num trained steps": 116992, "Timestamp in ms": 1700800164527, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903980150232827, "Avg loss": 0.28989657887723297, "Avg value loss": 0.06185238226316869, "Avg policy loss": 0.2280441956827417, "Total num played games": 58842, "Total num trained steps": 117120, "Timestamp in ms": 1700800225446, "logtype": "training_step"}
{"Avg objective": 23.283593749999987, "Games time in secs": 145.21899937093258, "Avg game time in secs": 1.6469191816286184, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 58880, "Total num trained steps": 117177, "Timestamp in ms": 1700800252192, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892602646759416, "Avg loss": 0.677449110080488, "Avg value loss": 0.43425557046430185, "Avg policy loss": 0.24319354130420834, "Total num played games": 58940, "Total num trained steps": 117248, "Timestamp in ms": 1700800284582, "logtype": "training_step"}
{"Avg objective": 22.11546874999999, "Games time in secs": 89.220492888242, "Avg game time in secs": 1.7079019689699635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 59008, "Total num trained steps": 117373, "Timestamp in ms": 1700800341413, "logtype": "played_game"}
{"Total num played games": 59038, "Total num trained steps": 117373, "Timestamp in ms": 1700800353117, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.233828125000002}
{"Ratio train steps to played games": 1.9867971156775788, "Avg loss": 0.3386560023063794, "Avg value loss": 0.09849276416935027, "Avg policy loss": 0.24016323906835169, "Total num played games": 59066, "Total num trained steps": 117376, "Timestamp in ms": 1700800355706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870801907532045, "Avg loss": 0.9953281108755618, "Avg value loss": 0.7200086357770488, "Avg policy loss": 0.2753194635733962, "Total num played games": 59134, "Total num trained steps": 117504, "Timestamp in ms": 1700800417544, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989227855379308, "Avg loss": 0.3176638282602653, "Avg value loss": 0.0705859353474807, "Avg policy loss": 0.24707789276726544, "Total num played games": 59134, "Total num trained steps": 117632, "Timestamp in ms": 1700800478668, "logtype": "training_step"}
{"Avg objective": 22.831562499999983, "Games time in secs": 195.41588130779564, "Avg game time in secs": 1.7753296162409242, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 59136, "Total num trained steps": 117759, "Timestamp in ms": 1700800536829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912746457438533, "Avg loss": 0.2807684587314725, "Avg value loss": 0.056229079025797546, "Avg policy loss": 0.2245393784251064, "Total num played games": 59136, "Total num trained steps": 117760, "Timestamp in ms": 1700800536948, "logtype": "training_step"}
{"Total num played games": 59232, "Total num trained steps": 117877, "Timestamp in ms": 1700800602129, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3562890625}
{"Avg objective": 21.86249999999999, "Games time in secs": 67.84372957982123, "Avg game time in secs": 1.5636212700919714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 59264, "Total num trained steps": 117883, "Timestamp in ms": 1700800604673, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987188996021846, "Avg loss": 0.5505572437541559, "Avg value loss": 0.310031590575818, "Avg policy loss": 0.24052565405145288, "Total num played games": 59324, "Total num trained steps": 117888, "Timestamp in ms": 1700800606755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891956580366774, "Avg loss": 0.566756678163074, "Avg value loss": 0.3173312524158973, "Avg policy loss": 0.24942543357610703, "Total num played games": 59328, "Total num trained steps": 118016, "Timestamp in ms": 1700800665173, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913531553398058, "Avg loss": 0.2880083069903776, "Avg value loss": 0.06620101787848398, "Avg policy loss": 0.22180729021783918, "Total num played games": 59328, "Total num trained steps": 118144, "Timestamp in ms": 1700800728976, "logtype": "training_step"}
{"Avg objective": 21.581249999999986, "Games time in secs": 126.81229335255921, "Avg game time in secs": 1.7780981364048785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 59392, "Total num trained steps": 118151, "Timestamp in ms": 1700800731485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990106007067138, "Avg loss": 0.6344651442486793, "Avg value loss": 0.3790874798723962, "Avg policy loss": 0.25537766597699374, "Total num played games": 59430, "Total num trained steps": 118272, "Timestamp in ms": 1700800791086, "logtype": "training_step"}
{"Avg objective": 22.145312499999985, "Games time in secs": 98.840421134606, "Avg game time in secs": 1.8204362624965142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.69, "agent_stopped_0": 0.41}, "Total num played games": 59520, "Total num trained steps": 118356, "Timestamp in ms": 1700800830326, "logtype": "played_game"}
{"Total num played games": 59526, "Total num trained steps": 118379, "Timestamp in ms": 1700800850449, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.252265625}
{"Ratio train steps to played games": 1.9858273791553454, "Avg loss": 0.677769216010347, "Avg value loss": 0.432988816377474, "Avg policy loss": 0.24478040484245867, "Total num played games": 59622, "Total num trained steps": 118400, "Timestamp in ms": 1700800860095, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879742376974943, "Avg loss": 0.5870266708079726, "Avg value loss": 0.31205915729515254, "Avg policy loss": 0.27496751002036035, "Total num played games": 59622, "Total num trained steps": 118528, "Timestamp in ms": 1700800919577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901210962396432, "Avg loss": 0.30857207742519677, "Avg value loss": 0.06867558104568161, "Avg policy loss": 0.23989649396389723, "Total num played games": 59622, "Total num trained steps": 118656, "Timestamp in ms": 1700800979191, "logtype": "training_step"}
{"Avg objective": 21.11539062499998, "Games time in secs": 184.9274815171957, "Avg game time in secs": 1.6653028624714352, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 59648, "Total num trained steps": 118737, "Timestamp in ms": 1700801015254, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889986604152712, "Avg loss": 0.4758150439010933, "Avg value loss": 0.239742244099034, "Avg policy loss": 0.23607279546558857, "Total num played games": 59720, "Total num trained steps": 118784, "Timestamp in ms": 1700801037145, "logtype": "training_step"}
{"Total num played games": 59720, "Total num trained steps": 118879, "Timestamp in ms": 1700801090428, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.102109375}
{"Avg objective": 21.666953124999985, "Games time in secs": 77.97756198048592, "Avg game time in secs": 1.7166680609661853, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 59776, "Total num trained steps": 118885, "Timestamp in ms": 1700801093231, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879463688645178, "Avg loss": 0.6496596224606037, "Avg value loss": 0.404230201325845, "Avg policy loss": 0.24542942096013576, "Total num played games": 59816, "Total num trained steps": 118912, "Timestamp in ms": 1700801105007, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901029824796042, "Avg loss": 0.4643009949941188, "Avg value loss": 0.2013912747206632, "Avg policy loss": 0.26290972204878926, "Total num played games": 59816, "Total num trained steps": 119040, "Timestamp in ms": 1700801166401, "logtype": "training_step"}
{"Avg objective": 21.460624999999986, "Games time in secs": 114.5341772492975, "Avg game time in secs": 1.9499285699857865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 59904, "Total num trained steps": 119127, "Timestamp in ms": 1700801207766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889842107020062, "Avg loss": 0.5040769076440483, "Avg value loss": 0.2586231161549222, "Avg policy loss": 0.2454537944868207, "Total num played games": 59914, "Total num trained steps": 119168, "Timestamp in ms": 1700801226040, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911039156123778, "Avg loss": 0.3520209586713463, "Avg value loss": 0.09410238280543126, "Avg policy loss": 0.25791857426520437, "Total num played games": 59914, "Total num trained steps": 119296, "Timestamp in ms": 1700801286634, "logtype": "training_step"}
{"Total num played games": 60014, "Total num trained steps": 119382, "Timestamp in ms": 1700801337487, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8174609375}
{"Avg objective": 21.604453124999985, "Games time in secs": 131.911357216537, "Avg game time in secs": 1.7215111448022071, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.52, "agent_stopped_0": 0.5}, "Total num played games": 60032, "Total num trained steps": 119387, "Timestamp in ms": 1700801339677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986757611046415, "Avg loss": 1.0738913064124063, "Avg value loss": 0.7894931362243369, "Avg policy loss": 0.2843981687910855, "Total num played games": 60110, "Total num trained steps": 119424, "Timestamp in ms": 1700801357133, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888870404258858, "Avg loss": 0.421420726692304, "Avg value loss": 0.151089323713677, "Avg policy loss": 0.27033140580169857, "Total num played games": 60110, "Total num trained steps": 119552, "Timestamp in ms": 1700801416841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910164698053567, "Avg loss": 0.30851192225236446, "Avg value loss": 0.06539340846939012, "Avg policy loss": 0.24311851302627474, "Total num played games": 60110, "Total num trained steps": 119680, "Timestamp in ms": 1700801477016, "logtype": "training_step"}
{"Avg objective": 22.05390624999999, "Games time in secs": 152.3112907987088, "Avg game time in secs": 1.6095673434901983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.51, "agent_stopped_0": 0.51}, "Total num played games": 60160, "Total num trained steps": 119713, "Timestamp in ms": 1700801491989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899511676577086, "Avg loss": 0.6261638759169728, "Avg value loss": 0.37429757084464654, "Avg policy loss": 0.251866306993179, "Total num played games": 60206, "Total num trained steps": 119808, "Timestamp in ms": 1700801535141, "logtype": "training_step"}
{"Total num played games": 60206, "Total num trained steps": 119885, "Timestamp in ms": 1700801580652, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5058203125}
{"Avg objective": 21.650468749999984, "Games time in secs": 92.22747267782688, "Avg game time in secs": 1.8768213057919638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 60288, "Total num trained steps": 119893, "Timestamp in ms": 1700801584216, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889058406023017, "Avg loss": 0.553178884787485, "Avg value loss": 0.3054502143932041, "Avg policy loss": 0.24772866803687066, "Total num played games": 60302, "Total num trained steps": 119936, "Timestamp in ms": 1700801604143, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910450731319027, "Avg loss": 0.3628499584738165, "Avg value loss": 0.09447710515814833, "Avg policy loss": 0.268372853519395, "Total num played games": 60302, "Total num trained steps": 120064, "Timestamp in ms": 1700801663409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899172185430463, "Avg loss": 0.7815091097727418, "Avg value loss": 0.4979713170614559, "Avg policy loss": 0.28353778913151473, "Total num played games": 60400, "Total num trained steps": 120192, "Timestamp in ms": 1700801723737, "logtype": "training_step"}
{"Avg objective": 24.30234374999998, "Games time in secs": 187.54107611998916, "Avg game time in secs": 1.8903152369894087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.67, "agent_stopped_0": 0.43}, "Total num played games": 60416, "Total num trained steps": 120292, "Timestamp in ms": 1700801771758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888752975403332, "Avg loss": 0.6039603728568181, "Avg value loss": 0.3338285197969526, "Avg policy loss": 0.27013185468968004, "Total num played games": 60496, "Total num trained steps": 120320, "Timestamp in ms": 1700801784320, "logtype": "training_step"}
{"Total num played games": 60496, "Total num trained steps": 120386, "Timestamp in ms": 1700801824489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.534843750000004}
{"Avg objective": 21.360624999999985, "Games time in secs": 55.50983866862953, "Avg game time in secs": 1.7078453841240844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.56}, "Total num played games": 60544, "Total num trained steps": 120392, "Timestamp in ms": 1700801827268, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878366781093213, "Avg loss": 0.6571327513083816, "Avg value loss": 0.3622947929543443, "Avg policy loss": 0.29483795864507556, "Total num played games": 60592, "Total num trained steps": 120448, "Timestamp in ms": 1700801852453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899656720359122, "Avg loss": 0.3661829836200923, "Avg value loss": 0.08696434760349803, "Avg policy loss": 0.27921863773372024, "Total num played games": 60592, "Total num trained steps": 120576, "Timestamp in ms": 1700801912583, "logtype": "training_step"}
{"Avg objective": 20.570312499999993, "Games time in secs": 133.20507264323533, "Avg game time in secs": 1.7232500589889241, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.53}, "Total num played games": 60672, "Total num trained steps": 120678, "Timestamp in ms": 1700801960473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888614269237106, "Avg loss": 0.46095314901322126, "Avg value loss": 0.20033498480916023, "Avg policy loss": 0.26061816315632313, "Total num played games": 60690, "Total num trained steps": 120704, "Timestamp in ms": 1700801972137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909540286702916, "Avg loss": 0.3854760271497071, "Avg value loss": 0.12413324482622556, "Avg policy loss": 0.26134278415702283, "Total num played games": 60690, "Total num trained steps": 120832, "Timestamp in ms": 1700802032247, "logtype": "training_step"}
{"Total num played games": 60786, "Total num trained steps": 120889, "Timestamp in ms": 1700802068383, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.614414062500003}
{"Avg objective": 21.963437499999984, "Games time in secs": 110.05611255019903, "Avg game time in secs": 1.7230895553075243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 60800, "Total num trained steps": 120893, "Timestamp in ms": 1700802070529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867777011267698, "Avg loss": 1.059253403218463, "Avg value loss": 0.7775548950012308, "Avg policy loss": 0.28169851296115667, "Total num played games": 60882, "Total num trained steps": 120960, "Timestamp in ms": 1700802102456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988896553989685, "Avg loss": 0.41097441606689245, "Avg value loss": 0.1352932037843857, "Avg policy loss": 0.2756812066072598, "Total num played games": 60882, "Total num trained steps": 121088, "Timestamp in ms": 1700802162190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909989816366085, "Avg loss": 0.30880170955788344, "Avg value loss": 0.06240925472229719, "Avg policy loss": 0.24639245658181608, "Total num played games": 60882, "Total num trained steps": 121216, "Timestamp in ms": 1700802224700, "logtype": "training_step"}
{"Avg objective": 22.188359374999987, "Games time in secs": 172.9977898467332, "Avg game time in secs": 1.6537654597050278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 60928, "Total num trained steps": 121257, "Timestamp in ms": 1700802243527, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897514102059557, "Avg loss": 0.5472852841485292, "Avg value loss": 0.2855701061198488, "Avg policy loss": 0.26171518105547875, "Total num played games": 60984, "Total num trained steps": 121344, "Timestamp in ms": 1700802284369, "logtype": "training_step"}
{"Total num played games": 60984, "Total num trained steps": 121392, "Timestamp in ms": 1700802314617, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2356640625}
{"Avg objective": 21.163828124999988, "Games time in secs": 74.38160273618996, "Avg game time in secs": 1.791845786763588, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.58, "agent_stopped_0": 0.44}, "Total num played games": 61056, "Total num trained steps": 121400, "Timestamp in ms": 1700802317909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988719711853307, "Avg loss": 0.4979558823397383, "Avg value loss": 0.23786524633760564, "Avg policy loss": 0.26009063969831914, "Total num played games": 61080, "Total num trained steps": 121472, "Timestamp in ms": 1700802352096, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908153241650295, "Avg loss": 0.321479884441942, "Avg value loss": 0.0690103137458209, "Avg policy loss": 0.2524695727042854, "Total num played games": 61080, "Total num trained steps": 121600, "Timestamp in ms": 1700802414109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989734872012815, "Avg loss": 0.543056774768047, "Avg value loss": 0.2887019370973576, "Avg policy loss": 0.2543548406101763, "Total num played games": 61178, "Total num trained steps": 121728, "Timestamp in ms": 1700802471731, "logtype": "training_step"}
{"Avg objective": 21.490624999999984, "Games time in secs": 209.17195430025458, "Avg game time in secs": 1.8121018531528534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 61184, "Total num trained steps": 121847, "Timestamp in ms": 1700802527081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885603316035119, "Avg loss": 0.3981471545994282, "Avg value loss": 0.14883721817750484, "Avg policy loss": 0.24930993444286287, "Total num played games": 61278, "Total num trained steps": 121856, "Timestamp in ms": 1700802530847, "logtype": "training_step"}
{"Total num played games": 61278, "Total num trained steps": 121894, "Timestamp in ms": 1700802558440, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1012890625}
{"Avg objective": 21.69429687499999, "Games time in secs": 33.72904163040221, "Avg game time in secs": 1.6066146417579148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 61312, "Total num trained steps": 121898, "Timestamp in ms": 1700802560810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98755173200378, "Avg loss": 1.1918254389893264, "Avg value loss": 0.8917300830362365, "Avg policy loss": 0.3000953564187512, "Total num played games": 61374, "Total num trained steps": 121984, "Timestamp in ms": 1700802599870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896210121549842, "Avg loss": 0.34345721639692783, "Avg value loss": 0.08270948537392542, "Avg policy loss": 0.2607477343408391, "Total num played games": 61374, "Total num trained steps": 122112, "Timestamp in ms": 1700802660966, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911874898191888, "Avg loss": 0.2909273385303095, "Avg value loss": 0.05291829208726995, "Avg policy loss": 0.23800904327072203, "Total num played games": 61390, "Total num trained steps": 122240, "Timestamp in ms": 1700802722481, "logtype": "training_step"}
{"Avg objective": 21.842968749999983, "Games time in secs": 162.31009178981185, "Avg game time in secs": 1.6918128325924044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.55, "agent_stopped_0": 0.46}, "Total num played games": 61440, "Total num trained steps": 122241, "Timestamp in ms": 1700802723120, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906783796974135, "Avg loss": 0.6327537305187434, "Avg value loss": 0.3758701229817234, "Avg policy loss": 0.25688359676860273, "Total num played games": 61470, "Total num trained steps": 122368, "Timestamp in ms": 1700802784754, "logtype": "training_step"}
{"Total num played games": 61470, "Total num trained steps": 122395, "Timestamp in ms": 1700802810505, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.030390625000003}
{"Ratio train steps to played games": 1.9896533801123997, "Avg loss": 0.7293957044603303, "Avg value loss": 0.4592473057564348, "Avg policy loss": 0.2701483949786052, "Total num played games": 61566, "Total num trained steps": 122496, "Timestamp in ms": 1700802860197, "logtype": "training_step"}
{"Avg objective": 21.478906249999984, "Games time in secs": 197.89684214442968, "Avg game time in secs": 1.8573736278776778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.66, "agent_stopped_0": 0.36}, "Total num played games": 61568, "Total num trained steps": 122623, "Timestamp in ms": 1700802921017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914899145743332, "Avg loss": 0.3241257533663884, "Avg value loss": 0.07229839454521425, "Avg policy loss": 0.25182735815178603, "Total num played games": 61570, "Total num trained steps": 122624, "Timestamp in ms": 1700802921110, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990707404884694, "Avg loss": 0.5523796018678695, "Avg value loss": 0.29686219949508086, "Avg policy loss": 0.25551740278024226, "Total num played games": 61662, "Total num trained steps": 122752, "Timestamp in ms": 1700802986168, "logtype": "training_step"}
{"Avg objective": 20.077578124999985, "Games time in secs": 97.49064178019762, "Avg game time in secs": 1.5982479476806475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 61696, "Total num trained steps": 122817, "Timestamp in ms": 1700803018508, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.5461158325197175, "Avg value loss": 0.2916458137042355, "Avg policy loss": 0.2544700220460072, "Total num played games": 61760, "Total num trained steps": 122880, "Timestamp in ms": 1700803049044, "logtype": "training_step"}
{"Total num played games": 61760, "Total num trained steps": 122896, "Timestamp in ms": 1700803065751, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.629062500000003}
{"Avg objective": 20.44609374999999, "Games time in secs": 50.36081180162728, "Avg game time in secs": 1.7339715498674195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 61824, "Total num trained steps": 122902, "Timestamp in ms": 1700803068869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886187273667875, "Avg loss": 0.7183685819618404, "Avg value loss": 0.44919922994449735, "Avg policy loss": 0.2691693576052785, "Total num played games": 61856, "Total num trained steps": 123008, "Timestamp in ms": 1700803118280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906880496637351, "Avg loss": 0.3020421286346391, "Avg value loss": 0.06473186938092113, "Avg policy loss": 0.23731025820598006, "Total num played games": 61856, "Total num trained steps": 123136, "Timestamp in ms": 1700803178429, "logtype": "training_step"}
{"Avg objective": 22.565703124999985, "Games time in secs": 142.7076990492642, "Avg game time in secs": 1.835296803197707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 61952, "Total num trained steps": 123209, "Timestamp in ms": 1700803211577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989540964555491, "Avg loss": 0.8310100784292445, "Avg value loss": 0.5923694842349505, "Avg policy loss": 0.23864060966297984, "Total num played games": 61956, "Total num trained steps": 123264, "Timestamp in ms": 1700803237305, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916069468655175, "Avg loss": 0.3423887016251683, "Avg value loss": 0.09945086049265228, "Avg policy loss": 0.24293783900793642, "Total num played games": 61956, "Total num trained steps": 123392, "Timestamp in ms": 1700803296821, "logtype": "training_step"}
{"Total num played games": 61956, "Total num trained steps": 123396, "Timestamp in ms": 1700803310722, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.254453124999998}
{"Ratio train steps to played games": 1.9905885386450075, "Avg loss": 0.628760872525163, "Avg value loss": 0.37927621591370553, "Avg policy loss": 0.2494846616173163, "Total num played games": 62052, "Total num trained steps": 123520, "Timestamp in ms": 1700803367605, "logtype": "training_step"}
{"Avg objective": 21.20289062499999, "Games time in secs": 192.61254532262683, "Avg game time in secs": 1.5983101234742207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 62080, "Total num trained steps": 123596, "Timestamp in ms": 1700803404190, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894931617055511, "Avg loss": 0.6047835549106821, "Avg value loss": 0.3690732764371205, "Avg policy loss": 0.23571027803700417, "Total num played games": 62150, "Total num trained steps": 123648, "Timestamp in ms": 1700803428676, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915687851971038, "Avg loss": 0.32596711022779346, "Avg value loss": 0.08790261970716529, "Avg policy loss": 0.2380644902586937, "Total num played games": 62150, "Total num trained steps": 123776, "Timestamp in ms": 1700803489203, "logtype": "training_step"}
{"Avg objective": 20.61406249999999, "Games time in secs": 92.68345993570983, "Avg game time in secs": 1.7915190477360738, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 62208, "Total num trained steps": 123794, "Timestamp in ms": 1700803496873, "logtype": "played_game"}
{"Total num played games": 62254, "Total num trained steps": 123898, "Timestamp in ms": 1700803556425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.967109375}
{"Ratio train steps to played games": 1.9884930187770824, "Avg loss": 0.49359288217965513, "Avg value loss": 0.2469775197969284, "Avg policy loss": 0.2466153601417318, "Total num played games": 62308, "Total num trained steps": 123904, "Timestamp in ms": 1700803559246, "logtype": "training_step"}
{"Avg objective": 20.182031249999984, "Games time in secs": 62.88359976373613, "Avg game time in secs": 1.8085300157545134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 62336, "Total num trained steps": 123905, "Timestamp in ms": 1700803559757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892702485966318, "Avg loss": 0.7773273922502995, "Avg value loss": 0.515437301772181, "Avg policy loss": 0.26189009472727776, "Total num played games": 62350, "Total num trained steps": 124032, "Timestamp in ms": 1700803619935, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913231756214915, "Avg loss": 0.308498473954387, "Avg value loss": 0.07069090139702894, "Avg policy loss": 0.23780757014174014, "Total num played games": 62350, "Total num trained steps": 124160, "Timestamp in ms": 1700803680222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902001601281025, "Avg loss": 0.6441512594465166, "Avg value loss": 0.3940524152421858, "Avg policy loss": 0.250098840566352, "Total num played games": 62450, "Total num trained steps": 124288, "Timestamp in ms": 1700803738579, "logtype": "training_step"}
{"Avg objective": 21.454687499999977, "Games time in secs": 227.4757347665727, "Avg game time in secs": 1.7941992105334066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 62464, "Total num trained steps": 124392, "Timestamp in ms": 1700803787233, "logtype": "played_game"}
{"Total num played games": 62548, "Total num trained steps": 124400, "Timestamp in ms": 1700803803944, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.954296875}
{"Avg objective": 20.306249999999988, "Games time in secs": 19.21949116140604, "Avg game time in secs": 1.6427550911030266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 62592, "Total num trained steps": 124405, "Timestamp in ms": 1700803806452, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986080071515229, "Avg loss": 0.6196956094354391, "Avg value loss": 0.37938702560495585, "Avg policy loss": 0.24030858650803566, "Total num played games": 62644, "Total num trained steps": 124416, "Timestamp in ms": 1700803810969, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881074005491348, "Avg loss": 0.7774211267242208, "Avg value loss": 0.4991011521779001, "Avg policy loss": 0.27831996546592563, "Total num played games": 62644, "Total num trained steps": 124544, "Timestamp in ms": 1700803870419, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99015069280378, "Avg loss": 0.3058088459074497, "Avg value loss": 0.06571158961742185, "Avg policy loss": 0.24009725428186357, "Total num played games": 62644, "Total num trained steps": 124672, "Timestamp in ms": 1700803929484, "logtype": "training_step"}
{"Avg objective": 20.88390624999999, "Games time in secs": 173.5445016603917, "Avg game time in secs": 1.7574518677720334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 62720, "Total num trained steps": 124783, "Timestamp in ms": 1700803979997, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889080130043986, "Avg loss": 0.42975095892325044, "Avg value loss": 0.2042171208304353, "Avg policy loss": 0.2255338355898857, "Total num played games": 62748, "Total num trained steps": 124800, "Timestamp in ms": 1700803987429, "logtype": "training_step"}
{"Total num played games": 62748, "Total num trained steps": 124902, "Timestamp in ms": 1700804046506, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.729648437500003}
{"Ratio train steps to played games": 1.9878906498631532, "Avg loss": 0.6366755394265056, "Avg value loss": 0.39458237009239383, "Avg policy loss": 0.2420931663364172, "Total num played games": 62844, "Total num trained steps": 124928, "Timestamp in ms": 1700804057662, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899433517917382, "Avg loss": 0.4747261879965663, "Avg value loss": 0.22912234693649225, "Avg policy loss": 0.24560384219512343, "Total num played games": 62844, "Total num trained steps": 125056, "Timestamp in ms": 1700804119688, "logtype": "training_step"}
{"Avg objective": 21.755546874999983, "Games time in secs": 200.06775993667543, "Avg game time in secs": 1.8702428206452169, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 62848, "Total num trained steps": 125179, "Timestamp in ms": 1700804180065, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892579056094073, "Avg loss": 0.2775334632024169, "Avg value loss": 0.0572682955826167, "Avg policy loss": 0.22026516834739596, "Total num played games": 62930, "Total num trained steps": 125184, "Timestamp in ms": 1700804181643, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909755322529392, "Avg loss": 0.5991041944362223, "Avg value loss": 0.3666845939005725, "Avg policy loss": 0.23241959523875266, "Total num played games": 62940, "Total num trained steps": 125312, "Timestamp in ms": 1700804241502, "logtype": "training_step"}
{"Avg objective": 22.00859374999999, "Games time in secs": 89.46993046067655, "Avg game time in secs": 1.6781335286650574, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 62976, "Total num trained steps": 125373, "Timestamp in ms": 1700804269535, "logtype": "played_game"}
{"Total num played games": 63036, "Total num trained steps": 125403, "Timestamp in ms": 1700804305189, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.480664062500004}
{"Avg objective": 22.232343749999984, "Games time in secs": 39.097634898498654, "Avg game time in secs": 1.8762608346150955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.7}, "Total num played games": 63104, "Total num trained steps": 125410, "Timestamp in ms": 1700804308633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986932142178293, "Avg loss": 0.7893044038210064, "Avg value loss": 0.5504531585029326, "Avg policy loss": 0.23885123943910003, "Total num played games": 63132, "Total num trained steps": 125440, "Timestamp in ms": 1700804322237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889596401191154, "Avg loss": 0.4119335499126464, "Avg value loss": 0.17274068447295576, "Avg policy loss": 0.2391928635770455, "Total num played games": 63132, "Total num trained steps": 125568, "Timestamp in ms": 1700804382640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910029778876006, "Avg loss": 0.26399699749890715, "Avg value loss": 0.053484899835893884, "Avg policy loss": 0.21051209466531873, "Total num played games": 63132, "Total num trained steps": 125696, "Timestamp in ms": 1700804441918, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900044284177896, "Avg loss": 0.5541389528661966, "Avg value loss": 0.3334451531263767, "Avg policy loss": 0.22069380735047162, "Total num played games": 63228, "Total num trained steps": 125824, "Timestamp in ms": 1700804499064, "logtype": "training_step"}
{"Total num played games": 63228, "Total num trained steps": 125904, "Timestamp in ms": 1700804548916, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.866328125000003}
{"Avg objective": 21.51070312499998, "Games time in secs": 242.0450031068176, "Avg game time in secs": 1.8635048930009361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 63232, "Total num trained steps": 125905, "Timestamp in ms": 1700804550678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988993114774809, "Avg loss": 0.5163692296482623, "Avg value loss": 0.28328704414889216, "Avg policy loss": 0.2330821875948459, "Total num played games": 63324, "Total num trained steps": 125952, "Timestamp in ms": 1700804573957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910144652896216, "Avg loss": 0.3501839772798121, "Avg value loss": 0.10772877969429828, "Avg policy loss": 0.24245519551914185, "Total num played games": 63324, "Total num trained steps": 126080, "Timestamp in ms": 1700804633385, "logtype": "training_step"}
{"Avg objective": 21.66484374999999, "Games time in secs": 111.5427467841655, "Avg game time in secs": 1.7382848099514376, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 63360, "Total num trained steps": 126142, "Timestamp in ms": 1700804662221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899091826437942, "Avg loss": 0.5875040221726522, "Avg value loss": 0.345703431928996, "Avg policy loss": 0.24180059251375496, "Total num played games": 63424, "Total num trained steps": 126208, "Timestamp in ms": 1700804694522, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919273461150353, "Avg loss": 0.28771928837522864, "Avg value loss": 0.06028751641861163, "Avg policy loss": 0.22743177006486803, "Total num played games": 63424, "Total num trained steps": 126336, "Timestamp in ms": 1700804753852, "logtype": "training_step"}
{"Avg objective": 21.68484374999998, "Games time in secs": 93.86059886775911, "Avg game time in secs": 1.7462517624953762, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.58}, "Total num played games": 63488, "Total num trained steps": 126342, "Timestamp in ms": 1700804756082, "logtype": "played_game"}
{"Total num played games": 63522, "Total num trained steps": 126408, "Timestamp in ms": 1700804798981, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.905078125000003}
{"Avg objective": 21.586562499999985, "Games time in secs": 46.9392231144011, "Avg game time in secs": 1.8675657936400967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.68, "agent_stopped_0": 0.37}, "Total num played games": 63616, "Total num trained steps": 126418, "Timestamp in ms": 1700804803021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878493508126631, "Avg loss": 0.8334663794375956, "Avg value loss": 0.5761841768107843, "Avg policy loss": 0.2572822046931833, "Total num played games": 63618, "Total num trained steps": 126464, "Timestamp in ms": 1700804823935, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989861359992455, "Avg loss": 0.35181904886849225, "Avg value loss": 0.09101158677367494, "Avg policy loss": 0.2608074602903798, "Total num played games": 63618, "Total num trained steps": 126592, "Timestamp in ms": 1700804882005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918733691722468, "Avg loss": 0.2881330116651952, "Avg value loss": 0.05254567487281747, "Avg policy loss": 0.23558733670506626, "Total num played games": 63618, "Total num trained steps": 126720, "Timestamp in ms": 1700804940434, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908811250274665, "Avg loss": 0.48773499741218984, "Avg value loss": 0.24165523354895413, "Avg policy loss": 0.2460797601379454, "Total num played games": 63714, "Total num trained steps": 126848, "Timestamp in ms": 1700805000169, "logtype": "training_step"}
{"Total num played games": 63714, "Total num trained steps": 126909, "Timestamp in ms": 1700805042414, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4531640625}
{"Avg objective": 21.777812499999985, "Games time in secs": 241.80024945922196, "Avg game time in secs": 1.6979688449937385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 63744, "Total num trained steps": 126915, "Timestamp in ms": 1700805044821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898918664786083, "Avg loss": 0.5388819666113704, "Avg value loss": 0.29475649853702635, "Avg policy loss": 0.24412547529209405, "Total num played games": 63810, "Total num trained steps": 126976, "Timestamp in ms": 1700805073949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918978216580474, "Avg loss": 0.30407679360359907, "Avg value loss": 0.06751259593875147, "Avg policy loss": 0.23656419629696757, "Total num played games": 63810, "Total num trained steps": 127104, "Timestamp in ms": 1700805134506, "logtype": "training_step"}
{"Avg objective": 22.053906249999986, "Games time in secs": 93.64011520892382, "Avg game time in secs": 1.7306100271671312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.62, "agent_stopped_0": 0.39}, "Total num played games": 63872, "Total num trained steps": 127114, "Timestamp in ms": 1700805138462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908618639293985, "Avg loss": 0.7293276262935251, "Avg value loss": 0.45958634733688086, "Avg policy loss": 0.26974128279834986, "Total num played games": 63908, "Total num trained steps": 127232, "Timestamp in ms": 1700805193230, "logtype": "training_step"}
{"Avg objective": 22.14140624999999, "Games time in secs": 92.1438848208636, "Avg game time in secs": 1.9733240914501948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.74}, "Total num played games": 64000, "Total num trained steps": 127312, "Timestamp in ms": 1700805230606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897978314533014, "Avg loss": 0.692707531270571, "Avg value loss": 0.433806148765143, "Avg policy loss": 0.2589013819815591, "Total num played games": 64006, "Total num trained steps": 127360, "Timestamp in ms": 1700805253325, "logtype": "training_step"}
{"Total num played games": 64006, "Total num trained steps": 127411, "Timestamp in ms": 1700805287606, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3078515625}
{"Ratio train steps to played games": 1.9888147015693738, "Avg loss": 0.7608870747499168, "Avg value loss": 0.4716778901638463, "Avg policy loss": 0.2892091782996431, "Total num played games": 64102, "Total num trained steps": 127488, "Timestamp in ms": 1700805324064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908271192786497, "Avg loss": 0.3431094696279615, "Avg value loss": 0.07543351905769669, "Avg policy loss": 0.2676759466994554, "Total num played games": 64102, "Total num trained steps": 127616, "Timestamp in ms": 1700805383127, "logtype": "training_step"}
{"Avg objective": 22.307109374999985, "Games time in secs": 189.4033143762499, "Avg game time in secs": 1.7592166625981918, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.64}, "Total num played games": 64128, "Total num trained steps": 127697, "Timestamp in ms": 1700805420009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897199464191146, "Avg loss": 0.5644127827836201, "Avg value loss": 0.2998866116977297, "Avg policy loss": 0.2645261724246666, "Total num played games": 64202, "Total num trained steps": 127744, "Timestamp in ms": 1700805441493, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991713653780256, "Avg loss": 0.35231015807949007, "Avg value loss": 0.09398912082542665, "Avg policy loss": 0.2583210379816592, "Total num played games": 64202, "Total num trained steps": 127872, "Timestamp in ms": 1700805499589, "logtype": "training_step"}
{"Avg objective": 21.17499999999999, "Games time in secs": 90.78013460710645, "Avg game time in secs": 1.797548784466926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 64256, "Total num trained steps": 127898, "Timestamp in ms": 1700805510789, "logtype": "played_game"}
{"Total num played games": 64300, "Total num trained steps": 127912, "Timestamp in ms": 1700805526217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.271250000000002}
{"Avg objective": 22.097421874999988, "Games time in secs": 19.02622927352786, "Avg game time in secs": 1.81631615756487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 64384, "Total num trained steps": 127920, "Timestamp in ms": 1700805529816, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876855705323313, "Avg loss": 1.1574091664515436, "Avg value loss": 0.8504997299460229, "Avg policy loss": 0.30690943845547736, "Total num played games": 64396, "Total num trained steps": 128000, "Timestamp in ms": 1700805567131, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896888005466178, "Avg loss": 0.3621690650470555, "Avg value loss": 0.08434905216563493, "Avg policy loss": 0.2778200089232996, "Total num played games": 64396, "Total num trained steps": 128128, "Timestamp in ms": 1700805627854, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991676501646065, "Avg loss": 0.31563658954109997, "Avg value loss": 0.053378297976450995, "Avg policy loss": 0.26225829194299877, "Total num played games": 64396, "Total num trained steps": 128256, "Timestamp in ms": 1700805688875, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906965204986664, "Avg loss": 0.6211783603066579, "Avg value loss": 0.3525877395295538, "Avg policy loss": 0.2685906266560778, "Total num played games": 64492, "Total num trained steps": 128384, "Timestamp in ms": 1700805747393, "logtype": "training_step"}
{"Total num played games": 64492, "Total num trained steps": 128413, "Timestamp in ms": 1700805770944, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.759687500000002}
{"Avg objective": 21.900234374999982, "Games time in secs": 243.4016679674387, "Avg game time in secs": 1.7413951366470428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 64512, "Total num trained steps": 128417, "Timestamp in ms": 1700805773218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897039697776677, "Avg loss": 0.6331311115063727, "Avg value loss": 0.3600836185796652, "Avg policy loss": 0.2730474910931662, "Total num played games": 64588, "Total num trained steps": 128512, "Timestamp in ms": 1700805819453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991685762061064, "Avg loss": 0.3153540581697598, "Avg value loss": 0.059835123392986134, "Avg policy loss": 0.2555189342238009, "Total num played games": 64588, "Total num trained steps": 128640, "Timestamp in ms": 1700805884116, "logtype": "training_step"}
{"Avg objective": 20.173046874999986, "Games time in secs": 124.71386374346912, "Avg game time in secs": 1.738640244162525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 64640, "Total num trained steps": 128670, "Timestamp in ms": 1700805897931, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990647126116934, "Avg loss": 0.5237852947320789, "Avg value loss": 0.2560507503512781, "Avg policy loss": 0.26773454586509615, "Total num played games": 64686, "Total num trained steps": 128768, "Timestamp in ms": 1700805944831, "logtype": "training_step"}
{"Avg objective": 20.094999999999985, "Games time in secs": 96.30132169090211, "Avg game time in secs": 1.7553089044085937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.6, "agent_stopped_0": 0.41}, "Total num played games": 64768, "Total num trained steps": 128866, "Timestamp in ms": 1700805994233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989504229178243, "Avg loss": 0.5940894196974114, "Avg value loss": 0.33570182125549763, "Avg policy loss": 0.25838760007172823, "Total num played games": 64788, "Total num trained steps": 128896, "Timestamp in ms": 1700806009552, "logtype": "training_step"}
{"Total num played games": 64788, "Total num trained steps": 128913, "Timestamp in ms": 1700806027837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.385664062500002}
{"Ratio train steps to played games": 1.9885179705320264, "Avg loss": 0.9525630872230977, "Avg value loss": 0.649366692872718, "Avg policy loss": 0.30319638457149267, "Total num played games": 64884, "Total num trained steps": 129024, "Timestamp in ms": 1700806083759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905061340237964, "Avg loss": 0.34376756695564836, "Avg value loss": 0.0783432508178521, "Avg policy loss": 0.2654243189608678, "Total num played games": 64884, "Total num trained steps": 129152, "Timestamp in ms": 1700806146506, "logtype": "training_step"}
{"Avg objective": 21.94265624999998, "Games time in secs": 205.46788913197815, "Avg game time in secs": 1.831431191167212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 64896, "Total num trained steps": 129260, "Timestamp in ms": 1700806199701, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894586193099628, "Avg loss": 0.4367353734560311, "Avg value loss": 0.18712023680564016, "Avg policy loss": 0.24961513618472964, "Total num played games": 64982, "Total num trained steps": 129280, "Timestamp in ms": 1700806208707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914283955556924, "Avg loss": 0.435279457247816, "Avg value loss": 0.16905138033325784, "Avg policy loss": 0.2662280765362084, "Total num played games": 64982, "Total num trained steps": 129408, "Timestamp in ms": 1700806273274, "logtype": "training_step"}
{"Total num played games": 64982, "Total num trained steps": 129416, "Timestamp in ms": 1700806287575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.168437500000003}
{"Avg objective": 20.288281249999986, "Games time in secs": 90.7278753630817, "Avg game time in secs": 1.722764407080831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 65024, "Total num trained steps": 129421, "Timestamp in ms": 1700806290429, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904729708964628, "Avg loss": 0.5644815316190943, "Avg value loss": 0.29358674280229025, "Avg policy loss": 0.2708947863429785, "Total num played games": 65078, "Total num trained steps": 129536, "Timestamp in ms": 1700806348932, "logtype": "training_step"}
{"Avg objective": 20.336718749999985, "Games time in secs": 114.01959041319788, "Avg game time in secs": 1.8354341553495033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 65152, "Total num trained steps": 129651, "Timestamp in ms": 1700806404449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989489673796299, "Avg loss": 0.3883434943854809, "Avg value loss": 0.13970731827430427, "Avg policy loss": 0.2486361776245758, "Total num played games": 65174, "Total num trained steps": 129664, "Timestamp in ms": 1700806410673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914536471599105, "Avg loss": 0.4634076290531084, "Avg value loss": 0.20190266103600152, "Avg policy loss": 0.2615049713058397, "Total num played games": 65174, "Total num trained steps": 129792, "Timestamp in ms": 1700806471020, "logtype": "training_step"}
{"Total num played games": 65270, "Total num trained steps": 129916, "Timestamp in ms": 1700806540791, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.512968750000002}
{"Ratio train steps to played games": 1.9904246843975977, "Avg loss": 0.5899456548504531, "Avg value loss": 0.3356268075876869, "Avg policy loss": 0.2543188437120989, "Total num played games": 65272, "Total num trained steps": 129920, "Timestamp in ms": 1700806542470, "logtype": "training_step"}
{"Avg objective": 22.378124999999983, "Games time in secs": 138.26505415327847, "Avg game time in secs": 1.793934123357758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 65280, "Total num trained steps": 129920, "Timestamp in ms": 1700806542714, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895358443227367, "Avg loss": 0.7541747498326004, "Avg value loss": 0.4896181506337598, "Avg policy loss": 0.264556595007889, "Total num played games": 65366, "Total num trained steps": 130048, "Timestamp in ms": 1700806600245, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914940488939203, "Avg loss": 0.2974507723702118, "Avg value loss": 0.05904937887680717, "Avg policy loss": 0.2384013927076012, "Total num played games": 65366, "Total num trained steps": 130176, "Timestamp in ms": 1700806660099, "logtype": "training_step"}
{"Avg objective": 21.406249999999982, "Games time in secs": 139.32343778572977, "Avg game time in secs": 1.6595871688914485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.6, "agent_stopped_0": 0.42}, "Total num played games": 65408, "Total num trained steps": 130226, "Timestamp in ms": 1700806682041, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903919591849204, "Avg loss": 0.791630873689428, "Avg value loss": 0.5365096073073801, "Avg policy loss": 0.2551212713588029, "Total num played games": 65466, "Total num trained steps": 130304, "Timestamp in ms": 1700806717835, "logtype": "training_step"}
{"Total num played games": 65466, "Total num trained steps": 130416, "Timestamp in ms": 1700806777733, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0761328125}
{"Avg objective": 21.896093749999984, "Games time in secs": 98.93404285795987, "Avg game time in secs": 1.7180954762879992, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 65536, "Total num trained steps": 130422, "Timestamp in ms": 1700806780975, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989429852658552, "Avg loss": 0.4120965036563575, "Avg value loss": 0.17305295600090176, "Avg policy loss": 0.23904354707337916, "Total num played games": 65562, "Total num trained steps": 130432, "Timestamp in ms": 1700806785602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913822031054573, "Avg loss": 0.5570659178774804, "Avg value loss": 0.2992909351596609, "Avg policy loss": 0.2577749826014042, "Total num played games": 65562, "Total num trained steps": 130560, "Timestamp in ms": 1700806844777, "logtype": "training_step"}
{"Avg objective": 20.667343749999983, "Games time in secs": 92.01446580700576, "Avg game time in secs": 1.8360986625630176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 65664, "Total num trained steps": 130621, "Timestamp in ms": 1700806872989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902534113060428, "Avg loss": 0.5675360998138785, "Avg value loss": 0.3203392297727987, "Avg policy loss": 0.2471968730678782, "Total num played games": 65664, "Total num trained steps": 130688, "Timestamp in ms": 1700806904105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922027290448343, "Avg loss": 0.3115561339072883, "Avg value loss": 0.06982805594452657, "Avg policy loss": 0.24172807799186558, "Total num played games": 65664, "Total num trained steps": 130816, "Timestamp in ms": 1700806963691, "logtype": "training_step"}
{"Total num played games": 65766, "Total num trained steps": 130916, "Timestamp in ms": 1700807019003, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.766093750000003}
{"Avg objective": 21.360937499999988, "Games time in secs": 148.7068840432912, "Avg game time in secs": 1.6280534105171682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.5}, "Total num played games": 65792, "Total num trained steps": 130922, "Timestamp in ms": 1700807021696, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881418723998663, "Avg loss": 0.7203491239342839, "Avg value loss": 0.46300228012842126, "Avg policy loss": 0.2573468426708132, "Total num played games": 65862, "Total num trained steps": 130944, "Timestamp in ms": 1700807031117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900853299322827, "Avg loss": 0.4010889322962612, "Avg value loss": 0.15407250213320367, "Avg policy loss": 0.2470164312981069, "Total num played games": 65862, "Total num trained steps": 131072, "Timestamp in ms": 1700807089677, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992028787464699, "Avg loss": 0.28504670260008425, "Avg value loss": 0.049737453897250816, "Avg policy loss": 0.23530924960505217, "Total num played games": 65862, "Total num trained steps": 131200, "Timestamp in ms": 1700807149960, "logtype": "training_step"}
{"Avg objective": 20.634374999999984, "Games time in secs": 136.29479059576988, "Avg game time in secs": 1.685618599425652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 65920, "Total num trained steps": 131218, "Timestamp in ms": 1700807157991, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909493344652982, "Avg loss": 0.6028276638826355, "Avg value loss": 0.3563014566025231, "Avg policy loss": 0.24652621487621218, "Total num played games": 65962, "Total num trained steps": 131328, "Timestamp in ms": 1700807211174, "logtype": "training_step"}
{"Avg objective": 21.53203124999999, "Games time in secs": 93.47845013253391, "Avg game time in secs": 1.7708751382306218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.62, "agent_stopped_0": 0.38}, "Total num played games": 66048, "Total num trained steps": 131418, "Timestamp in ms": 1700807251470, "logtype": "played_game"}
{"Total num played games": 66058, "Total num trained steps": 131418, "Timestamp in ms": 1700807260096, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.465937500000003}
{"Ratio train steps to played games": 1.9871209601838136, "Avg loss": 0.7737312008393928, "Avg value loss": 0.5281302409130149, "Avg policy loss": 0.2456009543966502, "Total num played games": 66154, "Total num trained steps": 131456, "Timestamp in ms": 1700807277778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989040723161109, "Avg loss": 0.46920970641076565, "Avg value loss": 0.20689238066552207, "Avg policy loss": 0.262317324988544, "Total num played games": 66154, "Total num trained steps": 131584, "Timestamp in ms": 1700807337656, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909907186262357, "Avg loss": 0.28231676551513374, "Avg value loss": 0.05063485779101029, "Avg policy loss": 0.23168190743308514, "Total num played games": 66154, "Total num trained steps": 131712, "Timestamp in ms": 1700807395881, "logtype": "training_step"}
{"Avg objective": 20.02312499999998, "Games time in secs": 185.8194269388914, "Avg game time in secs": 1.7972134482115507, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.65, "agent_stopped_0": 0.39}, "Total num played games": 66176, "Total num trained steps": 131801, "Timestamp in ms": 1700807437289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900377358490566, "Avg loss": 0.7258364142617211, "Avg value loss": 0.4840789306035731, "Avg policy loss": 0.24175748333800584, "Total num played games": 66250, "Total num trained steps": 131840, "Timestamp in ms": 1700807455317, "logtype": "training_step"}
{"Total num played games": 66250, "Total num trained steps": 131920, "Timestamp in ms": 1700807500881, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.2314453125}
{"Avg objective": 22.613046874999995, "Games time in secs": 66.53051652759314, "Avg game time in secs": 1.713636737622437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 66304, "Total num trained steps": 131926, "Timestamp in ms": 1700807503820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890875109275616, "Avg loss": 0.7583099582698196, "Avg value loss": 0.49085189716424793, "Avg policy loss": 0.26745806669350713, "Total num played games": 66346, "Total num trained steps": 131968, "Timestamp in ms": 1700807522440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910017182648538, "Avg loss": 0.38135252986103296, "Avg value loss": 0.12084317198605277, "Avg policy loss": 0.26050935545936227, "Total num played games": 66346, "Total num trained steps": 132096, "Timestamp in ms": 1700807580762, "logtype": "training_step"}
{"Avg objective": 21.56406249999998, "Games time in secs": 118.30848201178014, "Avg game time in secs": 1.8323370012076339, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.67}, "Total num played games": 66432, "Total num trained steps": 132187, "Timestamp in ms": 1700807622129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900066221178736, "Avg loss": 0.49866433604620397, "Avg value loss": 0.2442129278788343, "Avg policy loss": 0.2544514072360471, "Total num played games": 66444, "Total num trained steps": 132224, "Timestamp in ms": 1700807638691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919180061405093, "Avg loss": 0.34056461323052645, "Avg value loss": 0.0880943666852545, "Avg policy loss": 0.25247024570126086, "Total num played games": 66444, "Total num trained steps": 132352, "Timestamp in ms": 1700807698877, "logtype": "training_step"}
{"Total num played games": 66542, "Total num trained steps": 132422, "Timestamp in ms": 1700807739125, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.720625000000002}
{"Avg objective": 21.268749999999986, "Games time in secs": 119.17223013751209, "Avg game time in secs": 1.777565110634896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 66560, "Total num trained steps": 132427, "Timestamp in ms": 1700807741301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880548635913442, "Avg loss": 0.8211008310317993, "Avg value loss": 0.5447641773207579, "Avg policy loss": 0.2763366516446695, "Total num played games": 66638, "Total num trained steps": 132480, "Timestamp in ms": 1700807765412, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899606830937302, "Avg loss": 0.3646248315926641, "Avg value loss": 0.09687719648354687, "Avg policy loss": 0.26774763280991465, "Total num played games": 66638, "Total num trained steps": 132608, "Timestamp in ms": 1700807823069, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918965155016657, "Avg loss": 0.2943696241127327, "Avg value loss": 0.0525150104513159, "Avg policy loss": 0.24185461166780442, "Total num played games": 66638, "Total num trained steps": 132736, "Timestamp in ms": 1700807882352, "logtype": "training_step"}
{"Avg objective": 22.412499999999987, "Games time in secs": 155.95108843781054, "Avg game time in secs": 1.686635837162612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.61}, "Total num played games": 66688, "Total num trained steps": 132770, "Timestamp in ms": 1700807897252, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990874490529849, "Avg loss": 0.6416345199104398, "Avg value loss": 0.38098881527548656, "Avg policy loss": 0.2606457065558061, "Total num played games": 66736, "Total num trained steps": 132864, "Timestamp in ms": 1700807941468, "logtype": "training_step"}
{"Total num played games": 66736, "Total num trained steps": 132923, "Timestamp in ms": 1700807977484, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.383515625}
{"Avg objective": 22.70281249999999, "Games time in secs": 83.63287881202996, "Avg game time in secs": 1.7610350379545707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.64, "agent_stopped_0": 0.38}, "Total num played games": 66816, "Total num trained steps": 132932, "Timestamp in ms": 1700807980885, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899449365573378, "Avg loss": 0.6974514444591478, "Avg value loss": 0.43372452005860396, "Avg policy loss": 0.2637269275728613, "Total num played games": 66832, "Total num trained steps": 132992, "Timestamp in ms": 1700808008521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918452238448647, "Avg loss": 0.33602320577483624, "Avg value loss": 0.07744554206146859, "Avg policy loss": 0.2585776628693566, "Total num played games": 66832, "Total num trained steps": 133120, "Timestamp in ms": 1700808066459, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908411773494696, "Avg loss": 0.6423911923775449, "Avg value loss": 0.3673728345602285, "Avg policy loss": 0.2750183593016118, "Total num played games": 66930, "Total num trained steps": 133248, "Timestamp in ms": 1700808124101, "logtype": "training_step"}
{"Avg objective": 22.881640624999985, "Games time in secs": 192.21755146235228, "Avg game time in secs": 1.7335388362698723, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.6, "agent_stopped_0": 0.43}, "Total num played games": 66944, "Total num trained steps": 133353, "Timestamp in ms": 1700808173107, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898400668377394, "Avg loss": 0.5416021069977432, "Avg value loss": 0.280729698453797, "Avg policy loss": 0.26087240572087467, "Total num played games": 67028, "Total num trained steps": 133376, "Timestamp in ms": 1700808183599, "logtype": "training_step"}
{"Total num played games": 67028, "Total num trained steps": 133424, "Timestamp in ms": 1700808214940, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6011328125}
{"Avg objective": 21.303906249999986, "Games time in secs": 44.51782204210758, "Avg game time in secs": 1.7745425609464291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 67072, "Total num trained steps": 133431, "Timestamp in ms": 1700808217625, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889160359930875, "Avg loss": 0.6944202978629619, "Avg value loss": 0.41575712693156675, "Avg policy loss": 0.2786631745984778, "Total num played games": 67124, "Total num trained steps": 133504, "Timestamp in ms": 1700808251739, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908229545319112, "Avg loss": 0.3275374691002071, "Avg value loss": 0.0738794821081683, "Avg policy loss": 0.2536579897860065, "Total num played games": 67124, "Total num trained steps": 133632, "Timestamp in ms": 1700808310224, "logtype": "training_step"}
{"Avg objective": 21.234140624999984, "Games time in secs": 141.43751038052142, "Avg game time in secs": 1.8011987189238425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.58}, "Total num played games": 67200, "Total num trained steps": 133742, "Timestamp in ms": 1700808359063, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895139219419324, "Avg loss": 0.5009026132756844, "Avg value loss": 0.24931906042911578, "Avg policy loss": 0.25158355303574353, "Total num played games": 67232, "Total num trained steps": 133760, "Timestamp in ms": 1700808366961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991432651118515, "Avg loss": 0.4641461009159684, "Avg value loss": 0.19955578411463648, "Avg policy loss": 0.2645903108641505, "Total num played games": 67232, "Total num trained steps": 133888, "Timestamp in ms": 1700808426454, "logtype": "training_step"}
{"Total num played games": 67232, "Total num trained steps": 133928, "Timestamp in ms": 1700808453387, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.277734375}
{"Avg objective": 21.825546874999976, "Games time in secs": 100.22000339441001, "Avg game time in secs": 1.9371399384253891, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.8, "agent_stopped_0": 0.26}, "Total num played games": 67328, "Total num trained steps": 133941, "Timestamp in ms": 1700808459283, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904942965779469, "Avg loss": 0.8173216846771538, "Avg value loss": 0.5512170281435829, "Avg policy loss": 0.2661046596476808, "Total num played games": 67328, "Total num trained steps": 134016, "Timestamp in ms": 1700808493521, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923805846007605, "Avg loss": 0.32967106020078063, "Avg value loss": 0.07671906903851777, "Avg policy loss": 0.2529519918607548, "Total num played games": 67328, "Total num trained steps": 134144, "Timestamp in ms": 1700808553576, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913389096517766, "Avg loss": 0.7098634244175628, "Avg value loss": 0.4343315639125649, "Avg policy loss": 0.2755318598356098, "Total num played games": 67428, "Total num trained steps": 134272, "Timestamp in ms": 1700808613367, "logtype": "training_step"}
{"Avg objective": 21.821640624999986, "Games time in secs": 188.89869532361627, "Avg game time in secs": 1.801791670062812, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.62}, "Total num played games": 67456, "Total num trained steps": 134349, "Timestamp in ms": 1700808648182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990329650801173, "Avg loss": 0.5729249921860173, "Avg value loss": 0.313329301396152, "Avg policy loss": 0.25959569378755987, "Total num played games": 67526, "Total num trained steps": 134400, "Timestamp in ms": 1700808671848, "logtype": "training_step"}
{"Total num played games": 67526, "Total num trained steps": 134428, "Timestamp in ms": 1700808695229, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5716796875}
{"Avg objective": 21.824999999999985, "Games time in secs": 50.16704993508756, "Avg game time in secs": 1.7981368042819668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 67584, "Total num trained steps": 134436, "Timestamp in ms": 1700808698349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893969418236668, "Avg loss": 0.7596935860347003, "Avg value loss": 0.4581644076970406, "Avg policy loss": 0.3015291710617021, "Total num played games": 67622, "Total num trained steps": 134528, "Timestamp in ms": 1700808739775, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913046050102037, "Avg loss": 0.34817847958765924, "Avg value loss": 0.07283140777144581, "Avg policy loss": 0.27534707181621343, "Total num played games": 67622, "Total num trained steps": 134656, "Timestamp in ms": 1700808798632, "logtype": "training_step"}
{"Avg objective": 21.343749999999986, "Games time in secs": 137.76171655207872, "Avg game time in secs": 1.8319680446147686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.65, "agent_stopped_0": 0.4}, "Total num played games": 67712, "Total num trained steps": 134740, "Timestamp in ms": 1700808836118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901807335656487, "Avg loss": 0.5725448918528855, "Avg value loss": 0.296168743254384, "Avg policy loss": 0.2763761458918452, "Total num played games": 67724, "Total num trained steps": 134784, "Timestamp in ms": 1700808857042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920707577815842, "Avg loss": 0.37507157400250435, "Avg value loss": 0.09768939187051728, "Avg policy loss": 0.27738218079321086, "Total num played games": 67724, "Total num trained steps": 134912, "Timestamp in ms": 1700808914975, "logtype": "training_step"}
{"Total num played games": 67724, "Total num trained steps": 134929, "Timestamp in ms": 1700808933877, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7983984375}
{"Ratio train steps to played games": 1.991138307283987, "Avg loss": 0.6815808365354314, "Avg value loss": 0.39155393428518437, "Avg policy loss": 0.29002689255867153, "Total num played games": 67820, "Total num trained steps": 135040, "Timestamp in ms": 1700808984589, "logtype": "training_step"}
{"Avg objective": 20.832812499999985, "Games time in secs": 190.6074164621532, "Avg game time in secs": 1.7879625185305486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 67840, "Total num trained steps": 135132, "Timestamp in ms": 1700809026726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899740886873565, "Avg loss": 0.5029379029292613, "Avg value loss": 0.22790622551110573, "Avg policy loss": 0.27503167639952153, "Total num played games": 67924, "Total num trained steps": 135168, "Timestamp in ms": 1700809041977, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918732701254342, "Avg loss": 0.35112127487082034, "Avg value loss": 0.07961851646541618, "Avg policy loss": 0.27150275744497776, "Total num played games": 67924, "Total num trained steps": 135296, "Timestamp in ms": 1700809100114, "logtype": "training_step"}
{"Avg objective": 21.332578124999984, "Games time in secs": 94.22547980770469, "Avg game time in secs": 1.6979299637605436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.57}, "Total num played games": 67968, "Total num trained steps": 135342, "Timestamp in ms": 1700809120951, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908706006880128, "Avg loss": 0.5195109492633492, "Avg value loss": 0.24486567120766267, "Avg policy loss": 0.27464528125710785, "Total num played games": 68022, "Total num trained steps": 135424, "Timestamp in ms": 1700809158355, "logtype": "training_step"}
{"Total num played games": 68022, "Total num trained steps": 135431, "Timestamp in ms": 1700809172506, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.122578125}
{"Avg objective": 21.714296874999988, "Games time in secs": 54.50258461013436, "Avg game time in secs": 1.8067431003582897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 68096, "Total num trained steps": 135436, "Timestamp in ms": 1700809175454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899586012507706, "Avg loss": 0.7038132594898343, "Avg value loss": 0.4211221892328467, "Avg policy loss": 0.2826910566072911, "Total num played games": 68118, "Total num trained steps": 135552, "Timestamp in ms": 1700809230976, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991823013006841, "Avg loss": 0.31401894986629486, "Avg value loss": 0.055257450076169334, "Avg policy loss": 0.2587614980293438, "Total num played games": 68118, "Total num trained steps": 135680, "Timestamp in ms": 1700809290410, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908379265861382, "Avg loss": 0.5485950867878273, "Avg value loss": 0.2781912098726025, "Avg policy loss": 0.2704038767842576, "Total num played games": 68216, "Total num trained steps": 135808, "Timestamp in ms": 1700809348953, "logtype": "training_step"}
{"Avg objective": 19.886484374999977, "Games time in secs": 227.1198018398136, "Avg game time in secs": 1.9309062933316454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 68224, "Total num trained steps": 135924, "Timestamp in ms": 1700809402574, "logtype": "played_game"}
{"Total num played games": 68312, "Total num trained steps": 135931, "Timestamp in ms": 1700809415134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.861796875000003}
{"Ratio train steps to played games": 1.9889386357650778, "Avg loss": 0.4315133960917592, "Avg value loss": 0.16613489796873182, "Avg policy loss": 0.2653784956783056, "Total num played games": 68342, "Total num trained steps": 135936, "Timestamp in ms": 1700809417597, "logtype": "training_step"}
{"Avg objective": 22.006249999999984, "Games time in secs": 15.179353622719646, "Avg game time in secs": 1.6360145596263465, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.52}, "Total num played games": 68352, "Total num trained steps": 135936, "Timestamp in ms": 1700809417753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889925154952637, "Avg loss": 1.0163242989219725, "Avg value loss": 0.7201601960114203, "Avg policy loss": 0.2961641000583768, "Total num played games": 68408, "Total num trained steps": 136064, "Timestamp in ms": 1700809476809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908782598526489, "Avg loss": 0.32777685089968145, "Avg value loss": 0.06712877619429491, "Avg policy loss": 0.2606480739777908, "Total num played games": 68408, "Total num trained steps": 136192, "Timestamp in ms": 1700809535676, "logtype": "training_step"}
{"Avg objective": 21.32031249999999, "Games time in secs": 174.551559176296, "Avg game time in secs": 1.7264205709216185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.61, "agent_stopped_0": 0.41}, "Total num played games": 68480, "Total num trained steps": 136310, "Timestamp in ms": 1700809592305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897679170923952, "Avg loss": 0.40551071078516543, "Avg value loss": 0.15213014498294797, "Avg policy loss": 0.2533805688144639, "Total num played games": 68510, "Total num trained steps": 136320, "Timestamp in ms": 1700809596640, "logtype": "training_step"}
{"Total num played games": 68510, "Total num trained steps": 136431, "Timestamp in ms": 1700809657760, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9768359375}
{"Ratio train steps to played games": 1.9888493717750635, "Avg loss": 0.6024766090558842, "Avg value loss": 0.329825804248685, "Avg policy loss": 0.2726508090272546, "Total num played games": 68606, "Total num trained steps": 136448, "Timestamp in ms": 1700809664796, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907296737894644, "Avg loss": 0.593226921511814, "Avg value loss": 0.30650554090971127, "Avg policy loss": 0.2867213760036975, "Total num played games": 68606, "Total num trained steps": 136576, "Timestamp in ms": 1700809723659, "logtype": "training_step"}
{"Avg objective": 22.10234374999998, "Games time in secs": 189.86489089392126, "Avg game time in secs": 1.8369429550220957, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 68608, "Total num trained steps": 136703, "Timestamp in ms": 1700809782170, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923050017488633, "Avg loss": 0.30784224485978484, "Avg value loss": 0.05412086096475832, "Avg policy loss": 0.25372138584498316, "Total num played games": 68610, "Total num trained steps": 136704, "Timestamp in ms": 1700809782624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991616208663251, "Avg loss": 0.6731893974356353, "Avg value loss": 0.3970242446521297, "Avg policy loss": 0.27616514859255403, "Total num played games": 68704, "Total num trained steps": 136832, "Timestamp in ms": 1700809840552, "logtype": "training_step"}
{"Avg objective": 22.228593749999987, "Games time in secs": 89.21458044834435, "Avg game time in secs": 1.6964510083344067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 68736, "Total num trained steps": 136901, "Timestamp in ms": 1700809871385, "logtype": "played_game"}
{"Total num played games": 68800, "Total num trained steps": 136935, "Timestamp in ms": 1700809896790, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7334765625}
{"Avg objective": 22.39140624999999, "Games time in secs": 28.383023280650377, "Avg game time in secs": 1.7481340710946824, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 68864, "Total num trained steps": 136942, "Timestamp in ms": 1700809899768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879093125870877, "Avg loss": 1.0100966355530545, "Avg value loss": 0.7317079561180435, "Avg policy loss": 0.278388679260388, "Total num played games": 68896, "Total num trained steps": 136960, "Timestamp in ms": 1700809908050, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897816999535531, "Avg loss": 0.543414952699095, "Avg value loss": 0.24946028806152754, "Avg policy loss": 0.2939546628622338, "Total num played games": 68896, "Total num trained steps": 137088, "Timestamp in ms": 1700809967282, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916395726892708, "Avg loss": 0.3188445959240198, "Avg value loss": 0.06150297264684923, "Avg policy loss": 0.257341623888351, "Total num played games": 68896, "Total num trained steps": 137216, "Timestamp in ms": 1700810024873, "logtype": "training_step"}
{"Avg objective": 21.49828124999998, "Games time in secs": 157.50872030854225, "Avg game time in secs": 1.915696830881643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.76}, "Total num played games": 68992, "Total num trained steps": 137289, "Timestamp in ms": 1700810057277, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904782608695653, "Avg loss": 0.6117588678607717, "Avg value loss": 0.35375232408114243, "Avg policy loss": 0.2580065398942679, "Total num played games": 69000, "Total num trained steps": 137344, "Timestamp in ms": 1700810081845, "logtype": "training_step"}
{"Total num played games": 69000, "Total num trained steps": 137438, "Timestamp in ms": 1700810135003, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.082265625}
{"Ratio train steps to played games": 1.9895652425610744, "Avg loss": 0.47902469465043396, "Avg value loss": 0.2232064402778633, "Avg policy loss": 0.2558182505890727, "Total num played games": 69096, "Total num trained steps": 137472, "Timestamp in ms": 1700810150948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914177376403843, "Avg loss": 0.3728571096435189, "Avg value loss": 0.11997544340556487, "Avg policy loss": 0.2528816679259762, "Total num played games": 69096, "Total num trained steps": 137600, "Timestamp in ms": 1700810211696, "logtype": "training_step"}
{"Avg objective": 20.92812499999998, "Games time in secs": 192.5158677380532, "Avg game time in secs": 1.7239807149453554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 69120, "Total num trained steps": 137685, "Timestamp in ms": 1700810249793, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905191351601341, "Avg loss": 0.587936062249355, "Avg value loss": 0.3342613016429823, "Avg policy loss": 0.2536747577833012, "Total num played games": 69192, "Total num trained steps": 137728, "Timestamp in ms": 1700810268912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923546074690717, "Avg loss": 0.34154092939570546, "Avg value loss": 0.08376487824716605, "Avg policy loss": 0.2577760498970747, "Total num played games": 69192, "Total num trained steps": 137856, "Timestamp in ms": 1700810328158, "logtype": "training_step"}
{"Avg objective": 21.384843749999984, "Games time in secs": 87.8456433787942, "Avg game time in secs": 1.8331736976688262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 69248, "Total num trained steps": 137878, "Timestamp in ms": 1700810337639, "logtype": "played_game"}
{"Total num played games": 69292, "Total num trained steps": 137939, "Timestamp in ms": 1700810377253, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.576796875}
{"Avg objective": 21.276562499999986, "Games time in secs": 42.86496736481786, "Avg game time in secs": 1.7884570572059602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.68, "agent_stopped_0": 0.35}, "Total num played games": 69376, "Total num trained steps": 137946, "Timestamp in ms": 1700810380504, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885715109240791, "Avg loss": 0.9353272883454338, "Avg value loss": 0.6652345988841262, "Avg policy loss": 0.27009268989786506, "Total num played games": 69388, "Total num trained steps": 137984, "Timestamp in ms": 1700810397772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.39790925686247647, "Avg value loss": 0.1470826254808344, "Avg policy loss": 0.2508266292279586, "Total num played games": 69388, "Total num trained steps": 138112, "Timestamp in ms": 1700810456832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922609096673776, "Avg loss": 0.28216886427253485, "Avg value loss": 0.0504078874073457, "Avg policy loss": 0.23176097718533128, "Total num played games": 69388, "Total num trained steps": 138240, "Timestamp in ms": 1700810519684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913076015312436, "Avg loss": 0.7531920777400956, "Avg value loss": 0.49821206615888514, "Avg policy loss": 0.25498000264633447, "Total num played games": 69486, "Total num trained steps": 138368, "Timestamp in ms": 1700810583165, "logtype": "training_step"}
{"Total num played games": 69486, "Total num trained steps": 138441, "Timestamp in ms": 1700810634368, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0734765625}
{"Avg objective": 20.854374999999976, "Games time in secs": 256.2585125938058, "Avg game time in secs": 1.8095534063177183, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.69, "agent_stopped_0": 0.39}, "Total num played games": 69504, "Total num trained steps": 138444, "Timestamp in ms": 1700810636763, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903998160443792, "Avg loss": 0.5411451575346291, "Avg value loss": 0.2993344873539172, "Avg policy loss": 0.24181066860910505, "Total num played games": 69582, "Total num trained steps": 138496, "Timestamp in ms": 1700810661834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922250007185767, "Avg loss": 0.310728327720426, "Avg value loss": 0.07287909177830443, "Avg policy loss": 0.2378492356510833, "Total num played games": 69582, "Total num trained steps": 138624, "Timestamp in ms": 1700810724472, "logtype": "training_step"}
{"Avg objective": 20.798437499999988, "Games time in secs": 103.29012807831168, "Avg game time in secs": 1.6480965583905345, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.55, "agent_stopped_0": 0.46}, "Total num played games": 69632, "Total num trained steps": 138657, "Timestamp in ms": 1700810740053, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912743972445466, "Avg loss": 0.8090845156693831, "Avg value loss": 0.5574702968006022, "Avg policy loss": 0.2516142182284966, "Total num played games": 69680, "Total num trained steps": 138752, "Timestamp in ms": 1700810785398, "logtype": "training_step"}
{"Avg objective": 21.974687499999984, "Games time in secs": 91.97624514438212, "Avg game time in secs": 1.806475650781067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 69760, "Total num trained steps": 138855, "Timestamp in ms": 1700810832029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903548498050905, "Avg loss": 0.5104039390571415, "Avg value loss": 0.2578113343915902, "Avg policy loss": 0.2525926035596058, "Total num played games": 69776, "Total num trained steps": 138880, "Timestamp in ms": 1700810843820, "logtype": "training_step"}
{"Total num played games": 69776, "Total num trained steps": 138942, "Timestamp in ms": 1700810885349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.786406250000002}
{"Ratio train steps to played games": 1.9894521410579344, "Avg loss": 0.5916591088753194, "Avg value loss": 0.3281242960947566, "Avg policy loss": 0.2635348163312301, "Total num played games": 69872, "Total num trained steps": 139008, "Timestamp in ms": 1700810916109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912840622853216, "Avg loss": 0.32009630813263357, "Avg value loss": 0.07114864978939295, "Avg policy loss": 0.24894765997305512, "Total num played games": 69872, "Total num trained steps": 139136, "Timestamp in ms": 1700810974459, "logtype": "training_step"}
{"Avg objective": 20.335703124999988, "Games time in secs": 187.9241181947291, "Avg game time in secs": 1.8102055085037136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 69888, "Total num trained steps": 139236, "Timestamp in ms": 1700811019954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903956094214499, "Avg loss": 0.6011279366211966, "Avg value loss": 0.36216431962384377, "Avg policy loss": 0.2389636180596426, "Total num played games": 69968, "Total num trained steps": 139264, "Timestamp in ms": 1700811031845, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922107249028127, "Avg loss": 0.4539429509313777, "Avg value loss": 0.19844729799660854, "Avg policy loss": 0.255495649529621, "Total num played games": 69968, "Total num trained steps": 139392, "Timestamp in ms": 1700811088908, "logtype": "training_step"}
{"Avg objective": 22.297656249999992, "Games time in secs": 85.49957244284451, "Avg game time in secs": 1.5861237657954916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.5, "agent_stopped_0": 0.52}, "Total num played games": 70016, "Total num trained steps": 139430, "Timestamp in ms": 1700811105453, "logtype": "played_game"}
{"Total num played games": 70074, "Total num trained steps": 139444, "Timestamp in ms": 1700811123703, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.845351562500003}
{"Avg objective": 21.56328124999998, "Games time in secs": 21.354411808773875, "Avg game time in secs": 1.7699849800701486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 70144, "Total num trained steps": 139449, "Timestamp in ms": 1700811126808, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988299843237851, "Avg loss": 0.8996660377597436, "Avg value loss": 0.6387702473148238, "Avg policy loss": 0.2608957909978926, "Total num played games": 70170, "Total num trained steps": 139520, "Timestamp in ms": 1700811158541, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901382357132678, "Avg loss": 0.33227664534933865, "Avg value loss": 0.07813975316821598, "Avg policy loss": 0.25413689168635756, "Total num played games": 70170, "Total num trained steps": 139648, "Timestamp in ms": 1700811218444, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919481259797633, "Avg loss": 0.28297491604462266, "Avg value loss": 0.05106134252855554, "Avg policy loss": 0.23191357409814373, "Total num played games": 70170, "Total num trained steps": 139776, "Timestamp in ms": 1700811275892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910058632663516, "Avg loss": 0.5598392207175493, "Avg value loss": 0.3177366532472661, "Avg policy loss": 0.24210255884099752, "Total num played games": 70268, "Total num trained steps": 139904, "Timestamp in ms": 1700811332314, "logtype": "training_step"}
{"Total num played games": 70268, "Total num trained steps": 139947, "Timestamp in ms": 1700811363278, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.451093750000002}
{"Avg objective": 20.783593749999984, "Games time in secs": 238.09322023577988, "Avg game time in secs": 1.8396347816451453, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.65}, "Total num played games": 70272, "Total num trained steps": 139949, "Timestamp in ms": 1700811364901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900943664373827, "Avg loss": 0.6185956535628065, "Avg value loss": 0.36474161298247054, "Avg policy loss": 0.25385405065026134, "Total num played games": 70364, "Total num trained steps": 140032, "Timestamp in ms": 1700811402641, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919276902961742, "Avg loss": 0.3034653054783121, "Avg value loss": 0.06160792594891973, "Avg policy loss": 0.24185737932566553, "Total num played games": 70364, "Total num trained steps": 140160, "Timestamp in ms": 1700811462752, "logtype": "training_step"}
{"Avg objective": 20.895312499999985, "Games time in secs": 126.4221338070929, "Avg game time in secs": 1.6650003178365296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.54}, "Total num played games": 70400, "Total num trained steps": 140222, "Timestamp in ms": 1700811491323, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909031562216166, "Avg loss": 0.6523719558026642, "Avg value loss": 0.40040251110622194, "Avg policy loss": 0.25196944852359593, "Total num played games": 70464, "Total num trained steps": 140288, "Timestamp in ms": 1700811522368, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927196866485013, "Avg loss": 0.3045098410220817, "Avg value loss": 0.06506216275738552, "Avg policy loss": 0.23944767948705703, "Total num played games": 70464, "Total num trained steps": 140416, "Timestamp in ms": 1700811580072, "logtype": "training_step"}
{"Avg objective": 20.20804687499998, "Games time in secs": 91.07730161398649, "Avg game time in secs": 1.7217340268543921, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.67, "agent_stopped_0": 0.35}, "Total num played games": 70528, "Total num trained steps": 140423, "Timestamp in ms": 1700811582401, "logtype": "played_game"}
{"Total num played games": 70560, "Total num trained steps": 140447, "Timestamp in ms": 1700811605681, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.540546875000004}
{"Avg objective": 21.57109374999998, "Games time in secs": 27.85476679727435, "Avg game time in secs": 1.944542802782962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.77}, "Total num played games": 70656, "Total num trained steps": 140456, "Timestamp in ms": 1700811610256, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891304347826086, "Avg loss": 0.9230208937078714, "Avg value loss": 0.6474895144347101, "Avg policy loss": 0.27553138707298785, "Total num played games": 70656, "Total num trained steps": 140544, "Timestamp in ms": 1700811652132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909420289855073, "Avg loss": 0.3468131374102086, "Avg value loss": 0.08855952962767333, "Avg policy loss": 0.2582536070840433, "Total num played games": 70656, "Total num trained steps": 140672, "Timestamp in ms": 1700811710821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927536231884058, "Avg loss": 0.2887335710693151, "Avg value loss": 0.045600438461406156, "Avg policy loss": 0.2431331304833293, "Total num played games": 70656, "Total num trained steps": 140800, "Timestamp in ms": 1700811768456, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916899855846688, "Avg loss": 0.5336698724422604, "Avg value loss": 0.2712429201346822, "Avg policy loss": 0.262426953879185, "Total num played games": 70758, "Total num trained steps": 140928, "Timestamp in ms": 1700811825209, "logtype": "training_step"}
{"Total num played games": 70758, "Total num trained steps": 140948, "Timestamp in ms": 1700811847109, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5074609375}
{"Avg objective": 21.536484374999986, "Games time in secs": 239.1538779642433, "Avg game time in secs": 1.6890489221550524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 70784, "Total num trained steps": 140953, "Timestamp in ms": 1700811849410, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907979789426145, "Avg loss": 0.5870288432342932, "Avg value loss": 0.32804692987701856, "Avg policy loss": 0.2589819125132635, "Total num played games": 70854, "Total num trained steps": 141056, "Timestamp in ms": 1700811896276, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925903971547125, "Avg loss": 0.29684009577613324, "Avg value loss": 0.051463902127579786, "Avg policy loss": 0.24537619319744408, "Total num played games": 70854, "Total num trained steps": 141184, "Timestamp in ms": 1700811956021, "logtype": "training_step"}
{"Avg objective": 20.57374999999998, "Games time in secs": 114.551936943084, "Avg game time in secs": 1.6557754914392717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.56, "agent_stopped_0": 0.45}, "Total num played games": 70912, "Total num trained steps": 141200, "Timestamp in ms": 1700811963962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916422370052993, "Avg loss": 0.6090771544259042, "Avg value loss": 0.3504987692431314, "Avg policy loss": 0.2585783851100132, "Total num played games": 70952, "Total num trained steps": 141312, "Timestamp in ms": 1700812015642, "logtype": "training_step"}
{"Avg objective": 21.644531249999982, "Games time in secs": 91.28164027631283, "Avg game time in secs": 1.7278243619512068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 71040, "Total num trained steps": 141399, "Timestamp in ms": 1700812055244, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907668055399166, "Avg loss": 0.8422670608852059, "Avg value loss": 0.5916828851186438, "Avg policy loss": 0.2505841637030244, "Total num played games": 71048, "Total num trained steps": 141440, "Timestamp in ms": 1700812073830, "logtype": "training_step"}
{"Total num played games": 71048, "Total num trained steps": 141449, "Timestamp in ms": 1700812088321, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8351953125}
{"Ratio train steps to played games": 1.9898656246486, "Avg loss": 0.7567861122079194, "Avg value loss": 0.4686251236125827, "Avg policy loss": 0.2881609849864617, "Total num played games": 71144, "Total num trained steps": 141568, "Timestamp in ms": 1700812143936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916788485325536, "Avg loss": 0.30807693116366863, "Avg value loss": 0.060642781492788345, "Avg policy loss": 0.24743414856493473, "Total num played games": 71144, "Total num trained steps": 141696, "Timestamp in ms": 1700812203066, "logtype": "training_step"}
{"Avg objective": 21.70390624999998, "Games time in secs": 187.471640907228, "Avg game time in secs": 1.6799585968401516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.47, "agent_stopped_0": 0.55}, "Total num played games": 71168, "Total num trained steps": 141781, "Timestamp in ms": 1700812242716, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907358019146009, "Avg loss": 0.4672549777897075, "Avg value loss": 0.2322344032145338, "Avg policy loss": 0.2350205850088969, "Total num played games": 71242, "Total num trained steps": 141824, "Timestamp in ms": 1700812261533, "logtype": "training_step"}
{"Total num played games": 71242, "Total num trained steps": 141950, "Timestamp in ms": 1700812329395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.085546875000002}
{"Ratio train steps to played games": 1.9925324948766177, "Avg loss": 0.3124498084653169, "Avg value loss": 0.07012560110888444, "Avg policy loss": 0.24232420732732862, "Total num played games": 71242, "Total num trained steps": 141952, "Timestamp in ms": 1700812330629, "logtype": "training_step"}
{"Avg objective": 21.396874999999984, "Games time in secs": 89.37070291489363, "Avg game time in secs": 1.785418339917669, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 71296, "Total num trained steps": 141956, "Timestamp in ms": 1700812332086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916313886007457, "Avg loss": 0.6657238062471151, "Avg value loss": 0.41661715632653795, "Avg policy loss": 0.24910664418712258, "Total num played games": 71338, "Total num trained steps": 142080, "Timestamp in ms": 1700812387541, "logtype": "training_step"}
{"Avg objective": 20.649999999999988, "Games time in secs": 96.16804995946586, "Avg game time in secs": 1.8455040936387377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 71424, "Total num trained steps": 142172, "Timestamp in ms": 1700812428255, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905795072788355, "Avg loss": 0.63223743182607, "Avg value loss": 0.4004989759559976, "Avg policy loss": 0.23173844732809812, "Total num played games": 71440, "Total num trained steps": 142208, "Timestamp in ms": 1700812444894, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923712206047033, "Avg loss": 0.36343794874846935, "Avg value loss": 0.1324125702085439, "Avg policy loss": 0.23102537880185992, "Total num played games": 71440, "Total num trained steps": 142336, "Timestamp in ms": 1700812502762, "logtype": "training_step"}
{"Total num played games": 71540, "Total num trained steps": 142451, "Timestamp in ms": 1700812562350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.204882812500003}
{"Avg objective": 22.100468749999987, "Games time in secs": 136.15806847251952, "Avg game time in secs": 1.8358687838335754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 71552, "Total num trained steps": 142455, "Timestamp in ms": 1700812564413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887067954659667, "Avg loss": 0.7905491180717945, "Avg value loss": 0.5420597812189953, "Avg policy loss": 0.2484893302898854, "Total num played games": 71636, "Total num trained steps": 142464, "Timestamp in ms": 1700812568516, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904936065665308, "Avg loss": 0.5643303877441213, "Avg value loss": 0.3199326744652353, "Avg policy loss": 0.24439771298784763, "Total num played games": 71636, "Total num trained steps": 142592, "Timestamp in ms": 1700812627952, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922804176670947, "Avg loss": 0.27898713655304164, "Avg value loss": 0.044788906088797376, "Avg policy loss": 0.23419822938740253, "Total num played games": 71636, "Total num trained steps": 142720, "Timestamp in ms": 1700812692529, "logtype": "training_step"}
{"Avg objective": 22.32968749999999, "Games time in secs": 150.09589082747698, "Avg game time in secs": 1.628955517167924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 71680, "Total num trained steps": 142765, "Timestamp in ms": 1700812714509, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913430172582038, "Avg loss": 0.7318364901002496, "Avg value loss": 0.4915938795020338, "Avg policy loss": 0.24024261202430353, "Total num played games": 71734, "Total num trained steps": 142848, "Timestamp in ms": 1700812757127, "logtype": "training_step"}
{"Total num played games": 71734, "Total num trained steps": 142952, "Timestamp in ms": 1700812829566, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.819765625000002}
{"Avg objective": 20.95132812499999, "Games time in secs": 118.1533835530281, "Avg game time in secs": 1.715613067470258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 71808, "Total num trained steps": 142958, "Timestamp in ms": 1700812832662, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904775163580677, "Avg loss": 0.46230062062386423, "Avg value loss": 0.23092425739741884, "Avg policy loss": 0.23137636191677302, "Total num played games": 71830, "Total num trained steps": 142976, "Timestamp in ms": 1700812842522, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992245579841292, "Avg loss": 0.4266629929188639, "Avg value loss": 0.19510393595555797, "Avg policy loss": 0.23155905352905393, "Total num played games": 71830, "Total num trained steps": 143104, "Timestamp in ms": 1700812908370, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912692895870985, "Avg loss": 0.6542681897990406, "Avg value loss": 0.42205920976994094, "Avg policy loss": 0.23220897442661226, "Total num played games": 71930, "Total num trained steps": 143232, "Timestamp in ms": 1700812978080, "logtype": "training_step"}
{"Avg objective": 21.007031249999983, "Games time in secs": 209.68251681141555, "Avg game time in secs": 1.7233206689852523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.58, "agent_stopped_0": 0.44}, "Total num played games": 71936, "Total num trained steps": 143352, "Timestamp in ms": 1700813042345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903784744397857, "Avg loss": 0.3170800636289641, "Avg value loss": 0.10321586998179555, "Avg policy loss": 0.21386419190093875, "Total num played games": 72026, "Total num trained steps": 143360, "Timestamp in ms": 1700813045643, "logtype": "training_step"}
{"Total num played games": 72026, "Total num trained steps": 143453, "Timestamp in ms": 1700813104831, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.968007812499998}
{"Avg objective": 21.687968749999985, "Games time in secs": 65.22760813683271, "Avg game time in secs": 1.6361450771655655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 72064, "Total num trained steps": 143458, "Timestamp in ms": 1700813107573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895038961759242, "Avg loss": 0.6523782229050994, "Avg value loss": 0.41634383477503434, "Avg policy loss": 0.2360343892360106, "Total num played games": 72122, "Total num trained steps": 143488, "Timestamp in ms": 1700813125538, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991278666703641, "Avg loss": 0.31930389162153006, "Avg value loss": 0.09667296393308789, "Avg policy loss": 0.22263092815410346, "Total num played games": 72122, "Total num trained steps": 143616, "Timestamp in ms": 1700813191430, "logtype": "training_step"}
{"Avg objective": 21.039062499999986, "Games time in secs": 144.3800029605627, "Avg game time in secs": 1.7372072745347396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.6, "agent_stopped_0": 0.41}, "Total num played games": 72192, "Total num trained steps": 143738, "Timestamp in ms": 1700813251953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903627803932429, "Avg loss": 0.35618231643456966, "Avg value loss": 0.1544735097704688, "Avg policy loss": 0.2017088058637455, "Total num played games": 72220, "Total num trained steps": 143744, "Timestamp in ms": 1700813254806, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921351426197729, "Avg loss": 0.5569347371347249, "Avg value loss": 0.333004561252892, "Avg policy loss": 0.22393016843125224, "Total num played games": 72220, "Total num trained steps": 143872, "Timestamp in ms": 1700813320884, "logtype": "training_step"}
{"Total num played games": 72318, "Total num trained steps": 143954, "Timestamp in ms": 1700813378387, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6181640625}
{"Avg objective": 21.48359374999998, "Games time in secs": 127.5286963749677, "Avg game time in secs": 1.78130729777331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 72320, "Total num trained steps": 143956, "Timestamp in ms": 1700813379482, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885519374706548, "Avg loss": 0.8925802444573492, "Avg value loss": 0.6522985104093095, "Avg policy loss": 0.2402817407855764, "Total num played games": 72414, "Total num trained steps": 144000, "Timestamp in ms": 1700813400936, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903195514679481, "Avg loss": 0.40282575553283095, "Avg value loss": 0.1687385890108999, "Avg policy loss": 0.23408716602716595, "Total num played games": 72414, "Total num trained steps": 144128, "Timestamp in ms": 1700813465686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921009749495955, "Avg loss": 0.27651053888257593, "Avg value loss": 0.0545881976140663, "Avg policy loss": 0.22192233835812658, "Total num played games": 72414, "Total num trained steps": 144256, "Timestamp in ms": 1700813530928, "logtype": "training_step"}
{"Avg objective": 20.015390624999988, "Games time in secs": 184.01681384444237, "Avg game time in secs": 1.6827731659723213, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 72448, "Total num trained steps": 144321, "Timestamp in ms": 1700813563499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912150048269204, "Avg loss": 0.5336492353817448, "Avg value loss": 0.3010705199849326, "Avg policy loss": 0.23257871821988374, "Total num played games": 72510, "Total num trained steps": 144384, "Timestamp in ms": 1700813594903, "logtype": "training_step"}
{"Total num played games": 72510, "Total num trained steps": 144456, "Timestamp in ms": 1700813647389, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.794296875000004}
{"Avg objective": 21.77007812499999, "Games time in secs": 86.71418753266335, "Avg game time in secs": 1.754965658285073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 72576, "Total num trained steps": 144461, "Timestamp in ms": 1700813650213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903589235049446, "Avg loss": 0.5366921371314675, "Avg value loss": 0.30157269118353724, "Avg policy loss": 0.23511944629717618, "Total num played games": 72606, "Total num trained steps": 144512, "Timestamp in ms": 1700813676649, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992108090240476, "Avg loss": 0.29146787303034216, "Avg value loss": 0.06986771784431767, "Avg policy loss": 0.22160015476401895, "Total num played games": 72606, "Total num trained steps": 144640, "Timestamp in ms": 1700813740158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912382052763336, "Avg loss": 0.46248953975737095, "Avg value loss": 0.2285052889637882, "Avg policy loss": 0.23398424906190485, "Total num played games": 72702, "Total num trained steps": 144768, "Timestamp in ms": 1700813801772, "logtype": "training_step"}
{"Avg objective": 21.066093749999986, "Games time in secs": 215.63412388414145, "Avg game time in secs": 1.8032636989519233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 72704, "Total num trained steps": 144895, "Timestamp in ms": 1700813865847, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929439920774648, "Avg loss": 0.29269497632049024, "Avg value loss": 0.0599739785247948, "Avg policy loss": 0.23272100056055933, "Total num played games": 72704, "Total num trained steps": 144896, "Timestamp in ms": 1700813865908, "logtype": "training_step"}
{"Total num played games": 72804, "Total num trained steps": 144956, "Timestamp in ms": 1700813906161, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.492382812500004}
{"Avg objective": 21.241406249999983, "Games time in secs": 42.7397366669029, "Avg game time in secs": 1.6880162068118807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 72832, "Total num trained steps": 144959, "Timestamp in ms": 1700813908587, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893415637860081, "Avg loss": 1.102174743777141, "Avg value loss": 0.8347231680236291, "Avg policy loss": 0.267451569554396, "Total num played games": 72900, "Total num trained steps": 145024, "Timestamp in ms": 1700813941340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910973936899863, "Avg loss": 0.3465297658694908, "Avg value loss": 0.09582842720556073, "Avg policy loss": 0.25070133665576577, "Total num played games": 72900, "Total num trained steps": 145152, "Timestamp in ms": 1700814002578, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928532235939644, "Avg loss": 0.2727241662796587, "Avg value loss": 0.04700120579218492, "Avg policy loss": 0.2257229589158669, "Total num played games": 72900, "Total num trained steps": 145280, "Timestamp in ms": 1700814066063, "logtype": "training_step"}
{"Avg objective": 22.961718749999985, "Games time in secs": 163.12675952352583, "Avg game time in secs": 1.7709343241003808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.62, "agent_stopped_0": 0.4}, "Total num played games": 72960, "Total num trained steps": 145294, "Timestamp in ms": 1700814071714, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919995616198147, "Avg loss": 0.8688053251244128, "Avg value loss": 0.6270081630937057, "Avg policy loss": 0.24179717258084565, "Total num played games": 72996, "Total num trained steps": 145408, "Timestamp in ms": 1700814128364, "logtype": "training_step"}
{"Total num played games": 72996, "Total num trained steps": 145457, "Timestamp in ms": 1700814163404, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.755390625000004}
{"Avg objective": 22.796328124999988, "Games time in secs": 95.78062468022108, "Avg game time in secs": 1.9136328503955156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 73088, "Total num trained steps": 145465, "Timestamp in ms": 1700814167495, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911207792918513, "Avg loss": 0.5832906431751326, "Avg value loss": 0.3459656562190503, "Avg policy loss": 0.23732498730532825, "Total num played games": 73092, "Total num trained steps": 145536, "Timestamp in ms": 1700814202072, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928719969353692, "Avg loss": 0.28539653739426285, "Avg value loss": 0.05870131464325823, "Avg policy loss": 0.2266952256904915, "Total num played games": 73092, "Total num trained steps": 145664, "Timestamp in ms": 1700814264860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920068863748155, "Avg loss": 0.7178587996168062, "Avg value loss": 0.4622480434481986, "Avg policy loss": 0.25561074912548065, "Total num played games": 73188, "Total num trained steps": 145792, "Timestamp in ms": 1700814325504, "logtype": "training_step"}
{"Avg objective": 21.323437499999983, "Games time in secs": 195.64271857216954, "Avg game time in secs": 1.713448454378522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.52, "agent_stopped_0": 0.49}, "Total num played games": 73216, "Total num trained steps": 145868, "Timestamp in ms": 1700814363138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991089703353983, "Avg loss": 0.7148858901346102, "Avg value loss": 0.4654513337445678, "Avg policy loss": 0.24943456111941487, "Total num played games": 73286, "Total num trained steps": 145920, "Timestamp in ms": 1700814389014, "logtype": "training_step"}
{"Total num played games": 73286, "Total num trained steps": 145960, "Timestamp in ms": 1700814421373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.251718750000002}
{"Avg objective": 21.851953124999984, "Games time in secs": 60.972379975020885, "Avg game time in secs": 1.6975165501789888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 73344, "Total num trained steps": 145966, "Timestamp in ms": 1700814424110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902292115232618, "Avg loss": 0.6857704154681414, "Avg value loss": 0.4232529294677079, "Avg policy loss": 0.26251748600043356, "Total num played games": 73382, "Total num trained steps": 146048, "Timestamp in ms": 1700814463294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919871358098715, "Avg loss": 0.29956110287457705, "Avg value loss": 0.06403947176295333, "Avg policy loss": 0.235521633294411, "Total num played games": 73382, "Total num trained steps": 146176, "Timestamp in ms": 1700814521698, "logtype": "training_step"}
{"Avg objective": 21.452890624999977, "Games time in secs": 137.8521883469075, "Avg game time in secs": 1.8497729953523958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 73472, "Total num trained steps": 146260, "Timestamp in ms": 1700814561963, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991112986199951, "Avg loss": 0.6177650085883215, "Avg value loss": 0.3813427781133214, "Avg policy loss": 0.23642223700881004, "Total num played games": 73478, "Total num trained steps": 146304, "Timestamp in ms": 1700814582278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99285500421895, "Avg loss": 0.3274710311088711, "Avg value loss": 0.087399419862777, "Avg policy loss": 0.24007160984911025, "Total num played games": 73478, "Total num trained steps": 146432, "Timestamp in ms": 1700814643271, "logtype": "training_step"}
{"Total num played games": 73576, "Total num trained steps": 146460, "Timestamp in ms": 1700814666361, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7651953125}
{"Avg objective": 20.938203124999987, "Games time in secs": 106.53100794926286, "Avg game time in secs": 1.7420149429963203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 73600, "Total num trained steps": 146463, "Timestamp in ms": 1700814668494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893582365077642, "Avg loss": 0.8902551365317777, "Avg value loss": 0.6273192042426672, "Avg policy loss": 0.26293592946603894, "Total num played games": 73672, "Total num trained steps": 146560, "Timestamp in ms": 1700814712585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991082093604083, "Avg loss": 0.3113580426434055, "Avg value loss": 0.06960770298610441, "Avg policy loss": 0.2417503383476287, "Total num played games": 73672, "Total num trained steps": 146688, "Timestamp in ms": 1700814774119, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928330980562494, "Avg loss": 0.2815046062460169, "Avg value loss": 0.048746862725238316, "Avg policy loss": 0.23275774519424886, "Total num played games": 73672, "Total num trained steps": 146816, "Timestamp in ms": 1700814833561, "logtype": "training_step"}
{"Avg objective": 21.410156249999986, "Games time in secs": 175.06794008798897, "Avg game time in secs": 1.8070448340440635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.62}, "Total num played games": 73728, "Total num trained steps": 146838, "Timestamp in ms": 1700814843562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991920835027789, "Avg loss": 0.7364667683141306, "Avg value loss": 0.4868450728827156, "Avg policy loss": 0.2496216893196106, "Total num played games": 73770, "Total num trained steps": 146944, "Timestamp in ms": 1700814892673, "logtype": "training_step"}
{"Total num played games": 73770, "Total num trained steps": 146960, "Timestamp in ms": 1700814910561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.364687500000002}
{"Avg objective": 21.87812499999999, "Games time in secs": 70.4852447733283, "Avg game time in secs": 1.8035334404848982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 73856, "Total num trained steps": 146968, "Timestamp in ms": 1700814914047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910649013077735, "Avg loss": 0.6724839854286984, "Avg value loss": 0.41720840192283504, "Avg policy loss": 0.2552755892975256, "Total num played games": 73866, "Total num trained steps": 147072, "Timestamp in ms": 1700814962313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992784230904611, "Avg loss": 0.29593777598347515, "Avg value loss": 0.05684742293669842, "Avg policy loss": 0.239090351969935, "Total num played games": 73866, "Total num trained steps": 147200, "Timestamp in ms": 1700815023342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918205662060946, "Avg loss": 0.5652343839174137, "Avg value loss": 0.31365075065696146, "Avg policy loss": 0.25158363534137607, "Total num played games": 73966, "Total num trained steps": 147328, "Timestamp in ms": 1700815081034, "logtype": "training_step"}
{"Avg objective": 21.524999999999984, "Games time in secs": 213.7082933653146, "Avg game time in secs": 1.756197201073519, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 73984, "Total num trained steps": 147425, "Timestamp in ms": 1700815127756, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907654921020657, "Avg loss": 0.48560308769810945, "Avg value loss": 0.24250018660677597, "Avg policy loss": 0.2431028966093436, "Total num played games": 74070, "Total num trained steps": 147456, "Timestamp in ms": 1700815142047, "logtype": "training_step"}
{"Total num played games": 74070, "Total num trained steps": 147461, "Timestamp in ms": 1700815155847, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.062617187500003}
{"Avg objective": 22.06953124999999, "Games time in secs": 30.60703639872372, "Avg game time in secs": 1.8242690942861373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 74112, "Total num trained steps": 147466, "Timestamp in ms": 1700815158363, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899145160855378, "Avg loss": 0.7103874704334885, "Avg value loss": 0.4343146095634438, "Avg policy loss": 0.27607286791317165, "Total num played games": 74166, "Total num trained steps": 147584, "Timestamp in ms": 1700815212593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916403742954993, "Avg loss": 0.29540826682932675, "Avg value loss": 0.05318489045021124, "Avg policy loss": 0.2422233809484169, "Total num played games": 74166, "Total num trained steps": 147712, "Timestamp in ms": 1700815272806, "logtype": "training_step"}
{"Avg objective": 21.618437499999985, "Games time in secs": 168.25388325750828, "Avg game time in secs": 1.8442452011222485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 74240, "Total num trained steps": 147826, "Timestamp in ms": 1700815326617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907759015377986, "Avg loss": 0.4932475747773424, "Avg value loss": 0.2635411039518658, "Avg policy loss": 0.2297064739977941, "Total num played games": 74262, "Total num trained steps": 147840, "Timestamp in ms": 1700815333237, "logtype": "training_step"}
{"Total num played games": 74262, "Total num trained steps": 147962, "Timestamp in ms": 1700815415937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.2725390625}
{"Ratio train steps to played games": 1.9906231501910348, "Avg loss": 0.6032521636225283, "Avg value loss": 0.356642545259092, "Avg policy loss": 0.24660961353220046, "Total num played games": 74332, "Total num trained steps": 147968, "Timestamp in ms": 1700815419142, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916619597084375, "Avg loss": 0.6015271046198905, "Avg value loss": 0.34310288791311905, "Avg policy loss": 0.2584242237498984, "Total num played games": 74358, "Total num trained steps": 148096, "Timestamp in ms": 1700815478928, "logtype": "training_step"}
{"Avg objective": 21.888124999999988, "Games time in secs": 204.15705863945186, "Avg game time in secs": 1.8235214903834276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 74368, "Total num trained steps": 148208, "Timestamp in ms": 1700815530774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906392694063928, "Avg loss": 0.42629618023056537, "Avg value loss": 0.195341080223443, "Avg policy loss": 0.2309550999198109, "Total num played games": 74460, "Total num trained steps": 148224, "Timestamp in ms": 1700815537973, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992358313188289, "Avg loss": 0.4524555755779147, "Avg value loss": 0.1909948812390212, "Avg policy loss": 0.2614606871502474, "Total num played games": 74460, "Total num trained steps": 148352, "Timestamp in ms": 1700815597484, "logtype": "training_step"}
{"Avg objective": 20.340859374999987, "Games time in secs": 94.69492988288403, "Avg game time in secs": 1.7496843596018152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 74496, "Total num trained steps": 148414, "Timestamp in ms": 1700815625469, "logtype": "played_game"}
{"Total num played games": 74560, "Total num trained steps": 148464, "Timestamp in ms": 1700815665821, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.805859375}
{"Avg objective": 21.60640624999999, "Games time in secs": 43.352490248158574, "Avg game time in secs": 1.929280092517729, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.72, "agent_stopped_0": 0.33}, "Total num played games": 74624, "Total num trained steps": 148471, "Timestamp in ms": 1700815668822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888555507929704, "Avg loss": 0.6951728349085897, "Avg value loss": 0.441024331987137, "Avg policy loss": 0.254148502019234, "Total num played games": 74656, "Total num trained steps": 148480, "Timestamp in ms": 1700815672786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905700814402056, "Avg loss": 0.6074640392325819, "Avg value loss": 0.3332872745231725, "Avg policy loss": 0.2741767686093226, "Total num played games": 74656, "Total num trained steps": 148608, "Timestamp in ms": 1700815731612, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922846120874411, "Avg loss": 0.3016492377500981, "Avg value loss": 0.055277564766583964, "Avg policy loss": 0.24637167272157967, "Total num played games": 74656, "Total num trained steps": 148736, "Timestamp in ms": 1700815793930, "logtype": "training_step"}
{"Avg objective": 21.77953124999998, "Games time in secs": 159.9483729209751, "Avg game time in secs": 2.0128626151999924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.79, "agent_stopped_0": 0.3}, "Total num played games": 74752, "Total num trained steps": 148809, "Timestamp in ms": 1700815828770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913850763838725, "Avg loss": 0.6947155331727117, "Avg value loss": 0.44243151776026934, "Avg policy loss": 0.25228402332868427, "Total num played games": 74754, "Total num trained steps": 148864, "Timestamp in ms": 1700815854518, "logtype": "training_step"}
{"Total num played games": 74754, "Total num trained steps": 148966, "Timestamp in ms": 1700815912789, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.886328125000002}
{"Ratio train steps to played games": 1.9905277221108884, "Avg loss": 0.5630649294471368, "Avg value loss": 0.30805177698493935, "Avg policy loss": 0.255013152374886, "Total num played games": 74850, "Total num trained steps": 148992, "Timestamp in ms": 1700815923992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992251169004676, "Avg loss": 0.42839352576993406, "Avg value loss": 0.16115008160704747, "Avg policy loss": 0.26724344422109425, "Total num played games": 74850, "Total num trained steps": 149120, "Timestamp in ms": 1700815983930, "logtype": "training_step"}
{"Avg objective": 22.348671874999987, "Games time in secs": 188.1990628335625, "Avg game time in secs": 1.6808557861368172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 74880, "Total num trained steps": 149193, "Timestamp in ms": 1700816016969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914071464787981, "Avg loss": 0.6544186931569129, "Avg value loss": 0.39850658157956786, "Avg policy loss": 0.255912107299082, "Total num played games": 74946, "Total num trained steps": 149248, "Timestamp in ms": 1700816041687, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931150428308382, "Avg loss": 0.3250128774670884, "Avg value loss": 0.07634015328949317, "Avg policy loss": 0.24867272330448031, "Total num played games": 74946, "Total num trained steps": 149376, "Timestamp in ms": 1700816101209, "logtype": "training_step"}
{"Avg objective": 21.741406249999986, "Games time in secs": 88.37518029659986, "Avg game time in secs": 1.7228967603296041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.62}, "Total num played games": 75008, "Total num trained steps": 149386, "Timestamp in ms": 1700816105345, "logtype": "played_game"}
{"Total num played games": 75044, "Total num trained steps": 149466, "Timestamp in ms": 1700816157869, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5042578125}
{"Avg objective": 22.70421874999998, "Games time in secs": 56.7644375320524, "Avg game time in secs": 1.904787028033752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 75136, "Total num trained steps": 149475, "Timestamp in ms": 1700816162109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896593026350813, "Avg loss": 0.7817770172841847, "Avg value loss": 0.507607303588884, "Avg policy loss": 0.2741697090677917, "Total num played games": 75140, "Total num trained steps": 149504, "Timestamp in ms": 1700816175449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913760979504924, "Avg loss": 0.437488941824995, "Avg value loss": 0.16125830583041534, "Avg policy loss": 0.276230635587126, "Total num played games": 75140, "Total num trained steps": 149632, "Timestamp in ms": 1700816235040, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930662762842695, "Avg loss": 0.3089319202117622, "Avg value loss": 0.04682664088613819, "Avg policy loss": 0.2621052785543725, "Total num played games": 75140, "Total num trained steps": 149760, "Timestamp in ms": 1700816296926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922244670104736, "Avg loss": 0.6755019908305258, "Avg value loss": 0.3991240428586025, "Avg policy loss": 0.27637795405462384, "Total num played games": 75236, "Total num trained steps": 149888, "Timestamp in ms": 1700816355619, "logtype": "training_step"}
{"Avg objective": 21.803593749999983, "Games time in secs": 229.90711233206093, "Avg game time in secs": 1.644277827712358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.54, "agent_stopped_0": 0.48}, "Total num played games": 75264, "Total num trained steps": 149964, "Timestamp in ms": 1700816392017, "logtype": "played_game"}
{"Total num played games": 75332, "Total num trained steps": 149966, "Timestamp in ms": 1700816406429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.503359375000002}
{"Avg objective": 21.979531249999987, "Games time in secs": 17.263945093378425, "Avg game time in secs": 1.735501591290813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.65, "agent_stopped_0": 0.38}, "Total num played games": 75392, "Total num trained steps": 149972, "Timestamp in ms": 1700816409281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888502943204116, "Avg loss": 1.1927983654895797, "Avg value loss": 0.9125047334237024, "Avg policy loss": 0.28029364813119173, "Total num played games": 75428, "Total num trained steps": 150016, "Timestamp in ms": 1700816429223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990560534549504, "Avg loss": 0.562096209032461, "Avg value loss": 0.2577736000530422, "Avg policy loss": 0.304322610842064, "Total num played games": 75428, "Total num trained steps": 150144, "Timestamp in ms": 1700816488964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922442594262078, "Avg loss": 0.326593853533268, "Avg value loss": 0.04921664038556628, "Avg policy loss": 0.27737720939330757, "Total num played games": 75428, "Total num trained steps": 150272, "Timestamp in ms": 1700816548460, "logtype": "training_step"}
{"Avg objective": 20.940624999999983, "Games time in secs": 176.07043922692537, "Avg game time in secs": 1.8368634935031878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.63, "agent_stopped_0": 0.4}, "Total num played games": 75520, "Total num trained steps": 150352, "Timestamp in ms": 1700816585351, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99119578456813, "Avg loss": 0.5595958341145888, "Avg value loss": 0.28712546985480003, "Avg policy loss": 0.272470366791822, "Total num played games": 75532, "Total num trained steps": 150400, "Timestamp in ms": 1700816607886, "logtype": "training_step"}
{"Total num played games": 75532, "Total num trained steps": 150469, "Timestamp in ms": 1700816650429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8594140625}
{"Ratio train steps to played games": 1.990373935579415, "Avg loss": 0.7146259780274704, "Avg value loss": 0.4449430468666833, "Avg policy loss": 0.2696829364867881, "Total num played games": 75628, "Total num trained steps": 150528, "Timestamp in ms": 1700816678198, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920664304225948, "Avg loss": 0.3931770259514451, "Avg value loss": 0.12521276995539665, "Avg policy loss": 0.2679642535513267, "Total num played games": 75628, "Total num trained steps": 150656, "Timestamp in ms": 1700816739380, "logtype": "training_step"}
{"Avg objective": 21.791171874999982, "Games time in secs": 197.19355634599924, "Avg game time in secs": 1.7545445803698385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 75648, "Total num trained steps": 150749, "Timestamp in ms": 1700816782545, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991178723291868, "Avg loss": 0.47814440669026226, "Avg value loss": 0.21911905940214638, "Avg policy loss": 0.2590253457892686, "Total num played games": 75726, "Total num trained steps": 150784, "Timestamp in ms": 1700816798743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928558223067374, "Avg loss": 0.34506759024225175, "Avg value loss": 0.08298247901257128, "Avg policy loss": 0.2620851091342047, "Total num played games": 75726, "Total num trained steps": 150912, "Timestamp in ms": 1700816859149, "logtype": "training_step"}
{"Avg objective": 20.912499999999987, "Games time in secs": 91.49773318320513, "Avg game time in secs": 1.7461418427992612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.59}, "Total num played games": 75776, "Total num trained steps": 150946, "Timestamp in ms": 1700816874043, "logtype": "played_game"}
{"Total num played games": 75826, "Total num trained steps": 150971, "Timestamp in ms": 1700816898085, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.870039062500002}
{"Avg objective": 21.50671874999998, "Games time in secs": 27.419765459373593, "Avg game time in secs": 1.7915691267990042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 75904, "Total num trained steps": 150979, "Timestamp in ms": 1700816901463, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893970127235847, "Avg loss": 0.9583594531286508, "Avg value loss": 0.674994041735772, "Avg policy loss": 0.283365412033163, "Total num played games": 75922, "Total num trained steps": 151040, "Timestamp in ms": 1700816929980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910829535575987, "Avg loss": 0.35569677990861237, "Avg value loss": 0.0842213305295445, "Avg policy loss": 0.2714754519984126, "Total num played games": 75922, "Total num trained steps": 151168, "Timestamp in ms": 1700816989725, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927688943916124, "Avg loss": 0.28421464760322124, "Avg value loss": 0.03767726823571138, "Avg policy loss": 0.24653737910557538, "Total num played games": 75922, "Total num trained steps": 151296, "Timestamp in ms": 1700817048398, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918837148118915, "Avg loss": 0.5725231386022642, "Avg value loss": 0.31522184061759617, "Avg policy loss": 0.2573013041401282, "Total num played games": 76020, "Total num trained steps": 151424, "Timestamp in ms": 1700817106623, "logtype": "training_step"}
{"Total num played games": 76020, "Total num trained steps": 151475, "Timestamp in ms": 1700817140232, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.784023437500004}
{"Avg objective": 20.689453124999982, "Games time in secs": 240.9829999767244, "Avg game time in secs": 1.8501974054524908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 76032, "Total num trained steps": 151479, "Timestamp in ms": 1700817142446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910662672762625, "Avg loss": 0.6915241635870188, "Avg value loss": 0.4253401500900509, "Avg policy loss": 0.26618400565348566, "Total num played games": 76116, "Total num trained steps": 151552, "Timestamp in ms": 1700817177217, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992734773240843, "Avg loss": 0.3001064487034455, "Avg value loss": 0.05959386395988986, "Avg policy loss": 0.24051258340477943, "Total num played games": 76116, "Total num trained steps": 151680, "Timestamp in ms": 1700817236865, "logtype": "training_step"}
{"Avg objective": 21.621093749999982, "Games time in secs": 115.02136014960706, "Avg game time in secs": 1.7581770721735666, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 76160, "Total num trained steps": 151726, "Timestamp in ms": 1700817257467, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918650116776446, "Avg loss": 0.5317522549303249, "Avg value loss": 0.28620688714727294, "Avg policy loss": 0.24554536445066333, "Total num played games": 76214, "Total num trained steps": 151808, "Timestamp in ms": 1700817293989, "logtype": "training_step"}
{"Avg objective": 20.306015624999983, "Games time in secs": 93.29718028195202, "Avg game time in secs": 1.900254815162043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 76288, "Total num trained steps": 151923, "Timestamp in ms": 1700817350765, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909843799140372, "Avg loss": 0.4572761351009831, "Avg value loss": 0.22026312409434468, "Avg policy loss": 0.23701301135588437, "Total num played games": 76312, "Total num trained steps": 151936, "Timestamp in ms": 1700817357175, "logtype": "training_step"}
{"Total num played games": 76312, "Total num trained steps": 151978, "Timestamp in ms": 1700817386637, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.747851562500003}
{"Ratio train steps to played games": 1.9901450109936132, "Avg loss": 1.0320724050980061, "Avg value loss": 0.7396049648523331, "Avg policy loss": 0.29246744979172945, "Total num played games": 76408, "Total num trained steps": 152064, "Timestamp in ms": 1700817425301, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991820228248351, "Avg loss": 0.34521668672095984, "Avg value loss": 0.07805753148568328, "Avg policy loss": 0.26715915580280125, "Total num played games": 76408, "Total num trained steps": 152192, "Timestamp in ms": 1700817483285, "logtype": "training_step"}
{"Avg objective": 22.356015624999984, "Games time in secs": 185.8318122755736, "Avg game time in secs": 1.768861813499825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 76416, "Total num trained steps": 152308, "Timestamp in ms": 1700817536597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909418869108306, "Avg loss": 0.48221953795291483, "Avg value loss": 0.2250429971027188, "Avg policy loss": 0.25717653532046825, "Total num played games": 76506, "Total num trained steps": 152320, "Timestamp in ms": 1700817541347, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926280291741825, "Avg loss": 0.6158549938118085, "Avg value loss": 0.33831980801187456, "Avg policy loss": 0.27753518032841384, "Total num played games": 76506, "Total num trained steps": 152448, "Timestamp in ms": 1700817600505, "logtype": "training_step"}
{"Total num played games": 76506, "Total num trained steps": 152479, "Timestamp in ms": 1700817624392, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.384531250000002}
{"Avg objective": 21.83906249999998, "Games time in secs": 90.66837081126869, "Avg game time in secs": 1.6515671266970458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 76544, "Total num trained steps": 152484, "Timestamp in ms": 1700817627265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918017806323596, "Avg loss": 0.6106093096313998, "Avg value loss": 0.3244811892800499, "Avg policy loss": 0.2861281255027279, "Total num played games": 76602, "Total num trained steps": 152576, "Timestamp in ms": 1700817670361, "logtype": "training_step"}
{"Avg objective": 21.864843749999988, "Games time in secs": 98.91050576977432, "Avg game time in secs": 1.8949719350057421, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.7, "agent_stopped_0": 0.33}, "Total num played games": 76672, "Total num trained steps": 152699, "Timestamp in ms": 1700817726176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909126466753586, "Avg loss": 0.382773419492878, "Avg value loss": 0.11219757323851809, "Avg policy loss": 0.27057584456633776, "Total num played games": 76700, "Total num trained steps": 152704, "Timestamp in ms": 1700817728103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925814863103, "Avg loss": 0.6493823158089072, "Avg value loss": 0.3711271522624884, "Avg policy loss": 0.2782551688142121, "Total num played games": 76700, "Total num trained steps": 152832, "Timestamp in ms": 1700817786324, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917573831970414, "Avg loss": 0.546876295353286, "Avg value loss": 0.2930426891834941, "Avg policy loss": 0.2538336116122082, "Total num played games": 76796, "Total num trained steps": 152960, "Timestamp in ms": 1700817844696, "logtype": "training_step"}
{"Total num played games": 76796, "Total num trained steps": 152980, "Timestamp in ms": 1700817866655, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.414570312500004}
{"Avg objective": 22.059609374999983, "Games time in secs": 142.32496957667172, "Avg game time in secs": 1.90298560532392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 76800, "Total num trained steps": 152982, "Timestamp in ms": 1700817868501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990935337876502, "Avg loss": 0.7534127186518162, "Avg value loss": 0.4723923676647246, "Avg policy loss": 0.281020347494632, "Total num played games": 76892, "Total num trained steps": 153088, "Timestamp in ms": 1700817917735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926000104042032, "Avg loss": 0.312098111375235, "Avg value loss": 0.05509350376087241, "Avg policy loss": 0.2570046096807346, "Total num played games": 76892, "Total num trained steps": 153216, "Timestamp in ms": 1700817978295, "logtype": "training_step"}
{"Avg objective": 21.001562499999988, "Games time in secs": 138.02797147259116, "Avg game time in secs": 1.6617817461810773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 76928, "Total num trained steps": 153277, "Timestamp in ms": 1700818006529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917261982075594, "Avg loss": 0.5428489187033847, "Avg value loss": 0.2899485331145115, "Avg policy loss": 0.2529003852978349, "Total num played games": 76990, "Total num trained steps": 153344, "Timestamp in ms": 1700818037391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933499584372403, "Avg loss": 0.3130645474884659, "Avg value loss": 0.0601514568697894, "Avg policy loss": 0.25291308970190585, "Total num played games": 76992, "Total num trained steps": 153472, "Timestamp in ms": 1700818094577, "logtype": "training_step"}
{"Avg objective": 21.477812499999988, "Games time in secs": 88.99762235023081, "Avg game time in secs": 1.723505767120514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 77056, "Total num trained steps": 153474, "Timestamp in ms": 1700818095527, "logtype": "played_game"}
{"Total num played games": 77090, "Total num trained steps": 153481, "Timestamp in ms": 1700818108542, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3666015625}
{"Avg objective": 21.513828124999986, "Games time in secs": 16.8994100689888, "Avg game time in secs": 1.8170713722065557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.68, "agent_stopped_0": 0.36}, "Total num played games": 77184, "Total num trained steps": 153487, "Timestamp in ms": 1700818112426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98999818619957, "Avg loss": 1.0389318622183055, "Avg value loss": 0.7594263991049957, "Avg policy loss": 0.27950544748455286, "Total num played games": 77186, "Total num trained steps": 153600, "Timestamp in ms": 1700818164945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916435623040447, "Avg loss": 0.3166736215353012, "Avg value loss": 0.061750026303343475, "Avg policy loss": 0.2549235933693126, "Total num played games": 77186, "Total num trained steps": 153728, "Timestamp in ms": 1700818224577, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933018941258778, "Avg loss": 0.285292946617119, "Avg value loss": 0.04703361586143728, "Avg policy loss": 0.2382593301590532, "Total num played games": 77186, "Total num trained steps": 153856, "Timestamp in ms": 1700818283380, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924820786211537, "Avg loss": 0.6318024953361601, "Avg value loss": 0.37600610285880975, "Avg policy loss": 0.255796390469186, "Total num played games": 77282, "Total num trained steps": 153984, "Timestamp in ms": 1700818343873, "logtype": "training_step"}
{"Total num played games": 77282, "Total num trained steps": 153984, "Timestamp in ms": 1700818354814, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.088828125000003}
{"Avg objective": 22.91562499999999, "Games time in secs": 244.84306509047747, "Avg game time in secs": 1.7295248945592903, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.57, "agent_stopped_0": 0.44}, "Total num played games": 77312, "Total num trained steps": 153990, "Timestamp in ms": 1700818357270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916642973454988, "Avg loss": 0.8068908777786419, "Avg value loss": 0.5316060669138096, "Avg policy loss": 0.2752848161617294, "Total num played games": 77378, "Total num trained steps": 154112, "Timestamp in ms": 1700818414531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993318514306392, "Avg loss": 0.30233194155152887, "Avg value loss": 0.052776372263906524, "Avg policy loss": 0.24955556960776448, "Total num played games": 77378, "Total num trained steps": 154240, "Timestamp in ms": 1700818471263, "logtype": "training_step"}
{"Avg objective": 21.860156249999985, "Games time in secs": 118.11943883635104, "Avg game time in secs": 1.7463709413714241, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.63}, "Total num played games": 77440, "Total num trained steps": 154250, "Timestamp in ms": 1700818475389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992449274614074, "Avg loss": 0.7121566567802802, "Avg value loss": 0.44328510809282307, "Avg policy loss": 0.2688715463737026, "Total num played games": 77476, "Total num trained steps": 154368, "Timestamp in ms": 1700818530648, "logtype": "training_step"}
{"Avg objective": 22.282578124999986, "Games time in secs": 90.80351227708161, "Avg game time in secs": 1.9360568575793877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.71, "agent_stopped_0": 0.31}, "Total num played games": 77568, "Total num trained steps": 154448, "Timestamp in ms": 1700818566193, "logtype": "played_game"}
{"Total num played games": 77572, "Total num trained steps": 154484, "Timestamp in ms": 1700818593314, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2428125}
{"Ratio train steps to played games": 1.989171859710563, "Avg loss": 0.6767133711837232, "Avg value loss": 0.40817371220327914, "Avg policy loss": 0.26853966200724244, "Total num played games": 77668, "Total num trained steps": 154496, "Timestamp in ms": 1700818598068, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908199000875522, "Avg loss": 0.5776978975627571, "Avg value loss": 0.2873065931489691, "Avg policy loss": 0.29039130872115493, "Total num played games": 77668, "Total num trained steps": 154624, "Timestamp in ms": 1700818657221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924808157799867, "Avg loss": 0.3103084700414911, "Avg value loss": 0.05248387897154316, "Avg policy loss": 0.2578245926415548, "Total num played games": 77668, "Total num trained steps": 154752, "Timestamp in ms": 1700818716282, "logtype": "training_step"}
{"Avg objective": 20.683828124999984, "Games time in secs": 186.83917718194425, "Avg game time in secs": 1.791771255841013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.65, "agent_stopped_0": 0.39}, "Total num played games": 77696, "Total num trained steps": 154829, "Timestamp in ms": 1700818753032, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991615873260808, "Avg loss": 0.5740822735242546, "Avg value loss": 0.31442229555977974, "Avg policy loss": 0.2596599799580872, "Total num played games": 77766, "Total num trained steps": 154880, "Timestamp in ms": 1700818776176, "logtype": "training_step"}
{"Total num played games": 77766, "Total num trained steps": 154986, "Timestamp in ms": 1700818839103, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.046679687500003}
{"Avg objective": 22.105468749999986, "Games time in secs": 88.94157114438713, "Avg game time in secs": 1.7052903408766724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.59, "agent_stopped_0": 0.41}, "Total num played games": 77824, "Total num trained steps": 154992, "Timestamp in ms": 1700818841974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907914001695306, "Avg loss": 0.5240732242818922, "Avg value loss": 0.2719193640805315, "Avg policy loss": 0.2521538572618738, "Total num played games": 77862, "Total num trained steps": 155008, "Timestamp in ms": 1700818848883, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992448177544887, "Avg loss": 0.4784304335480556, "Avg value loss": 0.21258410936570726, "Avg policy loss": 0.2658463305560872, "Total num played games": 77862, "Total num trained steps": 155136, "Timestamp in ms": 1700818909246, "logtype": "training_step"}
{"Avg objective": 20.733203124999978, "Games time in secs": 104.82245236262679, "Avg game time in secs": 1.8994548800546909, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.78, "agent_stopped_0": 0.29}, "Total num played games": 77952, "Total num trained steps": 155220, "Timestamp in ms": 1700818946796, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99153433724122, "Avg loss": 0.5764554194174707, "Avg value loss": 0.3221004694933072, "Avg policy loss": 0.25435494957491755, "Total num played games": 77962, "Total num trained steps": 155264, "Timestamp in ms": 1700818967204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931633359841974, "Avg loss": 0.3273446020903066, "Avg value loss": 0.07214029658643994, "Avg policy loss": 0.2552043041214347, "Total num played games": 77962, "Total num trained steps": 155392, "Timestamp in ms": 1700819027208, "logtype": "training_step"}
{"Total num played games": 78060, "Total num trained steps": 155490, "Timestamp in ms": 1700819083791, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.616796875000006}
{"Avg objective": 21.450390624999983, "Games time in secs": 139.1770589761436, "Avg game time in secs": 1.780830565636279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.63, "agent_stopped_0": 0.39}, "Total num played games": 78080, "Total num trained steps": 155495, "Timestamp in ms": 1700819085974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989853626081171, "Avg loss": 0.6792934716213495, "Avg value loss": 0.41995092869910877, "Avg policy loss": 0.25934254575986415, "Total num played games": 78156, "Total num trained steps": 155520, "Timestamp in ms": 1700819097182, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915041711448898, "Avg loss": 0.3549613783834502, "Avg value loss": 0.09724399610422552, "Avg policy loss": 0.25771738425828516, "Total num played games": 78156, "Total num trained steps": 155648, "Timestamp in ms": 1700819159172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931291263626594, "Avg loss": 0.2868818308925256, "Avg value loss": 0.045799202081980184, "Avg policy loss": 0.2410826274426654, "Total num played games": 78156, "Total num trained steps": 155776, "Timestamp in ms": 1700819221643, "logtype": "training_step"}
{"Avg objective": 20.83101562499999, "Games time in secs": 151.08270119689405, "Avg game time in secs": 1.705836612629355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.59}, "Total num played games": 78208, "Total num trained steps": 155805, "Timestamp in ms": 1700819237057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923196851198692, "Avg loss": 0.5899978399975225, "Avg value loss": 0.3450907984661171, "Avg policy loss": 0.24490703956689686, "Total num played games": 78252, "Total num trained steps": 155904, "Timestamp in ms": 1700819284682, "logtype": "training_step"}
{"Total num played games": 78252, "Total num trained steps": 155992, "Timestamp in ms": 1700819339878, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.900898437500004}
{"Avg objective": 21.95546874999998, "Games time in secs": 106.64016690850258, "Avg game time in secs": 1.8552640868874732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.78, "agent_stopped_0": 0.27}, "Total num played games": 78336, "Total num trained steps": 156001, "Timestamp in ms": 1700819343697, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915122274978303, "Avg loss": 0.5021913304226473, "Avg value loss": 0.2577325080783339, "Avg policy loss": 0.24445881228893995, "Total num played games": 78348, "Total num trained steps": 156032, "Timestamp in ms": 1700819359065, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993145964159902, "Avg loss": 0.3615153150167316, "Avg value loss": 0.11564249929506332, "Avg policy loss": 0.2458728151395917, "Total num played games": 78348, "Total num trained steps": 156160, "Timestamp in ms": 1700819420409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992249643075668, "Avg loss": 0.5550511248875409, "Avg value loss": 0.3005972040555207, "Avg policy loss": 0.2544539199443534, "Total num played games": 78448, "Total num trained steps": 156288, "Timestamp in ms": 1700819480195, "logtype": "training_step"}
{"Avg objective": 21.24867187499999, "Games time in secs": 184.38791648298502, "Avg game time in secs": 1.7319370930927107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 78464, "Total num trained steps": 156388, "Timestamp in ms": 1700819528085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991279439847231, "Avg loss": 0.5168337718350813, "Avg value loss": 0.2710105098376516, "Avg policy loss": 0.24582327483221889, "Total num played games": 78550, "Total num trained steps": 156416, "Timestamp in ms": 1700819541523, "logtype": "training_step"}
{"Total num played games": 78550, "Total num trained steps": 156492, "Timestamp in ms": 1700819589732, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.488437500000003}
{"Avg objective": 19.834374999999987, "Games time in secs": 64.42405558750033, "Avg game time in secs": 1.816278621176025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.66}, "Total num played games": 78592, "Total num trained steps": 156497, "Timestamp in ms": 1700819592509, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904763115733795, "Avg loss": 0.6699965232983232, "Avg value loss": 0.40340299741365016, "Avg policy loss": 0.26659352821297944, "Total num played games": 78646, "Total num trained steps": 156544, "Timestamp in ms": 1700819615920, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992116572997991, "Avg loss": 0.3401486341608688, "Avg value loss": 0.08812414956628345, "Avg policy loss": 0.25202448200434446, "Total num played games": 78646, "Total num trained steps": 156672, "Timestamp in ms": 1700819682628, "logtype": "training_step"}
{"Avg objective": 21.568515624999986, "Games time in secs": 144.76192699931562, "Avg game time in secs": 1.743137634024606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 78720, "Total num trained steps": 156785, "Timestamp in ms": 1700819737271, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913134032663635, "Avg loss": 0.44839442300144583, "Avg value loss": 0.20517637381271925, "Avg policy loss": 0.24321805080398917, "Total num played games": 78742, "Total num trained steps": 156800, "Timestamp in ms": 1700819744273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929262655253868, "Avg loss": 0.41495453636161983, "Avg value loss": 0.1692074348393362, "Avg policy loss": 0.24574709904845804, "Total num played games": 78742, "Total num trained steps": 156928, "Timestamp in ms": 1700819807417, "logtype": "training_step"}
{"Total num played games": 78838, "Total num trained steps": 156995, "Timestamp in ms": 1700819851723, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.592382812500002}
{"Avg objective": 21.450468749999985, "Games time in secs": 116.64375843852758, "Avg game time in secs": 1.9375150267005665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 78848, "Total num trained steps": 156999, "Timestamp in ms": 1700819853915, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897002559100008, "Avg loss": 0.7690557901514694, "Avg value loss": 0.505991906276904, "Avg policy loss": 0.26306388480588794, "Total num played games": 78934, "Total num trained steps": 157056, "Timestamp in ms": 1700819880741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913218638356096, "Avg loss": 0.35927914979401976, "Avg value loss": 0.09903274232055992, "Avg policy loss": 0.2602464079391211, "Total num played games": 78934, "Total num trained steps": 157184, "Timestamp in ms": 1700819944528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929434717612182, "Avg loss": 0.30670459172688425, "Avg value loss": 0.061864857299951836, "Avg policy loss": 0.24483973626047373, "Total num played games": 78934, "Total num trained steps": 157312, "Timestamp in ms": 1700820006243, "logtype": "training_step"}
{"Avg objective": 20.501562499999988, "Games time in secs": 177.21655789203942, "Avg game time in secs": 1.71587924034975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 78976, "Total num trained steps": 157361, "Timestamp in ms": 1700820031132, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920918109120356, "Avg loss": 0.5353920337511227, "Avg value loss": 0.28944065239920747, "Avg policy loss": 0.24595137930009514, "Total num played games": 79032, "Total num trained steps": 157440, "Timestamp in ms": 1700820069140, "logtype": "training_step"}
{"Total num played games": 79032, "Total num trained steps": 157497, "Timestamp in ms": 1700820106201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.550156250000004}
{"Avg objective": 20.672656249999985, "Games time in secs": 78.38800687715411, "Avg game time in secs": 1.8081633914844133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.7, "agent_stopped_0": 0.3}, "Total num played games": 79104, "Total num trained steps": 157504, "Timestamp in ms": 1700820109520, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913052269740168, "Avg loss": 0.6957384333945811, "Avg value loss": 0.4398906311544124, "Avg policy loss": 0.2558477995917201, "Total num played games": 79128, "Total num trained steps": 157568, "Timestamp in ms": 1700820140792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929228591648973, "Avg loss": 0.31424728385172784, "Avg value loss": 0.06586666495422833, "Avg policy loss": 0.24838061816990376, "Total num played games": 79128, "Total num trained steps": 157696, "Timestamp in ms": 1700820207391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920606871481585, "Avg loss": 0.6179137357976288, "Avg value loss": 0.3533558758063009, "Avg policy loss": 0.26455786311998963, "Total num played games": 79226, "Total num trained steps": 157824, "Timestamp in ms": 1700820271469, "logtype": "training_step"}
{"Avg objective": 21.674453124999985, "Games time in secs": 221.7082183919847, "Avg game time in secs": 1.872666911862325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.71, "agent_stopped_0": 0.32}, "Total num played games": 79232, "Total num trained steps": 157944, "Timestamp in ms": 1700820331229, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912258585043618, "Avg loss": 0.3880749677773565, "Avg value loss": 0.13001605166937225, "Avg policy loss": 0.2580589149147272, "Total num played games": 79324, "Total num trained steps": 157952, "Timestamp in ms": 1700820335027, "logtype": "training_step"}
{"Total num played games": 79324, "Total num trained steps": 158000, "Timestamp in ms": 1700820368365, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.544296875}
{"Avg objective": 20.365390624999982, "Games time in secs": 39.684255661442876, "Avg game time in secs": 1.8693979486997705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 79360, "Total num trained steps": 158005, "Timestamp in ms": 1700820370913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99041803072274, "Avg loss": 0.8939402087125927, "Avg value loss": 0.6098126015858725, "Avg policy loss": 0.28412760491482913, "Total num played games": 79420, "Total num trained steps": 158080, "Timestamp in ms": 1700820408864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920297154369178, "Avg loss": 0.3153319915290922, "Avg value loss": 0.06014550710096955, "Avg policy loss": 0.25518648501019925, "Total num played games": 79420, "Total num trained steps": 158208, "Timestamp in ms": 1700820471841, "logtype": "training_step"}
{"Avg objective": 21.544921874999993, "Games time in secs": 161.61513244733214, "Avg game time in secs": 1.6889783192891628, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 79488, "Total num trained steps": 158333, "Timestamp in ms": 1700820532528, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912845536635058, "Avg loss": 0.30037905694916844, "Avg value loss": 0.0597435403324198, "Avg policy loss": 0.24063551623839885, "Total num played games": 79514, "Total num trained steps": 158336, "Timestamp in ms": 1700820533613, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928567835404196, "Avg loss": 0.5632879153126851, "Avg value loss": 0.30621044550207444, "Avg policy loss": 0.2570774726336822, "Total num played games": 79516, "Total num trained steps": 158464, "Timestamp in ms": 1700820598626, "logtype": "training_step"}
{"Total num played games": 79516, "Total num trained steps": 158501, "Timestamp in ms": 1700820627674, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.470390625}
{"Ratio train steps to played games": 1.9920489373461288, "Avg loss": 0.55939615087118, "Avg value loss": 0.30604504255461507, "Avg policy loss": 0.2533511077053845, "Total num played games": 79612, "Total num trained steps": 158592, "Timestamp in ms": 1700820672856, "logtype": "training_step"}
{"Avg objective": 20.51593749999998, "Games time in secs": 201.96883627027273, "Avg game time in secs": 1.8430854598409496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 79616, "Total num trained steps": 158716, "Timestamp in ms": 1700820734497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913680618287664, "Avg loss": 0.30457506445236504, "Avg value loss": 0.05815371331118513, "Avg policy loss": 0.24642135167960078, "Total num played games": 79702, "Total num trained steps": 158720, "Timestamp in ms": 1700820735999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927239882580223, "Avg loss": 0.6727214272832498, "Avg value loss": 0.41338364355033264, "Avg policy loss": 0.2593377794837579, "Total num played games": 79714, "Total num trained steps": 158848, "Timestamp in ms": 1700820799023, "logtype": "training_step"}
{"Avg objective": 22.233593749999986, "Games time in secs": 100.64299155957997, "Avg game time in secs": 1.67593311330711, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 79744, "Total num trained steps": 158921, "Timestamp in ms": 1700820835140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99181847796126, "Avg loss": 0.5066840581130236, "Avg value loss": 0.2575360780028859, "Avg policy loss": 0.24914797628298402, "Total num played games": 79814, "Total num trained steps": 158976, "Timestamp in ms": 1700820861784, "logtype": "training_step"}
{"Total num played games": 79814, "Total num trained steps": 159002, "Timestamp in ms": 1700820885573, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.459296875000003}
{"Avg objective": 21.224218749999984, "Games time in secs": 53.74076242558658, "Avg game time in secs": 1.7526820971543202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.66}, "Total num played games": 79872, "Total num trained steps": 159009, "Timestamp in ms": 1700820888881, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910399199098987, "Avg loss": 0.6071445376146585, "Avg value loss": 0.355843348428607, "Avg policy loss": 0.25130119640380144, "Total num played games": 79910, "Total num trained steps": 159104, "Timestamp in ms": 1700820937328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926292078588412, "Avg loss": 0.28874592622742057, "Avg value loss": 0.05523821696988307, "Avg policy loss": 0.23350770922843367, "Total num played games": 79910, "Total num trained steps": 159232, "Timestamp in ms": 1700821000952, "logtype": "training_step"}
{"Avg objective": 21.127343749999984, "Games time in secs": 152.03944098576903, "Avg game time in secs": 1.8846335573907709, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.76, "agent_stopped_0": 0.27}, "Total num played games": 80000, "Total num trained steps": 159316, "Timestamp in ms": 1700821040921, "logtype": "played_game"}
{"Total num played games": 80014, "Total num trained steps": 159320, "Timestamp in ms": 1700821053482, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.195507812499997}
{"Total num played games": 80036, "Total num trained steps": 159320, "Timestamp in ms": 1700821065781, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0736328125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700827753677, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5234375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1700827977487, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.171875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702309346141, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.615625}
