{"Avg objective": 20.4375, "Games time in secs": 126.21639002114534, "Avg game time in secs": 30.839737044414505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 5.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.6, "played_steps": 3.05, "reached_maximum_moves": 0.03}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1701792072043, "logtype": "played_game"}
{"Avg objective": 17.9296875, "Games time in secs": 121.02755500748754, "Avg game time in secs": 54.55737874472106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 5.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 6.05, "agent_stopped_0": 0.27, "reached_maximum_moves": 0.12}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1701792193070, "logtype": "played_game"}
{"Ratio train steps to played games": 0.4025157232704403, "Avg loss": 81.60059420764446, "Avg value loss": 79.7884973436594, "Avg policy loss": 1.8120978185907006, "Total num played games": 318, "Total num trained steps": 128, "Timestamp in ms": 1701792253717, "logtype": "training_step"}
{"Avg objective": 17.609375, "Games time in secs": 109.49573619291186, "Avg game time in secs": 55.075667471493944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 5.57, "agent_stopped_0": 0.38, "reached_maximum_moves": 0.14}, "Total num played games": 384, "Total num trained steps": 243, "Timestamp in ms": 1701792302567, "logtype": "played_game"}
{"Ratio train steps to played games": 0.6640625, "Avg loss": 12.983930714428425, "Avg value loss": 11.416928920894861, "Avg policy loss": 1.567001711577177, "Total num played games": 384, "Total num trained steps": 256, "Timestamp in ms": 1701792307737, "logtype": "training_step"}
{"Ratio train steps to played games": 0.8458149779735683, "Avg loss": 7.837335608899593, "Avg value loss": 6.398519145324826, "Avg policy loss": 1.4388165064156055, "Total num played games": 454, "Total num trained steps": 384, "Timestamp in ms": 1701792361360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.0118577075098814, "Avg loss": 7.051829557865858, "Avg value loss": 5.725034775212407, "Avg policy loss": 1.326794776134193, "Total num played games": 506, "Total num trained steps": 512, "Timestamp in ms": 1701792417077, "logtype": "training_step"}
{"Avg objective": 19.140625, "Games time in secs": 118.43878005631268, "Avg game time in secs": 51.391509915090865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "reached_maximum_moves": 0.17, "played_steps": 5.32, "agent_stopped_more": 0.36}, "Total num played games": 512, "Total num trained steps": 521, "Timestamp in ms": 1701792421006, "logtype": "played_game"}
{"Avg objective": 17.6015625, "Games time in secs": 205.85511429980397, "Avg game time in secs": 77.24175358586945, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.34, "played_steps": 8.27, "reached_maximum_moves": 0.31}, "Total num played games": 640, "Total num trained steps": 604, "Timestamp in ms": 1701792626861, "logtype": "played_game"}
{"Total num played games": 648, "Total num trained steps": 604, "Timestamp in ms": 1701792761373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.01171875}
{"Ratio train steps to played games": 0.9142857142857143, "Avg loss": 8.425801012665033, "Avg value loss": 7.223343113437295, "Avg policy loss": 1.2024578219279647, "Total num played games": 700, "Total num trained steps": 640, "Timestamp in ms": 1701792779094, "logtype": "training_step"}
{"Ratio train steps to played games": 1.077247191011236, "Avg loss": 6.00940565392375, "Avg value loss": 4.939097376540303, "Avg policy loss": 1.070308294147253, "Total num played games": 712, "Total num trained steps": 768, "Timestamp in ms": 1701792841095, "logtype": "training_step"}
{"Ratio train steps to played games": 1.2375690607734806, "Avg loss": 4.4700138960033655, "Avg value loss": 3.418764639645815, "Avg policy loss": 1.0512492354027927, "Total num played games": 724, "Total num trained steps": 896, "Timestamp in ms": 1701792900881, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 302.6692746747285, "Avg game time in secs": 35.77470412002003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"reached_maximum_moves": 0.13, "played_steps": 3.47, "agent_stopped_0": 0.63, "agent_stopped_more": 0.23}, "Total num played games": 768, "Total num trained steps": 958, "Timestamp in ms": 1701792929530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.292929292929293, "Avg loss": 5.318701466545463, "Avg value loss": 4.299741877242923, "Avg policy loss": 1.0189595655538142, "Total num played games": 792, "Total num trained steps": 1024, "Timestamp in ms": 1701792961808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3457943925233644, "Avg loss": 4.265311319380999, "Avg value loss": 3.2813268015161157, "Avg policy loss": 0.983984500169754, "Total num played games": 856, "Total num trained steps": 1152, "Timestamp in ms": 1701793021542, "logtype": "training_step"}
{"Avg objective": 19.453125, "Games time in secs": 231.84375097975135, "Avg game time in secs": 42.91545594156196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 4.77, "agent_stopped_0": 0.51, "reached_maximum_moves": 0.17}, "Total num played games": 896, "Total num trained steps": 1207, "Timestamp in ms": 1701793161374, "logtype": "played_game"}
{"Total num played games": 902, "Total num trained steps": 1207, "Timestamp in ms": 1701793358541, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.03125}
{"Ratio train steps to played games": 1.316872427983539, "Avg loss": 4.458446374163032, "Avg value loss": 3.5167707167565823, "Avg policy loss": 0.941675694193691, "Total num played games": 972, "Total num trained steps": 1280, "Timestamp in ms": 1701793394888, "logtype": "training_step"}
{"Ratio train steps to played games": 1.4396728016359919, "Avg loss": 3.3326858952641487, "Avg value loss": 2.42820583563298, "Avg policy loss": 0.9044800568372011, "Total num played games": 978, "Total num trained steps": 1408, "Timestamp in ms": 1701793458179, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 331.027800437063, "Avg game time in secs": 17.9546977232676, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "reached_maximum_moves": 0.03, "played_steps": 1.48, "agent_stopped_more": 0.3}, "Total num played games": 1024, "Total num trained steps": 1478, "Timestamp in ms": 1701793492402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.476923076923077, "Avg loss": 3.045815045014024, "Avg value loss": 2.1668190732598305, "Avg policy loss": 0.8789959978312254, "Total num played games": 1040, "Total num trained steps": 1536, "Timestamp in ms": 1701793520451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5045207956600362, "Avg loss": 3.092555670067668, "Avg value loss": 2.235303553752601, "Avg policy loss": 0.8572521135210991, "Total num played games": 1106, "Total num trained steps": 1664, "Timestamp in ms": 1701793581744, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 137.97887978889048, "Avg game time in secs": 23.97785902621399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 2.49, "agent_stopped_0": 0.56, "reached_maximum_moves": 0.05}, "Total num played games": 1152, "Total num trained steps": 1767, "Timestamp in ms": 1701793630381, "logtype": "played_game"}
{"Ratio train steps to played games": 1.5501730103806228, "Avg loss": 3.0304094906896353, "Avg value loss": 2.1644406216219068, "Avg policy loss": 0.8659688550978899, "Total num played games": 1156, "Total num trained steps": 1792, "Timestamp in ms": 1701793641504, "logtype": "training_step"}
{"Total num played games": 1254, "Total num trained steps": 1809, "Timestamp in ms": 1701793965140, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.16796875}
{"Avg objective": 18.3515625, "Games time in secs": 342.3197047878057, "Avg game time in secs": 63.17280740500428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.984375, "Avg reasons for ending game": {"reached_maximum_moves": 0.26, "played_steps": 6.64, "agent_stopped_0": 0.5, "agent_stopped_more": 0.24}, "Total num played games": 1280, "Total num trained steps": 1821, "Timestamp in ms": 1701793972701, "logtype": "played_game"}
{"Ratio train steps to played games": 1.4342301943198805, "Avg loss": 4.363131046295166, "Avg value loss": 3.571407862007618, "Avg policy loss": 0.7917232061736286, "Total num played games": 1338, "Total num trained steps": 1920, "Timestamp in ms": 1701794024681, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5192878338278932, "Avg loss": 2.818338595330715, "Avg value loss": 2.038916210643947, "Avg policy loss": 0.7794223786331713, "Total num played games": 1348, "Total num trained steps": 2048, "Timestamp in ms": 1701794096855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6142433234421365, "Avg loss": 2.4199286559596658, "Avg value loss": 1.6440526046790183, "Avg policy loss": 0.7758760494180024, "Total num played games": 1348, "Total num trained steps": 2176, "Timestamp in ms": 1701794164345, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 220.00107430294156, "Avg game time in secs": 12.820789447316201, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.38, "played_steps": 1.16, "reached_maximum_moves": 0.02}, "Total num played games": 1408, "Total num trained steps": 2231, "Timestamp in ms": 1701794192702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6340425531914893, "Avg loss": 2.786753362044692, "Avg value loss": 2.021304054185748, "Avg policy loss": 0.7654493115842342, "Total num played games": 1410, "Total num trained steps": 2304, "Timestamp in ms": 1701794228194, "logtype": "training_step"}
{"Total num played games": 1506, "Total num trained steps": 2409, "Timestamp in ms": 1701794576517, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5078125}
{"Avg objective": 20.15625, "Games time in secs": 392.28512274473906, "Avg game time in secs": 38.453818858382874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 4.62, "agent_stopped_0": 0.53, "reached_maximum_moves": 0.17}, "Total num played games": 1536, "Total num trained steps": 2424, "Timestamp in ms": 1701794584988, "logtype": "played_game"}
{"Ratio train steps to played games": 1.5670103092783505, "Avg loss": 2.9881886867806315, "Avg value loss": 2.2353426218032837, "Avg policy loss": 0.7528460621833801, "Total num played games": 1552, "Total num trained steps": 2432, "Timestamp in ms": 1701794589113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.618204804045512, "Avg loss": 3.036934698931873, "Avg value loss": 2.3390931701287627, "Avg policy loss": 0.6978415176272392, "Total num played games": 1582, "Total num trained steps": 2560, "Timestamp in ms": 1701794656326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6821026282853566, "Avg loss": 2.258306094445288, "Avg value loss": 1.5721731586381793, "Avg policy loss": 0.6861329642124474, "Total num played games": 1598, "Total num trained steps": 2688, "Timestamp in ms": 1701794724283, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 150.55275911837816, "Avg game time in secs": 16.752885931739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.38, "played_steps": 1.81, "reached_maximum_moves": 0.04}, "Total num played games": 1664, "Total num trained steps": 2711, "Timestamp in ms": 1701794735541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6781883194278904, "Avg loss": 2.408628638833761, "Avg value loss": 1.7906494131311774, "Avg policy loss": 0.6179792215116322, "Total num played games": 1678, "Total num trained steps": 2816, "Timestamp in ms": 1701794788615, "logtype": "training_step"}
{"Ratio train steps to played games": 1.688073394495413, "Avg loss": 2.203342297114432, "Avg value loss": 1.6206516465172172, "Avg policy loss": 0.5826906592119485, "Total num played games": 1744, "Total num trained steps": 2944, "Timestamp in ms": 1701794853312, "logtype": "training_step"}
{"Avg objective": 19.1640625, "Games time in secs": 154.1157776862383, "Avg game time in secs": 18.511367897634045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.24, "played_steps": 1.7, "agent_stopped_0": 0.71, "reached_maximum_moves": 0.05}, "Total num played games": 1792, "Total num trained steps": 3009, "Timestamp in ms": 1701794889656, "logtype": "played_game"}
{"Total num played games": 1854, "Total num trained steps": 3009, "Timestamp in ms": 1701795112319, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.64453125}
{"Avg objective": 21.0546875, "Games time in secs": 241.14918503910303, "Avg game time in secs": 29.465321180599858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.3, "played_steps": 3.65, "reached_maximum_moves": 0.13, "agent_stopped_0": 0.57}, "Total num played games": 1920, "Total num trained steps": 3043, "Timestamp in ms": 1701795130806, "logtype": "played_game"}
{"Ratio train steps to played games": 1.5950155763239875, "Avg loss": 2.8510690815746784, "Avg value loss": 2.3324151895940304, "Avg policy loss": 0.5186538868583739, "Total num played games": 1926, "Total num trained steps": 3072, "Timestamp in ms": 1701795144869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6580310880829014, "Avg loss": 2.017613962292671, "Avg value loss": 1.5417977701872587, "Avg policy loss": 0.47581617860123515, "Total num played games": 1930, "Total num trained steps": 3200, "Timestamp in ms": 1701795212138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.713697219361483, "Avg loss": 1.7895720871165395, "Avg value loss": 1.30999421980232, "Avg policy loss": 0.47957786568440497, "Total num played games": 1942, "Total num trained steps": 3328, "Timestamp in ms": 1701795278407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.6974459724950883, "Avg loss": 2.26280156057328, "Avg value loss": 1.795139901805669, "Avg policy loss": 0.4676616594661027, "Total num played games": 2036, "Total num trained steps": 3456, "Timestamp in ms": 1701795347027, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 280.5280598755926, "Avg game time in secs": 19.62353272625478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 2.21, "agent_stopped_0": 0.59, "reached_maximum_moves": 0.05}, "Total num played games": 2048, "Total num trained steps": 3579, "Timestamp in ms": 1701795411334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7148325358851675, "Avg loss": 1.7690487038344145, "Avg value loss": 1.3070737710222602, "Avg policy loss": 0.4619749435223639, "Total num played games": 2090, "Total num trained steps": 3584, "Timestamp in ms": 1701795414930, "logtype": "training_step"}
{"Total num played games": 2130, "Total num trained steps": 3609, "Timestamp in ms": 1701795545710, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.921875}
{"Avg objective": 20.5390625, "Games time in secs": 142.3279733080417, "Avg game time in secs": 13.254493192784139, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "reached_maximum_moves": 0.04, "played_steps": 1.25, "agent_stopped_more": 0.2}, "Total num played games": 2176, "Total num trained steps": 3623, "Timestamp in ms": 1701795553662, "logtype": "played_game"}
{"Ratio train steps to played games": 1.6716216216216215, "Avg loss": 2.6231411397457123, "Avg value loss": 2.1615251670591533, "Avg policy loss": 0.4616159831639379, "Total num played games": 2220, "Total num trained steps": 3712, "Timestamp in ms": 1701795603105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7266187050359711, "Avg loss": 1.639163289219141, "Avg value loss": 1.1852251146920025, "Avg policy loss": 0.45393815939314663, "Total num played games": 2224, "Total num trained steps": 3840, "Timestamp in ms": 1701795671388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.727787456445993, "Avg loss": 1.4779460681602359, "Avg value loss": 1.0339992623776197, "Avg policy loss": 0.44394679786637425, "Total num played games": 2296, "Total num trained steps": 3968, "Timestamp in ms": 1701795739729, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 193.51967399194837, "Avg game time in secs": 14.150312217505416, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.36, "played_steps": 1.46, "reached_maximum_moves": 0.04}, "Total num played games": 2304, "Total num trained steps": 3981, "Timestamp in ms": 1701795747182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7731601731601732, "Avg loss": 1.6032160250470042, "Avg value loss": 1.157514387741685, "Avg policy loss": 0.4457016319502145, "Total num played games": 2310, "Total num trained steps": 4096, "Timestamp in ms": 1701795808047, "logtype": "training_step"}
{"Total num played games": 2410, "Total num trained steps": 4210, "Timestamp in ms": 1701796040701, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.29296875}
{"Ratio train steps to played games": 1.7382716049382716, "Avg loss": 1.9968559639528394, "Avg value loss": 1.5561642893590033, "Avg policy loss": 0.44069168344140053, "Total num played games": 2430, "Total num trained steps": 4224, "Timestamp in ms": 1701796047875, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 300.7892552893609, "Avg game time in secs": 19.728110986980028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 2.34, "agent_stopped_0": 0.6, "reached_maximum_moves": 0.07}, "Total num played games": 2432, "Total num trained steps": 4224, "Timestamp in ms": 1701796047971, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7435897435897436, "Avg loss": 2.461346887052059, "Avg value loss": 2.0047659794799984, "Avg policy loss": 0.4565808910410851, "Total num played games": 2496, "Total num trained steps": 4352, "Timestamp in ms": 1701796116955, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7905675459632293, "Avg loss": 1.824775313027203, "Avg value loss": 1.3677987423725426, "Avg policy loss": 0.4569765627384186, "Total num played games": 2502, "Total num trained steps": 4480, "Timestamp in ms": 1701796186415, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 153.8305068165064, "Avg game time in secs": 13.068330277004861, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.35, "played_steps": 1.31, "reached_maximum_moves": 0.02}, "Total num played games": 2560, "Total num trained steps": 4510, "Timestamp in ms": 1701796201802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7736720554272518, "Avg loss": 2.100019946694374, "Avg value loss": 1.6394860874861479, "Avg policy loss": 0.46053384616971016, "Total num played games": 2598, "Total num trained steps": 4608, "Timestamp in ms": 1701796252703, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 115.18818783946335, "Avg game time in secs": 10.421517941838829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 1.06, "agent_stopped_0": 0.57, "reached_maximum_moves": 0.02}, "Total num played games": 2688, "Total num trained steps": 4729, "Timestamp in ms": 1701796316990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7592867756315007, "Avg loss": 1.6810568161308765, "Avg value loss": 1.2313027130439878, "Avg policy loss": 0.44975409586913884, "Total num played games": 2692, "Total num trained steps": 4736, "Timestamp in ms": 1701796321042, "logtype": "training_step"}
{"Total num played games": 2698, "Total num trained steps": 4811, "Timestamp in ms": 1701796474979, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.52734375}
{"Ratio train steps to played games": 1.743010752688172, "Avg loss": 1.6743423296138644, "Avg value loss": 1.2171523715369403, "Avg policy loss": 0.4571899683214724, "Total num played games": 2790, "Total num trained steps": 4864, "Timestamp in ms": 1701796503103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.7879656160458453, "Avg loss": 1.2112081493251026, "Avg value loss": 0.7591997487470508, "Avg policy loss": 0.45200840407051146, "Total num played games": 2792, "Total num trained steps": 4992, "Timestamp in ms": 1701796571474, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 305.2432670518756, "Avg game time in secs": 7.367747470125323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.61, "agent_stopped_0": 0.73, "reached_maximum_moves": 0.01}, "Total num played games": 2816, "Total num trained steps": 5086, "Timestamp in ms": 1701796622233, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7765440666204024, "Avg loss": 1.4541118238121271, "Avg value loss": 1.0044012507423759, "Avg policy loss": 0.4497105679474771, "Total num played games": 2882, "Total num trained steps": 5120, "Timestamp in ms": 1701796639949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.818087318087318, "Avg loss": 1.2966829305514693, "Avg value loss": 0.8370807599276304, "Avg policy loss": 0.4596021792385727, "Total num played games": 2886, "Total num trained steps": 5248, "Timestamp in ms": 1701796707653, "logtype": "training_step"}
{"Avg objective": 21.96875, "Games time in secs": 101.63805319927633, "Avg game time in secs": 9.055814400839154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.78}, "Total num played games": 2944, "Total num trained steps": 5281, "Timestamp in ms": 1701796723872, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8036912751677852, "Avg loss": 1.516616940498352, "Avg value loss": 1.0643281643278897, "Avg policy loss": 0.45228877547197044, "Total num played games": 2980, "Total num trained steps": 5376, "Timestamp in ms": 1701796773583, "logtype": "training_step"}
{"Total num played games": 2984, "Total num trained steps": 5411, "Timestamp in ms": 1701796894948, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.86328125}
{"Avg objective": 20.6875, "Games time in secs": 186.73215245082974, "Avg game time in secs": 9.962312956005917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 1.01, "agent_stopped_0": 0.55, "reached_maximum_moves": 0.02}, "Total num played games": 3072, "Total num trained steps": 5439, "Timestamp in ms": 1701796910608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7893368010403121, "Avg loss": 1.412004963029176, "Avg value loss": 0.9613846547435969, "Avg policy loss": 0.4506202929187566, "Total num played games": 3076, "Total num trained steps": 5504, "Timestamp in ms": 1701796945702, "logtype": "training_step"}
{"Ratio train steps to played games": 1.829759584145549, "Avg loss": 1.010736984666437, "Avg value loss": 0.5578759317286313, "Avg policy loss": 0.4528610499110073, "Total num played games": 3078, "Total num trained steps": 5632, "Timestamp in ms": 1701797011830, "logtype": "training_step"}
{"Ratio train steps to played games": 1.815889029003783, "Avg loss": 1.3813407444395125, "Avg value loss": 0.9335173759609461, "Avg policy loss": 0.4478233573026955, "Total num played games": 3172, "Total num trained steps": 5760, "Timestamp in ms": 1701797077850, "logtype": "training_step"}
{"Avg objective": 20.109375, "Games time in secs": 212.99751359038055, "Avg game time in secs": 8.092880002281163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 0.7, "agent_stopped_0": 0.7, "reached_maximum_moves": 0.01}, "Total num played games": 3200, "Total num trained steps": 5847, "Timestamp in ms": 1701797123606, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8017135862913096, "Avg loss": 1.3932890677824616, "Avg value loss": 0.9502743016928434, "Avg policy loss": 0.44301475887186825, "Total num played games": 3268, "Total num trained steps": 5888, "Timestamp in ms": 1701797144820, "logtype": "training_step"}
{"Total num played games": 3272, "Total num trained steps": 6014, "Timestamp in ms": 1701797303657, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.625}
{"Ratio train steps to played games": 1.8386308068459658, "Avg loss": 1.1311559271998703, "Avg value loss": 0.6954778349027038, "Avg policy loss": 0.4356780827511102, "Total num played games": 3272, "Total num trained steps": 6016, "Timestamp in ms": 1701797305714, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 189.12742619402707, "Avg game time in secs": 8.219466355018085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.35, "played_steps": 0.75, "reached_maximum_moves": 0.02}, "Total num played games": 3328, "Total num trained steps": 6031, "Timestamp in ms": 1701797312733, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8253119429590017, "Avg loss": 1.6482519810087979, "Avg value loss": 1.2083401295822114, "Avg policy loss": 0.43991184909828007, "Total num played games": 3366, "Total num trained steps": 6144, "Timestamp in ms": 1701797372136, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 113.4609906654805, "Avg game time in secs": 7.753789312177105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.81, "agent_stopped_0": 0.54, "reached_maximum_moves": 0.01}, "Total num played games": 3456, "Total num trained steps": 6251, "Timestamp in ms": 1701797426195, "logtype": "played_game"}
{"Ratio train steps to played games": 1.813475997686524, "Avg loss": 1.6218543956056237, "Avg value loss": 1.194352462887764, "Avg policy loss": 0.4275019243359566, "Total num played games": 3458, "Total num trained steps": 6272, "Timestamp in ms": 1701797436105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8507807981492193, "Avg loss": 1.207872317172587, "Avg value loss": 0.7688534965272993, "Avg policy loss": 0.4390188241377473, "Total num played games": 3458, "Total num trained steps": 6400, "Timestamp in ms": 1701797502232, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8354893138357706, "Avg loss": 1.5233720312826335, "Avg value loss": 1.0908558596856892, "Avg policy loss": 0.4325161713641137, "Total num played games": 3556, "Total num trained steps": 6528, "Timestamp in ms": 1701797566241, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 183.80944133922458, "Avg game time in secs": 8.856025621847948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.29, "played_steps": 0.82, "reached_maximum_moves": 0.01}, "Total num played games": 3584, "Total num trained steps": 6615, "Timestamp in ms": 1701797610004, "logtype": "played_game"}
{"Total num played games": 3654, "Total num trained steps": 6616, "Timestamp in ms": 1701797714238, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.1484375}
{"Avg objective": 22.5234375, "Games time in secs": 114.04505742527544, "Avg game time in secs": 6.850824054228724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.36, "played_steps": 0.62, "reached_maximum_moves": 0.01}, "Total num played games": 3712, "Total num trained steps": 6635, "Timestamp in ms": 1701797724052, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7768286171916712, "Avg loss": 2.0732429386116564, "Avg value loss": 1.6346976647619158, "Avg policy loss": 0.4385452715214342, "Total num played games": 3746, "Total num trained steps": 6656, "Timestamp in ms": 1701797733748, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8100320170757738, "Avg loss": 1.5901345335878432, "Avg value loss": 1.1167262268718332, "Avg policy loss": 0.473408316494897, "Total num played games": 3748, "Total num trained steps": 6784, "Timestamp in ms": 1701797796104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8441835645677696, "Avg loss": 1.0288124266080558, "Avg value loss": 0.580110551090911, "Avg policy loss": 0.44870187412016094, "Total num played games": 3748, "Total num trained steps": 6912, "Timestamp in ms": 1701797860172, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 189.14321553707123, "Avg game time in secs": 7.184860127614229, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.6, "agent_stopped_0": 0.57}, "Total num played games": 3840, "Total num trained steps": 7017, "Timestamp in ms": 1701797913196, "logtype": "played_game"}
{"Ratio train steps to played games": 1.831165452653486, "Avg loss": 1.3580102981068194, "Avg value loss": 0.9109366156626493, "Avg policy loss": 0.4470736822113395, "Total num played games": 3844, "Total num trained steps": 7040, "Timestamp in ms": 1701797924322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8647242455775235, "Avg loss": 1.078253148123622, "Avg value loss": 0.632023544749245, "Avg policy loss": 0.4462296033743769, "Total num played games": 3844, "Total num trained steps": 7168, "Timestamp in ms": 1701797987679, "logtype": "training_step"}
{"Total num played games": 3942, "Total num trained steps": 7220, "Timestamp in ms": 1701798115783, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.63671875}
{"Avg objective": 21.1171875, "Games time in secs": 207.7340471688658, "Avg game time in secs": 5.124550902051851, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.25, "played_steps": 0.31, "agent_stopped_0": 0.75}, "Total num played games": 3968, "Total num trained steps": 7230, "Timestamp in ms": 1701798120930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8083787803668816, "Avg loss": 1.630309927277267, "Avg value loss": 1.1969943903386593, "Avg policy loss": 0.43331553880125284, "Total num played games": 4034, "Total num trained steps": 7296, "Timestamp in ms": 1701798150926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8403569657907783, "Avg loss": 0.9505107151344419, "Avg value loss": 0.5127064182888716, "Avg policy loss": 0.4378042926546186, "Total num played games": 4034, "Total num trained steps": 7424, "Timestamp in ms": 1701798212160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8709117938553024, "Avg loss": 0.8935601147823036, "Avg value loss": 0.4762489835266024, "Avg policy loss": 0.4173111270647496, "Total num played games": 4036, "Total num trained steps": 7552, "Timestamp in ms": 1701798272397, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 163.12539751268923, "Avg game time in secs": 7.107162951200735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.62}, "Total num played games": 4096, "Total num trained steps": 7579, "Timestamp in ms": 1701798284056, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8586640851887706, "Avg loss": 1.444807832594961, "Avg value loss": 1.0269856245722622, "Avg policy loss": 0.41782220220193267, "Total num played games": 4132, "Total num trained steps": 7680, "Timestamp in ms": 1701798330724, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 97.48166555911303, "Avg game time in secs": 7.259349551051855, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.8}, "Total num played games": 4224, "Total num trained steps": 7793, "Timestamp in ms": 1701798381538, "logtype": "played_game"}
{"Ratio train steps to played games": 1.846736045411542, "Avg loss": 1.3673264496028423, "Avg value loss": 0.9499666963238269, "Avg policy loss": 0.4173597467597574, "Total num played games": 4228, "Total num trained steps": 7808, "Timestamp in ms": 1701798388147, "logtype": "training_step"}
{"Total num played games": 4232, "Total num trained steps": 7823, "Timestamp in ms": 1701798517053, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6953125}
{"Ratio train steps to played games": 1.8344891354600092, "Avg loss": 1.6501416084356606, "Avg value loss": 1.218966650776565, "Avg policy loss": 0.4311749590560794, "Total num played games": 4326, "Total num trained steps": 7936, "Timestamp in ms": 1701798570164, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8640776699029127, "Avg loss": 0.9493488022126257, "Avg value loss": 0.5294575532898307, "Avg policy loss": 0.41989124729298055, "Total num played games": 4326, "Total num trained steps": 8064, "Timestamp in ms": 1701798628164, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 284.2963665612042, "Avg game time in secs": 5.711175956472289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.47}, "Total num played games": 4352, "Total num trained steps": 8151, "Timestamp in ms": 1701798665834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8525554047942108, "Avg loss": 1.321403464768082, "Avg value loss": 0.9096219763159752, "Avg policy loss": 0.41178148542530835, "Total num played games": 4422, "Total num trained steps": 8192, "Timestamp in ms": 1701798683972, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8815015829941204, "Avg loss": 0.9239283790811896, "Avg value loss": 0.5110572041012347, "Avg policy loss": 0.4128711740486324, "Total num played games": 4422, "Total num trained steps": 8320, "Timestamp in ms": 1701798743545, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 89.3636039942503, "Avg game time in secs": 5.318162538125762, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 4480, "Total num trained steps": 8347, "Timestamp in ms": 1701798755198, "logtype": "played_game"}
{"Total num played games": 4520, "Total num trained steps": 8425, "Timestamp in ms": 1701798895836, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.203125}
{"Ratio train steps to played games": 1.8379025239338556, "Avg loss": 1.280784461647272, "Avg value loss": 0.8864877119194716, "Avg policy loss": 0.3942967609036714, "Total num played games": 4594, "Total num trained steps": 8448, "Timestamp in ms": 1701798906079, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 153.14788674376905, "Avg game time in secs": 6.334919085231377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.65, "agent_stopped_0": 0.51}, "Total num played games": 4608, "Total num trained steps": 8453, "Timestamp in ms": 1701798908346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8584742089293456, "Avg loss": 1.3577568926848471, "Avg value loss": 0.9493648903444409, "Avg policy loss": 0.40839202236384153, "Total num played games": 4614, "Total num trained steps": 8576, "Timestamp in ms": 1701798965226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8864325964456004, "Avg loss": 0.8785609765909612, "Avg value loss": 0.47109726280905306, "Avg policy loss": 0.4074637149460614, "Total num played games": 4614, "Total num trained steps": 8704, "Timestamp in ms": 1701799027017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8743633276740237, "Avg loss": 1.0613880609162152, "Avg value loss": 0.6693397897761315, "Avg policy loss": 0.392048267647624, "Total num played games": 4712, "Total num trained steps": 8832, "Timestamp in ms": 1701799085957, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 220.05945260822773, "Avg game time in secs": 4.781787070794962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 0.43, "agent_stopped_0": 0.72}, "Total num played games": 4736, "Total num trained steps": 8920, "Timestamp in ms": 1701799128406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8643362463587183, "Avg loss": 1.1720343702472746, "Avg value loss": 0.7899867726955563, "Avg policy loss": 0.38204759801737964, "Total num played games": 4806, "Total num trained steps": 8960, "Timestamp in ms": 1701799146102, "logtype": "training_step"}
{"Total num played games": 4808, "Total num trained steps": 9026, "Timestamp in ms": 1701799281350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.73046875}
{"Avg objective": 22.4453125, "Games time in secs": 158.90410230867565, "Avg game time in secs": 5.130778357706731, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.55}, "Total num played games": 4864, "Total num trained steps": 9039, "Timestamp in ms": 1701799287310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8554512045732952, "Avg loss": 1.3019939344376326, "Avg value loss": 0.9015899940859526, "Avg policy loss": 0.40040393196977675, "Total num played games": 4898, "Total num trained steps": 9088, "Timestamp in ms": 1701799310799, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8800489596083232, "Avg loss": 0.878064192365855, "Avg value loss": 0.48525726702064276, "Avg policy loss": 0.39280692348256707, "Total num played games": 4902, "Total num trained steps": 9216, "Timestamp in ms": 1701799368431, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 127.25792724080384, "Avg game time in secs": 5.6706461485882755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.69}, "Total num played games": 4992, "Total num trained steps": 9318, "Timestamp in ms": 1701799414568, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8695478191276511, "Avg loss": 1.1743017975240946, "Avg value loss": 0.7654491467401385, "Avg policy loss": 0.4088526568375528, "Total num played games": 4998, "Total num trained steps": 9344, "Timestamp in ms": 1701799425948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.89515806322529, "Avg loss": 0.799015729688108, "Avg value loss": 0.4150149514898658, "Avg policy loss": 0.3840007851831615, "Total num played games": 4998, "Total num trained steps": 9472, "Timestamp in ms": 1701799486596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8845700824499412, "Avg loss": 1.1126455194316804, "Avg value loss": 0.7324192468076944, "Avg policy loss": 0.380226275883615, "Total num played games": 5094, "Total num trained steps": 9600, "Timestamp in ms": 1701799543949, "logtype": "training_step"}
{"Total num played games": 5094, "Total num trained steps": 9631, "Timestamp in ms": 1701799657187, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.61328125}
{"Avg objective": 20.3671875, "Games time in secs": 246.49316839501262, "Avg game time in secs": 5.355023495314526, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.62}, "Total num played games": 5120, "Total num trained steps": 9640, "Timestamp in ms": 1701799661061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8750963762528914, "Avg loss": 1.2869307613000274, "Avg value loss": 0.9082148452289402, "Avg policy loss": 0.3787159286439419, "Total num played games": 5188, "Total num trained steps": 9728, "Timestamp in ms": 1701799700146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8995759444872784, "Avg loss": 0.798349027056247, "Avg value loss": 0.4189303875900805, "Avg policy loss": 0.3794186320155859, "Total num played games": 5188, "Total num trained steps": 9856, "Timestamp in ms": 1701799756221, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 104.85235304385424, "Avg game time in secs": 4.844127676537028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.54, "agent_stopped_0": 0.58}, "Total num played games": 5248, "Total num trained steps": 9880, "Timestamp in ms": 1701799765914, "logtype": "played_game"}
{"Ratio train steps to played games": 1.890193108670958, "Avg loss": 1.165941294748336, "Avg value loss": 0.7800387972965837, "Avg policy loss": 0.3859024984994903, "Total num played games": 5282, "Total num trained steps": 9984, "Timestamp in ms": 1701799812355, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8816524004465947, "Avg loss": 1.0510592004284263, "Avg value loss": 0.673295512329787, "Avg policy loss": 0.37776368111371994, "Total num played games": 5374, "Total num trained steps": 10112, "Timestamp in ms": 1701799870086, "logtype": "training_step"}
{"Avg objective": 20.234375, "Games time in secs": 104.45562336966395, "Avg game time in secs": 6.583938325959025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.94, "agent_stopped_0": 0.49}, "Total num played games": 5376, "Total num trained steps": 10112, "Timestamp in ms": 1701799870370, "logtype": "played_game"}
{"Total num played games": 5378, "Total num trained steps": 10231, "Timestamp in ms": 1701799971033, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.671875}
{"Ratio train steps to played games": 1.8886019918849133, "Avg loss": 0.8015660075470805, "Avg value loss": 0.4347445738967508, "Avg policy loss": 0.36682143388316035, "Total num played games": 5422, "Total num trained steps": 10240, "Timestamp in ms": 1701799975399, "logtype": "training_step"}
{"Ratio train steps to played games": 1.894736842105263, "Avg loss": 1.1482053720392287, "Avg value loss": 0.7688064011745155, "Avg policy loss": 0.37939896318130195, "Total num played games": 5472, "Total num trained steps": 10368, "Timestamp in ms": 1701800035549, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 198.1804455127567, "Avg game time in secs": 4.0025015885039466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.46, "agent_stopped_0": 0.67}, "Total num played games": 5504, "Total num trained steps": 10442, "Timestamp in ms": 1701800068550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8850574712643677, "Avg loss": 1.500820705667138, "Avg value loss": 1.1168207661248744, "Avg policy loss": 0.3839999311603606, "Total num played games": 5568, "Total num trained steps": 10496, "Timestamp in ms": 1701800091878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9078663793103448, "Avg loss": 0.8584833438508213, "Avg value loss": 0.4690766972489655, "Avg policy loss": 0.3894066489301622, "Total num played games": 5568, "Total num trained steps": 10624, "Timestamp in ms": 1701800153051, "logtype": "training_step"}
{"Avg objective": 23.3046875, "Games time in secs": 90.40728932619095, "Avg game time in secs": 4.282044123043306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.55}, "Total num played games": 5632, "Total num trained steps": 10638, "Timestamp in ms": 1701800158958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8983050847457628, "Avg loss": 1.434240554459393, "Avg value loss": 1.0512976059690118, "Avg policy loss": 0.3829429561737925, "Total num played games": 5664, "Total num trained steps": 10752, "Timestamp in ms": 1701800210291, "logtype": "training_step"}
{"Avg objective": 22.2578125, "Games time in secs": 91.81633958593011, "Avg game time in secs": 4.638175829051761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.52, "agent_stopped_0": 0.56}, "Total num played games": 5760, "Total num trained steps": 10833, "Timestamp in ms": 1701800250774, "logtype": "played_game"}
{"Total num played games": 5762, "Total num trained steps": 10833, "Timestamp in ms": 1701800288186, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.265625}
{"Ratio train steps to played games": 1.8579234972677596, "Avg loss": 1.5028915093280375, "Avg value loss": 1.124575651716441, "Avg policy loss": 0.3783158608712256, "Total num played games": 5856, "Total num trained steps": 10880, "Timestamp in ms": 1701800309320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8797814207650274, "Avg loss": 0.8903333055786788, "Avg value loss": 0.5096009036060423, "Avg policy loss": 0.3807323989458382, "Total num played games": 5856, "Total num trained steps": 11008, "Timestamp in ms": 1701800367459, "logtype": "training_step"}
{"Ratio train steps to played games": 1.901639344262295, "Avg loss": 0.6894154699984938, "Avg value loss": 0.3340642212424427, "Avg policy loss": 0.35535124503076077, "Total num played games": 5856, "Total num trained steps": 11136, "Timestamp in ms": 1701800422506, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 203.0881780963391, "Avg game time in secs": 3.375462114578113, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.26, "played_steps": 0.33, "agent_stopped_0": 0.74}, "Total num played games": 5888, "Total num trained steps": 11208, "Timestamp in ms": 1701800453862, "logtype": "played_game"}
{"Ratio train steps to played games": 1.89247311827957, "Avg loss": 1.1602717535570264, "Avg value loss": 0.7964666052721441, "Avg policy loss": 0.36380513827316463, "Total num played games": 5952, "Total num trained steps": 11264, "Timestamp in ms": 1701800479882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9138104838709677, "Avg loss": 0.7308327523060143, "Avg value loss": 0.3700629047816619, "Avg policy loss": 0.36076985124964267, "Total num played games": 5952, "Total num trained steps": 11392, "Timestamp in ms": 1701800537190, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 88.60477780178189, "Avg game time in secs": 3.9936120553466026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.51}, "Total num played games": 6016, "Total num trained steps": 11405, "Timestamp in ms": 1701800542467, "logtype": "played_game"}
{"Total num played games": 6048, "Total num trained steps": 11435, "Timestamp in ms": 1701800748846, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.83984375}
{"Ratio train steps to played games": 1.8756105503093454, "Avg loss": 1.4615995928179473, "Avg value loss": 1.0742865913780406, "Avg policy loss": 0.3873130043502897, "Total num played games": 6142, "Total num trained steps": 11520, "Timestamp in ms": 1701800785851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8964506675350048, "Avg loss": 0.8103277068585157, "Avg value loss": 0.42825535067822784, "Avg policy loss": 0.38207235699519515, "Total num played games": 6142, "Total num trained steps": 11648, "Timestamp in ms": 1701800843208, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 355.1440073437989, "Avg game time in secs": 4.671090216084849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 6144, "Total num trained steps": 11773, "Timestamp in ms": 1701800897611, "logtype": "played_game"}
{"Ratio train steps to played games": 1.915419648666233, "Avg loss": 0.6716747134923935, "Avg value loss": 0.3159243306145072, "Avg policy loss": 0.35575038474053144, "Total num played games": 6146, "Total num trained steps": 11776, "Timestamp in ms": 1701800898670, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9083039435716576, "Avg loss": 1.1034834459424019, "Avg value loss": 0.7294232612475753, "Avg policy loss": 0.37406018713954836, "Total num played games": 6238, "Total num trained steps": 11904, "Timestamp in ms": 1701800956930, "logtype": "training_step"}
{"Avg objective": 22.421875, "Games time in secs": 88.61825508624315, "Avg game time in secs": 3.3311672067502514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.43}, "Total num played games": 6272, "Total num trained steps": 11972, "Timestamp in ms": 1701800986230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8995895168929586, "Avg loss": 1.0817377590574324, "Avg value loss": 0.7068724430864677, "Avg policy loss": 0.374865320045501, "Total num played games": 6334, "Total num trained steps": 12032, "Timestamp in ms": 1701801013713, "logtype": "training_step"}
{"Total num played games": 6334, "Total num trained steps": 12035, "Timestamp in ms": 1701801050110, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1171875}
{"Avg objective": 20.9296875, "Games time in secs": 70.85149185732007, "Avg game time in secs": 3.9965847613930237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 6400, "Total num trained steps": 12050, "Timestamp in ms": 1701801057081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8917237087741132, "Avg loss": 1.2490326636470854, "Avg value loss": 0.8572695855982602, "Avg policy loss": 0.39176307478919625, "Total num played games": 6428, "Total num trained steps": 12160, "Timestamp in ms": 1701801106427, "logtype": "training_step"}
{"Ratio train steps to played games": 1.911636589919104, "Avg loss": 0.7813070751726627, "Avg value loss": 0.39475927292369306, "Avg policy loss": 0.3865478008519858, "Total num played games": 6428, "Total num trained steps": 12288, "Timestamp in ms": 1701801164752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.902973635806254, "Avg loss": 1.0267610461451113, "Avg value loss": 0.6552512621274218, "Avg policy loss": 0.37150977994315326, "Total num played games": 6524, "Total num trained steps": 12416, "Timestamp in ms": 1701801219742, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 218.32447633706033, "Avg game time in secs": 4.285322546362295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.61, "agent_stopped_0": 0.54}, "Total num played games": 6528, "Total num trained steps": 12540, "Timestamp in ms": 1701801275406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9137931034482758, "Avg loss": 0.7294805976562202, "Avg value loss": 0.3592428092379123, "Avg policy loss": 0.37023779179435223, "Total num played games": 6554, "Total num trained steps": 12544, "Timestamp in ms": 1701801276679, "logtype": "training_step"}
{"Total num played games": 6620, "Total num trained steps": 12636, "Timestamp in ms": 1701801380198, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.83203125}
{"Avg objective": 21.8359375, "Games time in secs": 108.67159863375127, "Avg game time in secs": 3.335151633233181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.51}, "Total num played games": 6656, "Total num trained steps": 12643, "Timestamp in ms": 1701801384078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8872505212987787, "Avg loss": 1.4969908026978374, "Avg value loss": 1.1054215978365391, "Avg policy loss": 0.3915692185983062, "Total num played games": 6714, "Total num trained steps": 12672, "Timestamp in ms": 1701801396759, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9064641048555258, "Avg loss": 0.8755932003259659, "Avg value loss": 0.49512107972986996, "Avg policy loss": 0.3804721259512007, "Total num played games": 6714, "Total num trained steps": 12800, "Timestamp in ms": 1701801453113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.911860396332446, "Avg loss": 0.7134296703152359, "Avg value loss": 0.34751286439131945, "Avg policy loss": 0.3659168095327914, "Total num played games": 6758, "Total num trained steps": 12928, "Timestamp in ms": 1701801507671, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 125.5392179787159, "Avg game time in secs": 3.8849448932596715, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 6784, "Total num trained steps": 12933, "Timestamp in ms": 1701801509617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9170337738619676, "Avg loss": 1.2586809368804097, "Avg value loss": 0.8843577520456165, "Avg policy loss": 0.3743231915868819, "Total num played games": 6810, "Total num trained steps": 13056, "Timestamp in ms": 1701801563745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9090645815233132, "Avg loss": 1.0936389793641865, "Avg value loss": 0.7155481106601655, "Avg policy loss": 0.37809087289497256, "Total num played games": 6906, "Total num trained steps": 13184, "Timestamp in ms": 1701801621168, "logtype": "training_step"}
{"Total num played games": 6906, "Total num trained steps": 13239, "Timestamp in ms": 1701801735840, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.13671875}
{"Avg objective": 21.625, "Games time in secs": 229.0772367697209, "Avg game time in secs": 3.8867159461660776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.62, "agent_stopped_0": 0.55}, "Total num played games": 6912, "Total num trained steps": 13244, "Timestamp in ms": 1701801738694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9017142857142857, "Avg loss": 1.0201670806854963, "Avg value loss": 0.6438685555476695, "Avg policy loss": 0.3762985309585929, "Total num played games": 7000, "Total num trained steps": 13312, "Timestamp in ms": 1701801768104, "logtype": "training_step"}
{"Ratio train steps to played games": 1.92, "Avg loss": 0.7668519336730242, "Avg value loss": 0.39276524155866355, "Avg policy loss": 0.37408669386059046, "Total num played games": 7000, "Total num trained steps": 13440, "Timestamp in ms": 1701801823710, "logtype": "training_step"}
{"Avg objective": 20.140625, "Games time in secs": 110.71985523588955, "Avg game time in secs": 3.6674398581380956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.51}, "Total num played games": 7040, "Total num trained steps": 13497, "Timestamp in ms": 1701801849414, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9109859154929578, "Avg loss": 1.389865956734866, "Avg value loss": 1.0018660647328943, "Avg policy loss": 0.38799989130347967, "Total num played games": 7100, "Total num trained steps": 13568, "Timestamp in ms": 1701801881632, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9214365881032547, "Avg loss": 0.7896999036893249, "Avg value loss": 0.3988937201211229, "Avg policy loss": 0.39080618182197213, "Total num played games": 7126, "Total num trained steps": 13696, "Timestamp in ms": 1701801939009, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 92.19571966305375, "Avg game time in secs": 3.5086961066554068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.67}, "Total num played games": 7168, "Total num trained steps": 13702, "Timestamp in ms": 1701801941610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.920928293496387, "Avg loss": 1.1235593785531819, "Avg value loss": 0.7156444019638002, "Avg policy loss": 0.4079149798490107, "Total num played games": 7196, "Total num trained steps": 13824, "Timestamp in ms": 1701801994386, "logtype": "training_step"}
{"Total num played games": 7196, "Total num trained steps": 13840, "Timestamp in ms": 1701802037291, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.37890625}
{"Ratio train steps to played games": 1.9138545953360768, "Avg loss": 1.3326032599434257, "Avg value loss": 0.915502539020963, "Avg policy loss": 0.41710072150453925, "Total num played games": 7290, "Total num trained steps": 13952, "Timestamp in ms": 1701802084482, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 195.08724457584321, "Avg game time in secs": 4.314836111094337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.72, "agent_stopped_0": 0.42}, "Total num played games": 7296, "Total num trained steps": 14073, "Timestamp in ms": 1701802136698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9161676646706587, "Avg loss": 0.7324703857302666, "Avg value loss": 0.3351463391445577, "Avg policy loss": 0.39732404914684594, "Total num played games": 7348, "Total num trained steps": 14080, "Timestamp in ms": 1701802139505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9236393176279447, "Avg loss": 0.997461870778352, "Avg value loss": 0.5870365025475621, "Avg policy loss": 0.4104253677651286, "Total num played games": 7386, "Total num trained steps": 14208, "Timestamp in ms": 1701802195694, "logtype": "training_step"}
{"Avg objective": 23.6328125, "Games time in secs": 85.76707294210792, "Avg game time in secs": 3.3470600623986684, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.55}, "Total num played games": 7424, "Total num trained steps": 14269, "Timestamp in ms": 1701802222465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9160652232023523, "Avg loss": 1.3900002525188029, "Avg value loss": 0.9812598380958661, "Avg policy loss": 0.4087404098827392, "Total num played games": 7482, "Total num trained steps": 14336, "Timestamp in ms": 1701802252292, "logtype": "training_step"}
{"Total num played games": 7482, "Total num trained steps": 14442, "Timestamp in ms": 1701802324131, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.83984375}
{"Avg objective": 21.84375, "Games time in secs": 106.4889867529273, "Avg game time in secs": 3.348269525624346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 7552, "Total num trained steps": 14451, "Timestamp in ms": 1701802328954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9091869060190074, "Avg loss": 1.0350843141786754, "Avg value loss": 0.6366944080218673, "Avg policy loss": 0.39838989544659853, "Total num played games": 7576, "Total num trained steps": 14464, "Timestamp in ms": 1701802335371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9260823653643084, "Avg loss": 0.9374902187846601, "Avg value loss": 0.5457099815830588, "Avg policy loss": 0.3917802374344319, "Total num played games": 7576, "Total num trained steps": 14592, "Timestamp in ms": 1701802395122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.91866527632951, "Avg loss": 1.1055792467668653, "Avg value loss": 0.7038505632663146, "Avg policy loss": 0.40172867360524833, "Total num played games": 7672, "Total num trained steps": 14720, "Timestamp in ms": 1701802452561, "logtype": "training_step"}
{"Avg objective": 22.1796875, "Games time in secs": 172.9157529976219, "Avg game time in secs": 3.724350566844805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.65, "agent_stopped_0": 0.49}, "Total num played games": 7680, "Total num trained steps": 14838, "Timestamp in ms": 1701802501870, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9143888602372356, "Avg loss": 0.8158669834956527, "Avg value loss": 0.4304612763226032, "Avg policy loss": 0.38540571136400104, "Total num played games": 7754, "Total num trained steps": 14848, "Timestamp in ms": 1701802505664, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9277806385169929, "Avg loss": 1.2004861203022301, "Avg value loss": 0.7878509545698762, "Avg policy loss": 0.41263517271727324, "Total num played games": 7768, "Total num trained steps": 14976, "Timestamp in ms": 1701802561568, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 85.48645071312785, "Avg game time in secs": 3.0017711572145345, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 7808, "Total num trained steps": 15030, "Timestamp in ms": 1701802587356, "logtype": "played_game"}
{"Total num played games": 7862, "Total num trained steps": 15043, "Timestamp in ms": 1701802625405, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.92578125}
{"Avg objective": 21.328125, "Games time in secs": 43.24737751297653, "Avg game time in secs": 3.387199785269331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.6, "agent_stopped_0": 0.5}, "Total num played games": 7936, "Total num trained steps": 15054, "Timestamp in ms": 1701802630604, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8984414278531925, "Avg loss": 1.7020324594341218, "Avg value loss": 1.2880250358721241, "Avg policy loss": 0.4140074288006872, "Total num played games": 7956, "Total num trained steps": 15104, "Timestamp in ms": 1701802652283, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9145299145299146, "Avg loss": 0.8504895884543657, "Avg value loss": 0.43598470534197986, "Avg policy loss": 0.41450488194823265, "Total num played games": 7956, "Total num trained steps": 15232, "Timestamp in ms": 1701802710365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9306184012066365, "Avg loss": 0.6695180526003242, "Avg value loss": 0.2745501239551231, "Avg policy loss": 0.39496793295256793, "Total num played games": 7956, "Total num trained steps": 15360, "Timestamp in ms": 1701802768433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9234972677595628, "Avg loss": 1.044333959929645, "Avg value loss": 0.6471583875827491, "Avg policy loss": 0.3971755688544363, "Total num played games": 8052, "Total num trained steps": 15488, "Timestamp in ms": 1701802825865, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 245.413215784356, "Avg game time in secs": 3.3000636441865936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.56}, "Total num played games": 8064, "Total num trained steps": 15598, "Timestamp in ms": 1701802876017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.916073619631902, "Avg loss": 0.7919498612172902, "Avg value loss": 0.39812020026147366, "Avg policy loss": 0.3938296576961875, "Total num played games": 8150, "Total num trained steps": 15616, "Timestamp in ms": 1701802884163, "logtype": "training_step"}
{"Total num played games": 8150, "Total num trained steps": 15643, "Timestamp in ms": 1701802978285, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.57421875}
{"Avg objective": 21.3515625, "Games time in secs": 106.38450501300395, "Avg game time in secs": 3.2030429554724833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 8192, "Total num trained steps": 15652, "Timestamp in ms": 1701802982402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9097525473071324, "Avg loss": 1.2545021544210613, "Avg value loss": 0.8382392120547593, "Avg policy loss": 0.41626294306479394, "Total num played games": 8244, "Total num trained steps": 15744, "Timestamp in ms": 1701803025264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9251576904415333, "Avg loss": 0.7362497048452497, "Avg value loss": 0.3273721334990114, "Avg policy loss": 0.4088775694835931, "Total num played games": 8244, "Total num trained steps": 15872, "Timestamp in ms": 1701803084643, "logtype": "training_step"}
{"Avg objective": 22.203125, "Games time in secs": 154.59157706052065, "Avg game time in secs": 3.8409536740218755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.76}, "Total num played games": 8320, "Total num trained steps": 15990, "Timestamp in ms": 1701803136994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.918925401775006, "Avg loss": 0.7757108386140317, "Avg value loss": 0.3850932418135926, "Avg policy loss": 0.39061760110780597, "Total num played games": 8338, "Total num trained steps": 16000, "Timestamp in ms": 1701803140916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9338129496402878, "Avg loss": 0.885270019993186, "Avg value loss": 0.4746930489782244, "Avg policy loss": 0.41057697497308254, "Total num played games": 8340, "Total num trained steps": 16128, "Timestamp in ms": 1701803199706, "logtype": "training_step"}
{"Total num played games": 8436, "Total num trained steps": 16246, "Timestamp in ms": 1701803271959, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.91015625}
{"Avg objective": 20.6953125, "Games time in secs": 137.26851532049477, "Avg game time in secs": 3.6493364011112135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.64, "agent_stopped_0": 0.53}, "Total num played games": 8448, "Total num trained steps": 16249, "Timestamp in ms": 1701803274262, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9120207010115267, "Avg loss": 1.1066791363991797, "Avg value loss": 0.7080197090981528, "Avg policy loss": 0.3986594162415713, "Total num played games": 8502, "Total num trained steps": 16256, "Timestamp in ms": 1701803277069, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9207502930832356, "Avg loss": 1.3324089450761676, "Avg value loss": 0.9120234536239877, "Avg policy loss": 0.4203855136875063, "Total num played games": 8530, "Total num trained steps": 16384, "Timestamp in ms": 1701803335111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9357561547479485, "Avg loss": 0.6908949753269553, "Avg value loss": 0.3053458782378584, "Avg policy loss": 0.3855490966234356, "Total num played games": 8530, "Total num trained steps": 16512, "Timestamp in ms": 1701803391722, "logtype": "training_step"}
{"Avg objective": 22.609375, "Games time in secs": 136.3869546931237, "Avg game time in secs": 3.2220833631872665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 8576, "Total num trained steps": 16558, "Timestamp in ms": 1701803410649, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9290517041502435, "Avg loss": 1.1112343943677843, "Avg value loss": 0.7205903067952022, "Avg policy loss": 0.3906440793070942, "Total num played games": 8626, "Total num trained steps": 16640, "Timestamp in ms": 1701803447264, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 87.59165815636516, "Avg game time in secs": 3.5862296840787167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 8704, "Total num trained steps": 16753, "Timestamp in ms": 1701803498241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9229357798165139, "Avg loss": 0.8757215435616672, "Avg value loss": 0.502033831551671, "Avg policy loss": 0.3736877159681171, "Total num played games": 8720, "Total num trained steps": 16768, "Timestamp in ms": 1701803505583, "logtype": "training_step"}
{"Total num played games": 8722, "Total num trained steps": 16845, "Timestamp in ms": 1701803566547, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2890625}
{"Ratio train steps to played games": 1.9165154264972777, "Avg loss": 1.1999873397871852, "Avg value loss": 0.8064686576835811, "Avg policy loss": 0.3935186837334186, "Total num played games": 8816, "Total num trained steps": 16896, "Timestamp in ms": 1701803590755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9310344827586208, "Avg loss": 0.7715312205255032, "Avg value loss": 0.38790709420572966, "Avg policy loss": 0.3836241230601445, "Total num played games": 8816, "Total num trained steps": 17024, "Timestamp in ms": 1701803649035, "logtype": "training_step"}
{"Avg objective": 20.2109375, "Games time in secs": 195.56969319470227, "Avg game time in secs": 3.6569445501081645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.67, "agent_stopped_0": 0.52}, "Total num played games": 8832, "Total num trained steps": 17126, "Timestamp in ms": 1701803693811, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9245960502692998, "Avg loss": 0.7999248683918267, "Avg value loss": 0.4309346058871597, "Avg policy loss": 0.3689902671612799, "Total num played games": 8912, "Total num trained steps": 17152, "Timestamp in ms": 1701803705377, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9389587073608618, "Avg loss": 0.7094925702549517, "Avg value loss": 0.3328612034674734, "Avg policy loss": 0.3766313672531396, "Total num played games": 8912, "Total num trained steps": 17280, "Timestamp in ms": 1701803759017, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 82.36797853372991, "Avg game time in secs": 3.0654360939224716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 8960, "Total num trained steps": 17320, "Timestamp in ms": 1701803776179, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9328225627359539, "Avg loss": 0.999786910135299, "Avg value loss": 0.6291973127517849, "Avg policy loss": 0.370589601341635, "Total num played games": 9006, "Total num trained steps": 17408, "Timestamp in ms": 1701803812933, "logtype": "training_step"}
{"Total num played games": 9006, "Total num trained steps": 17449, "Timestamp in ms": 1701803855218, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.94140625}
{"Avg objective": 21.296875, "Games time in secs": 85.9146817997098, "Avg game time in secs": 3.3014747557172086, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 9088, "Total num trained steps": 17464, "Timestamp in ms": 1701803862094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9270329670329671, "Avg loss": 1.100499373394996, "Avg value loss": 0.730304820346646, "Avg policy loss": 0.37019455479457974, "Total num played games": 9100, "Total num trained steps": 17536, "Timestamp in ms": 1701803892997, "logtype": "training_step"}
{"Ratio train steps to played games": 1.941098901098901, "Avg loss": 0.6409959285520017, "Avg value loss": 0.2767248924355954, "Avg policy loss": 0.3642710316926241, "Total num played games": 9100, "Total num trained steps": 17664, "Timestamp in ms": 1701803948546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9346454980426273, "Avg loss": 1.0677847154438496, "Avg value loss": 0.6913152497727424, "Avg policy loss": 0.37646946241147816, "Total num played games": 9196, "Total num trained steps": 17792, "Timestamp in ms": 1701804003457, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 180.6627639811486, "Avg game time in secs": 3.915196610032581, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.74, "agent_stopped_0": 0.45}, "Total num played games": 9216, "Total num trained steps": 17886, "Timestamp in ms": 1701804042757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.928540680154972, "Avg loss": 0.8436010766308755, "Avg value loss": 0.48126500204671174, "Avg policy loss": 0.3623360793571919, "Total num played games": 9292, "Total num trained steps": 17920, "Timestamp in ms": 1701804058019, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9423159707275075, "Avg loss": 0.678985508158803, "Avg value loss": 0.3149588516680524, "Avg policy loss": 0.3640266605652869, "Total num played games": 9292, "Total num trained steps": 18048, "Timestamp in ms": 1701804112987, "logtype": "training_step"}
{"Total num played games": 9292, "Total num trained steps": 18053, "Timestamp in ms": 1701804137009, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1640625}
{"Avg objective": 21.28125, "Games time in secs": 98.17225473560393, "Avg game time in secs": 2.821910030892468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 9344, "Total num trained steps": 18061, "Timestamp in ms": 1701804140929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9365011719582357, "Avg loss": 1.031537610804662, "Avg value loss": 0.6687638320727274, "Avg policy loss": 0.3627737909555435, "Total num played games": 9386, "Total num trained steps": 18176, "Timestamp in ms": 1701804191259, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 93.82403662241995, "Avg game time in secs": 3.6155393274093512, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.69}, "Total num played games": 9472, "Total num trained steps": 18273, "Timestamp in ms": 1701804234753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9299873471109237, "Avg loss": 1.0894106000196189, "Avg value loss": 0.7278360150521621, "Avg policy loss": 0.3615745874121785, "Total num played games": 9484, "Total num trained steps": 18304, "Timestamp in ms": 1701804247095, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9434837621256853, "Avg loss": 0.7569110337644815, "Avg value loss": 0.3900386242894456, "Avg policy loss": 0.36687241215258837, "Total num played games": 9484, "Total num trained steps": 18432, "Timestamp in ms": 1701804303209, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9353493222106362, "Avg loss": 1.0262772485148162, "Avg value loss": 0.6654471206711605, "Avg policy loss": 0.3608301298227161, "Total num played games": 9590, "Total num trained steps": 18560, "Timestamp in ms": 1701804360245, "logtype": "training_step"}
{"Total num played games": 9590, "Total num trained steps": 18655, "Timestamp in ms": 1701804424131, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.57421875}
{"Avg objective": 20.7265625, "Games time in secs": 191.37280896864831, "Avg game time in secs": 3.3689628038409865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.64, "agent_stopped_0": 0.49}, "Total num played games": 9600, "Total num trained steps": 18657, "Timestamp in ms": 1701804426126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9296778190830235, "Avg loss": 0.7853563430253416, "Avg value loss": 0.4340092702768743, "Avg policy loss": 0.35134707542601973, "Total num played games": 9684, "Total num trained steps": 18688, "Timestamp in ms": 1701804440596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.942998760842627, "Avg loss": 0.6521981321275234, "Avg value loss": 0.30032578960526735, "Avg policy loss": 0.35187234124168754, "Total num played games": 9684, "Total num trained steps": 18816, "Timestamp in ms": 1701804498084, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 93.83048724755645, "Avg game time in secs": 2.6655330136272823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 9728, "Total num trained steps": 18865, "Timestamp in ms": 1701804519957, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9370143149284254, "Avg loss": 1.0147847305051982, "Avg value loss": 0.6644072979106568, "Avg policy loss": 0.3503774395212531, "Total num played games": 9780, "Total num trained steps": 18944, "Timestamp in ms": 1701804555103, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 87.38058640062809, "Avg game time in secs": 3.1977676137757953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.69}, "Total num played games": 9856, "Total num trained steps": 19062, "Timestamp in ms": 1701804607338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9315373708729997, "Avg loss": 0.7006640965119004, "Avg value loss": 0.3620237512513995, "Avg policy loss": 0.3386403394397348, "Total num played games": 9874, "Total num trained steps": 19072, "Timestamp in ms": 1701804611459, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9441069258809234, "Avg loss": 0.8074493850581348, "Avg value loss": 0.45644273795187473, "Avg policy loss": 0.3510066482704133, "Total num played games": 9876, "Total num trained steps": 19200, "Timestamp in ms": 1701804668197, "logtype": "training_step"}
{"Total num played games": 9972, "Total num trained steps": 19255, "Timestamp in ms": 1701804722404, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.6328125}
{"Avg objective": 22.3359375, "Games time in secs": 117.26440554484725, "Avg game time in secs": 3.3723556245386135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 9984, "Total num trained steps": 19260, "Timestamp in ms": 1701804724602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9201271607391217, "Avg loss": 1.7690078211016953, "Avg value loss": 1.4125910316361114, "Avg policy loss": 0.3564168108860031, "Total num played games": 10066, "Total num trained steps": 19328, "Timestamp in ms": 1701804754760, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9328432346513014, "Avg loss": 0.7621886576525867, "Avg value loss": 0.40324164426419884, "Avg policy loss": 0.3589470100123435, "Total num played games": 10066, "Total num trained steps": 19456, "Timestamp in ms": 1701804811747, "logtype": "training_step"}
{"Ratio train steps to played games": 1.945559308563481, "Avg loss": 0.6016002499964088, "Avg value loss": 0.2619389803148806, "Avg policy loss": 0.33966126875020564, "Total num played games": 10066, "Total num trained steps": 19584, "Timestamp in ms": 1701804867581, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 163.78793686628342, "Avg game time in secs": 3.143326502526179, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.56}, "Total num played games": 10112, "Total num trained steps": 19629, "Timestamp in ms": 1701804888390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9396772288919504, "Avg loss": 0.8911552268546075, "Avg value loss": 0.5518789360066876, "Avg policy loss": 0.33927629701793194, "Total num played games": 10162, "Total num trained steps": 19712, "Timestamp in ms": 1701804924980, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 85.31952278502285, "Avg game time in secs": 3.259477675484959, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.58}, "Total num played games": 10240, "Total num trained steps": 19821, "Timestamp in ms": 1701804973710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9344773790951637, "Avg loss": 0.9151408639736474, "Avg value loss": 0.5747000033734366, "Avg policy loss": 0.34044085489585996, "Total num played games": 10256, "Total num trained steps": 19840, "Timestamp in ms": 1701804982351, "logtype": "training_step"}
{"Total num played games": 10256, "Total num trained steps": 19857, "Timestamp in ms": 1701805015337, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.7578125}
{"Ratio train steps to played games": 1.9292753623188406, "Avg loss": 1.106296246405691, "Avg value loss": 0.7472614287398756, "Avg policy loss": 0.3590348099824041, "Total num played games": 10350, "Total num trained steps": 19968, "Timestamp in ms": 1701805064202, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9416425120772947, "Avg loss": 0.59976129187271, "Avg value loss": 0.2668172207195312, "Avg policy loss": 0.33294407348148525, "Total num played games": 10350, "Total num trained steps": 20096, "Timestamp in ms": 1701805119129, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 187.31812477484345, "Avg game time in secs": 3.3025300336594228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.57, "agent_stopped_0": 0.55}, "Total num played games": 10368, "Total num trained steps": 20194, "Timestamp in ms": 1701805161028, "logtype": "played_game"}
{"Ratio train steps to played games": 1.936052077350182, "Avg loss": 0.8988424076233059, "Avg value loss": 0.5714565342059359, "Avg policy loss": 0.32738587353378534, "Total num played games": 10446, "Total num trained steps": 20224, "Timestamp in ms": 1701805172655, "logtype": "training_step"}
{"Ratio train steps to played games": 1.948305571510626, "Avg loss": 0.7719025381375104, "Avg value loss": 0.41795107547659427, "Avg policy loss": 0.3539514630101621, "Total num played games": 10446, "Total num trained steps": 20352, "Timestamp in ms": 1701805225310, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 80.16148837655783, "Avg game time in secs": 3.888135419692844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.8}, "Total num played games": 10496, "Total num trained steps": 20390, "Timestamp in ms": 1701805241190, "logtype": "played_game"}
{"Total num played games": 10542, "Total num trained steps": 20458, "Timestamp in ms": 1701805320585, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.359375}
{"Avg objective": 22.4765625, "Games time in secs": 85.92004271969199, "Avg game time in secs": 3.6182838287350023, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.75}, "Total num played games": 10624, "Total num trained steps": 20472, "Timestamp in ms": 1701805327110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.926260346124906, "Avg loss": 1.242014757823199, "Avg value loss": 0.8861253329087049, "Avg policy loss": 0.3558894316665828, "Total num played games": 10632, "Total num trained steps": 20480, "Timestamp in ms": 1701805330668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9375705152312899, "Avg loss": 0.9391337963752449, "Avg value loss": 0.563044770155102, "Avg policy loss": 0.3760890210978687, "Total num played games": 10636, "Total num trained steps": 20608, "Timestamp in ms": 1701805386230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9496051147047762, "Avg loss": 0.5802974330727011, "Avg value loss": 0.22388032160233706, "Avg policy loss": 0.3564171097241342, "Total num played games": 10636, "Total num trained steps": 20736, "Timestamp in ms": 1701805443780, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9437302030929755, "Avg loss": 0.9801658268552274, "Avg value loss": 0.6205610620090738, "Avg policy loss": 0.3596047693863511, "Total num played games": 10734, "Total num trained steps": 20864, "Timestamp in ms": 1701805500351, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 215.66766243614256, "Avg game time in secs": 3.567730406895862, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.65, "agent_stopped_0": 0.5}, "Total num played games": 10752, "Total num trained steps": 20963, "Timestamp in ms": 1701805542778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.938319482917821, "Avg loss": 0.8078079200349748, "Avg value loss": 0.4469329217681661, "Avg policy loss": 0.36087499640416354, "Total num played games": 10830, "Total num trained steps": 20992, "Timestamp in ms": 1701805555713, "logtype": "training_step"}
{"Total num played games": 10830, "Total num trained steps": 21060, "Timestamp in ms": 1701805650016, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9921875}
{"Avg objective": 20.359375, "Games time in secs": 111.20074823498726, "Avg game time in secs": 2.94363673630869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.57}, "Total num played games": 10880, "Total num trained steps": 21067, "Timestamp in ms": 1701805653978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9333577444159649, "Avg loss": 1.0696467109955847, "Avg value loss": 0.7086573163978755, "Avg policy loss": 0.3609893932007253, "Total num played games": 10924, "Total num trained steps": 21120, "Timestamp in ms": 1701805676429, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9449835225192238, "Avg loss": 0.683361831586808, "Avg value loss": 0.3323492616182193, "Avg policy loss": 0.35101257520727813, "Total num played games": 10924, "Total num trained steps": 21248, "Timestamp in ms": 1701805734054, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 124.74252720363438, "Avg game time in secs": 3.0738189433759544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 11008, "Total num trained steps": 21351, "Timestamp in ms": 1701805778721, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9396551724137931, "Avg loss": 0.8515956369228661, "Avg value loss": 0.5066304854117334, "Avg policy loss": 0.3449651449918747, "Total num played games": 11020, "Total num trained steps": 21376, "Timestamp in ms": 1701805789386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.951361161524501, "Avg loss": 0.7388295233249664, "Avg value loss": 0.3870979530038312, "Avg policy loss": 0.35173157206736505, "Total num played games": 11020, "Total num trained steps": 21504, "Timestamp in ms": 1701805844749, "logtype": "training_step"}
{"Ratio train steps to played games": 1.946023749550198, "Avg loss": 0.9020459251478314, "Avg value loss": 0.5416989452205598, "Avg policy loss": 0.36034697806462646, "Total num played games": 11116, "Total num trained steps": 21632, "Timestamp in ms": 1701805900499, "logtype": "training_step"}
{"Total num played games": 11116, "Total num trained steps": 21663, "Timestamp in ms": 1701805939590, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.85546875}
{"Avg objective": 20.4453125, "Games time in secs": 163.480944076553, "Avg game time in secs": 3.42153289700218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.67, "agent_stopped_0": 0.48}, "Total num played games": 11136, "Total num trained steps": 21668, "Timestamp in ms": 1701805942202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9411239964317573, "Avg loss": 0.9661549390293658, "Avg value loss": 0.5940845325822011, "Avg policy loss": 0.372070417040959, "Total num played games": 11210, "Total num trained steps": 21760, "Timestamp in ms": 1701805983233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9524531668153435, "Avg loss": 0.6003224595915526, "Avg value loss": 0.24079647881444544, "Avg policy loss": 0.359525979263708, "Total num played games": 11210, "Total num trained steps": 21888, "Timestamp in ms": 1701806040643, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 110.84933114238083, "Avg game time in secs": 3.1856447682221187, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 11264, "Total num trained steps": 21920, "Timestamp in ms": 1701806053052, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9472846276313462, "Avg loss": 1.2305072953458875, "Avg value loss": 0.8442791481502354, "Avg policy loss": 0.38622815744020045, "Total num played games": 11306, "Total num trained steps": 22016, "Timestamp in ms": 1701806094218, "logtype": "training_step"}
{"Avg objective": 22.4375, "Games time in secs": 83.02163467928767, "Avg game time in secs": 3.5933829068089835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.79}, "Total num played games": 11392, "Total num trained steps": 22114, "Timestamp in ms": 1701806136074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9420277144360638, "Avg loss": 1.0412609174381942, "Avg value loss": 0.6679871146334335, "Avg policy loss": 0.37327380664646626, "Total num played games": 11402, "Total num trained steps": 22144, "Timestamp in ms": 1701806149402, "logtype": "training_step"}
{"Total num played games": 11402, "Total num trained steps": 22264, "Timestamp in ms": 1701806322099, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.0703125}
{"Ratio train steps to played games": 1.9461726668996855, "Avg loss": 0.7790173168759793, "Avg value loss": 0.3920580926351249, "Avg policy loss": 0.38695922517217696, "Total num played games": 11444, "Total num trained steps": 22272, "Timestamp in ms": 1701806326142, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9484168406402227, "Avg loss": 1.2024892205372453, "Avg value loss": 0.8108593969373032, "Avg policy loss": 0.3916298288386315, "Total num played games": 11496, "Total num trained steps": 22400, "Timestamp in ms": 1701806383334, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 284.4217453375459, "Avg game time in secs": 3.3336277529015206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.66, "agent_stopped_0": 0.51}, "Total num played games": 11520, "Total num trained steps": 22486, "Timestamp in ms": 1701806420496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9433229813664596, "Avg loss": 0.9994999116752297, "Avg value loss": 0.6218597622355446, "Avg policy loss": 0.37764015002176166, "Total num played games": 11592, "Total num trained steps": 22528, "Timestamp in ms": 1701806438453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9544513457556936, "Avg loss": 0.698804834857583, "Avg value loss": 0.3127498127287254, "Avg policy loss": 0.38605502410791814, "Total num played games": 11592, "Total num trained steps": 22656, "Timestamp in ms": 1701806494909, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 84.8123476151377, "Avg game time in secs": 3.128116805499303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.61, "agent_stopped_0": 0.51}, "Total num played games": 11648, "Total num trained steps": 22681, "Timestamp in ms": 1701806505308, "logtype": "played_game"}
{"Ratio train steps to played games": 1.949349760438056, "Avg loss": 1.409575970377773, "Avg value loss": 1.0148761227028444, "Avg policy loss": 0.39469985221512616, "Total num played games": 11688, "Total num trained steps": 22784, "Timestamp in ms": 1701806548849, "logtype": "training_step"}
{"Total num played games": 11730, "Total num trained steps": 22865, "Timestamp in ms": 1701806665123, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9609375}
{"Avg objective": 20.890625, "Games time in secs": 163.5456929076463, "Avg game time in secs": 3.402491939938045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 11776, "Total num trained steps": 22873, "Timestamp in ms": 1701806668854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9377537212449256, "Avg loss": 1.0779866178054363, "Avg value loss": 0.6887582569615915, "Avg policy loss": 0.38922834978438914, "Total num played games": 11824, "Total num trained steps": 22912, "Timestamp in ms": 1701806685016, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9485791610284169, "Avg loss": 0.7063797765877098, "Avg value loss": 0.30900227033998817, "Avg policy loss": 0.3973775007762015, "Total num played games": 11824, "Total num trained steps": 23040, "Timestamp in ms": 1701806740800, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 120.73937780037522, "Avg game time in secs": 3.2422432319726795, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.69, "agent_stopped_0": 0.44}, "Total num played games": 11904, "Total num trained steps": 23150, "Timestamp in ms": 1701806789594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9442766028868748, "Avg loss": 0.9274365217424929, "Avg value loss": 0.5471165467752144, "Avg policy loss": 0.38031996763311327, "Total num played games": 11916, "Total num trained steps": 23168, "Timestamp in ms": 1701806797733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9543624161073825, "Avg loss": 0.7675439263693988, "Avg value loss": 0.37889215792529285, "Avg policy loss": 0.3886517642531544, "Total num played games": 11920, "Total num trained steps": 23296, "Timestamp in ms": 1701806855867, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9494007989347537, "Avg loss": 0.8872190876863897, "Avg value loss": 0.49235178157687187, "Avg policy loss": 0.3948673086706549, "Total num played games": 12016, "Total num trained steps": 23424, "Timestamp in ms": 1701806911174, "logtype": "training_step"}
{"Total num played games": 12016, "Total num trained steps": 23465, "Timestamp in ms": 1701807066167, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.06640625}
{"Avg objective": 20.9140625, "Games time in secs": 278.8401530198753, "Avg game time in secs": 3.6236411112040514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.74, "agent_stopped_0": 0.47}, "Total num played games": 12032, "Total num trained steps": 23469, "Timestamp in ms": 1701807068434, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9448389760528488, "Avg loss": 1.0763226198032498, "Avg value loss": 0.6764953306410462, "Avg policy loss": 0.39982729591429234, "Total num played games": 12110, "Total num trained steps": 23552, "Timestamp in ms": 1701807104966, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9554087530966144, "Avg loss": 0.6558143990114331, "Avg value loss": 0.2679014406166971, "Avg policy loss": 0.387912959093228, "Total num played games": 12110, "Total num trained steps": 23680, "Timestamp in ms": 1701807162393, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 109.33158944547176, "Avg game time in secs": 2.6390585909975925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 12160, "Total num trained steps": 23717, "Timestamp in ms": 1701807177766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9505161396034738, "Avg loss": 1.1586704580113292, "Avg value loss": 0.7610815276857466, "Avg policy loss": 0.3975889291614294, "Total num played games": 12206, "Total num trained steps": 23808, "Timestamp in ms": 1701807219208, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 88.47878420725465, "Avg game time in secs": 3.285008695005672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.75}, "Total num played games": 12288, "Total num trained steps": 23913, "Timestamp in ms": 1701807266245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9456998861973662, "Avg loss": 1.0266749041620642, "Avg value loss": 0.6334752311231568, "Avg policy loss": 0.3931996705941856, "Total num played games": 12302, "Total num trained steps": 23936, "Timestamp in ms": 1701807275716, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9561046984230206, "Avg loss": 0.8410438601858914, "Avg value loss": 0.4304916560649872, "Avg policy loss": 0.4105522045865655, "Total num played games": 12302, "Total num trained steps": 24064, "Timestamp in ms": 1701807331149, "logtype": "training_step"}
{"Total num played games": 12302, "Total num trained steps": 24066, "Timestamp in ms": 1701807380980, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.421875}
{"Ratio train steps to played games": 1.9515972894482092, "Avg loss": 1.0607837564311922, "Avg value loss": 0.6569216368952766, "Avg policy loss": 0.4038621191866696, "Total num played games": 12396, "Total num trained steps": 24192, "Timestamp in ms": 1701807436253, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 209.77248047105968, "Avg game time in secs": 3.0893819757038727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.6, "agent_stopped_0": 0.52}, "Total num played games": 12416, "Total num trained steps": 24285, "Timestamp in ms": 1701807476017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.946534336481511, "Avg loss": 0.9503835791256279, "Avg value loss": 0.5618317950284109, "Avg policy loss": 0.38855178095400333, "Total num played games": 12494, "Total num trained steps": 24320, "Timestamp in ms": 1701807492527, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9567792540419402, "Avg loss": 0.7044984193053097, "Avg value loss": 0.3244253786979243, "Avg policy loss": 0.38007304118946195, "Total num played games": 12494, "Total num trained steps": 24448, "Timestamp in ms": 1701807551648, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 91.04209009930491, "Avg game time in secs": 2.601566669793101, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 12544, "Total num trained steps": 24484, "Timestamp in ms": 1701807567060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9520254169976172, "Avg loss": 1.044620887376368, "Avg value loss": 0.6525667401729152, "Avg policy loss": 0.39205414336174726, "Total num played games": 12590, "Total num trained steps": 24576, "Timestamp in ms": 1701807607125, "logtype": "training_step"}
{"Total num played games": 12590, "Total num trained steps": 24668, "Timestamp in ms": 1701807734797, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.296875}
{"Avg objective": 22.640625, "Games time in secs": 173.95105240680277, "Avg game time in secs": 3.1416018355521373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 12672, "Total num trained steps": 24682, "Timestamp in ms": 1701807741011, "logtype": "played_game"}
{"Ratio train steps to played games": 1.947650583412173, "Avg loss": 1.1515828385017812, "Avg value loss": 0.7647503138286993, "Avg policy loss": 0.3868325154762715, "Total num played games": 12684, "Total num trained steps": 24704, "Timestamp in ms": 1701807750640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9577420372122358, "Avg loss": 0.8355163047090173, "Avg value loss": 0.43560880061704665, "Avg policy loss": 0.39990750374272466, "Total num played games": 12684, "Total num trained steps": 24832, "Timestamp in ms": 1701807809264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9530516431924883, "Avg loss": 1.4856349513866007, "Avg value loss": 1.077381183509715, "Avg policy loss": 0.4082537505310029, "Total num played games": 12780, "Total num trained steps": 24960, "Timestamp in ms": 1701807865462, "logtype": "training_step"}
{"Avg objective": 22.078125, "Games time in secs": 166.31917891278863, "Avg game time in secs": 3.0357431042793905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 12800, "Total num trained steps": 25055, "Timestamp in ms": 1701807907330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.948733882243281, "Avg loss": 0.8481363072060049, "Avg value loss": 0.45461536129005253, "Avg policy loss": 0.393520942190662, "Total num played games": 12874, "Total num trained steps": 25088, "Timestamp in ms": 1701807922916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9586764020506446, "Avg loss": 0.7076285895891488, "Avg value loss": 0.31350771500729024, "Avg policy loss": 0.3941208734177053, "Total num played games": 12874, "Total num trained steps": 25216, "Timestamp in ms": 1701807980944, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 86.57714360207319, "Avg game time in secs": 3.13336167630041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.67, "agent_stopped_0": 0.44}, "Total num played games": 12928, "Total num trained steps": 25245, "Timestamp in ms": 1701807993907, "logtype": "played_game"}
{"Total num played games": 12972, "Total num trained steps": 25268, "Timestamp in ms": 1701808084549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.26953125}
{"Avg objective": 21.25, "Games time in secs": 96.47258830070496, "Avg game time in secs": 3.245836455418612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 13056, "Total num trained steps": 25279, "Timestamp in ms": 1701808090380, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9396908005510485, "Avg loss": 1.6692949370481074, "Avg value loss": 1.2595409696223214, "Avg policy loss": 0.40975396567955613, "Total num played games": 13066, "Total num trained steps": 25344, "Timestamp in ms": 1701808116960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9494106842185825, "Avg loss": 0.7442456500139087, "Avg value loss": 0.335459265159443, "Avg policy loss": 0.4087863841559738, "Total num played games": 13066, "Total num trained steps": 25472, "Timestamp in ms": 1701808174862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.959283636920251, "Avg loss": 0.6037660154979676, "Avg value loss": 0.2318482098635286, "Avg policy loss": 0.3719178030733019, "Total num played games": 13066, "Total num trained steps": 25600, "Timestamp in ms": 1701808232561, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9547181279440815, "Avg loss": 0.9874737721402198, "Avg value loss": 0.6047405902063474, "Avg policy loss": 0.3827331718057394, "Total num played games": 13162, "Total num trained steps": 25728, "Timestamp in ms": 1701808290507, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 239.6695145778358, "Avg game time in secs": 2.8685535244731, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 13184, "Total num trained steps": 25819, "Timestamp in ms": 1701808330050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9502187358575953, "Avg loss": 0.9962422573007643, "Avg value loss": 0.6109329604078084, "Avg policy loss": 0.38530930131673813, "Total num played games": 13258, "Total num trained steps": 25856, "Timestamp in ms": 1701808346418, "logtype": "training_step"}
{"Total num played games": 13258, "Total num trained steps": 25871, "Timestamp in ms": 1701808416029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.25390625}
{"Avg objective": 23.015625, "Games time in secs": 89.65991773456335, "Avg game time in secs": 2.9543504763569217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.61}, "Total num played games": 13312, "Total num trained steps": 25878, "Timestamp in ms": 1701808419710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9460005991611744, "Avg loss": 1.3662859741598368, "Avg value loss": 0.952828784706071, "Avg policy loss": 0.4134571871254593, "Total num played games": 13352, "Total num trained steps": 25984, "Timestamp in ms": 1701808465804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.955587177950869, "Avg loss": 0.6529267821460962, "Avg value loss": 0.2702384553849697, "Avg policy loss": 0.3826883265282959, "Total num played games": 13352, "Total num trained steps": 26112, "Timestamp in ms": 1701808520636, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 144.02952899597585, "Avg game time in secs": 3.3103760756057454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.69, "agent_stopped_0": 0.43}, "Total num played games": 13440, "Total num trained steps": 26206, "Timestamp in ms": 1701808563739, "logtype": "played_game"}
{"Ratio train steps to played games": 1.951435371114086, "Avg loss": 0.8038021237589419, "Avg value loss": 0.431461795931682, "Avg policy loss": 0.372340319911018, "Total num played games": 13446, "Total num trained steps": 26240, "Timestamp in ms": 1701808578730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9610293023947643, "Avg loss": 0.6887272929307073, "Avg value loss": 0.3013566934969276, "Avg policy loss": 0.38737059640698135, "Total num played games": 13446, "Total num trained steps": 26368, "Timestamp in ms": 1701808638001, "logtype": "training_step"}
{"Total num played games": 13542, "Total num trained steps": 26473, "Timestamp in ms": 1701808774567, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.77734375}
{"Avg objective": 21.6015625, "Games time in secs": 213.5056206882, "Avg game time in secs": 3.094440363056492, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.64, "agent_stopped_0": 0.51}, "Total num played games": 13568, "Total num trained steps": 26479, "Timestamp in ms": 1701808777245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9430918157817543, "Avg loss": 1.3440131321549416, "Avg value loss": 0.941046497086063, "Avg policy loss": 0.4029666199348867, "Total num played games": 13636, "Total num trained steps": 26496, "Timestamp in ms": 1701808784781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9524787327662072, "Avg loss": 0.9337635049596429, "Avg value loss": 0.5370612484402955, "Avg policy loss": 0.39670224650762975, "Total num played games": 13636, "Total num trained steps": 26624, "Timestamp in ms": 1701808841117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.96186564975066, "Avg loss": 0.5992343784309924, "Avg value loss": 0.22074954537674785, "Avg policy loss": 0.3784848293289542, "Total num played games": 13636, "Total num trained steps": 26752, "Timestamp in ms": 1701808898528, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 128.35076635330915, "Avg game time in secs": 2.6746104229678167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.52}, "Total num played games": 13696, "Total num trained steps": 26770, "Timestamp in ms": 1701808905596, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9571865443425076, "Avg loss": 1.003351740539074, "Avg value loss": 0.6294649165356532, "Avg policy loss": 0.3738868241198361, "Total num played games": 13734, "Total num trained steps": 26880, "Timestamp in ms": 1701808952701, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 86.31318875961006, "Avg game time in secs": 3.192944841692224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.74}, "Total num played games": 13824, "Total num trained steps": 26971, "Timestamp in ms": 1701808991909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9531385594446051, "Avg loss": 1.0259890211746097, "Avg value loss": 0.6606011320836842, "Avg policy loss": 0.36538787721656263, "Total num played games": 13828, "Total num trained steps": 27008, "Timestamp in ms": 1701809007927, "logtype": "training_step"}
{"Total num played games": 13828, "Total num trained steps": 27075, "Timestamp in ms": 1701809133391, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.84375}
{"Ratio train steps to played games": 1.9491452377531964, "Avg loss": 1.1314295795746148, "Avg value loss": 0.7569233155809343, "Avg policy loss": 0.37450626329518855, "Total num played games": 13922, "Total num trained steps": 27136, "Timestamp in ms": 1701809160364, "logtype": "training_step"}
{"Ratio train steps to played games": 1.958339319063353, "Avg loss": 0.7059191358275712, "Avg value loss": 0.3309774426743388, "Avg policy loss": 0.37494169268757105, "Total num played games": 13922, "Total num trained steps": 27264, "Timestamp in ms": 1701809214599, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 255.4690579585731, "Avg game time in secs": 3.052694162237458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.68, "agent_stopped_0": 0.49}, "Total num played games": 13952, "Total num trained steps": 27338, "Timestamp in ms": 1701809247379, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9543378995433789, "Avg loss": 1.053252181969583, "Avg value loss": 0.6894665911095217, "Avg policy loss": 0.3637855944689363, "Total num played games": 14016, "Total num trained steps": 27392, "Timestamp in ms": 1701809272812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9634703196347032, "Avg loss": 0.69168924796395, "Avg value loss": 0.33118168194778264, "Avg policy loss": 0.3605075634550303, "Total num played games": 14016, "Total num trained steps": 27520, "Timestamp in ms": 1701809329755, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 86.59057096019387, "Avg game time in secs": 2.9695652176596923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.61}, "Total num played games": 14080, "Total num trained steps": 27529, "Timestamp in ms": 1701809333969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9591836734693877, "Avg loss": 1.0902626058086753, "Avg value loss": 0.7140887483255938, "Avg policy loss": 0.3761738499160856, "Total num played games": 14112, "Total num trained steps": 27648, "Timestamp in ms": 1701809384562, "logtype": "training_step"}
{"Total num played games": 14112, "Total num trained steps": 27678, "Timestamp in ms": 1701809479581, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.40625}
{"Ratio train steps to played games": 1.9552301844291144, "Avg loss": 0.9619512280914932, "Avg value loss": 0.5936484999256209, "Avg policy loss": 0.36830272735096514, "Total num played games": 14206, "Total num trained steps": 27776, "Timestamp in ms": 1701809521408, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 241.64557351730764, "Avg game time in secs": 3.475623857957544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.7, "agent_stopped_0": 0.44}, "Total num played games": 14208, "Total num trained steps": 27903, "Timestamp in ms": 1701809575615, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9628587507034327, "Avg loss": 0.5851170106325299, "Avg value loss": 0.2346139979781583, "Avg policy loss": 0.3505030150990933, "Total num played games": 14216, "Total num trained steps": 27904, "Timestamp in ms": 1701809575966, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9602097902097901, "Avg loss": 1.0774689223617315, "Avg value loss": 0.7168358236085624, "Avg policy loss": 0.3606331048067659, "Total num played games": 14300, "Total num trained steps": 28032, "Timestamp in ms": 1701809631664, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 82.97021236270666, "Avg game time in secs": 2.4527217950235354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.41}, "Total num played games": 14336, "Total num trained steps": 28096, "Timestamp in ms": 1701809658585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.956098916365657, "Avg loss": 1.0360731570981443, "Avg value loss": 0.6729663220467046, "Avg policy loss": 0.36310683214105666, "Total num played games": 14396, "Total num trained steps": 28160, "Timestamp in ms": 1701809687991, "logtype": "training_step"}
{"Total num played games": 14396, "Total num trained steps": 28278, "Timestamp in ms": 1701809867504, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.953125}
{"Avg objective": 21.5703125, "Games time in secs": 213.39718260243535, "Avg game time in secs": 2.9173152622097405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 14464, "Total num trained steps": 28287, "Timestamp in ms": 1701809871983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9554126918291166, "Avg loss": 0.6971757232677191, "Avg value loss": 0.34292540641035885, "Avg policy loss": 0.35425031720660627, "Total num played games": 14464, "Total num trained steps": 28288, "Timestamp in ms": 1701809872387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9610766045548653, "Avg loss": 0.9297363038640469, "Avg value loss": 0.5689130498794839, "Avg policy loss": 0.36082325922325253, "Total num played games": 14490, "Total num trained steps": 28416, "Timestamp in ms": 1701809928891, "logtype": "training_step"}
{"Ratio train steps to played games": 1.956945015768545, "Avg loss": 0.8548494691494852, "Avg value loss": 0.49765744048636407, "Avg policy loss": 0.35719202691689134, "Total num played games": 14586, "Total num trained steps": 28544, "Timestamp in ms": 1701809984711, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 163.62470808811486, "Avg game time in secs": 3.449614469631342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.75}, "Total num played games": 14592, "Total num trained steps": 28664, "Timestamp in ms": 1701810035607, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9560649474689589, "Avg loss": 0.6817533113062382, "Avg value loss": 0.32435167173389345, "Avg policy loss": 0.35740164504386485, "Total num played games": 14658, "Total num trained steps": 28672, "Timestamp in ms": 1701810038397, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9613184418414602, "Avg loss": 0.9925900807138532, "Avg value loss": 0.6254103929968551, "Avg policy loss": 0.36717968224547803, "Total num played games": 14684, "Total num trained steps": 28800, "Timestamp in ms": 1701810096334, "logtype": "training_step"}
{"Avg objective": 22.5, "Games time in secs": 89.4504167959094, "Avg game time in secs": 2.7321756790333893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.58}, "Total num played games": 14720, "Total num trained steps": 28864, "Timestamp in ms": 1701810125058, "logtype": "played_game"}
{"Total num played games": 14784, "Total num trained steps": 28880, "Timestamp in ms": 1701810226131, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.4296875}
{"Avg objective": 21.4609375, "Games time in secs": 104.95415905304253, "Avg game time in secs": 3.0976275551802246, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.7}, "Total num played games": 14848, "Total num trained steps": 28888, "Timestamp in ms": 1701810230012, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9443473585159297, "Avg loss": 1.5472572895232588, "Avg value loss": 1.170352840097621, "Avg policy loss": 0.376904453150928, "Total num played games": 14878, "Total num trained steps": 28928, "Timestamp in ms": 1701810247165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9529506654120177, "Avg loss": 0.8454677970148623, "Avg value loss": 0.4715367635944858, "Avg policy loss": 0.3739310335367918, "Total num played games": 14878, "Total num trained steps": 29056, "Timestamp in ms": 1701810305669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.961553972308106, "Avg loss": 0.6009226622991264, "Avg value loss": 0.24961520940996706, "Avg policy loss": 0.3513074555667117, "Total num played games": 14878, "Total num trained steps": 29184, "Timestamp in ms": 1701810362638, "logtype": "training_step"}
{"Ratio train steps to played games": 1.957526379057032, "Avg loss": 1.0178418145515025, "Avg value loss": 0.6665712997782975, "Avg policy loss": 0.3512705152388662, "Total num played games": 14974, "Total num trained steps": 29312, "Timestamp in ms": 1701810417719, "logtype": "training_step"}
{"Avg objective": 22.40625, "Games time in secs": 243.59749720431864, "Avg game time in secs": 3.0487495931156445, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 14976, "Total num trained steps": 29439, "Timestamp in ms": 1701810473610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9652202937249665, "Avg loss": 0.6044929504860193, "Avg value loss": 0.2684994572773576, "Avg policy loss": 0.33599349192809314, "Total num played games": 14976, "Total num trained steps": 29440, "Timestamp in ms": 1701810474006, "logtype": "training_step"}
{"Total num played games": 15068, "Total num trained steps": 29482, "Timestamp in ms": 1701810568684, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.08984375}
{"Avg objective": 21.3671875, "Games time in secs": 98.1389630138874, "Avg game time in secs": 2.7307352860079845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.55}, "Total num played games": 15104, "Total num trained steps": 29488, "Timestamp in ms": 1701810571749, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9501385041551247, "Avg loss": 1.371017990168184, "Avg value loss": 1.0081569387111813, "Avg policy loss": 0.36286104563623667, "Total num played games": 15162, "Total num trained steps": 29568, "Timestamp in ms": 1701810608263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9585806621817703, "Avg loss": 0.6374476761557162, "Avg value loss": 0.29052838461939245, "Avg policy loss": 0.34691929281689227, "Total num played games": 15162, "Total num trained steps": 29696, "Timestamp in ms": 1701810668613, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 154.0041743759066, "Avg game time in secs": 3.005872639536392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.72}, "Total num played games": 15232, "Total num trained steps": 29823, "Timestamp in ms": 1701810725754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957469152008401, "Avg loss": 0.5836392748169601, "Avg value loss": 0.247514832415618, "Avg policy loss": 0.3361244424013421, "Total num played games": 15232, "Total num trained steps": 29824, "Timestamp in ms": 1701810725926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962778505897772, "Avg loss": 0.8198017168324441, "Avg value loss": 0.4723155255196616, "Avg policy loss": 0.3474861851427704, "Total num played games": 15260, "Total num trained steps": 29952, "Timestamp in ms": 1701810783247, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9587783276895026, "Avg loss": 1.0046262454707175, "Avg value loss": 0.6470659085316584, "Avg policy loss": 0.3575603417120874, "Total num played games": 15356, "Total num trained steps": 30080, "Timestamp in ms": 1701810839573, "logtype": "training_step"}
{"Total num played games": 15356, "Total num trained steps": 30081, "Timestamp in ms": 1701810917978, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.69921875}
{"Avg objective": 20.390625, "Games time in secs": 193.9835532475263, "Avg game time in secs": 3.5571184767468367, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.79, "agent_stopped_0": 0.34}, "Total num played games": 15360, "Total num trained steps": 30084, "Timestamp in ms": 1701810919737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955210355987055, "Avg loss": 1.1101749436929822, "Avg value loss": 0.7306506121531129, "Avg policy loss": 0.37952433817554265, "Total num played games": 15450, "Total num trained steps": 30208, "Timestamp in ms": 1701810974421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9634951456310679, "Avg loss": 0.5895845263730735, "Avg value loss": 0.23410130699630827, "Avg policy loss": 0.3554832171648741, "Total num played games": 15450, "Total num trained steps": 30336, "Timestamp in ms": 1701811031566, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 139.08318793959916, "Avg game time in secs": 2.835781411791686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.6}, "Total num played games": 15488, "Total num trained steps": 30395, "Timestamp in ms": 1701811058821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9593516851041934, "Avg loss": 0.9300051049795002, "Avg value loss": 0.574779539136216, "Avg policy loss": 0.3552255660761148, "Total num played games": 15548, "Total num trained steps": 30464, "Timestamp in ms": 1701811089685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9622835150737652, "Avg loss": 0.6175726659130305, "Avg value loss": 0.27301532216370106, "Avg policy loss": 0.34455734537914395, "Total num played games": 15588, "Total num trained steps": 30592, "Timestamp in ms": 1701811148471, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 90.77469768375158, "Avg game time in secs": 2.8334704736917047, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.64}, "Total num played games": 15616, "Total num trained steps": 30594, "Timestamp in ms": 1701811149595, "logtype": "played_game"}
{"Total num played games": 15644, "Total num trained steps": 30684, "Timestamp in ms": 1701811298759, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.32421875}
{"Ratio train steps to played games": 1.9519634006862372, "Avg loss": 1.2229096328373998, "Avg value loss": 0.8657195093110204, "Avg policy loss": 0.3571901232935488, "Total num played games": 15738, "Total num trained steps": 30720, "Timestamp in ms": 1701811315163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9600965815224298, "Avg loss": 0.7038007648661733, "Avg value loss": 0.3423736426047981, "Avg policy loss": 0.36142712575383484, "Total num played games": 15738, "Total num trained steps": 30848, "Timestamp in ms": 1701811375301, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 280.6861981693655, "Avg game time in secs": 3.502681749101612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.8}, "Total num played games": 15744, "Total num trained steps": 30969, "Timestamp in ms": 1701811430282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9600101240192356, "Avg loss": 0.606554874451831, "Avg value loss": 0.26353677071165293, "Avg policy loss": 0.34301810420583934, "Total num played games": 15804, "Total num trained steps": 30976, "Timestamp in ms": 1701811433330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9643172919034988, "Avg loss": 1.0321132224053144, "Avg value loss": 0.6556121738394722, "Avg policy loss": 0.3765010512433946, "Total num played games": 15834, "Total num trained steps": 31104, "Timestamp in ms": 1701811492158, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 90.11399174295366, "Avg game time in secs": 3.024399233618169, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.62}, "Total num played games": 15872, "Total num trained steps": 31163, "Timestamp in ms": 1701811520396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9605775266792216, "Avg loss": 1.0016914773732424, "Avg value loss": 0.6430147880455479, "Avg policy loss": 0.3586766782682389, "Total num played games": 15930, "Total num trained steps": 31232, "Timestamp in ms": 1701811551079, "logtype": "training_step"}
{"Total num played games": 15930, "Total num trained steps": 31287, "Timestamp in ms": 1701811656023, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9375}
{"Avg objective": 22.328125, "Games time in secs": 141.569638364017, "Avg game time in secs": 3.714629536974826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.88, "agent_stopped_0": 0.31}, "Total num played games": 16000, "Total num trained steps": 31300, "Timestamp in ms": 1701811661966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9570644033949076, "Avg loss": 1.2010430849622935, "Avg value loss": 0.81579786085058, "Avg policy loss": 0.38524522189982235, "Total num played games": 16024, "Total num trained steps": 31360, "Timestamp in ms": 1701811688152, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965052421367948, "Avg loss": 0.6472759447060525, "Avg value loss": 0.2780121125979349, "Avg policy loss": 0.3692638340871781, "Total num played games": 16024, "Total num trained steps": 31488, "Timestamp in ms": 1701811745320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9608037707764823, "Avg loss": 0.9300995408557355, "Avg value loss": 0.5533834703965113, "Avg policy loss": 0.37671606754884124, "Total num played games": 16124, "Total num trained steps": 31616, "Timestamp in ms": 1701811801320, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 197.2998119108379, "Avg game time in secs": 3.756820943162893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.85, "agent_stopped_0": 0.41}, "Total num played games": 16128, "Total num trained steps": 31740, "Timestamp in ms": 1701811859266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9655727554179567, "Avg loss": 0.6180048442911357, "Avg value loss": 0.24644429702311754, "Avg policy loss": 0.3715605429606512, "Total num played games": 16148, "Total num trained steps": 31744, "Timestamp in ms": 1701811860582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9649815043156598, "Avg loss": 1.2859828723594546, "Avg value loss": 0.8972309695091099, "Avg policy loss": 0.38875190378166735, "Total num played games": 16220, "Total num trained steps": 31872, "Timestamp in ms": 1701811921452, "logtype": "training_step"}
{"Total num played games": 16220, "Total num trained steps": 31886, "Timestamp in ms": 1701812002932, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.34765625}
{"Avg objective": 22.90625, "Games time in secs": 147.1007054876536, "Avg game time in secs": 3.313360167958308, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.67}, "Total num played games": 16256, "Total num trained steps": 31893, "Timestamp in ms": 1701812006366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9614441583915656, "Avg loss": 1.0933845890685916, "Avg value loss": 0.7070338212652132, "Avg policy loss": 0.386350768385455, "Total num played games": 16314, "Total num trained steps": 32000, "Timestamp in ms": 1701812056139, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9642333088774762, "Avg loss": 0.7110738903284073, "Avg value loss": 0.346359881805256, "Avg policy loss": 0.3647140092216432, "Total num played games": 16356, "Total num trained steps": 32128, "Timestamp in ms": 1701812111949, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 106.84124139882624, "Avg game time in secs": 3.478056980195106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.7}, "Total num played games": 16384, "Total num trained steps": 32130, "Timestamp in ms": 1701812113208, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9656307129798902, "Avg loss": 1.0061841690912843, "Avg value loss": 0.6192039846209809, "Avg policy loss": 0.38698019506409764, "Total num played games": 16410, "Total num trained steps": 32256, "Timestamp in ms": 1701812169014, "logtype": "training_step"}
{"Ratio train steps to played games": 1.961715531863339, "Avg loss": 0.9927705181762576, "Avg value loss": 0.6129179722629488, "Avg policy loss": 0.37985254381783307, "Total num played games": 16508, "Total num trained steps": 32384, "Timestamp in ms": 1701812228057, "logtype": "training_step"}
{"Total num played games": 16508, "Total num trained steps": 32489, "Timestamp in ms": 1701812358211, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.63671875}
{"Avg objective": 21.265625, "Games time in secs": 247.0659511629492, "Avg game time in secs": 4.232737160244142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.93, "agent_stopped_0": 0.28}, "Total num played games": 16512, "Total num trained steps": 32491, "Timestamp in ms": 1701812360274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9585542168674699, "Avg loss": 0.8419653107412159, "Avg value loss": 0.4604409587336704, "Avg policy loss": 0.38152434560470283, "Total num played games": 16600, "Total num trained steps": 32512, "Timestamp in ms": 1701812368595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9660281893747742, "Avg loss": 0.8908209460787475, "Avg value loss": 0.4779435690725222, "Avg policy loss": 0.4128773754928261, "Total num played games": 16602, "Total num trained steps": 32640, "Timestamp in ms": 1701812425711, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 93.30839074589312, "Avg game time in secs": 3.2271076341712615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.69}, "Total num played games": 16640, "Total num trained steps": 32699, "Timestamp in ms": 1701812453582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9621556886227545, "Avg loss": 1.0695550898090005, "Avg value loss": 0.6603382790926844, "Avg policy loss": 0.40921680559404194, "Total num played games": 16700, "Total num trained steps": 32768, "Timestamp in ms": 1701812484542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9674641148325358, "Avg loss": 0.7010536561720073, "Avg value loss": 0.30652478779666126, "Avg policy loss": 0.3945288697723299, "Total num played games": 16720, "Total num trained steps": 32896, "Timestamp in ms": 1701812541062, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 90.32294747047126, "Avg game time in secs": 3.9107452862517675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.84, "agent_stopped_0": 0.34}, "Total num played games": 16768, "Total num trained steps": 32903, "Timestamp in ms": 1701812543905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966122886401524, "Avg loss": 1.0099758878350258, "Avg value loss": 0.6060050397645682, "Avg policy loss": 0.403970840619877, "Total num played games": 16796, "Total num trained steps": 33024, "Timestamp in ms": 1701812598732, "logtype": "training_step"}
{"Total num played games": 16892, "Total num trained steps": 33089, "Timestamp in ms": 1701812716811, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.69140625}
{"Avg objective": 22.4140625, "Games time in secs": 175.22920252755284, "Avg game time in secs": 3.7751627515244763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.66, "agent_stopped_0": 0.49}, "Total num played games": 16896, "Total num trained steps": 33094, "Timestamp in ms": 1701812719135, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9517249499587896, "Avg loss": 1.6047051288187504, "Avg value loss": 1.189541066181846, "Avg policy loss": 0.4151640455238521, "Total num played games": 16986, "Total num trained steps": 33152, "Timestamp in ms": 1701812743789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9592016955139526, "Avg loss": 0.7436882997862995, "Avg value loss": 0.336283358046785, "Avg policy loss": 0.4074049396440387, "Total num played games": 16986, "Total num trained steps": 33280, "Timestamp in ms": 1701812800351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9667961850936064, "Avg loss": 0.6172985113225877, "Avg value loss": 0.2527205554069951, "Avg policy loss": 0.36457795929163694, "Total num played games": 16986, "Total num trained steps": 33408, "Timestamp in ms": 1701812859985, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 168.07254677265882, "Avg game time in secs": 3.7296604675939307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.6}, "Total num played games": 17024, "Total num trained steps": 33469, "Timestamp in ms": 1701812887207, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9631776138625454, "Avg loss": 0.9085780729074031, "Avg value loss": 0.5394933852367103, "Avg policy loss": 0.3690846813842654, "Total num played games": 17082, "Total num trained steps": 33536, "Timestamp in ms": 1701812916647, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 86.89768109098077, "Avg game time in secs": 3.4416186402522726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.65}, "Total num played games": 17152, "Total num trained steps": 33663, "Timestamp in ms": 1701812974105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9622289577990208, "Avg loss": 0.6949381271842867, "Avg value loss": 0.3246683169854805, "Avg policy loss": 0.370269809383899, "Total num played games": 17156, "Total num trained steps": 33664, "Timestamp in ms": 1701812974196, "logtype": "training_step"}
{"Total num played games": 17180, "Total num trained steps": 33689, "Timestamp in ms": 1701813117966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.421875}
{"Ratio train steps to played games": 1.9561769132800741, "Avg loss": 1.4429925647564232, "Avg value loss": 1.0376931524369866, "Avg policy loss": 0.4052994125522673, "Total num played games": 17274, "Total num trained steps": 33792, "Timestamp in ms": 1701813162499, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9636447840685423, "Avg loss": 0.6573856868781149, "Avg value loss": 0.26196914073079824, "Avg policy loss": 0.3954165428876877, "Total num played games": 17274, "Total num trained steps": 33920, "Timestamp in ms": 1701813219607, "logtype": "training_step"}
{"Avg objective": 22.7578125, "Games time in secs": 297.30565369315445, "Avg game time in secs": 3.7696943561313674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.76, "agent_stopped_0": 0.42}, "Total num played games": 17280, "Total num trained steps": 34041, "Timestamp in ms": 1701813271411, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9651390973104006, "Avg loss": 0.5866391866002232, "Avg value loss": 0.21941857039928436, "Avg policy loss": 0.3672206178307533, "Total num played games": 17324, "Total num trained steps": 34048, "Timestamp in ms": 1701813274092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9675302245250432, "Avg loss": 1.0535115492530167, "Avg value loss": 0.675805696984753, "Avg policy loss": 0.37770584551617503, "Total num played games": 17370, "Total num trained steps": 34176, "Timestamp in ms": 1701813330741, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 86.09881851635873, "Avg game time in secs": 3.5736988124263007, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.68}, "Total num played games": 17408, "Total num trained steps": 34239, "Timestamp in ms": 1701813357510, "logtype": "played_game"}
{"Total num played games": 17466, "Total num trained steps": 34290, "Timestamp in ms": 1701813463619, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.94921875}
{"Avg objective": 22.7421875, "Games time in secs": 111.41931962408125, "Avg game time in secs": 4.02509069442749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.83}, "Total num played games": 17536, "Total num trained steps": 34302, "Timestamp in ms": 1701813468929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.95531235750114, "Avg loss": 1.0359210802707821, "Avg value loss": 0.662439031410031, "Avg policy loss": 0.37348205759190023, "Total num played games": 17544, "Total num trained steps": 34304, "Timestamp in ms": 1701813469635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9608200455580866, "Avg loss": 0.999680467415601, "Avg value loss": 0.6202674021478742, "Avg policy loss": 0.3794130745809525, "Total num played games": 17560, "Total num trained steps": 34432, "Timestamp in ms": 1701813525292, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968109339407745, "Avg loss": 0.6358956953044981, "Avg value loss": 0.2677940516732633, "Avg policy loss": 0.36810164363123477, "Total num played games": 17560, "Total num trained steps": 34560, "Timestamp in ms": 1701813581479, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 144.40303956530988, "Avg game time in secs": 4.071186152315931, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.78, "agent_stopped_0": 0.38}, "Total num played games": 17664, "Total num trained steps": 34632, "Timestamp in ms": 1701813613332, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9633235227529997, "Avg loss": 1.0338658958207816, "Avg value loss": 0.674820257932879, "Avg policy loss": 0.3590456396341324, "Total num played games": 17668, "Total num trained steps": 34688, "Timestamp in ms": 1701813638406, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705682589993208, "Avg loss": 0.6660415874794126, "Avg value loss": 0.30685885599814355, "Avg policy loss": 0.3591827342752367, "Total num played games": 17668, "Total num trained steps": 34816, "Timestamp in ms": 1701813696946, "logtype": "training_step"}
{"Total num played games": 17766, "Total num trained steps": 34891, "Timestamp in ms": 1701813838082, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.234375}
{"Avg objective": 23.2734375, "Games time in secs": 228.34484084136784, "Avg game time in secs": 4.041516959056025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.88, "agent_stopped_0": 0.35}, "Total num played games": 17792, "Total num trained steps": 34898, "Timestamp in ms": 1701813841677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9565509518477044, "Avg loss": 1.5073048016056418, "Avg value loss": 1.1250802513677627, "Avg policy loss": 0.3822245479095727, "Total num played games": 17860, "Total num trained steps": 34944, "Timestamp in ms": 1701813860627, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9637178051511759, "Avg loss": 0.781641460955143, "Avg value loss": 0.39243268233258277, "Avg policy loss": 0.38920877152122557, "Total num played games": 17860, "Total num trained steps": 35072, "Timestamp in ms": 1701813916123, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9708846584546473, "Avg loss": 0.5851778800133616, "Avg value loss": 0.22097658342681825, "Avg policy loss": 0.36420129449106753, "Total num played games": 17860, "Total num trained steps": 35200, "Timestamp in ms": 1701813971674, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 139.27011720463634, "Avg game time in secs": 4.24795517178427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.8, "agent_stopped_0": 0.38}, "Total num played games": 17920, "Total num trained steps": 35222, "Timestamp in ms": 1701813980948, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9674203608821563, "Avg loss": 1.0314576339442283, "Avg value loss": 0.6564256842248142, "Avg policy loss": 0.375031951116398, "Total num played games": 17956, "Total num trained steps": 35328, "Timestamp in ms": 1701814026015, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 87.15173656865954, "Avg game time in secs": 4.535069993376965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0234375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.92, "agent_stopped_0": 0.33}, "Total num played games": 18048, "Total num trained steps": 35423, "Timestamp in ms": 1701814068099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964103700421006, "Avg loss": 0.9866630719043314, "Avg value loss": 0.6119926961837336, "Avg policy loss": 0.3746703867800534, "Total num played games": 18052, "Total num trained steps": 35456, "Timestamp in ms": 1701814081978, "logtype": "training_step"}
{"Total num played games": 18052, "Total num trained steps": 35494, "Timestamp in ms": 1701814170988, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.51953125}
{"Ratio train steps to played games": 1.9609831367794555, "Avg loss": 1.0876923990435898, "Avg value loss": 0.6929037716472521, "Avg policy loss": 0.39478862448595464, "Total num played games": 18146, "Total num trained steps": 35584, "Timestamp in ms": 1701814208693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9680370329549213, "Avg loss": 0.5973796467296779, "Avg value loss": 0.22616261790972203, "Avg policy loss": 0.37121702590957284, "Total num played games": 18146, "Total num trained steps": 35712, "Timestamp in ms": 1701814263485, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 229.40243209525943, "Avg game time in secs": 3.5148823917406844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.69, "agent_stopped_0": 0.48}, "Total num played games": 18176, "Total num trained steps": 35791, "Timestamp in ms": 1701814297502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9644814733611051, "Avg loss": 0.9861323817167431, "Avg value loss": 0.6249841733369976, "Avg policy loss": 0.36114820453803986, "Total num played games": 18244, "Total num trained steps": 35840, "Timestamp in ms": 1701814319298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9714426660819995, "Avg loss": 0.6418075726833194, "Avg value loss": 0.2829474554164335, "Avg policy loss": 0.3588601176161319, "Total num played games": 18244, "Total num trained steps": 35968, "Timestamp in ms": 1701814376727, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 89.24705356918275, "Avg game time in secs": 4.0451390506495954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.79, "agent_stopped_0": 0.35}, "Total num played games": 18304, "Total num trained steps": 35992, "Timestamp in ms": 1701814386749, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9681025081788441, "Avg loss": 0.9509805366396904, "Avg value loss": 0.5755207407055423, "Avg policy loss": 0.3754597988445312, "Total num played games": 18340, "Total num trained steps": 36096, "Timestamp in ms": 1701814432195, "logtype": "training_step"}
{"Total num played games": 18340, "Total num trained steps": 36098, "Timestamp in ms": 1701814513366, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.24609375}
{"Avg objective": 21.3359375, "Games time in secs": 137.67621803469956, "Avg game time in secs": 4.644332956246217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.88, "agent_stopped_0": 0.34}, "Total num played games": 18432, "Total num trained steps": 36120, "Timestamp in ms": 1701814524425, "logtype": "played_game"}
{"Ratio train steps to played games": 1.965064554627319, "Avg loss": 1.0411175764165819, "Avg value loss": 0.6486093602143228, "Avg policy loss": 0.3925082148052752, "Total num played games": 18434, "Total num trained steps": 36224, "Timestamp in ms": 1701814570190, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9720082456330694, "Avg loss": 0.5770229045301676, "Avg value loss": 0.21132364741060883, "Avg policy loss": 0.3656992600299418, "Total num played games": 18434, "Total num trained steps": 36352, "Timestamp in ms": 1701814627036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9686994063680519, "Avg loss": 1.1803625484462827, "Avg value loss": 0.7905550037976354, "Avg policy loss": 0.3898075430188328, "Total num played games": 18530, "Total num trained steps": 36480, "Timestamp in ms": 1701814682145, "logtype": "training_step"}
{"Avg objective": 22.40625, "Games time in secs": 192.2780296113342, "Avg game time in secs": 3.8313615827064496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 18560, "Total num trained steps": 36558, "Timestamp in ms": 1701814716704, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9653709867926554, "Avg loss": 1.2070932288188487, "Avg value loss": 0.8187830398092046, "Avg policy loss": 0.3883101879619062, "Total num played games": 18626, "Total num trained steps": 36608, "Timestamp in ms": 1701814737891, "logtype": "training_step"}
{"Total num played games": 18626, "Total num trained steps": 36702, "Timestamp in ms": 1701814867401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6015625}
{"Avg objective": 22.9453125, "Games time in secs": 156.36272513121367, "Avg game time in secs": 4.124671407815185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.74, "agent_stopped_0": 0.42}, "Total num played games": 18688, "Total num trained steps": 36715, "Timestamp in ms": 1701814873067, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9625494176728282, "Avg loss": 1.0294409836642444, "Avg value loss": 0.6331315592397004, "Avg policy loss": 0.3963094272185117, "Total num played games": 18718, "Total num trained steps": 36736, "Timestamp in ms": 1701814881838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.8855657367967069, "Avg value loss": 0.4711090916534886, "Avg policy loss": 0.41445663990452886, "Total num played games": 18720, "Total num trained steps": 36864, "Timestamp in ms": 1701814940103, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 109.62029611133039, "Avg game time in secs": 5.042826197881368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.97, "agent_stopped_0": 0.33}, "Total num played games": 18816, "Total num trained steps": 36957, "Timestamp in ms": 1701814982687, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9659332482993197, "Avg loss": 1.0293640608433634, "Avg value loss": 0.611222151434049, "Avg policy loss": 0.4181418907828629, "Total num played games": 18816, "Total num trained steps": 36992, "Timestamp in ms": 1701814996885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727891156462585, "Avg loss": 0.7132722870446742, "Avg value loss": 0.30570803792215884, "Avg policy loss": 0.40756424865685403, "Total num played games": 18816, "Total num trained steps": 37120, "Timestamp in ms": 1701815050983, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9695431472081217, "Avg loss": 1.1234448566101491, "Avg value loss": 0.7213230530032888, "Avg policy loss": 0.4021217976696789, "Total num played games": 18912, "Total num trained steps": 37248, "Timestamp in ms": 1701815104905, "logtype": "training_step"}
{"Total num played games": 18912, "Total num trained steps": 37303, "Timestamp in ms": 1701815221927, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.484375}
{"Avg objective": 22.4296875, "Games time in secs": 243.75077826343477, "Avg game time in secs": 3.736662106079166, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.67}, "Total num played games": 18944, "Total num trained steps": 37313, "Timestamp in ms": 1701815226438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966484268125855, "Avg loss": 1.0057257965672761, "Avg value loss": 0.5949797256616876, "Avg policy loss": 0.4107460808008909, "Total num played games": 19006, "Total num trained steps": 37376, "Timestamp in ms": 1701815255134, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973063973063973, "Avg loss": 0.6510528465732932, "Avg value loss": 0.24757831974420696, "Avg policy loss": 0.4034745267126709, "Total num played games": 19008, "Total num trained steps": 37504, "Timestamp in ms": 1701815314093, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 92.52213856205344, "Avg game time in secs": 4.685300745928544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9921875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.9, "agent_stopped_0": 0.35}, "Total num played games": 19072, "Total num trained steps": 37517, "Timestamp in ms": 1701815318960, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9698492462311559, "Avg loss": 1.1385772405192256, "Avg value loss": 0.7159751923754811, "Avg policy loss": 0.4226020372007042, "Total num played games": 19104, "Total num trained steps": 37632, "Timestamp in ms": 1701815371770, "logtype": "training_step"}
{"Avg objective": 19.9453125, "Games time in secs": 91.43027282692492, "Avg game time in secs": 4.8445721049647545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.8, "agent_stopped_0": 0.37}, "Total num played games": 19200, "Total num trained steps": 37722, "Timestamp in ms": 1701815410391, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9662049573005624, "Avg loss": 0.9080591858364642, "Avg value loss": 0.49218358390498906, "Avg policy loss": 0.4158756004180759, "Total num played games": 19204, "Total num trained steps": 37760, "Timestamp in ms": 1701815427200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9729223078525306, "Avg loss": 0.6541757010854781, "Avg value loss": 0.25082727055996656, "Avg policy loss": 0.4033484326209873, "Total num played games": 19204, "Total num trained steps": 37888, "Timestamp in ms": 1701815485270, "logtype": "training_step"}
{"Total num played games": 19302, "Total num trained steps": 37905, "Timestamp in ms": 1701815584311, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.515625}
{"Avg objective": 20.7578125, "Games time in secs": 176.9991176072508, "Avg game time in secs": 3.8984387385717127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.62, "agent_stopped_0": 0.53}, "Total num played games": 19328, "Total num trained steps": 37910, "Timestamp in ms": 1701815587390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.959940193854403, "Avg loss": 1.7188774985261261, "Avg value loss": 1.2877565271919593, "Avg policy loss": 0.4311209595762193, "Total num played games": 19396, "Total num trained steps": 38016, "Timestamp in ms": 1701815634316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9665910497009693, "Avg loss": 0.6601650468073785, "Avg value loss": 0.25878020329400897, "Avg policy loss": 0.40138484071940184, "Total num played games": 19396, "Total num trained steps": 38144, "Timestamp in ms": 1701815689958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9731903485254692, "Avg loss": 0.569419692736119, "Avg value loss": 0.18367015331750736, "Avg policy loss": 0.3857495386619121, "Total num played games": 19396, "Total num trained steps": 38272, "Timestamp in ms": 1701815745638, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 167.44782758690417, "Avg game time in secs": 3.8659082193335053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.76, "agent_stopped_0": 0.39}, "Total num played games": 19456, "Total num trained steps": 38293, "Timestamp in ms": 1701815754838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9700389903550175, "Avg loss": 1.1265128219965845, "Avg value loss": 0.7217706331284717, "Avg policy loss": 0.4047421831637621, "Total num played games": 19492, "Total num trained steps": 38400, "Timestamp in ms": 1701815805503, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 91.35057431086898, "Avg game time in secs": 4.521164648293052, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.86}, "Total num played games": 19584, "Total num trained steps": 38492, "Timestamp in ms": 1701815846189, "logtype": "played_game"}
{"Total num played games": 19588, "Total num trained steps": 38508, "Timestamp in ms": 1701815936649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.02734375}
{"Ratio train steps to played games": 1.959914538610235, "Avg loss": 0.9772012224420905, "Avg value loss": 0.5832022146787494, "Avg policy loss": 0.3939990047365427, "Total num played games": 19658, "Total num trained steps": 38528, "Timestamp in ms": 1701815945198, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9640280459302917, "Avg loss": 1.0560815292410553, "Avg value loss": 0.6417885659029707, "Avg policy loss": 0.41429296834394336, "Total num played games": 19682, "Total num trained steps": 38656, "Timestamp in ms": 1701816001371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9704806422111574, "Avg loss": 0.5888376880902797, "Avg value loss": 0.2150548022473231, "Avg policy loss": 0.37378288758918643, "Total num played games": 19682, "Total num trained steps": 38784, "Timestamp in ms": 1701816056895, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 242.50201929733157, "Avg game time in secs": 4.702174500867841, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.74}, "Total num played games": 19712, "Total num trained steps": 38862, "Timestamp in ms": 1701816088691, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9674385681059763, "Avg loss": 0.8414385551586747, "Avg value loss": 0.46745568636106327, "Avg policy loss": 0.3739828788675368, "Total num played games": 19778, "Total num trained steps": 38912, "Timestamp in ms": 1701816109120, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9738598442714126, "Avg loss": 0.6602773170452565, "Avg value loss": 0.27231480774935335, "Avg policy loss": 0.3879625075496733, "Total num played games": 19778, "Total num trained steps": 39040, "Timestamp in ms": 1701816165796, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 84.05728584714234, "Avg game time in secs": 3.931393832550384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.72, "agent_stopped_0": 0.42}, "Total num played games": 19840, "Total num trained steps": 39057, "Timestamp in ms": 1701816172748, "logtype": "played_game"}
{"Total num played games": 19876, "Total num trained steps": 39112, "Timestamp in ms": 1701816312556, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.5625}
{"Avg objective": 20.1875, "Games time in secs": 153.87386616878211, "Avg game time in secs": 5.129591294593411, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.93, "agent_stopped_0": 0.41}, "Total num played games": 19968, "Total num trained steps": 39146, "Timestamp in ms": 1701816326622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9613420130195294, "Avg loss": 1.4306343004573137, "Avg value loss": 1.0282556855818257, "Avg policy loss": 0.40237859869375825, "Total num played games": 19970, "Total num trained steps": 39168, "Timestamp in ms": 1701816337191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9677516274411617, "Avg loss": 0.6938002060633153, "Avg value loss": 0.3036993731511757, "Avg policy loss": 0.39010083209723234, "Total num played games": 19970, "Total num trained steps": 39296, "Timestamp in ms": 1701816394535, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9741612418627943, "Avg loss": 0.555169238243252, "Avg value loss": 0.18164004752179608, "Avg policy loss": 0.37352919089607894, "Total num played games": 19970, "Total num trained steps": 39424, "Timestamp in ms": 1701816450851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9708989435917879, "Avg loss": 0.9390586337540299, "Avg value loss": 0.5599586155731231, "Avg policy loss": 0.3791000177152455, "Total num played games": 20068, "Total num trained steps": 39552, "Timestamp in ms": 1701816505359, "logtype": "training_step"}
{"Avg objective": 20.5390625, "Games time in secs": 215.33859681524336, "Avg game time in secs": 4.107081988171558, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.55, "agent_stopped_0": 0.54}, "Total num played games": 20096, "Total num trained steps": 39634, "Timestamp in ms": 1701816541961, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9674732249107496, "Avg loss": 1.0317474545445293, "Avg value loss": 0.6730088427430019, "Avg policy loss": 0.3587386223953217, "Total num played games": 20168, "Total num trained steps": 39680, "Timestamp in ms": 1701816562101, "logtype": "training_step"}
{"Total num played games": 20168, "Total num trained steps": 39713, "Timestamp in ms": 1701816706450, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.80078125}
{"Avg objective": 22.2421875, "Games time in secs": 169.81371200457215, "Avg game time in secs": 3.9956259066239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.73, "agent_stopped_0": 0.4}, "Total num played games": 20224, "Total num trained steps": 39723, "Timestamp in ms": 1701816711776, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964662915802981, "Avg loss": 1.0471117598935962, "Avg value loss": 0.6537432621698827, "Avg policy loss": 0.3933684956282377, "Total num played games": 20262, "Total num trained steps": 39808, "Timestamp in ms": 1701816748832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9709308064356925, "Avg loss": 0.5872103883884847, "Avg value loss": 0.21352261723950505, "Avg policy loss": 0.3736877751071006, "Total num played games": 20262, "Total num trained steps": 39936, "Timestamp in ms": 1701816806510, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 137.75947065651417, "Avg game time in secs": 4.537308799073799, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.83}, "Total num played games": 20352, "Total num trained steps": 40033, "Timestamp in ms": 1701816849536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96792415757933, "Avg loss": 0.981974461581558, "Avg value loss": 0.6173676144098863, "Avg policy loss": 0.36460684542544186, "Total num played games": 20358, "Total num trained steps": 40064, "Timestamp in ms": 1701816864477, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742116121426467, "Avg loss": 0.6151416834909469, "Avg value loss": 0.2575670931255445, "Avg policy loss": 0.3575745904818177, "Total num played games": 20358, "Total num trained steps": 40192, "Timestamp in ms": 1701816921997, "logtype": "training_step"}
{"Total num played games": 20454, "Total num trained steps": 40316, "Timestamp in ms": 1701817059392, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.12109375}
{"Ratio train steps to played games": 1.9706256109481917, "Avg loss": 0.9748125742189586, "Avg value loss": 0.6190146484295838, "Avg policy loss": 0.35579792642965913, "Total num played games": 20458, "Total num trained steps": 40320, "Timestamp in ms": 1701817061834, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 214.08149091526866, "Avg game time in secs": 3.7278018300421536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.66}, "Total num played games": 20480, "Total num trained steps": 40324, "Timestamp in ms": 1701817063617, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684640840957757, "Avg loss": 1.1569788199849427, "Avg value loss": 0.7909619575366378, "Avg policy loss": 0.3660168620990589, "Total num played games": 20548, "Total num trained steps": 40448, "Timestamp in ms": 1701817117978, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9746934008175978, "Avg loss": 0.5693785974290222, "Avg value loss": 0.22118284343741834, "Avg policy loss": 0.3481957530602813, "Total num played games": 20548, "Total num trained steps": 40576, "Timestamp in ms": 1701817175702, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 121.17793710529804, "Avg game time in secs": 4.0798431035655085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.8}, "Total num played games": 20608, "Total num trained steps": 40597, "Timestamp in ms": 1701817184795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.971662468513854, "Avg loss": 1.0275152476970106, "Avg value loss": 0.6698629311285913, "Avg policy loss": 0.35765232518315315, "Total num played games": 20644, "Total num trained steps": 40704, "Timestamp in ms": 1701817231489, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 86.85779133625329, "Avg game time in secs": 4.907618020093651, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.95, "agent_stopped_0": 0.32}, "Total num played games": 20736, "Total num trained steps": 40798, "Timestamp in ms": 1701817271653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9685661941953525, "Avg loss": 0.8437053326051682, "Avg value loss": 0.4959720706101507, "Avg policy loss": 0.3477332575712353, "Total num played games": 20742, "Total num trained steps": 40832, "Timestamp in ms": 1701817286280, "logtype": "training_step"}
{"Total num played games": 20742, "Total num trained steps": 40917, "Timestamp in ms": 1701817422100, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.046875}
{"Ratio train steps to played games": 1.9660170874532015, "Avg loss": 0.8439749579411, "Avg value loss": 0.48545572720468044, "Avg policy loss": 0.3585192284081131, "Total num played games": 20834, "Total num trained steps": 40960, "Timestamp in ms": 1701817441839, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9719715876367825, "Avg loss": 0.622682029614225, "Avg value loss": 0.2772688090335578, "Avg policy loss": 0.34541322151198983, "Total num played games": 20836, "Total num trained steps": 41088, "Timestamp in ms": 1701817498257, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 264.1316904872656, "Avg game time in secs": 4.370772711990867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.76, "agent_stopped_0": 0.49}, "Total num played games": 20864, "Total num trained steps": 41170, "Timestamp in ms": 1701817535785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969042614179247, "Avg loss": 1.1851796922273934, "Avg value loss": 0.8455098769627512, "Avg policy loss": 0.3396698231808841, "Total num played games": 20932, "Total num trained steps": 41216, "Timestamp in ms": 1701817555099, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9751576533537167, "Avg loss": 0.7122949121985584, "Avg value loss": 0.3558336014393717, "Avg policy loss": 0.356461307965219, "Total num played games": 20932, "Total num trained steps": 41344, "Timestamp in ms": 1701817612578, "logtype": "training_step"}
{"Avg objective": 22.484375, "Games time in secs": 84.78614983893931, "Avg game time in secs": 3.719442433313816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.68}, "Total num played games": 20992, "Total num trained steps": 41364, "Timestamp in ms": 1701817620571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972039942938659, "Avg loss": 1.0287439338862896, "Avg value loss": 0.6697534780250862, "Avg policy loss": 0.35899045458063483, "Total num played games": 21030, "Total num trained steps": 41472, "Timestamp in ms": 1701817666900, "logtype": "training_step"}
{"Total num played games": 21030, "Total num trained steps": 41521, "Timestamp in ms": 1701817764091, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.90234375}
{"Avg objective": 20.71875, "Games time in secs": 153.70727173611522, "Avg game time in secs": 4.928207858494716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.92}, "Total num played games": 21120, "Total num trained steps": 41543, "Timestamp in ms": 1701817774279, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9693239916682446, "Avg loss": 0.866426435764879, "Avg value loss": 0.5055948054650798, "Avg policy loss": 0.36083162599243224, "Total num played games": 21124, "Total num trained steps": 41600, "Timestamp in ms": 1701817799071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975383450104147, "Avg loss": 0.6039691979531199, "Avg value loss": 0.24883564503397793, "Avg policy loss": 0.3551335495430976, "Total num played games": 21124, "Total num trained steps": 41728, "Timestamp in ms": 1701817858978, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9722929035906136, "Avg loss": 0.8682914322707802, "Avg value loss": 0.5192547023762017, "Avg policy loss": 0.3490367273334414, "Total num played games": 21222, "Total num trained steps": 41856, "Timestamp in ms": 1701817916238, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 180.46483245678246, "Avg game time in secs": 4.3069590168161085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.79, "agent_stopped_0": 0.41}, "Total num played games": 21248, "Total num trained steps": 41942, "Timestamp in ms": 1701817954745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684452363090772, "Avg loss": 0.9155433636624366, "Avg value loss": 0.5572432620683685, "Avg policy loss": 0.35830010497011244, "Total num played games": 21328, "Total num trained steps": 41984, "Timestamp in ms": 1701817973196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744467366841711, "Avg loss": 0.6463693601544946, "Avg value loss": 0.2880834329407662, "Avg policy loss": 0.35828592255711555, "Total num played games": 21328, "Total num trained steps": 42112, "Timestamp in ms": 1701818031023, "logtype": "training_step"}
{"Total num played games": 21328, "Total num trained steps": 42124, "Timestamp in ms": 1701818085362, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.6953125}
{"Avg objective": 20.5546875, "Games time in secs": 134.69810235500336, "Avg game time in secs": 3.875389069027733, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.69, "agent_stopped_0": 0.51}, "Total num played games": 21376, "Total num trained steps": 42132, "Timestamp in ms": 1701818089443, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9718046867706096, "Avg loss": 0.9814528259448707, "Avg value loss": 0.6232749148039147, "Avg policy loss": 0.35817790520377457, "Total num played games": 21422, "Total num trained steps": 42240, "Timestamp in ms": 1701818136204, "logtype": "training_step"}
{"Avg objective": 22.8203125, "Games time in secs": 97.22406756319106, "Avg game time in secs": 4.414972537182621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.75}, "Total num played games": 21504, "Total num trained steps": 42347, "Timestamp in ms": 1701818186667, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9689097499767636, "Avg loss": 0.9171901436056942, "Avg value loss": 0.5679788255365565, "Avg policy loss": 0.3492113242391497, "Total num played games": 21518, "Total num trained steps": 42368, "Timestamp in ms": 1701818195407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9749047309229482, "Avg loss": 0.738663641968742, "Avg value loss": 0.37779948685783893, "Avg policy loss": 0.3608641622122377, "Total num played games": 21518, "Total num trained steps": 42496, "Timestamp in ms": 1701818252326, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9720551494401777, "Avg loss": 0.9877778450027108, "Avg value loss": 0.6259187166579068, "Avg policy loss": 0.3618591157719493, "Total num played games": 21614, "Total num trained steps": 42624, "Timestamp in ms": 1701818310306, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 166.39764038659632, "Avg game time in secs": 3.958742519331281, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.79, "agent_stopped_0": 0.48}, "Total num played games": 21632, "Total num trained steps": 42723, "Timestamp in ms": 1701818353065, "logtype": "played_game"}
{"Total num played games": 21710, "Total num trained steps": 42725, "Timestamp in ms": 1701818442718, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.8671875}
{"Avg objective": 21.71875, "Games time in secs": 94.70649659261107, "Avg game time in secs": 3.6723952336324146, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 21760, "Total num trained steps": 42734, "Timestamp in ms": 1701818447772, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960921016420512, "Avg loss": 1.2302213630173355, "Avg value loss": 0.8633685993263498, "Avg policy loss": 0.3668527870904654, "Total num played games": 21802, "Total num trained steps": 42752, "Timestamp in ms": 1701818454819, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966565767749037, "Avg loss": 1.0081762648187578, "Avg value loss": 0.612778730224818, "Avg policy loss": 0.39539752365089953, "Total num played games": 21804, "Total num trained steps": 42880, "Timestamp in ms": 1701818513304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972482113373693, "Avg loss": 0.5473457919433713, "Avg value loss": 0.19633137166965753, "Avg policy loss": 0.35101441643200815, "Total num played games": 21804, "Total num trained steps": 43008, "Timestamp in ms": 1701818573033, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 171.09995941072702, "Avg game time in secs": 4.312856458578608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.77, "agent_stopped_0": 0.41}, "Total num played games": 21888, "Total num trained steps": 43114, "Timestamp in ms": 1701818618873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9696803652968036, "Avg loss": 0.916448641801253, "Avg value loss": 0.5514611435355619, "Avg policy loss": 0.36498750536702573, "Total num played games": 21900, "Total num trained steps": 43136, "Timestamp in ms": 1701818629097, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9754794520547945, "Avg loss": 0.7545521133579314, "Avg value loss": 0.38301244773902, "Avg policy loss": 0.3715396660845727, "Total num played games": 21900, "Total num trained steps": 43264, "Timestamp in ms": 1701818688972, "logtype": "training_step"}
{"Total num played games": 21996, "Total num trained steps": 43327, "Timestamp in ms": 1701818783414, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.04296875}
{"Avg objective": 21.4296875, "Games time in secs": 167.7017168365419, "Avg game time in secs": 4.288245253817877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.8, "agent_stopped_0": 0.44}, "Total num played games": 22016, "Total num trained steps": 43333, "Timestamp in ms": 1701818786575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964282480760525, "Avg loss": 1.41221390850842, "Avg value loss": 1.0248340378748253, "Avg policy loss": 0.38737986818887293, "Total num played games": 22090, "Total num trained steps": 43392, "Timestamp in ms": 1701818812617, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9701222272521504, "Avg loss": 0.6562135815620422, "Avg value loss": 0.2829362218035385, "Avg policy loss": 0.3732773601077497, "Total num played games": 22090, "Total num trained steps": 43520, "Timestamp in ms": 1701818868675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9759167043911272, "Avg loss": 0.5406362360808998, "Avg value loss": 0.1854738403344527, "Avg policy loss": 0.35516239632852376, "Total num played games": 22090, "Total num trained steps": 43648, "Timestamp in ms": 1701818924122, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 150.69696757942438, "Avg game time in secs": 4.209530893320334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.77, "agent_stopped_0": 0.44}, "Total num played games": 22144, "Total num trained steps": 43680, "Timestamp in ms": 1701818937272, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731362120256017, "Avg loss": 0.9468817845918238, "Avg value loss": 0.5777199809090234, "Avg policy loss": 0.3691618018783629, "Total num played games": 22186, "Total num trained steps": 43776, "Timestamp in ms": 1701818976885, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 84.58215753734112, "Avg game time in secs": 4.657362849902711, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.79}, "Total num played games": 22272, "Total num trained steps": 43882, "Timestamp in ms": 1701819021854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970556552962298, "Avg loss": 0.853606338147074, "Avg value loss": 0.47940912877675146, "Avg policy loss": 0.37419721437618136, "Total num played games": 22280, "Total num trained steps": 43904, "Timestamp in ms": 1701819031202, "logtype": "training_step"}
{"Total num played games": 22282, "Total num trained steps": 43928, "Timestamp in ms": 1701819129114, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.20703125}
{"Ratio train steps to played games": 1.9678226671433678, "Avg loss": 1.156579197384417, "Avg value loss": 0.7569697573781013, "Avg policy loss": 0.399609433952719, "Total num played games": 22376, "Total num trained steps": 44032, "Timestamp in ms": 1701819178145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9735430818734359, "Avg loss": 0.6012031398713589, "Avg value loss": 0.22045493905898184, "Avg policy loss": 0.38074819603934884, "Total num played games": 22376, "Total num trained steps": 44160, "Timestamp in ms": 1701819238066, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 254.5280720796436, "Avg game time in secs": 3.9899993028957397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.69}, "Total num played games": 22400, "Total num trained steps": 44249, "Timestamp in ms": 1701819276382, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708081167675329, "Avg loss": 0.9159046770073473, "Avg value loss": 0.5451580913504586, "Avg policy loss": 0.3707465874031186, "Total num played games": 22472, "Total num trained steps": 44288, "Timestamp in ms": 1701819293598, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976504093983624, "Avg loss": 0.6796246776357293, "Avg value loss": 0.3068153877975419, "Avg policy loss": 0.37280928646214306, "Total num played games": 22472, "Total num trained steps": 44416, "Timestamp in ms": 1701819353000, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 88.28575411438942, "Avg game time in secs": 3.868532119435258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.72}, "Total num played games": 22528, "Total num trained steps": 44443, "Timestamp in ms": 1701819364668, "logtype": "played_game"}
{"Total num played games": 22568, "Total num trained steps": 44531, "Timestamp in ms": 1701819489857, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.01171875}
{"Ratio train steps to played games": 1.9685345589535088, "Avg loss": 1.2049738366622478, "Avg value loss": 0.8245482763741165, "Avg policy loss": 0.38042556517757475, "Total num played games": 22628, "Total num trained steps": 44544, "Timestamp in ms": 1701819496268, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 134.44528605602682, "Avg game time in secs": 4.537097546824953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.8}, "Total num played games": 22656, "Total num trained steps": 44551, "Timestamp in ms": 1701819499113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9712293707528021, "Avg loss": 0.8192258912604302, "Avg value loss": 0.42672232759650797, "Avg policy loss": 0.39250355679541826, "Total num played games": 22662, "Total num trained steps": 44672, "Timestamp in ms": 1701819553281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9768775924455035, "Avg loss": 0.5467215818352997, "Avg value loss": 0.19207387731876224, "Avg policy loss": 0.3546477030031383, "Total num played games": 22662, "Total num trained steps": 44800, "Timestamp in ms": 1701819611314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973816009138037, "Avg loss": 1.0557215258013457, "Avg value loss": 0.6767356295604259, "Avg policy loss": 0.378985907882452, "Total num played games": 22762, "Total num trained steps": 44928, "Timestamp in ms": 1701819669613, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 211.55594024807215, "Avg game time in secs": 4.1266602360556135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.71, "agent_stopped_0": 0.51}, "Total num played games": 22784, "Total num trained steps": 45021, "Timestamp in ms": 1701819710669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9711260827718962, "Avg loss": 0.901647636666894, "Avg value loss": 0.5322975528542884, "Avg policy loss": 0.3693500719964504, "Total num played games": 22858, "Total num trained steps": 45056, "Timestamp in ms": 1701819727403, "logtype": "training_step"}
{"Total num played games": 22858, "Total num trained steps": 45134, "Timestamp in ms": 1701819842880, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.32421875}
{"Avg objective": 21.4453125, "Games time in secs": 138.29629679955542, "Avg game time in secs": 4.620551895466633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.9}, "Total num played games": 22912, "Total num trained steps": 45148, "Timestamp in ms": 1701819848966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9686301847333565, "Avg loss": 1.1932758272159845, "Avg value loss": 0.8145436346530914, "Avg policy loss": 0.378732189303264, "Total num played games": 22952, "Total num trained steps": 45184, "Timestamp in ms": 1701819864900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97420704078076, "Avg loss": 0.6953681830782443, "Avg value loss": 0.315200824290514, "Avg policy loss": 0.38016735622659326, "Total num played games": 22952, "Total num trained steps": 45312, "Timestamp in ms": 1701819919189, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 114.43786163628101, "Avg game time in secs": 4.818435658889939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.83}, "Total num played games": 23040, "Total num trained steps": 45412, "Timestamp in ms": 1701819963404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9715376605345367, "Avg loss": 0.8669344314839691, "Avg value loss": 0.5039550941437483, "Avg policy loss": 0.36297934665344656, "Total num played games": 23048, "Total num trained steps": 45440, "Timestamp in ms": 1701819976486, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97709128774731, "Avg loss": 0.6145449024625123, "Avg value loss": 0.25507423048838973, "Avg policy loss": 0.35947067313827574, "Total num played games": 23048, "Total num trained steps": 45568, "Timestamp in ms": 1701820033734, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9744210162461113, "Avg loss": 1.2752395456191152, "Avg value loss": 0.9152185195125639, "Avg policy loss": 0.36002102377824485, "Total num played games": 23144, "Total num trained steps": 45696, "Timestamp in ms": 1701820088676, "logtype": "training_step"}
{"Total num played games": 23144, "Total num trained steps": 45736, "Timestamp in ms": 1701820169137, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.53515625}
{"Avg objective": 22.7890625, "Games time in secs": 208.86620922014117, "Avg game time in secs": 4.05334181690705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.77}, "Total num played games": 23168, "Total num trained steps": 45742, "Timestamp in ms": 1701820172270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9719425079610982, "Avg loss": 0.8819218864664435, "Avg value loss": 0.5161531630437821, "Avg policy loss": 0.3657687285449356, "Total num played games": 23238, "Total num trained steps": 45824, "Timestamp in ms": 1701820208580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977450727257079, "Avg loss": 0.5248204197268933, "Avg value loss": 0.18407912366092205, "Avg policy loss": 0.34074129711370915, "Total num played games": 23238, "Total num trained steps": 45952, "Timestamp in ms": 1701820265167, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 103.3379041440785, "Avg game time in secs": 3.651431775651872, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.68}, "Total num played games": 23296, "Total num trained steps": 45976, "Timestamp in ms": 1701820275608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974800719979429, "Avg loss": 1.0405236789956689, "Avg value loss": 0.6804135730490088, "Avg policy loss": 0.3601101068779826, "Total num played games": 23334, "Total num trained steps": 46080, "Timestamp in ms": 1701820321888, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 90.87683311849833, "Avg game time in secs": 4.454965060096583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.83}, "Total num played games": 23424, "Total num trained steps": 46180, "Timestamp in ms": 1701820366485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9720040969614203, "Avg loss": 1.4871743069961667, "Avg value loss": 1.1367091314168647, "Avg policy loss": 0.3504651840776205, "Total num played games": 23432, "Total num trained steps": 46208, "Timestamp in ms": 1701820379967, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774667121884602, "Avg loss": 0.8271866806317121, "Avg value loss": 0.4536063955165446, "Avg policy loss": 0.37358028977178037, "Total num played games": 23432, "Total num trained steps": 46336, "Timestamp in ms": 1701820438493, "logtype": "training_step"}
{"Total num played games": 23432, "Total num trained steps": 46337, "Timestamp in ms": 1701820513425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.7734375}
{"Ratio train steps to played games": 1.9750063759245091, "Avg loss": 0.9504703269340098, "Avg value loss": 0.5755158154061064, "Avg policy loss": 0.37495451141148806, "Total num played games": 23526, "Total num trained steps": 46464, "Timestamp in ms": 1701820570756, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 244.1264952942729, "Avg game time in secs": 4.233467169498908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.84}, "Total num played games": 23552, "Total num trained steps": 46549, "Timestamp in ms": 1701820610612, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972231628852015, "Avg loss": 0.9250267364550382, "Avg value loss": 0.5774555442621931, "Avg policy loss": 0.34757119277492166, "Total num played games": 23624, "Total num trained steps": 46592, "Timestamp in ms": 1701820632039, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9776498476125974, "Avg loss": 0.6349579633679241, "Avg value loss": 0.28063543990720063, "Avg policy loss": 0.35432252241298556, "Total num played games": 23624, "Total num trained steps": 46720, "Timestamp in ms": 1701820687566, "logtype": "training_step"}
{"Avg objective": 21.21875, "Games time in secs": 88.23785782791674, "Avg game time in secs": 3.8508320231339894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.7, "agent_stopped_0": 0.44}, "Total num played games": 23680, "Total num trained steps": 46747, "Timestamp in ms": 1701820698850, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750421585160203, "Avg loss": 0.8750908863730729, "Avg value loss": 0.5245041181333363, "Avg policy loss": 0.3505867674248293, "Total num played games": 23720, "Total num trained steps": 46848, "Timestamp in ms": 1701820743768, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 90.33605486340821, "Avg game time in secs": 4.185324435005896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.87}, "Total num played games": 23808, "Total num trained steps": 46941, "Timestamp in ms": 1701820789186, "logtype": "played_game"}
{"Total num played games": 23816, "Total num trained steps": 46941, "Timestamp in ms": 1701820881132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.01953125}
{"Ratio train steps to played games": 1.9648653170486867, "Avg loss": 1.1577744230162352, "Avg value loss": 0.8053307266673073, "Avg policy loss": 0.35244369925931096, "Total num played games": 23908, "Total num trained steps": 46976, "Timestamp in ms": 1701820897409, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9700543705562525, "Avg loss": 0.8565338961780071, "Avg value loss": 0.4920711796730757, "Avg policy loss": 0.3644627167377621, "Total num played games": 23910, "Total num trained steps": 47104, "Timestamp in ms": 1701820953619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9754077791718947, "Avg loss": 0.5265070169698447, "Avg value loss": 0.1918623154051602, "Avg policy loss": 0.33464470389299095, "Total num played games": 23910, "Total num trained steps": 47232, "Timestamp in ms": 1701821010692, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 257.9482461307198, "Avg game time in secs": 4.184630169707816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.79, "agent_stopped_0": 0.47}, "Total num played games": 23936, "Total num trained steps": 47315, "Timestamp in ms": 1701821047134, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9729628395267456, "Avg loss": 0.7854689180385321, "Avg value loss": 0.45800869876984507, "Avg policy loss": 0.3274602135643363, "Total num played games": 24004, "Total num trained steps": 47360, "Timestamp in ms": 1701821066611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978336943842693, "Avg loss": 0.5855583494994789, "Avg value loss": 0.25178428820800036, "Avg policy loss": 0.33377406373620033, "Total num played games": 24004, "Total num trained steps": 47488, "Timestamp in ms": 1701821123661, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 85.0978692676872, "Avg game time in secs": 3.5354593860683963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.69}, "Total num played games": 24064, "Total num trained steps": 47508, "Timestamp in ms": 1701821132232, "logtype": "played_game"}
{"Total num played games": 24100, "Total num trained steps": 47545, "Timestamp in ms": 1701821220092, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.11328125}
{"Avg objective": 22.09375, "Games time in secs": 98.60721799358726, "Avg game time in secs": 4.614804315468064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.86, "agent_stopped_0": 0.35}, "Total num played games": 24192, "Total num trained steps": 47569, "Timestamp in ms": 1701821230840, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968091262296437, "Avg loss": 1.816771658603102, "Avg value loss": 1.4491761153913103, "Avg policy loss": 0.36759555293247104, "Total num played games": 24194, "Total num trained steps": 47616, "Timestamp in ms": 1701821251624, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9733818302058361, "Avg loss": 0.6896539649460465, "Avg value loss": 0.3165391938528046, "Avg policy loss": 0.3731147712096572, "Total num played games": 24194, "Total num trained steps": 47744, "Timestamp in ms": 1701821309547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978631065553443, "Avg loss": 0.5386502651963383, "Avg value loss": 0.19300305389333516, "Avg policy loss": 0.34564721677452326, "Total num played games": 24194, "Total num trained steps": 47872, "Timestamp in ms": 1701821366114, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9761218608480857, "Avg loss": 0.9121908915694803, "Avg value loss": 0.5480481602717191, "Avg policy loss": 0.3641427276888862, "Total num played games": 24290, "Total num trained steps": 48000, "Timestamp in ms": 1701821423093, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 225.48798301257193, "Avg game time in secs": 3.7777441461221315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.68, "agent_stopped_0": 0.49}, "Total num played games": 24320, "Total num trained steps": 48077, "Timestamp in ms": 1701821456328, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9735914049044534, "Avg loss": 0.8801673231646419, "Avg value loss": 0.5279292078921571, "Avg policy loss": 0.35223812074400485, "Total num played games": 24386, "Total num trained steps": 48128, "Timestamp in ms": 1701821480374, "logtype": "training_step"}
{"Total num played games": 24386, "Total num trained steps": 48147, "Timestamp in ms": 1701821569349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.57421875}
{"Avg objective": 20.734375, "Games time in secs": 118.694150775671, "Avg game time in secs": 4.059757520721178, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.84}, "Total num played games": 24448, "Total num trained steps": 48157, "Timestamp in ms": 1701821575022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9712418300653596, "Avg loss": 0.9487871532328427, "Avg value loss": 0.582315111416392, "Avg policy loss": 0.3664720405358821, "Total num played games": 24480, "Total num trained steps": 48256, "Timestamp in ms": 1701821618200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764297385620915, "Avg loss": 0.5370928277261555, "Avg value loss": 0.20197989221196622, "Avg policy loss": 0.33511293621268123, "Total num played games": 24480, "Total num trained steps": 48384, "Timestamp in ms": 1701821674255, "logtype": "training_step"}
{"Avg objective": 18.703125, "Games time in secs": 141.6959831994027, "Avg game time in secs": 4.923592942781397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.046875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.95, "agent_stopped_0": 0.36}, "Total num played games": 24576, "Total num trained steps": 48478, "Timestamp in ms": 1701821716718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973757018471804, "Avg loss": 0.7251314853783697, "Avg value loss": 0.3893939462141134, "Avg policy loss": 0.3357375393388793, "Total num played games": 24578, "Total num trained steps": 48512, "Timestamp in ms": 1701821732534, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790056147774433, "Avg loss": 0.5696466281078756, "Avg value loss": 0.22802293044514954, "Avg policy loss": 0.3416236990597099, "Total num played games": 24578, "Total num trained steps": 48640, "Timestamp in ms": 1701821790315, "logtype": "training_step"}
{"Total num played games": 24672, "Total num trained steps": 48749, "Timestamp in ms": 1701821917080, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.44140625}
{"Avg objective": 22.4765625, "Games time in secs": 205.10504308342934, "Avg game time in secs": 3.713586861733347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 24704, "Total num trained steps": 48758, "Timestamp in ms": 1701821921823, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969946679592826, "Avg loss": 1.0329213531222194, "Avg value loss": 0.6859313362510875, "Avg policy loss": 0.34699000394903123, "Total num played games": 24756, "Total num trained steps": 48768, "Timestamp in ms": 1701821926172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974279253815715, "Avg loss": 1.0295668900944293, "Avg value loss": 0.6629808268044144, "Avg policy loss": 0.36658606212586164, "Total num played games": 24766, "Total num trained steps": 48896, "Timestamp in ms": 1701821983022, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979328165374677, "Avg loss": 0.5361379799433053, "Avg value loss": 0.19453799270559102, "Avg policy loss": 0.3415999826975167, "Total num played games": 24768, "Total num trained steps": 49024, "Timestamp in ms": 1701822039343, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 121.87078352458775, "Avg game time in secs": 4.475463490452967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.88, "agent_stopped_0": 0.38}, "Total num played games": 24832, "Total num trained steps": 49035, "Timestamp in ms": 1701822043694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769527793419677, "Avg loss": 1.0342199821025133, "Avg value loss": 0.676478109206073, "Avg policy loss": 0.35774188791401684, "Total num played games": 24862, "Total num trained steps": 49152, "Timestamp in ms": 1701822095219, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 92.32456500455737, "Avg game time in secs": 4.237951512273867, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.75, "agent_stopped_0": 0.45}, "Total num played games": 24960, "Total num trained steps": 49247, "Timestamp in ms": 1701822136019, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741607243009374, "Avg loss": 0.9146024482324719, "Avg value loss": 0.5757038143929094, "Avg policy loss": 0.33889864140655845, "Total num played games": 24962, "Total num trained steps": 49280, "Timestamp in ms": 1701822149952, "logtype": "training_step"}
{"Total num played games": 24962, "Total num trained steps": 49349, "Timestamp in ms": 1701822211101, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1171875}
{"Ratio train steps to played games": 1.9718630268199233, "Avg loss": 0.9911895850673318, "Avg value loss": 0.6532909420784563, "Avg policy loss": 0.33789865172002465, "Total num played games": 25056, "Total num trained steps": 49408, "Timestamp in ms": 1701822239396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976971583652618, "Avg loss": 0.5896330059040338, "Avg value loss": 0.248453714302741, "Avg policy loss": 0.3411792921833694, "Total num played games": 25056, "Total num trained steps": 49536, "Timestamp in ms": 1701822295198, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 191.07512086629868, "Avg game time in secs": 3.656054233739269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.62, "agent_stopped_0": 0.54}, "Total num played games": 25088, "Total num trained steps": 49608, "Timestamp in ms": 1701822327094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974554707379135, "Avg loss": 0.9394707093015313, "Avg value loss": 0.6060764369904064, "Avg policy loss": 0.3333942738827318, "Total num played games": 25152, "Total num trained steps": 49664, "Timestamp in ms": 1701822349826, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979643765903308, "Avg loss": 0.5727341515012085, "Avg value loss": 0.23018413386307657, "Avg policy loss": 0.3425500189187005, "Total num played games": 25152, "Total num trained steps": 49792, "Timestamp in ms": 1701822408138, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 86.10377439856529, "Avg game time in secs": 3.99278625898296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 25216, "Total num trained steps": 49805, "Timestamp in ms": 1701822413198, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977029702970297, "Avg loss": 0.7432188366074115, "Avg value loss": 0.4011937805917114, "Avg policy loss": 0.34202506160363555, "Total num played games": 25250, "Total num trained steps": 49920, "Timestamp in ms": 1701822463716, "logtype": "training_step"}
{"Total num played games": 25250, "Total num trained steps": 49953, "Timestamp in ms": 1701822565009, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3046875}
{"Avg objective": 22.3125, "Games time in secs": 163.70744916051626, "Avg game time in secs": 4.600987660582177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.87, "agent_stopped_0": 0.34}, "Total num played games": 25344, "Total num trained steps": 49979, "Timestamp in ms": 1701822576906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9747080176767677, "Avg loss": 1.3147973930463195, "Avg value loss": 0.9705141121521592, "Avg policy loss": 0.34428327216301113, "Total num played games": 25344, "Total num trained steps": 50048, "Timestamp in ms": 1701822608017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97979797979798, "Avg loss": 0.5507236765697598, "Avg value loss": 0.22331558191217482, "Avg policy loss": 0.32740809326060116, "Total num played games": 25344, "Total num trained steps": 50176, "Timestamp in ms": 1701822665909, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9773584905660377, "Avg loss": 0.7692976933903992, "Avg value loss": 0.4231076755095273, "Avg policy loss": 0.34619001648388803, "Total num played games": 25440, "Total num trained steps": 50304, "Timestamp in ms": 1701822721563, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 176.85876206308603, "Avg game time in secs": 3.8271628934016917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.74}, "Total num played games": 25472, "Total num trained steps": 50377, "Timestamp in ms": 1701822753765, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974743519461195, "Avg loss": 0.8898848248645663, "Avg value loss": 0.5513260377338156, "Avg policy loss": 0.33855878666508943, "Total num played games": 25538, "Total num trained steps": 50432, "Timestamp in ms": 1701822778437, "logtype": "training_step"}
{"Total num played games": 25538, "Total num trained steps": 50555, "Timestamp in ms": 1701822868633, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.90625}
{"Ratio train steps to played games": 1.9788649706457926, "Avg loss": 0.5759875234216452, "Avg value loss": 0.2315119623672217, "Avg policy loss": 0.3444755601231009, "Total num played games": 25550, "Total num trained steps": 50560, "Timestamp in ms": 1701822871293, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 120.03683105297387, "Avg game time in secs": 3.9422946114791557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.78, "agent_stopped_0": 0.42}, "Total num played games": 25600, "Total num trained steps": 50565, "Timestamp in ms": 1701822873802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775280898876404, "Avg loss": 1.1347415456548333, "Avg value loss": 0.7785650304285809, "Avg policy loss": 0.35617651138454676, "Total num played games": 25632, "Total num trained steps": 50688, "Timestamp in ms": 1701822927459, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 97.82004462741315, "Avg game time in secs": 4.55410029059567, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.93, "agent_stopped_0": 0.34}, "Total num played games": 25728, "Total num trained steps": 50785, "Timestamp in ms": 1701822971622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9749708511465216, "Avg loss": 1.042132240952924, "Avg value loss": 0.7053947795066051, "Avg policy loss": 0.33673746860586107, "Total num played games": 25730, "Total num trained steps": 50816, "Timestamp in ms": 1701822985122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9799455888068402, "Avg loss": 0.5873085921630263, "Avg value loss": 0.24815124820452183, "Avg policy loss": 0.3391573417466134, "Total num played games": 25730, "Total num trained steps": 50944, "Timestamp in ms": 1701823041301, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9775420119259661, "Avg loss": 0.9036859506741166, "Avg value loss": 0.5613619148498401, "Avg policy loss": 0.3423240357078612, "Total num played games": 25826, "Total num trained steps": 51072, "Timestamp in ms": 1701823096144, "logtype": "training_step"}
{"Avg objective": 22.484375, "Games time in secs": 161.0236049760133, "Avg game time in secs": 3.7564683820091886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.65, "agent_stopped_0": 0.51}, "Total num played games": 25856, "Total num trained steps": 51150, "Timestamp in ms": 1701823132646, "logtype": "played_game"}
{"Total num played games": 25922, "Total num trained steps": 51158, "Timestamp in ms": 1701823212018, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.72265625}
{"Avg objective": 20.078125, "Games time in secs": 85.22831056639552, "Avg game time in secs": 4.13123754922708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.71, "agent_stopped_0": 0.46}, "Total num played games": 25984, "Total num trained steps": 51169, "Timestamp in ms": 1701823217874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9679812423124232, "Avg loss": 1.220900074345991, "Avg value loss": 0.878110246732831, "Avg policy loss": 0.3427898205118254, "Total num played games": 26016, "Total num trained steps": 51200, "Timestamp in ms": 1701823231428, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972939729397294, "Avg loss": 0.7104222127236426, "Avg value loss": 0.3651243607746437, "Avg policy loss": 0.3452978499699384, "Total num played games": 26016, "Total num trained steps": 51328, "Timestamp in ms": 1701823287093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977859778597786, "Avg loss": 0.5002751615829766, "Avg value loss": 0.18095796852139756, "Avg policy loss": 0.3193171911407262, "Total num played games": 26016, "Total num trained steps": 51456, "Timestamp in ms": 1701823342800, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 165.31525757163763, "Avg game time in secs": 4.367151872516843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.8, "agent_stopped_0": 0.38}, "Total num played games": 26112, "Total num trained steps": 51546, "Timestamp in ms": 1701823383189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753388986750402, "Avg loss": 0.6874371969606727, "Avg value loss": 0.36956224183086306, "Avg policy loss": 0.3178749526850879, "Total num played games": 26114, "Total num trained steps": 51584, "Timestamp in ms": 1701823400372, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802021903959561, "Avg loss": 0.534286656184122, "Avg value loss": 0.21659209579229355, "Avg policy loss": 0.3176945581799373, "Total num played games": 26114, "Total num trained steps": 51712, "Timestamp in ms": 1701823455478, "logtype": "training_step"}
{"Total num played games": 26208, "Total num trained steps": 51762, "Timestamp in ms": 1701823583430, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.671875}
{"Avg objective": 23.4140625, "Games time in secs": 204.36340068280697, "Avg game time in secs": 4.131169701257022, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.81, "agent_stopped_0": 0.41}, "Total num played games": 26240, "Total num trained steps": 51769, "Timestamp in ms": 1701823587553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970914759333891, "Avg loss": 1.6597285789903253, "Avg value loss": 1.3056608082843013, "Avg policy loss": 0.3540677649434656, "Total num played games": 26302, "Total num trained steps": 51840, "Timestamp in ms": 1701823618338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757813094061287, "Avg loss": 0.6085358147975057, "Avg value loss": 0.26948291494045407, "Avg policy loss": 0.3390529052121565, "Total num played games": 26302, "Total num trained steps": 51968, "Timestamp in ms": 1701823677782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980685879400806, "Avg loss": 0.5153392406646162, "Avg value loss": 0.19734723010333255, "Avg policy loss": 0.317992003983818, "Total num played games": 26302, "Total num trained steps": 52096, "Timestamp in ms": 1701823734532, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 151.11563648469746, "Avg game time in secs": 4.160015593224671, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.83, "agent_stopped_0": 0.38}, "Total num played games": 26368, "Total num trained steps": 52106, "Timestamp in ms": 1701823738669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978331691794833, "Avg loss": 1.2792917182669044, "Avg value loss": 0.9313630292890593, "Avg policy loss": 0.34792870189994574, "Total num played games": 26398, "Total num trained steps": 52224, "Timestamp in ms": 1701823789103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9759945648071262, "Avg loss": 0.9273172288667411, "Avg value loss": 0.59057395986747, "Avg policy loss": 0.3367432705126703, "Total num played games": 26494, "Total num trained steps": 52352, "Timestamp in ms": 1701823845642, "logtype": "training_step"}
{"Total num played games": 26494, "Total num trained steps": 52366, "Timestamp in ms": 1701823964527, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.890625}
{"Avg objective": 21.53125, "Games time in secs": 227.98829518817365, "Avg game time in secs": 4.413301437089103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.84, "agent_stopped_0": 0.41}, "Total num played games": 26496, "Total num trained steps": 52369, "Timestamp in ms": 1701823966657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9738227771927186, "Avg loss": 0.8905876181088388, "Avg value loss": 0.5383525665383786, "Avg policy loss": 0.3522350515704602, "Total num played games": 26588, "Total num trained steps": 52480, "Timestamp in ms": 1701824013990, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786369790883105, "Avg loss": 0.5217159651219845, "Avg value loss": 0.19275055720936507, "Avg policy loss": 0.32896540488582104, "Total num played games": 26588, "Total num trained steps": 52608, "Timestamp in ms": 1701824069938, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 131.00747818127275, "Avg game time in secs": 3.267482284907601, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.65}, "Total num played games": 26624, "Total num trained steps": 52674, "Timestamp in ms": 1701824097665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9763153949932544, "Avg loss": 0.798942520050332, "Avg value loss": 0.4673158918158151, "Avg policy loss": 0.3316266261972487, "Total num played games": 26684, "Total num trained steps": 52736, "Timestamp in ms": 1701824123559, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980073413738857, "Avg loss": 0.5324904825538397, "Avg value loss": 0.2036747275851667, "Avg policy loss": 0.32881575368810445, "Total num played games": 26698, "Total num trained steps": 52864, "Timestamp in ms": 1701824178853, "logtype": "training_step"}
{"Avg objective": 22.90625, "Games time in secs": 83.9006226696074, "Avg game time in secs": 3.963552434986923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.76, "agent_stopped_0": 0.39}, "Total num played games": 26752, "Total num trained steps": 52871, "Timestamp in ms": 1701824181566, "logtype": "played_game"}
{"Total num played games": 26780, "Total num trained steps": 52968, "Timestamp in ms": 1701824300151, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.71875}
{"Ratio train steps to played games": 1.9721622627465576, "Avg loss": 1.473952571861446, "Avg value loss": 1.1195665716659278, "Avg policy loss": 0.3543860112549737, "Total num played games": 26870, "Total num trained steps": 52992, "Timestamp in ms": 1701824311557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976631688620972, "Avg loss": 1.1087230909615755, "Avg value loss": 0.7325936878332868, "Avg policy loss": 0.37612940091639757, "Total num played games": 26874, "Total num trained steps": 53120, "Timestamp in ms": 1701824366281, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 238.15689407102764, "Avg game time in secs": 4.864824014264741, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.94, "agent_stopped_0": 0.33}, "Total num played games": 26880, "Total num trained steps": 53241, "Timestamp in ms": 1701824419723, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785969084423305, "Avg loss": 0.5583425634540617, "Avg value loss": 0.21741473180009052, "Avg policy loss": 0.3409278329927474, "Total num played games": 26910, "Total num trained steps": 53248, "Timestamp in ms": 1701824422346, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978941124128726, "Avg loss": 1.026117643341422, "Avg value loss": 0.6699185858014971, "Avg policy loss": 0.3561990447342396, "Total num played games": 26972, "Total num trained steps": 53376, "Timestamp in ms": 1701824480166, "logtype": "training_step"}
{"Avg objective": 22.2734375, "Games time in secs": 90.18143909052014, "Avg game time in secs": 3.8784935022558784, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.76}, "Total num played games": 27008, "Total num trained steps": 53440, "Timestamp in ms": 1701824509904, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976651396482932, "Avg loss": 0.9749670929741114, "Avg value loss": 0.6214654591167346, "Avg policy loss": 0.35350164235569537, "Total num played games": 27068, "Total num trained steps": 53504, "Timestamp in ms": 1701824539242, "logtype": "training_step"}
{"Total num played games": 27068, "Total num trained steps": 53571, "Timestamp in ms": 1701824614524, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.16796875}
{"Avg objective": 21.8984375, "Games time in secs": 110.59231768734753, "Avg game time in secs": 3.406073131976882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.69}, "Total num played games": 27136, "Total num trained steps": 53583, "Timestamp in ms": 1701824620497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9745232309844636, "Avg loss": 0.8281865823082626, "Avg value loss": 0.47653155063744634, "Avg policy loss": 0.3516550261992961, "Total num played games": 27162, "Total num trained steps": 53632, "Timestamp in ms": 1701824641580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791988807893381, "Avg loss": 0.5670452998019755, "Avg value loss": 0.2245639687171206, "Avg policy loss": 0.3424813337624073, "Total num played games": 27162, "Total num trained steps": 53760, "Timestamp in ms": 1701824699764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770692691517464, "Avg loss": 1.0026660703588277, "Avg value loss": 0.65225206525065, "Avg policy loss": 0.35041399928741157, "Total num played games": 27256, "Total num trained steps": 53888, "Timestamp in ms": 1701824756314, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 186.75224137492478, "Avg game time in secs": 4.238716813590145, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.78, "agent_stopped_0": 0.44}, "Total num played games": 27264, "Total num trained steps": 54005, "Timestamp in ms": 1701824807249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768335529205094, "Avg loss": 0.6065609019715339, "Avg value loss": 0.26083678047871217, "Avg policy loss": 0.34572411933913827, "Total num played games": 27324, "Total num trained steps": 54016, "Timestamp in ms": 1701824811548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792367305161573, "Avg loss": 0.9405065986793488, "Avg value loss": 0.5768257873132825, "Avg policy loss": 0.36368081672117114, "Total num played games": 27356, "Total num trained steps": 54144, "Timestamp in ms": 1701824868767, "logtype": "training_step"}
{"Total num played games": 27356, "Total num trained steps": 54172, "Timestamp in ms": 1701824922437, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5859375}
{"Avg objective": 21.9765625, "Games time in secs": 119.2247608974576, "Avg game time in secs": 3.87504936469486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.71, "agent_stopped_0": 0.47}, "Total num played games": 27392, "Total num trained steps": 54180, "Timestamp in ms": 1701824926474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771220400728597, "Avg loss": 0.8550528842024505, "Avg value loss": 0.487550824531354, "Avg policy loss": 0.3675020677037537, "Total num played games": 27450, "Total num trained steps": 54272, "Timestamp in ms": 1701824967996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777503090234858, "Avg loss": 0.5553706842474639, "Avg value loss": 0.2083212765865028, "Avg policy loss": 0.3470494032371789, "Total num played games": 27504, "Total num trained steps": 54400, "Timestamp in ms": 1701825025115, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 99.54694512113929, "Avg game time in secs": 3.9175758367346134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 27520, "Total num trained steps": 54402, "Timestamp in ms": 1701825026022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9793814432989691, "Avg loss": 0.9814587950240821, "Avg value loss": 0.621432438492775, "Avg policy loss": 0.3600263688713312, "Total num played games": 27548, "Total num trained steps": 54528, "Timestamp in ms": 1701825081648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977101721892635, "Avg loss": 0.9540690921712667, "Avg value loss": 0.5900904563022777, "Avg policy loss": 0.3639786432031542, "Total num played games": 27644, "Total num trained steps": 54656, "Timestamp in ms": 1701825138349, "logtype": "training_step"}
{"Total num played games": 27644, "Total num trained steps": 54774, "Timestamp in ms": 1701825246324, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.26953125}
{"Avg objective": 21.6328125, "Games time in secs": 222.125818958506, "Avg game time in secs": 4.397517373567098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.89, "agent_stopped_0": 0.31}, "Total num played games": 27648, "Total num trained steps": 54777, "Timestamp in ms": 1701825248148, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781902217086733, "Avg loss": 0.6409498935099691, "Avg value loss": 0.27553094923496246, "Avg policy loss": 0.3654189449734986, "Total num played games": 27692, "Total num trained steps": 54784, "Timestamp in ms": 1701825251743, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796668829764221, "Avg loss": 1.1255814163014293, "Avg value loss": 0.7433606156846508, "Avg policy loss": 0.3822208095807582, "Total num played games": 27738, "Total num trained steps": 54912, "Timestamp in ms": 1701825309231, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 87.51689108088613, "Avg game time in secs": 3.712520627610502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.72}, "Total num played games": 27776, "Total num trained steps": 54973, "Timestamp in ms": 1701825335665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9768694777674019, "Avg loss": 1.135657550767064, "Avg value loss": 0.7681412398815155, "Avg policy loss": 0.36751630692742765, "Total num played games": 27842, "Total num trained steps": 55040, "Timestamp in ms": 1701825364817, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814668486459306, "Avg loss": 0.5916835076641291, "Avg value loss": 0.22599340096348897, "Avg policy loss": 0.3656901032663882, "Total num played games": 27842, "Total num trained steps": 55168, "Timestamp in ms": 1701825422772, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 93.68290169164538, "Avg game time in secs": 3.9939937443850795, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.76, "agent_stopped_0": 0.47}, "Total num played games": 27904, "Total num trained steps": 55184, "Timestamp in ms": 1701825429348, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979239745149975, "Avg loss": 1.0627311028074473, "Avg value loss": 0.6920545210596174, "Avg policy loss": 0.3706765703391284, "Total num played games": 27938, "Total num trained steps": 55296, "Timestamp in ms": 1701825477806, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 90.94065338559449, "Avg game time in secs": 4.739812395433546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9140625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.98, "agent_stopped_0": 0.34}, "Total num played games": 28032, "Total num trained steps": 55374, "Timestamp in ms": 1701825520289, "logtype": "played_game"}
{"Total num played games": 28036, "Total num trained steps": 55374, "Timestamp in ms": 1701825560403, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0}
{"Ratio train steps to played games": 1.9702452897262708, "Avg loss": 1.3637522209901363, "Avg value loss": 0.9765222802525386, "Avg policy loss": 0.3872299531940371, "Total num played games": 28130, "Total num trained steps": 55424, "Timestamp in ms": 1701825582254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9748311411304658, "Avg loss": 0.6948032600339502, "Avg value loss": 0.3199084212537855, "Avg policy loss": 0.3748948418069631, "Total num played games": 28130, "Total num trained steps": 55552, "Timestamp in ms": 1701825639902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793814432989691, "Avg loss": 0.525876562576741, "Avg value loss": 0.165990965499077, "Avg policy loss": 0.35988559864927083, "Total num played games": 28130, "Total num trained steps": 55680, "Timestamp in ms": 1701825697425, "logtype": "training_step"}
{"Avg objective": 22.25, "Games time in secs": 209.46050927601755, "Avg game time in secs": 3.3547405764838913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.61, "agent_stopped_0": 0.52}, "Total num played games": 28160, "Total num trained steps": 55755, "Timestamp in ms": 1701825729750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771841564514987, "Avg loss": 0.7900747989770025, "Avg value loss": 0.4308986818068661, "Avg policy loss": 0.35917612235061824, "Total num played games": 28226, "Total num trained steps": 55808, "Timestamp in ms": 1701825751692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817189824984058, "Avg loss": 0.5593603828456253, "Avg value loss": 0.2062182155204937, "Avg policy loss": 0.3531421635998413, "Total num played games": 28226, "Total num trained steps": 55936, "Timestamp in ms": 1701825809112, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 85.73586666025221, "Avg game time in secs": 3.665778027410852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.74}, "Total num played games": 28288, "Total num trained steps": 55951, "Timestamp in ms": 1701825815486, "logtype": "played_game"}
{"Total num played games": 28322, "Total num trained steps": 55974, "Timestamp in ms": 1701825847951, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.07421875}
{"Avg objective": 21.546875, "Games time in secs": 50.951585084199905, "Avg game time in secs": 4.514478531258646, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.015625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.85}, "Total num played games": 28416, "Total num trained steps": 56016, "Timestamp in ms": 1701825866438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972972972972973, "Avg loss": 1.5158436426427215, "Avg value loss": 1.1444136568461545, "Avg policy loss": 0.3714299788698554, "Total num played games": 28416, "Total num trained steps": 56064, "Timestamp in ms": 1701825888192, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9774774774774775, "Avg loss": 0.5822969118598849, "Avg value loss": 0.23055847629439086, "Avg policy loss": 0.35173843591473997, "Total num played games": 28416, "Total num trained steps": 56192, "Timestamp in ms": 1701825944145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981981981981982, "Avg loss": 0.4861144640017301, "Avg value loss": 0.15481423202436417, "Avg policy loss": 0.3313002318609506, "Total num played games": 28416, "Total num trained steps": 56320, "Timestamp in ms": 1701825998195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796591148207898, "Avg loss": 1.0077095550950617, "Avg value loss": 0.6515303362975828, "Avg policy loss": 0.35617922397796065, "Total num played games": 28514, "Total num trained steps": 56448, "Timestamp in ms": 1701826054243, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 221.67555879056454, "Avg game time in secs": 3.67355392940226, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.75}, "Total num played games": 28544, "Total num trained steps": 56524, "Timestamp in ms": 1701826088113, "logtype": "played_game"}
{"Total num played games": 28610, "Total num trained steps": 56575, "Timestamp in ms": 1701826166690, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0703125}
{"Ratio train steps to played games": 1.9774554351625306, "Avg loss": 0.8447376361582428, "Avg value loss": 0.4882926748250611, "Avg policy loss": 0.3564449662808329, "Total num played games": 28610, "Total num trained steps": 56576, "Timestamp in ms": 1701826167492, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 83.97998536750674, "Avg game time in secs": 3.6655909329419956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.76, "agent_stopped_0": 0.41}, "Total num played games": 28672, "Total num trained steps": 56588, "Timestamp in ms": 1701826172093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975473801560758, "Avg loss": 0.9664870530832559, "Avg value loss": 0.5827007421758026, "Avg policy loss": 0.3837863113731146, "Total num played games": 28704, "Total num trained steps": 56704, "Timestamp in ms": 1701826222967, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979933110367893, "Avg loss": 0.5252988322172314, "Avg value loss": 0.1644983152509667, "Avg policy loss": 0.36080051120370626, "Total num played games": 28704, "Total num trained steps": 56832, "Timestamp in ms": 1701826283432, "logtype": "training_step"}
{"Avg objective": 23.0234375, "Games time in secs": 158.4601869676262, "Avg game time in secs": 4.717033116321545, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 1.05, "agent_stopped_0": 0.27}, "Total num played games": 28800, "Total num trained steps": 56942, "Timestamp in ms": 1701826330554, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777777777777779, "Avg loss": 1.0590482512488961, "Avg value loss": 0.6901210811338387, "Avg policy loss": 0.36892717774026096, "Total num played games": 28800, "Total num trained steps": 56960, "Timestamp in ms": 1701826337889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822222222222223, "Avg loss": 0.6286795334890485, "Avg value loss": 0.2506511489045806, "Avg policy loss": 0.37802838324569166, "Total num played games": 28800, "Total num trained steps": 57088, "Timestamp in ms": 1701826394473, "logtype": "training_step"}
{"Total num played games": 28898, "Total num trained steps": 57177, "Timestamp in ms": 1701826474602, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9140625}
{"Avg objective": 21.6171875, "Games time in secs": 147.60367527604103, "Avg game time in secs": 3.552388834505109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.71}, "Total num played games": 28928, "Total num trained steps": 57184, "Timestamp in ms": 1701826478157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9734754415011038, "Avg loss": 1.4640364779625088, "Avg value loss": 1.0585758390370756, "Avg policy loss": 0.40546064358204603, "Total num played games": 28992, "Total num trained steps": 57216, "Timestamp in ms": 1701826492665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 0.7593241948634386, "Avg value loss": 0.36218659626320004, "Avg policy loss": 0.3971375925466418, "Total num played games": 28992, "Total num trained steps": 57344, "Timestamp in ms": 1701826547259, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823399558498895, "Avg loss": 0.5326563576236367, "Avg value loss": 0.16252601303858683, "Avg policy loss": 0.37013034522533417, "Total num played games": 28992, "Total num trained steps": 57472, "Timestamp in ms": 1701826601257, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 127.8999725561589, "Avg game time in secs": 3.565498982628924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.77}, "Total num played games": 29056, "Total num trained steps": 57484, "Timestamp in ms": 1701826606058, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800618769336542, "Avg loss": 0.9532578089274466, "Avg value loss": 0.5623365792562254, "Avg policy loss": 0.3909212304279208, "Total num played games": 29090, "Total num trained steps": 57600, "Timestamp in ms": 1701826658512, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 91.96028571017087, "Avg game time in secs": 4.649416934829787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.89}, "Total num played games": 29184, "Total num trained steps": 57692, "Timestamp in ms": 1701826698018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779346261906394, "Avg loss": 0.8878742454107851, "Avg value loss": 0.5070880422135815, "Avg policy loss": 0.38078621099703014, "Total num played games": 29186, "Total num trained steps": 57728, "Timestamp in ms": 1701826712893, "logtype": "training_step"}
{"Total num played games": 29186, "Total num trained steps": 57778, "Timestamp in ms": 1701826810247, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0234375}
{"Ratio train steps to played games": 1.9759562841530054, "Avg loss": 1.105148436035961, "Avg value loss": 0.7015662662452087, "Avg policy loss": 0.4035821675788611, "Total num played games": 29280, "Total num trained steps": 57856, "Timestamp in ms": 1701826844357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980327868852459, "Avg loss": 0.6217659444082528, "Avg value loss": 0.235647447174415, "Avg policy loss": 0.38611849560402334, "Total num played games": 29280, "Total num trained steps": 57984, "Timestamp in ms": 1701826902215, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 235.826736651361, "Avg game time in secs": 3.6634093466418562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.68, "agent_stopped_0": 0.5}, "Total num played games": 29312, "Total num trained steps": 58056, "Timestamp in ms": 1701826933845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9782135076252723, "Avg loss": 0.8316235863603652, "Avg value loss": 0.4626896470435895, "Avg policy loss": 0.3689339286647737, "Total num played games": 29376, "Total num trained steps": 58112, "Timestamp in ms": 1701826959813, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825708061002179, "Avg loss": 0.5652129433583468, "Avg value loss": 0.19671395100886002, "Avg policy loss": 0.36849899706430733, "Total num played games": 29376, "Total num trained steps": 58240, "Timestamp in ms": 1701827019778, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 91.02575789764524, "Avg game time in secs": 3.5230804561724653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.7, "agent_stopped_0": 0.44}, "Total num played games": 29440, "Total num trained steps": 58253, "Timestamp in ms": 1701827024871, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980456026058632, "Avg loss": 1.0203797612339258, "Avg value loss": 0.6546005645068362, "Avg policy loss": 0.3657792001031339, "Total num played games": 29472, "Total num trained steps": 58368, "Timestamp in ms": 1701827076488, "logtype": "training_step"}
{"Total num played games": 29472, "Total num trained steps": 58382, "Timestamp in ms": 1701827167965, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.70703125}
{"Ratio train steps to played games": 1.9784549820740038, "Avg loss": 1.0100253326818347, "Avg value loss": 0.6419501743512228, "Avg policy loss": 0.368075160542503, "Total num played games": 29566, "Total num trained steps": 58496, "Timestamp in ms": 1701827218602, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828181018737738, "Avg loss": 0.532163887983188, "Avg value loss": 0.17953697545453906, "Avg policy loss": 0.3526269127614796, "Total num played games": 29566, "Total num trained steps": 58624, "Timestamp in ms": 1701827274477, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 249.83508777432144, "Avg game time in secs": 4.173091966033098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.89, "agent_stopped_0": 0.44}, "Total num played games": 29568, "Total num trained steps": 58624, "Timestamp in ms": 1701827274706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806823545276786, "Avg loss": 0.8832746935077012, "Avg value loss": 0.5137536534457467, "Avg policy loss": 0.36952104745432734, "Total num played games": 29662, "Total num trained steps": 58752, "Timestamp in ms": 1701827332599, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 87.27583016268909, "Avg game time in secs": 3.3393081571994117, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 29696, "Total num trained steps": 58820, "Timestamp in ms": 1701827361982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786275959405875, "Avg loss": 0.7920259998645633, "Avg value loss": 0.41856945492327213, "Avg policy loss": 0.3734565400518477, "Total num played games": 29758, "Total num trained steps": 58880, "Timestamp in ms": 1701827387211, "logtype": "training_step"}
{"Total num played games": 29758, "Total num trained steps": 58982, "Timestamp in ms": 1701827461497, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.546875}
{"Avg objective": 21.625, "Games time in secs": 104.65965569578111, "Avg game time in secs": 3.653445528165321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.72}, "Total num played games": 29824, "Total num trained steps": 58990, "Timestamp in ms": 1701827466642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9766849792308723, "Avg loss": 0.848714625230059, "Avg value loss": 0.4842173549113795, "Avg policy loss": 0.3644972692709416, "Total num played games": 29852, "Total num trained steps": 59008, "Timestamp in ms": 1701827474803, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980972799142436, "Avg loss": 0.8066297548357397, "Avg value loss": 0.4312128872843459, "Avg policy loss": 0.3754168644081801, "Total num played games": 29852, "Total num trained steps": 59136, "Timestamp in ms": 1701827533422, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788967543742486, "Avg loss": 0.8914806004613638, "Avg value loss": 0.5188262095325626, "Avg policy loss": 0.372654388891533, "Total num played games": 29948, "Total num trained steps": 59264, "Timestamp in ms": 1701827592515, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 182.70415685512125, "Avg game time in secs": 3.777895028833882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.7}, "Total num played games": 29952, "Total num trained steps": 59387, "Timestamp in ms": 1701827649346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806576402321083, "Avg loss": 0.5620978076476604, "Avg value loss": 0.19764791725901887, "Avg policy loss": 0.3644498928915709, "Total num played games": 29984, "Total num trained steps": 59392, "Timestamp in ms": 1701827651012, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811929964716064, "Avg loss": 0.8429565101396292, "Avg value loss": 0.47532840201165527, "Avg policy loss": 0.36762811290100217, "Total num played games": 30042, "Total num trained steps": 59520, "Timestamp in ms": 1701827710292, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 88.44346693530679, "Avg game time in secs": 2.923495952185476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.57}, "Total num played games": 30080, "Total num trained steps": 59581, "Timestamp in ms": 1701827737790, "logtype": "played_game"}
{"Total num played games": 30140, "Total num trained steps": 59582, "Timestamp in ms": 1701827769438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4296875}
{"Avg objective": 21.53125, "Games time in secs": 36.74529714696109, "Avg game time in secs": 3.555080985141103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.76}, "Total num played games": 30208, "Total num trained steps": 59591, "Timestamp in ms": 1701827774535, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9728782165773633, "Avg loss": 1.3501718526240438, "Avg value loss": 0.9775579464621842, "Avg policy loss": 0.3726139129139483, "Total num played games": 30234, "Total num trained steps": 59648, "Timestamp in ms": 1701827801018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770787854733083, "Avg loss": 0.6177291902713478, "Avg value loss": 0.24659733392763883, "Avg policy loss": 0.37113185739144683, "Total num played games": 30234, "Total num trained steps": 59776, "Timestamp in ms": 1701827859669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813124297148905, "Avg loss": 0.5253563357982785, "Avg value loss": 0.1803729721577838, "Avg policy loss": 0.34498336690012366, "Total num played games": 30234, "Total num trained steps": 59904, "Timestamp in ms": 1701827919249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9792944279591165, "Avg loss": 0.8559345020912588, "Avg value loss": 0.5019530628924258, "Avg policy loss": 0.3539814418181777, "Total num played games": 30330, "Total num trained steps": 60032, "Timestamp in ms": 1701827976917, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 256.1740768440068, "Avg game time in secs": 3.700253778399201, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.73, "agent_stopped_0": 0.44}, "Total num played games": 30336, "Total num trained steps": 60153, "Timestamp in ms": 1701828030709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980250164581962, "Avg loss": 0.582365796668455, "Avg value loss": 0.23397991410456598, "Avg policy loss": 0.3483858830295503, "Total num played games": 30380, "Total num trained steps": 60160, "Timestamp in ms": 1701828033786, "logtype": "training_step"}
{"Total num played games": 30426, "Total num trained steps": 60182, "Timestamp in ms": 1701828083892, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8671875}
{"Avg objective": 22.15625, "Games time in secs": 56.47937434539199, "Avg game time in secs": 3.2978537353046704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.69}, "Total num played games": 30464, "Total num trained steps": 60188, "Timestamp in ms": 1701828087189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753604193971166, "Avg loss": 1.851293969899416, "Avg value loss": 1.4444565620506182, "Avg policy loss": 0.4068374240305275, "Total num played games": 30520, "Total num trained steps": 60288, "Timestamp in ms": 1701828128885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979521625163827, "Avg loss": 0.5860680057667196, "Avg value loss": 0.21218242339091375, "Avg policy loss": 0.37388558639213443, "Total num played games": 30520, "Total num trained steps": 60416, "Timestamp in ms": 1701828185889, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 153.0414959769696, "Avg game time in secs": 3.4649137596570654, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 30592, "Total num trained steps": 60540, "Timestamp in ms": 1701828240230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783034897399032, "Avg loss": 0.610245481133461, "Avg value loss": 0.2625163192860782, "Avg policy loss": 0.3477291713934392, "Total num played games": 30604, "Total num trained steps": 60544, "Timestamp in ms": 1701828241932, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981708910373661, "Avg loss": 1.0870823618024588, "Avg value loss": 0.7256587535375729, "Avg policy loss": 0.36142359394580126, "Total num played games": 30616, "Total num trained steps": 60672, "Timestamp in ms": 1701828299007, "logtype": "training_step"}
{"Total num played games": 30712, "Total num trained steps": 60783, "Timestamp in ms": 1701828391613, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.18359375}
{"Avg objective": 21.3671875, "Games time in secs": 153.61083065345883, "Avg game time in secs": 4.127799489244353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.84, "agent_stopped_0": 0.34}, "Total num played games": 30720, "Total num trained steps": 60787, "Timestamp in ms": 1701828393841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973897798844231, "Avg loss": 1.0430392995476723, "Avg value loss": 0.6919006810057908, "Avg policy loss": 0.35113861050922424, "Total num played games": 30802, "Total num trained steps": 60800, "Timestamp in ms": 1701828399580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777640719340388, "Avg loss": 0.8863256922923028, "Avg value loss": 0.5079616010189056, "Avg policy loss": 0.37836408941075206, "Total num played games": 30806, "Total num trained steps": 60928, "Timestamp in ms": 1701828457768, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819515678763877, "Avg loss": 0.5029876548796892, "Avg value loss": 0.1620483569568023, "Avg policy loss": 0.3409392988542095, "Total num played games": 30806, "Total num trained steps": 61056, "Timestamp in ms": 1701828511834, "logtype": "training_step"}
{"Avg objective": 22.1328125, "Games time in secs": 142.4515624102205, "Avg game time in secs": 3.163475049426779, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 30848, "Total num trained steps": 61109, "Timestamp in ms": 1701828536293, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9799365736845511, "Avg loss": 0.8817281611263752, "Avg value loss": 0.5328929085517302, "Avg policy loss": 0.3488352495478466, "Total num played games": 30902, "Total num trained steps": 61184, "Timestamp in ms": 1701828571116, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 88.69839197769761, "Avg game time in secs": 3.5982795904710656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.7}, "Total num played games": 30976, "Total num trained steps": 61304, "Timestamp in ms": 1701828624991, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9784123910939013, "Avg loss": 0.6483185838442296, "Avg value loss": 0.3016506552230567, "Avg policy loss": 0.3466679418925196, "Total num played games": 30990, "Total num trained steps": 61312, "Timestamp in ms": 1701828628217, "logtype": "training_step"}
{"Total num played games": 30996, "Total num trained steps": 61384, "Timestamp in ms": 1701828679495, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.05078125}
{"Ratio train steps to played games": 1.9761981344483757, "Avg loss": 1.1824477976188064, "Avg value loss": 0.8095909449039027, "Avg policy loss": 0.37285685120150447, "Total num played games": 31090, "Total num trained steps": 61440, "Timestamp in ms": 1701828704594, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803152138951432, "Avg loss": 0.5780060170218349, "Avg value loss": 0.215797909128014, "Avg policy loss": 0.36220811028033495, "Total num played games": 31090, "Total num trained steps": 61568, "Timestamp in ms": 1701828761763, "logtype": "training_step"}
{"Avg objective": 21.640625, "Games time in secs": 183.007727464661, "Avg game time in secs": 3.526208916082396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.66}, "Total num played games": 31104, "Total num trained steps": 61673, "Timestamp in ms": 1701828807999, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9779430623236727, "Avg loss": 0.7301844721660018, "Avg value loss": 0.3794988599838689, "Avg policy loss": 0.3506856003077701, "Total num played games": 31192, "Total num trained steps": 61696, "Timestamp in ms": 1701828817359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982014619133111, "Avg loss": 0.7530820434913039, "Avg value loss": 0.39763255638536066, "Avg policy loss": 0.3554494883865118, "Total num played games": 31192, "Total num trained steps": 61824, "Timestamp in ms": 1701828873072, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 89.53055936470628, "Avg game time in secs": 3.0193626613618108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 31232, "Total num trained steps": 61881, "Timestamp in ms": 1701828897530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800562515980569, "Avg loss": 0.819745886605233, "Avg value loss": 0.45928363694110885, "Avg policy loss": 0.36046225135214627, "Total num played games": 31288, "Total num trained steps": 61952, "Timestamp in ms": 1701828930211, "logtype": "training_step"}
{"Total num played games": 31288, "Total num trained steps": 61984, "Timestamp in ms": 1701828992469, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.52734375}
{"Avg objective": 20.953125, "Games time in secs": 100.39960780926049, "Avg game time in secs": 3.535052764651482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.74, "agent_stopped_0": 0.42}, "Total num played games": 31360, "Total num trained steps": 61996, "Timestamp in ms": 1701828997930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978172200624562, "Avg loss": 0.7699576842132956, "Avg value loss": 0.4129405547864735, "Avg policy loss": 0.3570171252358705, "Total num played games": 31382, "Total num trained steps": 62080, "Timestamp in ms": 1701829036554, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822828372952648, "Avg loss": 0.510420233476907, "Avg value loss": 0.17000778170768172, "Avg policy loss": 0.3404124502558261, "Total num played games": 31382, "Total num trained steps": 62208, "Timestamp in ms": 1701829091933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980146124523507, "Avg loss": 1.1256304383277893, "Avg value loss": 0.7622236185125075, "Avg policy loss": 0.3634068181272596, "Total num played games": 31480, "Total num trained steps": 62336, "Timestamp in ms": 1701829150549, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 204.1667858120054, "Avg game time in secs": 3.9794565959164174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8671875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.8, "agent_stopped_0": 0.41}, "Total num played games": 31488, "Total num trained steps": 62453, "Timestamp in ms": 1701829202096, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787126203750633, "Avg loss": 0.6399704581126571, "Avg value loss": 0.28522205364424735, "Avg policy loss": 0.3547484021401033, "Total num played games": 31568, "Total num trained steps": 62464, "Timestamp in ms": 1701829206435, "logtype": "training_step"}
{"Total num played games": 31578, "Total num trained steps": 62587, "Timestamp in ms": 1701829293090, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.953125}
{"Ratio train steps to played games": 1.9818884174529796, "Avg loss": 0.8582904315553606, "Avg value loss": 0.49324986623832956, "Avg policy loss": 0.36504056118428707, "Total num played games": 31582, "Total num trained steps": 62592, "Timestamp in ms": 1701829295250, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 94.7591470927, "Avg game time in secs": 3.1982243955135345, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.56}, "Total num played games": 31616, "Total num trained steps": 62596, "Timestamp in ms": 1701829296856, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802664814347057, "Avg loss": 0.8741827004123479, "Avg value loss": 0.5169929198455065, "Avg policy loss": 0.3571897658985108, "Total num played games": 31672, "Total num trained steps": 62720, "Timestamp in ms": 1701829351807, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 110.42393336631358, "Avg game time in secs": 3.445999905045028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.65, "agent_stopped_0": 0.47}, "Total num played games": 31744, "Total num trained steps": 62845, "Timestamp in ms": 1701829407280, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788413098236777, "Avg loss": 0.5434206693898886, "Avg value loss": 0.2087181995739229, "Avg policy loss": 0.3347024703398347, "Total num played games": 31756, "Total num trained steps": 62848, "Timestamp in ms": 1701829408428, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823721984386804, "Avg loss": 0.8679400784894824, "Avg value loss": 0.5026362887583673, "Avg policy loss": 0.3653037834446877, "Total num played games": 31768, "Total num trained steps": 62976, "Timestamp in ms": 1701829465290, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804167712779313, "Avg loss": 0.8775722153950483, "Avg value loss": 0.5146109720808454, "Avg policy loss": 0.36296124337241054, "Total num played games": 31864, "Total num trained steps": 63104, "Timestamp in ms": 1701829519907, "logtype": "training_step"}
{"Total num played games": 31864, "Total num trained steps": 63189, "Timestamp in ms": 1701829577620, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8671875}
{"Avg objective": 20.8671875, "Games time in secs": 172.4580397233367, "Avg game time in secs": 3.890773696359247, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.8, "agent_stopped_0": 0.34}, "Total num played games": 31872, "Total num trained steps": 63191, "Timestamp in ms": 1701829579738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978565617372802, "Avg loss": 0.8244713877793401, "Avg value loss": 0.46410528203705326, "Avg policy loss": 0.36036611383315176, "Total num played games": 31958, "Total num trained steps": 63232, "Timestamp in ms": 1701829599223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825708742724826, "Avg loss": 0.5381607671733946, "Avg value loss": 0.19415862945606932, "Avg policy loss": 0.344002136727795, "Total num played games": 31958, "Total num trained steps": 63360, "Timestamp in ms": 1701829659913, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 104.84739607572556, "Avg game time in secs": 3.0482379034074256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.66, "agent_stopped_0": 0.47}, "Total num played games": 32000, "Total num trained steps": 63415, "Timestamp in ms": 1701829684586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9805340653855752, "Avg loss": 0.7756690529640764, "Avg value loss": 0.42191204050322995, "Avg policy loss": 0.35375700192525983, "Total num played games": 32056, "Total num trained steps": 63488, "Timestamp in ms": 1701829718037, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 87.9323666896671, "Avg game time in secs": 3.5868854514556006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.83, "agent_stopped_0": 0.36}, "Total num played games": 32128, "Total num trained steps": 63614, "Timestamp in ms": 1701829772523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792172235704064, "Avg loss": 0.5540224118158221, "Avg value loss": 0.21421866252785549, "Avg policy loss": 0.3398037540027872, "Total num played games": 32142, "Total num trained steps": 63616, "Timestamp in ms": 1701829773340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825827320228913, "Avg loss": 0.8065058055799454, "Avg value loss": 0.44285608909558505, "Avg policy loss": 0.3636497179977596, "Total num played games": 32152, "Total num trained steps": 63744, "Timestamp in ms": 1701829826351, "logtype": "training_step"}
{"Total num played games": 32152, "Total num trained steps": 63791, "Timestamp in ms": 1701829899703, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.390625}
{"Ratio train steps to played games": 1.9807728090305774, "Avg loss": 0.7522626989521086, "Avg value loss": 0.3936493811197579, "Avg policy loss": 0.3586133220233023, "Total num played games": 32246, "Total num trained steps": 63872, "Timestamp in ms": 1701829935993, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 215.25233703292906, "Avg game time in secs": 3.2739360421983292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.7, "agent_stopped_0": 0.5}, "Total num played games": 32256, "Total num trained steps": 63985, "Timestamp in ms": 1701829987776, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789734075448362, "Avg loss": 0.6783782411366701, "Avg value loss": 0.3426583210239187, "Avg policy loss": 0.33571992442011833, "Total num played games": 32340, "Total num trained steps": 64000, "Timestamp in ms": 1701829995012, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9829313543599258, "Avg loss": 0.770402223104611, "Avg value loss": 0.4237013584934175, "Avg policy loss": 0.34670085285324603, "Total num played games": 32340, "Total num trained steps": 64128, "Timestamp in ms": 1701830053250, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 87.43741285055876, "Avg game time in secs": 2.8329024660488358, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 32384, "Total num trained steps": 64176, "Timestamp in ms": 1701830075213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810087557035392, "Avg loss": 0.9283346130978316, "Avg value loss": 0.5771001591347158, "Avg policy loss": 0.3512344575719908, "Total num played games": 32436, "Total num trained steps": 64256, "Timestamp in ms": 1701830108821, "logtype": "training_step"}
{"Avg objective": 21.1328125, "Games time in secs": 84.19053137302399, "Avg game time in secs": 3.5264948502008338, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.7, "agent_stopped_0": 0.47}, "Total num played games": 32512, "Total num trained steps": 64371, "Timestamp in ms": 1701830159404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789758406590028, "Avg loss": 0.772996049374342, "Avg value loss": 0.4380164908943698, "Avg policy loss": 0.3349795490503311, "Total num played games": 32534, "Total num trained steps": 64384, "Timestamp in ms": 1701830164233, "logtype": "training_step"}
{"Total num played games": 32536, "Total num trained steps": 64394, "Timestamp in ms": 1701830207355, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.7734375}
{"Ratio train steps to played games": 1.9770456634998468, "Avg loss": 1.2861038725823164, "Avg value loss": 0.8975251317024231, "Avg policy loss": 0.38857873040251434, "Total num played games": 32630, "Total num trained steps": 64512, "Timestamp in ms": 1701830260416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809684339564817, "Avg loss": 0.4856104312930256, "Avg value loss": 0.1410307451733388, "Avg policy loss": 0.344579687807709, "Total num played games": 32630, "Total num trained steps": 64640, "Timestamp in ms": 1701830317696, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 209.58897284418344, "Avg game time in secs": 3.3744920258031925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.68, "agent_stopped_0": 0.47}, "Total num played games": 32640, "Total num trained steps": 64754, "Timestamp in ms": 1701830368993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791895856252293, "Avg loss": 0.5707413714844733, "Avg value loss": 0.24894968589069322, "Avg policy loss": 0.32179169007577, "Total num played games": 32724, "Total num trained steps": 64768, "Timestamp in ms": 1701830374485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9826469509959672, "Avg loss": 0.8839029991067946, "Avg value loss": 0.5363093313062564, "Avg policy loss": 0.34759366628713906, "Total num played games": 32732, "Total num trained steps": 64896, "Timestamp in ms": 1701830431305, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 91.2897000964731, "Avg game time in secs": 3.429144088717294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.73}, "Total num played games": 32768, "Total num trained steps": 64961, "Timestamp in ms": 1701830460283, "logtype": "played_game"}
{"Total num played games": 32828, "Total num trained steps": 64994, "Timestamp in ms": 1701830496073, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.08203125}
{"Avg objective": 21.15625, "Games time in secs": 40.51975487358868, "Avg game time in secs": 3.384705197022413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.72}, "Total num played games": 32896, "Total num trained steps": 65003, "Timestamp in ms": 1701830500803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750926432173015, "Avg loss": 1.2895137390587479, "Avg value loss": 0.9390653087757528, "Avg policy loss": 0.35044841771014035, "Total num played games": 32922, "Total num trained steps": 65024, "Timestamp in ms": 1701830509991, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97898062086143, "Avg loss": 0.8106753099709749, "Avg value loss": 0.44336151774041355, "Avg policy loss": 0.36731379060074687, "Total num played games": 32922, "Total num trained steps": 65152, "Timestamp in ms": 1701830568181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828685985055585, "Avg loss": 0.46801916975528, "Avg value loss": 0.13519649393856525, "Avg policy loss": 0.3328226755838841, "Total num played games": 32922, "Total num trained steps": 65280, "Timestamp in ms": 1701830627558, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809800714761645, "Avg loss": 0.8677429864183068, "Avg value loss": 0.5280119701637886, "Avg policy loss": 0.33973101899027824, "Total num played games": 33018, "Total num trained steps": 65408, "Timestamp in ms": 1701830683614, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 236.56519358605146, "Avg game time in secs": 3.6134764632879524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.7, "agent_stopped_0": 0.51}, "Total num played games": 33024, "Total num trained steps": 65529, "Timestamp in ms": 1701830737368, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979939577039275, "Avg loss": 0.5090414467267692, "Avg value loss": 0.18199245678260922, "Avg policy loss": 0.32704898645170033, "Total num played games": 33100, "Total num trained steps": 65536, "Timestamp in ms": 1701830740538, "logtype": "training_step"}
{"Total num played games": 33118, "Total num trained steps": 65597, "Timestamp in ms": 1701830795515, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.44921875}
{"Avg objective": 21.109375, "Games time in secs": 61.33018505573273, "Avg game time in secs": 2.6568701572250575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 33152, "Total num trained steps": 65602, "Timestamp in ms": 1701830798698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977116704805492, "Avg loss": 1.2323069262783974, "Avg value loss": 0.8707209803396836, "Avg policy loss": 0.3615859381388873, "Total num played games": 33212, "Total num trained steps": 65664, "Timestamp in ms": 1701830825735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98097073346983, "Avg loss": 0.5084392114076763, "Avg value loss": 0.1755629419349134, "Avg policy loss": 0.33287627436220646, "Total num played games": 33212, "Total num trained steps": 65792, "Timestamp in ms": 1701830883939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982377529846931, "Avg loss": 0.43089350615628064, "Avg value loss": 0.11719969904515892, "Avg policy loss": 0.31369380466639996, "Total num played games": 33248, "Total num trained steps": 65920, "Timestamp in ms": 1701830940679, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 143.17212170921266, "Avg game time in secs": 3.459080376342172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.73}, "Total num played games": 33280, "Total num trained steps": 65923, "Timestamp in ms": 1701830941875, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829470397502102, "Avg loss": 0.7265054443851113, "Avg value loss": 0.4099775543436408, "Avg policy loss": 0.31652789912186563, "Total num played games": 33308, "Total num trained steps": 66048, "Timestamp in ms": 1701830995673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981080110166447, "Avg loss": 1.0020596620161086, "Avg value loss": 0.6793826002976857, "Avg policy loss": 0.3226770665496588, "Total num played games": 33404, "Total num trained steps": 66176, "Timestamp in ms": 1701831052456, "logtype": "training_step"}
{"Total num played games": 33404, "Total num trained steps": 66199, "Timestamp in ms": 1701831134783, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.90234375}
{"Avg objective": 22.0390625, "Games time in secs": 194.53728538751602, "Avg game time in secs": 3.9725581413076725, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.87}, "Total num played games": 33408, "Total num trained steps": 66201, "Timestamp in ms": 1701831136413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979312197743149, "Avg loss": 0.874719345709309, "Avg value loss": 0.5346362586133182, "Avg policy loss": 0.34008310036733747, "Total num played games": 33498, "Total num trained steps": 66304, "Timestamp in ms": 1701831179730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983163173920831, "Avg loss": 0.465594352921471, "Avg value loss": 0.1462562558008358, "Avg policy loss": 0.3193380953744054, "Total num played games": 33498, "Total num trained steps": 66432, "Timestamp in ms": 1701831234566, "logtype": "training_step"}
{"Avg objective": 19.6328125, "Games time in secs": 124.9529077745974, "Avg game time in secs": 3.323101841728203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.62}, "Total num played games": 33536, "Total num trained steps": 66491, "Timestamp in ms": 1701831261366, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981306185628386, "Avg loss": 0.7753281279001385, "Avg value loss": 0.4573630339000374, "Avg policy loss": 0.3179650978418067, "Total num played games": 33594, "Total num trained steps": 66560, "Timestamp in ms": 1701831292476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811062919612619, "Avg loss": 0.5895848511718214, "Avg value loss": 0.27018419466912746, "Avg policy loss": 0.31940065312664956, "Total num played games": 33658, "Total num trained steps": 66688, "Timestamp in ms": 1701831349564, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 88.66803302429616, "Avg game time in secs": 3.062970188984764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 33664, "Total num trained steps": 66689, "Timestamp in ms": 1701831350034, "logtype": "played_game"}
{"Total num played games": 33690, "Total num trained steps": 66799, "Timestamp in ms": 1701831415663, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8984375}
{"Ratio train steps to played games": 1.9786780383795308, "Avg loss": 1.188720407197252, "Avg value loss": 0.8532183304196224, "Avg policy loss": 0.33550206292420626, "Total num played games": 33768, "Total num trained steps": 66816, "Timestamp in ms": 1701831422712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815297182098035, "Avg loss": 0.9082417085301131, "Avg value loss": 0.5696057963650674, "Avg policy loss": 0.3386359110008925, "Total num played games": 33784, "Total num trained steps": 66944, "Timestamp in ms": 1701831479121, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 178.2959361691028, "Avg game time in secs": 3.864425652878708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.8}, "Total num played games": 33792, "Total num trained steps": 67061, "Timestamp in ms": 1701831528330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980511427390303, "Avg loss": 0.5028972108848393, "Avg value loss": 0.19919539720285684, "Avg policy loss": 0.30370181158650666, "Total num played games": 33866, "Total num trained steps": 67072, "Timestamp in ms": 1701831532285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834710743801653, "Avg loss": 0.80952742183581, "Avg value loss": 0.4748924662126228, "Avg policy loss": 0.3346349473576993, "Total num played games": 33880, "Total num trained steps": 67200, "Timestamp in ms": 1701831586706, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 82.3832520172, "Avg game time in secs": 3.24339721139404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.73}, "Total num played games": 33920, "Total num trained steps": 67257, "Timestamp in ms": 1701831610713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816046621144336, "Avg loss": 0.7367455647327006, "Avg value loss": 0.41058516007615253, "Avg policy loss": 0.32616040552966297, "Total num played games": 33976, "Total num trained steps": 67328, "Timestamp in ms": 1701831641637, "logtype": "training_step"}
{"Total num played games": 33976, "Total num trained steps": 67399, "Timestamp in ms": 1701831695830, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.59765625}
{"Avg objective": 21.328125, "Games time in secs": 90.65665983594954, "Avg game time in secs": 3.792100302831386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.77}, "Total num played games": 34048, "Total num trained steps": 67409, "Timestamp in ms": 1701831701370, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979923686527737, "Avg loss": 0.7862427367363125, "Avg value loss": 0.45843410497764125, "Avg policy loss": 0.3278086355421692, "Total num played games": 34070, "Total num trained steps": 67456, "Timestamp in ms": 1701831722239, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836513061344292, "Avg loss": 0.48244477761909366, "Avg value loss": 0.16075084824115038, "Avg policy loss": 0.3216939293779433, "Total num played games": 34070, "Total num trained steps": 67584, "Timestamp in ms": 1701831778180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819693244350778, "Avg loss": 0.8666033355984837, "Avg value loss": 0.5358312047319487, "Avg policy loss": 0.3307721350574866, "Total num played games": 34164, "Total num trained steps": 67712, "Timestamp in ms": 1701831834648, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 182.81044887565076, "Avg game time in secs": 3.887343893700745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.8}, "Total num played games": 34176, "Total num trained steps": 67822, "Timestamp in ms": 1701831884185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802673828010975, "Avg loss": 0.5896105356514454, "Avg value loss": 0.25786191929364577, "Avg policy loss": 0.33174861362203956, "Total num played games": 34258, "Total num trained steps": 67840, "Timestamp in ms": 1701831891550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837429221878466, "Avg loss": 0.5593424839898944, "Avg value loss": 0.22603201650781557, "Avg policy loss": 0.3333104664925486, "Total num played games": 34262, "Total num trained steps": 67968, "Timestamp in ms": 1701831948431, "logtype": "training_step"}
{"Total num played games": 34262, "Total num trained steps": 68000, "Timestamp in ms": 1701831983816, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.44921875}
{"Avg objective": 20.796875, "Games time in secs": 103.79868322983384, "Avg game time in secs": 3.3491597197426017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.7, "agent_stopped_0": 0.48}, "Total num played games": 34304, "Total num trained steps": 68008, "Timestamp in ms": 1701831987984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820700896495518, "Avg loss": 1.0931982656475157, "Avg value loss": 0.7549994972650893, "Avg policy loss": 0.3381987698376179, "Total num played games": 34356, "Total num trained steps": 68096, "Timestamp in ms": 1701832026313, "logtype": "training_step"}
{"Avg objective": 22.6640625, "Games time in secs": 90.10543159209192, "Avg game time in secs": 3.502969535649754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.71, "agent_stopped_0": 0.42}, "Total num played games": 34432, "Total num trained steps": 68212, "Timestamp in ms": 1701832078090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980377358490566, "Avg loss": 0.6865978843998164, "Avg value loss": 0.3597013350808993, "Avg policy loss": 0.326896547107026, "Total num played games": 34450, "Total num trained steps": 68224, "Timestamp in ms": 1701832083171, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9839777081156391, "Avg loss": 0.8208156581968069, "Avg value loss": 0.457436672586482, "Avg policy loss": 0.36337898252531886, "Total num played games": 34452, "Total num trained steps": 68352, "Timestamp in ms": 1701832136237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822844902448908, "Avg loss": 0.8532516714185476, "Avg value loss": 0.4935160491731949, "Avg policy loss": 0.359735626145266, "Total num played games": 34546, "Total num trained steps": 68480, "Timestamp in ms": 1701832194841, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 161.43614790029824, "Avg game time in secs": 3.228731201350456, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.63}, "Total num played games": 34560, "Total num trained steps": 68585, "Timestamp in ms": 1701832239526, "logtype": "played_game"}
{"Total num played games": 34642, "Total num trained steps": 68601, "Timestamp in ms": 1701832306346, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.484375}
{"Ratio train steps to played games": 1.9790008076612438, "Avg loss": 0.8173492879141122, "Avg value loss": 0.47811219427967444, "Avg policy loss": 0.3392370952060446, "Total num played games": 34666, "Total num trained steps": 68608, "Timestamp in ms": 1701832309421, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 70.45145799964666, "Avg game time in secs": 2.870625567898969, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.6}, "Total num played games": 34688, "Total num trained steps": 68609, "Timestamp in ms": 1701832309977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788116075541224, "Avg loss": 1.6534563307650387, "Avg value loss": 1.2603967337636277, "Avg policy loss": 0.3930595878046006, "Total num played games": 34736, "Total num trained steps": 68736, "Timestamp in ms": 1701832364804, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824965453707968, "Avg loss": 0.4916325379163027, "Avg value loss": 0.14790869073476642, "Avg policy loss": 0.34372384496964514, "Total num played games": 34736, "Total num trained steps": 68864, "Timestamp in ms": 1701832422070, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 161.58787307329476, "Avg game time in secs": 3.2438029363111127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.69}, "Total num played games": 34816, "Total num trained steps": 68973, "Timestamp in ms": 1701832471565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807073954983923, "Avg loss": 0.7636617536190897, "Avg value loss": 0.4166559400036931, "Avg policy loss": 0.3470058103557676, "Total num played games": 34832, "Total num trained steps": 68992, "Timestamp in ms": 1701832479944, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843821773082224, "Avg loss": 0.631996797863394, "Avg value loss": 0.27068642753874883, "Avg policy loss": 0.36131036770530045, "Total num played games": 34832, "Total num trained steps": 69120, "Timestamp in ms": 1701832536351, "logtype": "training_step"}
{"Total num played games": 34928, "Total num trained steps": 69201, "Timestamp in ms": 1701832613307, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.375}
{"Avg objective": 20.828125, "Games time in secs": 144.04229105450213, "Avg game time in secs": 3.371189542056527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.69, "agent_stopped_0": 0.46}, "Total num played games": 34944, "Total num trained steps": 69205, "Timestamp in ms": 1701832615608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9772714293872422, "Avg loss": 1.310383120086044, "Avg value loss": 0.9355383032234386, "Avg policy loss": 0.3748448067344725, "Total num played games": 35022, "Total num trained steps": 69248, "Timestamp in ms": 1701832633836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980926274912912, "Avg loss": 0.628429957665503, "Avg value loss": 0.2503367299796082, "Avg policy loss": 0.37809322657994926, "Total num played games": 35022, "Total num trained steps": 69376, "Timestamp in ms": 1701832688947, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845811204385815, "Avg loss": 0.4784502817783505, "Avg value loss": 0.13841926428722218, "Avg policy loss": 0.34003101708367467, "Total num played games": 35022, "Total num trained steps": 69504, "Timestamp in ms": 1701832746910, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 148.40132790245116, "Avg game time in secs": 3.231363150916877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.53}, "Total num played games": 35072, "Total num trained steps": 69542, "Timestamp in ms": 1701832764009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827723674468933, "Avg loss": 0.8993834464345127, "Avg value loss": 0.5508649870753288, "Avg policy loss": 0.3485184528399259, "Total num played games": 35118, "Total num trained steps": 69632, "Timestamp in ms": 1701832805184, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 87.32540314644575, "Avg game time in secs": 3.422033780865604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.71, "agent_stopped_0": 0.43}, "Total num played games": 35200, "Total num trained steps": 69738, "Timestamp in ms": 1701832851335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811427922299216, "Avg loss": 0.8358879783190787, "Avg value loss": 0.4892445760197006, "Avg policy loss": 0.3466433996800333, "Total num played games": 35212, "Total num trained steps": 69760, "Timestamp in ms": 1701832860221, "logtype": "training_step"}
{"Total num played games": 35212, "Total num trained steps": 69801, "Timestamp in ms": 1701832926535, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.484375}
{"Ratio train steps to played games": 1.9794935704979324, "Avg loss": 1.1585535125341266, "Avg value loss": 0.79274176817853, "Avg policy loss": 0.3658117479644716, "Total num played games": 35306, "Total num trained steps": 69888, "Timestamp in ms": 1701832965272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830906928000906, "Avg loss": 0.5153362527489662, "Avg value loss": 0.17763340659439564, "Avg policy loss": 0.3377028483664617, "Total num played games": 35306, "Total num trained steps": 70016, "Timestamp in ms": 1701833021963, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 209.99425520002842, "Avg game time in secs": 3.138483187489328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.65, "agent_stopped_0": 0.52}, "Total num played games": 35328, "Total num trained steps": 70106, "Timestamp in ms": 1701833061329, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814689265536722, "Avg loss": 0.8288749565836042, "Avg value loss": 0.490648592938669, "Avg policy loss": 0.3382263566600159, "Total num played games": 35400, "Total num trained steps": 70144, "Timestamp in ms": 1701833077616, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850847457627119, "Avg loss": 0.5517777861095965, "Avg value loss": 0.2123799049295485, "Avg policy loss": 0.3393978801323101, "Total num played games": 35400, "Total num trained steps": 70272, "Timestamp in ms": 1701833133504, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 82.5678024161607, "Avg game time in secs": 2.855296207490028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 35456, "Total num trained steps": 70297, "Timestamp in ms": 1701833143897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983322064457967, "Avg loss": 0.8164739657659084, "Avg value loss": 0.46464910148642957, "Avg policy loss": 0.351824875571765, "Total num played games": 35496, "Total num trained steps": 70400, "Timestamp in ms": 1701833189445, "logtype": "training_step"}
{"Total num played games": 35496, "Total num trained steps": 70403, "Timestamp in ms": 1701833226350, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.984375}
{"Avg objective": 22.3359375, "Games time in secs": 89.77175986021757, "Avg game time in secs": 3.357569297470036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.72}, "Total num played games": 35584, "Total num trained steps": 70419, "Timestamp in ms": 1701833233669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981652149480191, "Avg loss": 0.975913522997871, "Avg value loss": 0.6310429825098254, "Avg policy loss": 0.3448705532355234, "Total num played games": 35590, "Total num trained steps": 70528, "Timestamp in ms": 1701833281014, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852767631357122, "Avg loss": 0.4444740323815495, "Avg value loss": 0.12191537831677124, "Avg policy loss": 0.3225586513290182, "Total num played games": 35590, "Total num trained steps": 70656, "Timestamp in ms": 1701833335763, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98352295017654, "Avg loss": 0.8719713520258665, "Avg value loss": 0.5359378273715265, "Avg policy loss": 0.33603352191857994, "Total num played games": 35686, "Total num trained steps": 70784, "Timestamp in ms": 1701833391821, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 194.01040099561214, "Avg game time in secs": 3.0333396991773043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.62, "agent_stopped_0": 0.5}, "Total num played games": 35712, "Total num trained steps": 70866, "Timestamp in ms": 1701833427679, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981667784484686, "Avg loss": 0.7456298726610839, "Avg value loss": 0.4173240831005387, "Avg policy loss": 0.3283057832159102, "Total num played games": 35784, "Total num trained steps": 70912, "Timestamp in ms": 1701833447016, "logtype": "training_step"}
{"Total num played games": 35784, "Total num trained steps": 71003, "Timestamp in ms": 1701833523806, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8359375}
{"Avg objective": 21.25, "Games time in secs": 99.80639420263469, "Avg game time in secs": 2.9825111933168955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.61}, "Total num played games": 35840, "Total num trained steps": 71011, "Timestamp in ms": 1701833527486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800434806845422, "Avg loss": 0.7550930820871145, "Avg value loss": 0.42684495518915355, "Avg policy loss": 0.3282481248024851, "Total num played games": 35878, "Total num trained steps": 71040, "Timestamp in ms": 1701833540742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836111265956853, "Avg loss": 0.5354760738555342, "Avg value loss": 0.20563269348349422, "Avg policy loss": 0.3298433825839311, "Total num played games": 35878, "Total num trained steps": 71168, "Timestamp in ms": 1701833597603, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 110.17178912460804, "Avg game time in secs": 3.2108322417043382, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.64}, "Total num played games": 35968, "Total num trained steps": 71261, "Timestamp in ms": 1701833637658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818757991883027, "Avg loss": 0.6931907299440354, "Avg value loss": 0.3705010086414404, "Avg policy loss": 0.3226897254353389, "Total num played games": 35974, "Total num trained steps": 71296, "Timestamp in ms": 1701833652463, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854061266470229, "Avg loss": 0.46703997487202287, "Avg value loss": 0.14794131822418422, "Avg policy loss": 0.31909865501802415, "Total num played games": 35974, "Total num trained steps": 71424, "Timestamp in ms": 1701833709538, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983698364291655, "Avg loss": 0.9737290642224252, "Avg value loss": 0.6496629104949534, "Avg policy loss": 0.32406616443768144, "Total num played games": 36070, "Total num trained steps": 71552, "Timestamp in ms": 1701833764310, "logtype": "training_step"}
{"Total num played games": 36070, "Total num trained steps": 71607, "Timestamp in ms": 1701833856492, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.31640625}
{"Avg objective": 22.5390625, "Games time in secs": 221.38704821281135, "Avg game time in secs": 2.7454919696756406, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.53, "agent_stopped_0": 0.54}, "Total num played games": 36096, "Total num trained steps": 71610, "Timestamp in ms": 1701833859045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820816281384803, "Avg loss": 0.8793085087090731, "Avg value loss": 0.5607913844287395, "Avg policy loss": 0.3185171274235472, "Total num played games": 36164, "Total num trained steps": 71680, "Timestamp in ms": 1701833889881, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985621059617299, "Avg loss": 0.45171788008883595, "Avg value loss": 0.1413575718179345, "Avg policy loss": 0.31036030780524015, "Total num played games": 36164, "Total num trained steps": 71808, "Timestamp in ms": 1701833944831, "logtype": "training_step"}
{"Avg objective": 22.859375, "Games time in secs": 93.86484275199473, "Avg game time in secs": 2.8435768069466576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.67, "agent_stopped_0": 0.48}, "Total num played games": 36224, "Total num trained steps": 71826, "Timestamp in ms": 1701833952910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838940981798125, "Avg loss": 0.8346083275973797, "Avg value loss": 0.5098717138171196, "Avg policy loss": 0.32473661471158266, "Total num played games": 36260, "Total num trained steps": 71936, "Timestamp in ms": 1701833999449, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 83.84760026820004, "Avg game time in secs": 3.297944347446901, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.8, "agent_stopped_0": 0.38}, "Total num played games": 36352, "Total num trained steps": 72024, "Timestamp in ms": 1701834036758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982176257013973, "Avg loss": 0.7933516753837466, "Avg value loss": 0.47903805022360757, "Avg policy loss": 0.31431362114381045, "Total num played games": 36356, "Total num trained steps": 72064, "Timestamp in ms": 1701834053423, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856694905930246, "Avg loss": 0.5026732604019344, "Avg value loss": 0.17476108897244558, "Avg policy loss": 0.32791217148769647, "Total num played games": 36356, "Total num trained steps": 72192, "Timestamp in ms": 1701834109623, "logtype": "training_step"}
{"Total num played games": 36452, "Total num trained steps": 72209, "Timestamp in ms": 1701834143403, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.75390625}
{"Avg objective": 22.46875, "Games time in secs": 109.46529023349285, "Avg game time in secs": 2.960402825541678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.7, "agent_stopped_0": 0.48}, "Total num played games": 36480, "Total num trained steps": 72214, "Timestamp in ms": 1701834146223, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978875937175067, "Avg loss": 1.492288984823972, "Avg value loss": 1.1243017184897326, "Avg policy loss": 0.36798725253902376, "Total num played games": 36546, "Total num trained steps": 72320, "Timestamp in ms": 1701834191568, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823783724621025, "Avg loss": 0.49287593900226057, "Avg value loss": 0.16413080773781985, "Avg policy loss": 0.32874513138085604, "Total num played games": 36546, "Total num trained steps": 72448, "Timestamp in ms": 1701834247974, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985880807749138, "Avg loss": 0.45224226638674736, "Avg value loss": 0.13246633851667866, "Avg policy loss": 0.3197759271133691, "Total num played games": 36546, "Total num trained steps": 72576, "Timestamp in ms": 1701834302824, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 162.20507581532001, "Avg game time in secs": 2.867149130339385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 36608, "Total num trained steps": 72589, "Timestamp in ms": 1701834308428, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841438786092462, "Avg loss": 0.7674791156314313, "Avg value loss": 0.4440083873923868, "Avg policy loss": 0.32347072823904455, "Total num played games": 36642, "Total num trained steps": 72704, "Timestamp in ms": 1701834359000, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 90.37076317332685, "Avg game time in secs": 3.2900113930663792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.72, "agent_stopped_0": 0.42}, "Total num played games": 36736, "Total num trained steps": 72792, "Timestamp in ms": 1701834398803, "logtype": "played_game"}
{"Total num played games": 36736, "Total num trained steps": 72811, "Timestamp in ms": 1701834455156, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1015625}
{"Ratio train steps to played games": 1.977518327450448, "Avg loss": 0.9843092318624258, "Avg value loss": 0.6558526771841571, "Avg policy loss": 0.3284565599169582, "Total num played games": 36830, "Total num trained steps": 72832, "Timestamp in ms": 1701834464951, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809937550909584, "Avg loss": 0.9596644348930568, "Avg value loss": 0.5917315134429373, "Avg policy loss": 0.3679329300066456, "Total num played games": 36830, "Total num trained steps": 72960, "Timestamp in ms": 1701834521565, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844420309530275, "Avg loss": 0.44552537566050887, "Avg value loss": 0.12466719641815871, "Avg policy loss": 0.3208581832004711, "Total num played games": 36830, "Total num trained steps": 73088, "Timestamp in ms": 1701834576340, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 207.97831882722676, "Avg game time in secs": 2.871454756023013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.59, "agent_stopped_0": 0.54}, "Total num played games": 36864, "Total num trained steps": 73154, "Timestamp in ms": 1701834606782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827763635378866, "Avg loss": 0.7485947266686708, "Avg value loss": 0.4333495991304517, "Avg policy loss": 0.3152451324276626, "Total num played games": 36926, "Total num trained steps": 73216, "Timestamp in ms": 1701834634251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985892992526806, "Avg loss": 0.46387051534838974, "Avg value loss": 0.1512733107083477, "Avg policy loss": 0.31259720225352794, "Total num played games": 36932, "Total num trained steps": 73344, "Timestamp in ms": 1701834692554, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 88.92919998802245, "Avg game time in secs": 2.930146038212115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.67}, "Total num played games": 36992, "Total num trained steps": 73352, "Timestamp in ms": 1701834695711, "logtype": "played_game"}
{"Total num played games": 37020, "Total num trained steps": 73412, "Timestamp in ms": 1701834752058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.09765625}
{"Ratio train steps to played games": 1.979630328178046, "Avg loss": 1.3082579819019884, "Avg value loss": 0.9770422106375918, "Avg policy loss": 0.33121577103156596, "Total num played games": 37114, "Total num trained steps": 73472, "Timestamp in ms": 1701834779992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830522174920515, "Avg loss": 0.505311218323186, "Avg value loss": 0.18657430907478556, "Avg policy loss": 0.31873690604697913, "Total num played games": 37114, "Total num trained steps": 73600, "Timestamp in ms": 1701834837316, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 194.14407701604068, "Avg game time in secs": 3.563230977320927, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.73, "agent_stopped_0": 0.42}, "Total num played games": 37120, "Total num trained steps": 73720, "Timestamp in ms": 1701834889855, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831082898488352, "Avg loss": 0.45750155532732606, "Avg value loss": 0.162565479404293, "Avg policy loss": 0.29493607301265, "Total num played games": 37180, "Total num trained steps": 73728, "Timestamp in ms": 1701834892608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848427841977963, "Avg loss": 0.6375460855197161, "Avg value loss": 0.31470514746615663, "Avg policy loss": 0.322840936249122, "Total num played games": 37210, "Total num trained steps": 73856, "Timestamp in ms": 1701834948220, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 84.4700648020953, "Avg game time in secs": 2.764702125059557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.56}, "Total num played games": 37248, "Total num trained steps": 73916, "Timestamp in ms": 1701834974326, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832725713060262, "Avg loss": 0.6265189310070127, "Avg value loss": 0.31959367834497243, "Avg policy loss": 0.3069252517307177, "Total num played games": 37304, "Total num trained steps": 73984, "Timestamp in ms": 1701835003351, "logtype": "training_step"}
{"Total num played games": 37304, "Total num trained steps": 74016, "Timestamp in ms": 1701835063777, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4453125}
{"Avg objective": 21.390625, "Games time in secs": 94.56391434930265, "Avg game time in secs": 3.0086417905404232, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.72, "agent_stopped_0": 0.45}, "Total num played games": 37376, "Total num trained steps": 74026, "Timestamp in ms": 1701835068890, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816835124872987, "Avg loss": 0.9185103897470981, "Avg value loss": 0.5857177079888061, "Avg policy loss": 0.33279267617035657, "Total num played games": 37398, "Total num trained steps": 74112, "Timestamp in ms": 1701835107589, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985132894807209, "Avg loss": 0.4526071718428284, "Avg value loss": 0.13832871144404635, "Avg policy loss": 0.31427846068982035, "Total num played games": 37398, "Total num trained steps": 74240, "Timestamp in ms": 1701835164088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834640209100123, "Avg loss": 0.7675442872568965, "Avg value loss": 0.4403711391496472, "Avg policy loss": 0.3271731468848884, "Total num played games": 37494, "Total num trained steps": 74368, "Timestamp in ms": 1701835220451, "logtype": "training_step"}
{"Avg objective": 20.40625, "Games time in secs": 199.79193302616477, "Avg game time in secs": 3.3025230860657757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.76, "agent_stopped_0": 0.45}, "Total num played games": 37504, "Total num trained steps": 74481, "Timestamp in ms": 1701835268682, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981882515696499, "Avg loss": 0.5750362426042557, "Avg value loss": 0.2604890701477416, "Avg policy loss": 0.3145471728639677, "Total num played games": 37588, "Total num trained steps": 74496, "Timestamp in ms": 1701835275395, "logtype": "training_step"}
{"Total num played games": 37590, "Total num trained steps": 74620, "Timestamp in ms": 1701835348742, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6640625}
{"Ratio train steps to played games": 1.9846808510638299, "Avg loss": 0.6664071169216186, "Avg value loss": 0.3393200119026005, "Avg policy loss": 0.32708711025770754, "Total num played games": 37600, "Total num trained steps": 74624, "Timestamp in ms": 1701835351173, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 83.43166565150023, "Avg game time in secs": 2.697532354184659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.66, "agent_stopped_0": 0.48}, "Total num played games": 37632, "Total num trained steps": 74626, "Timestamp in ms": 1701835352114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983627003502813, "Avg loss": 0.6990588237531483, "Avg value loss": 0.35731677763396874, "Avg policy loss": 0.3417420438490808, "Total num played games": 37684, "Total num trained steps": 74752, "Timestamp in ms": 1701835407572, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 103.91402640752494, "Avg game time in secs": 2.791109789002803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.65, "agent_stopped_0": 0.48}, "Total num played games": 37760, "Total num trained steps": 74868, "Timestamp in ms": 1701835456028, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821059876118376, "Avg loss": 0.6030491567216814, "Avg value loss": 0.28178326826309785, "Avg policy loss": 0.32126588944811374, "Total num played games": 37778, "Total num trained steps": 74880, "Timestamp in ms": 1701835460983, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854942029752767, "Avg loss": 0.6377352266572416, "Avg value loss": 0.3071686018956825, "Avg policy loss": 0.3305666275555268, "Total num played games": 37778, "Total num trained steps": 75008, "Timestamp in ms": 1701835516273, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838411575223107, "Avg loss": 0.9925566338934004, "Avg value loss": 0.6666750688455068, "Avg policy loss": 0.325881564989686, "Total num played games": 37874, "Total num trained steps": 75136, "Timestamp in ms": 1701835570948, "logtype": "training_step"}
{"Total num played games": 37874, "Total num trained steps": 75224, "Timestamp in ms": 1701835640132, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.86328125}
{"Avg objective": 21.5546875, "Games time in secs": 186.54206989519298, "Avg game time in secs": 2.8156975322199287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.63, "agent_stopped_0": 0.48}, "Total num played games": 37888, "Total num trained steps": 75229, "Timestamp in ms": 1701835642570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823008849557522, "Avg loss": 0.675731064286083, "Avg value loss": 0.3537495543132536, "Avg policy loss": 0.32198151329066604, "Total num played games": 37968, "Total num trained steps": 75264, "Timestamp in ms": 1701835657931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856721449641803, "Avg loss": 0.476250640116632, "Avg value loss": 0.16231885005254298, "Avg policy loss": 0.31393178761936724, "Total num played games": 37968, "Total num trained steps": 75392, "Timestamp in ms": 1701835713012, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 86.11370320431888, "Avg game time in secs": 2.661466801975621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.58, "agent_stopped_0": 0.53}, "Total num played games": 38016, "Total num trained steps": 75431, "Timestamp in ms": 1701835728684, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841048815091167, "Avg loss": 0.6423491358291358, "Avg value loss": 0.3279989039292559, "Avg policy loss": 0.3143502325983718, "Total num played games": 38062, "Total num trained steps": 75520, "Timestamp in ms": 1701835766871, "logtype": "training_step"}
{"Avg objective": 21.5234375, "Games time in secs": 81.59720073081553, "Avg game time in secs": 2.7801768596254988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 38144, "Total num trained steps": 75624, "Timestamp in ms": 1701835810281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824938413962996, "Avg loss": 0.6532431279774755, "Avg value loss": 0.335251530748792, "Avg policy loss": 0.3179916023509577, "Total num played games": 38158, "Total num trained steps": 75648, "Timestamp in ms": 1701835822047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858483149012003, "Avg loss": 0.5333886079024523, "Avg value loss": 0.19087848550407216, "Avg policy loss": 0.3425101274624467, "Total num played games": 38158, "Total num trained steps": 75776, "Timestamp in ms": 1701835877477, "logtype": "training_step"}
{"Total num played games": 38256, "Total num trained steps": 75825, "Timestamp in ms": 1701835923258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.515625}
{"Avg objective": 21.8984375, "Games time in secs": 115.12437227740884, "Avg game time in secs": 2.7240367743070237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.6, "agent_stopped_0": 0.54}, "Total num played games": 38272, "Total num trained steps": 75829, "Timestamp in ms": 1701835925406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792438070404172, "Avg loss": 1.3151383087970316, "Avg value loss": 0.955633822013624, "Avg policy loss": 0.359504473162815, "Total num played games": 38350, "Total num trained steps": 75904, "Timestamp in ms": 1701835957970, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825814863103, "Avg loss": 0.4956233149860054, "Avg value loss": 0.14786235679639503, "Avg policy loss": 0.3477609606925398, "Total num played games": 38350, "Total num trained steps": 76032, "Timestamp in ms": 1701836013696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859191655801824, "Avg loss": 0.4351073189172894, "Avg value loss": 0.10653573117451742, "Avg policy loss": 0.3285715866368264, "Total num played games": 38350, "Total num trained steps": 76160, "Timestamp in ms": 1701836070201, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 160.63727314770222, "Avg game time in secs": 2.5193188149569323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 38400, "Total num trained steps": 76195, "Timestamp in ms": 1701836086043, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840572171651496, "Avg loss": 0.9832809793297201, "Avg value loss": 0.6355785102350637, "Avg policy loss": 0.3477024727035314, "Total num played games": 38450, "Total num trained steps": 76288, "Timestamp in ms": 1701836126768, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 86.86799291148782, "Avg game time in secs": 2.7035800366284093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.65}, "Total num played games": 38528, "Total num trained steps": 76398, "Timestamp in ms": 1701836172911, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9825653798256537, "Avg loss": 0.8347521098330617, "Avg value loss": 0.498926991072949, "Avg policy loss": 0.33582511986605823, "Total num played games": 38544, "Total num trained steps": 76416, "Timestamp in ms": 1701836181184, "logtype": "training_step"}
{"Total num played games": 38544, "Total num trained steps": 76425, "Timestamp in ms": 1701836203833, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0390625}
{"Ratio train steps to played games": 1.9810549200269165, "Avg loss": 1.133776354137808, "Avg value loss": 0.7466456715483218, "Avg policy loss": 0.38713069446384907, "Total num played games": 38638, "Total num trained steps": 76544, "Timestamp in ms": 1701836254811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984341839639733, "Avg loss": 0.4742038077674806, "Avg value loss": 0.12470177095383406, "Avg policy loss": 0.3495020344853401, "Total num played games": 38638, "Total num trained steps": 76672, "Timestamp in ms": 1701836312038, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 180.65452218987048, "Avg game time in secs": 2.8855680626729736, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.7, "agent_stopped_0": 0.46}, "Total num played games": 38656, "Total num trained steps": 76769, "Timestamp in ms": 1701836353566, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827541694635205, "Avg loss": 0.8840308820363134, "Avg value loss": 0.5328575392486528, "Avg policy loss": 0.35117335175164044, "Total num played games": 38734, "Total num trained steps": 76800, "Timestamp in ms": 1701836367215, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860329426343781, "Avg loss": 0.6230068933218718, "Avg value loss": 0.26560742704896256, "Avg policy loss": 0.3573994680773467, "Total num played games": 38734, "Total num trained steps": 76928, "Timestamp in ms": 1701836425328, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 87.10642606578767, "Avg game time in secs": 2.1689017258759122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.46, "agent_stopped_0": 0.61}, "Total num played games": 38784, "Total num trained steps": 76963, "Timestamp in ms": 1701836440673, "logtype": "played_game"}
{"Total num played games": 38828, "Total num trained steps": 77025, "Timestamp in ms": 1701836548117, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.78125}
{"Avg objective": 22.0234375, "Games time in secs": 115.04428449086845, "Avg game time in secs": 3.075297607734683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.7, "agent_stopped_0": 0.45}, "Total num played games": 38912, "Total num trained steps": 77041, "Timestamp in ms": 1701836555717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9797543805559839, "Avg loss": 1.1085421880707145, "Avg value loss": 0.7520635224645957, "Avg policy loss": 0.35647866781800985, "Total num played games": 38922, "Total num trained steps": 77056, "Timestamp in ms": 1701836562398, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830430090951132, "Avg loss": 0.6086510478053242, "Avg value loss": 0.2493457374512218, "Avg policy loss": 0.3593053137883544, "Total num played games": 38922, "Total num trained steps": 77184, "Timestamp in ms": 1701836618205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863059452237808, "Avg loss": 0.44898399990051985, "Avg value loss": 0.11143670135061257, "Avg policy loss": 0.33754730003420264, "Total num played games": 38922, "Total num trained steps": 77312, "Timestamp in ms": 1701836673928, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847249987185402, "Avg loss": 1.0012256423942745, "Avg value loss": 0.6415162003249861, "Avg policy loss": 0.35970944445580244, "Total num played games": 39018, "Total num trained steps": 77440, "Timestamp in ms": 1701836728070, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 210.22013515606523, "Avg game time in secs": 2.5577709853823762, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.55, "agent_stopped_0": 0.58}, "Total num played games": 39040, "Total num trained steps": 77530, "Timestamp in ms": 1701836765938, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831262463568031, "Avg loss": 0.7896883182693273, "Avg value loss": 0.44182264886330813, "Avg policy loss": 0.3478656660299748, "Total num played games": 39114, "Total num trained steps": 77568, "Timestamp in ms": 1701836781280, "logtype": "training_step"}
{"Total num played games": 39114, "Total num trained steps": 77627, "Timestamp in ms": 1701836883122, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.78515625}
{"Avg objective": 22.21875, "Games time in secs": 120.40974705480039, "Avg game time in secs": 2.6974599081877386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.6}, "Total num played games": 39168, "Total num trained steps": 77634, "Timestamp in ms": 1701836886348, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981636400734544, "Avg loss": 1.0311352703720331, "Avg value loss": 0.6646957062184811, "Avg policy loss": 0.36643955088220537, "Total num played games": 39208, "Total num trained steps": 77696, "Timestamp in ms": 1701836914823, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849010406039584, "Avg loss": 0.48858265159651637, "Avg value loss": 0.14747408736729994, "Avg policy loss": 0.34110856405459344, "Total num played games": 39208, "Total num trained steps": 77824, "Timestamp in ms": 1701836971345, "logtype": "training_step"}
{"Avg objective": 22.390625, "Games time in secs": 126.88245873712003, "Avg game time in secs": 2.7334003179130377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.64}, "Total num played games": 39296, "Total num trained steps": 77918, "Timestamp in ms": 1701837013230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98328414410747, "Avg loss": 0.6922239840496331, "Avg value loss": 0.35810205043526366, "Avg policy loss": 0.33412193681579083, "Total num played games": 39304, "Total num trained steps": 77952, "Timestamp in ms": 1701837026917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865408100956645, "Avg loss": 0.47742399433627725, "Avg value loss": 0.14457967464113608, "Avg policy loss": 0.33284431835636497, "Total num played games": 39304, "Total num trained steps": 78080, "Timestamp in ms": 1701837083706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98497461928934, "Avg loss": 0.6554107887204736, "Avg value loss": 0.31363499513827264, "Avg policy loss": 0.3417757893912494, "Total num played games": 39400, "Total num trained steps": 78208, "Timestamp in ms": 1701837140239, "logtype": "training_step"}
{"Total num played games": 39400, "Total num trained steps": 78227, "Timestamp in ms": 1701837216220, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.578125}
{"Avg objective": 20.7890625, "Games time in secs": 205.48320046439767, "Avg game time in secs": 2.4686903294932563, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.58, "agent_stopped_0": 0.51}, "Total num played games": 39424, "Total num trained steps": 78230, "Timestamp in ms": 1701837218714, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834911632146655, "Avg loss": 1.177230425644666, "Avg value loss": 0.8231583879096434, "Avg policy loss": 0.35407204437069595, "Total num played games": 39494, "Total num trained steps": 78336, "Timestamp in ms": 1701837263726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867321618473692, "Avg loss": 0.4434702591970563, "Avg value loss": 0.10876177996397018, "Avg policy loss": 0.3347084774868563, "Total num played games": 39494, "Total num trained steps": 78464, "Timestamp in ms": 1701837318180, "logtype": "training_step"}
{"Avg objective": 23.109375, "Games time in secs": 108.51143683306873, "Avg game time in secs": 2.5438236537011107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.73, "agent_stopped_0": 0.39}, "Total num played games": 39552, "Total num trained steps": 78486, "Timestamp in ms": 1701837327225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985147764587017, "Avg loss": 1.010831412160769, "Avg value loss": 0.6647846162086353, "Avg policy loss": 0.3460467985132709, "Total num played games": 39590, "Total num trained steps": 78592, "Timestamp in ms": 1701837373982, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 85.8568065315485, "Avg game time in secs": 2.937108074896969, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.66, "agent_stopped_0": 0.46}, "Total num played games": 39680, "Total num trained steps": 78682, "Timestamp in ms": 1701837413082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835710326059568, "Avg loss": 0.7716196067631245, "Avg value loss": 0.4318404845544137, "Avg policy loss": 0.3397791178431362, "Total num played games": 39686, "Total num trained steps": 78720, "Timestamp in ms": 1701837428594, "logtype": "training_step"}
{"Total num played games": 39686, "Total num trained steps": 78828, "Timestamp in ms": 1701837521471, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.28515625}
{"Ratio train steps to played games": 1.9821015585721469, "Avg loss": 0.8173062847927213, "Avg value loss": 0.48210022470448166, "Avg policy loss": 0.33520606823731214, "Total num played games": 39780, "Total num trained steps": 78848, "Timestamp in ms": 1701837531117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852941176470589, "Avg loss": 0.8044600621797144, "Avg value loss": 0.4542140217963606, "Avg policy loss": 0.35024604108184576, "Total num played games": 39780, "Total num trained steps": 78976, "Timestamp in ms": 1701837586367, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 207.36402598023415, "Avg game time in secs": 2.5839119796000887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 39808, "Total num trained steps": 79054, "Timestamp in ms": 1701837620446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983749623833885, "Avg loss": 0.8967280520591885, "Avg value loss": 0.5598337652627379, "Avg policy loss": 0.336894299602136, "Total num played games": 39876, "Total num trained steps": 79104, "Timestamp in ms": 1701837642139, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869595746815127, "Avg loss": 0.47759797098115087, "Avg value loss": 0.1426602370920591, "Avg policy loss": 0.3349377355771139, "Total num played games": 39876, "Total num trained steps": 79232, "Timestamp in ms": 1701837698585, "logtype": "training_step"}
{"Avg objective": 22.0390625, "Games time in secs": 85.03072335757315, "Avg game time in secs": 2.468798148649512, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 39936, "Total num trained steps": 79248, "Timestamp in ms": 1701837705477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853897728409886, "Avg loss": 0.7744333175942302, "Avg value loss": 0.42994360922602937, "Avg policy loss": 0.34448970784433186, "Total num played games": 39972, "Total num trained steps": 79360, "Timestamp in ms": 1701837753400, "logtype": "training_step"}
{"Total num played games": 39972, "Total num trained steps": 79430, "Timestamp in ms": 1701837813077, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0546875}
{"Avg objective": 20.859375, "Games time in secs": 115.0887648910284, "Avg game time in secs": 2.8629489379090955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.72}, "Total num played games": 40064, "Total num trained steps": 79447, "Timestamp in ms": 1701837820566, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983802535689328, "Avg loss": 0.6299290570896119, "Avg value loss": 0.30125524202594534, "Avg policy loss": 0.3286738129099831, "Total num played games": 40068, "Total num trained steps": 79488, "Timestamp in ms": 1701837838837, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870220624937607, "Avg loss": 0.4627633753698319, "Avg value loss": 0.13329384208191186, "Avg policy loss": 0.32946953491773456, "Total num played games": 40068, "Total num trained steps": 79616, "Timestamp in ms": 1701837895176, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985459615576138, "Avg loss": 0.82234176248312, "Avg value loss": 0.49132025823928416, "Avg policy loss": 0.33102150191552937, "Total num played games": 40164, "Total num trained steps": 79744, "Timestamp in ms": 1701837950801, "logtype": "training_step"}
{"Avg objective": 21.2578125, "Games time in secs": 165.1559035424143, "Avg game time in secs": 2.753235005395254, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.55, "agent_stopped_0": 0.58}, "Total num played games": 40192, "Total num trained steps": 79821, "Timestamp in ms": 1701837985722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839046199701937, "Avg loss": 0.745840473100543, "Avg value loss": 0.42433452093973756, "Avg policy loss": 0.3215059580979869, "Total num played games": 40260, "Total num trained steps": 79872, "Timestamp in ms": 1701838006703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987083954297069, "Avg loss": 0.4818613175302744, "Avg value loss": 0.15222721453756094, "Avg policy loss": 0.32963410078082234, "Total num played games": 40260, "Total num trained steps": 80000, "Timestamp in ms": 1701838063176, "logtype": "training_step"}
{"Avg objective": 22.09375, "Games time in secs": 84.59920098260045, "Avg game time in secs": 2.5332542323158123, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 40320, "Total num trained steps": 80016, "Timestamp in ms": 1701838070321, "logtype": "played_game"}
{"Total num played games": 40354, "Total num trained steps": 80034, "Timestamp in ms": 1701838094200, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1640625}
{"Avg objective": 21.546875, "Games time in secs": 34.988350454717875, "Avg game time in secs": 3.2728513442270923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.86}, "Total num played games": 40448, "Total num trained steps": 80059, "Timestamp in ms": 1701838105310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981012658227848, "Avg loss": 1.256444266764447, "Avg value loss": 0.8960919933160767, "Avg policy loss": 0.3603522649500519, "Total num played games": 40448, "Total num trained steps": 80128, "Timestamp in ms": 1701838135552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841772151898733, "Avg loss": 0.4826937133911997, "Avg value loss": 0.14417802396928892, "Avg policy loss": 0.3385156880831346, "Total num played games": 40448, "Total num trained steps": 80256, "Timestamp in ms": 1701838190429, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873417721518987, "Avg loss": 0.4204867302905768, "Avg value loss": 0.10279320139670745, "Avg policy loss": 0.3176935277879238, "Total num played games": 40448, "Total num trained steps": 80384, "Timestamp in ms": 1701838247606, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858911745843817, "Avg loss": 0.8008941027801484, "Avg value loss": 0.46705631329678, "Avg policy loss": 0.33383779239375144, "Total num played games": 40542, "Total num trained steps": 80512, "Timestamp in ms": 1701838303316, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 226.92730174027383, "Avg game time in secs": 2.372652676378493, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 40576, "Total num trained steps": 80578, "Timestamp in ms": 1701838332237, "logtype": "played_game"}
{"Total num played games": 40638, "Total num trained steps": 80638, "Timestamp in ms": 1701838382805, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.97265625}
{"Ratio train steps to played games": 1.984251968503937, "Avg loss": 0.8135822112672031, "Avg value loss": 0.47542598540894687, "Avg policy loss": 0.3381562262075022, "Total num played games": 40640, "Total num trained steps": 80640, "Timestamp in ms": 1701838383846, "logtype": "training_step"}
{"Avg objective": 22.703125, "Games time in secs": 54.19251199066639, "Avg game time in secs": 2.4215656524902442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.66, "agent_stopped_0": 0.44}, "Total num played games": 40704, "Total num trained steps": 80647, "Timestamp in ms": 1701838386430, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828881469115192, "Avg loss": 0.9891607780009508, "Avg value loss": 0.6224395442986861, "Avg policy loss": 0.3667212277650833, "Total num played games": 40732, "Total num trained steps": 80768, "Timestamp in ms": 1701838439698, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860551900225867, "Avg loss": 0.4530746832024306, "Avg value loss": 0.1153508901479654, "Avg policy loss": 0.33772379509173334, "Total num played games": 40732, "Total num trained steps": 80896, "Timestamp in ms": 1701838497979, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846176456179885, "Avg loss": 0.806240483187139, "Avg value loss": 0.46787872473942116, "Avg policy loss": 0.3383617515210062, "Total num played games": 40826, "Total num trained steps": 81024, "Timestamp in ms": 1701838554381, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 220.81995854340494, "Avg game time in secs": 2.586393996811239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.62}, "Total num played games": 40832, "Total num trained steps": 81141, "Timestamp in ms": 1701838607250, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983283640451635, "Avg loss": 0.6342494941782206, "Avg value loss": 0.30561397853307426, "Avg policy loss": 0.32863552402704954, "Total num played games": 40918, "Total num trained steps": 81152, "Timestamp in ms": 1701838613065, "logtype": "training_step"}
{"Total num played games": 40920, "Total num trained steps": 81238, "Timestamp in ms": 1701838668561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4609375}
{"Avg objective": 21.4140625, "Games time in secs": 64.43801478482783, "Avg game time in secs": 2.216923731859424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.58}, "Total num played games": 40960, "Total num trained steps": 81243, "Timestamp in ms": 1701838671688, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9817623250597356, "Avg loss": 0.857156434096396, "Avg value loss": 0.50623575784266, "Avg policy loss": 0.3509206746239215, "Total num played games": 41014, "Total num trained steps": 81280, "Timestamp in ms": 1701838687858, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848832106110108, "Avg loss": 0.49222794850356877, "Avg value loss": 0.1520456884172745, "Avg policy loss": 0.34018225769978017, "Total num played games": 41014, "Total num trained steps": 81408, "Timestamp in ms": 1701838742227, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 120.77391160279512, "Avg game time in secs": 2.746989930878044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 41088, "Total num trained steps": 81526, "Timestamp in ms": 1701838792462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834582076481464, "Avg loss": 0.5555917026940733, "Avg value loss": 0.22380771563621238, "Avg policy loss": 0.33178398583550006, "Total num played games": 41108, "Total num trained steps": 81536, "Timestamp in ms": 1701838796435, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865719567967306, "Avg loss": 0.6782497810199857, "Avg value loss": 0.34036290034418926, "Avg policy loss": 0.33788688224740326, "Total num played games": 41108, "Total num trained steps": 81664, "Timestamp in ms": 1701838849221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851463521188293, "Avg loss": 0.6466564550064504, "Avg value loss": 0.31749819993274286, "Avg policy loss": 0.3291582551319152, "Total num played games": 41202, "Total num trained steps": 81792, "Timestamp in ms": 1701838905278, "logtype": "training_step"}
{"Total num played games": 41202, "Total num trained steps": 81839, "Timestamp in ms": 1701838988020, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.09375}
{"Avg objective": 21.375, "Games time in secs": 197.46292325109243, "Avg game time in secs": 2.61695508378034, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.71, "agent_stopped_0": 0.43}, "Total num played games": 41216, "Total num trained steps": 81841, "Timestamp in ms": 1701838989925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837272375048431, "Avg loss": 0.8304115615319461, "Avg value loss": 0.5011910710018128, "Avg policy loss": 0.32922048144973814, "Total num played games": 41296, "Total num trained steps": 81920, "Timestamp in ms": 1701839025146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868268113134444, "Avg loss": 0.42604322265833616, "Avg value loss": 0.10817222238983959, "Avg policy loss": 0.3178709972416982, "Total num played games": 41296, "Total num trained steps": 82048, "Timestamp in ms": 1701839082303, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 109.1098420061171, "Avg game time in secs": 2.2556537588097854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.57}, "Total num played games": 41344, "Total num trained steps": 82087, "Timestamp in ms": 1701839099035, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985287011982992, "Avg loss": 0.7460830225609243, "Avg value loss": 0.42713244061451405, "Avg policy loss": 0.318950577522628, "Total num played games": 41392, "Total num trained steps": 82176, "Timestamp in ms": 1701839139434, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 84.19060921296477, "Avg game time in secs": 2.6074769725382794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.7}, "Total num played games": 41472, "Total num trained steps": 82282, "Timestamp in ms": 1701839183226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838981825194042, "Avg loss": 0.6706217783503234, "Avg value loss": 0.353524315985851, "Avg policy loss": 0.3170974615495652, "Total num played games": 41486, "Total num trained steps": 82304, "Timestamp in ms": 1701839192312, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869835607192787, "Avg loss": 0.5977523359470069, "Avg value loss": 0.2744873652118258, "Avg policy loss": 0.3232649676501751, "Total num played games": 41486, "Total num trained steps": 82432, "Timestamp in ms": 1701839247136, "logtype": "training_step"}
{"Total num played games": 41486, "Total num trained steps": 82443, "Timestamp in ms": 1701839305845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.46875}
{"Ratio train steps to played games": 1.9855699855699855, "Avg loss": 0.77210174780339, "Avg value loss": 0.448535842646379, "Avg policy loss": 0.3235659076599404, "Total num played games": 41580, "Total num trained steps": 82560, "Timestamp in ms": 1701839358448, "logtype": "training_step"}
{"Avg objective": 22.921875, "Games time in secs": 215.82258258387446, "Avg game time in secs": 2.415155644659535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 41600, "Total num trained steps": 82653, "Timestamp in ms": 1701839399048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840435742393703, "Avg loss": 0.6897540593054146, "Avg value loss": 0.38615988596575335, "Avg policy loss": 0.30359416850842535, "Total num played games": 41676, "Total num trained steps": 82688, "Timestamp in ms": 1701839414566, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871388808906805, "Avg loss": 0.4948372431099415, "Avg value loss": 0.17737647687317804, "Avg policy loss": 0.31746077141724527, "Total num played games": 41676, "Total num trained steps": 82816, "Timestamp in ms": 1701839471254, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 85.80020685866475, "Avg game time in secs": 2.370171714515891, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.6, "agent_stopped_0": 0.44}, "Total num played games": 41728, "Total num trained steps": 82847, "Timestamp in ms": 1701839484849, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985707445535073, "Avg loss": 0.7627067172434181, "Avg value loss": 0.45164825607207604, "Avg policy loss": 0.311058466671966, "Total num played games": 41770, "Total num trained steps": 82944, "Timestamp in ms": 1701839526526, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 83.0362604688853, "Avg game time in secs": 2.627306413007318, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 41856, "Total num trained steps": 83039, "Timestamp in ms": 1701839567885, "logtype": "played_game"}
{"Total num played games": 41866, "Total num trained steps": 83044, "Timestamp in ms": 1701839644880, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1796875}
{"Ratio train steps to played games": 1.9797902764537656, "Avg loss": 1.1464926211629063, "Avg value loss": 0.8414739184663631, "Avg policy loss": 0.3050186983309686, "Total num played games": 41960, "Total num trained steps": 83072, "Timestamp in ms": 1701839658212, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982840800762631, "Avg loss": 0.7730568740516901, "Avg value loss": 0.4436089637456462, "Avg policy loss": 0.3294479085598141, "Total num played games": 41960, "Total num trained steps": 83200, "Timestamp in ms": 1701839713884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858913250714967, "Avg loss": 0.39233537251129746, "Avg value loss": 0.10261713434010744, "Avg policy loss": 0.28971823723986745, "Total num played games": 41960, "Total num trained steps": 83328, "Timestamp in ms": 1701839771414, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 239.6479294039309, "Avg game time in secs": 2.430808857723605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.64, "agent_stopped_0": 0.46}, "Total num played games": 41984, "Total num trained steps": 83413, "Timestamp in ms": 1701839807533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844017500475557, "Avg loss": 0.7285378847736865, "Avg value loss": 0.432955377997132, "Avg policy loss": 0.29558250203263015, "Total num played games": 42056, "Total num trained steps": 83456, "Timestamp in ms": 1701839825421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874453110138863, "Avg loss": 0.469858075492084, "Avg value loss": 0.16156612621853128, "Avg policy loss": 0.3082919460721314, "Total num played games": 42056, "Total num trained steps": 83584, "Timestamp in ms": 1701839878559, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 80.53863517381251, "Avg game time in secs": 2.4159463387914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 42112, "Total num trained steps": 83607, "Timestamp in ms": 1701839888072, "logtype": "played_game"}
{"Total num played games": 42152, "Total num trained steps": 83644, "Timestamp in ms": 1701839949637, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4296875}
{"Avg objective": 21.7890625, "Games time in secs": 68.99177052080631, "Avg game time in secs": 2.833161089423811, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.75}, "Total num played games": 42240, "Total num trained steps": 83658, "Timestamp in ms": 1701839957064, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815367135350093, "Avg loss": 1.516764878295362, "Avg value loss": 1.1763172610662878, "Avg policy loss": 0.34044761629775167, "Total num played games": 42246, "Total num trained steps": 83712, "Timestamp in ms": 1701839979395, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845665861856743, "Avg loss": 0.49536367296241224, "Avg value loss": 0.17405886459164321, "Avg policy loss": 0.32130481069907546, "Total num played games": 42246, "Total num trained steps": 83840, "Timestamp in ms": 1701840036563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875964588363395, "Avg loss": 0.39363492256961763, "Avg value loss": 0.09907478553941473, "Avg policy loss": 0.294560136157088, "Total num played games": 42246, "Total num trained steps": 83968, "Timestamp in ms": 1701840091828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861130792121298, "Avg loss": 0.8786963834427297, "Avg value loss": 0.5696820449084044, "Avg policy loss": 0.30901433213148266, "Total num played games": 42342, "Total num trained steps": 84096, "Timestamp in ms": 1701840145982, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 224.44354294985533, "Avg game time in secs": 2.3524715568928514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.59, "agent_stopped_0": 0.58}, "Total num played games": 42368, "Total num trained steps": 84177, "Timestamp in ms": 1701840181507, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847299462720331, "Avg loss": 0.9017947094980627, "Avg value loss": 0.5965254024486057, "Avg policy loss": 0.3052693031495437, "Total num played games": 42436, "Total num trained steps": 84224, "Timestamp in ms": 1701840201665, "logtype": "training_step"}
{"Total num played games": 42436, "Total num trained steps": 84246, "Timestamp in ms": 1701840247664, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5390625}
{"Avg objective": 22.5859375, "Games time in secs": 69.34566539339721, "Avg game time in secs": 2.2406065759423655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.51, "agent_stopped_0": 0.54}, "Total num played games": 42496, "Total num trained steps": 84252, "Timestamp in ms": 1701840250853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833529273454031, "Avg loss": 1.0731222969479859, "Avg value loss": 0.748029216309078, "Avg policy loss": 0.3250930745853111, "Total num played games": 42530, "Total num trained steps": 84352, "Timestamp in ms": 1701840295121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863625675993417, "Avg loss": 0.43573220167309046, "Avg value loss": 0.1330669149174355, "Avg policy loss": 0.3026652857661247, "Total num played games": 42530, "Total num trained steps": 84480, "Timestamp in ms": 1701840351684, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 136.3630607817322, "Avg game time in secs": 2.4539383219816955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 42624, "Total num trained steps": 84561, "Timestamp in ms": 1701840387216, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847987238434832, "Avg loss": 0.6089063675608486, "Avg value loss": 0.30773837759625167, "Avg policy loss": 0.30116799171082675, "Total num played games": 42628, "Total num trained steps": 84608, "Timestamp in ms": 1701840409595, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877779863000844, "Avg loss": 0.4276399554219097, "Avg value loss": 0.12487071246141568, "Avg policy loss": 0.3027692437171936, "Total num played games": 42628, "Total num trained steps": 84736, "Timestamp in ms": 1701840469252, "logtype": "training_step"}
{"Total num played games": 42724, "Total num trained steps": 84850, "Timestamp in ms": 1701840575137, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.703125}
{"Avg objective": 20.9765625, "Games time in secs": 190.22474616393447, "Avg game time in secs": 2.3836412954260595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 42752, "Total num trained steps": 84855, "Timestamp in ms": 1701840577441, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98197019944883, "Avg loss": 0.9273347195703536, "Avg value loss": 0.6097547512035817, "Avg policy loss": 0.31757997756358236, "Total num played games": 42818, "Total num trained steps": 84864, "Timestamp in ms": 1701840580849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849595964314073, "Avg loss": 0.7049168506637216, "Avg value loss": 0.3806434584548697, "Avg policy loss": 0.32427340268623084, "Total num played games": 42818, "Total num trained steps": 84992, "Timestamp in ms": 1701840638079, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879489934139847, "Avg loss": 0.40039527462795377, "Avg value loss": 0.10017598990816623, "Avg policy loss": 0.30021928739733994, "Total num played games": 42818, "Total num trained steps": 85120, "Timestamp in ms": 1701840695752, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 123.27455553971231, "Avg game time in secs": 2.1587106410443084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.69}, "Total num played games": 42880, "Total num trained steps": 85131, "Timestamp in ms": 1701840700716, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865771812080537, "Avg loss": 1.00205281493254, "Avg value loss": 0.6709056112158578, "Avg policy loss": 0.3311472134664655, "Total num played games": 42912, "Total num trained steps": 85248, "Timestamp in ms": 1701840753420, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 88.46616678312421, "Avg game time in secs": 2.72837501912727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.8}, "Total num played games": 43008, "Total num trained steps": 85329, "Timestamp in ms": 1701840789183, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851190476190477, "Avg loss": 0.7939701152499765, "Avg value loss": 0.47282132162945345, "Avg policy loss": 0.32114878634456545, "Total num played games": 43008, "Total num trained steps": 85376, "Timestamp in ms": 1701840810429, "logtype": "training_step"}
{"Total num played games": 43008, "Total num trained steps": 85452, "Timestamp in ms": 1701840869294, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9296875}
{"Ratio train steps to played games": 1.983759454317665, "Avg loss": 0.7578673919197172, "Avg value loss": 0.43160543945850804, "Avg policy loss": 0.3262619574088603, "Total num played games": 43102, "Total num trained steps": 85504, "Timestamp in ms": 1701840891621, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867291540995777, "Avg loss": 0.45212985132820904, "Avg value loss": 0.14114235603483394, "Avg policy loss": 0.31098749476950616, "Total num played games": 43102, "Total num trained steps": 85632, "Timestamp in ms": 1701840951595, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 192.75504657439888, "Avg game time in secs": 2.1427506461477606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 43136, "Total num trained steps": 85698, "Timestamp in ms": 1701840981938, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853690156495971, "Avg loss": 0.746387847000733, "Avg value loss": 0.4360174792818725, "Avg policy loss": 0.3103703670203686, "Total num played games": 43196, "Total num trained steps": 85760, "Timestamp in ms": 1701841009950, "logtype": "training_step"}
{"Avg objective": 22.4765625, "Games time in secs": 83.40571405552328, "Avg game time in secs": 2.2210728466016008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.62, "agent_stopped_0": 0.49}, "Total num played games": 43264, "Total num trained steps": 85887, "Timestamp in ms": 1701841065344, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851153330559792, "Avg loss": 0.4636007668450475, "Avg value loss": 0.15304001740878448, "Avg policy loss": 0.3105607498437166, "Total num played games": 43264, "Total num trained steps": 85888, "Timestamp in ms": 1701841065447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868797930333548, "Avg loss": 0.6981054053176194, "Avg value loss": 0.37448781897546723, "Avg policy loss": 0.3236175945494324, "Total num played games": 43292, "Total num trained steps": 86016, "Timestamp in ms": 1701841120024, "logtype": "training_step"}
{"Total num played games": 43292, "Total num trained steps": 86053, "Timestamp in ms": 1701841173298, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.01171875}
{"Ratio train steps to played games": 1.9855252846540359, "Avg loss": 0.8657498981337994, "Avg value loss": 0.528316784359049, "Avg policy loss": 0.33743311057332903, "Total num played games": 43386, "Total num trained steps": 86144, "Timestamp in ms": 1701841216197, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 201.48613723926246, "Avg game time in secs": 2.4272181219857885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.76, "agent_stopped_0": 0.36}, "Total num played games": 43392, "Total num trained steps": 86264, "Timestamp in ms": 1701841266830, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845417740154583, "Avg loss": 0.4806624564807862, "Avg value loss": 0.16202142892871052, "Avg policy loss": 0.31864102627150714, "Total num played games": 43474, "Total num trained steps": 86272, "Timestamp in ms": 1701841269774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870291154960673, "Avg loss": 0.7579190949909389, "Avg value loss": 0.4282077437383123, "Avg policy loss": 0.3297113477019593, "Total num played games": 43482, "Total num trained steps": 86400, "Timestamp in ms": 1701841327498, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 86.49358919076622, "Avg game time in secs": 1.9901459415414138, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 43520, "Total num trained steps": 86456, "Timestamp in ms": 1701841353324, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855890586993437, "Avg loss": 0.7024958354886621, "Avg value loss": 0.37974678102182224, "Avg policy loss": 0.3227490510325879, "Total num played games": 43578, "Total num trained steps": 86528, "Timestamp in ms": 1701841386243, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 88.88632983528078, "Avg game time in secs": 2.061923927802127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.57, "agent_stopped_0": 0.49}, "Total num played games": 43648, "Total num trained steps": 86651, "Timestamp in ms": 1701841442210, "logtype": "played_game"}
{"Total num played games": 43674, "Total num trained steps": 86654, "Timestamp in ms": 1701841463878, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15625}
{"Ratio train steps to played games": 1.9840644747687517, "Avg loss": 0.4806611610110849, "Avg value loss": 0.16034866985864937, "Avg policy loss": 0.32031249336432666, "Total num played games": 43674, "Total num trained steps": 86656, "Timestamp in ms": 1701841465542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9828184975324439, "Avg loss": 1.1887699295766652, "Avg value loss": 0.8297412944375537, "Avg policy loss": 0.35902863275259733, "Total num played games": 43768, "Total num trained steps": 86784, "Timestamp in ms": 1701841524473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857430085907513, "Avg loss": 0.43376165977679193, "Avg value loss": 0.11083410400897264, "Avg policy loss": 0.3229275562334806, "Total num played games": 43768, "Total num trained steps": 86912, "Timestamp in ms": 1701841582136, "logtype": "training_step"}
{"Avg objective": 23.1484375, "Games time in secs": 191.90326027572155, "Avg game time in secs": 2.445076452611829, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.58}, "Total num played games": 43776, "Total num trained steps": 87028, "Timestamp in ms": 1701841634113, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984315155936531, "Avg loss": 0.5173768291715533, "Avg value loss": 0.21046822710195556, "Avg policy loss": 0.30690859886817634, "Total num played games": 43864, "Total num trained steps": 87040, "Timestamp in ms": 1701841638482, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872332664599672, "Avg loss": 0.6779518153052777, "Avg value loss": 0.34897851588902995, "Avg policy loss": 0.3289732947014272, "Total num played games": 43864, "Total num trained steps": 87168, "Timestamp in ms": 1701841694517, "logtype": "training_step"}
{"Avg objective": 22.7578125, "Games time in secs": 85.33691595867276, "Avg game time in secs": 2.0758114085765556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 43904, "Total num trained steps": 87222, "Timestamp in ms": 1701841719451, "logtype": "played_game"}
{"Total num played games": 43958, "Total num trained steps": 87254, "Timestamp in ms": 1701841824497, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.38671875}
{"Avg objective": 23.125, "Games time in secs": 108.82113098911941, "Avg game time in secs": 2.2244154380750842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 44032, "Total num trained steps": 87261, "Timestamp in ms": 1701841828272, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816580404975936, "Avg loss": 1.7358283707872033, "Avg value loss": 1.3946498288714793, "Avg policy loss": 0.3411785503849387, "Total num played games": 44052, "Total num trained steps": 87296, "Timestamp in ms": 1701841843791, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98456369744847, "Avg loss": 0.6427076999098063, "Avg value loss": 0.29630437219748273, "Avg policy loss": 0.3464033310301602, "Total num played games": 44052, "Total num trained steps": 87424, "Timestamp in ms": 1701841899470, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874466539544176, "Avg loss": 0.4111054081004113, "Avg value loss": 0.10330040304688737, "Avg policy loss": 0.3078050030162558, "Total num played games": 44052, "Total num trained steps": 87552, "Timestamp in ms": 1701841959212, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861369093462602, "Avg loss": 0.7703355283010751, "Avg value loss": 0.4576291990815662, "Avg policy loss": 0.31270632066298276, "Total num played games": 44146, "Total num trained steps": 87680, "Timestamp in ms": 1701842015366, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 234.29051771759987, "Avg game time in secs": 2.1759272787021473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 44160, "Total num trained steps": 87784, "Timestamp in ms": 1701842062562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846977984720402, "Avg loss": 0.685500297229737, "Avg value loss": 0.3768240563804284, "Avg policy loss": 0.30867623852100223, "Total num played games": 44242, "Total num trained steps": 87808, "Timestamp in ms": 1701842072837, "logtype": "training_step"}
{"Total num played games": 44242, "Total num trained steps": 87856, "Timestamp in ms": 1701842161957, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.66796875}
{"Avg objective": 21.765625, "Games time in secs": 101.6816132273525, "Avg game time in secs": 2.031099718544283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 44288, "Total num trained steps": 87859, "Timestamp in ms": 1701842164244, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983399494767232, "Avg loss": 0.9899553954601288, "Avg value loss": 0.6647784528322518, "Avg policy loss": 0.3251769507769495, "Total num played games": 44336, "Total num trained steps": 87936, "Timestamp in ms": 1701842199722, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862865391555395, "Avg loss": 0.4306404225062579, "Avg value loss": 0.12516632163897157, "Avg policy loss": 0.30547409737482667, "Total num played games": 44336, "Total num trained steps": 88064, "Timestamp in ms": 1701842254666, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 136.07531722076237, "Avg game time in secs": 2.2444666336959926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.64}, "Total num played games": 44416, "Total num trained steps": 88168, "Timestamp in ms": 1701842300320, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849651136619402, "Avg loss": 0.7091623002197593, "Avg value loss": 0.4132987561170012, "Avg policy loss": 0.2958635431714356, "Total num played games": 44430, "Total num trained steps": 88192, "Timestamp in ms": 1701842311023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987846049966239, "Avg loss": 0.61155866086483, "Avg value loss": 0.2919488804473076, "Avg policy loss": 0.3196097747422755, "Total num played games": 44430, "Total num trained steps": 88320, "Timestamp in ms": 1701842369728, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986434891973229, "Avg loss": 0.7665348160080612, "Avg value loss": 0.4413921273080632, "Avg policy loss": 0.3251426807837561, "Total num played games": 44526, "Total num trained steps": 88448, "Timestamp in ms": 1701842427659, "logtype": "training_step"}
{"Total num played games": 44526, "Total num trained steps": 88459, "Timestamp in ms": 1701842499729, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.58203125}
{"Avg objective": 22.0859375, "Games time in secs": 201.50966238602996, "Avg game time in secs": 2.226177204211126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 44544, "Total num trained steps": 88460, "Timestamp in ms": 1701842501829, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851187808157778, "Avg loss": 0.8787667241413146, "Avg value loss": 0.5460261858534068, "Avg policy loss": 0.33274054108187556, "Total num played games": 44620, "Total num trained steps": 88576, "Timestamp in ms": 1701842553696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987987449574182, "Avg loss": 0.4005938139744103, "Avg value loss": 0.09595821134280413, "Avg policy loss": 0.3046356003032997, "Total num played games": 44620, "Total num trained steps": 88704, "Timestamp in ms": 1701842608505, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 119.85460760444403, "Avg game time in secs": 2.2202874862850877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 44672, "Total num trained steps": 88734, "Timestamp in ms": 1701842621684, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866484769870734, "Avg loss": 0.6795040504075587, "Avg value loss": 0.3623968778701965, "Avg policy loss": 0.31710717210080475, "Total num played games": 44714, "Total num trained steps": 88832, "Timestamp in ms": 1701842666618, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 85.41321677528322, "Avg game time in secs": 2.1221007843414554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 44800, "Total num trained steps": 88925, "Timestamp in ms": 1701842707097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852488283865208, "Avg loss": 0.6130498016718775, "Avg value loss": 0.30054951255442575, "Avg policy loss": 0.31250029301736504, "Total num played games": 44810, "Total num trained steps": 88960, "Timestamp in ms": 1701842724513, "logtype": "training_step"}
{"Total num played games": 44810, "Total num trained steps": 89063, "Timestamp in ms": 1701842845878, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.95703125}
{"Ratio train steps to played games": 1.9839435239622305, "Avg loss": 0.6820210036821663, "Avg value loss": 0.3706720133777708, "Avg policy loss": 0.31134898914024234, "Total num played games": 44904, "Total num trained steps": 89088, "Timestamp in ms": 1701842858181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868163192588633, "Avg loss": 0.5769997197203338, "Avg value loss": 0.2516271756030619, "Avg policy loss": 0.32537253911141306, "Total num played games": 44904, "Total num trained steps": 89216, "Timestamp in ms": 1701842913049, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 242.63810793310404, "Avg game time in secs": 2.2152739645534893, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 44928, "Total num trained steps": 89299, "Timestamp in ms": 1701842949736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852235356857169, "Avg loss": 0.7468300543259829, "Avg value loss": 0.4355684954498429, "Avg policy loss": 0.3112615504069254, "Total num played games": 45004, "Total num trained steps": 89344, "Timestamp in ms": 1701842969418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988089947560217, "Avg loss": 0.47223070939071476, "Avg value loss": 0.16649144719121978, "Avg policy loss": 0.3057392662158236, "Total num played games": 45004, "Total num trained steps": 89472, "Timestamp in ms": 1701843028193, "logtype": "training_step"}
{"Avg objective": 20.5, "Games time in secs": 92.23427789285779, "Avg game time in secs": 2.0318629770190455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 45056, "Total num trained steps": 89502, "Timestamp in ms": 1701843041970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867621624018803, "Avg loss": 0.7014108181465417, "Avg value loss": 0.3912053366948385, "Avg policy loss": 0.3102054811315611, "Total num played games": 45098, "Total num trained steps": 89600, "Timestamp in ms": 1701843083705, "logtype": "training_step"}
{"Total num played games": 45098, "Total num trained steps": 89666, "Timestamp in ms": 1701843208248, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.01171875}
{"Avg objective": 21.640625, "Games time in secs": 170.2394197396934, "Avg game time in secs": 2.1037401414796477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 45184, "Total num trained steps": 89673, "Timestamp in ms": 1701843212210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985484156487874, "Avg loss": 0.760132645489648, "Avg value loss": 0.44982399861328304, "Avg policy loss": 0.3103086481569335, "Total num played games": 45192, "Total num trained steps": 89728, "Timestamp in ms": 1701843237464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883165161975571, "Avg loss": 0.4077319302596152, "Avg value loss": 0.11710322430008091, "Avg policy loss": 0.2906287022633478, "Total num played games": 45192, "Total num trained steps": 89856, "Timestamp in ms": 1701843293132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869281045751634, "Avg loss": 0.6286085303872824, "Avg value loss": 0.33337116619804874, "Avg policy loss": 0.2952373620355502, "Total num played games": 45288, "Total num trained steps": 89984, "Timestamp in ms": 1701843350998, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 175.79995067603886, "Avg game time in secs": 1.9958555786433863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 45312, "Total num trained steps": 90069, "Timestamp in ms": 1701843388010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855455667195487, "Avg loss": 0.6837737476453185, "Avg value loss": 0.39279795312904753, "Avg policy loss": 0.2909757997840643, "Total num played games": 45384, "Total num trained steps": 90112, "Timestamp in ms": 1701843407165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883659439450025, "Avg loss": 0.4460958018898964, "Avg value loss": 0.15536828787298873, "Avg policy loss": 0.2907275138422847, "Total num played games": 45384, "Total num trained steps": 90240, "Timestamp in ms": 1701843468739, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 90.34076512046158, "Avg game time in secs": 2.034784683783073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 45440, "Total num trained steps": 90263, "Timestamp in ms": 1701843478350, "logtype": "played_game"}
{"Total num played games": 45480, "Total num trained steps": 90268, "Timestamp in ms": 1701843546334, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8515625}
{"Avg objective": 21.1171875, "Games time in secs": 72.63622499629855, "Avg game time in secs": 2.507762897570501, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.75, "agent_stopped_0": 0.37}, "Total num played games": 45568, "Total num trained steps": 90277, "Timestamp in ms": 1701843550987, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828849782770879, "Avg loss": 1.3301132007036358, "Avg value loss": 0.9996085633174516, "Avg policy loss": 0.3305046398891136, "Total num played games": 45574, "Total num trained steps": 90368, "Timestamp in ms": 1701843592858, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856935972264889, "Avg loss": 0.4303301146719605, "Avg value loss": 0.13360075507080182, "Avg policy loss": 0.2967293589608744, "Total num played games": 45574, "Total num trained steps": 90496, "Timestamp in ms": 1701843646059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884802738403475, "Avg loss": 0.36471418861765414, "Avg value loss": 0.0822528891148977, "Avg policy loss": 0.2824612980475649, "Total num played games": 45574, "Total num trained steps": 90624, "Timestamp in ms": 1701843701483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872120522028554, "Avg loss": 0.8950976734049618, "Avg value loss": 0.5855161864310503, "Avg policy loss": 0.3095814884873107, "Total num played games": 45668, "Total num trained steps": 90752, "Timestamp in ms": 1701843757580, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 240.32468617334962, "Avg game time in secs": 2.067584834207082, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 45696, "Total num trained steps": 90829, "Timestamp in ms": 1701843791312, "logtype": "played_game"}
{"Total num played games": 45762, "Total num trained steps": 90868, "Timestamp in ms": 1701843890514, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.44140625}
{"Avg objective": 21.65625, "Games time in secs": 102.1776178535074, "Avg game time in secs": 1.991457390569849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.63, "agent_stopped_0": 0.4}, "Total num played games": 45824, "Total num trained steps": 90874, "Timestamp in ms": 1701843893489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818562456385207, "Avg loss": 0.850393534405157, "Avg value loss": 0.5451985806575976, "Avg policy loss": 0.3051949468208477, "Total num played games": 45856, "Total num trained steps": 90880, "Timestamp in ms": 1701843896023, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846475924633635, "Avg loss": 0.7912136050872505, "Avg value loss": 0.4622206662897952, "Avg policy loss": 0.3289929423481226, "Total num played games": 45856, "Total num trained steps": 91008, "Timestamp in ms": 1701843953505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874389392882066, "Avg loss": 0.36999870324507356, "Avg value loss": 0.08714764309115708, "Avg policy loss": 0.2828510570107028, "Total num played games": 45856, "Total num trained steps": 91136, "Timestamp in ms": 1701844006636, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986158868335147, "Avg loss": 0.6834059013053775, "Avg value loss": 0.39189265805180185, "Avg policy loss": 0.2915132484631613, "Total num played games": 45950, "Total num trained steps": 91264, "Timestamp in ms": 1701844064489, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 231.42460863105953, "Avg game time in secs": 2.3663140451244544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.72, "agent_stopped_0": 0.37}, "Total num played games": 45952, "Total num trained steps": 91390, "Timestamp in ms": 1701844124914, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887713800757278, "Avg loss": 0.36979766725562513, "Avg value loss": 0.09784434121684171, "Avg policy loss": 0.2719533278141171, "Total num played games": 45954, "Total num trained steps": 91392, "Timestamp in ms": 1701844125565, "logtype": "training_step"}
{"Total num played games": 46044, "Total num trained steps": 91469, "Timestamp in ms": 1701844169618, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3984375}
{"Avg objective": 21.7578125, "Games time in secs": 47.15931740961969, "Avg game time in secs": 1.9863630319014192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.56}, "Total num played games": 46080, "Total num trained steps": 91473, "Timestamp in ms": 1701844172073, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836143742684988, "Avg loss": 1.0628482701722533, "Avg value loss": 0.7535892057348974, "Avg policy loss": 0.30925906309857965, "Total num played games": 46138, "Total num trained steps": 91520, "Timestamp in ms": 1701844191924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863886601066365, "Avg loss": 0.45544686121866107, "Avg value loss": 0.14908330963226035, "Avg policy loss": 0.3063635496655479, "Total num played games": 46138, "Total num trained steps": 91648, "Timestamp in ms": 1701844248827, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 131.25215618871152, "Avg game time in secs": 1.9854738295543939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 46208, "Total num trained steps": 91772, "Timestamp in ms": 1701844303326, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850110308431024, "Avg loss": 0.45989460847340524, "Avg value loss": 0.17525209643645212, "Avg policy loss": 0.2846425058087334, "Total num played games": 46234, "Total num trained steps": 91776, "Timestamp in ms": 1701844305715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987801185274906, "Avg loss": 0.7370881107635796, "Avg value loss": 0.43255280557787046, "Avg policy loss": 0.3045353125780821, "Total num played games": 46234, "Total num trained steps": 91904, "Timestamp in ms": 1701844364728, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986445067990503, "Avg loss": 0.7648756535490975, "Avg value loss": 0.46044839872047305, "Avg policy loss": 0.30442724807653576, "Total num played games": 46330, "Total num trained steps": 92032, "Timestamp in ms": 1701844418032, "logtype": "training_step"}
{"Total num played games": 46330, "Total num trained steps": 92073, "Timestamp in ms": 1701844447610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5546875}
{"Avg objective": 22.25, "Games time in secs": 145.7848938666284, "Avg game time in secs": 2.0472584935632767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 46336, "Total num trained steps": 92075, "Timestamp in ms": 1701844449111, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851800792693435, "Avg loss": 0.8652655798941851, "Avg value loss": 0.5556090344325639, "Avg policy loss": 0.3096565513405949, "Total num played games": 46424, "Total num trained steps": 92160, "Timestamp in ms": 1701844486205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879372738238843, "Avg loss": 0.39297895738855004, "Avg value loss": 0.10287880577379838, "Avg policy loss": 0.29010015446692705, "Total num played games": 46424, "Total num trained steps": 92288, "Timestamp in ms": 1701844540945, "logtype": "training_step"}
{"Avg objective": 23.15625, "Games time in secs": 114.31436805799603, "Avg game time in secs": 1.8066455838270485, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 46464, "Total num trained steps": 92341, "Timestamp in ms": 1701844563425, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866718259598435, "Avg loss": 0.6471956836758181, "Avg value loss": 0.35063136683311313, "Avg policy loss": 0.2965643221978098, "Total num played games": 46518, "Total num trained steps": 92416, "Timestamp in ms": 1701844595558, "logtype": "training_step"}
{"Avg objective": 20.7109375, "Games time in secs": 82.37988416105509, "Avg game time in secs": 1.9993529323546682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 46592, "Total num trained steps": 92530, "Timestamp in ms": 1701844645805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985411482021797, "Avg loss": 0.5099931453587487, "Avg value loss": 0.22859046290977858, "Avg policy loss": 0.2814026827691123, "Total num played games": 46612, "Total num trained steps": 92544, "Timestamp in ms": 1701844651374, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881575559941647, "Avg loss": 0.5543855652213097, "Avg value loss": 0.2576412108610384, "Avg policy loss": 0.29674435465130955, "Total num played games": 46612, "Total num trained steps": 92672, "Timestamp in ms": 1701844709664, "logtype": "training_step"}
{"Total num played games": 46612, "Total num trained steps": 92675, "Timestamp in ms": 1701844788948, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.625}
{"Ratio train steps to played games": 1.9868967584464523, "Avg loss": 0.7811678966972977, "Avg value loss": 0.4780983350647148, "Avg policy loss": 0.30306956893764436, "Total num played games": 46706, "Total num trained steps": 92800, "Timestamp in ms": 1701844844764, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 242.73704350739717, "Avg game time in secs": 1.9333846934023313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 46720, "Total num trained steps": 92904, "Timestamp in ms": 1701844888542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856410256410257, "Avg loss": 0.5715329482918605, "Avg value loss": 0.2850811746320687, "Avg policy loss": 0.28645177150610834, "Total num played games": 46800, "Total num trained steps": 92928, "Timestamp in ms": 1701844899157, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988354700854701, "Avg loss": 0.4755676535423845, "Avg value loss": 0.18174703780096024, "Avg policy loss": 0.29382061678916216, "Total num played games": 46800, "Total num trained steps": 93056, "Timestamp in ms": 1701844955956, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 82.86130774207413, "Avg game time in secs": 1.8702287481137319, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 46848, "Total num trained steps": 93094, "Timestamp in ms": 1701844971404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869504030022602, "Avg loss": 0.8284109516534954, "Avg value loss": 0.5269107684725896, "Avg policy loss": 0.301500192261301, "Total num played games": 46898, "Total num trained steps": 93184, "Timestamp in ms": 1701845008305, "logtype": "training_step"}
{"Total num played games": 46898, "Total num trained steps": 93279, "Timestamp in ms": 1701845102540, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9921875}
{"Avg objective": 22.2734375, "Games time in secs": 133.91712879948318, "Avg game time in secs": 1.9035845478647389, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 46976, "Total num trained steps": 93284, "Timestamp in ms": 1701845105321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985699693564862, "Avg loss": 0.7377285505644977, "Avg value loss": 0.43850858756923117, "Avg policy loss": 0.29921996127814054, "Total num played games": 46992, "Total num trained steps": 93312, "Timestamp in ms": 1701845117002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884022812393598, "Avg loss": 0.5050653335638344, "Avg value loss": 0.2062586075917352, "Avg policy loss": 0.29880672798026353, "Total num played games": 46992, "Total num trained steps": 93440, "Timestamp in ms": 1701845174270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870880054366293, "Avg loss": 0.8527785998303443, "Avg value loss": 0.5480752544244751, "Avg policy loss": 0.3047033433103934, "Total num played games": 47088, "Total num trained steps": 93568, "Timestamp in ms": 1701845231403, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 170.6599868927151, "Avg game time in secs": 1.7996539542655228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 47104, "Total num trained steps": 93667, "Timestamp in ms": 1701845275981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858420584121064, "Avg loss": 0.7542719605844468, "Avg value loss": 0.4637661914166529, "Avg policy loss": 0.29050577618181705, "Total num played games": 47182, "Total num trained steps": 93696, "Timestamp in ms": 1701845289061, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988533762875673, "Avg loss": 0.5433723689056933, "Avg value loss": 0.2438425929285586, "Avg policy loss": 0.2995297792367637, "Total num played games": 47182, "Total num trained steps": 93824, "Timestamp in ms": 1701845345866, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 84.59215230867267, "Avg game time in secs": 1.8614381029765354, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 47232, "Total num trained steps": 93858, "Timestamp in ms": 1701845360574, "logtype": "played_game"}
{"Total num played games": 47278, "Total num trained steps": 93882, "Timestamp in ms": 1701845385654, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.26171875}
{"Avg objective": 21.9375, "Games time in secs": 28.474970838055015, "Avg game time in secs": 2.070026084998972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.26, "agent_stopped_more": 0.74, "played_steps": 0.82}, "Total num played games": 47360, "Total num trained steps": 93888, "Timestamp in ms": 1701845389049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832812631934476, "Avg loss": 1.4811934905592352, "Avg value loss": 1.1462920893682167, "Avg policy loss": 0.3349013972328976, "Total num played games": 47372, "Total num trained steps": 93952, "Timestamp in ms": 1701845416997, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859621717470235, "Avg loss": 0.45201363088563085, "Avg value loss": 0.14034873142372817, "Avg policy loss": 0.3116648949217051, "Total num played games": 47372, "Total num trained steps": 94080, "Timestamp in ms": 1701845475654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886641898167694, "Avg loss": 0.3866239411290735, "Avg value loss": 0.0884126351447776, "Avg policy loss": 0.29821130621712655, "Total num played games": 47372, "Total num trained steps": 94208, "Timestamp in ms": 1701845534800, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873599056206286, "Avg loss": 0.663473445456475, "Avg value loss": 0.353519252181286, "Avg policy loss": 0.3099541981937364, "Total num played games": 47468, "Total num trained steps": 94336, "Timestamp in ms": 1701845591391, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 242.54820683598518, "Avg game time in secs": 1.7848977009998634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 47488, "Total num trained steps": 94428, "Timestamp in ms": 1701845631598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860188377764696, "Avg loss": 0.8254214071203023, "Avg value loss": 0.5245840415009297, "Avg policy loss": 0.3008373578777537, "Total num played games": 47564, "Total num trained steps": 94464, "Timestamp in ms": 1701845646828, "logtype": "training_step"}
{"Total num played games": 47564, "Total num trained steps": 94486, "Timestamp in ms": 1701845724398, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3359375}
{"Avg objective": 21.765625, "Games time in secs": 95.5036845356226, "Avg game time in secs": 1.9365314198948909, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 47616, "Total num trained steps": 94491, "Timestamp in ms": 1701845727102, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848084267069537, "Avg loss": 1.2622404827270657, "Avg value loss": 0.9155535137979314, "Avg policy loss": 0.34668697649613023, "Total num played games": 47658, "Total num trained steps": 94592, "Timestamp in ms": 1701845769854, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987494229720089, "Avg loss": 0.42278913175687194, "Avg value loss": 0.1163774078595452, "Avg policy loss": 0.30641172430478036, "Total num played games": 47658, "Total num trained steps": 94720, "Timestamp in ms": 1701845825608, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 140.72397740744054, "Avg game time in secs": 2.133109912101645, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.76, "agent_stopped_0": 0.3}, "Total num played games": 47744, "Total num trained steps": 94813, "Timestamp in ms": 1701845867826, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862623555034344, "Avg loss": 0.6452530499082059, "Avg value loss": 0.3414383250637911, "Avg policy loss": 0.3038147232728079, "Total num played games": 47752, "Total num trained steps": 94848, "Timestamp in ms": 1701845883989, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889428715027644, "Avg loss": 0.43208372383378446, "Avg value loss": 0.1272270362242125, "Avg policy loss": 0.30485668824985623, "Total num played games": 47752, "Total num trained steps": 94976, "Timestamp in ms": 1701845943244, "logtype": "training_step"}
{"Total num played games": 47848, "Total num trained steps": 95087, "Timestamp in ms": 1701846014183, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.48046875}
{"Avg objective": 21.6015625, "Games time in secs": 148.3743527494371, "Avg game time in secs": 1.7776033030095277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.58, "agent_stopped_0": 0.47}, "Total num played games": 47872, "Total num trained steps": 95090, "Timestamp in ms": 1701846016200, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837303408285012, "Avg loss": 0.886419225949794, "Avg value loss": 0.5703318491287064, "Avg policy loss": 0.3160873812157661, "Total num played games": 47942, "Total num trained steps": 95104, "Timestamp in ms": 1701846021862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864002336156188, "Avg loss": 0.6361342112068087, "Avg value loss": 0.31211949820863083, "Avg policy loss": 0.3240147064207122, "Total num played games": 47942, "Total num trained steps": 95232, "Timestamp in ms": 1701846077982, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890701264027366, "Avg loss": 0.38781460747122765, "Avg value loss": 0.09220259607536718, "Avg policy loss": 0.2956120102899149, "Total num played games": 47942, "Total num trained steps": 95360, "Timestamp in ms": 1701846131019, "logtype": "training_step"}
{"Avg objective": 22.484375, "Games time in secs": 122.32054881192744, "Avg game time in secs": 1.7923375827231212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 48000, "Total num trained steps": 95379, "Timestamp in ms": 1701846138521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877596902452226, "Avg loss": 0.8497661736328155, "Avg value loss": 0.5324005316360854, "Avg policy loss": 0.3173656474100426, "Total num played games": 48038, "Total num trained steps": 95488, "Timestamp in ms": 1701846186493, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 83.34570826776326, "Avg game time in secs": 1.861251157562947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.68}, "Total num played games": 48128, "Total num trained steps": 95571, "Timestamp in ms": 1701846221867, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864544812398721, "Avg loss": 0.7707114000804722, "Avg value loss": 0.46023866496398114, "Avg policy loss": 0.31047273066360503, "Total num played games": 48134, "Total num trained steps": 95616, "Timestamp in ms": 1701846240835, "logtype": "training_step"}
{"Total num played games": 48134, "Total num trained steps": 95687, "Timestamp in ms": 1701846347668, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.20703125}
{"Ratio train steps to played games": 1.9852160570622874, "Avg loss": 0.9706242785323411, "Avg value loss": 0.6407569507136941, "Avg policy loss": 0.3298673270037398, "Total num played games": 48228, "Total num trained steps": 95744, "Timestamp in ms": 1701846371358, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878908517873435, "Avg loss": 0.44567757775075734, "Avg value loss": 0.13306375354295596, "Avg policy loss": 0.3126138219377026, "Total num played games": 48228, "Total num trained steps": 95872, "Timestamp in ms": 1701846426488, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 237.00253205373883, "Avg game time in secs": 1.7860019325453322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 48256, "Total num trained steps": 95948, "Timestamp in ms": 1701846458869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866727370555854, "Avg loss": 0.7988939119968563, "Avg value loss": 0.4868461111036595, "Avg policy loss": 0.31204780261032283, "Total num played games": 48322, "Total num trained steps": 96000, "Timestamp in ms": 1701846479902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893216340383262, "Avg loss": 0.44880396546795964, "Avg value loss": 0.13360080315032974, "Avg policy loss": 0.3152031641220674, "Total num played games": 48322, "Total num trained steps": 96128, "Timestamp in ms": 1701846536427, "logtype": "training_step"}
{"Avg objective": 22.7265625, "Games time in secs": 81.77798148617148, "Avg game time in secs": 1.8558200829429552, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.68}, "Total num played games": 48384, "Total num trained steps": 96138, "Timestamp in ms": 1701846540647, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881031064111037, "Avg loss": 1.0292488159611821, "Avg value loss": 0.6970955526339822, "Avg policy loss": 0.33215325721539557, "Total num played games": 48416, "Total num trained steps": 96256, "Timestamp in ms": 1701846592940, "logtype": "training_step"}
{"Total num played games": 48416, "Total num trained steps": 96289, "Timestamp in ms": 1701846670206, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.69140625}
{"Ratio train steps to played games": 1.9868893011750155, "Avg loss": 0.8298343466594815, "Avg value loss": 0.49541874905116856, "Avg policy loss": 0.33441559970378876, "Total num played games": 48510, "Total num trained steps": 96384, "Timestamp in ms": 1701846712872, "logtype": "training_step"}
{"Avg objective": 21.1328125, "Games time in secs": 228.18666711077094, "Avg game time in secs": 1.959212502129958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.67, "agent_stopped_0": 0.39}, "Total num played games": 48512, "Total num trained steps": 96509, "Timestamp in ms": 1701846768834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894459102902375, "Avg loss": 0.41643263259902596, "Avg value loss": 0.11510190379340202, "Avg policy loss": 0.3013307295041159, "Total num played games": 48512, "Total num trained steps": 96512, "Timestamp in ms": 1701846769616, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882319055260667, "Avg loss": 0.918976780725643, "Avg value loss": 0.5869722224888392, "Avg policy loss": 0.3320045591099188, "Total num played games": 48606, "Total num trained steps": 96640, "Timestamp in ms": 1701846826095, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 84.45685555227101, "Avg game time in secs": 1.5944288334430894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 48640, "Total num trained steps": 96705, "Timestamp in ms": 1701846853291, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869409880497721, "Avg loss": 0.8664637147448957, "Avg value loss": 0.539501212129835, "Avg policy loss": 0.3269625069806352, "Total num played games": 48702, "Total num trained steps": 96768, "Timestamp in ms": 1701846881601, "logtype": "training_step"}
{"Total num played games": 48702, "Total num trained steps": 96890, "Timestamp in ms": 1701846983373, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.64453125}
{"Avg objective": 22.1328125, "Games time in secs": 132.70624812692404, "Avg game time in secs": 1.7911183628602885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.65}, "Total num played games": 48768, "Total num trained steps": 96894, "Timestamp in ms": 1701846985997, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98606214642945, "Avg loss": 0.4362353188917041, "Avg value loss": 0.11917983333114535, "Avg policy loss": 0.3170554880052805, "Total num played games": 48788, "Total num trained steps": 96896, "Timestamp in ms": 1701846986707, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883597016148864, "Avg loss": 0.7417573155835271, "Avg value loss": 0.42324866232229397, "Avg policy loss": 0.318508661352098, "Total num played games": 48796, "Total num trained steps": 97024, "Timestamp in ms": 1701847041851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871548373900594, "Avg loss": 0.7357802833430469, "Avg value loss": 0.41841631970601156, "Avg policy loss": 0.3173639635788277, "Total num played games": 48890, "Total num trained steps": 97152, "Timestamp in ms": 1701847097330, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 163.2396231982857, "Avg game time in secs": 1.9285563903395087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 48896, "Total num trained steps": 97271, "Timestamp in ms": 1701847149237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860356865787432, "Avg loss": 0.5339642143808305, "Avg value loss": 0.21967862648307346, "Avg policy loss": 0.314285583794117, "Total num played games": 48982, "Total num trained steps": 97280, "Timestamp in ms": 1701847152473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988567695574065, "Avg loss": 0.7933240649290383, "Avg value loss": 0.4506533501553349, "Avg policy loss": 0.3426707076141611, "Total num played games": 48984, "Total num trained steps": 97408, "Timestamp in ms": 1701847210842, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 83.0250162538141, "Avg game time in secs": 1.8495891310012667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.63}, "Total num played games": 49024, "Total num trained steps": 97461, "Timestamp in ms": 1701847232262, "logtype": "played_game"}
{"Total num played games": 49078, "Total num trained steps": 97491, "Timestamp in ms": 1701847256222, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2109375}
{"Avg objective": 21.1640625, "Games time in secs": 26.830537604168057, "Avg game time in secs": 1.875661630590912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 49152, "Total num trained steps": 97496, "Timestamp in ms": 1701847259093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835678841617181, "Avg loss": 1.2971023074351251, "Avg value loss": 0.9636539832572453, "Avg policy loss": 0.3334483113139868, "Total num played games": 49172, "Total num trained steps": 97536, "Timestamp in ms": 1701847275449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861709916212478, "Avg loss": 0.5207936607766896, "Avg value loss": 0.19836655707331374, "Avg policy loss": 0.3224271035287529, "Total num played games": 49172, "Total num trained steps": 97664, "Timestamp in ms": 1701847331214, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887740990807776, "Avg loss": 0.38257780740968883, "Avg value loss": 0.08816340850898996, "Avg policy loss": 0.29441439697984606, "Total num played games": 49172, "Total num trained steps": 97792, "Timestamp in ms": 1701847387362, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874162776537447, "Avg loss": 0.8551318796817213, "Avg value loss": 0.5510556788940448, "Avg policy loss": 0.30407619604375213, "Total num played games": 49270, "Total num trained steps": 97920, "Timestamp in ms": 1701847442228, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 230.28202421218157, "Avg game time in secs": 1.8602996359404642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 49280, "Total num trained steps": 98031, "Timestamp in ms": 1701847489375, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862247791913135, "Avg loss": 0.5488439216278493, "Avg value loss": 0.25049817538820207, "Avg policy loss": 0.29834574356209487, "Total num played games": 49364, "Total num trained steps": 98048, "Timestamp in ms": 1701847497485, "logtype": "training_step"}
{"Total num played games": 49364, "Total num trained steps": 98093, "Timestamp in ms": 1701847581875, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.046875}
{"Avg objective": 21.8671875, "Games time in secs": 94.79759735055268, "Avg game time in secs": 1.7421737751137698, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 49408, "Total num trained steps": 98098, "Timestamp in ms": 1701847584173, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850378098588701, "Avg loss": 1.2281701231840998, "Avg value loss": 0.9012848692946136, "Avg policy loss": 0.32688525260891765, "Total num played games": 49458, "Total num trained steps": 98176, "Timestamp in ms": 1701847619112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987605645193902, "Avg loss": 0.4244215334765613, "Avg value loss": 0.12729961948934942, "Avg policy loss": 0.2971219118917361, "Total num played games": 49458, "Total num trained steps": 98304, "Timestamp in ms": 1701847678789, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 141.56299423240125, "Avg game time in secs": 1.8944051680155098, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 49536, "Total num trained steps": 98412, "Timestamp in ms": 1701847725736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863381361746781, "Avg loss": 0.6663284490350634, "Avg value loss": 0.37904240607167594, "Avg policy loss": 0.2872860385105014, "Total num played games": 49554, "Total num trained steps": 98432, "Timestamp in ms": 1701847734853, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889211768979296, "Avg loss": 0.5848437135573477, "Avg value loss": 0.2819854230619967, "Avg policy loss": 0.3028582935221493, "Total num played games": 49554, "Total num trained steps": 98560, "Timestamp in ms": 1701847791520, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987733644859813, "Avg loss": 0.8786963494494557, "Avg value loss": 0.5817002525436692, "Avg policy loss": 0.29699610092211515, "Total num played games": 49648, "Total num trained steps": 98688, "Timestamp in ms": 1701847847315, "logtype": "training_step"}
{"Total num played games": 49648, "Total num trained steps": 98697, "Timestamp in ms": 1701847920244, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.36328125}
{"Avg objective": 20.8046875, "Games time in secs": 196.40560345724225, "Avg game time in secs": 1.958515846330556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 49664, "Total num trained steps": 98699, "Timestamp in ms": 1701847922142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865707048369587, "Avg loss": 0.8380584088154137, "Avg value loss": 0.5257655733148567, "Avg policy loss": 0.3122928253142163, "Total num played games": 49742, "Total num trained steps": 98816, "Timestamp in ms": 1701847975815, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891439829520325, "Avg loss": 0.3683779453858733, "Avg value loss": 0.08929867448750883, "Avg policy loss": 0.27907927334308624, "Total num played games": 49742, "Total num trained steps": 98944, "Timestamp in ms": 1701848034178, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 126.20302840322256, "Avg game time in secs": 1.7930984281993005, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 49792, "Total num trained steps": 98978, "Timestamp in ms": 1701848048345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878807335767887, "Avg loss": 0.7774321038741618, "Avg value loss": 0.4859977897722274, "Avg policy loss": 0.2914343223674223, "Total num played games": 49838, "Total num trained steps": 99072, "Timestamp in ms": 1701848091161, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 84.93105045519769, "Avg game time in secs": 1.9403173375321785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 49920, "Total num trained steps": 99170, "Timestamp in ms": 1701848133276, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867019146038611, "Avg loss": 0.5689363486599177, "Avg value loss": 0.28326656538411044, "Avg policy loss": 0.28566978266462684, "Total num played games": 49932, "Total num trained steps": 99200, "Timestamp in ms": 1701848146958, "logtype": "training_step"}
{"Total num played games": 49932, "Total num trained steps": 99299, "Timestamp in ms": 1701848204067, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5390625}
{"Ratio train steps to played games": 1.985527525686643, "Avg loss": 0.6972407039720565, "Avg value loss": 0.40637525590136647, "Avg policy loss": 0.29086545773316175, "Total num played games": 50026, "Total num trained steps": 99328, "Timestamp in ms": 1701848217286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880861951785072, "Avg loss": 0.4697296195663512, "Avg value loss": 0.17310337073286064, "Avg policy loss": 0.29662624560296535, "Total num played games": 50026, "Total num trained steps": 99456, "Timestamp in ms": 1701848270400, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 175.81654793582857, "Avg game time in secs": 1.80430642227293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 50048, "Total num trained steps": 99544, "Timestamp in ms": 1701848309093, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869114126097367, "Avg loss": 0.7382643518503755, "Avg value loss": 0.45133854827145115, "Avg policy loss": 0.28692580619826913, "Total num played games": 50120, "Total num trained steps": 99584, "Timestamp in ms": 1701848325381, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989465283320032, "Avg loss": 0.42688547959551215, "Avg value loss": 0.13966860077925958, "Avg policy loss": 0.2872168781468645, "Total num played games": 50120, "Total num trained steps": 99712, "Timestamp in ms": 1701848381082, "logtype": "training_step"}
{"Avg objective": 21.578125, "Games time in secs": 81.95261718332767, "Avg game time in secs": 1.8472287362528732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 50176, "Total num trained steps": 99734, "Timestamp in ms": 1701848391046, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988191014815995, "Avg loss": 0.8061023929622024, "Avg value loss": 0.5060393689782359, "Avg policy loss": 0.3000630254391581, "Total num played games": 50216, "Total num trained steps": 99840, "Timestamp in ms": 1701848439624, "logtype": "training_step"}
{"Total num played games": 50216, "Total num trained steps": 99903, "Timestamp in ms": 1701848526895, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15234375}
{"Avg objective": 21.2109375, "Games time in secs": 138.96460696309805, "Avg game time in secs": 1.9610837904328946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.73, "agent_stopped_0": 0.31}, "Total num played games": 50304, "Total num trained steps": 99908, "Timestamp in ms": 1701848530010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870403498310476, "Avg loss": 0.7109744853805751, "Avg value loss": 0.4213595657492988, "Avg policy loss": 0.2896149166626856, "Total num played games": 50310, "Total num trained steps": 99968, "Timestamp in ms": 1701848557354, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895845756310873, "Avg loss": 0.37593346275389194, "Avg value loss": 0.10097753998707049, "Avg policy loss": 0.2749559200601652, "Total num played games": 50310, "Total num trained steps": 100096, "Timestamp in ms": 1701848613724, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988334722056898, "Avg loss": 0.862765338504687, "Avg value loss": 0.5610402785532642, "Avg policy loss": 0.3017250500852242, "Total num played games": 50406, "Total num trained steps": 100224, "Timestamp in ms": 1701848668877, "logtype": "training_step"}
{"Avg objective": 20.984375, "Games time in secs": 173.57535344921052, "Avg game time in secs": 1.6833068175474182, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 50432, "Total num trained steps": 100305, "Timestamp in ms": 1701848703592, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871683168316832, "Avg loss": 0.7773658942896873, "Avg value loss": 0.48983802620205097, "Avg policy loss": 0.28752786747645587, "Total num played games": 50500, "Total num trained steps": 100352, "Timestamp in ms": 1701848724971, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897029702970297, "Avg loss": 0.42603806918486953, "Avg value loss": 0.13311087456531823, "Avg policy loss": 0.29292719590011984, "Total num played games": 50500, "Total num trained steps": 100480, "Timestamp in ms": 1701848782463, "logtype": "training_step"}
{"Avg objective": 22.0859375, "Games time in secs": 84.90243052877486, "Avg game time in secs": 1.8279156795761082, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.64}, "Total num played games": 50560, "Total num trained steps": 100494, "Timestamp in ms": 1701848788495, "logtype": "played_game"}
{"Total num played games": 50594, "Total num trained steps": 100505, "Timestamp in ms": 1701848804127, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.140625}
{"Avg objective": 22.015625, "Games time in secs": 19.768927074968815, "Avg game time in secs": 1.8864497090980876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.73, "agent_stopped_0": 0.37}, "Total num played games": 50688, "Total num trained steps": 100513, "Timestamp in ms": 1701848808264, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848484848484849, "Avg loss": 1.5960992358159274, "Avg value loss": 1.262291264720261, "Avg policy loss": 0.3338079797104001, "Total num played games": 50688, "Total num trained steps": 100608, "Timestamp in ms": 1701848851543, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873737373737375, "Avg loss": 0.40944228903390467, "Avg value loss": 0.1106160026974976, "Avg policy loss": 0.2988262849394232, "Total num played games": 50688, "Total num trained steps": 100736, "Timestamp in ms": 1701848908378, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898989898989898, "Avg loss": 0.36438843607902527, "Avg value loss": 0.08019951844471507, "Avg policy loss": 0.2841889151604846, "Total num played games": 50688, "Total num trained steps": 100864, "Timestamp in ms": 1701848966392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886381537492124, "Avg loss": 0.8637328795157373, "Avg value loss": 0.5557502507872414, "Avg policy loss": 0.3079826283501461, "Total num played games": 50784, "Total num trained steps": 100992, "Timestamp in ms": 1701849022902, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 245.14954241737723, "Avg game time in secs": 1.705103854270419, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.57}, "Total num played games": 50816, "Total num trained steps": 101061, "Timestamp in ms": 1701849053414, "logtype": "played_game"}
{"Total num played games": 50880, "Total num trained steps": 101107, "Timestamp in ms": 1701849093278, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.14453125}
{"Avg objective": 22.9609375, "Games time in secs": 42.62630295753479, "Avg game time in secs": 1.7615601556753973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.63}, "Total num played games": 50944, "Total num trained steps": 101111, "Timestamp in ms": 1701849096040, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837368069996468, "Avg loss": 0.9769027896691114, "Avg value loss": 0.6722160327772144, "Avg policy loss": 0.3046867559896782, "Total num played games": 50974, "Total num trained steps": 101120, "Timestamp in ms": 1701849099473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862478910817278, "Avg loss": 0.9551154065411538, "Avg value loss": 0.6159956419141963, "Avg policy loss": 0.33911976555828005, "Total num played games": 50974, "Total num trained steps": 101248, "Timestamp in ms": 1701849154950, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988758975163809, "Avg loss": 0.38736214069649577, "Avg value loss": 0.09148960805032402, "Avg policy loss": 0.295872533461079, "Total num played games": 50974, "Total num trained steps": 101376, "Timestamp in ms": 1701849210812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987546504797337, "Avg loss": 0.8891621655784547, "Avg value loss": 0.5874489625857677, "Avg policy loss": 0.30171319900546223, "Total num played games": 51070, "Total num trained steps": 101504, "Timestamp in ms": 1701849265910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898970121784079, "Avg loss": 0.4112831959500909, "Avg value loss": 0.11999702782486565, "Avg policy loss": 0.29128617024980485, "Total num played games": 51070, "Total num trained steps": 101632, "Timestamp in ms": 1701849319001, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 222.96157602593303, "Avg game time in secs": 2.0193612599687185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.77, "agent_stopped_0": 0.34}, "Total num played games": 51072, "Total num trained steps": 101632, "Timestamp in ms": 1701849319002, "logtype": "played_game"}
{"Total num played games": 51166, "Total num trained steps": 101708, "Timestamp in ms": 1701849406698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.10546875}
{"Avg objective": 21.4140625, "Games time in secs": 89.62795087881386, "Avg game time in secs": 1.713778464923962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 51200, "Total num trained steps": 101711, "Timestamp in ms": 1701849408630, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851736246586031, "Avg loss": 1.2123552625998855, "Avg value loss": 0.8828505471465178, "Avg policy loss": 0.329504725523293, "Total num played games": 51260, "Total num trained steps": 101760, "Timestamp in ms": 1701849431119, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987670698400312, "Avg loss": 0.4954822389408946, "Avg value loss": 0.1732258778065443, "Avg policy loss": 0.32225636462680995, "Total num played games": 51260, "Total num trained steps": 101888, "Timestamp in ms": 1701849487750, "logtype": "training_step"}
{"Avg objective": 22.765625, "Games time in secs": 135.60952716879547, "Avg game time in secs": 1.8072606329078553, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 51328, "Total num trained steps": 102015, "Timestamp in ms": 1701849544239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986892334060455, "Avg loss": 0.3691882458515465, "Avg value loss": 0.07381066735251807, "Avg policy loss": 0.2953775787027553, "Total num played games": 51344, "Total num trained steps": 102016, "Timestamp in ms": 1701849544811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889399485941273, "Avg loss": 0.7562627901788801, "Avg value loss": 0.43728331397869624, "Avg policy loss": 0.31897946493700147, "Total num played games": 51356, "Total num trained steps": 102144, "Timestamp in ms": 1701849604934, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877939747327502, "Avg loss": 0.7786945210536942, "Avg value loss": 0.47392490578931756, "Avg policy loss": 0.3047696161083877, "Total num played games": 51450, "Total num trained steps": 102272, "Timestamp in ms": 1701849662093, "logtype": "training_step"}
{"Total num played games": 51450, "Total num trained steps": 102309, "Timestamp in ms": 1701849693975, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.84765625}
{"Avg objective": 21.7890625, "Games time in secs": 151.23921176977456, "Avg game time in secs": 1.9453547803714173, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 51456, "Total num trained steps": 102311, "Timestamp in ms": 1701849695479, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866521806611828, "Avg loss": 1.0352233143057674, "Avg value loss": 0.7091274872655049, "Avg policy loss": 0.3260958216851577, "Total num played games": 51544, "Total num trained steps": 102400, "Timestamp in ms": 1701849732205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989135495887009, "Avg loss": 0.400064236484468, "Avg value loss": 0.09941700077615678, "Avg policy loss": 0.3006472409470007, "Total num played games": 51544, "Total num trained steps": 102528, "Timestamp in ms": 1701849786483, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 114.08267090842128, "Avg game time in secs": 1.6877831698220689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 51584, "Total num trained steps": 102581, "Timestamp in ms": 1701849809562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879163439194423, "Avg loss": 0.832801366224885, "Avg value loss": 0.5219600359268952, "Avg policy loss": 0.31084132310934365, "Total num played games": 51640, "Total num trained steps": 102656, "Timestamp in ms": 1701849842600, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 85.19561266340315, "Avg game time in secs": 1.8672052794863703, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 51712, "Total num trained steps": 102775, "Timestamp in ms": 1701849894757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867785208953492, "Avg loss": 0.4807553291320801, "Avg value loss": 0.1865048607578501, "Avg policy loss": 0.29425047303084284, "Total num played games": 51734, "Total num trained steps": 102784, "Timestamp in ms": 1701849898864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989233386167704, "Avg loss": 0.6275103283114731, "Avg value loss": 0.32004516769666225, "Avg policy loss": 0.307465156307444, "Total num played games": 51734, "Total num trained steps": 102912, "Timestamp in ms": 1701849957999, "logtype": "training_step"}
{"Total num played games": 51734, "Total num trained steps": 102912, "Timestamp in ms": 1701849982538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.203125}
{"Ratio train steps to played games": 1.9880952380952381, "Avg loss": 0.7113257958553731, "Avg value loss": 0.401324265927542, "Avg policy loss": 0.3100015271920711, "Total num played games": 51828, "Total num trained steps": 103040, "Timestamp in ms": 1701850037400, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 188.79357571341097, "Avg game time in secs": 1.9345294879603898, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.72, "agent_stopped_0": 0.35}, "Total num played games": 51840, "Total num trained steps": 103147, "Timestamp in ms": 1701850083551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98690393652261, "Avg loss": 0.6397591470740736, "Avg value loss": 0.3422431882354431, "Avg policy loss": 0.2975159618072212, "Total num played games": 51924, "Total num trained steps": 103168, "Timestamp in ms": 1701850092879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98936907788306, "Avg loss": 0.556492893723771, "Avg value loss": 0.245375836500898, "Avg policy loss": 0.311117057222873, "Total num played games": 51924, "Total num trained steps": 103296, "Timestamp in ms": 1701850149505, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 83.881561441347, "Avg game time in secs": 1.7109698975400534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 51968, "Total num trained steps": 103341, "Timestamp in ms": 1701850167433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988158400615148, "Avg loss": 0.8585554959718138, "Avg value loss": 0.5392593080468941, "Avg policy loss": 0.31929619249422103, "Total num played games": 52020, "Total num trained steps": 103424, "Timestamp in ms": 1701850201813, "logtype": "training_step"}
{"Total num played games": 52020, "Total num trained steps": 103514, "Timestamp in ms": 1701850272519, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1171875}
{"Avg objective": 21.7265625, "Games time in secs": 107.73017051443458, "Avg game time in secs": 1.8025455434399191, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.66}, "Total num played games": 52096, "Total num trained steps": 103518, "Timestamp in ms": 1701850275163, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870284376559082, "Avg loss": 0.6532151051796973, "Avg value loss": 0.35209069892880507, "Avg policy loss": 0.3011244139634073, "Total num played games": 52114, "Total num trained steps": 103552, "Timestamp in ms": 1701850288566, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989484591472541, "Avg loss": 0.4348314246162772, "Avg value loss": 0.13078518025577068, "Avg policy loss": 0.30404624342918396, "Total num played games": 52114, "Total num trained steps": 103680, "Timestamp in ms": 1701850341488, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883542752068648, "Avg loss": 0.89016172895208, "Avg value loss": 0.5741977046418469, "Avg policy loss": 0.31596401834394783, "Total num played games": 52208, "Total num trained steps": 103808, "Timestamp in ms": 1701850394455, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 159.0751655884087, "Avg game time in secs": 1.9593407164356904, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 52224, "Total num trained steps": 103908, "Timestamp in ms": 1701850434238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871520342612419, "Avg loss": 0.5891155791468918, "Avg value loss": 0.27395503147272393, "Avg policy loss": 0.31516054598614573, "Total num played games": 52304, "Total num trained steps": 103936, "Timestamp in ms": 1701850444838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895992658305293, "Avg loss": 0.4597970915492624, "Avg value loss": 0.15046532888663933, "Avg policy loss": 0.30933176213875413, "Total num played games": 52304, "Total num trained steps": 104064, "Timestamp in ms": 1701850497470, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 77.58328988403082, "Avg game time in secs": 1.7950876091927057, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 52352, "Total num trained steps": 104102, "Timestamp in ms": 1701850511822, "logtype": "played_game"}
{"Total num played games": 52398, "Total num trained steps": 104119, "Timestamp in ms": 1701850588824, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.12890625}
{"Avg objective": 21.6171875, "Games time in secs": 79.85484576411545, "Avg game time in secs": 1.9526589614251861, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 52480, "Total num trained steps": 104125, "Timestamp in ms": 1701850591677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849119865884326, "Avg loss": 1.4967974952887744, "Avg value loss": 1.1544316889485344, "Avg policy loss": 0.34236581809818745, "Total num played games": 52492, "Total num trained steps": 104192, "Timestamp in ms": 1701850618332, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987331402880439, "Avg loss": 0.48274784022942185, "Avg value loss": 0.156049748766236, "Avg policy loss": 0.3266980906482786, "Total num played games": 52492, "Total num trained steps": 104320, "Timestamp in ms": 1701850671884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897889202164138, "Avg loss": 0.3707535956054926, "Avg value loss": 0.0725932109344285, "Avg policy loss": 0.2981603860389441, "Total num played games": 52492, "Total num trained steps": 104448, "Timestamp in ms": 1701850722850, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885715372328288, "Avg loss": 0.6978089273907244, "Avg value loss": 0.3911239725712221, "Avg policy loss": 0.3066849467577413, "Total num played games": 52588, "Total num trained steps": 104576, "Timestamp in ms": 1701850774259, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 219.4609570875764, "Avg game time in secs": 1.7724289805046283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 52608, "Total num trained steps": 104669, "Timestamp in ms": 1701850811138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874720018222543, "Avg loss": 0.7912405233364552, "Avg value loss": 0.4932423966820352, "Avg policy loss": 0.29799812368582934, "Total num played games": 52682, "Total num trained steps": 104704, "Timestamp in ms": 1701850825105, "logtype": "training_step"}
{"Total num played games": 52682, "Total num trained steps": 104722, "Timestamp in ms": 1701850885444, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.921875}
{"Avg objective": 21.2578125, "Games time in secs": 76.8722806405276, "Avg game time in secs": 1.8084160340222297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 52736, "Total num trained steps": 104728, "Timestamp in ms": 1701850888010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863574351978173, "Avg loss": 1.0669335464481264, "Avg value loss": 0.7297485451563261, "Avg policy loss": 0.3371850128751248, "Total num played games": 52776, "Total num trained steps": 104832, "Timestamp in ms": 1701850929022, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887827800515385, "Avg loss": 0.4077647151425481, "Avg value loss": 0.10496219011838548, "Avg policy loss": 0.30280252476222813, "Total num played games": 52776, "Total num trained steps": 104960, "Timestamp in ms": 1701850982712, "logtype": "training_step"}
{"Avg objective": 22.9765625, "Games time in secs": 131.56299028359354, "Avg game time in secs": 2.0745061188208638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.8, "agent_stopped_0": 0.3}, "Total num played games": 52864, "Total num trained steps": 105049, "Timestamp in ms": 1701851019573, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876678645734822, "Avg loss": 0.7955518076196313, "Avg value loss": 0.4999790319125168, "Avg policy loss": 0.2955727764638141, "Total num played games": 52870, "Total num trained steps": 105088, "Timestamp in ms": 1701851034585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900888972952524, "Avg loss": 0.4340263558551669, "Avg value loss": 0.1447297495615203, "Avg policy loss": 0.28929660737048835, "Total num played games": 52870, "Total num trained steps": 105216, "Timestamp in ms": 1701851088362, "logtype": "training_step"}
{"Total num played games": 52964, "Total num trained steps": 105325, "Timestamp in ms": 1701851224343, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.87890625}
{"Avg objective": 21.7421875, "Games time in secs": 206.9162482880056, "Avg game time in secs": 1.819431828262168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 52992, "Total num trained steps": 105330, "Timestamp in ms": 1701851226490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985431037732293, "Avg loss": 0.9174396093003452, "Avg value loss": 0.6064510862051975, "Avg policy loss": 0.310988521319814, "Total num played games": 53058, "Total num trained steps": 105344, "Timestamp in ms": 1701851232240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878434920275925, "Avg loss": 0.5991974838543683, "Avg value loss": 0.2919074947712943, "Avg policy loss": 0.307289982913062, "Total num played games": 53058, "Total num trained steps": 105472, "Timestamp in ms": 1701851283007, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990274793622074, "Avg loss": 0.36039421847090125, "Avg value loss": 0.07767947256797925, "Avg policy loss": 0.28271474700886756, "Total num played games": 53058, "Total num trained steps": 105600, "Timestamp in ms": 1701851332747, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 110.05430006980896, "Avg game time in secs": 1.8866208787658252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 53120, "Total num trained steps": 105610, "Timestamp in ms": 1701851336544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890883094404936, "Avg loss": 0.8489609474781901, "Avg value loss": 0.5350148438592441, "Avg policy loss": 0.31394610297866166, "Total num played games": 53154, "Total num trained steps": 105728, "Timestamp in ms": 1701851384385, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 78.33322834223509, "Avg game time in secs": 2.065925031056395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.87, "agent_stopped_0": 0.23}, "Total num played games": 53248, "Total num trained steps": 105807, "Timestamp in ms": 1701851414877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987906103286385, "Avg loss": 0.8268418489024043, "Avg value loss": 0.5114144913386554, "Avg policy loss": 0.3154273509280756, "Total num played games": 53250, "Total num trained steps": 105856, "Timestamp in ms": 1701851433984, "logtype": "training_step"}
{"Total num played games": 53250, "Total num trained steps": 105930, "Timestamp in ms": 1701851525445, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9296875}
{"Ratio train steps to played games": 1.9868026394721057, "Avg loss": 0.8717157761566341, "Avg value loss": 0.5464409682899714, "Avg policy loss": 0.3252748060040176, "Total num played games": 53344, "Total num trained steps": 105984, "Timestamp in ms": 1701851547452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892021595680864, "Avg loss": 0.4090509077068418, "Avg value loss": 0.10805543727474287, "Avg policy loss": 0.3009954718872905, "Total num played games": 53344, "Total num trained steps": 106112, "Timestamp in ms": 1701851598391, "logtype": "training_step"}
{"Avg objective": 22.6640625, "Games time in secs": 209.82417030073702, "Avg game time in secs": 1.738990718324203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.56, "agent_stopped_0": 0.45}, "Total num played games": 53376, "Total num trained steps": 106181, "Timestamp in ms": 1701851624702, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880239520958083, "Avg loss": 0.8660000585950911, "Avg value loss": 0.5623128222068772, "Avg policy loss": 0.30368724709842354, "Total num played games": 53440, "Total num trained steps": 106240, "Timestamp in ms": 1701851647600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904004491017964, "Avg loss": 0.41096331970766187, "Avg value loss": 0.10682378761703148, "Avg policy loss": 0.30413953156676143, "Total num played games": 53440, "Total num trained steps": 106368, "Timestamp in ms": 1701851697289, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 75.01727610640228, "Avg game time in secs": 1.8686877893051133, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.72}, "Total num played games": 53504, "Total num trained steps": 106375, "Timestamp in ms": 1701851699719, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892408846383742, "Avg loss": 0.9345942351501435, "Avg value loss": 0.6289033520151861, "Avg policy loss": 0.3056908849393949, "Total num played games": 53536, "Total num trained steps": 106496, "Timestamp in ms": 1701851747213, "logtype": "training_step"}
{"Total num played games": 53536, "Total num trained steps": 106530, "Timestamp in ms": 1701851773073, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3828125}
{"Ratio train steps to played games": 1.9881409658773075, "Avg loss": 0.7276487916242331, "Avg value loss": 0.4284474004234653, "Avg policy loss": 0.29920139722526073, "Total num played games": 53630, "Total num trained steps": 106624, "Timestamp in ms": 1701851810645, "logtype": "training_step"}
{"Avg objective": 22.5859375, "Games time in secs": 160.76724858768284, "Avg game time in secs": 1.9872871559346095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.73, "agent_stopped_0": 0.35}, "Total num played games": 53632, "Total num trained steps": 106751, "Timestamp in ms": 1701851860487, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900082022220564, "Avg loss": 0.3600817278493196, "Avg value loss": 0.0835391879954841, "Avg policy loss": 0.2765425400575623, "Total num played games": 53638, "Total num trained steps": 106752, "Timestamp in ms": 1701851860913, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893533856977998, "Avg loss": 0.7473458559252322, "Avg value loss": 0.44394579794607125, "Avg policy loss": 0.30340006144251674, "Total num played games": 53726, "Total num trained steps": 106880, "Timestamp in ms": 1701851912492, "logtype": "training_step"}
{"Avg objective": 23.1015625, "Games time in secs": 77.34505731984973, "Avg game time in secs": 1.7891793402814073, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 53760, "Total num trained steps": 106946, "Timestamp in ms": 1701851937832, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882571534745448, "Avg loss": 1.4080229371320456, "Avg value loss": 1.1002476600697264, "Avg policy loss": 0.30777529545594007, "Total num played games": 53820, "Total num trained steps": 107008, "Timestamp in ms": 1701851962319, "logtype": "training_step"}
{"Avg objective": 22.6796875, "Games time in secs": 75.2015550751239, "Avg game time in secs": 1.9799071087909397, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.76, "agent_stopped_0": 0.31}, "Total num played games": 53888, "Total num trained steps": 107131, "Timestamp in ms": 1701852013033, "logtype": "played_game"}
{"Total num played games": 53916, "Total num trained steps": 107131, "Timestamp in ms": 1701852075803, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9921875}
{"Ratio train steps to played games": 1.9857651245551602, "Avg loss": 0.6368278469890356, "Avg value loss": 0.318950904882513, "Avg policy loss": 0.3178769391961396, "Total num played games": 53948, "Total num trained steps": 107136, "Timestamp in ms": 1701852078077, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860025921125717, "Avg loss": 1.6917301004286855, "Avg value loss": 1.3258954676566646, "Avg policy loss": 0.365834632772021, "Total num played games": 54010, "Total num trained steps": 107264, "Timestamp in ms": 1701852127660, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883725236067396, "Avg loss": 0.45368984062224627, "Avg value loss": 0.12988415255676955, "Avg policy loss": 0.3238056891132146, "Total num played games": 54010, "Total num trained steps": 107392, "Timestamp in ms": 1701852177055, "logtype": "training_step"}
{"Avg objective": 22.703125, "Games time in secs": 210.1883714813739, "Avg game time in secs": 1.979884893167764, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.77, "agent_stopped_0": 0.34}, "Total num played games": 54016, "Total num trained steps": 107512, "Timestamp in ms": 1701852223222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987357214151048, "Avg loss": 0.4449069262482226, "Avg value loss": 0.14732215818366967, "Avg policy loss": 0.29758476733695716, "Total num played games": 54102, "Total num trained steps": 107520, "Timestamp in ms": 1701852226477, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989649563803046, "Avg loss": 0.7707574721425772, "Avg value loss": 0.4574222877272405, "Avg policy loss": 0.3133351821452379, "Total num played games": 54104, "Total num trained steps": 107648, "Timestamp in ms": 1701852275884, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 74.62790655344725, "Avg game time in secs": 1.7507821152394172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 54144, "Total num trained steps": 107702, "Timestamp in ms": 1701852297850, "logtype": "played_game"}
{"Total num played games": 54202, "Total num trained steps": 107735, "Timestamp in ms": 1701852370884, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4140625}
{"Avg objective": 20.71875, "Games time in secs": 75.95140215754509, "Avg game time in secs": 1.90866845252458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 54272, "Total num trained steps": 107740, "Timestamp in ms": 1701852373801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849712686017387, "Avg loss": 1.272127460455522, "Avg value loss": 0.9472727475513238, "Avg policy loss": 0.32485472422558814, "Total num played games": 54296, "Total num trained steps": 107776, "Timestamp in ms": 1701852389027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987328716664211, "Avg loss": 0.5557333996985108, "Avg value loss": 0.22813208954175934, "Avg policy loss": 0.3276013071881607, "Total num played games": 54296, "Total num trained steps": 107904, "Timestamp in ms": 1701852442557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896861647266835, "Avg loss": 0.3824280274566263, "Avg value loss": 0.08083689954946749, "Avg policy loss": 0.301591127528809, "Total num played games": 54296, "Total num trained steps": 108032, "Timestamp in ms": 1701852493870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988527724665392, "Avg loss": 0.7200148375704885, "Avg value loss": 0.4130298717645928, "Avg policy loss": 0.3069849640596658, "Total num played games": 54392, "Total num trained steps": 108160, "Timestamp in ms": 1701852546825, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 222.2685176283121, "Avg game time in secs": 2.159651788591873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.77}, "Total num played games": 54400, "Total num trained steps": 108276, "Timestamp in ms": 1701852596070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873733666128321, "Avg loss": 0.5106422808021307, "Avg value loss": 0.20417227392317727, "Avg policy loss": 0.30647000460885465, "Total num played games": 54488, "Total num trained steps": 108288, "Timestamp in ms": 1701852600872, "logtype": "training_step"}
{"Total num played games": 54488, "Total num trained steps": 108337, "Timestamp in ms": 1701852687516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3125}
{"Avg objective": 21.3359375, "Games time in secs": 93.77120655961335, "Avg game time in secs": 1.674308238303638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.5}, "Total num played games": 54528, "Total num trained steps": 108340, "Timestamp in ms": 1701852689841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862958484482063, "Avg loss": 1.0237983781844378, "Avg value loss": 0.6985115504357964, "Avg policy loss": 0.325286821112968, "Total num played games": 54582, "Total num trained steps": 108416, "Timestamp in ms": 1701852722916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886409439009196, "Avg loss": 0.41575718740932643, "Avg value loss": 0.11202702962327749, "Avg policy loss": 0.3037301568547264, "Total num played games": 54582, "Total num trained steps": 108544, "Timestamp in ms": 1701852775529, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 131.8012764994055, "Avg game time in secs": 1.7875747993239202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 54656, "Total num trained steps": 108659, "Timestamp in ms": 1701852821643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875448094227814, "Avg loss": 0.6030495297163725, "Avg value loss": 0.3037146083370317, "Avg policy loss": 0.29933492036070675, "Total num played games": 54676, "Total num trained steps": 108672, "Timestamp in ms": 1701852826725, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899041627039287, "Avg loss": 0.697844858514145, "Avg value loss": 0.3768657744512893, "Avg policy loss": 0.32097907608840615, "Total num played games": 54676, "Total num trained steps": 108800, "Timestamp in ms": 1701852882379, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887533776382094, "Avg loss": 0.7680635661818087, "Avg value loss": 0.4527155954274349, "Avg policy loss": 0.3153479699976742, "Total num played games": 54772, "Total num trained steps": 108928, "Timestamp in ms": 1701852936040, "logtype": "training_step"}
{"Total num played games": 54772, "Total num trained steps": 108940, "Timestamp in ms": 1701853012878, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.92578125}
{"Avg objective": 21.703125, "Games time in secs": 193.1148663237691, "Avg game time in secs": 1.9120257314061746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 54784, "Total num trained steps": 108943, "Timestamp in ms": 1701853014758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876790726497284, "Avg loss": 0.8383592711761594, "Avg value loss": 0.524685952172149, "Avg policy loss": 0.31367332278750837, "Total num played games": 54866, "Total num trained steps": 109056, "Timestamp in ms": 1701853060366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989993803083877, "Avg loss": 0.3810015367344022, "Avg value loss": 0.0868063866510056, "Avg policy loss": 0.29419515130575746, "Total num played games": 54866, "Total num trained steps": 109184, "Timestamp in ms": 1701853110141, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 111.98422467149794, "Avg game time in secs": 1.828910245152656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.67, "agent_stopped_0": 0.35}, "Total num played games": 54912, "Total num trained steps": 109226, "Timestamp in ms": 1701853126742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889374090247454, "Avg loss": 0.8758220379240811, "Avg value loss": 0.5627205631171819, "Avg policy loss": 0.31310146872419864, "Total num played games": 54960, "Total num trained steps": 109312, "Timestamp in ms": 1701853161000, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 75.02969651669264, "Avg game time in secs": 1.947198987880256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.71, "agent_stopped_0": 0.36}, "Total num played games": 55040, "Total num trained steps": 109416, "Timestamp in ms": 1701853201772, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987794245858762, "Avg loss": 0.5790007298346609, "Avg value loss": 0.27409339594305493, "Avg policy loss": 0.30490734172053635, "Total num played games": 55056, "Total num trained steps": 109440, "Timestamp in ms": 1701853211279, "logtype": "training_step"}
{"Total num played games": 55056, "Total num trained steps": 109541, "Timestamp in ms": 1701853281788, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.06640625}
{"Ratio train steps to played games": 1.9867271078875792, "Avg loss": 0.6381863581482321, "Avg value loss": 0.3254933370044455, "Avg policy loss": 0.31269302091095597, "Total num played games": 55150, "Total num trained steps": 109568, "Timestamp in ms": 1701853293055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890299184043518, "Avg loss": 0.4707064942922443, "Avg value loss": 0.17115176824154332, "Avg policy loss": 0.2995547236641869, "Total num played games": 55150, "Total num trained steps": 109696, "Timestamp in ms": 1701853344801, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 183.6788968425244, "Avg game time in secs": 1.8783202642080141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.63, "agent_stopped_0": 0.41}, "Total num played games": 55168, "Total num trained steps": 109793, "Timestamp in ms": 1701853385451, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987980595177757, "Avg loss": 0.6549682843033224, "Avg value loss": 0.36240492010256276, "Avg policy loss": 0.2925633698469028, "Total num played games": 55244, "Total num trained steps": 109824, "Timestamp in ms": 1701853398668, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902975888784302, "Avg loss": 0.5215876386500895, "Avg value loss": 0.22198283503530547, "Avg policy loss": 0.2996047956403345, "Total num played games": 55244, "Total num trained steps": 109952, "Timestamp in ms": 1701853451713, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 78.56554807722569, "Avg game time in secs": 1.7493807607097551, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.56}, "Total num played games": 55296, "Total num trained steps": 109981, "Timestamp in ms": 1701853464017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892298239907478, "Avg loss": 0.6948234788142145, "Avg value loss": 0.40362339044804685, "Avg policy loss": 0.2912000888027251, "Total num played games": 55338, "Total num trained steps": 110080, "Timestamp in ms": 1701853505123, "logtype": "training_step"}
{"Total num played games": 55338, "Total num trained steps": 110145, "Timestamp in ms": 1701853573278, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.19921875}
{"Avg objective": 20.9140625, "Games time in secs": 112.7653516959399, "Avg game time in secs": 1.8553504903102294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 55424, "Total num trained steps": 110152, "Timestamp in ms": 1701853576782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881656804733727, "Avg loss": 0.7770569869317114, "Avg value loss": 0.48604538801009767, "Avg policy loss": 0.29101159423589706, "Total num played games": 55432, "Total num trained steps": 110208, "Timestamp in ms": 1701853600230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904748159907635, "Avg loss": 0.3914279043674469, "Avg value loss": 0.11148278933251277, "Avg policy loss": 0.2799451168393716, "Total num played games": 55432, "Total num trained steps": 110336, "Timestamp in ms": 1701853651767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893387120011525, "Avg loss": 0.6686346840579063, "Avg value loss": 0.37682145001599565, "Avg policy loss": 0.29181323386728764, "Total num played games": 55528, "Total num trained steps": 110464, "Timestamp in ms": 1701853703516, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 162.28745166957378, "Avg game time in secs": 1.7449760961753782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 55552, "Total num trained steps": 110549, "Timestamp in ms": 1701853739069, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882780194886915, "Avg loss": 0.8432949454290792, "Avg value loss": 0.555473856133176, "Avg policy loss": 0.28782109869644046, "Total num played games": 55622, "Total num trained steps": 110592, "Timestamp in ms": 1701853757945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990579267196433, "Avg loss": 0.5076595472637564, "Avg value loss": 0.20406307454686612, "Avg policy loss": 0.3035964712034911, "Total num played games": 55622, "Total num trained steps": 110720, "Timestamp in ms": 1701853812917, "logtype": "training_step"}
{"Avg objective": 22.2265625, "Games time in secs": 81.26157669723034, "Avg game time in secs": 1.938677491954877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.33, "agent_stopped_more": 0.67, "played_steps": 0.72}, "Total num played games": 55680, "Total num trained steps": 110739, "Timestamp in ms": 1701853820331, "logtype": "played_game"}
{"Total num played games": 55716, "Total num trained steps": 110750, "Timestamp in ms": 1701853886882, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.62890625}
{"Avg objective": 21.8046875, "Games time in secs": 70.31177767552435, "Avg game time in secs": 2.0714550580159994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 55808, "Total num trained steps": 110758, "Timestamp in ms": 1701853890643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861673535208744, "Avg loss": 1.2455021233763546, "Avg value loss": 0.9210017842124216, "Avg policy loss": 0.3245003294432536, "Total num played games": 55810, "Total num trained steps": 110848, "Timestamp in ms": 1701853926465, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884608493101594, "Avg loss": 0.39347650576382875, "Avg value loss": 0.10210566048044711, "Avg policy loss": 0.291370845050551, "Total num played games": 55810, "Total num trained steps": 110976, "Timestamp in ms": 1701853981981, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907543450994445, "Avg loss": 0.34358767606317997, "Avg value loss": 0.06979410003987141, "Avg policy loss": 0.27379357628524303, "Total num played games": 55810, "Total num trained steps": 111104, "Timestamp in ms": 1701854033144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989696622781912, "Avg loss": 0.898998477961868, "Avg value loss": 0.5940455316740554, "Avg policy loss": 0.3049529518466443, "Total num played games": 55904, "Total num trained steps": 111232, "Timestamp in ms": 1701854082406, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 220.6104952469468, "Avg game time in secs": 1.7179473288415466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 55936, "Total num trained steps": 111301, "Timestamp in ms": 1701854111254, "logtype": "played_game"}
{"Total num played games": 56000, "Total num trained steps": 111351, "Timestamp in ms": 1701854187591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.53125}
{"Avg objective": 21.546875, "Games time in secs": 79.20034178718925, "Avg game time in secs": 1.9447892130701803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 56064, "Total num trained steps": 111357, "Timestamp in ms": 1701854190454, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985309848106682, "Avg loss": 0.8072814063634723, "Avg value loss": 0.513304082560353, "Avg policy loss": 0.29397731833159924, "Total num played games": 56090, "Total num trained steps": 111360, "Timestamp in ms": 1701854192121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987520946981852, "Avg loss": 0.8788472132291645, "Avg value loss": 0.5641678557149135, "Avg policy loss": 0.31467935314867646, "Total num played games": 56094, "Total num trained steps": 111488, "Timestamp in ms": 1701854242963, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898028309623133, "Avg loss": 0.3631849088706076, "Avg value loss": 0.08699449215782806, "Avg policy loss": 0.276190418866463, "Total num played games": 56094, "Total num trained steps": 111616, "Timestamp in ms": 1701854292084, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988752046700363, "Avg loss": 0.8372479829704389, "Avg value loss": 0.5564687778532971, "Avg policy loss": 0.28077920945361257, "Total num played games": 56188, "Total num trained steps": 111744, "Timestamp in ms": 1701854341355, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 199.72749078646302, "Avg game time in secs": 1.9605300224066013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.7}, "Total num played games": 56192, "Total num trained steps": 111867, "Timestamp in ms": 1701854390182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879873476205707, "Avg loss": 0.4057757337577641, "Avg value loss": 0.1247862390591763, "Avg policy loss": 0.28098949522245675, "Total num played games": 56272, "Total num trained steps": 111872, "Timestamp in ms": 1701854391899, "logtype": "training_step"}
{"Total num played games": 56284, "Total num trained steps": 111956, "Timestamp in ms": 1701854447560, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0}
{"Avg objective": 21.03125, "Games time in secs": 59.48904825001955, "Avg game time in secs": 1.718777814443456, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 56320, "Total num trained steps": 111959, "Timestamp in ms": 1701854449671, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865905140302955, "Avg loss": 1.1055335144046694, "Avg value loss": 0.8013213549274951, "Avg policy loss": 0.30421216308604926, "Total num played games": 56378, "Total num trained steps": 112000, "Timestamp in ms": 1701854466251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888609031891873, "Avg loss": 0.44367832294665277, "Avg value loss": 0.14975134361884557, "Avg policy loss": 0.2939269777853042, "Total num played games": 56378, "Total num trained steps": 112128, "Timestamp in ms": 1701854517673, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 117.31300028599799, "Avg game time in secs": 1.7747636497224448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.71}, "Total num played games": 56448, "Total num trained steps": 112250, "Timestamp in ms": 1701854566984, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987676181032651, "Avg loss": 0.41421727591659874, "Avg value loss": 0.13979601764003746, "Avg policy loss": 0.2744212648831308, "Total num played games": 56476, "Total num trained steps": 112256, "Timestamp in ms": 1701854569290, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899426304979106, "Avg loss": 0.7211373483296484, "Avg value loss": 0.43081950893974863, "Avg policy loss": 0.2903178418055177, "Total num played games": 56476, "Total num trained steps": 112384, "Timestamp in ms": 1701854622631, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988828395672771, "Avg loss": 0.6913736136630177, "Avg value loss": 0.39405202653142624, "Avg policy loss": 0.2973215834936127, "Total num played games": 56572, "Total num trained steps": 112512, "Timestamp in ms": 1701854675930, "logtype": "training_step"}
{"Total num played games": 56572, "Total num trained steps": 112556, "Timestamp in ms": 1701854760255, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5625}
{"Avg objective": 20.7421875, "Games time in secs": 194.67407089844346, "Avg game time in secs": 1.8850268124806462, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.75, "agent_stopped_0": 0.33}, "Total num played games": 56576, "Total num trained steps": 112557, "Timestamp in ms": 1701854761658, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877880916246073, "Avg loss": 0.87670085625723, "Avg value loss": 0.5730267619364895, "Avg policy loss": 0.30367409193422645, "Total num played games": 56666, "Total num trained steps": 112640, "Timestamp in ms": 1701854799073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900292944622877, "Avg loss": 0.37893076217733324, "Avg value loss": 0.0951471661683172, "Avg policy loss": 0.28378359437920153, "Total num played games": 56666, "Total num trained steps": 112768, "Timestamp in ms": 1701854853636, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 117.19501946493983, "Avg game time in secs": 1.7152338176529156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 56704, "Total num trained steps": 112824, "Timestamp in ms": 1701854878853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889186427539551, "Avg loss": 0.8197299132589251, "Avg value loss": 0.5287467956659384, "Avg policy loss": 0.29098310379777104, "Total num played games": 56762, "Total num trained steps": 112896, "Timestamp in ms": 1701854910474, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 84.9000108782202, "Avg game time in secs": 1.8111194088851335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 56832, "Total num trained steps": 113018, "Timestamp in ms": 1701854963754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878293292060925, "Avg loss": 0.46482949797064066, "Avg value loss": 0.18067328137112781, "Avg policy loss": 0.2841562151443213, "Total num played games": 56858, "Total num trained steps": 113024, "Timestamp in ms": 1701854966257, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900805515494742, "Avg loss": 0.6748968712054193, "Avg value loss": 0.38109909603372216, "Avg policy loss": 0.2937977691181004, "Total num played games": 56858, "Total num trained steps": 113152, "Timestamp in ms": 1701855022319, "logtype": "training_step"}
{"Total num played games": 56858, "Total num trained steps": 113159, "Timestamp in ms": 1701855037057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.83203125}
{"Ratio train steps to played games": 1.9890434049726085, "Avg loss": 0.7802816967014223, "Avg value loss": 0.4952110723243095, "Avg policy loss": 0.2850706276949495, "Total num played games": 56952, "Total num trained steps": 113280, "Timestamp in ms": 1701855091650, "logtype": "training_step"}
{"Avg objective": 22.1875, "Games time in secs": 179.91170880571008, "Avg game time in secs": 1.9346494599449215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.67}, "Total num played games": 56960, "Total num trained steps": 113396, "Timestamp in ms": 1701855143666, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880096764015005, "Avg loss": 0.45852322375867516, "Avg value loss": 0.1919714923715219, "Avg policy loss": 0.26655173173639923, "Total num played games": 57046, "Total num trained steps": 113408, "Timestamp in ms": 1701855148917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902534796480034, "Avg loss": 0.5976396796759218, "Avg value loss": 0.310150681209052, "Avg policy loss": 0.2874889970989898, "Total num played games": 57046, "Total num trained steps": 113536, "Timestamp in ms": 1701855205011, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 81.63929862901568, "Avg game time in secs": 1.8395293228968512, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 57088, "Total num trained steps": 113585, "Timestamp in ms": 1701855225305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891498372475587, "Avg loss": 0.7378061087802052, "Avg value loss": 0.4500047008332331, "Avg policy loss": 0.28780140390153974, "Total num played games": 57142, "Total num trained steps": 113664, "Timestamp in ms": 1701855259274, "logtype": "training_step"}
{"Total num played games": 57142, "Total num trained steps": 113760, "Timestamp in ms": 1701855356966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.26171875}
{"Avg objective": 22.078125, "Games time in secs": 134.30875592306256, "Avg game time in secs": 1.8314753600861877, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.63}, "Total num played games": 57216, "Total num trained steps": 113765, "Timestamp in ms": 1701855359614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988119365434342, "Avg loss": 0.7066009365953505, "Avg value loss": 0.4214345205400605, "Avg policy loss": 0.28516641503665596, "Total num played games": 57236, "Total num trained steps": 113792, "Timestamp in ms": 1701855371829, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903557201761128, "Avg loss": 0.4675384752918035, "Avg value loss": 0.17629288145690225, "Avg policy loss": 0.2912455960176885, "Total num played games": 57236, "Total num trained steps": 113920, "Timestamp in ms": 1701855428720, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893075178789466, "Avg loss": 0.7827818905934691, "Avg value loss": 0.48744512544362806, "Avg policy loss": 0.29533676186110824, "Total num played games": 57330, "Total num trained steps": 114048, "Timestamp in ms": 1701855483306, "logtype": "training_step"}
{"Avg objective": 22.078125, "Games time in secs": 170.3112907167524, "Avg game time in secs": 1.8759000034042401, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 57344, "Total num trained steps": 114152, "Timestamp in ms": 1701855529925, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988280161604904, "Avg loss": 0.5330968287307769, "Avg value loss": 0.25203176992363296, "Avg policy loss": 0.2810650592437014, "Total num played games": 57424, "Total num trained steps": 114176, "Timestamp in ms": 1701855540150, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99052660908331, "Avg loss": 0.4269140784163028, "Avg value loss": 0.13631423664628528, "Avg policy loss": 0.2905998417409137, "Total num played games": 57424, "Total num trained steps": 114304, "Timestamp in ms": 1701855594828, "logtype": "training_step"}
{"Avg objective": 20.6875, "Games time in secs": 79.90990148484707, "Avg game time in secs": 1.7951559900102438, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 57472, "Total num trained steps": 114341, "Timestamp in ms": 1701855609835, "logtype": "played_game"}
{"Total num played games": 57518, "Total num trained steps": 114360, "Timestamp in ms": 1701855665425, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.23046875}
{"Avg objective": 21.8671875, "Games time in secs": 58.74012181535363, "Avg game time in secs": 1.8830594151222613, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 57600, "Total num trained steps": 114366, "Timestamp in ms": 1701855668576, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862528639866694, "Avg loss": 1.2541099714580923, "Avg value loss": 0.9381692003225908, "Avg policy loss": 0.31594075507018715, "Total num played games": 57612, "Total num trained steps": 114432, "Timestamp in ms": 1701855696138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884746233423591, "Avg loss": 0.421743786893785, "Avg value loss": 0.1255221869214438, "Avg policy loss": 0.29622159886639565, "Total num played games": 57612, "Total num trained steps": 114560, "Timestamp in ms": 1701855751685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990696382698049, "Avg loss": 0.3514458411373198, "Avg value loss": 0.07369945029495284, "Avg policy loss": 0.27774639159906656, "Total num played games": 57612, "Total num trained steps": 114688, "Timestamp in ms": 1701855806010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896544553425988, "Avg loss": 0.7006689342670143, "Avg value loss": 0.40817897202214226, "Avg policy loss": 0.29248996765818447, "Total num played games": 57706, "Total num trained steps": 114816, "Timestamp in ms": 1701855862652, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 232.05493614077568, "Avg game time in secs": 1.864733962342143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 57728, "Total num trained steps": 114904, "Timestamp in ms": 1701855900631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886505190311419, "Avg loss": 0.6484722595196217, "Avg value loss": 0.35794398799771443, "Avg policy loss": 0.29052826936822385, "Total num played games": 57800, "Total num trained steps": 114944, "Timestamp in ms": 1701855917502, "logtype": "training_step"}
{"Total num played games": 57800, "Total num trained steps": 114961, "Timestamp in ms": 1701855987730, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8046875}
{"Avg objective": 22.1796875, "Games time in secs": 89.4965028911829, "Avg game time in secs": 1.704925758560421, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 57856, "Total num trained steps": 114966, "Timestamp in ms": 1701855990127, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987632569869071, "Avg loss": 1.3955987172666937, "Avg value loss": 1.0684124596882612, "Avg policy loss": 0.3271862523397431, "Total num played games": 57894, "Total num trained steps": 115072, "Timestamp in ms": 1701856037244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898435070991813, "Avg loss": 0.3778656795620918, "Avg value loss": 0.08149586300714873, "Avg policy loss": 0.2963698176899925, "Total num played games": 57894, "Total num trained steps": 115200, "Timestamp in ms": 1701856094267, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 141.316820980981, "Avg game time in secs": 1.9655304165935377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 57984, "Total num trained steps": 115285, "Timestamp in ms": 1701856131444, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988825274194661, "Avg loss": 0.6254186369478703, "Avg value loss": 0.3404804515012074, "Avg policy loss": 0.2849381845444441, "Total num played games": 57988, "Total num trained steps": 115328, "Timestamp in ms": 1701856149054, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99103262744016, "Avg loss": 0.400676216580905, "Avg value loss": 0.10247675763093866, "Avg policy loss": 0.29819945397321135, "Total num played games": 57988, "Total num trained steps": 115456, "Timestamp in ms": 1701856206212, "logtype": "training_step"}
{"Total num played games": 58082, "Total num trained steps": 115565, "Timestamp in ms": 1701856274253, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8125}
{"Avg objective": 22.203125, "Games time in secs": 145.02459716238081, "Avg game time in secs": 1.7959845938894432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 58112, "Total num trained steps": 115569, "Timestamp in ms": 1701856276469, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867986798679869, "Avg loss": 1.1228359965607524, "Avg value loss": 0.804643035546178, "Avg policy loss": 0.3181929684942588, "Total num played games": 58176, "Total num trained steps": 115584, "Timestamp in ms": 1701856282931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988998899889989, "Avg loss": 0.7815033618826419, "Avg value loss": 0.45497855014400557, "Avg policy loss": 0.3265248058596626, "Total num played games": 58176, "Total num trained steps": 115712, "Timestamp in ms": 1701856339576, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911991199119912, "Avg loss": 0.3613148557487875, "Avg value loss": 0.06785522986319847, "Avg policy loss": 0.29345962568186224, "Total num played games": 58176, "Total num trained steps": 115840, "Timestamp in ms": 1701856396185, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 122.33836090005934, "Avg game time in secs": 1.9631507572776172, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 58240, "Total num trained steps": 115846, "Timestamp in ms": 1701856398808, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901664664492877, "Avg loss": 0.8390692339744419, "Avg value loss": 0.5093739749572705, "Avg policy loss": 0.3296952643431723, "Total num played games": 58270, "Total num trained steps": 115968, "Timestamp in ms": 1701856457134, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989171407031732, "Avg loss": 1.0398067638743669, "Avg value loss": 0.716199801187031, "Avg policy loss": 0.3236069664126262, "Total num played games": 58364, "Total num trained steps": 116096, "Timestamp in ms": 1701856511938, "logtype": "training_step"}
{"Total num played games": 58364, "Total num trained steps": 116167, "Timestamp in ms": 1701856585724, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.97265625}
{"Avg objective": 21.9375, "Games time in secs": 188.22018509358168, "Avg game time in secs": 1.9598460960987723, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.82, "agent_stopped_0": 0.3}, "Total num played games": 58368, "Total num trained steps": 116168, "Timestamp in ms": 1701856587028, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881624414109276, "Avg loss": 1.0974999710451812, "Avg value loss": 0.7562141454836819, "Avg policy loss": 0.34128583292476833, "Total num played games": 58458, "Total num trained steps": 116224, "Timestamp in ms": 1701856611957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903520476239351, "Avg loss": 0.5213283633347601, "Avg value loss": 0.17821955838007852, "Avg policy loss": 0.34310880850534886, "Total num played games": 58458, "Total num trained steps": 116352, "Timestamp in ms": 1701856671427, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 109.80710075050592, "Avg game time in secs": 1.6778147166478448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 58496, "Total num trained steps": 116409, "Timestamp in ms": 1701856696835, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892748573965913, "Avg loss": 0.7623336338438094, "Avg value loss": 0.4280386824393645, "Avg policy loss": 0.33429495082236826, "Total num played games": 58554, "Total num trained steps": 116480, "Timestamp in ms": 1701856727668, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 86.35102197341621, "Avg game time in secs": 1.7594363099342445, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.72, "agent_stopped_0": 0.33}, "Total num played games": 58624, "Total num trained steps": 116602, "Timestamp in ms": 1701856783186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882011935208865, "Avg loss": 0.5131267188116908, "Avg value loss": 0.19347914640093222, "Avg policy loss": 0.31964757200330496, "Total num played games": 58650, "Total num trained steps": 116608, "Timestamp in ms": 1701856786401, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990383631713555, "Avg loss": 0.7481307999696583, "Avg value loss": 0.4139372647332493, "Avg policy loss": 0.3341935347998515, "Total num played games": 58650, "Total num trained steps": 116736, "Timestamp in ms": 1701856844545, "logtype": "training_step"}
{"Total num played games": 58650, "Total num trained steps": 116768, "Timestamp in ms": 1701856923204, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.1953125}
{"Ratio train steps to played games": 1.989377638567343, "Avg loss": 0.8246347687672824, "Avg value loss": 0.49672945524798706, "Avg policy loss": 0.32790530065540224, "Total num played games": 58744, "Total num trained steps": 116864, "Timestamp in ms": 1701856963408, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 228.43677922338247, "Avg game time in secs": 2.04021186218597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.75, "agent_stopped_0": 0.34}, "Total num played games": 58752, "Total num trained steps": 116979, "Timestamp in ms": 1701857011623, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883578639654644, "Avg loss": 0.5379189532250166, "Avg value loss": 0.21938131327624433, "Avg policy loss": 0.31853764201514423, "Total num played games": 58838, "Total num trained steps": 116992, "Timestamp in ms": 1701857017185, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905333288011149, "Avg loss": 0.7072714280802757, "Avg value loss": 0.37289441627217457, "Avg policy loss": 0.33437701454386115, "Total num played games": 58838, "Total num trained steps": 117120, "Timestamp in ms": 1701857075037, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 85.69391503371298, "Avg game time in secs": 1.7730447848443873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.63, "agent_stopped_0": 0.37}, "Total num played games": 58880, "Total num trained steps": 117169, "Timestamp in ms": 1701857097321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894627888824787, "Avg loss": 1.1758250452112406, "Avg value loss": 0.8454908401472494, "Avg policy loss": 0.3303342070430517, "Total num played games": 58934, "Total num trained steps": 117248, "Timestamp in ms": 1701857131781, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 87.08045897074044, "Avg game time in secs": 1.7776389656501124, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 59008, "Total num trained steps": 117361, "Timestamp in ms": 1701857184402, "logtype": "played_game"}
{"Total num played games": 59030, "Total num trained steps": 117369, "Timestamp in ms": 1701857252571, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.96484375}
{"Ratio train steps to played games": 1.98565435106239, "Avg loss": 0.7246762556023896, "Avg value loss": 0.4087516042345669, "Avg policy loss": 0.3159246571594849, "Total num played games": 59110, "Total num trained steps": 117376, "Timestamp in ms": 1701857255992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873993640484406, "Avg loss": 1.314046674175188, "Avg value loss": 0.9672493248945102, "Avg policy loss": 0.3467973512597382, "Total num played games": 59124, "Total num trained steps": 117504, "Timestamp in ms": 1701857312989, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895812191326703, "Avg loss": 0.3952894324902445, "Avg value loss": 0.09054804174229503, "Avg policy loss": 0.304741392377764, "Total num played games": 59124, "Total num trained steps": 117632, "Timestamp in ms": 1701857367469, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 228.73622764274478, "Avg game time in secs": 1.988370019797003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.71, "agent_stopped_0": 0.33}, "Total num played games": 59136, "Total num trained steps": 117739, "Timestamp in ms": 1701857413138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885845519943262, "Avg loss": 0.6123516447842121, "Avg value loss": 0.3193551537115127, "Avg policy loss": 0.2929964793147519, "Total num played games": 59218, "Total num trained steps": 117760, "Timestamp in ms": 1701857421932, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907291701847412, "Avg loss": 0.5691437420900911, "Avg value loss": 0.249864648852963, "Avg policy loss": 0.31927909317892045, "Total num played games": 59218, "Total num trained steps": 117888, "Timestamp in ms": 1701857475429, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 79.56690145842731, "Avg game time in secs": 1.6979091429675464, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 59264, "Total num trained steps": 117929, "Timestamp in ms": 1701857492705, "logtype": "played_game"}
{"Total num played games": 59314, "Total num trained steps": 117970, "Timestamp in ms": 1701857542565, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.12109375}
{"Avg objective": 22.6953125, "Games time in secs": 52.97279031202197, "Avg game time in secs": 1.910140559397405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.7}, "Total num played games": 59392, "Total num trained steps": 117976, "Timestamp in ms": 1701857545678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865169674117964, "Avg loss": 1.3018676445353776, "Avg value loss": 0.9757693072897382, "Avg policy loss": 0.3260983348591253, "Total num played games": 59408, "Total num trained steps": 118016, "Timestamp in ms": 1701857563476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886883921357392, "Avg loss": 0.5005704169161618, "Avg value loss": 0.17414671077858657, "Avg policy loss": 0.326423708233051, "Total num played games": 59408, "Total num trained steps": 118144, "Timestamp in ms": 1701857617650, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908429841098843, "Avg loss": 0.38247728743590415, "Avg value loss": 0.08358027320355177, "Avg policy loss": 0.29889701458159834, "Total num played games": 59408, "Total num trained steps": 118272, "Timestamp in ms": 1701857675556, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898490807031697, "Avg loss": 0.7445251669269055, "Avg value loss": 0.4392650173685979, "Avg policy loss": 0.3052601491799578, "Total num played games": 59502, "Total num trained steps": 118400, "Timestamp in ms": 1701857729411, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 226.19485682435334, "Avg game time in secs": 1.8530554234603187, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 59520, "Total num trained steps": 118496, "Timestamp in ms": 1701857771873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988858312638432, "Avg loss": 0.6848118654452264, "Avg value loss": 0.39252848937758245, "Avg policy loss": 0.29228336818050593, "Total num played games": 59596, "Total num trained steps": 118528, "Timestamp in ms": 1701857786431, "logtype": "training_step"}
{"Total num played games": 59596, "Total num trained steps": 118571, "Timestamp in ms": 1701857819842, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.640625}
{"Avg objective": 22.2265625, "Games time in secs": 50.46672511100769, "Avg game time in secs": 1.7779745189473033, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 59648, "Total num trained steps": 118576, "Timestamp in ms": 1701857822340, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878706651030322, "Avg loss": 0.837563497480005, "Avg value loss": 0.5073167243972421, "Avg policy loss": 0.33024677145294845, "Total num played games": 59690, "Total num trained steps": 118656, "Timestamp in ms": 1701857855959, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900150779024963, "Avg loss": 0.3789944928139448, "Avg value loss": 0.08434926252812147, "Avg policy loss": 0.2946452327305451, "Total num played games": 59690, "Total num trained steps": 118784, "Timestamp in ms": 1701857909157, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 123.3953789640218, "Avg game time in secs": 2.011098763847258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.76, "agent_stopped_0": 0.3}, "Total num played games": 59776, "Total num trained steps": 118877, "Timestamp in ms": 1701857945735, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989010437575271, "Avg loss": 0.6280788192525506, "Avg value loss": 0.3334159295191057, "Avg policy loss": 0.2946628882782534, "Total num played games": 59784, "Total num trained steps": 118912, "Timestamp in ms": 1701857960764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911682055399438, "Avg loss": 0.4372107007075101, "Avg value loss": 0.14205355333979242, "Avg policy loss": 0.2951571453595534, "Total num played games": 59784, "Total num trained steps": 119040, "Timestamp in ms": 1701858016155, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901800327332242, "Avg loss": 0.8656787811778486, "Avg value loss": 0.5481472341634799, "Avg policy loss": 0.3175315427361056, "Total num played games": 59878, "Total num trained steps": 119168, "Timestamp in ms": 1701858074321, "logtype": "training_step"}
{"Total num played games": 59878, "Total num trained steps": 119171, "Timestamp in ms": 1701858113855, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.171875}
{"Avg objective": 22.1640625, "Games time in secs": 170.1668509542942, "Avg game time in secs": 1.827734362334013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 59904, "Total num trained steps": 119175, "Timestamp in ms": 1701858115902, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989194957646902, "Avg loss": 0.7021816866472363, "Avg value loss": 0.381400594022125, "Avg policy loss": 0.32078109320718795, "Total num played games": 59972, "Total num trained steps": 119296, "Timestamp in ms": 1701858169900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913292870006003, "Avg loss": 0.3579243627609685, "Avg value loss": 0.06478665155009367, "Avg policy loss": 0.2931377097265795, "Total num played games": 59972, "Total num trained steps": 119424, "Timestamp in ms": 1701858226459, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 116.06320011615753, "Avg game time in secs": 1.8719725982373348, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 60032, "Total num trained steps": 119439, "Timestamp in ms": 1701858231967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902114200099883, "Avg loss": 0.6599590950645506, "Avg value loss": 0.3451477547350805, "Avg policy loss": 0.314811346703209, "Total num played games": 60070, "Total num trained steps": 119552, "Timestamp in ms": 1701858276655, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 79.42083541676402, "Avg game time in secs": 2.1006816615263233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.84, "agent_stopped_0": 0.25}, "Total num played games": 60160, "Total num trained steps": 119639, "Timestamp in ms": 1701858311388, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892128182966557, "Avg loss": 0.9471402813214809, "Avg value loss": 0.6361944634700194, "Avg policy loss": 0.3109458078397438, "Total num played games": 60164, "Total num trained steps": 119680, "Timestamp in ms": 1701858327309, "logtype": "training_step"}
{"Total num played games": 60164, "Total num trained steps": 119771, "Timestamp in ms": 1701858427801, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.875}
{"Ratio train steps to played games": 1.9882505227521656, "Avg loss": 0.7348072933964431, "Avg value loss": 0.41744492918951437, "Avg policy loss": 0.3173623714828864, "Total num played games": 60258, "Total num trained steps": 119808, "Timestamp in ms": 1701858443872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903747220286103, "Avg loss": 0.43022445496171713, "Avg value loss": 0.11431156389880925, "Avg policy loss": 0.31591289362404495, "Total num played games": 60258, "Total num trained steps": 119936, "Timestamp in ms": 1701858496638, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 213.99470421299338, "Avg game time in secs": 1.78195291555312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 60288, "Total num trained steps": 120009, "Timestamp in ms": 1701858525383, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893955461293744, "Avg loss": 0.8984635230153799, "Avg value loss": 0.5906518527481239, "Avg policy loss": 0.3078116656979546, "Total num played games": 60352, "Total num trained steps": 120064, "Timestamp in ms": 1701858547680, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915164369034994, "Avg loss": 0.42875529965385795, "Avg value loss": 0.11646131644374691, "Avg policy loss": 0.31229398399591446, "Total num played games": 60352, "Total num trained steps": 120192, "Timestamp in ms": 1701858598204, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 75.16706930659711, "Avg game time in secs": 1.7651999653025996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.68, "agent_stopped_0": 0.35}, "Total num played games": 60416, "Total num trained steps": 120198, "Timestamp in ms": 1701858600550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904711487559554, "Avg loss": 0.7018063608556986, "Avg value loss": 0.3869815290381666, "Avg policy loss": 0.31482483202125877, "Total num played games": 60448, "Total num trained steps": 120320, "Timestamp in ms": 1701858648158, "logtype": "training_step"}
{"Total num played games": 60448, "Total num trained steps": 120370, "Timestamp in ms": 1701858705953, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.30078125}
{"Ratio train steps to played games": 1.9894948961051833, "Avg loss": 1.0678815904539078, "Avg value loss": 0.7425973704375792, "Avg policy loss": 0.32528423028998077, "Total num played games": 60542, "Total num trained steps": 120448, "Timestamp in ms": 1701858737180, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 187.79220906086266, "Avg game time in secs": 2.1049960094096605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.82, "agent_stopped_0": 0.23}, "Total num played games": 60544, "Total num trained steps": 120575, "Timestamp in ms": 1701858788343, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991345995045417, "Avg loss": 0.4512685954105109, "Avg value loss": 0.13007002518861555, "Avg policy loss": 0.3211985706584528, "Total num played games": 60548, "Total num trained steps": 120576, "Timestamp in ms": 1701858788592, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905669712061744, "Avg loss": 0.9285500263795257, "Avg value loss": 0.5965394427767023, "Avg policy loss": 0.3320105893071741, "Total num played games": 60638, "Total num trained steps": 120704, "Timestamp in ms": 1701858840991, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 78.98432177305222, "Avg game time in secs": 1.8771749483275926, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.7}, "Total num played games": 60672, "Total num trained steps": 120769, "Timestamp in ms": 1701858867327, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989397082551286, "Avg loss": 0.9726757234893739, "Avg value loss": 0.6384040860866662, "Avg policy loss": 0.33427163935266435, "Total num played games": 60738, "Total num trained steps": 120832, "Timestamp in ms": 1701858893388, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915044947150053, "Avg loss": 0.4271586884278804, "Avg value loss": 0.11059087191824801, "Avg policy loss": 0.31656781339552253, "Total num played games": 60738, "Total num trained steps": 120960, "Timestamp in ms": 1701858946008, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 82.81494360603392, "Avg game time in secs": 1.8030354648071807, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.78}, "Total num played games": 60800, "Total num trained steps": 120971, "Timestamp in ms": 1701858950142, "logtype": "played_game"}
{"Total num played games": 60834, "Total num trained steps": 120973, "Timestamp in ms": 1701859017904, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.734375}
{"Avg objective": 21.6171875, "Games time in secs": 72.37813986837864, "Avg game time in secs": 2.0856913292809622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.84, "agent_stopped_0": 0.26}, "Total num played games": 60928, "Total num trained steps": 120982, "Timestamp in ms": 1701859022520, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873949579831933, "Avg loss": 1.5985966636799276, "Avg value loss": 1.2417729552835226, "Avg policy loss": 0.35682371293660253, "Total num played games": 60928, "Total num trained steps": 121088, "Timestamp in ms": 1701859066316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894957983193278, "Avg loss": 0.42396465060301125, "Avg value loss": 0.1053238658059854, "Avg policy loss": 0.3186407891334966, "Total num played games": 60928, "Total num trained steps": 121216, "Timestamp in ms": 1701859117163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915802258403361, "Avg loss": 0.3707159758778289, "Avg value loss": 0.06490347345243208, "Avg policy loss": 0.30581250321120024, "Total num played games": 60928, "Total num trained steps": 121344, "Timestamp in ms": 1701859167578, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906263314870047, "Avg loss": 0.7380875055678189, "Avg value loss": 0.4216794361418579, "Avg policy loss": 0.31640805944334716, "Total num played games": 61022, "Total num trained steps": 121472, "Timestamp in ms": 1701859219102, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 223.30017897859216, "Avg game time in secs": 1.7897582560690353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.7, "agent_stopped_0": 0.32}, "Total num played games": 61056, "Total num trained steps": 121537, "Timestamp in ms": 1701859245821, "logtype": "played_game"}
{"Total num played games": 61118, "Total num trained steps": 121575, "Timestamp in ms": 1701859332897, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.71484375}
{"Avg objective": 21.984375, "Games time in secs": 89.92558160424232, "Avg game time in secs": 1.9054832177207572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.78}, "Total num played games": 61184, "Total num trained steps": 121582, "Timestamp in ms": 1701859335747, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986538587205123, "Avg loss": 0.9597386631648988, "Avg value loss": 0.6446715098863933, "Avg policy loss": 0.3150671577313915, "Total num played games": 61212, "Total num trained steps": 121600, "Timestamp in ms": 1701859342331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886296804548127, "Avg loss": 0.6828218083828688, "Avg value loss": 0.34766964486334473, "Avg policy loss": 0.3351521666627377, "Total num played games": 61212, "Total num trained steps": 121728, "Timestamp in ms": 1701859393552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907207737045023, "Avg loss": 0.36618446628563106, "Avg value loss": 0.06818568793823943, "Avg policy loss": 0.2979987773578614, "Total num played games": 61212, "Total num trained steps": 121856, "Timestamp in ms": 1701859443992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897563044400222, "Avg loss": 0.6875774117652327, "Avg value loss": 0.38098101745708846, "Avg policy loss": 0.30659639823716134, "Total num played games": 61306, "Total num trained steps": 121984, "Timestamp in ms": 1701859494450, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 206.235156070441, "Avg game time in secs": 2.054655034778989, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 61312, "Total num trained steps": 122104, "Timestamp in ms": 1701859541982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887947882736157, "Avg loss": 0.48539216979406774, "Avg value loss": 0.18528069707099348, "Avg policy loss": 0.3001114741200581, "Total num played games": 61400, "Total num trained steps": 122112, "Timestamp in ms": 1701859544738, "logtype": "training_step"}
{"Total num played games": 61400, "Total num trained steps": 122176, "Timestamp in ms": 1701859593262, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.25390625}
{"Avg objective": 21.1484375, "Games time in secs": 53.56717078015208, "Avg game time in secs": 1.7765448316786205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.73}, "Total num played games": 61440, "Total num trained steps": 122180, "Timestamp in ms": 1701859595549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878362116629265, "Avg loss": 1.2241050985176116, "Avg value loss": 0.8828791353153065, "Avg policy loss": 0.34122596052475274, "Total num played games": 61494, "Total num trained steps": 122240, "Timestamp in ms": 1701859618892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899177155494845, "Avg loss": 0.4180103603284806, "Avg value loss": 0.10836454448872246, "Avg policy loss": 0.3096458137733862, "Total num played games": 61494, "Total num trained steps": 122368, "Timestamp in ms": 1701859669854, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 121.64193587936461, "Avg game time in secs": 1.9798418390419101, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.73}, "Total num played games": 61568, "Total num trained steps": 122483, "Timestamp in ms": 1701859717191, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888943010228932, "Avg loss": 0.5681578833609819, "Avg value loss": 0.277358130144421, "Avg policy loss": 0.2907997544389218, "Total num played games": 61590, "Total num trained steps": 122496, "Timestamp in ms": 1701859722378, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909725604805975, "Avg loss": 0.5113791234325618, "Avg value loss": 0.19921624744893052, "Avg policy loss": 0.312162876711227, "Total num played games": 61590, "Total num trained steps": 122624, "Timestamp in ms": 1701859774240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989949097039847, "Avg loss": 0.9395023547112942, "Avg value loss": 0.6153368334635161, "Avg policy loss": 0.32416551548521966, "Total num played games": 61686, "Total num trained steps": 122752, "Timestamp in ms": 1701859825396, "logtype": "training_step"}
{"Total num played games": 61686, "Total num trained steps": 122778, "Timestamp in ms": 1701859899619, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.46484375}
{"Avg objective": 22.6484375, "Games time in secs": 184.44963560067117, "Avg game time in secs": 1.851631490062573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.69, "agent_stopped_0": 0.41}, "Total num played games": 61696, "Total num trained steps": 122783, "Timestamp in ms": 1701859901641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889932016833927, "Avg loss": 0.9188864035531878, "Avg value loss": 0.5702606982085854, "Avg policy loss": 0.34862570255063474, "Total num played games": 61780, "Total num trained steps": 122880, "Timestamp in ms": 1701859944547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910650696018128, "Avg loss": 0.4136502156034112, "Avg value loss": 0.09678819193504751, "Avg policy loss": 0.31686202657874674, "Total num played games": 61780, "Total num trained steps": 123008, "Timestamp in ms": 1701860001528, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 120.5614494048059, "Avg game time in secs": 1.9333942328958074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.73}, "Total num played games": 61824, "Total num trained steps": 123054, "Timestamp in ms": 1701860022202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901089310534312, "Avg loss": 0.741069016745314, "Avg value loss": 0.4212588735681493, "Avg policy loss": 0.3198101441375911, "Total num played games": 61874, "Total num trained steps": 123136, "Timestamp in ms": 1701860058728, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 81.30915520712733, "Avg game time in secs": 1.9773053797980538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.78}, "Total num played games": 61952, "Total num trained steps": 123242, "Timestamp in ms": 1701860103512, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989027302652811, "Avg loss": 0.7355963739100844, "Avg value loss": 0.4199804991076235, "Avg policy loss": 0.3156158810015768, "Total num played games": 61972, "Total num trained steps": 123264, "Timestamp in ms": 1701860113018, "logtype": "training_step"}
{"Total num played games": 61972, "Total num trained steps": 123381, "Timestamp in ms": 1701860229851, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.16015625}
{"Ratio train steps to played games": 1.9880772081332774, "Avg loss": 0.7077498170547187, "Avg value loss": 0.3779514192137867, "Avg policy loss": 0.32979839690960944, "Total num played games": 62066, "Total num trained steps": 123392, "Timestamp in ms": 1701860235134, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901395288886023, "Avg loss": 0.6367503628134727, "Avg value loss": 0.31244239246007055, "Avg policy loss": 0.324307969189249, "Total num played games": 62066, "Total num trained steps": 123520, "Timestamp in ms": 1701860293079, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 234.57023840397596, "Avg game time in secs": 2.0695650485431543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.8}, "Total num played games": 62080, "Total num trained steps": 123624, "Timestamp in ms": 1701860338082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891891891891893, "Avg loss": 0.5469657860230654, "Avg value loss": 0.24913905543508008, "Avg policy loss": 0.2978267288999632, "Total num played games": 62160, "Total num trained steps": 123648, "Timestamp in ms": 1701860347731, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912483912483911, "Avg loss": 0.42838057153858244, "Avg value loss": 0.13068364854552783, "Avg policy loss": 0.2976969218580052, "Total num played games": 62160, "Total num trained steps": 123776, "Timestamp in ms": 1701860401048, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 78.22431413270533, "Avg game time in secs": 1.8237074456119444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 62208, "Total num trained steps": 123814, "Timestamp in ms": 1701860416306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902338730403495, "Avg loss": 0.7907394380308688, "Avg value loss": 0.48387207914493047, "Avg policy loss": 0.30686735338531435, "Total num played games": 62256, "Total num trained steps": 123904, "Timestamp in ms": 1701860453244, "logtype": "training_step"}
{"Total num played games": 62256, "Total num trained steps": 123985, "Timestamp in ms": 1701860567185, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.47265625}
{"Avg objective": 20.703125, "Games time in secs": 154.03875317424536, "Avg game time in secs": 1.9934775514120702, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.78, "agent_stopped_0": 0.25}, "Total num played games": 62336, "Total num trained steps": 123992, "Timestamp in ms": 1701860570345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892862870890136, "Avg loss": 0.5759213406126946, "Avg value loss": 0.268727066606516, "Avg policy loss": 0.30719427310395986, "Total num played games": 62350, "Total num trained steps": 124032, "Timestamp in ms": 1701860585874, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913392141138733, "Avg loss": 0.38768627657555044, "Avg value loss": 0.08734526520129293, "Avg policy loss": 0.3003410135861486, "Total num played games": 62350, "Total num trained steps": 124160, "Timestamp in ms": 1701860638303, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903276430836243, "Avg loss": 0.7856550817377865, "Avg value loss": 0.46429915237240493, "Avg policy loss": 0.3213559247087687, "Total num played games": 62446, "Total num trained steps": 124288, "Timestamp in ms": 1701860691080, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 158.99234694056213, "Avg game time in secs": 2.0495972197386436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.81}, "Total num played games": 62464, "Total num trained steps": 124385, "Timestamp in ms": 1701860729338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893191775127115, "Avg loss": 0.6327943913638592, "Avg value loss": 0.328349123505177, "Avg policy loss": 0.3044452655594796, "Total num played games": 62542, "Total num trained steps": 124416, "Timestamp in ms": 1701860740903, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913658021809344, "Avg loss": 0.4609158276580274, "Avg value loss": 0.14749038030277006, "Avg policy loss": 0.3134254461620003, "Total num played games": 62542, "Total num trained steps": 124544, "Timestamp in ms": 1701860790727, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 74.46334882453084, "Avg game time in secs": 1.972718321805587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.78, "agent_stopped_0": 0.3}, "Total num played games": 62592, "Total num trained steps": 124578, "Timestamp in ms": 1701860803801, "logtype": "played_game"}
{"Total num played games": 62636, "Total num trained steps": 124588, "Timestamp in ms": 1701860886639, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.30859375}
{"Avg objective": 21.46875, "Games time in secs": 85.95081556402147, "Avg game time in secs": 2.1116420505277347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.83, "agent_stopped_0": 0.23}, "Total num played games": 62720, "Total num trained steps": 124593, "Timestamp in ms": 1701860889752, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874382273234497, "Avg loss": 0.9719959408976138, "Avg value loss": 0.6456471209821757, "Avg policy loss": 0.3263488123193383, "Total num played games": 62730, "Total num trained steps": 124672, "Timestamp in ms": 1701860922825, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989478718316595, "Avg loss": 0.40816277102567255, "Avg value loss": 0.08668350774678402, "Avg policy loss": 0.32147926499601454, "Total num played games": 62730, "Total num trained steps": 124800, "Timestamp in ms": 1701860974027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915192093097402, "Avg loss": 0.356195904314518, "Avg value loss": 0.05681453211582266, "Avg policy loss": 0.299381370190531, "Total num played games": 62730, "Total num trained steps": 124928, "Timestamp in ms": 1701861026337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905768496116134, "Avg loss": 0.7037361760158092, "Avg value loss": 0.392361817706842, "Avg policy loss": 0.31137435138225555, "Total num played games": 62824, "Total num trained steps": 125056, "Timestamp in ms": 1701861076976, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 221.41291208006442, "Avg game time in secs": 1.880586816376308, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 62848, "Total num trained steps": 125142, "Timestamp in ms": 1701861111172, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.7002692900132388, "Avg value loss": 0.3944390660035424, "Avg policy loss": 0.3058302174322307, "Total num played games": 62918, "Total num trained steps": 125184, "Timestamp in ms": 1701861128374, "logtype": "training_step"}
{"Total num played games": 62918, "Total num trained steps": 125192, "Timestamp in ms": 1701861244485, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0625}
{"Avg objective": 22.015625, "Games time in secs": 135.88296588882804, "Avg game time in secs": 2.0042084415908903, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.25, "agent_stopped_more": 0.75, "played_steps": 0.84}, "Total num played games": 62976, "Total num trained steps": 125198, "Timestamp in ms": 1701861247055, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887005649717515, "Avg loss": 0.6892785937525332, "Avg value loss": 0.36623374023474753, "Avg policy loss": 0.3230448487447575, "Total num played games": 63012, "Total num trained steps": 125312, "Timestamp in ms": 1701861294744, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907319240779533, "Avg loss": 0.35581105994060636, "Avg value loss": 0.06522893617511727, "Avg policy loss": 0.2905821221647784, "Total num played games": 63012, "Total num trained steps": 125440, "Timestamp in ms": 1701861348480, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 135.17816845700145, "Avg game time in secs": 2.005536557684536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.73}, "Total num played games": 63104, "Total num trained steps": 125523, "Timestamp in ms": 1701861382234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897949481824233, "Avg loss": 0.7522291862405837, "Avg value loss": 0.45194232018548064, "Avg policy loss": 0.3002868758048862, "Total num played games": 63106, "Total num trained steps": 125568, "Timestamp in ms": 1701861401136, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918232814629353, "Avg loss": 0.3929794596042484, "Avg value loss": 0.09744001657236367, "Avg policy loss": 0.29553944047074765, "Total num played games": 63106, "Total num trained steps": 125696, "Timestamp in ms": 1701861455120, "logtype": "training_step"}
{"Total num played games": 63202, "Total num trained steps": 125794, "Timestamp in ms": 1701861567694, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.28515625}
{"Avg objective": 21.9453125, "Games time in secs": 187.65856283530593, "Avg game time in secs": 1.8555711285298457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 63232, "Total num trained steps": 125796, "Timestamp in ms": 1701861569893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987866531850354, "Avg loss": 1.2184799031820148, "Avg value loss": 0.8969763964123558, "Avg policy loss": 0.32150349603034556, "Total num played games": 63296, "Total num trained steps": 125824, "Timestamp in ms": 1701861582679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898887765419615, "Avg loss": 0.4658509779255837, "Avg value loss": 0.15037323223077692, "Avg policy loss": 0.3154777438612655, "Total num played games": 63296, "Total num trained steps": 125952, "Timestamp in ms": 1701861639896, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919110212335693, "Avg loss": 0.3541187907103449, "Avg value loss": 0.0640364866994787, "Avg policy loss": 0.2900823036907241, "Total num played games": 63296, "Total num trained steps": 126080, "Timestamp in ms": 1701861696413, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 128.89645596034825, "Avg game time in secs": 1.827546703410917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.77, "agent_stopped_0": 0.28}, "Total num played games": 63360, "Total num trained steps": 126086, "Timestamp in ms": 1701861698790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909764947152548, "Avg loss": 0.9792148765409365, "Avg value loss": 0.6678661302430555, "Avg policy loss": 0.31134874653071165, "Total num played games": 63390, "Total num trained steps": 126208, "Timestamp in ms": 1701861753811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900447356814315, "Avg loss": 0.5997909936122596, "Avg value loss": 0.2980926255113445, "Avg policy loss": 0.30169836815912277, "Total num played games": 63484, "Total num trained steps": 126336, "Timestamp in ms": 1701861810553, "logtype": "training_step"}
{"Total num played games": 63484, "Total num trained steps": 126395, "Timestamp in ms": 1701861893424, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6328125}
{"Avg objective": 21.265625, "Games time in secs": 196.17209438607097, "Avg game time in secs": 1.9446046286902856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.81, "agent_stopped_0": 0.29}, "Total num played games": 63488, "Total num trained steps": 126397, "Timestamp in ms": 1701861894962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891157318569317, "Avg loss": 0.6645816941745579, "Avg value loss": 0.3583846246183384, "Avg policy loss": 0.3061970745911822, "Total num played games": 63578, "Total num trained steps": 126464, "Timestamp in ms": 1701861923845, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911290068891756, "Avg loss": 0.37240294413641095, "Avg value loss": 0.0769822486618068, "Avg policy loss": 0.29542069567833096, "Total num played games": 63578, "Total num trained steps": 126592, "Timestamp in ms": 1701861980082, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 110.16355111449957, "Avg game time in secs": 1.8157600358244963, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.67}, "Total num played games": 63616, "Total num trained steps": 126650, "Timestamp in ms": 1701862005126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901215566793353, "Avg loss": 0.904088459443301, "Avg value loss": 0.5996200943773147, "Avg policy loss": 0.30446835688780993, "Total num played games": 63674, "Total num trained steps": 126720, "Timestamp in ms": 1701862034963, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 85.30734202638268, "Avg game time in secs": 2.00139699022111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.77}, "Total num played games": 63744, "Total num trained steps": 126843, "Timestamp in ms": 1701862090434, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891952076276502, "Avg loss": 0.5013045647647232, "Avg value loss": 0.18877245610929094, "Avg policy loss": 0.312532109557651, "Total num played games": 63768, "Total num trained steps": 126848, "Timestamp in ms": 1701862093205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912181658512107, "Avg loss": 0.607793492032215, "Avg value loss": 0.2837494298873935, "Avg policy loss": 0.32404406322166324, "Total num played games": 63768, "Total num trained steps": 126976, "Timestamp in ms": 1701862150520, "logtype": "training_step"}
{"Total num played games": 63768, "Total num trained steps": 126997, "Timestamp in ms": 1701862242489, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3828125}
{"Ratio train steps to played games": 1.9902915661895964, "Avg loss": 0.8954545489978045, "Avg value loss": 0.5595549004210625, "Avg policy loss": 0.33589965372812003, "Total num played games": 63862, "Total num trained steps": 127104, "Timestamp in ms": 1701862289484, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 247.06563708744943, "Avg game time in secs": 2.0040223503747256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.83, "agent_stopped_0": 0.28}, "Total num played games": 63872, "Total num trained steps": 127216, "Timestamp in ms": 1701862337500, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893520545374945, "Avg loss": 0.5580359871964902, "Avg value loss": 0.2469234906602651, "Avg policy loss": 0.3111125029390678, "Total num played games": 63956, "Total num trained steps": 127232, "Timestamp in ms": 1701862344647, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913690662330352, "Avg loss": 0.5706052780151367, "Avg value loss": 0.24899414886021987, "Avg policy loss": 0.32161112502217293, "Total num played games": 63956, "Total num trained steps": 127360, "Timestamp in ms": 1701862401702, "logtype": "training_step"}
{"Avg objective": 20.5859375, "Games time in secs": 83.91126741655171, "Avg game time in secs": 1.831680949719157, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.67}, "Total num played games": 64000, "Total num trained steps": 127405, "Timestamp in ms": 1701862421411, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903672016486604, "Avg loss": 0.6422842126339674, "Avg value loss": 0.3370648431882728, "Avg policy loss": 0.3052193745970726, "Total num played games": 64052, "Total num trained steps": 127488, "Timestamp in ms": 1701862456699, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 86.10179937258363, "Avg game time in secs": 1.9517143787670648, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.77}, "Total num played games": 64128, "Total num trained steps": 127597, "Timestamp in ms": 1701862507513, "logtype": "played_game"}
{"Total num played games": 64146, "Total num trained steps": 127597, "Timestamp in ms": 1701862570775, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.39453125}
{"Ratio train steps to played games": 1.9865348692403486, "Avg loss": 0.7731684744358063, "Avg value loss": 0.4767261256056372, "Avg policy loss": 0.29644236143212765, "Total num played games": 64240, "Total num trained steps": 127616, "Timestamp in ms": 1701862579878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885429638854297, "Avg loss": 0.7530936908442527, "Avg value loss": 0.4300204140308779, "Avg policy loss": 0.32307327806483954, "Total num played games": 64240, "Total num trained steps": 127744, "Timestamp in ms": 1701862637692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905199252801993, "Avg loss": 0.3546641634311527, "Avg value loss": 0.07039031377644278, "Avg policy loss": 0.28427385014947504, "Total num played games": 64240, "Total num trained steps": 127872, "Timestamp in ms": 1701862696925, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 234.37239929288626, "Avg game time in secs": 1.8827605377446162, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 64256, "Total num trained steps": 127973, "Timestamp in ms": 1701862741886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896011440295955, "Avg loss": 0.6556414960650727, "Avg value loss": 0.3711894168809522, "Avg policy loss": 0.2844520864309743, "Total num played games": 64334, "Total num trained steps": 128000, "Timestamp in ms": 1701862753821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916063045978798, "Avg loss": 0.4598658422473818, "Avg value loss": 0.1557840906898491, "Avg policy loss": 0.3040817539440468, "Total num played games": 64334, "Total num trained steps": 128128, "Timestamp in ms": 1701862808610, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 81.55192927643657, "Avg game time in secs": 1.8518583779368782, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.74, "agent_stopped_0": 0.29}, "Total num played games": 64384, "Total num trained steps": 128161, "Timestamp in ms": 1701862823438, "logtype": "played_game"}
{"Total num played games": 64428, "Total num trained steps": 128201, "Timestamp in ms": 1701862877788, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.79296875}
{"Avg objective": 21.9609375, "Games time in secs": 57.335452837869525, "Avg game time in secs": 1.8948932706407504, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 64512, "Total num trained steps": 128205, "Timestamp in ms": 1701862880773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877871113728651, "Avg loss": 1.399272923124954, "Avg value loss": 1.0675068518612534, "Avg policy loss": 0.33176607044879347, "Total num played games": 64522, "Total num trained steps": 128256, "Timestamp in ms": 1701862902088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989770930845293, "Avg loss": 0.4875675397925079, "Avg value loss": 0.16344180615851656, "Avg policy loss": 0.32412573392502964, "Total num played games": 64522, "Total num trained steps": 128384, "Timestamp in ms": 1701862959937, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991754750317721, "Avg loss": 0.38202006090432405, "Avg value loss": 0.08166989299934357, "Avg policy loss": 0.30035016767214984, "Total num played games": 64522, "Total num trained steps": 128512, "Timestamp in ms": 1701863016873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908227064504147, "Avg loss": 0.7499198927544057, "Avg value loss": 0.42500732035841793, "Avg policy loss": 0.3249125686706975, "Total num played games": 64616, "Total num trained steps": 128640, "Timestamp in ms": 1701863074774, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 230.9487018585205, "Avg game time in secs": 1.7819176999473711, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.7, "agent_stopped_0": 0.37}, "Total num played games": 64640, "Total num trained steps": 128724, "Timestamp in ms": 1701863111722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898627766102115, "Avg loss": 1.0165841216221452, "Avg value loss": 0.6808305616723374, "Avg policy loss": 0.3357535731047392, "Total num played games": 64712, "Total num trained steps": 128768, "Timestamp in ms": 1701863131504, "logtype": "training_step"}
{"Total num played games": 64712, "Total num trained steps": 128802, "Timestamp in ms": 1701863228953, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.22265625}
{"Avg objective": 22.7265625, "Games time in secs": 119.90629553608596, "Avg game time in secs": 1.7981003129680175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.72}, "Total num played games": 64768, "Total num trained steps": 128806, "Timestamp in ms": 1701863231629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889362096102212, "Avg loss": 0.827712242025882, "Avg value loss": 0.4892274201265536, "Avg policy loss": 0.3384848271962255, "Total num played games": 64806, "Total num trained steps": 128896, "Timestamp in ms": 1701863268711, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909267660401815, "Avg loss": 0.4060856404248625, "Avg value loss": 0.0879995777795557, "Avg policy loss": 0.3180860634893179, "Total num played games": 64806, "Total num trained steps": 129024, "Timestamp in ms": 1701863325697, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 131.53808279894292, "Avg game time in secs": 1.9931926045828732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.83, "agent_stopped_0": 0.21}, "Total num played games": 64896, "Total num trained steps": 129107, "Timestamp in ms": 1701863363167, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898927646986317, "Avg loss": 0.6804677443578839, "Avg value loss": 0.3652418852725532, "Avg policy loss": 0.3152258680202067, "Total num played games": 64904, "Total num trained steps": 129152, "Timestamp in ms": 1701863381735, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918649081720696, "Avg loss": 0.4223278171848506, "Avg value loss": 0.10111118765780702, "Avg policy loss": 0.3212166327284649, "Total num played games": 64904, "Total num trained steps": 129280, "Timestamp in ms": 1701863437235, "logtype": "training_step"}
{"Total num played games": 65004, "Total num trained steps": 129403, "Timestamp in ms": 1701863547464, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1953125}
{"Avg objective": 21.234375, "Games time in secs": 186.4107050485909, "Avg game time in secs": 1.8783575060515432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.69, "agent_stopped_0": 0.34}, "Total num played games": 65024, "Total num trained steps": 129406, "Timestamp in ms": 1701863549578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885061003718614, "Avg loss": 0.7165240237955004, "Avg value loss": 0.3943813469959423, "Avg policy loss": 0.3221426805248484, "Total num played games": 65074, "Total num trained steps": 129408, "Timestamp in ms": 1701863550297, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989861439675566, "Avg loss": 0.8843627064488828, "Avg value loss": 0.5482330595841631, "Avg policy loss": 0.3361296500079334, "Total num played games": 65098, "Total num trained steps": 129536, "Timestamp in ms": 1701863607532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918123444652678, "Avg loss": 0.37998031452298164, "Avg value loss": 0.07291802420513704, "Avg policy loss": 0.3070622904924676, "Total num played games": 65098, "Total num trained steps": 129664, "Timestamp in ms": 1701863666388, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 127.36873439885676, "Avg game time in secs": 1.943704959587194, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.79, "agent_stopped_0": 0.29}, "Total num played games": 65152, "Total num trained steps": 129690, "Timestamp in ms": 1701863676947, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909037918763037, "Avg loss": 0.7378877096343786, "Avg value loss": 0.42358030276955105, "Avg policy loss": 0.3143074106192216, "Total num played games": 65192, "Total num trained steps": 129792, "Timestamp in ms": 1701863723660, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 86.4556701015681, "Avg game time in secs": 2.028947509592399, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.74, "agent_stopped_0": 0.3}, "Total num played games": 65280, "Total num trained steps": 129878, "Timestamp in ms": 1701863763402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900131728088717, "Avg loss": 0.7191680879332125, "Avg value loss": 0.4151200869237073, "Avg policy loss": 0.3040479860501364, "Total num played games": 65286, "Total num trained steps": 129920, "Timestamp in ms": 1701863780803, "logtype": "training_step"}
{"Total num played games": 65286, "Total num trained steps": 130005, "Timestamp in ms": 1701863882089, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.328125}
{"Ratio train steps to played games": 1.9891098195166719, "Avg loss": 0.7426497051492333, "Avg value loss": 0.4339711411157623, "Avg policy loss": 0.30867856252007186, "Total num played games": 65380, "Total num trained steps": 130048, "Timestamp in ms": 1701863903421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910676047721017, "Avg loss": 0.4249121390748769, "Avg value loss": 0.12046303440001793, "Avg policy loss": 0.3044491048203781, "Total num played games": 65380, "Total num trained steps": 130176, "Timestamp in ms": 1701863960686, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 228.34665512479842, "Avg game time in secs": 1.9823884870274924, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 65408, "Total num trained steps": 130253, "Timestamp in ms": 1701863991749, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901032439367097, "Avg loss": 0.650480208452791, "Avg value loss": 0.3463356938736979, "Avg policy loss": 0.3041445087874308, "Total num played games": 65476, "Total num trained steps": 130304, "Timestamp in ms": 1701864013120, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920581587146435, "Avg loss": 0.39109964785166085, "Avg value loss": 0.08975819961051457, "Avg policy loss": 0.30134144716430455, "Total num played games": 65476, "Total num trained steps": 130432, "Timestamp in ms": 1701864065941, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 79.51464656740427, "Avg game time in secs": 1.814377723087091, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.77, "agent_stopped_0": 0.3}, "Total num played games": 65536, "Total num trained steps": 130446, "Timestamp in ms": 1701864071264, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910937595315072, "Avg loss": 0.7005433267913759, "Avg value loss": 0.385806563164806, "Avg policy loss": 0.3147367693018168, "Total num played games": 65572, "Total num trained steps": 130560, "Timestamp in ms": 1701864120240, "logtype": "training_step"}
{"Total num played games": 65572, "Total num trained steps": 130608, "Timestamp in ms": 1701864233662, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.546875}
{"Avg objective": 22.1328125, "Games time in secs": 167.03624609299004, "Avg game time in secs": 2.042798302252777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.82, "agent_stopped_0": 0.27}, "Total num played games": 65664, "Total num trained steps": 130618, "Timestamp in ms": 1701864238300, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901927938354704, "Avg loss": 1.0920815551653504, "Avg value loss": 0.7700125957489945, "Avg policy loss": 0.3220689685549587, "Total num played games": 65666, "Total num trained steps": 130688, "Timestamp in ms": 1701864269551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921420522035758, "Avg loss": 0.4041911284439266, "Avg value loss": 0.09576432639732957, "Avg policy loss": 0.30842680612113327, "Total num played games": 65666, "Total num trained steps": 130816, "Timestamp in ms": 1701864326149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910592099261015, "Avg loss": 0.9605012407992035, "Avg value loss": 0.627547993150074, "Avg policy loss": 0.33295324875507504, "Total num played games": 65766, "Total num trained steps": 130944, "Timestamp in ms": 1701864378641, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 175.5162877831608, "Avg game time in secs": 1.801199981055106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 65792, "Total num trained steps": 131025, "Timestamp in ms": 1701864413817, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901005131942546, "Avg loss": 0.6831203075125813, "Avg value loss": 0.363812646974111, "Avg policy loss": 0.31930766557343304, "Total num played games": 65862, "Total num trained steps": 131072, "Timestamp in ms": 1701864433630, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920439707266708, "Avg loss": 0.414997543906793, "Avg value loss": 0.09695938212098554, "Avg policy loss": 0.31803815881721675, "Total num played games": 65862, "Total num trained steps": 131200, "Timestamp in ms": 1701864489694, "logtype": "training_step"}
{"Total num played games": 65862, "Total num trained steps": 131208, "Timestamp in ms": 1701864552648, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6953125}
{"Avg objective": 21.7578125, "Games time in secs": 141.5253573153168, "Avg game time in secs": 2.009119302412728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.81, "agent_stopped_0": 0.25}, "Total num played games": 65920, "Total num trained steps": 131213, "Timestamp in ms": 1701864555342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911456122263327, "Avg loss": 0.8501752354204655, "Avg value loss": 0.5239894983824342, "Avg policy loss": 0.32618573028594255, "Total num played games": 65956, "Total num trained steps": 131328, "Timestamp in ms": 1701864604621, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 84.61135688051581, "Avg game time in secs": 2.2211139647843083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.89, "agent_stopped_0": 0.2}, "Total num played games": 66048, "Total num trained steps": 131408, "Timestamp in ms": 1701864639954, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902498107494322, "Avg loss": 0.7300239929463714, "Avg value loss": 0.41419144824612886, "Avg policy loss": 0.31583254667930305, "Total num played games": 66050, "Total num trained steps": 131456, "Timestamp in ms": 1701864659583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921877365632097, "Avg loss": 0.4075074859429151, "Avg value loss": 0.09169805969577283, "Avg policy loss": 0.31580942834261805, "Total num played games": 66050, "Total num trained steps": 131584, "Timestamp in ms": 1701864713625, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912315181568045, "Avg loss": 1.060253934469074, "Avg value loss": 0.7461889057303779, "Avg policy loss": 0.3140650294953957, "Total num played games": 66146, "Total num trained steps": 131712, "Timestamp in ms": 1701864767510, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 158.51509364508092, "Avg game time in secs": 1.7474520189862233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.68, "agent_stopped_0": 0.34}, "Total num played games": 66176, "Total num trained steps": 131786, "Timestamp in ms": 1701864798469, "logtype": "played_game"}
{"Total num played games": 66244, "Total num trained steps": 131812, "Timestamp in ms": 1701864855008, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.09765625}
{"Avg objective": 22.1796875, "Games time in secs": 59.310687217861414, "Avg game time in secs": 2.0715960296074627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.81, "agent_stopped_0": 0.23}, "Total num played games": 66304, "Total num trained steps": 131818, "Timestamp in ms": 1701864857780, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873978715065272, "Avg loss": 1.1336918245069683, "Avg value loss": 0.8187318813288584, "Avg policy loss": 0.31495993107091635, "Total num played games": 66338, "Total num trained steps": 131840, "Timestamp in ms": 1701864866251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893273840031354, "Avg loss": 0.6128475558944046, "Avg value loss": 0.2874743416905403, "Avg policy loss": 0.325373217347078, "Total num played games": 66338, "Total num trained steps": 131968, "Timestamp in ms": 1701864915860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912568964997437, "Avg loss": 0.3722192980349064, "Avg value loss": 0.07437289785593748, "Avg policy loss": 0.29784640204161406, "Total num played games": 66338, "Total num trained steps": 132096, "Timestamp in ms": 1701864965741, "logtype": "training_step"}
{"Avg objective": 22.2578125, "Games time in secs": 139.3614595439285, "Avg game time in secs": 2.1035789689049125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.84, "agent_stopped_0": 0.24}, "Total num played games": 66432, "Total num trained steps": 132173, "Timestamp in ms": 1701864997141, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903061685281633, "Avg loss": 0.9378222567029297, "Avg value loss": 0.6324511841812637, "Avg policy loss": 0.3053710734238848, "Total num played games": 66434, "Total num trained steps": 132224, "Timestamp in ms": 1701865017131, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922328927958575, "Avg loss": 0.4305623737163842, "Avg value loss": 0.11649250696063973, "Avg policy loss": 0.3140698653878644, "Total num played games": 66434, "Total num trained steps": 132352, "Timestamp in ms": 1701865068517, "logtype": "training_step"}
{"Total num played games": 66528, "Total num trained steps": 132412, "Timestamp in ms": 1701865118455, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.62109375}
{"Avg objective": 21.28125, "Games time in secs": 123.5743995681405, "Avg game time in secs": 1.8358383069135016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 66560, "Total num trained steps": 132417, "Timestamp in ms": 1701865120716, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988532316652157, "Avg loss": 1.3809633092023432, "Avg value loss": 1.0296606981137302, "Avg policy loss": 0.3513026061700657, "Total num played games": 66622, "Total num trained steps": 132480, "Timestamp in ms": 1701865145271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904536039146228, "Avg loss": 0.43526355060748756, "Avg value loss": 0.10871400448377244, "Avg policy loss": 0.32654954632744193, "Total num played games": 66622, "Total num trained steps": 132608, "Timestamp in ms": 1701865195123, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923150816522575, "Avg loss": 0.3732211086899042, "Avg value loss": 0.06795108978985809, "Avg policy loss": 0.3052700205007568, "Total num played games": 66624, "Total num trained steps": 132736, "Timestamp in ms": 1701865244733, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 125.36125545203686, "Avg game time in secs": 2.0052797160460614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.84, "agent_stopped_0": 0.2}, "Total num played games": 66688, "Total num trained steps": 132739, "Timestamp in ms": 1701865246078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99136690647482, "Avg loss": 1.0697056006174535, "Avg value loss": 0.7442639484652318, "Avg policy loss": 0.32544164930004627, "Total num played games": 66720, "Total num trained steps": 132864, "Timestamp in ms": 1701865296084, "logtype": "training_step"}
{"Avg objective": 22.203125, "Games time in secs": 79.55933224596083, "Avg game time in secs": 2.041337284303154, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.77, "agent_stopped_0": 0.29}, "Total num played games": 66816, "Total num trained steps": 132938, "Timestamp in ms": 1701865325638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990361878535724, "Avg loss": 0.7146175347734243, "Avg value loss": 0.3938364968635142, "Avg policy loss": 0.3207810327876359, "Total num played games": 66818, "Total num trained steps": 132992, "Timestamp in ms": 1701865347562, "logtype": "training_step"}
{"Total num played games": 66818, "Total num trained steps": 133017, "Timestamp in ms": 1701865380338, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.62109375}
{"Ratio train steps to played games": 1.989478718316595, "Avg loss": 0.6250850141514093, "Avg value loss": 0.29636673734057695, "Avg policy loss": 0.32871827331837267, "Total num played games": 66912, "Total num trained steps": 133120, "Timestamp in ms": 1701865421498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913916786226686, "Avg loss": 0.3736024487297982, "Avg value loss": 0.06371541001135483, "Avg policy loss": 0.30988703796174377, "Total num played games": 66912, "Total num trained steps": 133248, "Timestamp in ms": 1701865471568, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 172.84355419501662, "Avg game time in secs": 1.9247987770359032, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.78, "agent_stopped_0": 0.25}, "Total num played games": 66944, "Total num trained steps": 133318, "Timestamp in ms": 1701865498481, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990508312688416, "Avg loss": 1.0463637688662857, "Avg value loss": 0.7277523450029548, "Avg policy loss": 0.31861142558045685, "Total num played games": 67006, "Total num trained steps": 133376, "Timestamp in ms": 1701865521390, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922401957858293, "Avg loss": 0.4256057236343622, "Avg value loss": 0.11391134446603246, "Avg policy loss": 0.311694375006482, "Total num played games": 67010, "Total num trained steps": 133504, "Timestamp in ms": 1701865571921, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 74.49987935088575, "Avg game time in secs": 1.9330982013052562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.79}, "Total num played games": 67072, "Total num trained steps": 133507, "Timestamp in ms": 1701865572981, "logtype": "played_game"}
{"Total num played games": 67100, "Total num trained steps": 133622, "Timestamp in ms": 1701865663542, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.88671875}
{"Ratio train steps to played games": 1.988734113164866, "Avg loss": 1.0253413273021579, "Avg value loss": 0.7084742580191232, "Avg policy loss": 0.31686706200707704, "Total num played games": 67194, "Total num trained steps": 133632, "Timestamp in ms": 1701865668294, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906539274339972, "Avg loss": 0.7909006846603006, "Avg value loss": 0.4679835536808241, "Avg policy loss": 0.32291713217273355, "Total num played games": 67194, "Total num trained steps": 133760, "Timestamp in ms": 1701865719130, "logtype": "training_step"}
{"Avg objective": 23.15625, "Games time in secs": 193.0801084190607, "Avg game time in secs": 2.009044652164448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.77, "agent_stopped_0": 0.28}, "Total num played games": 67200, "Total num trained steps": 133879, "Timestamp in ms": 1701865766062, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897161539604695, "Avg loss": 0.44783612876199186, "Avg value loss": 0.14981408111634664, "Avg policy loss": 0.2980220497120172, "Total num played games": 67290, "Total num trained steps": 133888, "Timestamp in ms": 1701865769407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991618368256799, "Avg loss": 0.7338321988936514, "Avg value loss": 0.4072447945654858, "Avg policy loss": 0.326587398070842, "Total num played games": 67290, "Total num trained steps": 134016, "Timestamp in ms": 1701865820878, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 77.69643535651267, "Avg game time in secs": 1.8543663956661476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 67328, "Total num trained steps": 134074, "Timestamp in ms": 1701865843758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906805567922121, "Avg loss": 0.7532470498699695, "Avg value loss": 0.44973166767158546, "Avg policy loss": 0.3035153748933226, "Total num played games": 67386, "Total num trained steps": 134144, "Timestamp in ms": 1701865870896, "logtype": "training_step"}
{"Total num played games": 67386, "Total num trained steps": 134223, "Timestamp in ms": 1701865940403, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.91796875}
{"Avg objective": 20.8046875, "Games time in secs": 99.48864023201168, "Avg game time in secs": 1.9816132665291661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.83, "agent_stopped_0": 0.22}, "Total num played games": 67456, "Total num trained steps": 134230, "Timestamp in ms": 1701865943247, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898043864848844, "Avg loss": 0.6325386655516922, "Avg value loss": 0.327240535087185, "Avg policy loss": 0.30529812979511917, "Total num played games": 67480, "Total num trained steps": 134272, "Timestamp in ms": 1701865959882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991701244813278, "Avg loss": 0.39778544241562486, "Avg value loss": 0.0934097999415826, "Avg policy loss": 0.3043756439583376, "Total num played games": 67480, "Total num trained steps": 134400, "Timestamp in ms": 1701866009471, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907070348338216, "Avg loss": 0.796779305441305, "Avg value loss": 0.48647962091490626, "Avg policy loss": 0.3102996813831851, "Total num played games": 67578, "Total num trained steps": 134528, "Timestamp in ms": 1701866059240, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 162.3234855812043, "Avg game time in secs": 2.050049199111527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.85, "agent_stopped_0": 0.25}, "Total num played games": 67584, "Total num trained steps": 134649, "Timestamp in ms": 1701866105571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897745071962645, "Avg loss": 0.4242041378747672, "Avg value loss": 0.12265233517973684, "Avg policy loss": 0.3015518030151725, "Total num played games": 67674, "Total num trained steps": 134656, "Timestamp in ms": 1701866108270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916659278304814, "Avg loss": 0.5349626303650439, "Avg value loss": 0.23312801503925584, "Avg policy loss": 0.3018346189055592, "Total num played games": 67674, "Total num trained steps": 134784, "Timestamp in ms": 1701866158968, "logtype": "training_step"}
{"Total num played games": 67674, "Total num trained steps": 134827, "Timestamp in ms": 1701866224886, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.07421875}
{"Avg objective": 21.4453125, "Games time in secs": 122.05132320895791, "Avg game time in secs": 1.7911385131883435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.7}, "Total num played games": 67712, "Total num trained steps": 134833, "Timestamp in ms": 1701866227622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990792114272223, "Avg loss": 0.7820911183953285, "Avg value loss": 0.46967204537941143, "Avg policy loss": 0.3124190594535321, "Total num played games": 67768, "Total num trained steps": 134912, "Timestamp in ms": 1701866257448, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 78.17133192718029, "Avg game time in secs": 2.116727882254054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.83, "played_steps": 0.9, "agent_stopped_0": 0.17}, "Total num played games": 67840, "Total num trained steps": 135031, "Timestamp in ms": 1701866305797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897447987269405, "Avg loss": 0.5234397908207029, "Avg value loss": 0.22243794216774404, "Avg policy loss": 0.30100184376351535, "Total num played games": 67868, "Total num trained steps": 135040, "Timestamp in ms": 1701866309010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916160782695822, "Avg loss": 0.6014981179032475, "Avg value loss": 0.2757005328312516, "Avg policy loss": 0.32579758565407246, "Total num played games": 67868, "Total num trained steps": 135168, "Timestamp in ms": 1701866359386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907009593314107, "Avg loss": 1.132943311939016, "Avg value loss": 0.8206223385350313, "Avg policy loss": 0.3123209736077115, "Total num played games": 67964, "Total num trained steps": 135296, "Timestamp in ms": 1701866409155, "logtype": "training_step"}
{"Avg objective": 23.3046875, "Games time in secs": 151.22086504288018, "Avg game time in secs": 1.9335684644029243, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.8, "agent_stopped_0": 0.24}, "Total num played games": 67968, "Total num trained steps": 135419, "Timestamp in ms": 1701866457018, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902269119981189, "Avg loss": 0.43688297085464, "Avg value loss": 0.13514458961435594, "Avg policy loss": 0.3017383813858032, "Total num played games": 68044, "Total num trained steps": 135424, "Timestamp in ms": 1701866458646, "logtype": "training_step"}
{"Total num played games": 68060, "Total num trained steps": 135427, "Timestamp in ms": 1701866522591, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8359375}
{"Avg objective": 21.734375, "Games time in secs": 67.97535420767963, "Avg game time in secs": 1.889145530643873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.8}, "Total num played games": 68096, "Total num trained steps": 135431, "Timestamp in ms": 1701866524995, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889074742494939, "Avg loss": 1.5854471630882472, "Avg value loss": 1.2491310731275007, "Avg policy loss": 0.33631607552524656, "Total num played games": 68154, "Total num trained steps": 135552, "Timestamp in ms": 1701866572850, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907855738474631, "Avg loss": 0.3782120442483574, "Avg value loss": 0.0887660016596783, "Avg policy loss": 0.28944604261778295, "Total num played games": 68154, "Total num trained steps": 135680, "Timestamp in ms": 1701866622735, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 145.53878634236753, "Avg game time in secs": 2.0213774534495315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 68224, "Total num trained steps": 135804, "Timestamp in ms": 1701866670534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899191185089673, "Avg loss": 0.45446911826729774, "Avg value loss": 0.16349523959797807, "Avg policy loss": 0.2909738846356049, "Total num played games": 68248, "Total num trained steps": 135808, "Timestamp in ms": 1701866671958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917362637362637, "Avg loss": 0.7965151369571686, "Avg value loss": 0.4958725265460089, "Avg policy loss": 0.3006426057545468, "Total num played games": 68250, "Total num trained steps": 135936, "Timestamp in ms": 1701866721740, "logtype": "training_step"}
{"Total num played games": 68346, "Total num trained steps": 136030, "Timestamp in ms": 1701866770944, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5234375}
{"Avg objective": 20.6171875, "Games time in secs": 102.01054645329714, "Avg game time in secs": 2.117185147551936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.84, "agent_stopped_0": 0.22}, "Total num played games": 68352, "Total num trained steps": 136033, "Timestamp in ms": 1701866772544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880771478667445, "Avg loss": 0.9140906429383904, "Avg value loss": 0.6127727567218244, "Avg policy loss": 0.3013178907567635, "Total num played games": 68440, "Total num trained steps": 136064, "Timestamp in ms": 1701866785214, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989947399181765, "Avg loss": 0.5406673743855208, "Avg value loss": 0.23506193334469572, "Avg policy loss": 0.3056054401677102, "Total num played games": 68440, "Total num trained steps": 136192, "Timestamp in ms": 1701866836714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918176504967855, "Avg loss": 0.33802015148103237, "Avg value loss": 0.06618932296987623, "Avg policy loss": 0.27183082792907953, "Total num played games": 68440, "Total num trained steps": 136320, "Timestamp in ms": 1701866887202, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 136.2295444495976, "Avg game time in secs": 1.6927430731157074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 68480, "Total num trained steps": 136374, "Timestamp in ms": 1701866908774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908952959028832, "Avg loss": 0.7892969337990507, "Avg value loss": 0.5016953749582171, "Avg policy loss": 0.28760156070347875, "Total num played games": 68536, "Total num trained steps": 136448, "Timestamp in ms": 1701866938770, "logtype": "training_step"}
{"Avg objective": 20.2109375, "Games time in secs": 76.71804223582149, "Avg game time in secs": 2.056458104212652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.84, "played_steps": 0.88, "agent_stopped_0": 0.16}, "Total num played games": 68608, "Total num trained steps": 136568, "Timestamp in ms": 1701866985492, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899755216225667, "Avg loss": 0.45583881507627666, "Avg value loss": 0.17320846117218025, "Avg policy loss": 0.2826303538167849, "Total num played games": 68632, "Total num trained steps": 136576, "Timestamp in ms": 1701866988324, "logtype": "training_step"}
{"Total num played games": 68632, "Total num trained steps": 136631, "Timestamp in ms": 1701867081612, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0859375}
{"Ratio train steps to played games": 1.9891162005645606, "Avg loss": 0.880616947542876, "Avg value loss": 0.5680871161748655, "Avg policy loss": 0.3125298283994198, "Total num played games": 68726, "Total num trained steps": 136704, "Timestamp in ms": 1701867110889, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909786689171494, "Avg loss": 0.36436734115704894, "Avg value loss": 0.07430613273754716, "Avg policy loss": 0.2900612074881792, "Total num played games": 68726, "Total num trained steps": 136832, "Timestamp in ms": 1701867159608, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 218.45962868258357, "Avg game time in secs": 2.014291222934844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.81, "agent_stopped_0": 0.26}, "Total num played games": 68736, "Total num trained steps": 136945, "Timestamp in ms": 1701867203952, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900034871556433, "Avg loss": 0.49158879928290844, "Avg value loss": 0.20705438507138751, "Avg policy loss": 0.2845344073139131, "Total num played games": 68824, "Total num trained steps": 136960, "Timestamp in ms": 1701867210038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918633034987796, "Avg loss": 0.4770812336355448, "Avg value loss": 0.18542331518256105, "Avg policy loss": 0.29165792209096253, "Total num played games": 68824, "Total num trained steps": 137088, "Timestamp in ms": 1701867260492, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 77.72576180286705, "Avg game time in secs": 1.8233351422386477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.73, "agent_stopped_0": 0.31}, "Total num played games": 68864, "Total num trained steps": 137142, "Timestamp in ms": 1701867281678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909460243760881, "Avg loss": 1.0121116016525775, "Avg value loss": 0.7134490097814705, "Avg policy loss": 0.2986625889316201, "Total num played games": 68920, "Total num trained steps": 137216, "Timestamp in ms": 1701867311042, "logtype": "training_step"}
{"Total num played games": 68920, "Total num trained steps": 137232, "Timestamp in ms": 1701867383168, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.53125}
{"Avg objective": 21.96875, "Games time in secs": 104.37991155870259, "Avg game time in secs": 2.0194707788759843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.82, "played_steps": 0.89, "agent_stopped_0": 0.18}, "Total num played games": 68992, "Total num trained steps": 137239, "Timestamp in ms": 1701867386058, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900889674558786, "Avg loss": 0.7604970952961594, "Avg value loss": 0.43998357164673507, "Avg policy loss": 0.3205135220196098, "Total num played games": 69014, "Total num trained steps": 137344, "Timestamp in ms": 1701867427068, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991943663604486, "Avg loss": 0.3677661551628262, "Avg value loss": 0.07202974596293643, "Avg policy loss": 0.2957364092580974, "Total num played games": 69014, "Total num trained steps": 137472, "Timestamp in ms": 1701867478851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991086415465648, "Avg loss": 0.5686204795492813, "Avg value loss": 0.27160174486925825, "Avg policy loss": 0.2970187416067347, "Total num played games": 69108, "Total num trained steps": 137600, "Timestamp in ms": 1701867528008, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 183.7937915250659, "Avg game time in secs": 1.9124729020695668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 69120, "Total num trained steps": 137708, "Timestamp in ms": 1701867569852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901739783827523, "Avg loss": 0.5661074497038499, "Avg value loss": 0.2823405030358117, "Avg policy loss": 0.2837669487344101, "Total num played games": 69204, "Total num trained steps": 137728, "Timestamp in ms": 1701867577192, "logtype": "training_step"}
{"Total num played games": 69204, "Total num trained steps": 137835, "Timestamp in ms": 1701867676754, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4375}
{"Avg objective": 22.125, "Games time in secs": 109.41796809248626, "Avg game time in secs": 1.9295941693126224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.79, "agent_stopped_0": 0.27}, "Total num played games": 69248, "Total num trained steps": 137839, "Timestamp in ms": 1701867679270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893214811394269, "Avg loss": 0.8128603480290622, "Avg value loss": 0.5014594016829506, "Avg policy loss": 0.3114009521668777, "Total num played games": 69298, "Total num trained steps": 137856, "Timestamp in ms": 1701867685680, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911685762936882, "Avg loss": 0.509473848156631, "Avg value loss": 0.20786145303281955, "Avg policy loss": 0.30161239916924387, "Total num played games": 69298, "Total num trained steps": 137984, "Timestamp in ms": 1701867735045, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 98.34312211535871, "Avg game time in secs": 2.064506552691455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.84, "played_steps": 0.91, "agent_stopped_0": 0.16}, "Total num played games": 69376, "Total num trained steps": 138092, "Timestamp in ms": 1701867777613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902585237916823, "Avg loss": 0.6738296633120626, "Avg value loss": 0.3795692084822804, "Avg policy loss": 0.2942604561103508, "Total num played games": 69394, "Total num trained steps": 138112, "Timestamp in ms": 1701867785532, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920886531976827, "Avg loss": 0.4751017102971673, "Avg value loss": 0.17640106615726836, "Avg policy loss": 0.2987006448674947, "Total num played games": 69394, "Total num trained steps": 138240, "Timestamp in ms": 1701867836057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912502878194795, "Avg loss": 0.6372257953044027, "Avg value loss": 0.3350539569510147, "Avg policy loss": 0.30217184277717024, "Total num played games": 69488, "Total num trained steps": 138368, "Timestamp in ms": 1701867887456, "logtype": "training_step"}
{"Total num played games": 69488, "Total num trained steps": 138435, "Timestamp in ms": 1701867975416, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7734375}
{"Avg objective": 21.6484375, "Games time in secs": 199.7788061890751, "Avg game time in secs": 1.999645574396709, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.79, "agent_stopped_0": 0.28}, "Total num played games": 69504, "Total num trained steps": 138439, "Timestamp in ms": 1701867977392, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903998160443792, "Avg loss": 0.6115784212015569, "Avg value loss": 0.3135918137268163, "Avg policy loss": 0.29798661079257727, "Total num played games": 69582, "Total num trained steps": 138496, "Timestamp in ms": 1701868001442, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922393722514444, "Avg loss": 0.37760511855594814, "Avg value loss": 0.07480632062652148, "Avg policy loss": 0.3027987991226837, "Total num played games": 69582, "Total num trained steps": 138624, "Timestamp in ms": 1701868055020, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 91.11867251619697, "Avg game time in secs": 1.9274343839060748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.84, "agent_stopped_0": 0.22}, "Total num played games": 69632, "Total num trained steps": 138658, "Timestamp in ms": 1701868068511, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911600941392573, "Avg loss": 0.7940077153034508, "Avg value loss": 0.4901368732971605, "Avg policy loss": 0.3038708340609446, "Total num played games": 69684, "Total num trained steps": 138752, "Timestamp in ms": 1701868108857, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 87.95936936326325, "Avg game time in secs": 2.0207918410160346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.82, "played_steps": 0.88, "agent_stopped_0": 0.18}, "Total num played games": 69760, "Total num trained steps": 138863, "Timestamp in ms": 1701868156470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902550874175982, "Avg loss": 0.6241808170452714, "Avg value loss": 0.32932683124090545, "Avg policy loss": 0.2948539926437661, "Total num played games": 69780, "Total num trained steps": 138880, "Timestamp in ms": 1701868163252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920750931498996, "Avg loss": 0.5106607463676482, "Avg value loss": 0.19819405287853442, "Avg policy loss": 0.31246669543907046, "Total num played games": 69780, "Total num trained steps": 139008, "Timestamp in ms": 1701868218013, "logtype": "training_step"}
{"Total num played games": 69780, "Total num trained steps": 139039, "Timestamp in ms": 1701868290687, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1796875}
{"Ratio train steps to played games": 1.9912413773363482, "Avg loss": 0.6402439037337899, "Avg value loss": 0.3315103801432997, "Avg policy loss": 0.3087335255695507, "Total num played games": 69874, "Total num trained steps": 139136, "Timestamp in ms": 1701868333474, "logtype": "training_step"}
{"Avg objective": 22.859375, "Games time in secs": 218.84684825316072, "Avg game time in secs": 1.9735962791310158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.8, "agent_stopped_0": 0.27}, "Total num played games": 69888, "Total num trained steps": 139241, "Timestamp in ms": 1701868375317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903387165928255, "Avg loss": 0.6824410096742213, "Avg value loss": 0.37682904809480533, "Avg policy loss": 0.3056119686225429, "Total num played games": 69970, "Total num trained steps": 139264, "Timestamp in ms": 1701868383726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921680720308703, "Avg loss": 0.5491040913620964, "Avg value loss": 0.22188811635714956, "Avg policy loss": 0.3272159770131111, "Total num played games": 69970, "Total num trained steps": 139392, "Timestamp in ms": 1701868434643, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 76.01636030711234, "Avg game time in secs": 1.9310165138740558, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.25, "agent_stopped_more": 0.75, "played_steps": 0.8}, "Total num played games": 70016, "Total num trained steps": 139435, "Timestamp in ms": 1701868451333, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913222196848595, "Avg loss": 0.5883740226272494, "Avg value loss": 0.2631753307359759, "Avg policy loss": 0.3251986943650991, "Total num played games": 70064, "Total num trained steps": 139520, "Timestamp in ms": 1701868485205, "logtype": "training_step"}
{"Avg objective": 20.8203125, "Games time in secs": 76.25593808479607, "Avg game time in secs": 2.1267094110808102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.81, "played_steps": 0.87, "agent_stopped_0": 0.19}, "Total num played games": 70144, "Total num trained steps": 139625, "Timestamp in ms": 1701868527589, "logtype": "played_game"}
{"Total num played games": 70158, "Total num trained steps": 139643, "Timestamp in ms": 1701868587381, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.12109375}
{"Ratio train steps to played games": 1.9900815139941856, "Avg loss": 0.6109564304351807, "Avg value loss": 0.2961025492113549, "Avg policy loss": 0.31485388067085296, "Total num played games": 70170, "Total num trained steps": 139648, "Timestamp in ms": 1701868589511, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 1.0268882575910538, "Avg value loss": 0.6821101203095168, "Avg policy loss": 0.34477814531419426, "Total num played games": 70252, "Total num trained steps": 139776, "Timestamp in ms": 1701868640835, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914593178841884, "Avg loss": 0.3804888518061489, "Avg value loss": 0.06874880037503317, "Avg policy loss": 0.3117400516057387, "Total num played games": 70252, "Total num trained steps": 139904, "Timestamp in ms": 1701868690807, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 200.7438303064555, "Avg game time in secs": 2.1279094860656187, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.92, "agent_stopped_0": 0.2}, "Total num played games": 70272, "Total num trained steps": 139997, "Timestamp in ms": 1701868728334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990603587979416, "Avg loss": 0.6533052679151297, "Avg value loss": 0.3380143809481524, "Avg policy loss": 0.31529089028481394, "Total num played games": 70346, "Total num trained steps": 140032, "Timestamp in ms": 1701868742325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924373809456117, "Avg loss": 0.4615364708006382, "Avg value loss": 0.13193681932170875, "Avg policy loss": 0.3295996501110494, "Total num played games": 70346, "Total num trained steps": 140160, "Timestamp in ms": 1701868794418, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 76.60797468572855, "Avg game time in secs": 1.9519378010882065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.79, "agent_stopped_0": 0.27}, "Total num played games": 70400, "Total num trained steps": 140187, "Timestamp in ms": 1701868804942, "logtype": "played_game"}
{"Total num played games": 70442, "Total num trained steps": 140243, "Timestamp in ms": 1701868886663, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.87890625}
{"Avg objective": 21.703125, "Games time in secs": 84.93536284938455, "Avg game time in secs": 2.135091119882418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.84, "agent_stopped_0": 0.2}, "Total num played games": 70528, "Total num trained steps": 140250, "Timestamp in ms": 1701868889877, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888851083134853, "Avg loss": 1.116877919062972, "Avg value loss": 0.7765011101728305, "Avg policy loss": 0.34037680400069803, "Total num played games": 70536, "Total num trained steps": 140288, "Timestamp in ms": 1701868904786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990699784507202, "Avg loss": 0.45753371017053723, "Avg value loss": 0.12769437351380475, "Avg policy loss": 0.3298393350560218, "Total num played games": 70536, "Total num trained steps": 140416, "Timestamp in ms": 1701868956143, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925144607009186, "Avg loss": 0.35760996700264513, "Avg value loss": 0.05012977618025616, "Avg policy loss": 0.3074801885522902, "Total num played games": 70536, "Total num trained steps": 140544, "Timestamp in ms": 1701869005940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916749256689792, "Avg loss": 0.9297888611909002, "Avg value loss": 0.6000485255790409, "Avg policy loss": 0.3297403338365257, "Total num played games": 70630, "Total num trained steps": 140672, "Timestamp in ms": 1701869055648, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 197.47626930475235, "Avg game time in secs": 1.9704413822037168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.78, "agent_stopped_0": 0.3}, "Total num played games": 70656, "Total num trained steps": 140753, "Timestamp in ms": 1701869087354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908376223064306, "Avg loss": 0.7366727699991316, "Avg value loss": 0.41247677203500643, "Avg policy loss": 0.3241959976730868, "Total num played games": 70724, "Total num trained steps": 140800, "Timestamp in ms": 1701869105029, "logtype": "training_step"}
{"Total num played games": 70724, "Total num trained steps": 140846, "Timestamp in ms": 1701869182160, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.15625}
{"Avg objective": 20.890625, "Games time in secs": 97.48473041690886, "Avg game time in secs": 1.9522635947650997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.79}, "Total num played games": 70784, "Total num trained steps": 140850, "Timestamp in ms": 1701869184838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900025417266796, "Avg loss": 1.1044523669406772, "Avg value loss": 0.7633694731630385, "Avg policy loss": 0.3410828937776387, "Total num played games": 70818, "Total num trained steps": 140928, "Timestamp in ms": 1701869216377, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918099918099919, "Avg loss": 0.3883859575726092, "Avg value loss": 0.0701738388161175, "Avg policy loss": 0.31821211567148566, "Total num played games": 70818, "Total num trained steps": 141056, "Timestamp in ms": 1701869266993, "logtype": "training_step"}
{"Avg objective": 22.6171875, "Games time in secs": 115.07730893231928, "Avg game time in secs": 2.119279807433486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.81, "agent_stopped_0": 0.25}, "Total num played games": 70912, "Total num trained steps": 141138, "Timestamp in ms": 1701869299916, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909747292418774, "Avg loss": 0.8177314244676381, "Avg value loss": 0.5038661572325509, "Avg policy loss": 0.3138652725610882, "Total num played games": 70912, "Total num trained steps": 141184, "Timestamp in ms": 1701869318529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927797833935017, "Avg loss": 0.3901818491285667, "Avg value loss": 0.07206577021861449, "Avg policy loss": 0.318116084090434, "Total num played games": 70912, "Total num trained steps": 141312, "Timestamp in ms": 1701869369834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918882379450202, "Avg loss": 0.6904984121210873, "Avg value loss": 0.37422973933280446, "Avg policy loss": 0.31626867945306003, "Total num played games": 71008, "Total num trained steps": 141440, "Timestamp in ms": 1701869420968, "logtype": "training_step"}
{"Total num played games": 71008, "Total num trained steps": 141450, "Timestamp in ms": 1701869495540, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.87890625}
{"Avg objective": 21.3828125, "Games time in secs": 197.69939562305808, "Avg game time in secs": 1.7735901986889075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.73}, "Total num played games": 71040, "Total num trained steps": 141454, "Timestamp in ms": 1701869497615, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910551039351918, "Avg loss": 0.6908310102298856, "Avg value loss": 0.371391302527627, "Avg policy loss": 0.31943971139844507, "Total num played games": 71102, "Total num trained steps": 141568, "Timestamp in ms": 1701869543968, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926871800641277, "Avg loss": 0.35368631675373763, "Avg value loss": 0.05568589497124776, "Avg policy loss": 0.298000420210883, "Total num played games": 71108, "Total num trained steps": 141696, "Timestamp in ms": 1701869595354, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 98.76969660818577, "Avg game time in secs": 1.8164013466303004, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.74, "played_steps": 0.8, "agent_stopped_0": 0.26}, "Total num played games": 71168, "Total num trained steps": 141698, "Timestamp in ms": 1701869596385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919660664625412, "Avg loss": 0.8896701168268919, "Avg value loss": 0.5722525259188842, "Avg policy loss": 0.3174175943713635, "Total num played games": 71198, "Total num trained steps": 141824, "Timestamp in ms": 1701869644363, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991135050216013, "Avg loss": 0.5938917023595423, "Avg value loss": 0.2908925471419934, "Avg policy loss": 0.30299915454816073, "Total num played games": 71292, "Total num trained steps": 141952, "Timestamp in ms": 1701869694537, "logtype": "training_step"}
{"Total num played games": 71292, "Total num trained steps": 142051, "Timestamp in ms": 1701869801897, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.54296875}
{"Avg objective": 21.328125, "Games time in secs": 206.9163855034858, "Avg game time in secs": 2.0611088295845548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.84, "agent_stopped_0": 0.2}, "Total num played games": 71296, "Total num trained steps": 142053, "Timestamp in ms": 1701869803302, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903062225086152, "Avg loss": 0.6894772925879806, "Avg value loss": 0.3820910648209974, "Avg policy loss": 0.3073862273013219, "Total num played games": 71386, "Total num trained steps": 142080, "Timestamp in ms": 1701869813635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992099291177542, "Avg loss": 0.5400669237133116, "Avg value loss": 0.22022819583071396, "Avg policy loss": 0.3198387320153415, "Total num played games": 71386, "Total num trained steps": 142208, "Timestamp in ms": 1701869865148, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 84.9600660726428, "Avg game time in secs": 1.7774091668397887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.72}, "Total num played games": 71424, "Total num trained steps": 142266, "Timestamp in ms": 1701869888262, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912145715005176, "Avg loss": 0.6145465292502195, "Avg value loss": 0.30389411555370316, "Avg policy loss": 0.3106524223694578, "Total num played games": 71482, "Total num trained steps": 142336, "Timestamp in ms": 1701869916220, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 76.84106386639178, "Avg game time in secs": 1.9675204706582008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.78, "agent_stopped_0": 0.28}, "Total num played games": 71552, "Total num trained steps": 142459, "Timestamp in ms": 1701869965103, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903878394992736, "Avg loss": 0.4765856652520597, "Avg value loss": 0.17720365530112758, "Avg policy loss": 0.2993820117553696, "Total num played games": 71576, "Total num trained steps": 142464, "Timestamp in ms": 1701869967011, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921621772661227, "Avg loss": 0.735724062891677, "Avg value loss": 0.4239866082498338, "Avg policy loss": 0.311737451585941, "Total num played games": 71576, "Total num trained steps": 142592, "Timestamp in ms": 1701870019811, "logtype": "training_step"}
{"Total num played games": 71674, "Total num trained steps": 142653, "Timestamp in ms": 1701870126410, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.234375}
{"Avg objective": 21.953125, "Games time in secs": 162.96269777230918, "Avg game time in secs": 2.109787113717175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.23, "agent_stopped_more": 0.77, "played_steps": 0.91}, "Total num played games": 71680, "Total num trained steps": 142657, "Timestamp in ms": 1701870128066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886300300969793, "Avg loss": 1.2532541246619076, "Avg value loss": 0.9440174768678844, "Avg policy loss": 0.30923664662986994, "Total num played games": 71768, "Total num trained steps": 142720, "Timestamp in ms": 1701870152922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904135547876491, "Avg loss": 0.38767239078879356, "Avg value loss": 0.09549068051273935, "Avg policy loss": 0.29218171106185764, "Total num played games": 71768, "Total num trained steps": 142848, "Timestamp in ms": 1701870202849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992197079478319, "Avg loss": 0.3320303170476109, "Avg value loss": 0.05016683042049408, "Avg policy loss": 0.2818634838331491, "Total num played games": 71768, "Total num trained steps": 142976, "Timestamp in ms": 1701870253505, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 147.0734380632639, "Avg game time in secs": 1.9020425881899428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.7}, "Total num played games": 71808, "Total num trained steps": 143029, "Timestamp in ms": 1701870275140, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912475996994405, "Avg loss": 0.8819489682791755, "Avg value loss": 0.5836426680034492, "Avg policy loss": 0.2983063079882413, "Total num played games": 71866, "Total num trained steps": 143104, "Timestamp in ms": 1701870305278, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 79.7057506237179, "Avg game time in secs": 2.01675192687253, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.87, "agent_stopped_0": 0.22}, "Total num played games": 71936, "Total num trained steps": 143227, "Timestamp in ms": 1701870354845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902592891087458, "Avg loss": 0.4442264608805999, "Avg value loss": 0.1613567715685349, "Avg policy loss": 0.28286969009786844, "Total num played games": 71966, "Total num trained steps": 143232, "Timestamp in ms": 1701870356751, "logtype": "training_step"}
{"Total num played games": 71966, "Total num trained steps": 143253, "Timestamp in ms": 1701870415104, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.52734375}
{"Ratio train steps to played games": 1.9894532334165973, "Avg loss": 1.5141987695824355, "Avg value loss": 1.1785813136957586, "Avg policy loss": 0.3356174521613866, "Total num played games": 72060, "Total num trained steps": 143360, "Timestamp in ms": 1701870458293, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912295309464336, "Avg loss": 0.37878471007570624, "Avg value loss": 0.07736313476925716, "Avg policy loss": 0.301421576179564, "Total num played games": 72060, "Total num trained steps": 143488, "Timestamp in ms": 1701870509518, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 202.70197211019695, "Avg game time in secs": 1.9843867711460916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.74}, "Total num played games": 72064, "Total num trained steps": 143612, "Timestamp in ms": 1701870557548, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909612665317327, "Avg loss": 0.34347595658618957, "Avg value loss": 0.05504093144554645, "Avg policy loss": 0.28843502735253423, "Total num played games": 72134, "Total num trained steps": 143616, "Timestamp in ms": 1701870559001, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921695262909886, "Avg loss": 0.6905249394476414, "Avg value loss": 0.38182529248297215, "Avg policy loss": 0.3086996505735442, "Total num played games": 72154, "Total num trained steps": 143744, "Timestamp in ms": 1701870609717, "logtype": "training_step"}
{"Avg objective": 22.96875, "Games time in secs": 74.44223811663687, "Avg game time in secs": 1.8431876023678342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 72192, "Total num trained steps": 143801, "Timestamp in ms": 1701870631990, "logtype": "played_game"}
{"Total num played games": 72248, "Total num trained steps": 143856, "Timestamp in ms": 1701870714374, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.60546875}
{"Avg objective": 22.3515625, "Games time in secs": 85.22114196233451, "Avg game time in secs": 1.9943801844783593, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.86, "agent_stopped_0": 0.21}, "Total num played games": 72320, "Total num trained steps": 143862, "Timestamp in ms": 1701870717211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988775538414752, "Avg loss": 0.8852255404926836, "Avg value loss": 0.5800129790441133, "Avg policy loss": 0.30521255068015307, "Total num played games": 72342, "Total num trained steps": 143872, "Timestamp in ms": 1701870720982, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905449116695695, "Avg loss": 0.8575504710897803, "Avg value loss": 0.5308526688895654, "Avg policy loss": 0.32669780927244574, "Total num played games": 72342, "Total num trained steps": 144000, "Timestamp in ms": 1701870772816, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992314284924387, "Avg loss": 0.3571042369585484, "Avg value loss": 0.059192651184275746, "Avg policy loss": 0.2979115875205025, "Total num played games": 72342, "Total num trained steps": 144128, "Timestamp in ms": 1701870823949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913859745996687, "Avg loss": 0.919048537267372, "Avg value loss": 0.6027662168489769, "Avg policy loss": 0.3162823150632903, "Total num played games": 72440, "Total num trained steps": 144256, "Timestamp in ms": 1701870875122, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 205.2197308782488, "Avg game time in secs": 1.9828210477280663, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.8, "agent_stopped_0": 0.29}, "Total num played games": 72448, "Total num trained steps": 144371, "Timestamp in ms": 1701870922431, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990515054593581, "Avg loss": 0.5935861968901008, "Avg value loss": 0.29004884845926426, "Avg policy loss": 0.303537355735898, "Total num played games": 72536, "Total num trained steps": 144384, "Timestamp in ms": 1701870927381, "logtype": "training_step"}
{"Total num played games": 72536, "Total num trained steps": 144456, "Timestamp in ms": 1701871012626, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4453125}
{"Avg objective": 22.640625, "Games time in secs": 92.54617562703788, "Avg game time in secs": 1.8273443651560228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.71}, "Total num played games": 72576, "Total num trained steps": 144460, "Timestamp in ms": 1701871014977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897012253889577, "Avg loss": 1.118223745143041, "Avg value loss": 0.7751576070440933, "Avg policy loss": 0.3430661408929154, "Total num played games": 72630, "Total num trained steps": 144512, "Timestamp in ms": 1701871035792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914635825416493, "Avg loss": 0.4511971364263445, "Avg value loss": 0.12862631829921156, "Avg policy loss": 0.3225708168465644, "Total num played games": 72630, "Total num trained steps": 144640, "Timestamp in ms": 1701871086523, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 118.13198840245605, "Avg game time in secs": 1.8701402881852118, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.82, "agent_stopped_0": 0.23}, "Total num played games": 72704, "Total num trained steps": 144754, "Timestamp in ms": 1701871133109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905948354096197, "Avg loss": 0.6373647546861321, "Avg value loss": 0.33401921406039037, "Avg policy loss": 0.30334554344881326, "Total num played games": 72726, "Total num trained steps": 144768, "Timestamp in ms": 1701871139109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923548662101587, "Avg loss": 0.5654962565749884, "Avg value loss": 0.24420037004165351, "Avg policy loss": 0.3212958931690082, "Total num played games": 72726, "Total num trained steps": 144896, "Timestamp in ms": 1701871191434, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914860893685975, "Avg loss": 0.8266096755396575, "Avg value loss": 0.5046482626494253, "Avg policy loss": 0.321961424080655, "Total num played games": 72822, "Total num trained steps": 145024, "Timestamp in ms": 1701871242492, "logtype": "training_step"}
{"Total num played games": 72822, "Total num trained steps": 145057, "Timestamp in ms": 1701871318017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.01171875}
{"Avg objective": 22.421875, "Games time in secs": 186.63266735710204, "Avg game time in secs": 2.045327251107665, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.84, "agent_stopped_0": 0.27}, "Total num played games": 72832, "Total num trained steps": 145060, "Timestamp in ms": 1701871319742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906742004498328, "Avg loss": 0.7296003005467355, "Avg value loss": 0.4168521774117835, "Avg policy loss": 0.31274813145864755, "Total num played games": 72916, "Total num trained steps": 145152, "Timestamp in ms": 1701871357360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924296450710406, "Avg loss": 0.3615967461373657, "Avg value loss": 0.05957220625714399, "Avg policy loss": 0.30202454060781747, "Total num played games": 72916, "Total num trained steps": 145280, "Timestamp in ms": 1701871408631, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 107.0613775588572, "Avg game time in secs": 1.8982255207374692, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 72960, "Total num trained steps": 145326, "Timestamp in ms": 1701871426804, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915630307346737, "Avg loss": 0.990798921091482, "Avg value loss": 0.6695697706018109, "Avg policy loss": 0.32122915307991207, "Total num played games": 73012, "Total num trained steps": 145408, "Timestamp in ms": 1701871458684, "logtype": "training_step"}
{"Avg objective": 22.5703125, "Games time in secs": 77.29351017251611, "Avg game time in secs": 2.001356128428597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.81, "agent_stopped_0": 0.23}, "Total num played games": 73088, "Total num trained steps": 145519, "Timestamp in ms": 1701871504097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906442347148132, "Avg loss": 0.7419147149194032, "Avg value loss": 0.43154979537939653, "Avg policy loss": 0.31036490469705313, "Total num played games": 73110, "Total num trained steps": 145536, "Timestamp in ms": 1701871511182, "logtype": "training_step"}
{"Total num played games": 73110, "Total num trained steps": 145658, "Timestamp in ms": 1701871630642, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.41796875}
{"Ratio train steps to played games": 1.9908700762649318, "Avg loss": 0.6193569481838495, "Avg value loss": 0.29176317516248673, "Avg policy loss": 0.32759377802722156, "Total num played games": 73166, "Total num trained steps": 145664, "Timestamp in ms": 1701871633368, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915851592809135, "Avg loss": 0.8609135327860713, "Avg value loss": 0.5186719365010504, "Avg policy loss": 0.3422416008543223, "Total num played games": 73204, "Total num trained steps": 145792, "Timestamp in ms": 1701871686489, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 226.64527714811265, "Avg game time in secs": 1.9849938733532326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.82, "agent_stopped_0": 0.23}, "Total num played games": 73216, "Total num trained steps": 145900, "Timestamp in ms": 1701871730743, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907773745531938, "Avg loss": 0.7317904084920883, "Avg value loss": 0.4160653891740367, "Avg policy loss": 0.3157250180374831, "Total num played games": 73298, "Total num trained steps": 145920, "Timestamp in ms": 1701871739149, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925236704957843, "Avg loss": 0.6031948047457263, "Avg value loss": 0.2747018523514271, "Avg policy loss": 0.3284929491346702, "Total num played games": 73298, "Total num trained steps": 146048, "Timestamp in ms": 1701871790980, "logtype": "training_step"}
{"Avg objective": 23.453125, "Games time in secs": 77.69404728338122, "Avg game time in secs": 1.8747287430305732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.8}, "Total num played games": 73344, "Total num trained steps": 146090, "Timestamp in ms": 1701871808437, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991661443714745, "Avg loss": 0.9453241445589811, "Avg value loss": 0.6143748351896647, "Avg policy loss": 0.3309493063716218, "Total num played games": 73394, "Total num trained steps": 146176, "Timestamp in ms": 1701871842867, "logtype": "training_step"}
{"Total num played games": 73394, "Total num trained steps": 146260, "Timestamp in ms": 1701871942525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.48046875}
{"Avg objective": 20.609375, "Games time in secs": 136.98693548701704, "Avg game time in secs": 2.0874037207686342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.16, "agent_stopped_more": 0.84, "played_steps": 0.88}, "Total num played games": 73472, "Total num trained steps": 146267, "Timestamp in ms": 1701871945425, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990855649902025, "Avg loss": 0.9139264235273004, "Avg value loss": 0.5942125197907444, "Avg policy loss": 0.3197138967225328, "Total num played games": 73488, "Total num trained steps": 146304, "Timestamp in ms": 1701871960379, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925974308730676, "Avg loss": 0.4695158719550818, "Avg value loss": 0.15985260150046088, "Avg policy loss": 0.30966326931957155, "Total num played games": 73488, "Total num trained steps": 146432, "Timestamp in ms": 1701872013734, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917914707401267, "Avg loss": 0.8439179977867752, "Avg value loss": 0.5267021793988533, "Avg policy loss": 0.31721581099554896, "Total num played games": 73582, "Total num trained steps": 146560, "Timestamp in ms": 1701872065659, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 160.78768395073712, "Avg game time in secs": 1.8185108600009698, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.73, "agent_stopped_0": 0.31}, "Total num played games": 73600, "Total num trained steps": 146657, "Timestamp in ms": 1701872106213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990987567186058, "Avg loss": 0.9107933582272381, "Avg value loss": 0.6035291363368742, "Avg policy loss": 0.30726421519648284, "Total num played games": 73676, "Total num trained steps": 146688, "Timestamp in ms": 1701872118116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992724903632119, "Avg loss": 0.6561585182789713, "Avg value loss": 0.3468920389423147, "Avg policy loss": 0.3092664862051606, "Total num played games": 73676, "Total num trained steps": 146816, "Timestamp in ms": 1701872170926, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 77.11227379366755, "Avg game time in secs": 2.0125017874815967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.8, "agent_stopped_0": 0.23}, "Total num played games": 73728, "Total num trained steps": 146846, "Timestamp in ms": 1701872183326, "logtype": "played_game"}
{"Total num played games": 73770, "Total num trained steps": 146861, "Timestamp in ms": 1701872280996, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6484375}
{"Avg objective": 21.609375, "Games time in secs": 101.20831555873156, "Avg game time in secs": 2.040015178194153, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.86, "agent_stopped_0": 0.21}, "Total num played games": 73856, "Total num trained steps": 146868, "Timestamp in ms": 1701872284534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893723600129969, "Avg loss": 1.8648998661665246, "Avg value loss": 1.5230096995364875, "Avg policy loss": 0.3418901312397793, "Total num played games": 73864, "Total num trained steps": 146944, "Timestamp in ms": 1701872316072, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911188129535362, "Avg loss": 0.4056590576656163, "Avg value loss": 0.09956123950541951, "Avg policy loss": 0.30609781900420785, "Total num played games": 73864, "Total num trained steps": 147072, "Timestamp in ms": 1701872368278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928517274991877, "Avg loss": 0.35461412859149277, "Avg value loss": 0.06093019919353537, "Avg policy loss": 0.2936839309986681, "Total num played games": 73864, "Total num trained steps": 147200, "Timestamp in ms": 1701872420628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919956733369388, "Avg loss": 0.7132230205461383, "Avg value loss": 0.4130398443667218, "Avg policy loss": 0.30018317920621485, "Total num played games": 73960, "Total num trained steps": 147328, "Timestamp in ms": 1701872472924, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 223.88354235328734, "Avg game time in secs": 1.9744736349530285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.82, "agent_stopped_0": 0.23}, "Total num played games": 73984, "Total num trained steps": 147413, "Timestamp in ms": 1701872508418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911821103519054, "Avg loss": 0.7194692923221737, "Avg value loss": 0.4263065845007077, "Avg policy loss": 0.29316270793788135, "Total num played games": 74054, "Total num trained steps": 147456, "Timestamp in ms": 1701872526067, "logtype": "training_step"}
{"Total num played games": 74054, "Total num trained steps": 147461, "Timestamp in ms": 1701872597183, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.29296875}
{"Avg objective": 21.34375, "Games time in secs": 91.31164254061878, "Avg game time in secs": 1.9022858724056277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.76, "played_steps": 0.78}, "Total num played games": 74112, "Total num trained steps": 147464, "Timestamp in ms": 1701872599729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903840966715218, "Avg loss": 0.7395211034454405, "Avg value loss": 0.41880778007907793, "Avg policy loss": 0.32071332074701786, "Total num played games": 74148, "Total num trained steps": 147584, "Timestamp in ms": 1701872648925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921238603873335, "Avg loss": 0.35808664199430496, "Avg value loss": 0.06117772441939451, "Avg policy loss": 0.2969089205143973, "Total num played games": 74148, "Total num trained steps": 147712, "Timestamp in ms": 1701872700888, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 133.13162853568792, "Avg game time in secs": 2.110833441009163, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.86, "agent_stopped_0": 0.23}, "Total num played games": 74240, "Total num trained steps": 147792, "Timestamp in ms": 1701872732861, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913256647180841, "Avg loss": 0.6670850480441004, "Avg value loss": 0.37003447400638834, "Avg policy loss": 0.2970505739795044, "Total num played games": 74242, "Total num trained steps": 147840, "Timestamp in ms": 1701872751892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930497562026885, "Avg loss": 0.36422273819334805, "Avg value loss": 0.07389220400364138, "Avg policy loss": 0.2903305316576734, "Total num played games": 74242, "Total num trained steps": 147968, "Timestamp in ms": 1701872805103, "logtype": "training_step"}
{"Total num played games": 74338, "Total num trained steps": 148062, "Timestamp in ms": 1701872927614, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5546875}
{"Avg objective": 20.9921875, "Games time in secs": 197.05172087438405, "Avg game time in secs": 1.9878982487716712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.79, "agent_stopped_0": 0.27}, "Total num played games": 74368, "Total num trained steps": 148066, "Timestamp in ms": 1701872929913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896818572656922, "Avg loss": 1.1747387528885156, "Avg value loss": 0.8603895863925572, "Avg policy loss": 0.31434916483704, "Total num played games": 74432, "Total num trained steps": 148096, "Timestamp in ms": 1701872942453, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914015477214102, "Avg loss": 0.48753606411628425, "Avg value loss": 0.1834285364311654, "Avg policy loss": 0.3041075220098719, "Total num played games": 74432, "Total num trained steps": 148224, "Timestamp in ms": 1701873000284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931212381771282, "Avg loss": 0.3402822343632579, "Avg value loss": 0.055137662289780565, "Avg policy loss": 0.28514457249548286, "Total num played games": 74432, "Total num trained steps": 148352, "Timestamp in ms": 1701873056305, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 128.8782131243497, "Avg game time in secs": 1.9685478561586933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.83, "played_steps": 0.86, "agent_stopped_0": 0.17}, "Total num played games": 74496, "Total num trained steps": 148358, "Timestamp in ms": 1701873058791, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923114080991868, "Avg loss": 0.6129244187613949, "Avg value loss": 0.31161032064119354, "Avg policy loss": 0.30131409503519535, "Total num played games": 74526, "Total num trained steps": 148480, "Timestamp in ms": 1701873112345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914770443032885, "Avg loss": 0.6083770928671584, "Avg value loss": 0.313387984293513, "Avg policy loss": 0.29498910484835505, "Total num played games": 74622, "Total num trained steps": 148608, "Timestamp in ms": 1701873166101, "logtype": "training_step"}
{"Total num played games": 74622, "Total num trained steps": 148666, "Timestamp in ms": 1701873270079, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.265625}
{"Avg objective": 21.65625, "Games time in secs": 212.32036079652607, "Avg game time in secs": 1.9815263797790976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.88, "agent_stopped_0": 0.2}, "Total num played games": 74624, "Total num trained steps": 148667, "Timestamp in ms": 1701873271112, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990684726163071, "Avg loss": 0.5775438251439482, "Avg value loss": 0.2770016985014081, "Avg policy loss": 0.3005421214038506, "Total num played games": 74716, "Total num trained steps": 148736, "Timestamp in ms": 1701873300882, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923978799721613, "Avg loss": 0.3455246662488207, "Avg value loss": 0.06591356996796094, "Avg policy loss": 0.27961109671741724, "Total num played games": 74716, "Total num trained steps": 148864, "Timestamp in ms": 1701873357497, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 113.43359842710197, "Avg game time in secs": 1.8538369116868125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.77}, "Total num played games": 74752, "Total num trained steps": 148925, "Timestamp in ms": 1701873384546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915521574079025, "Avg loss": 0.9767202998045832, "Avg value loss": 0.6788677065778757, "Avg policy loss": 0.2978526073275134, "Total num played games": 74812, "Total num trained steps": 148992, "Timestamp in ms": 1701873412622, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 83.72247731126845, "Avg game time in secs": 1.8950009790132754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.77, "agent_stopped_0": 0.27}, "Total num played games": 74880, "Total num trained steps": 149119, "Timestamp in ms": 1701873468268, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911870743757512, "Avg loss": 0.3869355086935684, "Avg value loss": 0.09370786070940085, "Avg policy loss": 0.2932276469655335, "Total num played games": 74890, "Total num trained steps": 149120, "Timestamp in ms": 1701873468846, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924173653014365, "Avg loss": 0.6725639221258461, "Avg value loss": 0.3671429870300926, "Avg policy loss": 0.30542093503754586, "Total num played games": 74908, "Total num trained steps": 149248, "Timestamp in ms": 1701873525730, "logtype": "training_step"}
{"Total num played games": 74908, "Total num trained steps": 149269, "Timestamp in ms": 1701873615275, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.40625}
{"Ratio train steps to played games": 1.991613556971814, "Avg loss": 0.9060241191182286, "Avg value loss": 0.6025156468967907, "Avg policy loss": 0.3035084776347503, "Total num played games": 75002, "Total num trained steps": 149376, "Timestamp in ms": 1701873664047, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 247.4896423444152, "Avg game time in secs": 2.0602303616906283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.86, "agent_stopped_0": 0.2}, "Total num played games": 75008, "Total num trained steps": 149496, "Timestamp in ms": 1701873715758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990825077234473, "Avg loss": 0.4370623950380832, "Avg value loss": 0.15360238713037688, "Avg policy loss": 0.2834600085625425, "Total num played games": 75096, "Total num trained steps": 149504, "Timestamp in ms": 1701873719213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924898133106075, "Avg loss": 0.7371278440114111, "Avg value loss": 0.42548489436740056, "Avg policy loss": 0.31164295016787946, "Total num played games": 75098, "Total num trained steps": 149632, "Timestamp in ms": 1701873775074, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 84.07476462423801, "Avg game time in secs": 1.8675836186303059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.25, "agent_stopped_more": 0.75, "played_steps": 0.8}, "Total num played games": 75136, "Total num trained steps": 149689, "Timestamp in ms": 1701873799833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991701244813278, "Avg loss": 0.7556737462291494, "Avg value loss": 0.4487086881999858, "Avg policy loss": 0.30696506111416966, "Total num played games": 75192, "Total num trained steps": 149760, "Timestamp in ms": 1701873830880, "logtype": "training_step"}
{"Total num played games": 75192, "Total num trained steps": 149872, "Timestamp in ms": 1701873983509, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0390625}
{"Avg objective": 21.21875, "Games time in secs": 186.56515724770725, "Avg game time in secs": 2.0297112200350966, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.17, "agent_stopped_more": 0.83, "played_steps": 0.86}, "Total num played games": 75264, "Total num trained steps": 149876, "Timestamp in ms": 1701873986398, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909146454852165, "Avg loss": 0.5657358790049329, "Avg value loss": 0.2567378152743913, "Avg policy loss": 0.3089980542426929, "Total num played games": 75286, "Total num trained steps": 149888, "Timestamp in ms": 1701873991892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926148287862284, "Avg loss": 0.5376420505344868, "Avg value loss": 0.21244459910667501, "Avg policy loss": 0.3251974533777684, "Total num played games": 75286, "Total num trained steps": 150016, "Timestamp in ms": 1701874048836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917619590883766, "Avg loss": 0.8088194497395307, "Avg value loss": 0.47878750419477, "Avg policy loss": 0.3300319471163675, "Total num played games": 75382, "Total num trained steps": 150144, "Timestamp in ms": 1701874104591, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 166.58103319443762, "Avg game time in secs": 2.1020184664375847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.91, "agent_stopped_0": 0.21}, "Total num played games": 75392, "Total num trained steps": 150255, "Timestamp in ms": 1701874152979, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909772642959351, "Avg loss": 0.5391295510344207, "Avg value loss": 0.21821550981258042, "Avg policy loss": 0.3209140438120812, "Total num played games": 75476, "Total num trained steps": 150272, "Timestamp in ms": 1701874160350, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926864168742382, "Avg loss": 0.518658546730876, "Avg value loss": 0.18546892740414478, "Avg policy loss": 0.33318961353506893, "Total num played games": 75476, "Total num trained steps": 150400, "Timestamp in ms": 1701874215684, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 82.81876705773175, "Avg game time in secs": 1.8721166397590423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.78, "agent_stopped_0": 0.28}, "Total num played games": 75520, "Total num trained steps": 150445, "Timestamp in ms": 1701874235798, "logtype": "played_game"}
{"Total num played games": 75570, "Total num trained steps": 150474, "Timestamp in ms": 1701874317700, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4921875}
{"Avg objective": 20.359375, "Games time in secs": 84.79110221751034, "Avg game time in secs": 2.038778834787081, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.8, "agent_stopped_0": 0.23}, "Total num played games": 75648, "Total num trained steps": 150478, "Timestamp in ms": 1701874320589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894269401564812, "Avg loss": 1.1256835693493485, "Avg value loss": 0.7768170162162278, "Avg policy loss": 0.348866552230902, "Total num played games": 75664, "Total num trained steps": 150528, "Timestamp in ms": 1701874343101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911186297314443, "Avg loss": 0.4265469037927687, "Avg value loss": 0.09742311455192976, "Avg policy loss": 0.3291237900266424, "Total num played games": 75664, "Total num trained steps": 150656, "Timestamp in ms": 1701874399658, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928103193064073, "Avg loss": 0.36201656982302666, "Avg value loss": 0.05095972420531325, "Avg policy loss": 0.31105684651993215, "Total num played games": 75664, "Total num trained steps": 150784, "Timestamp in ms": 1701874456064, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991974656810982, "Avg loss": 0.6953414524905384, "Avg value loss": 0.3694753643794684, "Avg policy loss": 0.3258660949068144, "Total num played games": 75760, "Total num trained steps": 150912, "Timestamp in ms": 1701874514409, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 237.65629485808313, "Avg game time in secs": 2.0022035115835024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.81, "agent_stopped_0": 0.23}, "Total num played games": 75776, "Total num trained steps": 151013, "Timestamp in ms": 1701874558277, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911936087747515, "Avg loss": 0.6705912668257952, "Avg value loss": 0.34348977885383647, "Avg policy loss": 0.3271014934871346, "Total num played games": 75854, "Total num trained steps": 151040, "Timestamp in ms": 1701874569570, "logtype": "training_step"}
{"Total num played games": 75854, "Total num trained steps": 151074, "Timestamp in ms": 1701874639759, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3125}
{"Avg objective": 22.5078125, "Games time in secs": 83.83960579521954, "Avg game time in secs": 1.9637618307460798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.26, "agent_stopped_more": 0.74, "played_steps": 0.8}, "Total num played games": 75904, "Total num trained steps": 151076, "Timestamp in ms": 1701874642117, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990414494127561, "Avg loss": 1.0923965370748192, "Avg value loss": 0.7320222000125796, "Avg policy loss": 0.3603743454441428, "Total num played games": 75948, "Total num trained steps": 151168, "Timestamp in ms": 1701874682302, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920998577974403, "Avg loss": 0.39400247018784285, "Avg value loss": 0.05841187230544165, "Avg policy loss": 0.3355905970092863, "Total num played games": 75948, "Total num trained steps": 151296, "Timestamp in ms": 1701874738967, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 136.99639860726893, "Avg game time in secs": 1.988382119234302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.84, "agent_stopped_0": 0.2}, "Total num played games": 76032, "Total num trained steps": 151390, "Timestamp in ms": 1701874779114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991307435364667, "Avg loss": 0.6092458192724735, "Avg value loss": 0.28626229817746207, "Avg policy loss": 0.3229835160309449, "Total num played games": 76042, "Total num trained steps": 151424, "Timestamp in ms": 1701874793910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930038662844218, "Avg loss": 0.4077419221866876, "Avg value loss": 0.09090408848715015, "Avg policy loss": 0.31683783687185496, "Total num played games": 76042, "Total num trained steps": 151552, "Timestamp in ms": 1701874846853, "logtype": "training_step"}
{"Total num played games": 76136, "Total num trained steps": 151676, "Timestamp in ms": 1701874965782, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.11328125}
{"Ratio train steps to played games": 1.9915835084033613, "Avg loss": 1.0188188997562975, "Avg value loss": 0.6787739499704912, "Avg policy loss": 0.3400449502514675, "Total num played games": 76156, "Total num trained steps": 151680, "Timestamp in ms": 1701874967792, "logtype": "training_step"}
{"Avg objective": 21.96875, "Games time in secs": 188.68092255480587, "Avg game time in secs": 1.8355613097955938, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.75, "agent_stopped_0": 0.33}, "Total num played games": 76160, "Total num trained steps": 151680, "Timestamp in ms": 1701874967795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991433818706546, "Avg loss": 0.8088885776232928, "Avg value loss": 0.4680032011528965, "Avg policy loss": 0.34088538284413517, "Total num played games": 76230, "Total num trained steps": 151808, "Timestamp in ms": 1701875023236, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931260658533385, "Avg loss": 0.37385340314358473, "Avg value loss": 0.05483676024596207, "Avg policy loss": 0.31901664251927286, "Total num played games": 76230, "Total num trained steps": 151936, "Timestamp in ms": 1701875082338, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 122.32066799513996, "Avg game time in secs": 1.8775768009363674, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.74}, "Total num played games": 76288, "Total num trained steps": 151954, "Timestamp in ms": 1701875090116, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923484094125046, "Avg loss": 1.0059806003700942, "Avg value loss": 0.6655187653959729, "Avg policy loss": 0.3404618395725265, "Total num played games": 76324, "Total num trained steps": 152064, "Timestamp in ms": 1701875134690, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 79.78476520814002, "Avg game time in secs": 2.098343678910169, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.86, "agent_stopped_0": 0.24}, "Total num played games": 76416, "Total num trained steps": 152144, "Timestamp in ms": 1701875169901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991572666125782, "Avg loss": 0.6464731784071773, "Avg value loss": 0.3195300171501003, "Avg policy loss": 0.3269431689986959, "Total num played games": 76418, "Total num trained steps": 152192, "Timestamp in ms": 1701875191125, "logtype": "training_step"}
{"Total num played games": 76418, "Total num trained steps": 152277, "Timestamp in ms": 1701875286581, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2734375}
{"Ratio train steps to played games": 1.9907988289418654, "Avg loss": 0.6547967344522476, "Avg value loss": 0.3319420573534444, "Avg policy loss": 0.32285467733163387, "Total num played games": 76512, "Total num trained steps": 152320, "Timestamp in ms": 1701875305858, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924717691342535, "Avg loss": 0.4095657952129841, "Avg value loss": 0.09136459656292573, "Avg policy loss": 0.3182011980097741, "Total num played games": 76512, "Total num trained steps": 152448, "Timestamp in ms": 1701875361603, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 222.45343077741563, "Avg game time in secs": 1.8762351183831925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.74, "agent_stopped_0": 0.28}, "Total num played games": 76544, "Total num trained steps": 152518, "Timestamp in ms": 1701875392354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916457811194652, "Avg loss": 0.7024766139220446, "Avg value loss": 0.38473323185462505, "Avg policy loss": 0.3177433816017583, "Total num played games": 76608, "Total num trained steps": 152576, "Timestamp in ms": 1701875416396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933166248955723, "Avg loss": 0.38757670391350985, "Avg value loss": 0.06957274305750616, "Avg policy loss": 0.3180039597209543, "Total num played games": 76608, "Total num trained steps": 152704, "Timestamp in ms": 1701875470494, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 80.58294121176004, "Avg game time in secs": 1.9638245848473161, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.25, "agent_stopped_more": 0.75, "played_steps": 0.83}, "Total num played games": 76672, "Total num trained steps": 152710, "Timestamp in ms": 1701875472937, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925425673385309, "Avg loss": 0.8900961282197386, "Avg value loss": 0.559684910957003, "Avg policy loss": 0.33041122381109744, "Total num played games": 76702, "Total num trained steps": 152832, "Timestamp in ms": 1701875524977, "logtype": "training_step"}
{"Total num played games": 76702, "Total num trained steps": 152878, "Timestamp in ms": 1701875621098, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.17578125}
{"Ratio train steps to played games": 1.9917704047085785, "Avg loss": 0.7549587609246373, "Avg value loss": 0.4234906022029463, "Avg policy loss": 0.33146816003136337, "Total num played games": 76796, "Total num trained steps": 152960, "Timestamp in ms": 1701875659295, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 238.82060710899532, "Avg game time in secs": 2.085539187755785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.82, "played_steps": 0.91, "agent_stopped_0": 0.18}, "Total num played games": 76800, "Total num trained steps": 153083, "Timestamp in ms": 1701875711758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911037119891788, "Avg loss": 0.370919999666512, "Avg value loss": 0.06647255612188019, "Avg policy loss": 0.30444744252599776, "Total num played games": 76886, "Total num trained steps": 153088, "Timestamp in ms": 1701875713542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992613015658326, "Avg loss": 0.8188460520468652, "Avg value loss": 0.49971230342634954, "Avg policy loss": 0.3191337457392365, "Total num played games": 76892, "Total num trained steps": 153216, "Timestamp in ms": 1701875768413, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 83.87086434662342, "Avg game time in secs": 1.857725197725813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.84, "agent_stopped_0": 0.21}, "Total num played games": 76928, "Total num trained steps": 153277, "Timestamp in ms": 1701875795629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917779394191302, "Avg loss": 0.8400281481444836, "Avg value loss": 0.5281956149556208, "Avg policy loss": 0.31183255335781723, "Total num played games": 76988, "Total num trained steps": 153344, "Timestamp in ms": 1701875824646, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 82.79696535505354, "Avg game time in secs": 2.0163731743377866, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.23, "agent_stopped_more": 0.77, "played_steps": 0.82}, "Total num played games": 77056, "Total num trained steps": 153470, "Timestamp in ms": 1701875878426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991280880215902, "Avg loss": 0.40505165548529476, "Avg value loss": 0.08613866780069657, "Avg policy loss": 0.31891298899427056, "Total num played games": 77070, "Total num trained steps": 153472, "Timestamp in ms": 1701875878886, "logtype": "training_step"}
{"Total num played games": 77082, "Total num trained steps": 153482, "Timestamp in ms": 1701875951250, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.171875}
{"Ratio train steps to played games": 1.9902430807504923, "Avg loss": 1.2001096005551517, "Avg value loss": 0.8737197866430506, "Avg policy loss": 0.32638981274794787, "Total num played games": 77176, "Total num trained steps": 153600, "Timestamp in ms": 1701876002996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919145848450295, "Avg loss": 0.3592515920754522, "Avg value loss": 0.05946904080337845, "Avg policy loss": 0.29978255031164736, "Total num played games": 77176, "Total num trained steps": 153728, "Timestamp in ms": 1701876061505, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 233.75591401942074, "Avg game time in secs": 2.0663987649895716, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.85, "agent_stopped_0": 0.22}, "Total num played games": 77184, "Total num trained steps": 153844, "Timestamp in ms": 1701876112182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910448533788856, "Avg loss": 0.44721950218081474, "Avg value loss": 0.16317874695232604, "Avg policy loss": 0.2840407539624721, "Total num played games": 77274, "Total num trained steps": 153856, "Timestamp in ms": 1701876116673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927012966845252, "Avg loss": 0.6970339459367096, "Avg value loss": 0.38696421097847633, "Avg policy loss": 0.31006973481271416, "Total num played games": 77274, "Total num trained steps": 153984, "Timestamp in ms": 1701876171083, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 84.09179086238146, "Avg game time in secs": 1.9130300002580043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.81, "agent_stopped_0": 0.23}, "Total num played games": 77312, "Total num trained steps": 154041, "Timestamp in ms": 1701876196274, "logtype": "played_game"}
{"Total num played games": 77370, "Total num trained steps": 154084, "Timestamp in ms": 1701876285641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.21875}
{"Avg objective": 22.1640625, "Games time in secs": 92.06095334328711, "Avg game time in secs": 2.0007733752718195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.83, "agent_stopped_0": 0.22}, "Total num played games": 77440, "Total num trained steps": 154090, "Timestamp in ms": 1701876288335, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894531653413199, "Avg loss": 1.0377490285318345, "Avg value loss": 0.7311398638994433, "Avg policy loss": 0.306609173421748, "Total num played games": 77464, "Total num trained steps": 154112, "Timestamp in ms": 1701876298029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911184550242693, "Avg loss": 0.5010868748649955, "Avg value loss": 0.1878136352461297, "Avg policy loss": 0.31327323988080025, "Total num played games": 77464, "Total num trained steps": 154240, "Timestamp in ms": 1701876352783, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927708354848703, "Avg loss": 0.32598671689629555, "Avg value loss": 0.04535494852461852, "Avg policy loss": 0.28063177049625665, "Total num played games": 77464, "Total num trained steps": 154368, "Timestamp in ms": 1701876409384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919546157813306, "Avg loss": 0.9288648868678138, "Avg value loss": 0.63317659436143, "Avg policy loss": 0.29568829969502985, "Total num played games": 77560, "Total num trained steps": 154496, "Timestamp in ms": 1701876467222, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 229.4569289702922, "Avg game time in secs": 1.9517660995479673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.83, "agent_stopped_0": 0.24}, "Total num played games": 77568, "Total num trained steps": 154611, "Timestamp in ms": 1701876517792, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911788188631623, "Avg loss": 0.45986529998481274, "Avg value loss": 0.16270323740900494, "Avg policy loss": 0.29716206376906484, "Total num played games": 77654, "Total num trained steps": 154624, "Timestamp in ms": 1701876522977, "logtype": "training_step"}
{"Total num played games": 77654, "Total num trained steps": 154684, "Timestamp in ms": 1701876648959, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6328125}
{"Avg objective": 21.921875, "Games time in secs": 133.4733304064721, "Avg game time in secs": 1.8590701158973388, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.75}, "Total num played games": 77696, "Total num trained steps": 154688, "Timestamp in ms": 1701876651266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990417759942378, "Avg loss": 0.8942145346663892, "Avg value loss": 0.5604591186856851, "Avg policy loss": 0.3337554136523977, "Total num played games": 77748, "Total num trained steps": 154752, "Timestamp in ms": 1701876678335, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920769666100735, "Avg loss": 0.3826763902325183, "Avg value loss": 0.07385147953755222, "Avg policy loss": 0.30882490682415664, "Total num played games": 77748, "Total num trained steps": 154880, "Timestamp in ms": 1701876735449, "logtype": "training_step"}
{"Avg objective": 20.3515625, "Games time in secs": 133.83082487806678, "Avg game time in secs": 1.9942702510161325, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.79, "agent_stopped_0": 0.25}, "Total num played games": 77824, "Total num trained steps": 154991, "Timestamp in ms": 1701876785096, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913028956090542, "Avg loss": 0.5912288769613951, "Avg value loss": 0.2930662308644969, "Avg policy loss": 0.29816264554392546, "Total num played games": 77842, "Total num trained steps": 155008, "Timestamp in ms": 1701876792514, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929600986613911, "Avg loss": 0.5325137227773666, "Avg value loss": 0.21749098619329743, "Avg policy loss": 0.31502273422665894, "Total num played games": 77842, "Total num trained steps": 155136, "Timestamp in ms": 1701876847439, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992147604506146, "Avg loss": 1.0853537563234568, "Avg value loss": 0.754983813763829, "Avg policy loss": 0.3303699520183727, "Total num played games": 77938, "Total num trained steps": 155264, "Timestamp in ms": 1701876902531, "logtype": "training_step"}
{"Total num played games": 77938, "Total num trained steps": 155284, "Timestamp in ms": 1701876940201, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.17578125}
{"Avg objective": 22.3984375, "Games time in secs": 157.02595876343548, "Avg game time in secs": 1.8161207463999745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.78, "agent_stopped_0": 0.29}, "Total num played games": 77952, "Total num trained steps": 155285, "Timestamp in ms": 1701876942123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913881484519171, "Avg loss": 0.7944004985038191, "Avg value loss": 0.4634172359656077, "Avg policy loss": 0.33098326169420034, "Total num played games": 78032, "Total num trained steps": 155392, "Timestamp in ms": 1701876989278, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930285011277424, "Avg loss": 0.3596392145846039, "Avg value loss": 0.048566944169579074, "Avg policy loss": 0.3110722708515823, "Total num played games": 78032, "Total num trained steps": 155520, "Timestamp in ms": 1701877044166, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 118.40713335759938, "Avg game time in secs": 1.9490384968812577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.78, "played_steps": 0.79, "agent_stopped_0": 0.22}, "Total num played games": 78080, "Total num trained steps": 155557, "Timestamp in ms": 1701877060530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922688989580932, "Avg loss": 0.6154501002747566, "Avg value loss": 0.30266667751129717, "Avg policy loss": 0.31278342055156827, "Total num played games": 78126, "Total num trained steps": 155648, "Timestamp in ms": 1701877100529, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 80.93884006328881, "Avg game time in secs": 2.0077229073649505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.8, "played_steps": 0.84, "agent_stopped_0": 0.2}, "Total num played games": 78208, "Total num trained steps": 155746, "Timestamp in ms": 1701877141469, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914474188847127, "Avg loss": 0.5952448438620195, "Avg value loss": 0.2944595243607182, "Avg policy loss": 0.3007853184826672, "Total num played games": 78222, "Total num trained steps": 155776, "Timestamp in ms": 1701877155002, "logtype": "training_step"}
{"Total num played games": 78222, "Total num trained steps": 155887, "Timestamp in ms": 1701877265654, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.75390625}
{"Ratio train steps to played games": 1.9907043260636397, "Avg loss": 0.643864948535338, "Avg value loss": 0.3409059260447975, "Avg policy loss": 0.302959019318223, "Total num played games": 78316, "Total num trained steps": 155904, "Timestamp in ms": 1701877273268, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923387302722304, "Avg loss": 0.5785010871477425, "Avg value loss": 0.27712708624312654, "Avg policy loss": 0.301373997121118, "Total num played games": 78316, "Total num trained steps": 156032, "Timestamp in ms": 1701877327713, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 228.9900652896613, "Avg game time in secs": 1.9358347809902625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.77, "played_steps": 0.84, "agent_stopped_0": 0.23}, "Total num played games": 78336, "Total num trained steps": 156125, "Timestamp in ms": 1701877370459, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915827062874634, "Avg loss": 0.7488225267734379, "Avg value loss": 0.45412416962790303, "Avg policy loss": 0.29469836212228984, "Total num played games": 78410, "Total num trained steps": 156160, "Timestamp in ms": 1701877385261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932151511286826, "Avg loss": 0.4422882511280477, "Avg value loss": 0.12571449592360295, "Avg policy loss": 0.31657375837676227, "Total num played games": 78410, "Total num trained steps": 156288, "Timestamp in ms": 1701877439604, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 79.65507439896464, "Avg game time in secs": 1.8084096159873297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.78, "agent_stopped_0": 0.27}, "Total num played games": 78464, "Total num trained steps": 156314, "Timestamp in ms": 1701877450114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992408223575268, "Avg loss": 0.7984283422119915, "Avg value loss": 0.4810816755343694, "Avg policy loss": 0.317346666008234, "Total num played games": 78506, "Total num trained steps": 156416, "Timestamp in ms": 1701877495524, "logtype": "training_step"}
{"Total num played games": 78506, "Total num trained steps": 156487, "Timestamp in ms": 1701877589605, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3359375}
{"Avg objective": 20.8828125, "Games time in secs": 142.5072154738009, "Avg game time in secs": 2.0416111283848295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.88, "played_steps": 0.9, "agent_stopped_0": 0.12}, "Total num played games": 78592, "Total num trained steps": 156492, "Timestamp in ms": 1701877592621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916412213740458, "Avg loss": 0.609286776278168, "Avg value loss": 0.30257967082434334, "Avg policy loss": 0.30670710222329944, "Total num played games": 78600, "Total num trained steps": 156544, "Timestamp in ms": 1701877614524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932824427480915, "Avg loss": 0.37002174952067435, "Avg value loss": 0.06291465443791822, "Avg policy loss": 0.30710709060076624, "Total num played games": 78600, "Total num trained steps": 156672, "Timestamp in ms": 1701877670923, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924773813154417, "Avg loss": 0.9496788205578923, "Avg value loss": 0.6310304807557259, "Avg policy loss": 0.31864833610598, "Total num played games": 78696, "Total num trained steps": 156800, "Timestamp in ms": 1701877726547, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 170.80437719263136, "Avg game time in secs": 1.891851058069733, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.25, "agent_stopped_more": 0.75, "played_steps": 0.81}, "Total num played games": 78720, "Total num trained steps": 156885, "Timestamp in ms": 1701877763426, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917121462114482, "Avg loss": 0.6712235948070884, "Avg value loss": 0.3689808343478944, "Avg policy loss": 0.3022427677642554, "Total num played games": 78790, "Total num trained steps": 156928, "Timestamp in ms": 1701877781593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933367178575963, "Avg loss": 0.3774302611127496, "Avg value loss": 0.08738345053279772, "Avg policy loss": 0.29004681238438934, "Total num played games": 78790, "Total num trained steps": 157056, "Timestamp in ms": 1701877837016, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 81.2113713528961, "Avg game time in secs": 1.8874737711448688, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 78848, "Total num trained steps": 157074, "Timestamp in ms": 1701877844637, "logtype": "played_game"}
{"Total num played games": 78900, "Total num trained steps": 157089, "Timestamp in ms": 1701877925389, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.05078125}
{"Avg objective": 21.4921875, "Games time in secs": 83.7422240357846, "Avg game time in secs": 1.995858118054457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.83, "played_steps": 0.88, "agent_stopped_0": 0.17}, "Total num played games": 78976, "Total num trained steps": 157094, "Timestamp in ms": 1701877928380, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989809352609059, "Avg loss": 1.4365918824914843, "Avg value loss": 1.1059233531414066, "Avg policy loss": 0.3306685354327783, "Total num played games": 78994, "Total num trained steps": 157184, "Timestamp in ms": 1701877967222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914423880294705, "Avg loss": 0.38318902533501387, "Avg value loss": 0.07416948713944294, "Avg policy loss": 0.30901953752618283, "Total num played games": 78994, "Total num trained steps": 157312, "Timestamp in ms": 1701878025156, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930627642605767, "Avg loss": 0.3525240153539926, "Avg value loss": 0.05303448987251613, "Avg policy loss": 0.29948952386621386, "Total num played games": 78994, "Total num trained steps": 157440, "Timestamp in ms": 1701878080166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923123609144244, "Avg loss": 0.9191134999273345, "Avg value loss": 0.6139906237367541, "Avg policy loss": 0.30512287374585867, "Total num played games": 79088, "Total num trained steps": 157568, "Timestamp in ms": 1701878135377, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 249.75511256419122, "Avg game time in secs": 2.0095862437883625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.75, "played_steps": 0.87, "agent_stopped_0": 0.25}, "Total num played games": 79104, "Total num trained steps": 157668, "Timestamp in ms": 1701878178135, "logtype": "played_game"}
{"Total num played games": 79188, "Total num trained steps": 157690, "Timestamp in ms": 1701878255691, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0390625}
{"Avg objective": 22.40625, "Games time in secs": 79.96885837614536, "Avg game time in secs": 1.8693218146072468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.76, "agent_stopped_0": 0.29}, "Total num played games": 79232, "Total num trained steps": 157694, "Timestamp in ms": 1701878258104, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892900393581592, "Avg loss": 0.6326856571249664, "Avg value loss": 0.33750566822709516, "Avg policy loss": 0.2951799931470305, "Total num played games": 79272, "Total num trained steps": 157696, "Timestamp in ms": 1701878259356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906536162054438, "Avg loss": 0.8190957352053374, "Avg value loss": 0.4866934420133475, "Avg policy loss": 0.33240228798240423, "Total num played games": 79282, "Total num trained steps": 157824, "Timestamp in ms": 1701878315318, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922807194571277, "Avg loss": 0.3425975202117115, "Avg value loss": 0.0544022415560903, "Avg policy loss": 0.28819527744781226, "Total num played games": 79282, "Total num trained steps": 157952, "Timestamp in ms": 1701878371208, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 160.77226652763784, "Avg game time in secs": 2.0501134857477155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.76, "played_steps": 0.82, "agent_stopped_0": 0.24}, "Total num played games": 79360, "Total num trained steps": 158059, "Timestamp in ms": 1701878418876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915213666599476, "Avg loss": 0.5575906597077847, "Avg value loss": 0.26996986237645615, "Avg policy loss": 0.28762079728767276, "Total num played games": 79376, "Total num trained steps": 158080, "Timestamp in ms": 1701878427280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931465430356783, "Avg loss": 0.4418758769752458, "Avg value loss": 0.1436094346572645, "Avg policy loss": 0.2982664395822212, "Total num played games": 79376, "Total num trained steps": 158208, "Timestamp in ms": 1701878482782, "logtype": "training_step"}
{"Total num played games": 79470, "Total num trained steps": 158292, "Timestamp in ms": 1701878585595, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.01953125}
{"Avg objective": 22.3125, "Games time in secs": 168.6455013602972, "Avg game time in secs": 2.0573774964286713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.85, "agent_stopped_0": 0.21}, "Total num played games": 79488, "Total num trained steps": 158295, "Timestamp in ms": 1701878587522, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900457493338697, "Avg loss": 1.1798512893728912, "Avg value loss": 0.8679817716474645, "Avg policy loss": 0.3118695174343884, "Total num played games": 79564, "Total num trained steps": 158336, "Timestamp in ms": 1701878606502, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916545171182947, "Avg loss": 0.43155884137377143, "Avg value loss": 0.12210613136994652, "Avg policy loss": 0.3094527099747211, "Total num played games": 79564, "Total num trained steps": 158464, "Timestamp in ms": 1701878661555, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932632849027199, "Avg loss": 0.3347446813713759, "Avg value loss": 0.049375481365132146, "Avg policy loss": 0.28536919760517776, "Total num played games": 79564, "Total num trained steps": 158592, "Timestamp in ms": 1701878716224, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 141.4336447790265, "Avg game time in secs": 1.7864747856656322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.72, "agent_stopped_0": 0.3}, "Total num played games": 79616, "Total num trained steps": 158621, "Timestamp in ms": 1701878728956, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924679889530506, "Avg loss": 0.9787715100683272, "Avg value loss": 0.6683011301065562, "Avg policy loss": 0.3104703789576888, "Total num played games": 79660, "Total num trained steps": 158720, "Timestamp in ms": 1701878773177, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 85.65945672802627, "Avg game time in secs": 2.0449621312582167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.87, "played_steps": 0.9, "agent_stopped_0": 0.13}, "Total num played games": 79744, "Total num trained steps": 158816, "Timestamp in ms": 1701878814615, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917245530004766, "Avg loss": 0.5869161689188331, "Avg value loss": 0.2822239708912093, "Avg policy loss": 0.3046921914210543, "Total num played games": 79754, "Total num trained steps": 158848, "Timestamp in ms": 1701878829261, "logtype": "training_step"}
{"Total num played games": 79754, "Total num trained steps": 158892, "Timestamp in ms": 1701878911994, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.75390625}
{"Ratio train steps to played games": 1.9909828674481516, "Avg loss": 0.8336947993375361, "Avg value loss": 0.5147623075172305, "Avg policy loss": 0.31893248262349516, "Total num played games": 79848, "Total num trained steps": 158976, "Timestamp in ms": 1701878947531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925859132351469, "Avg loss": 0.3526861915597692, "Avg value loss": 0.0552418154256884, "Avg policy loss": 0.29744437662884593, "Total num played games": 79848, "Total num trained steps": 159104, "Timestamp in ms": 1701879000927, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 224.02981559745967, "Avg game time in secs": 1.8037024602817837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 79872, "Total num trained steps": 159190, "Timestamp in ms": 1701879038645, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917817472230561, "Avg loss": 0.7837343014543876, "Avg value loss": 0.4928814385930309, "Avg policy loss": 0.2908528670668602, "Total num played games": 79944, "Total num trained steps": 159232, "Timestamp in ms": 1701879056611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933953767637347, "Avg loss": 0.40538740367628634, "Avg value loss": 0.09739681988139637, "Avg policy loss": 0.307990584988147, "Total num played games": 79944, "Total num trained steps": 159360, "Timestamp in ms": 1701879110128, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 80.4605822917074, "Avg game time in secs": 2.0570440457377117, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.79, "played_steps": 0.85, "agent_stopped_0": 0.21}, "Total num played games": 80000, "Total num trained steps": 159381, "Timestamp in ms": 1701879119106, "logtype": "played_game"}
{"Total num played games": 80038, "Total num trained steps": 159387, "Timestamp in ms": 1701879186308, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.7265625}
{"Avg objective": 21.859375, "Games time in secs": 71.5209802724421, "Avg game time in secs": 2.2325862767756917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.83, "played_steps": 0.91, "agent_stopped_0": 0.17}, "Total num played games": 80128, "Total num trained steps": 159387, "Timestamp in ms": 1701879190627, "logtype": "played_game"}
{"Total num played games": 80132, "Total num trained steps": 159387, "Timestamp in ms": 1701879260028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.421875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702241936848, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8671875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702242665857, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8671875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702243963837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.22265625}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702301677752, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.0}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702301998824, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8671875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702307998902, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702308912099, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.125}
