{"Avg objective": 16.40625, "Games time in secs": 229.82830013148487, "Avg game time in secs": 61.82739845071046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.16, "agent_stopped_more": 0.54, "played_steps": 9.01, "reached_maximum_moves": 0.3}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1699702028859, "logtype": "played_game"}
{"Avg objective": 16.328125, "Games time in secs": 248.12448230572045, "Avg game time in secs": 92.3640895455028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 13.4, "reached_maximum_moves": 0.45, "agent_stopped_0": 0.06}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1699702276983, "logtype": "played_game"}
{"Ratio train steps to played games": 0.43944636678200694, "Avg loss": 65.8518794476986, "Avg value loss": 65.02068145573139, "Avg policy loss": 0.8311979449354112, "Total num played games": 289, "Total num trained steps": 128, "Timestamp in ms": 1699702352590, "logtype": "training_step"}
{"Ratio train steps to played games": 0.7822085889570553, "Avg loss": 13.337828144431114, "Avg value loss": 12.556674156337976, "Avg policy loss": 0.7811540025286376, "Total num played games": 326, "Total num trained steps": 256, "Timestamp in ms": 1699702428296, "logtype": "training_step"}
{"Ratio train steps to played games": 1.0185676392572944, "Avg loss": 8.075910355895758, "Avg value loss": 7.317187488079071, "Avg policy loss": 0.7587228743359447, "Total num played games": 377, "Total num trained steps": 384, "Timestamp in ms": 1699702499725, "logtype": "training_step"}
{"Avg objective": 15.6015625, "Games time in secs": 239.57636282406747, "Avg game time in secs": 88.16518813869334, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 12.58, "agent_stopped_0": 0.19, "reached_maximum_moves": 0.47}, "Total num played games": 384, "Total num trained steps": 425, "Timestamp in ms": 1699702516560, "logtype": "played_game"}
{"Ratio train steps to played games": 1.257985257985258, "Avg loss": 6.03746660426259, "Avg value loss": 5.301794979721308, "Avg policy loss": 0.7356716068461537, "Total num played games": 407, "Total num trained steps": 512, "Timestamp in ms": 1699702550685, "logtype": "training_step"}
{"Total num played games": 474, "Total num trained steps": 602, "Timestamp in ms": 1699702884363, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.26953125}
{"Ratio train steps to played games": 1.3278008298755186, "Avg loss": 6.4455362316221, "Avg value loss": 5.7343011405318975, "Avg policy loss": 0.7112351190298796, "Total num played games": 482, "Total num trained steps": 640, "Timestamp in ms": 1699702899496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5390781563126252, "Avg loss": 5.113981816917658, "Avg value loss": 4.428109128028154, "Avg policy loss": 0.6858726730570197, "Total num played games": 499, "Total num trained steps": 768, "Timestamp in ms": 1699702948255, "logtype": "training_step"}
{"Ratio train steps to played games": 1.767258382642998, "Avg loss": 3.595043435692787, "Avg value loss": 2.9138877857476473, "Avg policy loss": 0.6811556494794786, "Total num played games": 507, "Total num trained steps": 896, "Timestamp in ms": 1699702997003, "logtype": "training_step"}
{"Avg objective": 16.5234375, "Games time in secs": 486.92287454754114, "Avg game time in secs": 84.55615343753016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 11.77, "agent_stopped_0": 0.16, "reached_maximum_moves": 0.38}, "Total num played games": 512, "Total num trained steps": 912, "Timestamp in ms": 1699703003483, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9357277882797732, "Avg loss": 2.8889017179608345, "Avg value loss": 2.218347634188831, "Avg policy loss": 0.6705540977418423, "Total num played games": 529, "Total num trained steps": 1024, "Timestamp in ms": 1699703047321, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9965337954939342, "Avg loss": 2.780829893425107, "Avg value loss": 2.113109689205885, "Avg policy loss": 0.6677202018909156, "Total num played games": 577, "Total num trained steps": 1152, "Timestamp in ms": 1699703098366, "logtype": "training_step"}
{"Total num played games": 633, "Total num trained steps": 1205, "Timestamp in ms": 1699703476653, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.10546875}
{"Avg objective": 15.875, "Games time in secs": 478.9907168690115, "Avg game time in secs": 104.50136374209251, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"reached_maximum_moves": 0.53, "played_steps": 14.56, "agent_stopped_more": 0.28, "agent_stopped_0": 0.19}, "Total num played games": 640, "Total num trained steps": 1218, "Timestamp in ms": 1699703482474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.948249619482496, "Avg loss": 3.2468383088707924, "Avg value loss": 2.6019633896648884, "Avg policy loss": 0.6448749569244683, "Total num played games": 657, "Total num trained steps": 1280, "Timestamp in ms": 1699703509880, "logtype": "training_step"}
{"Ratio train steps to played games": 2.0828402366863905, "Avg loss": 2.9817496770992875, "Avg value loss": 2.339783437550068, "Avg policy loss": 0.6419662344269454, "Total num played games": 676, "Total num trained steps": 1408, "Timestamp in ms": 1699703560575, "logtype": "training_step"}
{"Ratio train steps to played games": 2.160337552742616, "Avg loss": 2.4423983730375767, "Avg value loss": 1.8046983107924461, "Avg policy loss": 0.6377000706270337, "Total num played games": 711, "Total num trained steps": 1536, "Timestamp in ms": 1699703610281, "logtype": "training_step"}
{"Ratio train steps to played games": 2.2639455782312927, "Avg loss": 2.2680683750659227, "Avg value loss": 1.63695123558864, "Avg policy loss": 0.6311171450652182, "Total num played games": 735, "Total num trained steps": 1664, "Timestamp in ms": 1699703659567, "logtype": "training_step"}
{"Avg objective": 17.2578125, "Games time in secs": 226.49133188091218, "Avg game time in secs": 61.52927812555572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.34, "played_steps": 8.43, "reached_maximum_moves": 0.28}, "Total num played games": 768, "Total num trained steps": 1775, "Timestamp in ms": 1699703708965, "logtype": "played_game"}
{"Ratio train steps to played games": 2.319948186528497, "Avg loss": 2.331606143154204, "Avg value loss": 1.7054064171388745, "Avg policy loss": 0.6261997153051198, "Total num played games": 772, "Total num trained steps": 1792, "Timestamp in ms": 1699703715824, "logtype": "training_step"}
{"Total num played games": 827, "Total num trained steps": 1808, "Timestamp in ms": 1699704028772, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.1015625}
{"Ratio train steps to played games": 2.2247972190034764, "Avg loss": 3.2934019938111305, "Avg value loss": 2.6686427160166204, "Avg policy loss": 0.6247592698782682, "Total num played games": 862, "Total num trained steps": 1920, "Timestamp in ms": 1699704072661, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3352337514253136, "Avg loss": 2.0675580706447363, "Avg value loss": 1.4446972059085965, "Avg policy loss": 0.6228608661331236, "Total num played games": 877, "Total num trained steps": 2048, "Timestamp in ms": 1699704123313, "logtype": "training_step"}
{"Avg objective": 16.828125, "Games time in secs": 447.7650093752891, "Avg game time in secs": 77.7317394449783, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 10.76, "reached_maximum_moves": 0.37, "agent_stopped_0": 0.31}, "Total num played games": 896, "Total num trained steps": 2132, "Timestamp in ms": 1699704156730, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4070796460176993, "Avg loss": 2.15861143078655, "Avg value loss": 1.5351117588579655, "Avg policy loss": 0.6234996733255684, "Total num played games": 904, "Total num trained steps": 2176, "Timestamp in ms": 1699704173300, "logtype": "training_step"}
{"Ratio train steps to played games": 2.447396386822529, "Avg loss": 1.94566569942981, "Avg value loss": 1.3365511568263173, "Avg policy loss": 0.6091145211830735, "Total num played games": 941, "Total num trained steps": 2304, "Timestamp in ms": 1699704222689, "logtype": "training_step"}
{"Total num played games": 1016, "Total num trained steps": 2409, "Timestamp in ms": 1699704545976, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.06640625}
{"Avg objective": 17.125, "Games time in secs": 395.2278128694743, "Avg game time in secs": 91.20139499698416, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.28, "played_steps": 12.29, "reached_maximum_moves": 0.42}, "Total num played games": 1024, "Total num trained steps": 2420, "Timestamp in ms": 1699704551958, "logtype": "played_game"}
{"Ratio train steps to played games": 2.3452266152362586, "Avg loss": 2.2504963679239154, "Avg value loss": 1.6413296442478895, "Avg policy loss": 0.6091667390428483, "Total num played games": 1037, "Total num trained steps": 2432, "Timestamp in ms": 1699704556721, "logtype": "training_step"}
{"Ratio train steps to played games": 2.397003745318352, "Avg loss": 2.2893784129992127, "Avg value loss": 1.6719413250684738, "Avg policy loss": 0.6174370716325939, "Total num played games": 1068, "Total num trained steps": 2560, "Timestamp in ms": 1699704607787, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4751381215469612, "Avg loss": 1.8325113346800208, "Avg value loss": 1.225470632314682, "Avg policy loss": 0.6070407149381936, "Total num played games": 1086, "Total num trained steps": 2688, "Timestamp in ms": 1699704656189, "logtype": "training_step"}
{"Ratio train steps to played games": 2.462817147856518, "Avg loss": 1.7703964551910758, "Avg value loss": 1.1653745626099408, "Avg policy loss": 0.6050218902528286, "Total num played games": 1143, "Total num trained steps": 2816, "Timestamp in ms": 1699704704719, "logtype": "training_step"}
{"Avg objective": 17.6640625, "Games time in secs": 170.19871884025633, "Avg game time in secs": 40.84404774541326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.3, "played_steps": 5.56, "reached_maximum_moves": 0.18}, "Total num played games": 1152, "Total num trained steps": 2862, "Timestamp in ms": 1699704722157, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5153846153846153, "Avg loss": 1.6189551763236523, "Avg value loss": 1.0123687884770334, "Avg policy loss": 0.6065863911062479, "Total num played games": 1170, "Total num trained steps": 2944, "Timestamp in ms": 1699704754047, "logtype": "training_step"}
{"Total num played games": 1235, "Total num trained steps": 3011, "Timestamp in ms": 1699705079701, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 20.91796875}
{"Ratio train steps to played games": 2.4150943396226414, "Avg loss": 2.1022955691441894, "Avg value loss": 1.5113056194968522, "Avg policy loss": 0.5909899570979178, "Total num played games": 1272, "Total num trained steps": 3072, "Timestamp in ms": 1699705114426, "logtype": "training_step"}
{"Avg objective": 16.6796875, "Games time in secs": 409.46012813411653, "Avg game time in secs": 74.31809955026256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.234375, "Avg reasons for ending game": {"reached_maximum_moves": 0.38, "played_steps": 10.12, "agent_stopped_0": 0.34, "agent_stopped_more": 0.28}, "Total num played games": 1280, "Total num trained steps": 3102, "Timestamp in ms": 1699705131617, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4521072796934864, "Avg loss": 1.8395119281485677, "Avg value loss": 1.2518926276825368, "Avg policy loss": 0.5876192995347083, "Total num played games": 1305, "Total num trained steps": 3200, "Timestamp in ms": 1699705184334, "logtype": "training_step"}
{"Ratio train steps to played games": 2.481730052199851, "Avg loss": 1.7384612439200282, "Avg value loss": 1.1593144722282887, "Avg policy loss": 0.5791467730887234, "Total num played games": 1341, "Total num trained steps": 3328, "Timestamp in ms": 1699705232261, "logtype": "training_step"}
{"Ratio train steps to played games": 2.480976310122039, "Avg loss": 1.6862704465165734, "Avg value loss": 1.1098894062452018, "Avg policy loss": 0.5763810542412102, "Total num played games": 1393, "Total num trained steps": 3456, "Timestamp in ms": 1699705280647, "logtype": "training_step"}
{"Avg objective": 17.828125, "Games time in secs": 176.71594009175897, "Avg game time in secs": 54.73924762723618, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.21, "played_steps": 7.48, "reached_maximum_moves": 0.26}, "Total num played games": 1408, "Total num trained steps": 3527, "Timestamp in ms": 1699705308333, "logtype": "played_game"}
{"Ratio train steps to played games": 2.522167487684729, "Avg loss": 1.5578024163842201, "Avg value loss": 0.988172076176852, "Avg policy loss": 0.5696303439326584, "Total num played games": 1421, "Total num trained steps": 3584, "Timestamp in ms": 1699705329450, "logtype": "training_step"}
{"Total num played games": 1473, "Total num trained steps": 3616, "Timestamp in ms": 1699705584982, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.1875}
{"Ratio train steps to played games": 2.4198174706649285, "Avg loss": 2.0550762582570314, "Avg value loss": 1.4939649309962988, "Avg policy loss": 0.5611113356426358, "Total num played games": 1534, "Total num trained steps": 3712, "Timestamp in ms": 1699705622769, "logtype": "training_step"}
{"Avg objective": 18.2734375, "Games time in secs": 314.94485928304493, "Avg game time in secs": 61.13281309623562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "reached_maximum_moves": 0.33, "played_steps": 8.18, "agent_stopped_more": 0.16}, "Total num played games": 1536, "Total num trained steps": 3713, "Timestamp in ms": 1699705623278, "logtype": "played_game"}
{"Ratio train steps to played games": 2.47741935483871, "Avg loss": 1.532426917925477, "Avg value loss": 0.9828465208411217, "Avg policy loss": 0.5495803970843554, "Total num played games": 1550, "Total num trained steps": 3840, "Timestamp in ms": 1699705671259, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4846587351283658, "Avg loss": 1.4934082087129354, "Avg value loss": 0.9466937235556543, "Avg policy loss": 0.5467144849244505, "Total num played games": 1597, "Total num trained steps": 3968, "Timestamp in ms": 1699705718865, "logtype": "training_step"}
{"Avg objective": 18.34375, "Games time in secs": 136.33890927024186, "Avg game time in secs": 40.661128173116595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.2, "played_steps": 5.41, "reached_maximum_moves": 0.18}, "Total num played games": 1664, "Total num trained steps": 4077, "Timestamp in ms": 1699705759618, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4389517569982133, "Avg loss": 1.851078437641263, "Avg value loss": 1.3213159530423582, "Avg policy loss": 0.5297624985687435, "Total num played games": 1679, "Total num trained steps": 4096, "Timestamp in ms": 1699705766589, "logtype": "training_step"}
{"Total num played games": 1785, "Total num trained steps": 4216, "Timestamp in ms": 1699706060296, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.26953125}
{"Ratio train steps to played games": 2.3663865546218488, "Avg loss": 1.7713143089786172, "Avg value loss": 1.2603194531984627, "Avg policy loss": 0.510994856711477, "Total num played games": 1785, "Total num trained steps": 4224, "Timestamp in ms": 1699706064425, "logtype": "training_step"}
{"Avg objective": 18.390625, "Games time in secs": 306.5379662178457, "Avg game time in secs": 61.625431940032286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "reached_maximum_moves": 0.27, "played_steps": 8.15, "agent_stopped_more": 0.21}, "Total num played games": 1792, "Total num trained steps": 4227, "Timestamp in ms": 1699706066156, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2821185107498687, "Avg loss": 2.2724393932148814, "Avg value loss": 1.782722933217883, "Avg policy loss": 0.4897164786234498, "Total num played games": 1907, "Total num trained steps": 4352, "Timestamp in ms": 1699706113910, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 57.325636100023985, "Avg game time in secs": 6.420647459934116, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.05, "played_steps": 0.2}, "Total num played games": 1920, "Total num trained steps": 4377, "Timestamp in ms": 1699706123481, "logtype": "played_game"}
{"Ratio train steps to played games": 2.299794661190965, "Avg loss": 1.7189930258318782, "Avg value loss": 1.239592376165092, "Avg policy loss": 0.47940065152943134, "Total num played games": 1948, "Total num trained steps": 4480, "Timestamp in ms": 1699706163937, "logtype": "training_step"}
{"Ratio train steps to played games": 2.2823179791976225, "Avg loss": 1.7213053265586495, "Avg value loss": 1.2473815074190497, "Avg policy loss": 0.4739238142501563, "Total num played games": 2019, "Total num trained steps": 4608, "Timestamp in ms": 1699706213682, "logtype": "training_step"}
{"Avg objective": 19.453125, "Games time in secs": 106.76357056573033, "Avg game time in secs": 28.073818817952997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.11, "played_steps": 3.66, "reached_maximum_moves": 0.13}, "Total num played games": 2048, "Total num trained steps": 4651, "Timestamp in ms": 1699706230245, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2182669789227165, "Avg loss": 1.663066165521741, "Avg value loss": 1.1972029022872448, "Avg policy loss": 0.4658632620703429, "Total num played games": 2135, "Total num trained steps": 4736, "Timestamp in ms": 1699706263581, "logtype": "training_step"}
{"Avg objective": 19.4453125, "Games time in secs": 59.26622404716909, "Avg game time in secs": 31.48842193231394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "reached_maximum_moves": 0.14, "played_steps": 3.74, "agent_stopped_more": 0.07}, "Total num played games": 2176, "Total num trained steps": 4804, "Timestamp in ms": 1699706289512, "logtype": "played_game"}
{"Total num played games": 2233, "Total num trained steps": 4819, "Timestamp in ms": 1699706573612, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.17578125}
{"Avg objective": 17.953125, "Games time in secs": 297.3764480818063, "Avg game time in secs": 48.51762786641484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.09, "played_steps": 6.34, "reached_maximum_moves": 0.24}, "Total num played games": 2304, "Total num trained steps": 4850, "Timestamp in ms": 1699706586888, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0875536480686696, "Avg loss": 2.0080045238137245, "Avg value loss": 1.5577365760691464, "Avg policy loss": 0.45026793819852173, "Total num played games": 2330, "Total num trained steps": 4864, "Timestamp in ms": 1699706592165, "logtype": "training_step"}
{"Ratio train steps to played games": 2.054320987654321, "Avg loss": 1.910009873099625, "Avg value loss": 1.4923798320814967, "Avg policy loss": 0.4176300400868058, "Total num played games": 2430, "Total num trained steps": 4992, "Timestamp in ms": 1699706642829, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 57.632124591618776, "Avg game time in secs": 7.0496634200681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.125, "Avg reasons for ending game": {"agent_stopped_0": 0.92, "agent_stopped_more": 0.08, "played_steps": 0.3}, "Total num played games": 2432, "Total num trained steps": 4996, "Timestamp in ms": 1699706644520, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0678513731825525, "Avg loss": 1.3935719579458237, "Avg value loss": 0.9888021247461438, "Avg policy loss": 0.4047698264475912, "Total num played games": 2476, "Total num trained steps": 5120, "Timestamp in ms": 1699706692416, "logtype": "training_step"}
{"Avg objective": 19.8359375, "Games time in secs": 82.96049211733043, "Avg game time in secs": 24.571054469430237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.09375, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.12, "played_steps": 3.14, "reached_maximum_moves": 0.11}, "Total num played games": 2560, "Total num trained steps": 5209, "Timestamp in ms": 1699706727481, "logtype": "played_game"}
{"Ratio train steps to played games": 2.022350674373796, "Avg loss": 1.5648438530042768, "Avg value loss": 1.1746002901345491, "Avg policy loss": 0.39024356775917113, "Total num played games": 2595, "Total num trained steps": 5248, "Timestamp in ms": 1699706743069, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 50.19573059491813, "Avg game time in secs": 22.885528896193136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.86, "agent_stopped_more": 0.06, "played_steps": 2.41, "reached_maximum_moves": 0.08}, "Total num played games": 2688, "Total num trained steps": 5341, "Timestamp in ms": 1699706777677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9713971397139713, "Avg loss": 1.5314523689448833, "Avg value loss": 1.1567505402490497, "Avg policy loss": 0.3747018270660192, "Total num played games": 2727, "Total num trained steps": 5376, "Timestamp in ms": 1699706792550, "logtype": "training_step"}
{"Avg objective": 20.28125, "Games time in secs": 82.52487365528941, "Avg game time in secs": 28.94585043643019, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.12, "played_steps": 3.5, "agent_stopped_0": 0.76, "reached_maximum_moves": 0.12}, "Total num played games": 2816, "Total num trained steps": 5421, "Timestamp in ms": 1699706860202, "logtype": "played_game"}
{"Total num played games": 2833, "Total num trained steps": 5421, "Timestamp in ms": 1699707039084, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.3046875}
{"Avg objective": 20.828125, "Games time in secs": 200.943273762241, "Avg game time in secs": 23.501943802504684, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"reached_maximum_moves": 0.1, "played_steps": 2.74, "agent_stopped_more": 0.04, "agent_stopped_0": 0.86}, "Total num played games": 2944, "Total num trained steps": 5475, "Timestamp in ms": 1699707061145, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8435510887772195, "Avg loss": 2.34068960044533, "Avg value loss": 1.9913083999417722, "Avg policy loss": 0.34938120492734015, "Total num played games": 2985, "Total num trained steps": 5504, "Timestamp in ms": 1699707071937, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 58.1035325769335, "Avg game time in secs": 8.558679972120444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.09, "played_steps": 0.55}, "Total num played games": 3072, "Total num trained steps": 5630, "Timestamp in ms": 1699707119249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.832736739342662, "Avg loss": 1.775448925793171, "Avg value loss": 1.4525552005507052, "Avg policy loss": 0.3228937347885221, "Total num played games": 3073, "Total num trained steps": 5632, "Timestamp in ms": 1699707119741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8355640535372848, "Avg loss": 1.3976113582029939, "Avg value loss": 1.0861835894174874, "Avg policy loss": 0.3114277678541839, "Total num played games": 3138, "Total num trained steps": 5760, "Timestamp in ms": 1699707168009, "logtype": "training_step"}
{"Avg objective": 18.7578125, "Games time in secs": 92.68409043177962, "Avg game time in secs": 25.96237636184378, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.13, "played_steps": 3.27, "reached_maximum_moves": 0.1}, "Total num played games": 3200, "Total num trained steps": 5867, "Timestamp in ms": 1699707211933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.835983785469286, "Avg loss": 1.5383069682866335, "Avg value loss": 1.2346415310166776, "Avg policy loss": 0.3036654444877058, "Total num played games": 3207, "Total num trained steps": 5888, "Timestamp in ms": 1699707221235, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8352654057352045, "Avg loss": 1.3066557785496116, "Avg value loss": 1.0108471466228366, "Avg policy loss": 0.2958086293656379, "Total num played games": 3277, "Total num trained steps": 6016, "Timestamp in ms": 1699707279860, "logtype": "training_step"}
{"Total num played games": 3310, "Total num trained steps": 6021, "Timestamp in ms": 1699707494242, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.28125}
{"Avg objective": 18.2109375, "Games time in secs": 288.1225412469357, "Avg game time in secs": 34.811955550540006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_more": 0.08, "played_steps": 4.53, "reached_maximum_moves": 0.18, "agent_stopped_0": 0.74}, "Total num played games": 3328, "Total num trained steps": 6034, "Timestamp in ms": 1699707500056, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8315444245676804, "Avg loss": 1.3016512361355126, "Avg value loss": 1.0204569904599339, "Avg policy loss": 0.281194239272736, "Total num played games": 3354, "Total num trained steps": 6144, "Timestamp in ms": 1699707555496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8427857772553629, "Avg loss": 1.0486222747713327, "Avg value loss": 0.7722300547175109, "Avg policy loss": 0.276392217958346, "Total num played games": 3403, "Total num trained steps": 6272, "Timestamp in ms": 1699707618708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.854534917415242, "Avg loss": 1.0019474308937788, "Avg value loss": 0.734018431045115, "Avg policy loss": 0.2679289988009259, "Total num played games": 3451, "Total num trained steps": 6400, "Timestamp in ms": 1699707678269, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 179.3487084042281, "Avg game time in secs": 8.52508153821691, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.96, "agent_stopped_more": 0.02, "played_steps": 0.54, "reached_maximum_moves": 0.02}, "Total num played games": 3456, "Total num trained steps": 6403, "Timestamp in ms": 1699707679405, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8451102317693613, "Avg loss": 1.0259187971241772, "Avg value loss": 0.7620896792504936, "Avg policy loss": 0.26382912159897387, "Total num played games": 3538, "Total num trained steps": 6528, "Timestamp in ms": 1699707738631, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 103.3712284527719, "Avg game time in secs": 14.06129741751647, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "reached_maximum_moves": 0.05, "played_steps": 1.46, "agent_stopped_more": 0.05}, "Total num played games": 3584, "Total num trained steps": 6621, "Timestamp in ms": 1699707782777, "logtype": "played_game"}
{"Total num played games": 3594, "Total num trained steps": 6621, "Timestamp in ms": 1699707977747, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.30078125}
{"Ratio train steps to played games": 1.8320946875860171, "Avg loss": 1.1937859496101737, "Avg value loss": 0.938987776171416, "Avg policy loss": 0.25479817437008023, "Total num played games": 3633, "Total num trained steps": 6656, "Timestamp in ms": 1699707995328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8424769147202607, "Avg loss": 0.849003239069134, "Avg value loss": 0.6025599704589695, "Avg policy loss": 0.24644327105488628, "Total num played games": 3682, "Total num trained steps": 6784, "Timestamp in ms": 1699708056250, "logtype": "training_step"}
{"Avg objective": 18.0390625, "Games time in secs": 324.2803619559854, "Avg game time in secs": 19.752008245297475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1953125, "Avg reasons for ending game": {"reached_maximum_moves": 0.09, "played_steps": 2.34, "agent_stopped_more": 0.07, "agent_stopped_0": 0.84}, "Total num played games": 3712, "Total num trained steps": 6887, "Timestamp in ms": 1699708107057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8466470745391397, "Avg loss": 0.8165256665088236, "Avg value loss": 0.5799158615991473, "Avg policy loss": 0.23660980188287795, "Total num played games": 3743, "Total num trained steps": 6912, "Timestamp in ms": 1699708119216, "logtype": "training_step"}
{"Ratio train steps to played games": 1.855072463768116, "Avg loss": 0.7844907441176474, "Avg value loss": 0.5553643056191504, "Avg policy loss": 0.22912643908057362, "Total num played games": 3795, "Total num trained steps": 7040, "Timestamp in ms": 1699708181744, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 103.21208141557872, "Avg game time in secs": 8.926512552963686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.04, "played_steps": 0.58, "reached_maximum_moves": 0.02}, "Total num played games": 3840, "Total num trained steps": 7102, "Timestamp in ms": 1699708210270, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8639791937581274, "Avg loss": 0.7909070611931384, "Avg value loss": 0.567310590762645, "Avg policy loss": 0.22359647357370704, "Total num played games": 3845, "Total num trained steps": 7168, "Timestamp in ms": 1699708242464, "logtype": "training_step"}
{"Total num played games": 3903, "Total num trained steps": 7223, "Timestamp in ms": 1699708465325, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.32421875}
{"Ratio train steps to played games": 1.8482391689891056, "Avg loss": 1.0318505624309182, "Avg value loss": 0.815351591212675, "Avg policy loss": 0.21649897145107388, "Total num played games": 3947, "Total num trained steps": 7296, "Timestamp in ms": 1699708506401, "logtype": "training_step"}
{"Avg objective": 19.6640625, "Games time in secs": 347.69846897758543, "Avg game time in secs": 13.72989622678142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.05, "played_steps": 1.44, "reached_maximum_moves": 0.05}, "Total num played games": 3968, "Total num trained steps": 7398, "Timestamp in ms": 1699708557969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8592536939644377, "Avg loss": 0.7788468655198812, "Avg value loss": 0.5689012608490884, "Avg policy loss": 0.20994560280814767, "Total num played games": 3993, "Total num trained steps": 7424, "Timestamp in ms": 1699708570498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8651518893553964, "Avg loss": 0.8016573092900217, "Avg value loss": 0.594493251061067, "Avg policy loss": 0.20716405368875712, "Total num played games": 4049, "Total num trained steps": 7552, "Timestamp in ms": 1699708632300, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 105.0680177025497, "Avg game time in secs": 10.369089383035316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.94, "agent_stopped_more": 0.02, "played_steps": 0.88, "reached_maximum_moves": 0.04}, "Total num played games": 4096, "Total num trained steps": 7614, "Timestamp in ms": 1699708663037, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8745423480595558, "Avg loss": 0.8340807559434325, "Avg value loss": 0.6336347865872085, "Avg policy loss": 0.20044597156811506, "Total num played games": 4097, "Total num trained steps": 7680, "Timestamp in ms": 1699708695264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8619127116622942, "Avg loss": 0.7778147626668215, "Avg value loss": 0.581750338897109, "Avg policy loss": 0.19606442051008344, "Total num played games": 4193, "Total num trained steps": 7808, "Timestamp in ms": 1699708753246, "logtype": "training_step"}
{"Total num played games": 4203, "Total num trained steps": 7824, "Timestamp in ms": 1699708973544, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.2265625}
{"Avg objective": 20.2890625, "Games time in secs": 316.11609001643956, "Avg game time in secs": 17.254846581068705, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1484375, "Avg reasons for ending game": {"reached_maximum_moves": 0.08, "played_steps": 1.99, "agent_stopped_0": 0.89, "agent_stopped_more": 0.03}, "Total num played games": 4224, "Total num trained steps": 7836, "Timestamp in ms": 1699708979154, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8672941176470588, "Avg loss": 1.0051012393087149, "Avg value loss": 0.822735991794616, "Avg policy loss": 0.1823652401799336, "Total num played games": 4250, "Total num trained steps": 7936, "Timestamp in ms": 1699709028505, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8742445374244538, "Avg loss": 0.6686685995664448, "Avg value loss": 0.4902496603317559, "Avg policy loss": 0.17841893364675343, "Total num played games": 4302, "Total num trained steps": 8064, "Timestamp in ms": 1699709090926, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 137.37106252089143, "Avg game time in secs": 6.124966210438288, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.18}, "Total num played games": 4352, "Total num trained steps": 8114, "Timestamp in ms": 1699709116525, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8797613584212942, "Avg loss": 0.8015630433801562, "Avg value loss": 0.6300098169595003, "Avg policy loss": 0.17155322444159538, "Total num played games": 4358, "Total num trained steps": 8192, "Timestamp in ms": 1699709155832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8685983827493262, "Avg loss": 0.7489424701780081, "Avg value loss": 0.5783750966656953, "Avg policy loss": 0.17056737397797406, "Total num played games": 4452, "Total num trained steps": 8320, "Timestamp in ms": 1699709216858, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 148.1279252525419, "Avg game time in secs": 8.115276097829337, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.97, "agent_stopped_more": 0.01, "played_steps": 0.52, "reached_maximum_moves": 0.02}, "Total num played games": 4480, "Total num trained steps": 8414, "Timestamp in ms": 1699709264653, "logtype": "played_game"}
{"Total num played games": 4522, "Total num trained steps": 8425, "Timestamp in ms": 1699709473975, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.32421875}
{"Ratio train steps to played games": 1.850383351588171, "Avg loss": 0.7417966672219336, "Avg value loss": 0.5845479595009238, "Avg policy loss": 0.15724871191196144, "Total num played games": 4565, "Total num trained steps": 8448, "Timestamp in ms": 1699709484640, "logtype": "training_step"}
{"Ratio train steps to played games": 1.878011388523872, "Avg loss": 0.8885278499219567, "Avg value loss": 0.7371224334929138, "Avg policy loss": 0.1514054170693271, "Total num played games": 4566, "Total num trained steps": 8576, "Timestamp in ms": 1699709552890, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 317.71757796406746, "Avg game time in secs": 13.41376960540947, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "reached_maximum_moves": 0.05, "played_steps": 1.34, "agent_stopped_more": 0.05}, "Total num played games": 4608, "Total num trained steps": 8634, "Timestamp in ms": 1699709582371, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8841740636501407, "Avg loss": 0.5771203329786658, "Avg value loss": 0.4297022521495819, "Avg policy loss": 0.14741807855898514, "Total num played games": 4619, "Total num trained steps": 8704, "Timestamp in ms": 1699709618378, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8904109589041096, "Avg loss": 0.7511021778918803, "Avg value loss": 0.6064514766912907, "Avg policy loss": 0.14465069671859965, "Total num played games": 4672, "Total num trained steps": 8832, "Timestamp in ms": 1699709684960, "logtype": "training_step"}
{"Avg objective": 20.9921875, "Games time in secs": 158.56989516690373, "Avg game time in secs": 6.767943613405805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "reached_maximum_moves": 0.01, "played_steps": 0.27, "agent_stopped_more": 0.02}, "Total num played games": 4736, "Total num trained steps": 8949, "Timestamp in ms": 1699709740941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8758375209380234, "Avg loss": 0.7052174848504364, "Avg value loss": 0.5711141529027373, "Avg policy loss": 0.13410332653438672, "Total num played games": 4776, "Total num trained steps": 8960, "Timestamp in ms": 1699709745792, "logtype": "training_step"}
{"Total num played games": 4781, "Total num trained steps": 9027, "Timestamp in ms": 1699709974182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.40625}
{"Ratio train steps to played games": 1.882145816072908, "Avg loss": 0.6990438618231565, "Avg value loss": 0.5723836960969493, "Avg policy loss": 0.12666016403818503, "Total num played games": 4828, "Total num trained steps": 9088, "Timestamp in ms": 1699710007265, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 301.2078282311559, "Avg game time in secs": 6.88226433575619, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.01, "played_steps": 0.3, "reached_maximum_moves": 0.01}, "Total num played games": 4864, "Total num trained steps": 9157, "Timestamp in ms": 1699710042149, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8879328006556033, "Avg loss": 0.6213248269632459, "Avg value loss": 0.4957071729004383, "Avg policy loss": 0.1256176481838338, "Total num played games": 4881, "Total num trained steps": 9216, "Timestamp in ms": 1699710070886, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8935954600729632, "Avg loss": 0.7534180397633463, "Avg value loss": 0.6313480454264209, "Avg policy loss": 0.12206998583860695, "Total num played games": 4934, "Total num trained steps": 9344, "Timestamp in ms": 1699710134336, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 149.3161309156567, "Avg game time in secs": 6.3440716207405785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.97, "agent_stopped_more": 0.02, "played_steps": 0.22, "reached_maximum_moves": 0.01}, "Total num played games": 4992, "Total num trained steps": 9467, "Timestamp in ms": 1699710191465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8861011549183593, "Avg loss": 0.5240103469695896, "Avg value loss": 0.4048412519041449, "Avg policy loss": 0.11916909646242857, "Total num played games": 5022, "Total num trained steps": 9472, "Timestamp in ms": 1699710193285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8905080740448996, "Avg loss": 0.59673250769265, "Avg value loss": 0.48482993547804654, "Avg policy loss": 0.11190257576527074, "Total num played games": 5078, "Total num trained steps": 9600, "Timestamp in ms": 1699710252975, "logtype": "training_step"}
{"Total num played games": 5085, "Total num trained steps": 9630, "Timestamp in ms": 1699710456314, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 21.75}
{"Avg objective": 18.90625, "Games time in secs": 271.48788721859455, "Avg game time in secs": 14.516250470711384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.91, "agent_stopped_more": 0.02, "played_steps": 1.61, "reached_maximum_moves": 0.07}, "Total num played games": 5120, "Total num trained steps": 9646, "Timestamp in ms": 1699710462953, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8951879992207286, "Avg loss": 0.5232706912793219, "Avg value loss": 0.41589044930879027, "Avg policy loss": 0.10738024592865258, "Total num played games": 5133, "Total num trained steps": 9728, "Timestamp in ms": 1699710503266, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9012345679012346, "Avg loss": 0.4615092920139432, "Avg value loss": 0.3542269060853869, "Avg policy loss": 0.10728238901356235, "Total num played games": 5184, "Total num trained steps": 9856, "Timestamp in ms": 1699710565461, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 158.54715463519096, "Avg game time in secs": 5.6744207638839725, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.98, "agent_stopped_more": 0.02, "played_steps": 0.12}, "Total num played games": 5248, "Total num trained steps": 9977, "Timestamp in ms": 1699710621501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8894776684330052, "Avg loss": 0.6109812017530203, "Avg value loss": 0.5104510365054011, "Avg policy loss": 0.10053016745951027, "Total num played games": 5283, "Total num trained steps": 9984, "Timestamp in ms": 1699710624469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.8948650674662668, "Avg loss": 0.5765472792554647, "Avg value loss": 0.4785933141829446, "Avg policy loss": 0.09795395913533866, "Total num played games": 5336, "Total num trained steps": 10112, "Timestamp in ms": 1699710685037, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 97.01320902444422, "Avg game time in secs": 7.28366529844061, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.95, "agent_stopped_more": 0.04, "played_steps": 0.45, "reached_maximum_moves": 0.02}, "Total num played games": 5376, "Total num trained steps": 10181, "Timestamp in ms": 1699710718514, "logtype": "played_game"}
{"Total num played games": 5392, "Total num trained steps": 10232, "Timestamp in ms": 1699710928758, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.296875}
{"Ratio train steps to played games": 1.8987576488040052, "Avg loss": 0.4951449402142316, "Avg value loss": 0.39645499864127487, "Avg policy loss": 0.0986899392446503, "Total num played games": 5393, "Total num trained steps": 10240, "Timestamp in ms": 1699710932781, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9062327633756204, "Avg loss": 0.5054223411716521, "Avg value loss": 0.40070315334014595, "Avg policy loss": 0.1047191860852763, "Total num played games": 5439, "Total num trained steps": 10368, "Timestamp in ms": 1699710993061, "logtype": "training_step"}
{"Avg objective": 19.8203125, "Games time in secs": 319.90335927158594, "Avg game time in secs": 12.838280592564843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.078125, "Avg reasons for ending game": {"agent_stopped_0": 0.9, "reached_maximum_moves": 0.04, "played_steps": 1.34, "agent_stopped_more": 0.06}, "Total num played games": 5504, "Total num trained steps": 10467, "Timestamp in ms": 1699711038418, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8985166425470332, "Avg loss": 0.581177102169022, "Avg value loss": 0.47909344581421465, "Avg policy loss": 0.10208365402650088, "Total num played games": 5528, "Total num trained steps": 10496, "Timestamp in ms": 1699711051260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.904966828043751, "Avg loss": 0.5601667021401227, "Avg value loss": 0.45578816754277796, "Avg policy loss": 0.10437852918403223, "Total num played games": 5577, "Total num trained steps": 10624, "Timestamp in ms": 1699711109261, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 122.35928385518491, "Avg game time in secs": 11.512435791795724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.0546875, "Avg reasons for ending game": {"agent_stopped_0": 0.88, "agent_stopped_more": 0.07, "played_steps": 1.23, "reached_maximum_moves": 0.05}, "Total num played games": 5632, "Total num trained steps": 10742, "Timestamp in ms": 1699711160777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.8989756269869305, "Avg loss": 0.49991190526634455, "Avg value loss": 0.38992471585515887, "Avg policy loss": 0.10998718877090141, "Total num played games": 5662, "Total num trained steps": 10752, "Timestamp in ms": 1699711164997, "logtype": "training_step"}
{"Total num played games": 5719, "Total num trained steps": 10834, "Timestamp in ms": 1699711321702, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.19140625}
{"Ratio train steps to played games": 1.8892168779301963, "Avg loss": 0.7064424192067236, "Avg value loss": 0.5903856868389994, "Avg policy loss": 0.11605673626763746, "Total num played games": 5759, "Total num trained steps": 10880, "Timestamp in ms": 1699711343784, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 184.18973338976502, "Avg game time in secs": 15.18259885936277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.09, "played_steps": 1.85, "reached_maximum_moves": 0.06}, "Total num played games": 5760, "Total num trained steps": 10883, "Timestamp in ms": 1699711344967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9101162588929377, "Avg loss": 0.44080524309538305, "Avg value loss": 0.3180416099494323, "Avg policy loss": 0.12276363163255155, "Total num played games": 5763, "Total num trained steps": 11008, "Timestamp in ms": 1699711405195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9042407660738714, "Avg loss": 0.5486631128005683, "Avg value loss": 0.4207633923506364, "Avg policy loss": 0.1278997210902162, "Total num played games": 5848, "Total num trained steps": 11136, "Timestamp in ms": 1699711463981, "logtype": "training_step"}
{"Avg objective": 20.3984375, "Games time in secs": 152.57181657478213, "Avg game time in secs": 9.476085516653256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.13, "played_steps": 1.02, "agent_stopped_0": 0.85, "reached_maximum_moves": 0.02}, "Total num played games": 5888, "Total num trained steps": 11209, "Timestamp in ms": 1699711497539, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9104477611940298, "Avg loss": 0.6697860371787101, "Avg value loss": 0.5337580989580601, "Avg policy loss": 0.1360279354848899, "Total num played games": 5896, "Total num trained steps": 11264, "Timestamp in ms": 1699711522009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9042126379137412, "Avg loss": 0.7034824048168957, "Avg value loss": 0.5646216253517196, "Avg policy loss": 0.13886077608913183, "Total num played games": 5982, "Total num trained steps": 11392, "Timestamp in ms": 1699711582774, "logtype": "training_step"}
{"Total num played games": 5993, "Total num trained steps": 11437, "Timestamp in ms": 1699711731835, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.74609375}
{"Avg objective": 21.4765625, "Games time in secs": 239.32671098038554, "Avg game time in secs": 17.89820960724319, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_0": 0.75, "agent_stopped_more": 0.18, "played_steps": 2.54, "reached_maximum_moves": 0.07}, "Total num played games": 6016, "Total num trained steps": 11445, "Timestamp in ms": 1699711736866, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9076005961251863, "Avg loss": 0.7746829513926059, "Avg value loss": 0.6167523459298536, "Avg policy loss": 0.15793060924625024, "Total num played games": 6039, "Total num trained steps": 11520, "Timestamp in ms": 1699711774799, "logtype": "training_step"}
{"Ratio train steps to played games": 1.913107752956636, "Avg loss": 0.648586846422404, "Avg value loss": 0.48478166526183486, "Avg policy loss": 0.16380519012454897, "Total num played games": 6088, "Total num trained steps": 11648, "Timestamp in ms": 1699711836487, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 159.0797061510384, "Avg game time in secs": 6.876621881892788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.15, "played_steps": 0.68, "reached_maximum_moves": 0.01}, "Total num played games": 6144, "Total num trained steps": 11775, "Timestamp in ms": 1699711895949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9149455195966825, "Avg loss": 0.5487464650068432, "Avg value loss": 0.3816939691314474, "Avg policy loss": 0.16705249407095835, "Total num played games": 6149, "Total num trained steps": 11776, "Timestamp in ms": 1699711896172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9115143728922435, "Avg loss": 0.6810975999105722, "Avg value loss": 0.5008792130975053, "Avg policy loss": 0.18021839013090357, "Total num played games": 6227, "Total num trained steps": 11904, "Timestamp in ms": 1699711955446, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 91.93372299708426, "Avg game time in secs": 8.200392991668195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.85}, "Total num played games": 6272, "Total num trained steps": 11974, "Timestamp in ms": 1699711987883, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9160694378085683, "Avg loss": 0.6851086122915149, "Avg value loss": 0.497739908634685, "Avg policy loss": 0.18736870272550732, "Total num played games": 6279, "Total num trained steps": 12032, "Timestamp in ms": 1699712015724, "logtype": "training_step"}
{"Total num played games": 6280, "Total num trained steps": 12038, "Timestamp in ms": 1699712085648, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8046875}
{"Ratio train steps to played games": 1.907593347976153, "Avg loss": 0.6260979047510773, "Avg value loss": 0.4347315540071577, "Avg policy loss": 0.19136634946335107, "Total num played games": 6374, "Total num trained steps": 12160, "Timestamp in ms": 1699712144803, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 203.58958571776748, "Avg game time in secs": 8.72774512549222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.17, "played_steps": 1.06, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.8}, "Total num played games": 6400, "Total num trained steps": 12254, "Timestamp in ms": 1699712191472, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9117784347284892, "Avg loss": 0.8598228944465518, "Avg value loss": 0.6624704459682107, "Avg policy loss": 0.19735245843185112, "Total num played games": 6427, "Total num trained steps": 12288, "Timestamp in ms": 1699712207675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9167824610159023, "Avg loss": 0.7333884995896369, "Avg value loss": 0.5203796589048579, "Avg policy loss": 0.21300884115044028, "Total num played games": 6477, "Total num trained steps": 12416, "Timestamp in ms": 1699712269233, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 137.30932228639722, "Avg game time in secs": 5.38586955802748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.2, "played_steps": 0.5, "reached_maximum_moves": 0.01}, "Total num played games": 6528, "Total num trained steps": 12543, "Timestamp in ms": 1699712328782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9208269525267994, "Avg loss": 0.5807483461685479, "Avg value loss": 0.3700004960410297, "Avg policy loss": 0.21074785385280848, "Total num played games": 6530, "Total num trained steps": 12544, "Timestamp in ms": 1699712329156, "logtype": "training_step"}
{"Total num played games": 6616, "Total num trained steps": 12639, "Timestamp in ms": 1699712414620, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.953125}
{"Avg objective": 20.46875, "Games time in secs": 97.74905248917639, "Avg game time in secs": 7.465313633700134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.77, "agent_stopped_more": 0.2, "played_steps": 0.89, "reached_maximum_moves": 0.02}, "Total num played games": 6656, "Total num trained steps": 12664, "Timestamp in ms": 1699712426531, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9028382640036041, "Avg loss": 0.772196181351319, "Avg value loss": 0.5437527782050893, "Avg policy loss": 0.22844339872244745, "Total num played games": 6659, "Total num trained steps": 12672, "Timestamp in ms": 1699712430361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9207683073229291, "Avg loss": 0.623768285382539, "Avg value loss": 0.3833897567819804, "Avg policy loss": 0.24037852697074413, "Total num played games": 6664, "Total num trained steps": 12800, "Timestamp in ms": 1699712497327, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9131271274234127, "Avg loss": 0.7008469547145069, "Avg value loss": 0.4554743281332776, "Avg policy loss": 0.24537262390367687, "Total num played games": 6757, "Total num trained steps": 12928, "Timestamp in ms": 1699712557813, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 175.33756666444242, "Avg game time in secs": 7.561856166503276, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.2, "played_steps": 1.01, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.78}, "Total num played games": 6784, "Total num trained steps": 13021, "Timestamp in ms": 1699712601869, "logtype": "played_game"}
{"Ratio train steps to played games": 1.917180616740088, "Avg loss": 0.8975232029333711, "Avg value loss": 0.6462696116650477, "Avg policy loss": 0.25125358323566616, "Total num played games": 6810, "Total num trained steps": 13056, "Timestamp in ms": 1699712618840, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9225608866851394, "Avg loss": 0.6867737462744117, "Avg value loss": 0.43444974534213543, "Avg policy loss": 0.25232399709057063, "Total num played games": 6857, "Total num trained steps": 13184, "Timestamp in ms": 1699712680687, "logtype": "training_step"}
{"Total num played games": 6908, "Total num trained steps": 13241, "Timestamp in ms": 1699712801239, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.44140625}
{"Avg objective": 21.09375, "Games time in secs": 201.9211019333452, "Avg game time in secs": 7.901465945033124, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.24, "played_steps": 1.0}, "Total num played games": 6912, "Total num trained steps": 13245, "Timestamp in ms": 1699712803790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9144254278728607, "Avg loss": 0.8249281346797943, "Avg value loss": 0.5598290180787444, "Avg policy loss": 0.265099112293683, "Total num played games": 6953, "Total num trained steps": 13312, "Timestamp in ms": 1699712836885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.92, "Avg loss": 0.71247877785936, "Avg value loss": 0.45431993913371116, "Avg policy loss": 0.25815883523318917, "Total num played games": 7000, "Total num trained steps": 13440, "Timestamp in ms": 1699712898321, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 124.68923536501825, "Avg game time in secs": 5.260507334140129, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.83, "agent_stopped_more": 0.16, "played_steps": 0.55, "reached_maximum_moves": 0.01}, "Total num played games": 7040, "Total num trained steps": 13502, "Timestamp in ms": 1699712928479, "logtype": "played_game"}
{"Ratio train steps to played games": 1.924266061551553, "Avg loss": 0.8416315806098282, "Avg value loss": 0.5675703556044027, "Avg policy loss": 0.27406122244428843, "Total num played games": 7051, "Total num trained steps": 13568, "Timestamp in ms": 1699712959861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9281993523863157, "Avg loss": 0.7335480097681284, "Avg value loss": 0.4600523655535653, "Avg policy loss": 0.27349563932511955, "Total num played games": 7103, "Total num trained steps": 13696, "Timestamp in ms": 1699713022371, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 137.88497967272997, "Avg game time in secs": 4.860526592310634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.81, "agent_stopped_more": 0.18, "played_steps": 0.49, "reached_maximum_moves": 0.01}, "Total num played games": 7168, "Total num trained steps": 13791, "Timestamp in ms": 1699713066364, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9221357063403781, "Avg loss": 0.8618648485280573, "Avg value loss": 0.5860453227069229, "Avg policy loss": 0.27581951988395303, "Total num played games": 7192, "Total num trained steps": 13824, "Timestamp in ms": 1699713081548, "logtype": "training_step"}
{"Total num played games": 7196, "Total num trained steps": 13842, "Timestamp in ms": 1699713121138, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.58984375}
{"Ratio train steps to played games": 1.9268056898218477, "Avg loss": 0.6891580491792411, "Avg value loss": 0.41371880134101957, "Avg policy loss": 0.27543924492783844, "Total num played games": 7241, "Total num trained steps": 13952, "Timestamp in ms": 1699713173672, "logtype": "training_step"}
{"Avg objective": 20.5625, "Games time in secs": 163.00326634198427, "Avg game time in secs": 8.558917433518218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.18, "played_steps": 1.2, "reached_maximum_moves": 0.03}, "Total num played games": 7296, "Total num trained steps": 14072, "Timestamp in ms": 1699713229368, "logtype": "played_game"}
{"Ratio train steps to played games": 1.921921921921922, "Avg loss": 0.6358452460262924, "Avg value loss": 0.37137516180519015, "Avg policy loss": 0.26447008445393294, "Total num played games": 7326, "Total num trained steps": 14080, "Timestamp in ms": 1699713232359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.922077922077922, "Avg loss": 0.6968836958985776, "Avg value loss": 0.4315718978177756, "Avg policy loss": 0.26531180238816887, "Total num played games": 7392, "Total num trained steps": 14208, "Timestamp in ms": 1699713293437, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 99.34148973040283, "Avg game time in secs": 6.720886862385669, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.24, "played_steps": 0.81}, "Total num played games": 7424, "Total num trained steps": 14283, "Timestamp in ms": 1699713328710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9257119828049436, "Avg loss": 0.6382129881531, "Avg value loss": 0.36698276177048683, "Avg policy loss": 0.2712302263826132, "Total num played games": 7444, "Total num trained steps": 14336, "Timestamp in ms": 1699713355571, "logtype": "training_step"}
{"Total num played games": 7493, "Total num trained steps": 14445, "Timestamp in ms": 1699713445959, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.53515625}
{"Ratio train steps to played games": 1.9205948745186563, "Avg loss": 0.6610137135721743, "Avg value loss": 0.39180790970567614, "Avg policy loss": 0.26920580316800624, "Total num played games": 7531, "Total num trained steps": 14464, "Timestamp in ms": 1699713454362, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 179.10908072814345, "Avg game time in secs": 5.732709819727461, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.34, "played_steps": 0.75, "reached_maximum_moves": 0.01}, "Total num played games": 7552, "Total num trained steps": 14577, "Timestamp in ms": 1699713507820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9234115475876614, "Avg loss": 0.6509909930173308, "Avg value loss": 0.38003114389721304, "Avg policy loss": 0.27095984225161374, "Total num played games": 7586, "Total num trained steps": 14592, "Timestamp in ms": 1699713514616, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9268228825762534, "Avg loss": 0.7047290878836066, "Avg value loss": 0.41624066373333335, "Avg policy loss": 0.2884884246159345, "Total num played games": 7639, "Total num trained steps": 14720, "Timestamp in ms": 1699713577233, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 97.42841087467968, "Avg game time in secs": 4.051480963695212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.43}, "Total num played games": 7680, "Total num trained steps": 14782, "Timestamp in ms": 1699713605248, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9314426954598674, "Avg loss": 0.6665534125640988, "Avg value loss": 0.38130721682682633, "Avg policy loss": 0.2852461994625628, "Total num played games": 7687, "Total num trained steps": 14848, "Timestamp in ms": 1699713636899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9269171384457024, "Avg loss": 0.8938078570645303, "Avg value loss": 0.610162110067904, "Avg policy loss": 0.2836457446683198, "Total num played games": 7772, "Total num trained steps": 14976, "Timestamp in ms": 1699713695737, "logtype": "training_step"}
{"Total num played games": 7786, "Total num trained steps": 15046, "Timestamp in ms": 1699713766718, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.9140625}
{"Avg objective": 21.625, "Games time in secs": 165.72173560783267, "Avg game time in secs": 7.142263107423787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 1.03, "agent_stopped_0": 0.66, "reached_maximum_moves": 0.02}, "Total num played games": 7808, "Total num trained steps": 15055, "Timestamp in ms": 1699713770970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9281246010468531, "Avg loss": 0.8862501126714051, "Avg value loss": 0.59346174786333, "Avg policy loss": 0.29278836108278483, "Total num played games": 7833, "Total num trained steps": 15104, "Timestamp in ms": 1699713794055, "logtype": "training_step"}
{"Ratio train steps to played games": 1.932622763608679, "Avg loss": 0.6241165087558329, "Avg value loss": 0.32609612576197833, "Avg policy loss": 0.2980203836923465, "Total num played games": 7881, "Total num trained steps": 15232, "Timestamp in ms": 1699713853327, "logtype": "training_step"}
{"Avg objective": 20.0859375, "Games time in secs": 139.5358111783862, "Avg game time in secs": 5.254029639312648, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.74, "agent_stopped_more": 0.24, "played_steps": 0.66, "reached_maximum_moves": 0.02}, "Total num played games": 7936, "Total num trained steps": 15352, "Timestamp in ms": 1699713910506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.926260346124906, "Avg loss": 0.679213063325733, "Avg value loss": 0.3866997287841514, "Avg policy loss": 0.2925133304670453, "Total num played games": 7974, "Total num trained steps": 15360, "Timestamp in ms": 1699713913843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9296037876900074, "Avg loss": 0.8582132214214653, "Avg value loss": 0.5728632612153888, "Avg policy loss": 0.285349954967387, "Total num played games": 8026, "Total num trained steps": 15488, "Timestamp in ms": 1699713974254, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 93.90305876359344, "Avg game time in secs": 3.226003899530042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.84, "agent_stopped_more": 0.16, "played_steps": 0.29}, "Total num played games": 8064, "Total num trained steps": 15552, "Timestamp in ms": 1699714004409, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9332673022161693, "Avg loss": 0.8205541053321213, "Avg value loss": 0.532894846284762, "Avg policy loss": 0.2876592583488673, "Total num played games": 8077, "Total num trained steps": 15616, "Timestamp in ms": 1699714033881, "logtype": "training_step"}
{"Total num played games": 8127, "Total num trained steps": 15649, "Timestamp in ms": 1699714105488, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1484375}
{"Ratio train steps to played games": 1.9261071690726694, "Avg loss": 0.9652368323877454, "Avg value loss": 0.6784743693424389, "Avg policy loss": 0.286762457806617, "Total num played games": 8174, "Total num trained steps": 15744, "Timestamp in ms": 1699714151964, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 193.3308149985969, "Avg game time in secs": 3.7022642336814897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.76, "agent_stopped_more": 0.24, "played_steps": 0.39}, "Total num played games": 8192, "Total num trained steps": 15842, "Timestamp in ms": 1699714197741, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9303089272683045, "Avg loss": 0.6303385188803077, "Avg value loss": 0.3491213625529781, "Avg policy loss": 0.2812171543482691, "Total num played games": 8222, "Total num trained steps": 15872, "Timestamp in ms": 1699714210749, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9336475707034082, "Avg loss": 0.7338917071465403, "Avg value loss": 0.4562703501433134, "Avg policy loss": 0.27762134897056967, "Total num played games": 8274, "Total num trained steps": 16000, "Timestamp in ms": 1699714270558, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 94.852176155895, "Avg game time in secs": 4.315018659894122, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.78, "agent_stopped_more": 0.21, "played_steps": 0.48, "reached_maximum_moves": 0.01}, "Total num played games": 8320, "Total num trained steps": 16048, "Timestamp in ms": 1699714292594, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9369445111698294, "Avg loss": 0.6790198858361691, "Avg value loss": 0.40521448547951877, "Avg policy loss": 0.2738054033834487, "Total num played games": 8326, "Total num trained steps": 16128, "Timestamp in ms": 1699714329577, "logtype": "training_step"}
{"Total num played games": 8422, "Total num trained steps": 16253, "Timestamp in ms": 1699714419656, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.0234375}
{"Ratio train steps to played games": 1.9288087327954437, "Avg loss": 0.5699794846586883, "Avg value loss": 0.29612189705949277, "Avg policy loss": 0.27385758922901005, "Total num played games": 8427, "Total num trained steps": 16256, "Timestamp in ms": 1699714422007, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 130.53109754994512, "Avg game time in secs": 3.9113108686287887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.24, "played_steps": 0.48, "agent_stopped_0": 0.76}, "Total num played games": 8448, "Total num trained steps": 16258, "Timestamp in ms": 1699714423125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9343565525383708, "Avg loss": 0.8667971063405275, "Avg value loss": 0.5829864280531183, "Avg policy loss": 0.28381067980080843, "Total num played games": 8470, "Total num trained steps": 16384, "Timestamp in ms": 1699714483705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9381382791407442, "Avg loss": 0.7249573227018118, "Avg value loss": 0.44759613648056984, "Avg policy loss": 0.2773611842421815, "Total num played games": 8519, "Total num trained steps": 16512, "Timestamp in ms": 1699714543634, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 174.21224685385823, "Avg game time in secs": 5.203473742731148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.33, "played_steps": 0.78, "reached_maximum_moves": 0.02}, "Total num played games": 8576, "Total num trained steps": 16626, "Timestamp in ms": 1699714597337, "logtype": "played_game"}
{"Ratio train steps to played games": 1.931739029486882, "Avg loss": 0.8474991738330573, "Avg value loss": 0.5658851150656119, "Avg policy loss": 0.28161405748687685, "Total num played games": 8614, "Total num trained steps": 16640, "Timestamp in ms": 1699714603758, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9348026771290099, "Avg loss": 0.8603843925520778, "Avg value loss": 0.5635256133973598, "Avg policy loss": 0.2968587790383026, "Total num played games": 8666, "Total num trained steps": 16768, "Timestamp in ms": 1699714662573, "logtype": "training_step"}
{"Avg objective": 22.0234375, "Games time in secs": 92.92540699988604, "Avg game time in secs": 3.515146054996876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.79, "agent_stopped_more": 0.21, "played_steps": 0.38}, "Total num played games": 8704, "Total num trained steps": 16828, "Timestamp in ms": 1699714690268, "logtype": "played_game"}
{"Total num played games": 8716, "Total num trained steps": 16855, "Timestamp in ms": 1699714793342, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.140625}
{"Ratio train steps to played games": 1.9278868096759472, "Avg loss": 0.8140627830289304, "Avg value loss": 0.5278949175262824, "Avg policy loss": 0.28616786701604724, "Total num played games": 8764, "Total num trained steps": 16896, "Timestamp in ms": 1699714812359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9360855225747753, "Avg loss": 0.5938973012380302, "Avg value loss": 0.3113329947227612, "Avg policy loss": 0.282564306166023, "Total num played games": 8792, "Total num trained steps": 17024, "Timestamp in ms": 1699714872710, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 226.57674575969577, "Avg game time in secs": 3.2823243953462224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.71, "agent_stopped_more": 0.29, "played_steps": 0.37}, "Total num played games": 8832, "Total num trained steps": 17119, "Timestamp in ms": 1699714916845, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9356731745852613, "Avg loss": 0.7726667295210063, "Avg value loss": 0.4900062488159165, "Avg policy loss": 0.2826604802394286, "Total num played games": 8861, "Total num trained steps": 17152, "Timestamp in ms": 1699714931727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.938846499102334, "Avg loss": 0.7134363176301122, "Avg value loss": 0.43519470968749374, "Avg policy loss": 0.2782416024710983, "Total num played games": 8912, "Total num trained steps": 17280, "Timestamp in ms": 1699714990613, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 113.00920054875314, "Avg game time in secs": 3.2572757042507874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.38}, "Total num played games": 8960, "Total num trained steps": 17367, "Timestamp in ms": 1699715029855, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9425287356321839, "Avg loss": 0.5886238242965192, "Avg value loss": 0.31462834996636957, "Avg policy loss": 0.27399547246750444, "Total num played games": 8961, "Total num trained steps": 17408, "Timestamp in ms": 1699715048315, "logtype": "training_step"}
{"Total num played games": 9011, "Total num trained steps": 17456, "Timestamp in ms": 1699715116977, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.34765625}
{"Ratio train steps to played games": 1.93564411082901, "Avg loss": 0.773730346467346, "Avg value loss": 0.5060852859169245, "Avg policy loss": 0.26764506183099, "Total num played games": 9059, "Total num trained steps": 17536, "Timestamp in ms": 1699715155725, "logtype": "training_step"}
{"Avg objective": 22.0390625, "Games time in secs": 160.46244830079377, "Avg game time in secs": 2.847840156595339, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.22, "played_steps": 0.32, "agent_stopped_0": 0.78}, "Total num played games": 9088, "Total num trained steps": 17611, "Timestamp in ms": 1699715190317, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9394970901504338, "Avg loss": 0.637153169605881, "Avg value loss": 0.3834932156605646, "Avg policy loss": 0.25365996081382036, "Total num played games": 9107, "Total num trained steps": 17664, "Timestamp in ms": 1699715214713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9433096668487166, "Avg loss": 0.5865578388329595, "Avg value loss": 0.3370143133215606, "Avg policy loss": 0.24954352038912475, "Total num played games": 9155, "Total num trained steps": 17792, "Timestamp in ms": 1699715272269, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 132.0716504920274, "Avg game time in secs": 4.217522231789189, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.6}, "Total num played games": 9216, "Total num trained steps": 17902, "Timestamp in ms": 1699715322389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9367704280155642, "Avg loss": 0.8047058216761798, "Avg value loss": 0.5481597509933636, "Avg policy loss": 0.2565460620680824, "Total num played games": 9252, "Total num trained steps": 17920, "Timestamp in ms": 1699715330187, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9397033533963886, "Avg loss": 0.7729642309714109, "Avg value loss": 0.5162932102102786, "Avg policy loss": 0.25667101377621293, "Total num played games": 9304, "Total num trained steps": 18048, "Timestamp in ms": 1699715389262, "logtype": "training_step"}
{"Total num played games": 9304, "Total num trained steps": 18057, "Timestamp in ms": 1699715420093, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.41796875}
{"Avg objective": 21.703125, "Games time in secs": 103.21384943462908, "Avg game time in secs": 3.3594618671631906, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.45}, "Total num played games": 9344, "Total num trained steps": 18069, "Timestamp in ms": 1699715425603, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9434345594525235, "Avg loss": 0.5444067281205207, "Avg value loss": 0.28678174351807684, "Avg policy loss": 0.25762497913092375, "Total num played games": 9352, "Total num trained steps": 18176, "Timestamp in ms": 1699715475718, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9385723363694132, "Avg loss": 0.7450633407570422, "Avg value loss": 0.4814589233137667, "Avg policy loss": 0.26360441476572305, "Total num played games": 9442, "Total num trained steps": 18304, "Timestamp in ms": 1699715534070, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 151.51935254223645, "Avg game time in secs": 2.917399507656228, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.46, "agent_stopped_0": 0.69}, "Total num played games": 9472, "Total num trained steps": 18392, "Timestamp in ms": 1699715577122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9404147805032108, "Avg loss": 0.7613887351471931, "Avg value loss": 0.49407203251030296, "Avg policy loss": 0.26731669716537, "Total num played games": 9499, "Total num trained steps": 18432, "Timestamp in ms": 1699715597127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9437578550481776, "Avg loss": 0.6406546414364129, "Avg value loss": 0.38115038140676916, "Avg policy loss": 0.2595042645698413, "Total num played games": 9548, "Total num trained steps": 18560, "Timestamp in ms": 1699715656348, "logtype": "training_step"}
{"Total num played games": 9597, "Total num trained steps": 18659, "Timestamp in ms": 1699715735447, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.15234375}
{"Avg objective": 22.359375, "Games time in secs": 159.66553281992674, "Avg game time in secs": 2.7637131746014347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 9600, "Total num trained steps": 18661, "Timestamp in ms": 1699715736788, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9375842405391395, "Avg loss": 0.82619290612638, "Avg value loss": 0.5555895904544741, "Avg policy loss": 0.27060331031680107, "Total num played games": 9645, "Total num trained steps": 18688, "Timestamp in ms": 1699715748536, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9412917870408584, "Avg loss": 0.6633072174154222, "Avg value loss": 0.3972165444865823, "Avg policy loss": 0.26609067479148507, "Total num played games": 9692, "Total num trained steps": 18816, "Timestamp in ms": 1699715808515, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 104.0342964567244, "Avg game time in secs": 2.5412450110161444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.4}, "Total num played games": 9728, "Total num trained steps": 18884, "Timestamp in ms": 1699715840823, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9446668719843958, "Avg loss": 0.6761939458083361, "Avg value loss": 0.403713472886011, "Avg policy loss": 0.2724804659374058, "Total num played games": 9741, "Total num trained steps": 18944, "Timestamp in ms": 1699715868705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9477124183006536, "Avg loss": 0.8001553651411086, "Avg value loss": 0.52928472077474, "Avg policy loss": 0.2708706563571468, "Total num played games": 9792, "Total num trained steps": 19072, "Timestamp in ms": 1699715930650, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 138.03967428021133, "Avg game time in secs": 3.110714528884273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.49, "agent_stopped_0": 0.69}, "Total num played games": 9856, "Total num trained steps": 19174, "Timestamp in ms": 1699715978868, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9414500960663363, "Avg loss": 0.7565107683185488, "Avg value loss": 0.47596609499305487, "Avg policy loss": 0.2805446769343689, "Total num played games": 9889, "Total num trained steps": 19200, "Timestamp in ms": 1699715990393, "logtype": "training_step"}
{"Total num played games": 9890, "Total num trained steps": 19259, "Timestamp in ms": 1699716107269, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.2265625}
{"Ratio train steps to played games": 1.9448581203461461, "Avg loss": 0.7708902962040156, "Avg value loss": 0.47062547435052693, "Avg policy loss": 0.3002648251131177, "Total num played games": 9938, "Total num trained steps": 19328, "Timestamp in ms": 1699716142883, "logtype": "training_step"}
{"Avg objective": 21.1328125, "Games time in secs": 189.1685484368354, "Avg game time in secs": 2.5959021451999433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 9984, "Total num trained steps": 19375, "Timestamp in ms": 1699716168036, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9480324421748272, "Avg loss": 0.6576451291330159, "Avg value loss": 0.36796038795728236, "Avg policy loss": 0.289684739545919, "Total num played games": 9987, "Total num trained steps": 19456, "Timestamp in ms": 1699716216662, "logtype": "training_step"}
{"Ratio train steps to played games": 1.941409735302865, "Avg loss": 0.8714849024545401, "Avg value loss": 0.5665831528604031, "Avg policy loss": 0.30490174563601613, "Total num played games": 10087, "Total num trained steps": 19584, "Timestamp in ms": 1699716287562, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 167.91148826293647, "Avg game time in secs": 2.4909236234234413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.45, "agent_stopped_0": 0.68}, "Total num played games": 10112, "Total num trained steps": 19668, "Timestamp in ms": 1699716335948, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9444608858636678, "Avg loss": 0.686115468852222, "Avg value loss": 0.3872607728699222, "Avg policy loss": 0.29885469493456185, "Total num played games": 10137, "Total num trained steps": 19712, "Timestamp in ms": 1699716360282, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9478645066273932, "Avg loss": 0.7683526487089694, "Avg value loss": 0.4582505270373076, "Avg policy loss": 0.31010212015826255, "Total num played games": 10185, "Total num trained steps": 19840, "Timestamp in ms": 1699716434111, "logtype": "training_step"}
{"Total num played games": 10197, "Total num trained steps": 19859, "Timestamp in ms": 1699716547539, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.78515625}
{"Avg objective": 22.0859375, "Games time in secs": 218.24930064752698, "Avg game time in secs": 3.1521869834541576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.56}, "Total num played games": 10240, "Total num trained steps": 19869, "Timestamp in ms": 1699716554197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9490483162518302, "Avg loss": 0.7620110507123172, "Avg value loss": 0.45930421131197363, "Avg policy loss": 0.30270684033166617, "Total num played games": 10245, "Total num trained steps": 19968, "Timestamp in ms": 1699716612515, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9430477663894798, "Avg loss": 0.8051826111041009, "Avg value loss": 0.48826878785621375, "Avg policy loss": 0.316913825343363, "Total num played games": 10342, "Total num trained steps": 20096, "Timestamp in ms": 1699716688830, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 181.5113880354911, "Avg game time in secs": 2.304909142825636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 0.39, "agent_stopped_0": 0.73}, "Total num played games": 10368, "Total num trained steps": 20179, "Timestamp in ms": 1699716735709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9461123941493457, "Avg loss": 0.6741809023078531, "Avg value loss": 0.3516973527148366, "Avg policy loss": 0.32248355506453663, "Total num played games": 10392, "Total num trained steps": 20224, "Timestamp in ms": 1699716760706, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9493295019157089, "Avg loss": 0.6463420453947037, "Avg value loss": 0.3297479224856943, "Avg policy loss": 0.3165941243059933, "Total num played games": 10440, "Total num trained steps": 20352, "Timestamp in ms": 1699716841494, "logtype": "training_step"}
{"Total num played games": 10489, "Total num trained steps": 20460, "Timestamp in ms": 1699716949551, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.12890625}
{"Avg objective": 20.21875, "Games time in secs": 215.3766683228314, "Avg game time in secs": 3.037450656891451, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.62}, "Total num played games": 10496, "Total num trained steps": 20461, "Timestamp in ms": 1699716951086, "logtype": "played_game"}
{"Ratio train steps to played games": 1.943627218373351, "Avg loss": 0.9093350823968649, "Avg value loss": 0.5848230263218284, "Avg policy loss": 0.3245120559586212, "Total num played games": 10537, "Total num trained steps": 20480, "Timestamp in ms": 1699716963025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.94644375177104, "Avg loss": 0.7885493577923626, "Avg value loss": 0.4701862863730639, "Avg policy loss": 0.31836306885816157, "Total num played games": 10587, "Total num trained steps": 20608, "Timestamp in ms": 1699717047105, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 134.71707383915782, "Avg game time in secs": 1.9866686915629543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.34}, "Total num played games": 10624, "Total num trained steps": 20667, "Timestamp in ms": 1699717085803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9496051147047762, "Avg loss": 0.690021556103602, "Avg value loss": 0.3721184404566884, "Avg policy loss": 0.3179031148320064, "Total num played games": 10636, "Total num trained steps": 20736, "Timestamp in ms": 1699717132279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9449986016593641, "Avg loss": 0.6884478442370892, "Avg value loss": 0.3744297086959705, "Avg policy loss": 0.3140181384515017, "Total num played games": 10727, "Total num trained steps": 20864, "Timestamp in ms": 1699717220405, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 191.2851833831519, "Avg game time in secs": 2.2956455829698825, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.45}, "Total num played games": 10752, "Total num trained steps": 20956, "Timestamp in ms": 1699717277088, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9464948071216617, "Avg loss": 0.8715980986598879, "Avg value loss": 0.5627560771536082, "Avg policy loss": 0.3088420194108039, "Total num played games": 10784, "Total num trained steps": 20992, "Timestamp in ms": 1699717300542, "logtype": "training_step"}
{"Total num played games": 10833, "Total num trained steps": 21061, "Timestamp in ms": 1699717431287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.62890625}
{"Avg objective": 20.796875, "Games time in secs": 160.55982749164104, "Avg game time in secs": 2.264206844876753, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.52}, "Total num played games": 10880, "Total num trained steps": 21071, "Timestamp in ms": 1699717437648, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9409061667126184, "Avg loss": 0.8543844397645444, "Avg value loss": 0.5363686580676585, "Avg policy loss": 0.31801577645819634, "Total num played games": 10881, "Total num trained steps": 21120, "Timestamp in ms": 1699717469200, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9526697913794688, "Avg loss": 0.5513293570838869, "Avg value loss": 0.23182152514345944, "Avg policy loss": 0.3195078349672258, "Total num played games": 10881, "Total num trained steps": 21248, "Timestamp in ms": 1699717550604, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9467213114754098, "Avg loss": 0.6892188645433635, "Avg value loss": 0.3840018743649125, "Avg policy loss": 0.30521698924712837, "Total num played games": 10980, "Total num trained steps": 21376, "Timestamp in ms": 1699717632121, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 244.09184928424656, "Avg game time in secs": 1.9378700248635141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.26, "played_steps": 0.35, "agent_stopped_0": 0.74}, "Total num played games": 11008, "Total num trained steps": 21454, "Timestamp in ms": 1699717681740, "logtype": "played_game"}
{"Ratio train steps to played games": 1.949854914762423, "Avg loss": 0.6837339519988745, "Avg value loss": 0.37791611591819674, "Avg policy loss": 0.30581783247180283, "Total num played games": 11028, "Total num trained steps": 21504, "Timestamp in ms": 1699717710029, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9527850501038186, "Avg loss": 0.778718845685944, "Avg value loss": 0.4770498377038166, "Avg policy loss": 0.30166900635231286, "Total num played games": 11077, "Total num trained steps": 21632, "Timestamp in ms": 1699717792628, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 124.35680288821459, "Avg game time in secs": 2.404969537470606, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.51, "agent_stopped_0": 0.57}, "Total num played games": 11136, "Total num trained steps": 21653, "Timestamp in ms": 1699717806097, "logtype": "played_game"}
{"Total num played games": 11138, "Total num trained steps": 21662, "Timestamp in ms": 1699717892932, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.015625}
{"Ratio train steps to played games": 1.94519935633828, "Avg loss": 0.8574637093115598, "Avg value loss": 0.5627621858147904, "Avg policy loss": 0.2947015285026282, "Total num played games": 11186, "Total num trained steps": 21760, "Timestamp in ms": 1699717954990, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9481975967957277, "Avg loss": 0.5616844380274415, "Avg value loss": 0.2857953733182512, "Avg policy loss": 0.2758890682598576, "Total num played games": 11235, "Total num trained steps": 21888, "Timestamp in ms": 1699718032489, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 276.02468142285943, "Avg game time in secs": 2.2046378915692912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.42, "agent_stopped_0": 0.69}, "Total num played games": 11264, "Total num trained steps": 21962, "Timestamp in ms": 1699718082122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9509925558312655, "Avg loss": 0.7423258300404996, "Avg value loss": 0.448957716813311, "Avg policy loss": 0.29336811089888215, "Total num played games": 11284, "Total num trained steps": 22016, "Timestamp in ms": 1699718114310, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9539398217594635, "Avg loss": 0.6275516264140606, "Avg value loss": 0.3437371924519539, "Avg policy loss": 0.2838144317502156, "Total num played games": 11333, "Total num trained steps": 22144, "Timestamp in ms": 1699718194231, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 178.67019957117736, "Avg game time in secs": 2.3980083190253936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 11392, "Total num trained steps": 22254, "Timestamp in ms": 1699718260792, "logtype": "played_game"}
{"Total num played games": 11430, "Total num trained steps": 22263, "Timestamp in ms": 1699718360441, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.75390625}
{"Ratio train steps to played games": 1.9411662163340015, "Avg loss": 0.7726563033647835, "Avg value loss": 0.46654837869573385, "Avg policy loss": 0.30610791756771505, "Total num played games": 11473, "Total num trained steps": 22272, "Timestamp in ms": 1699718366016, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9514723819480746, "Avg loss": 0.7420447077602148, "Avg value loss": 0.4284605720313266, "Avg policy loss": 0.3135841282783076, "Total num played games": 11478, "Total num trained steps": 22400, "Timestamp in ms": 1699718450192, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 224.86109728738666, "Avg game time in secs": 2.578487815131666, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.67}, "Total num played games": 11520, "Total num trained steps": 22450, "Timestamp in ms": 1699718485654, "logtype": "played_game"}
{"Ratio train steps to played games": 1.954368005552182, "Avg loss": 0.6322506316937506, "Avg value loss": 0.3381684535415843, "Avg policy loss": 0.2940821781521663, "Total num played games": 11527, "Total num trained steps": 22528, "Timestamp in ms": 1699718530717, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9489848589125947, "Avg loss": 0.792014084989205, "Avg value loss": 0.4895255733281374, "Avg policy loss": 0.302488504210487, "Total num played games": 11624, "Total num trained steps": 22656, "Timestamp in ms": 1699718610173, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 174.80782672390342, "Avg game time in secs": 2.2702738773514284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.55, "agent_stopped_0": 0.57}, "Total num played games": 11648, "Total num trained steps": 22740, "Timestamp in ms": 1699718660462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9517690396641822, "Avg loss": 0.81137181725353, "Avg value loss": 0.5153510114178061, "Avg policy loss": 0.2960208016447723, "Total num played games": 11673, "Total num trained steps": 22784, "Timestamp in ms": 1699718684953, "logtype": "training_step"}
{"Total num played games": 11721, "Total num trained steps": 22863, "Timestamp in ms": 1699718763531, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.20703125}
{"Ratio train steps to played games": 1.9467244455773642, "Avg loss": 0.8550336218904704, "Avg value loss": 0.5558960718335584, "Avg policy loss": 0.2991375576239079, "Total num played games": 11769, "Total num trained steps": 22912, "Timestamp in ms": 1699718793741, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 207.15820717066526, "Avg game time in secs": 2.467882733908482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.62}, "Total num played games": 11776, "Total num trained steps": 23028, "Timestamp in ms": 1699718867620, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9499788404570462, "Avg loss": 0.6284278403036296, "Avg value loss": 0.33409547159681097, "Avg policy loss": 0.2943323628278449, "Total num played games": 11815, "Total num trained steps": 23040, "Timestamp in ms": 1699718873465, "logtype": "training_step"}
{"Ratio train steps to played games": 1.952384965447497, "Avg loss": 0.8302424279972911, "Avg value loss": 0.5219724896596745, "Avg policy loss": 0.30826993787195534, "Total num played games": 11866, "Total num trained steps": 23168, "Timestamp in ms": 1699718956959, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 127.0647214576602, "Avg game time in secs": 2.288928676251089, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.63}, "Total num played games": 11904, "Total num trained steps": 23226, "Timestamp in ms": 1699718994685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9552627161322813, "Avg loss": 0.622608550125733, "Avg value loss": 0.3224599469685927, "Avg policy loss": 0.3001486036228016, "Total num played games": 11914, "Total num trained steps": 23296, "Timestamp in ms": 1699719033693, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95134955014995, "Avg loss": 0.8331475781742483, "Avg value loss": 0.5263411977794021, "Avg policy loss": 0.30680637806653976, "Total num played games": 12004, "Total num trained steps": 23424, "Timestamp in ms": 1699719108396, "logtype": "training_step"}
{"Total num played games": 12012, "Total num trained steps": 23466, "Timestamp in ms": 1699719202037, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.09765625}
{"Avg objective": 21.171875, "Games time in secs": 209.8518554866314, "Avg game time in secs": 2.2573646231467137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.6, "agent_stopped_0": 0.58}, "Total num played games": 12032, "Total num trained steps": 23470, "Timestamp in ms": 1699719204537, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9529021558872306, "Avg loss": 0.748140758369118, "Avg value loss": 0.4377349386923015, "Avg policy loss": 0.3104058192111552, "Total num played games": 12060, "Total num trained steps": 23552, "Timestamp in ms": 1699719253317, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95532617671346, "Avg loss": 0.7122723038773984, "Avg value loss": 0.4045658747199923, "Avg policy loss": 0.3077064340468496, "Total num played games": 12110, "Total num trained steps": 23680, "Timestamp in ms": 1699719328621, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 142.41353510133922, "Avg game time in secs": 2.189792702018167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 12160, "Total num trained steps": 23717, "Timestamp in ms": 1699719346951, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9573296061826853, "Avg loss": 0.5829753295984119, "Avg value loss": 0.27101478131953627, "Avg policy loss": 0.3119605453684926, "Total num played games": 12163, "Total num trained steps": 23808, "Timestamp in ms": 1699719401010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.952443103026348, "Avg loss": 0.694064250215888, "Avg value loss": 0.3901553553296253, "Avg policy loss": 0.30390889465343207, "Total num played games": 12259, "Total num trained steps": 23936, "Timestamp in ms": 1699719470881, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 165.33074454404414, "Avg game time in secs": 1.8654989471688168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 12288, "Total num trained steps": 24010, "Timestamp in ms": 1699719512282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9552287316161534, "Avg loss": 0.682318230625242, "Avg value loss": 0.3824277217499912, "Avg policy loss": 0.2998905157437548, "Total num played games": 12307, "Total num trained steps": 24064, "Timestamp in ms": 1699719542176, "logtype": "training_step"}
{"Total num played games": 12307, "Total num trained steps": 24068, "Timestamp in ms": 1699719613587, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.40234375}
{"Ratio train steps to played games": 1.9579927154997976, "Avg loss": 0.7115678645204753, "Avg value loss": 0.41544436349067837, "Avg policy loss": 0.2961234914837405, "Total num played games": 12355, "Total num trained steps": 24192, "Timestamp in ms": 1699719692496, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 237.62942877411842, "Avg game time in secs": 1.9512353021855233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 12416, "Total num trained steps": 24297, "Timestamp in ms": 1699719749911, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9528627639926122, "Avg loss": 0.6583347728010267, "Avg value loss": 0.3691122835734859, "Avg policy loss": 0.28922249178867787, "Total num played games": 12453, "Total num trained steps": 24320, "Timestamp in ms": 1699719761541, "logtype": "training_step"}
{"Ratio train steps to played games": 1.955290730224746, "Avg loss": 0.8364978758618236, "Avg value loss": 0.5402789651998319, "Avg policy loss": 0.29621891013812274, "Total num played games": 12503, "Total num trained steps": 24448, "Timestamp in ms": 1699719833596, "logtype": "training_step"}
{"Avg objective": 22.875, "Games time in secs": 113.92960546724498, "Avg game time in secs": 1.9411254256410757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.54}, "Total num played games": 12544, "Total num trained steps": 24500, "Timestamp in ms": 1699719863841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9580909887658353, "Avg loss": 0.8298757954034954, "Avg value loss": 0.523697562632151, "Avg policy loss": 0.3061782324220985, "Total num played games": 12551, "Total num trained steps": 24576, "Timestamp in ms": 1699719912389, "logtype": "training_step"}
{"Total num played games": 12600, "Total num trained steps": 24670, "Timestamp in ms": 1699720051401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2890625}
{"Ratio train steps to played games": 1.9531151170145478, "Avg loss": 0.7069068429991603, "Avg value loss": 0.4017798254499212, "Avg policy loss": 0.30512701091356575, "Total num played games": 12648, "Total num trained steps": 24704, "Timestamp in ms": 1699720073537, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 258.7563857883215, "Avg game time in secs": 2.3316920393699547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.61, "agent_stopped_0": 0.58}, "Total num played games": 12672, "Total num trained steps": 24788, "Timestamp in ms": 1699720122602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9557375758053084, "Avg loss": 0.6716852409299463, "Avg value loss": 0.36785144032910466, "Avg policy loss": 0.3038338014157489, "Total num played games": 12697, "Total num trained steps": 24832, "Timestamp in ms": 1699720152696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9583366025892508, "Avg loss": 0.6679677059873939, "Avg value loss": 0.3612730649765581, "Avg policy loss": 0.30669464042875916, "Total num played games": 12745, "Total num trained steps": 24960, "Timestamp in ms": 1699720233539, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 184.232416305691, "Avg game time in secs": 2.298863934178371, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.66}, "Total num played games": 12800, "Total num trained steps": 25078, "Timestamp in ms": 1699720306835, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9536640448563196, "Avg loss": 0.8572370747569948, "Avg value loss": 0.5486947844037786, "Avg policy loss": 0.3085422887234017, "Total num played games": 12841, "Total num trained steps": 25088, "Timestamp in ms": 1699720312594, "logtype": "training_step"}
{"Ratio train steps to played games": 1.956015824994182, "Avg loss": 0.9333085983525962, "Avg value loss": 0.6106211791047826, "Avg policy loss": 0.32268741354346275, "Total num played games": 12891, "Total num trained steps": 25216, "Timestamp in ms": 1699720396430, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 126.50177078135312, "Avg game time in secs": 2.016599687820417, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.6}, "Total num played games": 12928, "Total num trained steps": 25274, "Timestamp in ms": 1699720433337, "logtype": "played_game"}
{"Total num played games": 12941, "Total num trained steps": 25274, "Timestamp in ms": 1699720503010, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.4765625}
{"Ratio train steps to played games": 1.951112479790592, "Avg loss": 1.0522817512974143, "Avg value loss": 0.7279703359818086, "Avg policy loss": 0.3243114216020331, "Total num played games": 12989, "Total num trained steps": 25344, "Timestamp in ms": 1699720543919, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9555470249520153, "Avg loss": 0.5070764285046607, "Avg value loss": 0.19603210559580475, "Avg policy loss": 0.31104432384017855, "Total num played games": 13025, "Total num trained steps": 25472, "Timestamp in ms": 1699720621405, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 243.8520312216133, "Avg game time in secs": 1.9821892346080858, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.55, "agent_stopped_0": 0.57}, "Total num played games": 13056, "Total num trained steps": 25565, "Timestamp in ms": 1699720677189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955764382305753, "Avg loss": 0.9981367439031601, "Avg value loss": 0.6845694155199453, "Avg policy loss": 0.3135673254728317, "Total num played games": 13089, "Total num trained steps": 25600, "Timestamp in ms": 1699720697872, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9580637795874876, "Avg loss": 0.6834909291937947, "Avg value loss": 0.36018127109855413, "Avg policy loss": 0.32330966368317604, "Total num played games": 13139, "Total num trained steps": 25728, "Timestamp in ms": 1699720780240, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 131.73165224306285, "Avg game time in secs": 2.123714429442771, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.61}, "Total num played games": 13184, "Total num trained steps": 25773, "Timestamp in ms": 1699720808921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9607188898157275, "Avg loss": 0.7080576438456774, "Avg value loss": 0.3859091675840318, "Avg policy loss": 0.32214847567956895, "Total num played games": 13187, "Total num trained steps": 25856, "Timestamp in ms": 1699720859300, "logtype": "training_step"}
{"Total num played games": 13236, "Total num trained steps": 25876, "Timestamp in ms": 1699720940245, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6328125}
{"Ratio train steps to played games": 1.9559620596205962, "Avg loss": 1.0653152726590633, "Avg value loss": 0.7323071102146059, "Avg policy loss": 0.33300816896371543, "Total num played games": 13284, "Total num trained steps": 25984, "Timestamp in ms": 1699721011898, "logtype": "training_step"}
{"Avg objective": 22.96875, "Games time in secs": 247.6542176157236, "Avg game time in secs": 1.7665056443220237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.42, "agent_stopped_0": 0.65}, "Total num played games": 13312, "Total num trained steps": 26061, "Timestamp in ms": 1699721056575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9583739593489837, "Avg loss": 0.6051079200115055, "Avg value loss": 0.28369534359080717, "Avg policy loss": 0.3214125743834302, "Total num played games": 13333, "Total num trained steps": 26112, "Timestamp in ms": 1699721089336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9609147298408192, "Avg loss": 0.6614924389868975, "Avg value loss": 0.33529373281635344, "Avg policy loss": 0.32619871257338673, "Total num played games": 13381, "Total num trained steps": 26240, "Timestamp in ms": 1699721162014, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 170.35750085674226, "Avg game time in secs": 2.163469301900477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.55}, "Total num played games": 13440, "Total num trained steps": 26349, "Timestamp in ms": 1699721226933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9561540173603382, "Avg loss": 0.7843257968779653, "Avg value loss": 0.449840827495791, "Avg policy loss": 0.334484968916513, "Total num played games": 13479, "Total num trained steps": 26368, "Timestamp in ms": 1699721237970, "logtype": "training_step"}
{"Total num played games": 13528, "Total num trained steps": 26476, "Timestamp in ms": 1699721327053, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.98046875}
{"Avg objective": 21.0546875, "Games time in secs": 103.45758555270731, "Avg game time in secs": 2.0382627221406437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.65}, "Total num played games": 13568, "Total num trained steps": 26481, "Timestamp in ms": 1699721330390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9516794342958161, "Avg loss": 0.7498853106517345, "Avg value loss": 0.41093925293534994, "Avg policy loss": 0.33894605725072324, "Total num played games": 13576, "Total num trained steps": 26496, "Timestamp in ms": 1699721338020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9611078373600472, "Avg loss": 0.6246024591382593, "Avg value loss": 0.28259762533707544, "Avg policy loss": 0.3420048230327666, "Total num played games": 13576, "Total num trained steps": 26624, "Timestamp in ms": 1699721411300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9564835807796388, "Avg loss": 0.6762229301966727, "Avg value loss": 0.35090074106119573, "Avg policy loss": 0.3253221844788641, "Total num played games": 13673, "Total num trained steps": 26752, "Timestamp in ms": 1699721482745, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 202.58602512441576, "Avg game time in secs": 1.963405137968948, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 13696, "Total num trained steps": 26836, "Timestamp in ms": 1699721532977, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9588252441335083, "Avg loss": 0.7222672696225345, "Avg value loss": 0.39293123921379447, "Avg policy loss": 0.32933603099081665, "Total num played games": 13722, "Total num trained steps": 26880, "Timestamp in ms": 1699721557208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9611502432648318, "Avg loss": 0.5982378260232508, "Avg value loss": 0.2806009904597886, "Avg policy loss": 0.31763683317694813, "Total num played games": 13771, "Total num trained steps": 27008, "Timestamp in ms": 1699721631611, "logtype": "training_step"}
{"Total num played games": 13819, "Total num trained steps": 27077, "Timestamp in ms": 1699721764156, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.015625}
{"Avg objective": 20.421875, "Games time in secs": 233.32939309813082, "Avg game time in secs": 1.995332992853946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.56, "agent_stopped_0": 0.58}, "Total num played games": 13824, "Total num trained steps": 27079, "Timestamp in ms": 1699721766306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9568760366337348, "Avg loss": 0.9402708415873349, "Avg value loss": 0.6150932569871657, "Avg policy loss": 0.3251775880344212, "Total num played games": 13867, "Total num trained steps": 27136, "Timestamp in ms": 1699721799703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9593244699964067, "Avg loss": 0.6216262970119715, "Avg value loss": 0.30748435971327126, "Avg policy loss": 0.3141419452149421, "Total num played games": 13915, "Total num trained steps": 27264, "Timestamp in ms": 1699721876401, "logtype": "training_step"}
{"Avg objective": 21.921875, "Games time in secs": 141.6546801403165, "Avg game time in secs": 1.7881419655750506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 13952, "Total num trained steps": 27324, "Timestamp in ms": 1699721907961, "logtype": "played_game"}
{"Ratio train steps to played games": 1.961543970209109, "Avg loss": 0.7862121472135186, "Avg value loss": 0.46243477414827794, "Avg policy loss": 0.323777373181656, "Total num played games": 13964, "Total num trained steps": 27392, "Timestamp in ms": 1699721956690, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9632588999072556, "Avg loss": 0.6904670314397663, "Avg value loss": 0.36585692618973553, "Avg policy loss": 0.32461010571569204, "Total num played games": 14017, "Total num trained steps": 27520, "Timestamp in ms": 1699722038773, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 193.6741359643638, "Avg game time in secs": 1.9471211118943756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.61, "agent_stopped_0": 0.51}, "Total num played games": 14080, "Total num trained steps": 27623, "Timestamp in ms": 1699722101635, "logtype": "played_game"}
{"Ratio train steps to played games": 1.958835199093099, "Avg loss": 0.9178541842848063, "Avg value loss": 0.5988664118340239, "Avg policy loss": 0.31898776651360095, "Total num played games": 14114, "Total num trained steps": 27648, "Timestamp in ms": 1699722115971, "logtype": "training_step"}
{"Total num played games": 14114, "Total num trained steps": 27677, "Timestamp in ms": 1699722168796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.046875}
{"Ratio train steps to played games": 1.9612342889422398, "Avg loss": 0.7646277882158756, "Avg value loss": 0.4242892520269379, "Avg policy loss": 0.3403385381679982, "Total num played games": 14162, "Total num trained steps": 27776, "Timestamp in ms": 1699722226472, "logtype": "training_step"}
{"Avg objective": 22.625, "Games time in secs": 147.63039320521057, "Avg game time in secs": 2.1504948969668476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.73}, "Total num played games": 14208, "Total num trained steps": 27821, "Timestamp in ms": 1699722249266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9634789951446063, "Avg loss": 0.633251897059381, "Avg value loss": 0.30577214097138494, "Avg policy loss": 0.32747975131496787, "Total num played games": 14211, "Total num trained steps": 27904, "Timestamp in ms": 1699722295245, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9582925806902334, "Avg loss": 0.9188152942806482, "Avg value loss": 0.6004878971725702, "Avg policy loss": 0.3183273972244933, "Total num played games": 14314, "Total num trained steps": 28032, "Timestamp in ms": 1699722382444, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 189.55260846205056, "Avg game time in secs": 1.9697429244115483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.49, "agent_stopped_0": 0.6}, "Total num played games": 14336, "Total num trained steps": 28119, "Timestamp in ms": 1699722438852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9604566972988025, "Avg loss": 0.7311512618325651, "Avg value loss": 0.41827627981547266, "Avg policy loss": 0.3128749786410481, "Total num played games": 14364, "Total num trained steps": 28160, "Timestamp in ms": 1699722465796, "logtype": "training_step"}
{"Total num played games": 14413, "Total num trained steps": 28279, "Timestamp in ms": 1699722585327, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.40625}
{"Ratio train steps to played games": 1.9570361145703612, "Avg loss": 0.779410780640319, "Avg value loss": 0.47305427526589483, "Avg policy loss": 0.3063565056072548, "Total num played games": 14454, "Total num trained steps": 28288, "Timestamp in ms": 1699722590569, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 234.97780610248446, "Avg game time in secs": 2.427855322966934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.74}, "Total num played games": 14464, "Total num trained steps": 28411, "Timestamp in ms": 1699722673830, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9597241379310344, "Avg loss": 0.7484844147693366, "Avg value loss": 0.43217646749690175, "Avg policy loss": 0.31630794203374535, "Total num played games": 14500, "Total num trained steps": 28416, "Timestamp in ms": 1699722676035, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9605055292259084, "Avg loss": 0.7047589456196874, "Avg value loss": 0.40292964765103534, "Avg policy loss": 0.3018293009372428, "Total num played games": 14559, "Total num trained steps": 28544, "Timestamp in ms": 1699722753240, "logtype": "training_step"}
{"Avg objective": 20.765625, "Games time in secs": 120.07397237978876, "Avg game time in secs": 1.6008451088855509, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.39}, "Total num played games": 14592, "Total num trained steps": 28609, "Timestamp in ms": 1699722793905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9627601314348302, "Avg loss": 0.7135444995947182, "Avg value loss": 0.4130108456593007, "Avg policy loss": 0.30053364753257483, "Total num played games": 14608, "Total num trained steps": 28672, "Timestamp in ms": 1699722831233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964997270742358, "Avg loss": 0.6646292521618307, "Avg value loss": 0.3616636077640578, "Avg policy loss": 0.3029656419530511, "Total num played games": 14656, "Total num trained steps": 28800, "Timestamp in ms": 1699722913786, "logtype": "training_step"}
{"Total num played games": 14705, "Total num trained steps": 28880, "Timestamp in ms": 1699722997959, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.43359375}
{"Avg objective": 20.875, "Games time in secs": 206.50006782077253, "Avg game time in secs": 1.880660646551405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.53}, "Total num played games": 14720, "Total num trained steps": 28883, "Timestamp in ms": 1699723000406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.960821527824849, "Avg loss": 0.7605580554809421, "Avg value loss": 0.4575264436425641, "Avg policy loss": 0.30303161044139415, "Total num played games": 14753, "Total num trained steps": 28928, "Timestamp in ms": 1699723028066, "logtype": "training_step"}
{"Ratio train steps to played games": 1.962777815307708, "Avg loss": 0.8005811180919409, "Avg value loss": 0.5040002256282605, "Avg policy loss": 0.2965808982262388, "Total num played games": 14803, "Total num trained steps": 29056, "Timestamp in ms": 1699723110770, "logtype": "training_step"}
{"Avg objective": 20.9453125, "Games time in secs": 137.7674044854939, "Avg game time in secs": 2.07731540282839, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.72}, "Total num played games": 14848, "Total num trained steps": 29103, "Timestamp in ms": 1699723138174, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9649205494209534, "Avg loss": 0.6983528032433242, "Avg value loss": 0.3959702915744856, "Avg policy loss": 0.30238251050468534, "Total num played games": 14852, "Total num trained steps": 29184, "Timestamp in ms": 1699723185468, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9607331594086561, "Avg loss": 0.745343831833452, "Avg value loss": 0.43462307419395074, "Avg policy loss": 0.31072075944393873, "Total num played games": 14949, "Total num trained steps": 29312, "Timestamp in ms": 1699723258749, "logtype": "training_step"}
{"Avg objective": 20.9921875, "Games time in secs": 171.4026807807386, "Avg game time in secs": 1.6887637288309634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 14976, "Total num trained steps": 29390, "Timestamp in ms": 1699723309577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9628617148953194, "Avg loss": 0.7625535945408046, "Avg value loss": 0.45470667898189276, "Avg policy loss": 0.3078469152096659, "Total num played games": 14998, "Total num trained steps": 29440, "Timestamp in ms": 1699723342555, "logtype": "training_step"}
{"Total num played games": 14998, "Total num trained steps": 29481, "Timestamp in ms": 1699723391526, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.703125}
{"Ratio train steps to played games": 1.9651070051841022, "Avg loss": 0.6024799284059554, "Avg value loss": 0.30762623058399186, "Avg policy loss": 0.2948536945041269, "Total num played games": 15046, "Total num trained steps": 29568, "Timestamp in ms": 1699723447996, "logtype": "training_step"}
{"Avg objective": 21.640625, "Games time in secs": 209.99741578288376, "Avg game time in secs": 2.152663712608046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 15104, "Total num trained steps": 29680, "Timestamp in ms": 1699723519575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9609720663012613, "Avg loss": 0.5716703739017248, "Avg value loss": 0.28432214102940634, "Avg policy loss": 0.2873482289724052, "Total num played games": 15143, "Total num trained steps": 29696, "Timestamp in ms": 1699723528356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9630726698262244, "Avg loss": 0.6311490859370679, "Avg value loss": 0.33799646666739136, "Avg policy loss": 0.29315262008458376, "Total num played games": 15192, "Total num trained steps": 29824, "Timestamp in ms": 1699723598593, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 110.74586152471602, "Avg game time in secs": 1.7361785587418126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 15232, "Total num trained steps": 29877, "Timestamp in ms": 1699723630321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9651597664195264, "Avg loss": 0.6518508815206587, "Avg value loss": 0.35885790700558573, "Avg policy loss": 0.29299297532998025, "Total num played games": 15241, "Total num trained steps": 29952, "Timestamp in ms": 1699723675878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9610770635024124, "Avg loss": 0.7569630923680961, "Avg value loss": 0.4637702477048151, "Avg policy loss": 0.2931928461184725, "Total num played games": 15338, "Total num trained steps": 30080, "Timestamp in ms": 1699723755424, "logtype": "training_step"}
{"Total num played games": 15338, "Total num trained steps": 30081, "Timestamp in ms": 1699723813408, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.05859375}
{"Avg objective": 22.2578125, "Games time in secs": 185.70063445530832, "Avg game time in secs": 1.6989945298846578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 15360, "Total num trained steps": 30083, "Timestamp in ms": 1699723816021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9632783049525542, "Avg loss": 0.7451214075554162, "Avg value loss": 0.4455852362443693, "Avg policy loss": 0.2995361692737788, "Total num played games": 15386, "Total num trained steps": 30208, "Timestamp in ms": 1699723888736, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9655306466243359, "Avg loss": 0.5603136152494699, "Avg value loss": 0.2674914105446078, "Avg policy loss": 0.2928222039481625, "Total num played games": 15434, "Total num trained steps": 30336, "Timestamp in ms": 1699723971373, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 229.0266900882125, "Avg game time in secs": 1.870825543461251, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 15488, "Total num trained steps": 30457, "Timestamp in ms": 1699724045048, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9614963621144808, "Avg loss": 0.7312831566669047, "Avg value loss": 0.43002211215207353, "Avg policy loss": 0.30126104468945414, "Total num played games": 15531, "Total num trained steps": 30464, "Timestamp in ms": 1699724047885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.963416982221937, "Avg loss": 0.8688673020806164, "Avg value loss": 0.556222113838885, "Avg policy loss": 0.31264519749674946, "Total num played games": 15581, "Total num trained steps": 30592, "Timestamp in ms": 1699724131954, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 123.78033188916743, "Avg game time in secs": 1.6370356452680426, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 15616, "Total num trained steps": 30652, "Timestamp in ms": 1699724168829, "logtype": "played_game"}
{"Total num played games": 15629, "Total num trained steps": 30684, "Timestamp in ms": 1699724245337, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.9296875}
{"Ratio train steps to played games": 1.9595585890157556, "Avg loss": 0.9156975303776562, "Avg value loss": 0.6116027248208411, "Avg policy loss": 0.30409481923561543, "Total num played games": 15677, "Total num trained steps": 30720, "Timestamp in ms": 1699724269880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.963651410019734, "Avg loss": 0.54384680185467, "Avg value loss": 0.24787493114126846, "Avg policy loss": 0.29597186960745603, "Total num played games": 15709, "Total num trained steps": 30848, "Timestamp in ms": 1699724350813, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 239.52782274782658, "Avg game time in secs": 1.6784569614537759, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 15744, "Total num trained steps": 30942, "Timestamp in ms": 1699724408357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9636744009128946, "Avg loss": 0.8253023633733392, "Avg value loss": 0.5199087541550398, "Avg policy loss": 0.3053936124779284, "Total num played games": 15774, "Total num trained steps": 30976, "Timestamp in ms": 1699724425061, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9656828667130126, "Avg loss": 0.6723622863646597, "Avg value loss": 0.3629742132034153, "Avg policy loss": 0.3093880679225549, "Total num played games": 15823, "Total num trained steps": 31104, "Timestamp in ms": 1699724493579, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 109.32017838209867, "Avg game time in secs": 1.8036543316557072, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.62}, "Total num played games": 15872, "Total num trained steps": 31141, "Timestamp in ms": 1699724517677, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967741935483871, "Avg loss": 0.5674822847358882, "Avg value loss": 0.25423188757849857, "Avg policy loss": 0.3132504011737183, "Total num played games": 15872, "Total num trained steps": 31232, "Timestamp in ms": 1699724575781, "logtype": "training_step"}
{"Total num played games": 15923, "Total num trained steps": 31285, "Timestamp in ms": 1699724638937, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.21484375}
{"Ratio train steps to played games": 1.9634963371110137, "Avg loss": 0.9068188625387847, "Avg value loss": 0.577800979022868, "Avg policy loss": 0.329017884330824, "Total num played games": 15971, "Total num trained steps": 31360, "Timestamp in ms": 1699724689370, "logtype": "training_step"}
{"Avg objective": 22.453125, "Games time in secs": 217.81952619366348, "Avg game time in secs": 1.4687758446962107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.47}, "Total num played games": 16000, "Total num trained steps": 31434, "Timestamp in ms": 1699724735497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9652353014604917, "Avg loss": 0.613151230616495, "Avg value loss": 0.29359725496033207, "Avg policy loss": 0.319553975132294, "Total num played games": 16022, "Total num trained steps": 31488, "Timestamp in ms": 1699724768755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9672080144359405, "Avg loss": 0.6289203090127558, "Avg value loss": 0.3212902822997421, "Avg policy loss": 0.30763002927415073, "Total num played games": 16071, "Total num trained steps": 31616, "Timestamp in ms": 1699724844956, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 182.00159435905516, "Avg game time in secs": 1.9337263329070993, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.72}, "Total num played games": 16128, "Total num trained steps": 31730, "Timestamp in ms": 1699724917498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9635059070946992, "Avg loss": 0.6373771652579308, "Avg value loss": 0.32902945310343057, "Avg policy loss": 0.308347710641101, "Total num played games": 16167, "Total num trained steps": 31744, "Timestamp in ms": 1699724924357, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9651026573771502, "Avg loss": 0.6754846361000091, "Avg value loss": 0.36419487721286714, "Avg policy loss": 0.3112897598184645, "Total num played games": 16219, "Total num trained steps": 31872, "Timestamp in ms": 1699724995830, "logtype": "training_step"}
{"Total num played games": 16219, "Total num trained steps": 31886, "Timestamp in ms": 1699725046487, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.70703125}
{"Avg objective": 22.171875, "Games time in secs": 131.25914166122675, "Avg game time in secs": 1.703604052963783, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 16256, "Total num trained steps": 31891, "Timestamp in ms": 1699725048758, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967172803835987, "Avg loss": 0.7917969895061105, "Avg value loss": 0.46915092412382364, "Avg policy loss": 0.3226460627047345, "Total num played games": 16267, "Total num trained steps": 32000, "Timestamp in ms": 1699725119457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9631530705774518, "Avg loss": 0.6438317995052785, "Avg value loss": 0.3387429212452844, "Avg policy loss": 0.30508887383621186, "Total num played games": 16365, "Total num trained steps": 32128, "Timestamp in ms": 1699725202069, "logtype": "training_step"}
{"Avg objective": 21.96875, "Games time in secs": 208.13550024479628, "Avg game time in secs": 1.5293330682325177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 16384, "Total num trained steps": 32222, "Timestamp in ms": 1699725256893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9652714311825992, "Avg loss": 0.7080854792147875, "Avg value loss": 0.3852102253586054, "Avg policy loss": 0.3228752489667386, "Total num played games": 16413, "Total num trained steps": 32256, "Timestamp in ms": 1699725277058, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967255938278355, "Avg loss": 0.8738879153970629, "Avg value loss": 0.5441201058565639, "Avg policy loss": 0.3297678027302027, "Total num played games": 16461, "Total num trained steps": 32384, "Timestamp in ms": 1699725357517, "logtype": "training_step"}
{"Total num played games": 16511, "Total num trained steps": 32486, "Timestamp in ms": 1699725456812, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.26953125}
{"Avg objective": 21.984375, "Games time in secs": 200.944290375337, "Avg game time in secs": 1.9542881748348009, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.73, "agent_stopped_0": 0.43}, "Total num played games": 16512, "Total num trained steps": 32486, "Timestamp in ms": 1699725457838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9634035871731386, "Avg loss": 0.9268527871463448, "Avg value loss": 0.5827329704770818, "Avg policy loss": 0.34411981992889196, "Total num played games": 16559, "Total num trained steps": 32512, "Timestamp in ms": 1699725475721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9653179190751444, "Avg loss": 0.7947663434315473, "Avg value loss": 0.4533737951423973, "Avg policy loss": 0.3413925433997065, "Total num played games": 16608, "Total num trained steps": 32640, "Timestamp in ms": 1699725558925, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 147.30381733737886, "Avg game time in secs": 1.542488616585615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 16640, "Total num trained steps": 32708, "Timestamp in ms": 1699725605142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9672790585975024, "Avg loss": 0.7343505476601422, "Avg value loss": 0.4004287090501748, "Avg policy loss": 0.333921839017421, "Total num played games": 16656, "Total num trained steps": 32768, "Timestamp in ms": 1699725643266, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9692887931034482, "Avg loss": 0.6617598372977227, "Avg value loss": 0.3342826789012179, "Avg policy loss": 0.3274771578144282, "Total num played games": 16704, "Total num trained steps": 32896, "Timestamp in ms": 1699725721775, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 175.9961441922933, "Avg game time in secs": 1.7183216619159793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 16768, "Total num trained steps": 32998, "Timestamp in ms": 1699725781138, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96548029996429, "Avg loss": 0.9162278198637068, "Avg value loss": 0.5798369021504186, "Avg policy loss": 0.3363909169565886, "Total num played games": 16802, "Total num trained steps": 33024, "Timestamp in ms": 1699725797257, "logtype": "training_step"}
{"Total num played games": 16802, "Total num trained steps": 33088, "Timestamp in ms": 1699725882006, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.51953125}
{"Ratio train steps to played games": 1.9674183976261128, "Avg loss": 0.8210508904885501, "Avg value loss": 0.4690784412669018, "Avg policy loss": 0.35197245166637003, "Total num played games": 16850, "Total num trained steps": 33152, "Timestamp in ms": 1699725926519, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 171.82260071113706, "Avg game time in secs": 1.8455003127310192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.7}, "Total num played games": 16896, "Total num trained steps": 33193, "Timestamp in ms": 1699725952961, "logtype": "played_game"}
{"Ratio train steps to played games": 1.969288123557607, "Avg loss": 0.7659459314309061, "Avg value loss": 0.42455314460676163, "Avg policy loss": 0.34139277995564044, "Total num played games": 16899, "Total num trained steps": 33280, "Timestamp in ms": 1699726004061, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9657546337157987, "Avg loss": 0.9570745779201388, "Avg value loss": 0.6167502790922299, "Avg policy loss": 0.3403242976637557, "Total num played games": 16995, "Total num trained steps": 33408, "Timestamp in ms": 1699726086717, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 175.6302437093109, "Avg game time in secs": 1.41660254218732, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 17024, "Total num trained steps": 33481, "Timestamp in ms": 1699726128591, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9668621700879765, "Avg loss": 0.8408262839075178, "Avg value loss": 0.506578310392797, "Avg policy loss": 0.33424797584302723, "Total num played games": 17050, "Total num trained steps": 33536, "Timestamp in ms": 1699726163403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968711620562606, "Avg loss": 0.7067276567686349, "Avg value loss": 0.37651679769624025, "Avg policy loss": 0.33021085464861244, "Total num played games": 17099, "Total num trained steps": 33664, "Timestamp in ms": 1699726237289, "logtype": "training_step"}
{"Total num played games": 17146, "Total num trained steps": 33687, "Timestamp in ms": 1699726273503, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.16796875}
{"Avg objective": 20.7421875, "Games time in secs": 146.40519674122334, "Avg game time in secs": 2.0416635911387857, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.75, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.73, "agent_stopped_0": 0.38}, "Total num played games": 17152, "Total num trained steps": 33690, "Timestamp in ms": 1699726274996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.965336745376294, "Avg loss": 0.9140217462554574, "Avg value loss": 0.5704870633780956, "Avg policy loss": 0.3435346798505634, "Total num played games": 17194, "Total num trained steps": 33792, "Timestamp in ms": 1699726338793, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9669469411423601, "Avg loss": 0.6577677531167865, "Avg value loss": 0.3234009310253896, "Avg policy loss": 0.33436682482715696, "Total num played games": 17245, "Total num trained steps": 33920, "Timestamp in ms": 1699726419307, "logtype": "training_step"}
{"Avg objective": 20.4765625, "Games time in secs": 185.77738878130913, "Avg game time in secs": 1.6333028488152195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 17280, "Total num trained steps": 33980, "Timestamp in ms": 1699726460774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688313190308218, "Avg loss": 0.6439000905957073, "Avg value loss": 0.31831383239477873, "Avg policy loss": 0.32558625377714634, "Total num played games": 17293, "Total num trained steps": 34048, "Timestamp in ms": 1699726501848, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9660587930736926, "Avg loss": 0.5822530633304268, "Avg value loss": 0.2521409025066532, "Avg policy loss": 0.33011216344311833, "Total num played games": 17382, "Total num trained steps": 34176, "Timestamp in ms": 1699726577618, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 175.40247625857592, "Avg game time in secs": 1.5408596110646613, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 17408, "Total num trained steps": 34270, "Timestamp in ms": 1699726636177, "logtype": "played_game"}
{"Total num played games": 17439, "Total num trained steps": 34288, "Timestamp in ms": 1699726707160, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.9296875}
{"Ratio train steps to played games": 1.9617408212284113, "Avg loss": 0.8012349084019661, "Avg value loss": 0.49389258987503126, "Avg policy loss": 0.3073423190508038, "Total num played games": 17486, "Total num trained steps": 34304, "Timestamp in ms": 1699726716948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9689483616400756, "Avg loss": 0.5978515215683728, "Avg value loss": 0.27810587943531573, "Avg policy loss": 0.3197456377092749, "Total num played games": 17487, "Total num trained steps": 34432, "Timestamp in ms": 1699726798953, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 185.7638550195843, "Avg game time in secs": 1.5730755116965156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 17536, "Total num trained steps": 34468, "Timestamp in ms": 1699726821941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970241149307337, "Avg loss": 0.7259418894536793, "Avg value loss": 0.4274806033936329, "Avg policy loss": 0.2984612782020122, "Total num played games": 17541, "Total num trained steps": 34560, "Timestamp in ms": 1699726879137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966606191178138, "Avg loss": 0.8341434842441231, "Avg value loss": 0.5340265260310844, "Avg policy loss": 0.3001169618219137, "Total num played games": 17638, "Total num trained steps": 34688, "Timestamp in ms": 1699726959632, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 190.13536311499774, "Avg game time in secs": 1.5814923463622108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 17664, "Total num trained steps": 34767, "Timestamp in ms": 1699727012076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9685061630668326, "Avg loss": 0.6592957987450063, "Avg value loss": 0.36451914138160646, "Avg policy loss": 0.29477665305603296, "Total num played games": 17686, "Total num trained steps": 34816, "Timestamp in ms": 1699727044884, "logtype": "training_step"}
{"Total num played games": 17734, "Total num trained steps": 34888, "Timestamp in ms": 1699727126091, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.58203125}
{"Ratio train steps to played games": 1.965133280845799, "Avg loss": 0.9118340429849923, "Avg value loss": 0.6061291539808735, "Avg policy loss": 0.3057048803893849, "Total num played games": 17782, "Total num trained steps": 34944, "Timestamp in ms": 1699727161179, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 215.2249759528786, "Avg game time in secs": 1.721486013091635, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.6, "agent_stopped_0": 0.51}, "Total num played games": 17792, "Total num trained steps": 35053, "Timestamp in ms": 1699727227301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9669657879977567, "Avg loss": 0.6036370529327542, "Avg value loss": 0.3152667636750266, "Avg policy loss": 0.2883702887920663, "Total num played games": 17830, "Total num trained steps": 35072, "Timestamp in ms": 1699727238663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968790200794228, "Avg loss": 0.7098747442942113, "Avg value loss": 0.4172144635231234, "Avg policy loss": 0.29266027570702136, "Total num played games": 17879, "Total num trained steps": 35200, "Timestamp in ms": 1699727316239, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 122.52500531636178, "Avg game time in secs": 1.676107206279994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.61}, "Total num played games": 17920, "Total num trained steps": 35251, "Timestamp in ms": 1699727349826, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9706030010598539, "Avg loss": 0.643740935716778, "Avg value loss": 0.3531321306945756, "Avg policy loss": 0.2906088068848476, "Total num played games": 17927, "Total num trained steps": 35328, "Timestamp in ms": 1699727399866, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9670457697642163, "Avg loss": 0.838628526777029, "Avg value loss": 0.5464427566039376, "Avg policy loss": 0.2921857775654644, "Total num played games": 18025, "Total num trained steps": 35456, "Timestamp in ms": 1699727475363, "logtype": "training_step"}
{"Total num played games": 18025, "Total num trained steps": 35489, "Timestamp in ms": 1699727519538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3046875}
{"Avg objective": 21.53125, "Games time in secs": 172.11666082777083, "Avg game time in secs": 1.6916807802044787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 18048, "Total num trained steps": 35492, "Timestamp in ms": 1699727521943, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688485586233608, "Avg loss": 0.7416293800342828, "Avg value loss": 0.43625618156511337, "Avg policy loss": 0.3053731989348307, "Total num played games": 18073, "Total num trained steps": 35584, "Timestamp in ms": 1699727582348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705882352941178, "Avg loss": 0.6052406746894121, "Avg value loss": 0.30890331126283854, "Avg policy loss": 0.2963373642414808, "Total num played games": 18122, "Total num trained steps": 35712, "Timestamp in ms": 1699727655933, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 202.1714678965509, "Avg game time in secs": 1.5119159905589186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 18176, "Total num trained steps": 35832, "Timestamp in ms": 1699727724115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967122235029365, "Avg loss": 0.6265443139709532, "Avg value loss": 0.3337655902141705, "Avg policy loss": 0.2927787305088714, "Total num played games": 18219, "Total num trained steps": 35840, "Timestamp in ms": 1699727728921, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9688526384935405, "Avg loss": 0.6859108391217887, "Avg value loss": 0.40446446725400165, "Avg policy loss": 0.28144636971410364, "Total num played games": 18268, "Total num trained steps": 35968, "Timestamp in ms": 1699727804150, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 117.64453075453639, "Avg game time in secs": 1.528153306528111, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 18304, "Total num trained steps": 36028, "Timestamp in ms": 1699727841759, "logtype": "played_game"}
{"Total num played games": 18317, "Total num trained steps": 36089, "Timestamp in ms": 1699727911513, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3359375}
{"Ratio train steps to played games": 1.9656918804116974, "Avg loss": 0.7657227013260126, "Avg value loss": 0.4767378402175382, "Avg policy loss": 0.2889848636696115, "Total num played games": 18363, "Total num trained steps": 36096, "Timestamp in ms": 1699727915700, "logtype": "training_step"}
{"Ratio train steps to played games": 1.967358244623072, "Avg loss": 0.6624010305386037, "Avg value loss": 0.372911081998609, "Avg policy loss": 0.28948994842357934, "Total num played games": 18412, "Total num trained steps": 36224, "Timestamp in ms": 1699727996618, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 215.38320279866457, "Avg game time in secs": 1.5726688695867779, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.59, "agent_stopped_0": 0.52}, "Total num played games": 18432, "Total num trained steps": 36317, "Timestamp in ms": 1699728057143, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9688566321832854, "Avg loss": 0.7755355990957469, "Avg value loss": 0.4818534618243575, "Avg policy loss": 0.2936821397161111, "Total num played games": 18463, "Total num trained steps": 36352, "Timestamp in ms": 1699728080191, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9705596369922214, "Avg loss": 0.7577229656744748, "Avg value loss": 0.4669823015574366, "Avg policy loss": 0.290740660042502, "Total num played games": 18512, "Total num trained steps": 36480, "Timestamp in ms": 1699728163754, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 135.40833728387952, "Avg game time in secs": 1.589797999811708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 18560, "Total num trained steps": 36524, "Timestamp in ms": 1699728192551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9723599137931034, "Avg loss": 0.6452250292059034, "Avg value loss": 0.3590661444468424, "Avg policy loss": 0.28615888010244817, "Total num played games": 18560, "Total num trained steps": 36608, "Timestamp in ms": 1699728251498, "logtype": "training_step"}
{"Total num played games": 18609, "Total num trained steps": 36691, "Timestamp in ms": 1699728327333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.69140625}
{"Ratio train steps to played games": 1.96896607171571, "Avg loss": 1.0188067522831261, "Avg value loss": 0.7210865330416709, "Avg policy loss": 0.2977202153997496, "Total num played games": 18657, "Total num trained steps": 36736, "Timestamp in ms": 1699728355599, "logtype": "training_step"}
{"Avg objective": 22.9609375, "Games time in secs": 205.25258489511907, "Avg game time in secs": 1.3758084522123681, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.46}, "Total num played games": 18688, "Total num trained steps": 36804, "Timestamp in ms": 1699728397804, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708099438652766, "Avg loss": 0.7720832671038806, "Avg value loss": 0.46884110418614, "Avg policy loss": 0.3032421497628093, "Total num played games": 18705, "Total num trained steps": 36864, "Timestamp in ms": 1699728436484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9715915147638845, "Avg loss": 0.727170982863754, "Avg value loss": 0.43007147032767534, "Avg policy loss": 0.2970995205687359, "Total num played games": 18762, "Total num trained steps": 36992, "Timestamp in ms": 1699728514152, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 186.52112386003137, "Avg game time in secs": 1.7785233208414866, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.7, "agent_stopped_0": 0.46}, "Total num played games": 18816, "Total num trained steps": 37110, "Timestamp in ms": 1699728584325, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9682379765629143, "Avg loss": 0.7800605231896043, "Avg value loss": 0.4759577213553712, "Avg policy loss": 0.30410279822535813, "Total num played games": 18859, "Total num trained steps": 37120, "Timestamp in ms": 1699728590483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9699069177067907, "Avg loss": 0.8576552923768759, "Avg value loss": 0.5437160822912119, "Avg policy loss": 0.31393920723348856, "Total num played games": 18908, "Total num trained steps": 37248, "Timestamp in ms": 1699728672997, "logtype": "training_step"}
{"Total num played games": 18908, "Total num trained steps": 37293, "Timestamp in ms": 1699728755850, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.30859375}
{"Avg objective": 22.359375, "Games time in secs": 174.4806452319026, "Avg game time in secs": 1.4169906575552886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.52}, "Total num played games": 18944, "Total num trained steps": 37297, "Timestamp in ms": 1699728758806, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9716712386579447, "Avg loss": 0.721141537418589, "Avg value loss": 0.4014062177739106, "Avg policy loss": 0.3197353152791038, "Total num played games": 18956, "Total num trained steps": 37376, "Timestamp in ms": 1699728807254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9686614173228347, "Avg loss": 0.6898794018197805, "Avg value loss": 0.3801100652781315, "Avg policy loss": 0.3097693311283365, "Total num played games": 19050, "Total num trained steps": 37504, "Timestamp in ms": 1699728881861, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 184.54387805610895, "Avg game time in secs": 1.5921686507354025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 19072, "Total num trained steps": 37602, "Timestamp in ms": 1699728943356, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694876223373632, "Avg loss": 0.7704219503793865, "Avg value loss": 0.44481783907394856, "Avg policy loss": 0.3256041124695912, "Total num played games": 19107, "Total num trained steps": 37632, "Timestamp in ms": 1699728964574, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9711317602839842, "Avg loss": 0.6965497161727399, "Avg value loss": 0.3836939961183816, "Avg policy loss": 0.312855725758709, "Total num played games": 19156, "Total num trained steps": 37760, "Timestamp in ms": 1699729049973, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 135.037467809394, "Avg game time in secs": 1.4219944093056256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 19200, "Total num trained steps": 37806, "Timestamp in ms": 1699729078390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727675084613383, "Avg loss": 0.6354960047174245, "Avg value loss": 0.32541782793123275, "Avg policy loss": 0.31007817306090146, "Total num played games": 19205, "Total num trained steps": 37888, "Timestamp in ms": 1699729126147, "logtype": "training_step"}
{"Total num played games": 19205, "Total num trained steps": 37894, "Timestamp in ms": 1699729166084, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.57421875}
{"Ratio train steps to played games": 1.9691789691789692, "Avg loss": 0.766843200661242, "Avg value loss": 0.44098206114722416, "Avg policy loss": 0.32586114027071744, "Total num played games": 19305, "Total num trained steps": 38016, "Timestamp in ms": 1699729246045, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 227.25421022996306, "Avg game time in secs": 1.515144446020713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 19328, "Total num trained steps": 38100, "Timestamp in ms": 1699729305644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970908903012453, "Avg loss": 0.6820091737899929, "Avg value loss": 0.35185971175087616, "Avg policy loss": 0.33014945941977203, "Total num played games": 19353, "Total num trained steps": 38144, "Timestamp in ms": 1699729338854, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9725286052984228, "Avg loss": 0.6553392095956951, "Avg value loss": 0.3344244674080983, "Avg policy loss": 0.3209147515008226, "Total num played games": 19402, "Total num trained steps": 38272, "Timestamp in ms": 1699729422429, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 195.3374424315989, "Avg game time in secs": 1.5751547107065562, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 19456, "Total num trained steps": 38388, "Timestamp in ms": 1699729500982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9693814750230794, "Avg loss": 0.7836211146786809, "Avg value loss": 0.4628871871973388, "Avg policy loss": 0.3207339266082272, "Total num played games": 19498, "Total num trained steps": 38400, "Timestamp in ms": 1699729507082, "logtype": "training_step"}
{"Total num played games": 19546, "Total num trained steps": 38494, "Timestamp in ms": 1699729595786, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.14453125}
{"Avg objective": 21.0, "Games time in secs": 97.84241743199527, "Avg game time in secs": 1.3043410827958724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.44}, "Total num played games": 19584, "Total num trained steps": 38499, "Timestamp in ms": 1699729598824, "logtype": "played_game"}
{"Ratio train steps to played games": 1.966265183219353, "Avg loss": 0.7029225013684481, "Avg value loss": 0.39490235364064574, "Avg policy loss": 0.3080201457487419, "Total num played games": 19594, "Total num trained steps": 38528, "Timestamp in ms": 1699729618517, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972797795243442, "Avg loss": 0.48759575956501067, "Avg value loss": 0.18777574464911595, "Avg policy loss": 0.29982001229655, "Total num played games": 19594, "Total num trained steps": 38656, "Timestamp in ms": 1699729696789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.969379982734982, "Avg loss": 0.5985421801451594, "Avg value loss": 0.3005616175942123, "Avg policy loss": 0.2979805626673624, "Total num played games": 19693, "Total num trained steps": 38784, "Timestamp in ms": 1699729767508, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 232.63135929778218, "Avg game time in secs": 1.4713706787879346, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.57, "agent_stopped_0": 0.52}, "Total num played games": 19712, "Total num trained steps": 38876, "Timestamp in ms": 1699729831460, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710262384763448, "Avg loss": 0.8521371956449002, "Avg value loss": 0.5346064752084203, "Avg policy loss": 0.31753072782885283, "Total num played games": 19742, "Total num trained steps": 38912, "Timestamp in ms": 1699729853557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726629610914603, "Avg loss": 0.5652901637367904, "Avg value loss": 0.2594244576757774, "Avg policy loss": 0.3058657005894929, "Total num played games": 19790, "Total num trained steps": 39040, "Timestamp in ms": 1699729936991, "logtype": "training_step"}
{"Total num played games": 19839, "Total num trained steps": 39095, "Timestamp in ms": 1699729989507, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6171875}
{"Avg objective": 20.65625, "Games time in secs": 159.03586269170046, "Avg game time in secs": 1.608485372751602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.63}, "Total num played games": 19840, "Total num trained steps": 39096, "Timestamp in ms": 1699729990496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694775481470308, "Avg loss": 0.8595384692307562, "Avg value loss": 0.5470905213733204, "Avg policy loss": 0.3124479374382645, "Total num played games": 19887, "Total num trained steps": 39168, "Timestamp in ms": 1699730035165, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9711562578379733, "Avg loss": 0.6734003538731486, "Avg value loss": 0.36290440533775836, "Avg policy loss": 0.31049594876822084, "Total num played games": 19935, "Total num trained steps": 39296, "Timestamp in ms": 1699730115381, "logtype": "training_step"}
{"Avg objective": 22.90625, "Games time in secs": 164.59730808623135, "Avg game time in secs": 1.3629773492866661, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 19968, "Total num trained steps": 39361, "Timestamp in ms": 1699730155094, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9724320808525542, "Avg loss": 0.7851714540738612, "Avg value loss": 0.47335123288212344, "Avg policy loss": 0.31182022066786885, "Total num played games": 19987, "Total num trained steps": 39424, "Timestamp in ms": 1699730195978, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9741452458198154, "Avg loss": 0.7464610892347991, "Avg value loss": 0.43460510578006506, "Avg policy loss": 0.31185598380398005, "Total num played games": 20035, "Total num trained steps": 39552, "Timestamp in ms": 1699730273310, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 184.61573222838342, "Avg game time in secs": 1.4169845896976767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.58}, "Total num played games": 20096, "Total num trained steps": 39656, "Timestamp in ms": 1699730339709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710396900303015, "Avg loss": 0.8782115888316184, "Avg value loss": 0.5652171669062227, "Avg policy loss": 0.3129944121465087, "Total num played games": 20131, "Total num trained steps": 39680, "Timestamp in ms": 1699730354301, "logtype": "training_step"}
{"Total num played games": 20131, "Total num trained steps": 39698, "Timestamp in ms": 1699730387866, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.59375}
{"Ratio train steps to played games": 1.9727439417215917, "Avg loss": 0.75785195780918, "Avg value loss": 0.4431372302933596, "Avg policy loss": 0.31471472792327404, "Total num played games": 20179, "Total num trained steps": 39808, "Timestamp in ms": 1699730455036, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 140.54410398378968, "Avg game time in secs": 1.3625197152287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 20224, "Total num trained steps": 39851, "Timestamp in ms": 1699730480254, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741460279796332, "Avg loss": 0.651268775574863, "Avg value loss": 0.3423559991642833, "Avg policy loss": 0.30891277559567243, "Total num played games": 20229, "Total num trained steps": 39936, "Timestamp in ms": 1699730533589, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970974565848379, "Avg loss": 0.7068699784576893, "Avg value loss": 0.400058719154913, "Avg policy loss": 0.30681126087438315, "Total num played games": 20327, "Total num trained steps": 40064, "Timestamp in ms": 1699730614145, "logtype": "training_step"}
{"Avg objective": 20.53125, "Games time in secs": 184.38438230007887, "Avg game time in secs": 1.4011771964724176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.49, "agent_stopped_0": 0.58}, "Total num played games": 20352, "Total num trained steps": 40143, "Timestamp in ms": 1699730664638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726134969325153, "Avg loss": 0.7593351344112307, "Avg value loss": 0.4523664870066568, "Avg policy loss": 0.3069686504313722, "Total num played games": 20375, "Total num trained steps": 40192, "Timestamp in ms": 1699730693530, "logtype": "training_step"}
{"Total num played games": 20428, "Total num trained steps": 40301, "Timestamp in ms": 1699730780518, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.40625}
{"Ratio train steps to played games": 1.9690857589372925, "Avg loss": 0.680439249612391, "Avg value loss": 0.36890785314608365, "Avg policy loss": 0.3115313925081864, "Total num played games": 20476, "Total num trained steps": 40320, "Timestamp in ms": 1699730792848, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 202.2955527883023, "Avg game time in secs": 1.494251265830826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 20480, "Total num trained steps": 40442, "Timestamp in ms": 1699730866934, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970717209121029, "Avg loss": 0.5260423712898046, "Avg value loss": 0.21736664569471031, "Avg policy loss": 0.3086757225682959, "Total num played games": 20524, "Total num trained steps": 40448, "Timestamp in ms": 1699730870775, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9721493146689997, "Avg loss": 0.6127743744291365, "Avg value loss": 0.3058932919520885, "Avg policy loss": 0.3068810768891126, "Total num played games": 20574, "Total num trained steps": 40576, "Timestamp in ms": 1699730949408, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 120.91906670667231, "Avg game time in secs": 1.232182735344395, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 20608, "Total num trained steps": 40639, "Timestamp in ms": 1699730987853, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737186636279882, "Avg loss": 0.8266868838109076, "Avg value loss": 0.5316529954434372, "Avg policy loss": 0.2950338980881497, "Total num played games": 20623, "Total num trained steps": 40704, "Timestamp in ms": 1699731027347, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727979900468666, "Avg loss": 0.8136303811334074, "Avg value loss": 0.5040988713735715, "Avg policy loss": 0.30953150370623916, "Total num played games": 20693, "Total num trained steps": 40832, "Timestamp in ms": 1699731106817, "logtype": "training_step"}
{"Total num played games": 20725, "Total num trained steps": 40902, "Timestamp in ms": 1699731195015, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1953125}
{"Avg objective": 22.1640625, "Games time in secs": 208.91895626299083, "Avg game time in secs": 1.5255499289050931, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 20736, "Total num trained steps": 40904, "Timestamp in ms": 1699731196772, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9717903047224763, "Avg loss": 0.7611774026881903, "Avg value loss": 0.44603966549038887, "Avg policy loss": 0.3151377368485555, "Total num played games": 20773, "Total num trained steps": 40960, "Timestamp in ms": 1699731226596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9727757238200412, "Avg loss": 0.6468503347132355, "Avg value loss": 0.3375552866491489, "Avg policy loss": 0.3092950488207862, "Total num played games": 20827, "Total num trained steps": 41088, "Timestamp in ms": 1699731298521, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 135.60460906289518, "Avg game time in secs": 1.214345491694985, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 20864, "Total num trained steps": 41145, "Timestamp in ms": 1699731332377, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739930073279373, "Avg loss": 0.6375771609600633, "Avg value loss": 0.34020847169449553, "Avg policy loss": 0.2973686894401908, "Total num played games": 20879, "Total num trained steps": 41216, "Timestamp in ms": 1699731372680, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9753929953652827, "Avg loss": 0.6450030882842839, "Avg value loss": 0.3413551005651243, "Avg policy loss": 0.3036479871952906, "Total num played games": 20929, "Total num trained steps": 41344, "Timestamp in ms": 1699731453929, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 176.22065286710858, "Avg game time in secs": 1.21817280598043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.4}, "Total num played games": 20992, "Total num trained steps": 41441, "Timestamp in ms": 1699731508598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9723675449443545, "Avg loss": 0.7933647723402828, "Avg value loss": 0.49788535601692274, "Avg policy loss": 0.2954794215038419, "Total num played games": 21026, "Total num trained steps": 41472, "Timestamp in ms": 1699731529997, "logtype": "training_step"}
{"Total num played games": 21026, "Total num trained steps": 41502, "Timestamp in ms": 1699731583965, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.88671875}
{"Ratio train steps to played games": 1.9739489418240486, "Avg loss": 0.8746212995611131, "Avg value loss": 0.5648770331172273, "Avg policy loss": 0.309744261438027, "Total num played games": 21074, "Total num trained steps": 41600, "Timestamp in ms": 1699731644639, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 159.94467898644507, "Avg game time in secs": 1.2558331150357844, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.59}, "Total num played games": 21120, "Total num trained steps": 41642, "Timestamp in ms": 1699731668543, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755231512167408, "Avg loss": 0.5459997020661831, "Avg value loss": 0.24878205452114344, "Avg policy loss": 0.29721764591522515, "Total num played games": 21122, "Total num trained steps": 41728, "Timestamp in ms": 1699731719136, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9725246241575947, "Avg loss": 0.7028197955805808, "Avg value loss": 0.4042923908564262, "Avg policy loss": 0.29852739826310426, "Total num played games": 21219, "Total num trained steps": 41856, "Timestamp in ms": 1699731797391, "logtype": "training_step"}
{"Avg objective": 23.1015625, "Games time in secs": 173.22364335507154, "Avg game time in secs": 1.2505360501236282, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.49, "agent_stopped_0": 0.55}, "Total num played games": 21248, "Total num trained steps": 41928, "Timestamp in ms": 1699731841766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9740913151831476, "Avg loss": 0.7191769126802683, "Avg value loss": 0.4355320342583582, "Avg policy loss": 0.2836448821472004, "Total num played games": 21267, "Total num trained steps": 41984, "Timestamp in ms": 1699731873629, "logtype": "training_step"}
{"Total num played games": 21315, "Total num trained steps": 42103, "Timestamp in ms": 1699731983922, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.67578125}
{"Ratio train steps to played games": 1.9712119084398259, "Avg loss": 0.6966026513837278, "Avg value loss": 0.40060253359843045, "Avg policy loss": 0.2960001192986965, "Total num played games": 21363, "Total num trained steps": 42112, "Timestamp in ms": 1699731989579, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 209.1577333174646, "Avg game time in secs": 1.2007220879168017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 21376, "Total num trained steps": 42215, "Timestamp in ms": 1699732050924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9727710055578909, "Avg loss": 0.6534378528594971, "Avg value loss": 0.3666177444974892, "Avg policy loss": 0.2868201086530462, "Total num played games": 21411, "Total num trained steps": 42240, "Timestamp in ms": 1699732064341, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974323127825155, "Avg loss": 0.5772872259840369, "Avg value loss": 0.28978103742701933, "Avg policy loss": 0.28750618582125753, "Total num played games": 21459, "Total num trained steps": 42368, "Timestamp in ms": 1699732142653, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 116.81049379333854, "Avg game time in secs": 1.2312032292829826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.53}, "Total num played games": 21504, "Total num trained steps": 42409, "Timestamp in ms": 1699732167735, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757764552724568, "Avg loss": 0.5247030099853873, "Avg value loss": 0.24627017875900492, "Avg policy loss": 0.27843283489346504, "Total num played games": 21508, "Total num trained steps": 42496, "Timestamp in ms": 1699732222205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972785337406276, "Avg loss": 0.8844081677962095, "Avg value loss": 0.6080891857272945, "Avg policy loss": 0.2763189934194088, "Total num played games": 21606, "Total num trained steps": 42624, "Timestamp in ms": 1699732298777, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 180.23861523531377, "Avg game time in secs": 1.1702957774105016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.38, "agent_stopped_0": 0.65}, "Total num played games": 21632, "Total num trained steps": 42704, "Timestamp in ms": 1699732347973, "logtype": "played_game"}
{"Total num played games": 21656, "Total num trained steps": 42707, "Timestamp in ms": 1699732372565, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.578125}
{"Ratio train steps to played games": 1.96972908219683, "Avg loss": 0.9248095480725169, "Avg value loss": 0.6272409819066525, "Avg policy loss": 0.2975685668643564, "Total num played games": 21704, "Total num trained steps": 42752, "Timestamp in ms": 1699732402386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9756726870622927, "Avg loss": 0.47192255104891956, "Avg value loss": 0.18563925387570634, "Avg policy loss": 0.28628329653292894, "Total num played games": 21704, "Total num trained steps": 42880, "Timestamp in ms": 1699732482606, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 195.49563068524003, "Avg game time in secs": 1.4231144125078572, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 21760, "Total num trained steps": 42995, "Timestamp in ms": 1699732543469, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97270767395991, "Avg loss": 0.8803036611061543, "Avg value loss": 0.5940358052030206, "Avg policy loss": 0.2862678434466943, "Total num played games": 21801, "Total num trained steps": 43008, "Timestamp in ms": 1699732551871, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974187643020595, "Avg loss": 0.6342184108216316, "Avg value loss": 0.342747162503656, "Avg policy loss": 0.2914712497731671, "Total num played games": 21850, "Total num trained steps": 43136, "Timestamp in ms": 1699732626322, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 112.87625592201948, "Avg game time in secs": 1.1637069557764335, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.46}, "Total num played games": 21888, "Total num trained steps": 43191, "Timestamp in ms": 1699732656346, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756153249006805, "Avg loss": 0.5237337925937027, "Avg value loss": 0.24735604948364198, "Avg policy loss": 0.2763777474174276, "Total num played games": 21899, "Total num trained steps": 43264, "Timestamp in ms": 1699732698074, "logtype": "training_step"}
{"Total num played games": 21948, "Total num trained steps": 43306, "Timestamp in ms": 1699732748843, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9765625}
{"Ratio train steps to played games": 1.972722313147845, "Avg loss": 0.982544524827972, "Avg value loss": 0.6825653633568436, "Avg policy loss": 0.29997916624415666, "Total num played games": 21996, "Total num trained steps": 43392, "Timestamp in ms": 1699732801874, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 201.4950179811567, "Avg game time in secs": 1.2582909936754731, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 22016, "Total num trained steps": 43483, "Timestamp in ms": 1699732857841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9735612897374268, "Avg loss": 0.5419323476962745, "Avg value loss": 0.2625221692142077, "Avg policy loss": 0.2794101807521656, "Total num played games": 22051, "Total num trained steps": 43520, "Timestamp in ms": 1699732880636, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9750667451015884, "Avg loss": 0.6301235943101346, "Avg value loss": 0.34269869641866535, "Avg policy loss": 0.2874249031301588, "Total num played games": 22099, "Total num trained steps": 43648, "Timestamp in ms": 1699732951989, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 120.74522198364139, "Avg game time in secs": 1.3706670488900272, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.67}, "Total num played games": 22144, "Total num trained steps": 43692, "Timestamp in ms": 1699732978586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9760754751049519, "Avg loss": 0.6952316202223301, "Avg value loss": 0.4006280534667894, "Avg policy loss": 0.2946035685017705, "Total num played games": 22153, "Total num trained steps": 43776, "Timestamp in ms": 1699733027491, "logtype": "training_step"}
{"Ratio train steps to played games": 1.973036131583678, "Avg loss": 0.7098936948459595, "Avg value loss": 0.4182577198371291, "Avg policy loss": 0.29163597943261266, "Total num played games": 22252, "Total num trained steps": 43904, "Timestamp in ms": 1699733098206, "logtype": "training_step"}
{"Total num played games": 22255, "Total num trained steps": 43907, "Timestamp in ms": 1699733128522, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.30859375}
{"Avg objective": 22.734375, "Games time in secs": 152.29698501713574, "Avg game time in secs": 1.3136081548727816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.45, "agent_stopped_0": 0.62}, "Total num played games": 22272, "Total num trained steps": 43910, "Timestamp in ms": 1699733130883, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9742635519885217, "Avg loss": 0.7764212512411177, "Avg value loss": 0.47275392385199666, "Avg policy loss": 0.3036673291353509, "Total num played games": 22303, "Total num trained steps": 44032, "Timestamp in ms": 1699733192302, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9757057849760638, "Avg loss": 0.6636778966058046, "Avg value loss": 0.38243134593358263, "Avg policy loss": 0.2812465453753248, "Total num played games": 22351, "Total num trained steps": 44160, "Timestamp in ms": 1699733251752, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977231126389571, "Avg loss": 0.6473774230107665, "Avg value loss": 0.3601699593127705, "Avg policy loss": 0.28720746317412704, "Total num played games": 22399, "Total num trained steps": 44288, "Timestamp in ms": 1699733310902, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 180.0264102872461, "Avg game time in secs": 1.1472797022433951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.41, "agent_stopped_0": 0.61}, "Total num played games": 22400, "Total num trained steps": 44288, "Timestamp in ms": 1699733310910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732551423874896, "Avg loss": 0.7644618866033852, "Avg value loss": 0.4788886198657565, "Avg policy loss": 0.2855732672614977, "Total num played games": 22509, "Total num trained steps": 44416, "Timestamp in ms": 1699733367628, "logtype": "training_step"}
{"Avg objective": 22.828125, "Games time in secs": 97.64363233745098, "Avg game time in secs": 1.2699517499568174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 22528, "Total num trained steps": 44507, "Timestamp in ms": 1699733408553, "logtype": "played_game"}
{"Total num played games": 22557, "Total num trained steps": 44507, "Timestamp in ms": 1699733450799, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.01171875}
{"Ratio train steps to played games": 1.9704932537049324, "Avg loss": 0.808843098115176, "Avg value loss": 0.5086548377294093, "Avg policy loss": 0.3001882575917989, "Total num played games": 22605, "Total num trained steps": 44544, "Timestamp in ms": 1699733467696, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9761557177615572, "Avg loss": 0.5032217346597463, "Avg value loss": 0.20267101610079408, "Avg policy loss": 0.3005507196066901, "Total num played games": 22605, "Total num trained steps": 44672, "Timestamp in ms": 1699733525833, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 172.03605452924967, "Avg game time in secs": 1.3891576429450652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 22656, "Total num trained steps": 44796, "Timestamp in ms": 1699733580590, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9734372935112992, "Avg loss": 0.5151646307203919, "Avg value loss": 0.22744445508578792, "Avg policy loss": 0.287720178370364, "Total num played games": 22701, "Total num trained steps": 44800, "Timestamp in ms": 1699733582144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9742057388935272, "Avg loss": 0.814097564201802, "Avg value loss": 0.5277678624843247, "Avg policy loss": 0.28632969793397933, "Total num played games": 22757, "Total num trained steps": 44928, "Timestamp in ms": 1699733639059, "logtype": "training_step"}
{"Avg objective": 21.8046875, "Games time in secs": 94.87044842727482, "Avg game time in secs": 1.1512766677624313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.45}, "Total num played games": 22784, "Total num trained steps": 45005, "Timestamp in ms": 1699733675460, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757070817803113, "Avg loss": 0.6437138712499291, "Avg value loss": 0.3608109939377755, "Avg policy loss": 0.28290287940762937, "Total num played games": 22805, "Total num trained steps": 45056, "Timestamp in ms": 1699733698640, "logtype": "training_step"}
{"Total num played games": 22858, "Total num trained steps": 45110, "Timestamp in ms": 1699733773499, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.51171875}
{"Ratio train steps to played games": 1.972539945865712, "Avg loss": 0.7895784047432244, "Avg value loss": 0.5045468609896488, "Avg policy loss": 0.28503153729252517, "Total num played games": 22906, "Total num trained steps": 45184, "Timestamp in ms": 1699733806937, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 185.5352137479931, "Avg game time in secs": 1.4879733741399832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 22912, "Total num trained steps": 45302, "Timestamp in ms": 1699733860996, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739490307122631, "Avg loss": 0.4600734931882471, "Avg value loss": 0.19379304547328502, "Avg policy loss": 0.26628044759854674, "Total num played games": 22955, "Total num trained steps": 45312, "Timestamp in ms": 1699733865033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975265171274561, "Avg loss": 0.7224390236660838, "Avg value loss": 0.4421580625930801, "Avg policy loss": 0.28028096444904804, "Total num played games": 23004, "Total num trained steps": 45440, "Timestamp in ms": 1699733924437, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 90.62539879977703, "Avg game time in secs": 1.1147529331792612, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.36}, "Total num played games": 23040, "Total num trained steps": 45500, "Timestamp in ms": 1699733951622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765333564674243, "Avg loss": 0.5501481830142438, "Avg value loss": 0.2818599754245952, "Avg policy loss": 0.2682882099179551, "Total num played games": 23054, "Total num trained steps": 45568, "Timestamp in ms": 1699733981525, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777537329582342, "Avg loss": 0.5829689905513078, "Avg value loss": 0.31930828117765486, "Avg policy loss": 0.2636607118183747, "Total num played games": 23105, "Total num trained steps": 45696, "Timestamp in ms": 1699734039672, "logtype": "training_step"}
{"Total num played games": 23151, "Total num trained steps": 45709, "Timestamp in ms": 1699734081209, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.94921875}
{"Avg objective": 22.09375, "Games time in secs": 131.07237090729177, "Avg game time in secs": 1.2159031977353152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 23168, "Total num trained steps": 45711, "Timestamp in ms": 1699734082694, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9752144488986594, "Avg loss": 0.9678485919721425, "Avg value loss": 0.6778274539392442, "Avg policy loss": 0.2900211368687451, "Total num played games": 23199, "Total num trained steps": 45824, "Timestamp in ms": 1699734134241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9766851636770335, "Avg loss": 0.5242829893250018, "Avg value loss": 0.25669902469962835, "Avg policy loss": 0.26758396183140576, "Total num played games": 23247, "Total num trained steps": 45952, "Timestamp in ms": 1699734191391, "logtype": "training_step"}
{"Avg objective": 20.7421875, "Games time in secs": 125.12841237708926, "Avg game time in secs": 1.1973641544900602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 23296, "Total num trained steps": 45988, "Timestamp in ms": 1699734207823, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978021978021978, "Avg loss": 0.5001207180321217, "Avg value loss": 0.23612320877145976, "Avg policy loss": 0.26399750588461757, "Total num played games": 23296, "Total num trained steps": 46080, "Timestamp in ms": 1699734249726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9750384681142075, "Avg loss": 0.6745954463258386, "Avg value loss": 0.41456839349120855, "Avg policy loss": 0.2600270522525534, "Total num played games": 23396, "Total num trained steps": 46208, "Timestamp in ms": 1699734307138, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 133.15829597599804, "Avg game time in secs": 1.0907992893189657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.37}, "Total num played games": 23424, "Total num trained steps": 46285, "Timestamp in ms": 1699734340981, "logtype": "played_game"}
{"Total num played games": 23445, "Total num trained steps": 46313, "Timestamp in ms": 1699734383279, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.94921875}
{"Ratio train steps to played games": 1.97228961818414, "Avg loss": 0.6839358215220273, "Avg value loss": 0.40568757441360503, "Avg policy loss": 0.2782482448965311, "Total num played games": 23493, "Total num trained steps": 46336, "Timestamp in ms": 1699734393863, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777380496318053, "Avg loss": 0.4745002742856741, "Avg value loss": 0.19831322156824172, "Avg policy loss": 0.27618705260101706, "Total num played games": 23493, "Total num trained steps": 46464, "Timestamp in ms": 1699734451831, "logtype": "training_step"}
{"Avg objective": 19.8828125, "Games time in secs": 158.26410237140954, "Avg game time in secs": 1.4269302728644107, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.59, "agent_stopped_0": 0.51}, "Total num played games": 23552, "Total num trained steps": 46572, "Timestamp in ms": 1699734499245, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975074183976261, "Avg loss": 0.6460235218983144, "Avg value loss": 0.37320477911271155, "Avg policy loss": 0.27281873708125204, "Total num played games": 23590, "Total num trained steps": 46592, "Timestamp in ms": 1699734507906, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764362467213807, "Avg loss": 0.6363654991146177, "Avg value loss": 0.3636447586468421, "Avg policy loss": 0.2727207432035357, "Total num played games": 23638, "Total num trained steps": 46720, "Timestamp in ms": 1699734567537, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 89.97671978548169, "Avg game time in secs": 1.1655194670020137, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 23680, "Total num trained steps": 46768, "Timestamp in ms": 1699734589222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777515092666864, "Avg loss": 0.5794904613867402, "Avg value loss": 0.303811663587112, "Avg policy loss": 0.2756787983234972, "Total num played games": 23687, "Total num trained steps": 46848, "Timestamp in ms": 1699734625545, "logtype": "training_step"}
{"Total num played games": 23738, "Total num trained steps": 46917, "Timestamp in ms": 1699734684522, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.5234375}
{"Ratio train steps to played games": 1.9749012023879593, "Avg loss": 0.7045473775360733, "Avg value loss": 0.4232140733511187, "Avg policy loss": 0.28133330633863807, "Total num played games": 23786, "Total num trained steps": 46976, "Timestamp in ms": 1699734712207, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 163.40018725581467, "Avg game time in secs": 1.444414165103808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.55, "agent_stopped_0": 0.58}, "Total num played games": 23808, "Total num trained steps": 47062, "Timestamp in ms": 1699734752627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9762534088525279, "Avg loss": 0.6763727117795497, "Avg value loss": 0.40697810339042917, "Avg policy loss": 0.2693946142680943, "Total num played games": 23835, "Total num trained steps": 47104, "Timestamp in ms": 1699734771708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9775991290876356, "Avg loss": 0.5383233991451561, "Avg value loss": 0.2686127761262469, "Avg policy loss": 0.2697106178384274, "Total num played games": 23883, "Total num trained steps": 47232, "Timestamp in ms": 1699734829612, "logtype": "training_step"}
{"Avg objective": 22.421875, "Games time in secs": 132.22960335947573, "Avg game time in secs": 1.3643991860735696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 23936, "Total num trained steps": 47352, "Timestamp in ms": 1699734884852, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9751021769955792, "Avg loss": 0.652936061611399, "Avg value loss": 0.38643500569742173, "Avg policy loss": 0.2665010542841628, "Total num played games": 23978, "Total num trained steps": 47360, "Timestamp in ms": 1699734888425, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764431681025514, "Avg loss": 0.7062241586390883, "Avg value loss": 0.42653245106339455, "Avg policy loss": 0.27969170559663326, "Total num played games": 24027, "Total num trained steps": 47488, "Timestamp in ms": 1699734948303, "logtype": "training_step"}
{"Total num played games": 24027, "Total num trained steps": 47518, "Timestamp in ms": 1699735029294, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.4296875}
{"Avg objective": 22.1015625, "Games time in secs": 146.73302232846618, "Avg game time in secs": 1.0828789232473355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 24064, "Total num trained steps": 47522, "Timestamp in ms": 1699735031585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778193146417447, "Avg loss": 0.5460330878850073, "Avg value loss": 0.26913860387867317, "Avg policy loss": 0.27689448604360223, "Total num played games": 24075, "Total num trained steps": 47616, "Timestamp in ms": 1699735074028, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786158309158723, "Avg loss": 0.5272017223760486, "Avg value loss": 0.26585221965797246, "Avg policy loss": 0.2613494994584471, "Total num played games": 24130, "Total num trained steps": 47744, "Timestamp in ms": 1699735133490, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 146.54426009953022, "Avg game time in secs": 1.1881384273729054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.48}, "Total num played games": 24192, "Total num trained steps": 47847, "Timestamp in ms": 1699735178130, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758141070617854, "Avg loss": 0.7049994829576463, "Avg value loss": 0.4343533697538078, "Avg policy loss": 0.27064612100366503, "Total num played games": 24229, "Total num trained steps": 47872, "Timestamp in ms": 1699735189386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9769759874788913, "Avg loss": 0.5879602236673236, "Avg value loss": 0.3180556478910148, "Avg policy loss": 0.26990457449574023, "Total num played games": 24279, "Total num trained steps": 48000, "Timestamp in ms": 1699735247304, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 93.19092500954866, "Avg game time in secs": 1.1413726289320039, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 24320, "Total num trained steps": 48050, "Timestamp in ms": 1699735271321, "logtype": "played_game"}
{"Total num played games": 24328, "Total num trained steps": 48122, "Timestamp in ms": 1699735349375, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.98828125}
{"Ratio train steps to played games": 1.9747650896557383, "Avg loss": 0.6523569265846163, "Avg value loss": 0.38606821943540126, "Avg policy loss": 0.26628870621789247, "Total num played games": 24365, "Total num trained steps": 48128, "Timestamp in ms": 1699735352267, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9754380219420338, "Avg loss": 0.7056579657364637, "Avg value loss": 0.4334865733399056, "Avg policy loss": 0.2721713889623061, "Total num played games": 24428, "Total num trained steps": 48256, "Timestamp in ms": 1699735408979, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 178.98367519304156, "Avg game time in secs": 1.2248227510572178, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.52, "agent_stopped_0": 0.54}, "Total num played games": 24448, "Total num trained steps": 48347, "Timestamp in ms": 1699735450305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9764297385620915, "Avg loss": 0.5674238936044276, "Avg value loss": 0.29949300101725385, "Avg policy loss": 0.26793089520651847, "Total num played games": 24480, "Total num trained steps": 48384, "Timestamp in ms": 1699735467036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777804957599479, "Avg loss": 0.5352050778456032, "Avg value loss": 0.2704756976454519, "Avg policy loss": 0.2647293796762824, "Total num played games": 24528, "Total num trained steps": 48512, "Timestamp in ms": 1699735524477, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 90.89426653273404, "Avg game time in secs": 1.2308825421932852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 24576, "Total num trained steps": 48549, "Timestamp in ms": 1699735541199, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787234042553192, "Avg loss": 0.5966082562226802, "Avg value loss": 0.3289161237771623, "Avg policy loss": 0.2676921347156167, "Total num played games": 24581, "Total num trained steps": 48640, "Timestamp in ms": 1699735582126, "logtype": "training_step"}
{"Total num played games": 24629, "Total num trained steps": 48725, "Timestamp in ms": 1699735670883, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.46484375}
{"Ratio train steps to played games": 1.9762531912307006, "Avg loss": 0.7155796259175986, "Avg value loss": 0.4475598481949419, "Avg policy loss": 0.2680197734152898, "Total num played games": 24677, "Total num trained steps": 48768, "Timestamp in ms": 1699735690832, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 184.18825196661055, "Avg game time in secs": 1.084771565234405, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.32, "played_steps": 0.37, "agent_stopped_0": 0.68}, "Total num played games": 24704, "Total num trained steps": 48845, "Timestamp in ms": 1699735725387, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774731052333576, "Avg loss": 0.5497708932962269, "Avg value loss": 0.28595490171574056, "Avg policy loss": 0.2638159957714379, "Total num played games": 24726, "Total num trained steps": 48896, "Timestamp in ms": 1699735748593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788084281908453, "Avg loss": 0.5117784242611378, "Avg value loss": 0.25197048037080094, "Avg policy loss": 0.2598079488379881, "Total num played games": 24774, "Total num trained steps": 49024, "Timestamp in ms": 1699735807300, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 136.0522932689637, "Avg game time in secs": 1.097550785416388, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.39}, "Total num played games": 24832, "Total num trained steps": 49143, "Timestamp in ms": 1699735861440, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9756813248653429, "Avg loss": 0.5277260192669928, "Avg value loss": 0.27269989147316664, "Avg policy loss": 0.25502612930722535, "Total num played games": 24878, "Total num trained steps": 49152, "Timestamp in ms": 1699735865548, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97693264331849, "Avg loss": 0.6356663659680635, "Avg value loss": 0.38327562145423144, "Avg policy loss": 0.25239074241835624, "Total num played games": 24927, "Total num trained steps": 49280, "Timestamp in ms": 1699735921932, "logtype": "training_step"}
{"Total num played games": 24927, "Total num trained steps": 49326, "Timestamp in ms": 1699735994935, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.453125}
{"Avg objective": 21.4765625, "Games time in secs": 135.63547018915415, "Avg game time in secs": 1.0863883260462899, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 24960, "Total num trained steps": 49329, "Timestamp in ms": 1699735997076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9782982982982984, "Avg loss": 0.6525404381100088, "Avg value loss": 0.38726889772806317, "Avg policy loss": 0.26527154038194567, "Total num played games": 24975, "Total num trained steps": 49408, "Timestamp in ms": 1699736031948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794996803069054, "Avg loss": 0.49243032187223434, "Avg value loss": 0.239692906383425, "Avg policy loss": 0.2527374116471037, "Total num played games": 25024, "Total num trained steps": 49536, "Timestamp in ms": 1699736089560, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 141.17234074510634, "Avg game time in secs": 1.188624400048866, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 25088, "Total num trained steps": 49644, "Timestamp in ms": 1699736138248, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9760076393586121, "Avg loss": 0.5573147237300873, "Avg value loss": 0.3150290191406384, "Avg policy loss": 0.24228571087587625, "Total num played games": 25133, "Total num trained steps": 49664, "Timestamp in ms": 1699736147078, "logtype": "training_step"}
{"Ratio train steps to played games": 1.97732417298757, "Avg loss": 0.594251967035234, "Avg value loss": 0.3498266175156459, "Avg policy loss": 0.24442534730769694, "Total num played games": 25181, "Total num trained steps": 49792, "Timestamp in ms": 1699736203945, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 93.24861855991185, "Avg game time in secs": 1.0670867252483731, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.44}, "Total num played games": 25216, "Total num trained steps": 49854, "Timestamp in ms": 1699736231497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786753339410996, "Avg loss": 0.6148466202430427, "Avg value loss": 0.3573272573412396, "Avg policy loss": 0.2575193616794422, "Total num played games": 25229, "Total num trained steps": 49920, "Timestamp in ms": 1699736260871, "logtype": "training_step"}
{"Total num played games": 25229, "Total num trained steps": 49929, "Timestamp in ms": 1699736312344, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6015625}
{"Ratio train steps to played games": 1.9759949463044852, "Avg loss": 0.5819605491124094, "Avg value loss": 0.3290413722861558, "Avg policy loss": 0.25291917531285435, "Total num played games": 25327, "Total num trained steps": 50048, "Timestamp in ms": 1699736366455, "logtype": "training_step"}
{"Avg objective": 21.5, "Games time in secs": 180.53684944100678, "Avg game time in secs": 1.1346624082361814, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 25344, "Total num trained steps": 50146, "Timestamp in ms": 1699736412034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976794578835395, "Avg loss": 0.7380820426624268, "Avg value loss": 0.4840860247495584, "Avg policy loss": 0.25399600551463664, "Total num played games": 25382, "Total num trained steps": 50176, "Timestamp in ms": 1699736425122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779804970116388, "Avg loss": 0.6390904830768704, "Avg value loss": 0.39308772346703336, "Avg policy loss": 0.24600275279954076, "Total num played games": 25432, "Total num trained steps": 50304, "Timestamp in ms": 1699736482969, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 94.2048115786165, "Avg game time in secs": 1.0991704391199164, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 25472, "Total num trained steps": 50356, "Timestamp in ms": 1699736506239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788503041004513, "Avg loss": 0.6801422529388219, "Avg value loss": 0.424372642475646, "Avg policy loss": 0.255769613198936, "Total num played games": 25485, "Total num trained steps": 50432, "Timestamp in ms": 1699736541114, "logtype": "training_step"}
{"Total num played games": 25533, "Total num trained steps": 50529, "Timestamp in ms": 1699736626156, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.43359375}
{"Ratio train steps to played games": 1.9764278175208163, "Avg loss": 0.7366083862725645, "Avg value loss": 0.48333285009721294, "Avg policy loss": 0.25327553995884955, "Total num played games": 25581, "Total num trained steps": 50560, "Timestamp in ms": 1699736640679, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 177.3348175417632, "Avg game time in secs": 1.1420956618967466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.46, "agent_stopped_0": 0.59}, "Total num played games": 25600, "Total num trained steps": 50652, "Timestamp in ms": 1699736683574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9777205509383902, "Avg loss": 0.5835156298708171, "Avg value loss": 0.33921794610796496, "Avg policy loss": 0.24429768102709204, "Total num played games": 25629, "Total num trained steps": 50688, "Timestamp in ms": 1699736700012, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790084511430464, "Avg loss": 0.5355878975242376, "Avg value loss": 0.2851782132056542, "Avg policy loss": 0.2504096858901903, "Total num played games": 25677, "Total num trained steps": 50816, "Timestamp in ms": 1699736757872, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 131.05845304764807, "Avg game time in secs": 1.2257649575767573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 25728, "Total num trained steps": 50941, "Timestamp in ms": 1699736814633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977486220013974, "Avg loss": 0.5497712616343051, "Avg value loss": 0.30335695459507406, "Avg policy loss": 0.24641430715564638, "Total num played games": 25760, "Total num trained steps": 50944, "Timestamp in ms": 1699736815513, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977120514110952, "Avg loss": 0.8492187610827386, "Avg value loss": 0.5877717394614592, "Avg policy loss": 0.2614470230182633, "Total num played games": 25831, "Total num trained steps": 51072, "Timestamp in ms": 1699736874556, "logtype": "training_step"}
{"Total num played games": 25831, "Total num trained steps": 51130, "Timestamp in ms": 1699736934429, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.05859375}
{"Avg objective": 21.390625, "Games time in secs": 121.728656090796, "Avg game time in secs": 0.9859671136364341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.39}, "Total num played games": 25856, "Total num trained steps": 51134, "Timestamp in ms": 1699736936362, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783994744773754, "Avg loss": 0.5264429557137191, "Avg value loss": 0.26511305663734674, "Avg policy loss": 0.2613298991927877, "Total num played games": 25879, "Total num trained steps": 51200, "Timestamp in ms": 1699736965249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795973464979943, "Avg loss": 0.6442724047228694, "Avg value loss": 0.380360787617974, "Avg policy loss": 0.26391161896754056, "Total num played games": 25928, "Total num trained steps": 51328, "Timestamp in ms": 1699737023714, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 138.84053858555853, "Avg game time in secs": 1.20301355374977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 25984, "Total num trained steps": 51444, "Timestamp in ms": 1699737075202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9771373679154658, "Avg loss": 0.5542651293799281, "Avg value loss": 0.2907821600092575, "Avg policy loss": 0.2634829682065174, "Total num played games": 26025, "Total num trained steps": 51456, "Timestamp in ms": 1699737080134, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783309043491601, "Avg loss": 0.8023961950093508, "Avg value loss": 0.5281787058338523, "Avg policy loss": 0.27421748253982514, "Total num played games": 26074, "Total num trained steps": 51584, "Timestamp in ms": 1699737137865, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 87.50328803062439, "Avg game time in secs": 1.201349770766683, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 26112, "Total num trained steps": 51641, "Timestamp in ms": 1699737162706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979634024959804, "Avg loss": 0.5848051400389522, "Avg value loss": 0.3064339017146267, "Avg policy loss": 0.2783712464151904, "Total num played games": 26122, "Total num trained steps": 51712, "Timestamp in ms": 1699737194875, "logtype": "training_step"}
{"Total num played games": 26122, "Total num trained steps": 51732, "Timestamp in ms": 1699737242058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3359375}
{"Ratio train steps to played games": 1.9765508826781562, "Avg loss": 0.5956947794184089, "Avg value loss": 0.32048398145707324, "Avg policy loss": 0.275210804422386, "Total num played games": 26227, "Total num trained steps": 51840, "Timestamp in ms": 1699737291298, "logtype": "training_step"}
{"Avg objective": 20.3125, "Games time in secs": 175.5117516797036, "Avg game time in secs": 1.2347558052861132, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.51, "agent_stopped_0": 0.58}, "Total num played games": 26240, "Total num trained steps": 51946, "Timestamp in ms": 1699737338218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773228825812343, "Avg loss": 0.5995141461025923, "Avg value loss": 0.3279878372559324, "Avg policy loss": 0.2715263043064624, "Total num played games": 26282, "Total num trained steps": 51968, "Timestamp in ms": 1699737347812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9783541563817264, "Avg loss": 0.6394169272389263, "Avg value loss": 0.36445526662282646, "Avg policy loss": 0.27496166445780545, "Total num played games": 26333, "Total num trained steps": 52096, "Timestamp in ms": 1699737406482, "logtype": "training_step"}
{"Avg objective": 22.6328125, "Games time in secs": 96.1113963034004, "Avg game time in secs": 1.2338169933209429, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.56}, "Total num played games": 26368, "Total num trained steps": 52158, "Timestamp in ms": 1699737434329, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791564027740933, "Avg loss": 0.7873491286300123, "Avg value loss": 0.5055264561669901, "Avg policy loss": 0.28182266489602625, "Total num played games": 26387, "Total num trained steps": 52224, "Timestamp in ms": 1699737463728, "logtype": "training_step"}
{"Total num played games": 26435, "Total num trained steps": 52333, "Timestamp in ms": 1699737549406, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.234375}
{"Ratio train steps to played games": 1.9767775554129063, "Avg loss": 0.5219064680859447, "Avg value loss": 0.25217086757766083, "Avg policy loss": 0.26973560359328985, "Total num played games": 26483, "Total num trained steps": 52352, "Timestamp in ms": 1699737558401, "logtype": "training_step"}
{"Avg objective": 18.9296875, "Games time in secs": 170.67504570819438, "Avg game time in secs": 1.324802103888942, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 26496, "Total num trained steps": 52456, "Timestamp in ms": 1699737605007, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9775784753363228, "Avg loss": 0.4742808919399977, "Avg value loss": 0.21622879715869203, "Avg policy loss": 0.25805209029931575, "Total num played games": 26537, "Total num trained steps": 52480, "Timestamp in ms": 1699737615404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9787482133453698, "Avg loss": 0.6707180885132402, "Avg value loss": 0.4125756162102334, "Avg policy loss": 0.2581424652598798, "Total num played games": 26586, "Total num trained steps": 52608, "Timestamp in ms": 1699737672629, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 93.09977242909372, "Avg game time in secs": 1.0187791212665616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 26624, "Total num trained steps": 52663, "Timestamp in ms": 1699737698107, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800255312758128, "Avg loss": 0.6082938581239432, "Avg value loss": 0.3438442025799304, "Avg policy loss": 0.2644496619468555, "Total num played games": 26634, "Total num trained steps": 52736, "Timestamp in ms": 1699737730515, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777029554807333, "Avg loss": 0.604408806655556, "Avg value loss": 0.3472234439686872, "Avg policy loss": 0.2571853606496006, "Total num played games": 26730, "Total num trained steps": 52864, "Timestamp in ms": 1699737787217, "logtype": "training_step"}
{"Total num played games": 26730, "Total num trained steps": 52933, "Timestamp in ms": 1699737896987, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.38671875}
{"Avg objective": 22.4140625, "Games time in secs": 200.56727879866958, "Avg game time in secs": 1.0168774995108834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.43, "agent_stopped_0": 0.6}, "Total num played games": 26752, "Total num trained steps": 52935, "Timestamp in ms": 1699737898674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978937934125028, "Avg loss": 0.5400484949350357, "Avg value loss": 0.2787257245508954, "Avg policy loss": 0.2613227725960314, "Total num played games": 26778, "Total num trained steps": 52992, "Timestamp in ms": 1699737925205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801684932528145, "Avg loss": 0.6519572369288653, "Avg value loss": 0.39941534982062876, "Avg policy loss": 0.2525418899022043, "Total num played games": 26826, "Total num trained steps": 53120, "Timestamp in ms": 1699737982554, "logtype": "training_step"}
{"Avg objective": 20.4375, "Games time in secs": 136.07516369596124, "Avg game time in secs": 1.0910605988028692, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 26880, "Total num trained steps": 53238, "Timestamp in ms": 1699738034750, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773107059304096, "Avg loss": 0.635728957131505, "Avg value loss": 0.37369558634236455, "Avg policy loss": 0.262033375678584, "Total num played games": 26929, "Total num trained steps": 53248, "Timestamp in ms": 1699738038903, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785372724913814, "Avg loss": 0.6943931169807911, "Avg value loss": 0.42831850791117176, "Avg policy loss": 0.2660746176261455, "Total num played games": 26977, "Total num trained steps": 53376, "Timestamp in ms": 1699738096197, "logtype": "training_step"}
{"Avg objective": 23.0390625, "Games time in secs": 93.28205407783389, "Avg game time in secs": 1.0691057636140613, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 27008, "Total num trained steps": 53446, "Timestamp in ms": 1699738128032, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9797964847363552, "Avg loss": 0.536195604596287, "Avg value loss": 0.28602852858603, "Avg policy loss": 0.2501670758938417, "Total num played games": 27025, "Total num trained steps": 53504, "Timestamp in ms": 1699738154225, "logtype": "training_step"}
{"Total num played games": 27025, "Total num trained steps": 53536, "Timestamp in ms": 1699738191999, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.82421875}
{"Ratio train steps to played games": 1.9810142946847413, "Avg loss": 0.5150440884754062, "Avg value loss": 0.26044947328045964, "Avg policy loss": 0.25459461146965623, "Total num played games": 27073, "Total num trained steps": 53632, "Timestamp in ms": 1699738235555, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 153.51395050995052, "Avg game time in secs": 1.2432766438869294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 27136, "Total num trained steps": 53732, "Timestamp in ms": 1699738281546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781064871030651, "Avg loss": 0.835970600368455, "Avg value loss": 0.5643597187008709, "Avg policy loss": 0.27161087456624955, "Total num played games": 27177, "Total num trained steps": 53760, "Timestamp in ms": 1699738294512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791023945938004, "Avg loss": 0.5283049817662686, "Avg value loss": 0.26376602990785614, "Avg policy loss": 0.26453895412851125, "Total num played games": 27228, "Total num trained steps": 53888, "Timestamp in ms": 1699738353517, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 98.38792655989528, "Avg game time in secs": 1.1985314704070333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 27264, "Total num trained steps": 53948, "Timestamp in ms": 1699738379934, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9798042737235642, "Avg loss": 0.566666885977611, "Avg value loss": 0.3050425421097316, "Avg policy loss": 0.26162434788420796, "Total num played games": 27283, "Total num trained steps": 54016, "Timestamp in ms": 1699738410717, "logtype": "training_step"}
{"Total num played games": 27331, "Total num trained steps": 54137, "Timestamp in ms": 1699738486418, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.48828125}
{"Ratio train steps to played games": 1.9779352670417185, "Avg loss": 0.6211791564710438, "Avg value loss": 0.3566191310528666, "Avg policy loss": 0.26456002693157643, "Total num played games": 27374, "Total num trained steps": 54144, "Timestamp in ms": 1699738489687, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 157.56553213112056, "Avg game time in secs": 1.2613480524596525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.54, "agent_stopped_0": 0.53}, "Total num played games": 27392, "Total num trained steps": 54248, "Timestamp in ms": 1699738537502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9787800342727968, "Avg loss": 0.511242366861552, "Avg value loss": 0.2410818969947286, "Avg policy loss": 0.2701604701578617, "Total num played games": 27427, "Total num trained steps": 54272, "Timestamp in ms": 1699738547855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9799454049135579, "Avg loss": 0.5762798055075109, "Avg value loss": 0.31255182391032577, "Avg policy loss": 0.2637279828777537, "Total num played games": 27475, "Total num trained steps": 54400, "Timestamp in ms": 1699738606305, "logtype": "training_step"}
{"Avg objective": 20.90625, "Games time in secs": 88.1409978158772, "Avg game time in secs": 1.1993864682881394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 27520, "Total num trained steps": 54444, "Timestamp in ms": 1699738625643, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980891488356886, "Avg loss": 0.7579354420304298, "Avg value loss": 0.48689595627365634, "Avg policy loss": 0.27103949210140854, "Total num played games": 27527, "Total num trained steps": 54528, "Timestamp in ms": 1699738663121, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9784615384615385, "Avg loss": 0.8805108226370066, "Avg value loss": 0.6039611821179278, "Avg policy loss": 0.27654963673558086, "Total num played games": 27625, "Total num trained steps": 54656, "Timestamp in ms": 1699738720024, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 133.16463480889797, "Avg game time in secs": 1.1364600514934864, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 27648, "Total num trained steps": 54739, "Timestamp in ms": 1699738758808, "logtype": "played_game"}
{"Total num played games": 27673, "Total num trained steps": 54739, "Timestamp in ms": 1699738774538, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.59765625}
{"Ratio train steps to played games": 1.9762274088236356, "Avg loss": 0.8024956558365375, "Avg value loss": 0.5112996239913628, "Avg policy loss": 0.291196032660082, "Total num played games": 27721, "Total num trained steps": 54784, "Timestamp in ms": 1699738795830, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808448468669961, "Avg loss": 0.4661218565888703, "Avg value loss": 0.1817459756275639, "Avg policy loss": 0.2843758788658306, "Total num played games": 27721, "Total num trained steps": 54912, "Timestamp in ms": 1699738854682, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816381638163816, "Avg loss": 0.7062225968111306, "Avg value loss": 0.4263978106318973, "Avg policy loss": 0.279824786237441, "Total num played games": 27775, "Total num trained steps": 55040, "Timestamp in ms": 1699738911173, "logtype": "training_step"}
{"Avg objective": 22.6953125, "Games time in secs": 152.3672570604831, "Avg game time in secs": 1.1584936877479777, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 27776, "Total num trained steps": 55040, "Timestamp in ms": 1699738911178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9792630861407097, "Avg loss": 0.7561003321316093, "Avg value loss": 0.47163627902045846, "Avg policy loss": 0.284464058582671, "Total num played games": 27873, "Total num trained steps": 55168, "Timestamp in ms": 1699738968221, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 88.49913207255304, "Avg game time in secs": 1.0902551419712836, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 27904, "Total num trained steps": 55238, "Timestamp in ms": 1699738999678, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980161145926589, "Avg loss": 0.7810259363614023, "Avg value loss": 0.4830924578127451, "Avg policy loss": 0.29793346871156245, "Total num played games": 27925, "Total num trained steps": 55296, "Timestamp in ms": 1699739025379, "logtype": "training_step"}
{"Total num played games": 27973, "Total num trained steps": 55344, "Timestamp in ms": 1699739109902, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.94140625}
{"Ratio train steps to played games": 1.9779451125941259, "Avg loss": 0.9690881303977221, "Avg value loss": 0.667394996562507, "Avg policy loss": 0.30169312679208815, "Total num played games": 28021, "Total num trained steps": 55424, "Timestamp in ms": 1699739147000, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 196.28679797053337, "Avg game time in secs": 1.192465084415744, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 28032, "Total num trained steps": 55532, "Timestamp in ms": 1699739195964, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979122875770423, "Avg loss": 0.5170760434120893, "Avg value loss": 0.22659539710730314, "Avg policy loss": 0.29048064490780234, "Total num played games": 28069, "Total num trained steps": 55552, "Timestamp in ms": 1699739204993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9799793748444223, "Avg loss": 0.575396032538265, "Avg value loss": 0.28479655273258686, "Avg policy loss": 0.2905994774773717, "Total num played games": 28121, "Total num trained steps": 55680, "Timestamp in ms": 1699739261190, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 89.04306118190289, "Avg game time in secs": 0.9539564544247696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.43}, "Total num played games": 28160, "Total num trained steps": 55734, "Timestamp in ms": 1699739285008, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811146609868655, "Avg loss": 0.7665501264855266, "Avg value loss": 0.4813632207806222, "Avg policy loss": 0.28518691135104746, "Total num played games": 28170, "Total num trained steps": 55808, "Timestamp in ms": 1699739318764, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9788792188495012, "Avg loss": 0.7593174250796437, "Avg value loss": 0.48390540899708867, "Avg policy loss": 0.27541201934218407, "Total num played games": 28266, "Total num trained steps": 55936, "Timestamp in ms": 1699739376092, "logtype": "training_step"}
{"Total num played games": 28266, "Total num trained steps": 55947, "Timestamp in ms": 1699739427572, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.48828125}
{"Avg objective": 21.5546875, "Games time in secs": 144.17508269660175, "Avg game time in secs": 1.2239098304708023, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 28288, "Total num trained steps": 55948, "Timestamp in ms": 1699739429183, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800452073179347, "Avg loss": 0.6493696039542556, "Avg value loss": 0.35899095016065985, "Avg policy loss": 0.290378654259257, "Total num played games": 28314, "Total num trained steps": 56064, "Timestamp in ms": 1699739481445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980718389791674, "Avg loss": 0.5228290297091007, "Avg value loss": 0.2462636639829725, "Avg policy loss": 0.2765653661917895, "Total num played games": 28369, "Total num trained steps": 56192, "Timestamp in ms": 1699739540429, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 129.7335566636175, "Avg game time in secs": 1.1087259715568507, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 28416, "Total num trained steps": 56233, "Timestamp in ms": 1699739558917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819122356335996, "Avg loss": 0.6009574916679412, "Avg value loss": 0.32960973045555875, "Avg policy loss": 0.27134775929152966, "Total num played games": 28417, "Total num trained steps": 56320, "Timestamp in ms": 1699739597657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979693473152597, "Avg loss": 0.6677676602266729, "Avg value loss": 0.39606051676673815, "Avg policy loss": 0.27170714654494077, "Total num played games": 28513, "Total num trained steps": 56448, "Timestamp in ms": 1699739657900, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 132.37646796368062, "Avg game time in secs": 0.9551035289332503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 0.37, "agent_stopped_0": 0.67}, "Total num played games": 28544, "Total num trained steps": 56517, "Timestamp in ms": 1699739691293, "logtype": "played_game"}
{"Total num played games": 28561, "Total num trained steps": 56549, "Timestamp in ms": 1699739778368, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3359375}
{"Ratio train steps to played games": 1.977524555209899, "Avg loss": 0.6492850366048515, "Avg value loss": 0.37147142499452457, "Avg policy loss": 0.27781361108645797, "Total num played games": 28609, "Total num trained steps": 56576, "Timestamp in ms": 1699739790859, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819986717466531, "Avg loss": 0.45524780615232885, "Avg value loss": 0.18059103254927322, "Avg policy loss": 0.2746567741269246, "Total num played games": 28609, "Total num trained steps": 56704, "Timestamp in ms": 1699739849628, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 207.47257316485047, "Avg game time in secs": 1.3675531639019027, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 28672, "Total num trained steps": 56814, "Timestamp in ms": 1699739898766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979174647396831, "Avg loss": 0.6427418657112867, "Avg value loss": 0.36406379437539726, "Avg policy loss": 0.2786780677270144, "Total num played games": 28715, "Total num trained steps": 56832, "Timestamp in ms": 1699739906161, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9803219413830269, "Avg loss": 0.5707851580809802, "Avg value loss": 0.30509256263030693, "Avg policy loss": 0.26569259515963495, "Total num played games": 28763, "Total num trained steps": 56960, "Timestamp in ms": 1699739963111, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 89.95576017722487, "Avg game time in secs": 1.0454181107197655, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 28800, "Total num trained steps": 57018, "Timestamp in ms": 1699739988722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980915368333391, "Avg loss": 0.6353602739982307, "Avg value loss": 0.35773124819388613, "Avg policy loss": 0.27762902225367725, "Total num played games": 28819, "Total num trained steps": 57088, "Timestamp in ms": 1699740020314, "logtype": "training_step"}
{"Total num played games": 28867, "Total num trained steps": 57152, "Timestamp in ms": 1699740075466, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.10546875}
{"Ratio train steps to played games": 1.978765346705862, "Avg loss": 0.6719555321615189, "Avg value loss": 0.38970540947047994, "Avg policy loss": 0.2822501198388636, "Total num played games": 28915, "Total num trained steps": 57216, "Timestamp in ms": 1699740104191, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 161.14087975025177, "Avg game time in secs": 1.2110923514555907, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.53, "agent_stopped_0": 0.56}, "Total num played games": 28928, "Total num trained steps": 57321, "Timestamp in ms": 1699740149863, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795974729865018, "Avg loss": 0.464618141297251, "Avg value loss": 0.20046024967450649, "Avg policy loss": 0.2641578904585913, "Total num played games": 28967, "Total num trained steps": 57344, "Timestamp in ms": 1699740159685, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807003032809485, "Avg loss": 0.5945116772782058, "Avg value loss": 0.3184105713153258, "Avg policy loss": 0.2761011030524969, "Total num played games": 29016, "Total num trained steps": 57472, "Timestamp in ms": 1699740218570, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 91.82273744419217, "Avg game time in secs": 1.1348141410853714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 29056, "Total num trained steps": 57524, "Timestamp in ms": 1699740241685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981389748882009, "Avg loss": 0.59526557312347, "Avg value loss": 0.3215383755741641, "Avg policy loss": 0.27372719161212444, "Total num played games": 29070, "Total num trained steps": 57600, "Timestamp in ms": 1699740275549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798340078194663, "Avg loss": 0.49374132265802473, "Avg value loss": 0.23499880108283833, "Avg policy loss": 0.2587425218662247, "Total num played games": 29158, "Total num trained steps": 57728, "Timestamp in ms": 1699740333341, "logtype": "training_step"}
{"Total num played games": 29166, "Total num trained steps": 57753, "Timestamp in ms": 1699740389219, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.47265625}
{"Avg objective": 21.1015625, "Games time in secs": 149.2319927420467, "Avg game time in secs": 1.1206603687460301, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 29184, "Total num trained steps": 57756, "Timestamp in ms": 1699740390918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9803861162456358, "Avg loss": 0.6696388609707355, "Avg value loss": 0.40520813333569095, "Avg policy loss": 0.26443073141854256, "Total num played games": 29214, "Total num trained steps": 57856, "Timestamp in ms": 1699740436474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815460323969654, "Avg loss": 0.6579195810481906, "Avg value loss": 0.4026037309668027, "Avg policy loss": 0.255315855727531, "Total num played games": 29262, "Total num trained steps": 57984, "Timestamp in ms": 1699740494258, "logtype": "training_step"}
{"Avg objective": 21.640625, "Games time in secs": 160.7632857300341, "Avg game time in secs": 1.124883907221374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 29312, "Total num trained steps": 58111, "Timestamp in ms": 1699740551681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823298652566945, "Avg loss": 0.506403588457033, "Avg value loss": 0.24259081127820536, "Avg policy loss": 0.26381277141626924, "Total num played games": 29312, "Total num trained steps": 58112, "Timestamp in ms": 1699740551750, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9801774846146, "Avg loss": 0.686338541796431, "Avg value loss": 0.4279984974418767, "Avg policy loss": 0.258340046973899, "Total num played games": 29411, "Total num trained steps": 58240, "Timestamp in ms": 1699740608065, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 88.77284338884056, "Avg game time in secs": 1.1384891127672745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.52}, "Total num played games": 29440, "Total num trained steps": 58314, "Timestamp in ms": 1699740640454, "logtype": "played_game"}
{"Total num played games": 29462, "Total num trained steps": 58353, "Timestamp in ms": 1699740713802, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5}
{"Ratio train steps to played games": 1.9779389338845776, "Avg loss": 0.7900838651694357, "Avg value loss": 0.5271375161828473, "Avg policy loss": 0.2629463340854272, "Total num played games": 29509, "Total num trained steps": 58368, "Timestamp in ms": 1699740721047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9822433073534396, "Avg loss": 0.6317264146637172, "Avg value loss": 0.35817815200425684, "Avg policy loss": 0.27354826673399657, "Total num played games": 29510, "Total num trained steps": 58496, "Timestamp in ms": 1699740780694, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 194.00444593653083, "Avg game time in secs": 1.3710823525616433, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 29568, "Total num trained steps": 58614, "Timestamp in ms": 1699740834458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97983789260385, "Avg loss": 0.5595602213870734, "Avg value loss": 0.2896613102639094, "Avg policy loss": 0.26989891147240996, "Total num played games": 29610, "Total num trained steps": 58624, "Timestamp in ms": 1699740838828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809832085777868, "Avg loss": 0.8298395597375929, "Avg value loss": 0.543775899335742, "Avg policy loss": 0.28606365679297596, "Total num played games": 29658, "Total num trained steps": 58752, "Timestamp in ms": 1699740901454, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 97.9414891730994, "Avg game time in secs": 1.1064492161967792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 29696, "Total num trained steps": 58808, "Timestamp in ms": 1699740932400, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820574968019928, "Avg loss": 0.5828588660806417, "Avg value loss": 0.3083912000292912, "Avg policy loss": 0.27446766337379813, "Total num played games": 29706, "Total num trained steps": 58880, "Timestamp in ms": 1699740969561, "logtype": "training_step"}
{"Total num played games": 29757, "Total num trained steps": 58956, "Timestamp in ms": 1699741032387, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.43359375}
{"Ratio train steps to played games": 1.979768495218923, "Avg loss": 0.718100497033447, "Avg value loss": 0.4333761121961288, "Avg policy loss": 0.28472438897006214, "Total num played games": 29805, "Total num trained steps": 59008, "Timestamp in ms": 1699741058016, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 167.9989809654653, "Avg game time in secs": 1.1431865307094995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 29824, "Total num trained steps": 59101, "Timestamp in ms": 1699741100399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980906441563662, "Avg loss": 0.7794110216200352, "Avg value loss": 0.5021909581264481, "Avg policy loss": 0.2772200661711395, "Total num played games": 29853, "Total num trained steps": 59136, "Timestamp in ms": 1699741115076, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811125225646855, "Avg loss": 0.7421527721453458, "Avg value loss": 0.45142312796087936, "Avg policy loss": 0.2907296495977789, "Total num played games": 29914, "Total num trained steps": 59264, "Timestamp in ms": 1699741172318, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 97.2226576115936, "Avg game time in secs": 1.1888507256371668, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 29952, "Total num trained steps": 59320, "Timestamp in ms": 1699741197622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822108003471064, "Avg loss": 0.5960142347030342, "Avg value loss": 0.30076633050339296, "Avg policy loss": 0.2952479034429416, "Total num played games": 29962, "Total num trained steps": 59392, "Timestamp in ms": 1699741229317, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980138399095083, "Avg loss": 0.7584252904634923, "Avg value loss": 0.4631557898246683, "Avg policy loss": 0.29526949347928166, "Total num played games": 30058, "Total num trained steps": 59520, "Timestamp in ms": 1699741286891, "logtype": "training_step"}
{"Total num played games": 30059, "Total num trained steps": 59556, "Timestamp in ms": 1699741347476, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.4140625}
{"Avg objective": 22.6171875, "Games time in secs": 151.5624252911657, "Avg game time in secs": 1.1896103555773152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.54, "agent_stopped_0": 0.48}, "Total num played games": 30080, "Total num trained steps": 59559, "Timestamp in ms": 1699741349184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981200385292457, "Avg loss": 0.8754805449862033, "Avg value loss": 0.5802590056555346, "Avg policy loss": 0.2952215374680236, "Total num played games": 30107, "Total num trained steps": 59648, "Timestamp in ms": 1699741390073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821925984878632, "Avg loss": 0.5434085424058139, "Avg value loss": 0.26565635873703286, "Avg policy loss": 0.27775218442548066, "Total num played games": 30156, "Total num trained steps": 59776, "Timestamp in ms": 1699741448251, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 113.43750464916229, "Avg game time in secs": 1.2460482079186477, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 30208, "Total num trained steps": 59809, "Timestamp in ms": 1699741462622, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830177436440677, "Avg loss": 0.630534399766475, "Avg value loss": 0.3493360076099634, "Avg policy loss": 0.28119839599821717, "Total num played games": 30208, "Total num trained steps": 59904, "Timestamp in ms": 1699741506228, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980894241874278, "Avg loss": 0.6005961869377643, "Avg value loss": 0.31300663482397795, "Avg policy loss": 0.28758955490775406, "Total num played games": 30305, "Total num trained steps": 60032, "Timestamp in ms": 1699741563369, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 134.99804225564003, "Avg game time in secs": 1.0628187737020198, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 30336, "Total num trained steps": 60102, "Timestamp in ms": 1699741597620, "logtype": "played_game"}
{"Total num played games": 30353, "Total num trained steps": 60158, "Timestamp in ms": 1699741670290, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.60546875}
{"Ratio train steps to played games": 1.981228387946649, "Avg loss": 0.5538360474165529, "Avg value loss": 0.275181915378198, "Avg policy loss": 0.27865413459949195, "Total num played games": 30363, "Total num trained steps": 60160, "Timestamp in ms": 1699741671989, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983092661425611, "Avg loss": 0.7120696508791298, "Avg value loss": 0.41740591649431735, "Avg policy loss": 0.2946637322893366, "Total num played games": 30401, "Total num trained steps": 60288, "Timestamp in ms": 1699741729272, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 185.56051412411034, "Avg game time in secs": 1.240829954331275, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 30464, "Total num trained steps": 60405, "Timestamp in ms": 1699741783181, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980462859765292, "Avg loss": 0.7778349765576422, "Avg value loss": 0.4918708192417398, "Avg policy loss": 0.2859641556860879, "Total num played games": 30506, "Total num trained steps": 60416, "Timestamp in ms": 1699741787864, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981119109947644, "Avg loss": 0.8317464159335941, "Avg value loss": 0.5441789168398827, "Avg policy loss": 0.2875674953684211, "Total num played games": 30560, "Total num trained steps": 60544, "Timestamp in ms": 1699741844368, "logtype": "training_step"}
{"Avg objective": 23.0390625, "Games time in secs": 91.53244475461543, "Avg game time in secs": 1.1018822620535502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 30592, "Total num trained steps": 60612, "Timestamp in ms": 1699741874713, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818057098059711, "Avg loss": 0.6788849546574056, "Avg value loss": 0.39677976217353716, "Avg policy loss": 0.2821051983628422, "Total num played games": 30614, "Total num trained steps": 60672, "Timestamp in ms": 1699741900742, "logtype": "training_step"}
{"Total num played games": 30662, "Total num trained steps": 60761, "Timestamp in ms": 1699741960028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.65234375}
{"Ratio train steps to played games": 1.9797785737544773, "Avg loss": 0.8014948214404285, "Avg value loss": 0.5046977491001599, "Avg policy loss": 0.2967970772879198, "Total num played games": 30710, "Total num trained steps": 60800, "Timestamp in ms": 1699741978017, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 152.5845995452255, "Avg game time in secs": 1.3818784993054578, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.67, "agent_stopped_0": 0.41}, "Total num played games": 30720, "Total num trained steps": 60910, "Timestamp in ms": 1699742027298, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808505104363092, "Avg loss": 0.5755142457783222, "Avg value loss": 0.2821482867002487, "Avg policy loss": 0.2933659548871219, "Total num played games": 30758, "Total num trained steps": 60928, "Timestamp in ms": 1699742034721, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819515678763877, "Avg loss": 0.6672826402354985, "Avg value loss": 0.37826091155875474, "Avg policy loss": 0.2890217329841107, "Total num played games": 30806, "Total num trained steps": 61056, "Timestamp in ms": 1699742092938, "logtype": "training_step"}
{"Avg objective": 22.8359375, "Games time in secs": 89.46325770951807, "Avg game time in secs": 1.3061750853521517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.59}, "Total num played games": 30848, "Total num trained steps": 61105, "Timestamp in ms": 1699742116761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982984378038504, "Avg loss": 0.8595154606737196, "Avg value loss": 0.5761126017314382, "Avg policy loss": 0.28340285213198513, "Total num played games": 30854, "Total num trained steps": 61184, "Timestamp in ms": 1699742152749, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982570735650768, "Avg loss": 0.7070715599693358, "Avg value loss": 0.408753793919459, "Avg policy loss": 0.2983177690766752, "Total num played games": 30925, "Total num trained steps": 61312, "Timestamp in ms": 1699742210108, "logtype": "training_step"}
{"Total num played games": 30973, "Total num trained steps": 61364, "Timestamp in ms": 1699742267836, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.97265625}
{"Avg objective": 20.5078125, "Games time in secs": 152.2894358355552, "Avg game time in secs": 1.5511778679938288, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.67, "agent_stopped_0": 0.48}, "Total num played games": 30976, "Total num trained steps": 61366, "Timestamp in ms": 1699742269051, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980561555075594, "Avg loss": 0.7881687935441732, "Avg value loss": 0.502208445686847, "Avg policy loss": 0.28596034180372953, "Total num played games": 31021, "Total num trained steps": 61440, "Timestamp in ms": 1699742302109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981621552029354, "Avg loss": 0.5214629743713886, "Avg value loss": 0.23880292975809425, "Avg policy loss": 0.2826600428670645, "Total num played games": 31069, "Total num trained steps": 61568, "Timestamp in ms": 1699742358622, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 116.70774008706212, "Avg game time in secs": 1.0651796862803167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 31104, "Total num trained steps": 61631, "Timestamp in ms": 1699742385759, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827104155284891, "Avg loss": 0.562496589962393, "Avg value loss": 0.2944179392652586, "Avg policy loss": 0.26807865290902555, "Total num played games": 31117, "Total num trained steps": 61696, "Timestamp in ms": 1699742414537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814114479841036, "Avg loss": 0.5177766904234886, "Avg value loss": 0.2433981243520975, "Avg policy loss": 0.2743785686325282, "Total num played games": 31200, "Total num trained steps": 61824, "Timestamp in ms": 1699742471172, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 133.02520345151424, "Avg game time in secs": 1.4566846884554252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.73, "agent_stopped_0": 0.41}, "Total num played games": 31232, "Total num trained steps": 61930, "Timestamp in ms": 1699742518785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811007003293786, "Avg loss": 0.6935825499240309, "Avg value loss": 0.4029579809284769, "Avg policy loss": 0.29062456591054797, "Total num played games": 31271, "Total num trained steps": 61952, "Timestamp in ms": 1699742528129, "logtype": "training_step"}
{"Total num played games": 31271, "Total num trained steps": 61964, "Timestamp in ms": 1699742552030, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0078125}
{"Ratio train steps to played games": 1.9821514096874102, "Avg loss": 0.5981887299567461, "Avg value loss": 0.30911076365737244, "Avg policy loss": 0.28907796449493617, "Total num played games": 31319, "Total num trained steps": 62080, "Timestamp in ms": 1699742605923, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 109.49781505391002, "Avg game time in secs": 1.239140575969941, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 31360, "Total num trained steps": 62131, "Timestamp in ms": 1699742628282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829779095342832, "Avg loss": 0.5034776981920004, "Avg value loss": 0.22510669520124793, "Avg policy loss": 0.27837100194301456, "Total num played games": 31371, "Total num trained steps": 62208, "Timestamp in ms": 1699742664963, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9811530638189676, "Avg loss": 0.5006767672020942, "Avg value loss": 0.23609671654412523, "Avg policy loss": 0.2645800426835194, "Total num played games": 31464, "Total num trained steps": 62336, "Timestamp in ms": 1699742721813, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 135.02140209823847, "Avg game time in secs": 1.249977811719873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.58, "agent_stopped_0": 0.53}, "Total num played games": 31488, "Total num trained steps": 62428, "Timestamp in ms": 1699742763304, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818827934130787, "Avg loss": 0.7001652580220252, "Avg value loss": 0.42932435957482085, "Avg policy loss": 0.27084089908748865, "Total num played games": 31517, "Total num trained steps": 62464, "Timestamp in ms": 1699742780044, "logtype": "training_step"}
{"Total num played games": 31572, "Total num trained steps": 62565, "Timestamp in ms": 1699742848160, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.79296875}
{"Avg objective": 21.890625, "Games time in secs": 88.29271621257067, "Avg game time in secs": 1.1689880653575528, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 31616, "Total num trained steps": 62574, "Timestamp in ms": 1699742851597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979506641366224, "Avg loss": 0.7724014325067401, "Avg value loss": 0.4969423835282214, "Avg policy loss": 0.2754590390250087, "Total num played games": 31620, "Total num trained steps": 62592, "Timestamp in ms": 1699742859818, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835547122074637, "Avg loss": 0.4655069704167545, "Avg value loss": 0.1912522537750192, "Avg policy loss": 0.27425471460446715, "Total num played games": 31620, "Total num trained steps": 62720, "Timestamp in ms": 1699742917648, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813051702395965, "Avg loss": 0.6391743298154324, "Avg value loss": 0.3654741805512458, "Avg policy loss": 0.2737001448404044, "Total num played games": 31720, "Total num trained steps": 62848, "Timestamp in ms": 1699742975787, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 162.04335929639637, "Avg game time in secs": 1.1764224884245778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.49, "agent_stopped_0": 0.59}, "Total num played games": 31744, "Total num trained steps": 62930, "Timestamp in ms": 1699743013640, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823407202216066, "Avg loss": 0.6028623688034713, "Avg value loss": 0.33336527581559494, "Avg policy loss": 0.2694970938609913, "Total num played games": 31768, "Total num trained steps": 62976, "Timestamp in ms": 1699743032801, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831552482715273, "Avg loss": 0.5572064658626914, "Avg value loss": 0.28841385699342936, "Avg policy loss": 0.26879260689020157, "Total num played games": 31820, "Total num trained steps": 63104, "Timestamp in ms": 1699743088694, "logtype": "training_step"}
{"Total num played games": 31869, "Total num trained steps": 63169, "Timestamp in ms": 1699743132477, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6015625}
{"Avg objective": 19.8203125, "Games time in secs": 119.93181056156754, "Avg game time in secs": 1.4465903189993696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.62}, "Total num played games": 31872, "Total num trained steps": 63171, "Timestamp in ms": 1699743133572, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811072469217033, "Avg loss": 0.6735224381554872, "Avg value loss": 0.40071444830391556, "Avg policy loss": 0.2728079871740192, "Total num played games": 31917, "Total num trained steps": 63232, "Timestamp in ms": 1699743160675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821367120287814, "Avg loss": 0.485272026155144, "Avg value loss": 0.2212059330777265, "Avg policy loss": 0.264066094532609, "Total num played games": 31965, "Total num trained steps": 63360, "Timestamp in ms": 1699743219453, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 114.02031548507512, "Avg game time in secs": 1.249565073332633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.51}, "Total num played games": 32000, "Total num trained steps": 63423, "Timestamp in ms": 1699743247593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831943273045325, "Avg loss": 0.5121061964891851, "Avg value loss": 0.24200740229571238, "Avg policy loss": 0.2700987949501723, "Total num played games": 32013, "Total num trained steps": 63488, "Timestamp in ms": 1699743277291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9813436322297318, "Avg loss": 0.5436150231398642, "Avg value loss": 0.2739227584679611, "Avg policy loss": 0.2696922661270946, "Total num played games": 32107, "Total num trained steps": 63616, "Timestamp in ms": 1699743336217, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 130.29322837106884, "Avg game time in secs": 1.1887723015825031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.52, "agent_stopped_0": 0.51}, "Total num played games": 32128, "Total num trained steps": 63708, "Timestamp in ms": 1699743377886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821817277193856, "Avg loss": 0.5883915892336518, "Avg value loss": 0.30818688799627125, "Avg policy loss": 0.28020470042247325, "Total num played games": 32158, "Total num trained steps": 63744, "Timestamp in ms": 1699743393299, "logtype": "training_step"}
{"Total num played games": 32158, "Total num trained steps": 63769, "Timestamp in ms": 1699743422293, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.81640625}
{"Ratio train steps to played games": 1.983201887846985, "Avg loss": 0.44772253721021116, "Avg value loss": 0.176919644291047, "Avg policy loss": 0.27080289472360164, "Total num played games": 32206, "Total num trained steps": 63872, "Timestamp in ms": 1699743469171, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841269841269842, "Avg loss": 0.5878249180968851, "Avg value loss": 0.32322721427772194, "Avg policy loss": 0.26459770917426795, "Total num played games": 32255, "Total num trained steps": 64000, "Timestamp in ms": 1699743529069, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 151.18357856944203, "Avg game time in secs": 1.357189409493003, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.64}, "Total num played games": 32256, "Total num trained steps": 64000, "Timestamp in ms": 1699743529070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9818586395524924, "Avg loss": 0.6955875684507191, "Avg value loss": 0.4194598346366547, "Avg policy loss": 0.2761277339886874, "Total num played games": 32357, "Total num trained steps": 64128, "Timestamp in ms": 1699743585921, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 91.27943084202707, "Avg game time in secs": 1.1847895023674937, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.53}, "Total num played games": 32384, "Total num trained steps": 64206, "Timestamp in ms": 1699743620349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9826282822672714, "Avg loss": 0.6821634860243648, "Avg value loss": 0.38782008917769417, "Avg policy loss": 0.29434338852297515, "Total num played games": 32409, "Total num trained steps": 64256, "Timestamp in ms": 1699743642746, "logtype": "training_step"}
{"Total num played games": 32457, "Total num trained steps": 64371, "Timestamp in ms": 1699743709532, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.89453125}
{"Ratio train steps to played games": 1.9807106598984772, "Avg loss": 0.5857425758149475, "Avg value loss": 0.29700686066644266, "Avg policy loss": 0.28873571823351085, "Total num played games": 32505, "Total num trained steps": 64384, "Timestamp in ms": 1699743715774, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 148.63198190927505, "Avg game time in secs": 1.3409998214774532, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.64}, "Total num played games": 32512, "Total num trained steps": 64500, "Timestamp in ms": 1699743768981, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9814177775047608, "Avg loss": 0.567377059487626, "Avg value loss": 0.2836313176085241, "Avg policy loss": 0.28374573856126517, "Total num played games": 32558, "Total num trained steps": 64512, "Timestamp in ms": 1699743773777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820618177358027, "Avg loss": 0.5453563390765339, "Avg value loss": 0.2656166930682957, "Avg policy loss": 0.27973964787088335, "Total num played games": 32612, "Total num trained steps": 64640, "Timestamp in ms": 1699743831378, "logtype": "training_step"}
{"Avg objective": 20.359375, "Games time in secs": 95.42126529663801, "Avg game time in secs": 1.148000858942396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 32640, "Total num trained steps": 64715, "Timestamp in ms": 1699743864403, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829164498055905, "Avg loss": 0.6316593047231436, "Avg value loss": 0.3490667807054706, "Avg policy loss": 0.28259252291172743, "Total num played games": 32663, "Total num trained steps": 64768, "Timestamp in ms": 1699743887657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838892115802025, "Avg loss": 0.6371604113373905, "Avg value loss": 0.3581944770994596, "Avg policy loss": 0.27896593476179987, "Total num played games": 32711, "Total num trained steps": 64896, "Timestamp in ms": 1699743945741, "logtype": "training_step"}
{"Total num played games": 32759, "Total num trained steps": 64974, "Timestamp in ms": 1699744000444, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8828125}
{"Avg objective": 22.2734375, "Games time in secs": 137.2729033511132, "Avg game time in secs": 1.3037544978869846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.58, "agent_stopped_0": 0.49}, "Total num played games": 32768, "Total num trained steps": 64975, "Timestamp in ms": 1699744001676, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9819855518639315, "Avg loss": 0.6190820841584355, "Avg value loss": 0.34699076920514926, "Avg policy loss": 0.2720913130324334, "Total num played games": 32807, "Total num trained steps": 65024, "Timestamp in ms": 1699744025547, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9829559289018748, "Avg loss": 0.6631000866182148, "Avg value loss": 0.3907594319898635, "Avg policy loss": 0.2723406597506255, "Total num played games": 32856, "Total num trained steps": 65152, "Timestamp in ms": 1699744082587, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 103.05756904371083, "Avg game time in secs": 1.187955995555967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 32896, "Total num trained steps": 65204, "Timestamp in ms": 1699744104734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838930253760827, "Avg loss": 0.5203457602765411, "Avg value loss": 0.24738900095690042, "Avg policy loss": 0.2729567587375641, "Total num played games": 32905, "Total num trained steps": 65280, "Timestamp in ms": 1699744139562, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982000545438017, "Avg loss": 0.5240950367879122, "Avg value loss": 0.24990545841865242, "Avg policy loss": 0.2741895775543526, "Total num played games": 33001, "Total num trained steps": 65408, "Timestamp in ms": 1699744195857, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 129.69024521298707, "Avg game time in secs": 1.1459242402052041, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 33024, "Total num trained steps": 65492, "Timestamp in ms": 1699744234424, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9829646887954249, "Avg loss": 0.5835382689256221, "Avg value loss": 0.31105976505205035, "Avg policy loss": 0.27247850503772497, "Total num played games": 33049, "Total num trained steps": 65536, "Timestamp in ms": 1699744254569, "logtype": "training_step"}
{"Total num played games": 33049, "Total num trained steps": 65577, "Timestamp in ms": 1699744289980, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.42578125}
{"Ratio train steps to played games": 1.9839562498111611, "Avg loss": 0.6082073720172048, "Avg value loss": 0.3386602778919041, "Avg policy loss": 0.2695470943581313, "Total num played games": 33097, "Total num trained steps": 65664, "Timestamp in ms": 1699744328944, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 147.69443322718143, "Avg game time in secs": 1.2722321440814994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.58}, "Total num played games": 33152, "Total num trained steps": 65780, "Timestamp in ms": 1699744382118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821046606212154, "Avg loss": 0.5867249509319663, "Avg value loss": 0.31977492867736146, "Avg policy loss": 0.2669500248739496, "Total num played games": 33193, "Total num trained steps": 65792, "Timestamp in ms": 1699744387902, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9830034293965466, "Avg loss": 0.64592026011087, "Avg value loss": 0.37578799173934385, "Avg policy loss": 0.2701322687789798, "Total num played games": 33242, "Total num trained steps": 65920, "Timestamp in ms": 1699744445682, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 88.31785775534809, "Avg game time in secs": 1.0875132812507218, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 33280, "Total num trained steps": 65976, "Timestamp in ms": 1699744470436, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839891859417242, "Avg loss": 0.6022889313753694, "Avg value loss": 0.343365985667333, "Avg policy loss": 0.2589229515288025, "Total num played games": 33290, "Total num trained steps": 66048, "Timestamp in ms": 1699744503318, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820588851948364, "Avg loss": 0.5375725170597434, "Avg value loss": 0.2748871010844596, "Avg policy loss": 0.26268541428726166, "Total num played games": 33387, "Total num trained steps": 66176, "Timestamp in ms": 1699744561823, "logtype": "training_step"}
{"Total num played games": 33390, "Total num trained steps": 66177, "Timestamp in ms": 1699744578298, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5859375}
{"Avg objective": 21.15625, "Games time in secs": 109.55299653299153, "Avg game time in secs": 1.1841184610821074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 33408, "Total num trained steps": 66179, "Timestamp in ms": 1699744579990, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982863807643998, "Avg loss": 0.7524522375315428, "Avg value loss": 0.4781805103411898, "Avg policy loss": 0.2742717310320586, "Total num played games": 33438, "Total num trained steps": 66304, "Timestamp in ms": 1699744638111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833701558488088, "Avg loss": 0.5126017448492348, "Avg value loss": 0.2612446575658396, "Avg policy loss": 0.2513570880983025, "Total num played games": 33494, "Total num trained steps": 66432, "Timestamp in ms": 1699744697501, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 141.12369137071073, "Avg game time in secs": 1.1352842039632378, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 33536, "Total num trained steps": 66481, "Timestamp in ms": 1699744721114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843479816349652, "Avg loss": 0.5969714855309576, "Avg value loss": 0.3431606784579344, "Avg policy loss": 0.2538108028238639, "Total num played games": 33542, "Total num trained steps": 66560, "Timestamp in ms": 1699744757482, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982372175980975, "Avg loss": 0.553565351292491, "Avg value loss": 0.31256957340519875, "Avg policy loss": 0.24099577439483255, "Total num played games": 33640, "Total num trained steps": 66688, "Timestamp in ms": 1699744814144, "logtype": "training_step"}
{"Avg objective": 21.046875, "Games time in secs": 130.3960839174688, "Avg game time in secs": 1.2641274790803436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 33664, "Total num trained steps": 66771, "Timestamp in ms": 1699744851510, "logtype": "played_game"}
{"Total num played games": 33690, "Total num trained steps": 66781, "Timestamp in ms": 1699744873765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.80078125}
{"Ratio train steps to played games": 1.9804078487165808, "Avg loss": 0.7801408504601568, "Avg value loss": 0.530989661521744, "Avg policy loss": 0.24915118527133018, "Total num played games": 33738, "Total num trained steps": 66816, "Timestamp in ms": 1699744890298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9842017902661686, "Avg loss": 0.40375588450115174, "Avg value loss": 0.1602724051917903, "Avg policy loss": 0.24348347762133926, "Total num played games": 33738, "Total num trained steps": 66944, "Timestamp in ms": 1699744947706, "logtype": "training_step"}
{"Avg objective": 20.734375, "Games time in secs": 151.27240538783371, "Avg game time in secs": 1.1983651977207046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 33792, "Total num trained steps": 67064, "Timestamp in ms": 1699745002782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982237853174134, "Avg loss": 0.49543253413867205, "Avg value loss": 0.2618363383808173, "Avg policy loss": 0.23359619604889303, "Total num played games": 33836, "Total num trained steps": 67072, "Timestamp in ms": 1699745006048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9831488859377306, "Avg loss": 0.6866136265452951, "Avg value loss": 0.44331051147310063, "Avg policy loss": 0.24330311140511185, "Total num played games": 33885, "Total num trained steps": 67200, "Timestamp in ms": 1699745065777, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 92.82744283042848, "Avg game time in secs": 1.0153265410626773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.43}, "Total num played games": 33920, "Total num trained steps": 67261, "Timestamp in ms": 1699745095610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984115757522176, "Avg loss": 0.5548864759039134, "Avg value loss": 0.31363140838220716, "Avg policy loss": 0.24125506810378283, "Total num played games": 33933, "Total num trained steps": 67328, "Timestamp in ms": 1699745125056, "logtype": "training_step"}
{"Total num played games": 33981, "Total num trained steps": 67381, "Timestamp in ms": 1699745168282, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.43359375}
{"Ratio train steps to played games": 1.9822798201533987, "Avg loss": 0.7257767657283694, "Avg value loss": 0.46956878469791263, "Avg policy loss": 0.2562079761410132, "Total num played games": 34029, "Total num trained steps": 67456, "Timestamp in ms": 1699745202198, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 151.40739333443344, "Avg game time in secs": 1.1647733875870472, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 34048, "Total num trained steps": 67548, "Timestamp in ms": 1699745247017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832438301493676, "Avg loss": 0.5183220296166837, "Avg value loss": 0.2744268251117319, "Avg policy loss": 0.24389521370176226, "Total num played games": 34077, "Total num trained steps": 67584, "Timestamp in ms": 1699745263222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837981952420016, "Avg loss": 0.7037765423301607, "Avg value loss": 0.4520136343780905, "Avg policy loss": 0.25176290527451783, "Total num played games": 34132, "Total num trained steps": 67712, "Timestamp in ms": 1699745321553, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 94.87870000116527, "Avg game time in secs": 1.2259491654258454, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 34176, "Total num trained steps": 67755, "Timestamp in ms": 1699745341896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847571679344647, "Avg loss": 0.5652638890314847, "Avg value loss": 0.3059719709563069, "Avg policy loss": 0.2592919176677242, "Total num played games": 34180, "Total num trained steps": 67840, "Timestamp in ms": 1699745380977, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825569524254003, "Avg loss": 0.6404252741485834, "Avg value loss": 0.39076066750567406, "Avg policy loss": 0.24966460769064724, "Total num played games": 34283, "Total num trained steps": 67968, "Timestamp in ms": 1699745439393, "logtype": "training_step"}
{"Total num played games": 34283, "Total num trained steps": 67985, "Timestamp in ms": 1699745475198, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.87890625}
{"Avg objective": 21.328125, "Games time in secs": 135.0745588093996, "Avg game time in secs": 1.1684220647293841, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 34304, "Total num trained steps": 67987, "Timestamp in ms": 1699745476972, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834843144679735, "Avg loss": 0.6069890556391329, "Avg value loss": 0.3471746436553076, "Avg policy loss": 0.2598144107032567, "Total num played games": 34331, "Total num trained steps": 68096, "Timestamp in ms": 1699745525162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984322736395102, "Avg loss": 0.44137045310344547, "Avg value loss": 0.20218424126505852, "Avg policy loss": 0.23918621300254017, "Total num played games": 34381, "Total num trained steps": 68224, "Timestamp in ms": 1699745585420, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 124.71729265898466, "Avg game time in secs": 1.3540400330966804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 34432, "Total num trained steps": 68257, "Timestamp in ms": 1699745601689, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850434176516714, "Avg loss": 0.512419244972989, "Avg value loss": 0.27427530591376126, "Avg policy loss": 0.23814394127111882, "Total num played games": 34433, "Total num trained steps": 68352, "Timestamp in ms": 1699745643923, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832604477395812, "Avg loss": 0.6744533372111619, "Avg value loss": 0.4255472272634506, "Avg policy loss": 0.24890611274167895, "Total num played games": 34529, "Total num trained steps": 68480, "Timestamp in ms": 1699745704033, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 136.14409326948225, "Avg game time in secs": 1.0472491428081412, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.4, "agent_stopped_0": 0.64}, "Total num played games": 34560, "Total num trained steps": 68550, "Timestamp in ms": 1699745737834, "logtype": "played_game"}
{"Total num played games": 34577, "Total num trained steps": 68587, "Timestamp in ms": 1699745822662, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.671875}
{"Ratio train steps to played games": 1.9814296028880867, "Avg loss": 0.6619940206874162, "Avg value loss": 0.413276094943285, "Avg policy loss": 0.2487179241143167, "Total num played games": 34625, "Total num trained steps": 68608, "Timestamp in ms": 1699745832694, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851263537906136, "Avg loss": 0.4921050937846303, "Avg value loss": 0.23476958513492718, "Avg policy loss": 0.2573355104541406, "Total num played games": 34625, "Total num trained steps": 68736, "Timestamp in ms": 1699745891738, "logtype": "training_step"}
{"Avg objective": 23.6171875, "Games time in secs": 200.73171943612397, "Avg game time in secs": 1.2380923078017076, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 34688, "Total num trained steps": 68836, "Timestamp in ms": 1699745938565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833530140260938, "Avg loss": 0.6591283131856471, "Avg value loss": 0.40981812949758023, "Avg policy loss": 0.24931018089409918, "Total num played games": 34721, "Total num trained steps": 68864, "Timestamp in ms": 1699745950809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984267594696425, "Avg loss": 0.47719357442110777, "Avg value loss": 0.23205189598957077, "Avg policy loss": 0.2451416776748374, "Total num played games": 34769, "Total num trained steps": 68992, "Timestamp in ms": 1699746009589, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 88.52392701432109, "Avg game time in secs": 1.208854605225497, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 34816, "Total num trained steps": 69032, "Timestamp in ms": 1699746027090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848950406340637, "Avg loss": 0.4819060505833477, "Avg value loss": 0.2371938211726956, "Avg policy loss": 0.24471222388092428, "Total num played games": 34823, "Total num trained steps": 69120, "Timestamp in ms": 1699746066455, "logtype": "training_step"}
{"Total num played games": 34871, "Total num trained steps": 69187, "Timestamp in ms": 1699746152415, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6328125}
{"Ratio train steps to played games": 1.9830751166986453, "Avg loss": 0.7239268568810076, "Avg value loss": 0.4633246786543168, "Avg policy loss": 0.2606021730462089, "Total num played games": 34919, "Total num trained steps": 69248, "Timestamp in ms": 1699746180475, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 189.33015771768987, "Avg game time in secs": 1.2002821302448865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.51, "agent_stopped_0": 0.58}, "Total num played games": 34944, "Total num trained steps": 69328, "Timestamp in ms": 1699746216420, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840134984413875, "Avg loss": 0.5811083086300641, "Avg value loss": 0.31990206107730046, "Avg policy loss": 0.261206250754185, "Total num played games": 34967, "Total num trained steps": 69376, "Timestamp in ms": 1699746238108, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9847792563824318, "Avg loss": 0.5519720802549273, "Avg value loss": 0.28753713035257533, "Avg policy loss": 0.2644349472830072, "Total num played games": 35018, "Total num trained steps": 69504, "Timestamp in ms": 1699746298206, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 136.87971369549632, "Avg game time in secs": 1.2071011523948982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 35072, "Total num trained steps": 69628, "Timestamp in ms": 1699746353300, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831111870585554, "Avg loss": 0.6251052401494235, "Avg value loss": 0.3607899434864521, "Avg policy loss": 0.26431529747787863, "Total num played games": 35110, "Total num trained steps": 69632, "Timestamp in ms": 1699746354765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837342888016833, "Avg loss": 0.598182218382135, "Avg value loss": 0.3240411850856617, "Avg policy loss": 0.27414103772025555, "Total num played games": 35166, "Total num trained steps": 69760, "Timestamp in ms": 1699746410965, "logtype": "training_step"}
{"Total num played games": 35166, "Total num trained steps": 69791, "Timestamp in ms": 1699746443054, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.68359375}
{"Avg objective": 21.78125, "Games time in secs": 92.14685840718448, "Avg game time in secs": 1.0857631034014048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 35200, "Total num trained steps": 69795, "Timestamp in ms": 1699746445447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846651899812575, "Avg loss": 0.6359435056801885, "Avg value loss": 0.3669627271592617, "Avg policy loss": 0.26898077386431396, "Total num played games": 35214, "Total num trained steps": 69888, "Timestamp in ms": 1699746487261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854246419963135, "Avg loss": 0.5541348548140377, "Avg value loss": 0.2843354375218041, "Avg policy loss": 0.26979941758327186, "Total num played games": 35265, "Total num trained steps": 70016, "Timestamp in ms": 1699746543972, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 146.32800437696278, "Avg game time in secs": 1.3534266953211045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 35328, "Total num trained steps": 70122, "Timestamp in ms": 1699746591775, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834577536477773, "Avg loss": 0.7493415153585374, "Avg value loss": 0.4759876444004476, "Avg policy loss": 0.2733538676984608, "Total num played games": 35364, "Total num trained steps": 70144, "Timestamp in ms": 1699746601215, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843838246921948, "Avg loss": 0.6609384312760085, "Avg value loss": 0.3903340712422505, "Avg policy loss": 0.2706043622456491, "Total num played games": 35412, "Total num trained steps": 70272, "Timestamp in ms": 1699746663940, "logtype": "training_step"}
{"Avg objective": 23.046875, "Games time in secs": 96.72285974025726, "Avg game time in secs": 1.1898304446513066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.54}, "Total num played games": 35456, "Total num trained steps": 70317, "Timestamp in ms": 1699746688498, "logtype": "played_game"}
{"Total num played games": 35460, "Total num trained steps": 70392, "Timestamp in ms": 1699746744548, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.71875}
{"Ratio train steps to played games": 1.982763476595505, "Avg loss": 0.6010645935311913, "Avg value loss": 0.33307669596979395, "Avg policy loss": 0.26798790064640343, "Total num played games": 35506, "Total num trained steps": 70400, "Timestamp in ms": 1699746748741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9834912956661135, "Avg loss": 0.5953671985771507, "Avg value loss": 0.32115943171083927, "Avg policy loss": 0.27420776698272675, "Total num played games": 35557, "Total num trained steps": 70528, "Timestamp in ms": 1699746806400, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 153.01951636001468, "Avg game time in secs": 1.26700531996903, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.5, "agent_stopped_0": 0.59}, "Total num played games": 35584, "Total num trained steps": 70605, "Timestamp in ms": 1699746841517, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844123016430277, "Avg loss": 0.6361711972858757, "Avg value loss": 0.3552689566859044, "Avg policy loss": 0.2809022341389209, "Total num played games": 35605, "Total num trained steps": 70656, "Timestamp in ms": 1699746863354, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853031917877377, "Avg loss": 0.5679366749245673, "Avg value loss": 0.29031771689187735, "Avg policy loss": 0.27761895733419806, "Total num played games": 35654, "Total num trained steps": 70784, "Timestamp in ms": 1699746921145, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 130.1754562202841, "Avg game time in secs": 1.253167515838868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.52}, "Total num played games": 35712, "Total num trained steps": 70896, "Timestamp in ms": 1699746971693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9834969651198568, "Avg loss": 0.6598883371334523, "Avg value loss": 0.3847594883409329, "Avg policy loss": 0.27512885234318674, "Total num played games": 35751, "Total num trained steps": 70912, "Timestamp in ms": 1699746978524, "logtype": "training_step"}
{"Total num played games": 35800, "Total num trained steps": 70996, "Timestamp in ms": 1699747055399, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.59765625}
{"Avg objective": 22.1015625, "Games time in secs": 86.97075522132218, "Avg game time in secs": 1.264813962916378, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 35840, "Total num trained steps": 71002, "Timestamp in ms": 1699747058664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816726177192592, "Avg loss": 0.9330979497171938, "Avg value loss": 0.6457842040108517, "Avg policy loss": 0.2873137505957857, "Total num played games": 35848, "Total num trained steps": 71040, "Timestamp in ms": 1699747075924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852711448337426, "Avg loss": 0.4608357511460781, "Avg value loss": 0.18665042874636129, "Avg policy loss": 0.27418532234150916, "Total num played games": 35848, "Total num trained steps": 71168, "Timestamp in ms": 1699747134096, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98355729905684, "Avg loss": 0.5909675643779337, "Avg value loss": 0.32321941578993574, "Avg policy loss": 0.26774814689997584, "Total num played games": 35943, "Total num trained steps": 71296, "Timestamp in ms": 1699747192006, "logtype": "training_step"}
{"Avg objective": 22.765625, "Games time in secs": 171.22370886430144, "Avg game time in secs": 1.2254440832912223, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.5, "agent_stopped_0": 0.57}, "Total num played games": 35968, "Total num trained steps": 71380, "Timestamp in ms": 1699747229888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843307217869646, "Avg loss": 0.5737381619401276, "Avg value loss": 0.31378817779477686, "Avg policy loss": 0.2599499822827056, "Total num played games": 35994, "Total num trained steps": 71424, "Timestamp in ms": 1699747249349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848812694185531, "Avg loss": 0.6153911766596138, "Avg value loss": 0.34946185210719705, "Avg policy loss": 0.2659293240867555, "Total num played games": 36048, "Total num trained steps": 71552, "Timestamp in ms": 1699747307023, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 96.65459005907178, "Avg game time in secs": 1.4544259165559197, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.72, "agent_stopped_0": 0.38}, "Total num played games": 36096, "Total num trained steps": 71594, "Timestamp in ms": 1699747326543, "logtype": "played_game"}
{"Total num played games": 36096, "Total num trained steps": 71596, "Timestamp in ms": 1699747386435, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4921875}
{"Ratio train steps to played games": 1.983178397521027, "Avg loss": 0.8772668926976621, "Avg value loss": 0.5910308884922415, "Avg policy loss": 0.28623600711580366, "Total num played games": 36144, "Total num trained steps": 71680, "Timestamp in ms": 1699747424714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840300610615311, "Avg loss": 0.5296136443503201, "Avg value loss": 0.2534992747241631, "Avg policy loss": 0.2761143691604957, "Total num played games": 36193, "Total num trained steps": 71808, "Timestamp in ms": 1699747482398, "logtype": "training_step"}
{"Avg objective": 23.84375, "Games time in secs": 187.73120949044824, "Avg game time in secs": 1.1315227893937845, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 36224, "Total num trained steps": 71878, "Timestamp in ms": 1699747514274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846875431093944, "Avg loss": 0.6027565016411245, "Avg value loss": 0.31598513142671436, "Avg policy loss": 0.2867713732412085, "Total num played games": 36245, "Total num trained steps": 71936, "Timestamp in ms": 1699747540529, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985589507618549, "Avg loss": 0.5002347107511014, "Avg value loss": 0.21784360910532996, "Avg policy loss": 0.2823910961160436, "Total num played games": 36293, "Total num trained steps": 72064, "Timestamp in ms": 1699747598963, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859701246183048, "Avg loss": 0.4927532479632646, "Avg value loss": 0.20784002222353593, "Avg policy loss": 0.2849132284754887, "Total num played games": 36351, "Total num trained steps": 72192, "Timestamp in ms": 1699747655914, "logtype": "training_step"}
{"Avg objective": 20.421875, "Games time in secs": 141.64445530250669, "Avg game time in secs": 1.5452821667713579, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.68, "agent_stopped_0": 0.47}, "Total num played games": 36352, "Total num trained steps": 72192, "Timestamp in ms": 1699747655918, "logtype": "played_game"}
{"Total num played games": 36401, "Total num trained steps": 72197, "Timestamp in ms": 1699747677412, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.640625}
{"Ratio train steps to played games": 1.9841147905292327, "Avg loss": 0.7717018423136324, "Avg value loss": 0.48647010960849, "Avg policy loss": 0.28523172764107585, "Total num played games": 36449, "Total num trained steps": 72320, "Timestamp in ms": 1699747734334, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 109.68586288206279, "Avg game time in secs": 1.0999044566124212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.41}, "Total num played games": 36480, "Total num trained steps": 72390, "Timestamp in ms": 1699747765604, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98503986629038, "Avg loss": 0.4948888656217605, "Avg value loss": 0.22717410780023783, "Avg policy loss": 0.2677147565409541, "Total num played games": 36497, "Total num trained steps": 72448, "Timestamp in ms": 1699747792337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858264700248995, "Avg loss": 0.48701630416326225, "Avg value loss": 0.2173227079329081, "Avg policy loss": 0.26969359547365457, "Total num played games": 36547, "Total num trained steps": 72576, "Timestamp in ms": 1699747851244, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 133.6015986315906, "Avg game time in secs": 1.3366954256343888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 36608, "Total num trained steps": 72680, "Timestamp in ms": 1699747899206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984089730644325, "Avg loss": 0.6376438781153411, "Avg value loss": 0.36215264943894, "Avg policy loss": 0.2754912265809253, "Total num played games": 36643, "Total num trained steps": 72704, "Timestamp in ms": 1699747910021, "logtype": "training_step"}
{"Total num played games": 36691, "Total num trained steps": 72801, "Timestamp in ms": 1699747996714, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83203125}
{"Avg objective": 22.484375, "Games time in secs": 101.22717384807765, "Avg game time in secs": 1.2400307410571259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 36736, "Total num trained steps": 72808, "Timestamp in ms": 1699748000433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823892865891832, "Avg loss": 0.7209904813207686, "Avg value loss": 0.43560633179731667, "Avg policy loss": 0.28538414801005274, "Total num played games": 36739, "Total num trained steps": 72832, "Timestamp in ms": 1699748010474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985873322627181, "Avg loss": 0.4436577025335282, "Avg value loss": 0.15976417739875615, "Avg policy loss": 0.2838935242034495, "Total num played games": 36739, "Total num trained steps": 72960, "Timestamp in ms": 1699748070028, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841726618705036, "Avg loss": 0.6407962006051093, "Avg value loss": 0.3649256323114969, "Avg policy loss": 0.27587056637275964, "Total num played games": 36835, "Total num trained steps": 73088, "Timestamp in ms": 1699748129168, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 162.91141892410815, "Avg game time in secs": 1.1932597833219916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 36864, "Total num trained steps": 73162, "Timestamp in ms": 1699748163345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850070491269927, "Avg loss": 0.5620482973754406, "Avg value loss": 0.2834198022610508, "Avg policy loss": 0.2786284970352426, "Total num played games": 36884, "Total num trained steps": 73216, "Timestamp in ms": 1699748188808, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859200693165817, "Avg loss": 0.725046006264165, "Avg value loss": 0.44720152841182426, "Avg policy loss": 0.27784447837620974, "Total num played games": 36932, "Total num trained steps": 73344, "Timestamp in ms": 1699748247768, "logtype": "training_step"}
{"Total num played games": 36980, "Total num trained steps": 73404, "Timestamp in ms": 1699748310210, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5625}
{"Avg objective": 22.8984375, "Games time in secs": 148.33967025205493, "Avg game time in secs": 1.2895564452337567, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 36992, "Total num trained steps": 73405, "Timestamp in ms": 1699748311685, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842281516690072, "Avg loss": 0.8373901902232319, "Avg value loss": 0.5374810550129041, "Avg policy loss": 0.2999091378878802, "Total num played games": 37028, "Total num trained steps": 73472, "Timestamp in ms": 1699748343729, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849240810162085, "Avg loss": 0.5720749304164201, "Avg value loss": 0.293346275400836, "Avg policy loss": 0.2787286532111466, "Total num played games": 37079, "Total num trained steps": 73600, "Timestamp in ms": 1699748402956, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 114.37212214060128, "Avg game time in secs": 1.2468936777877389, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 37120, "Total num trained steps": 73650, "Timestamp in ms": 1699748426057, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857789269553976, "Avg loss": 0.6021165351849049, "Avg value loss": 0.3179357330664061, "Avg policy loss": 0.28418080031406134, "Total num played games": 37128, "Total num trained steps": 73728, "Timestamp in ms": 1699748461007, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9837765243083534, "Avg loss": 0.6704302213620394, "Avg value loss": 0.39218603499466553, "Avg policy loss": 0.27824418689124286, "Total num played games": 37230, "Total num trained steps": 73856, "Timestamp in ms": 1699748518235, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 134.86161271482706, "Avg game time in secs": 1.1972865429415833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 37248, "Total num trained steps": 73950, "Timestamp in ms": 1699748560919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846558291753849, "Avg loss": 0.7103126225993037, "Avg value loss": 0.4277670434676111, "Avg policy loss": 0.28254557866603136, "Total num played games": 37278, "Total num trained steps": 73984, "Timestamp in ms": 1699748575811, "logtype": "training_step"}
{"Total num played games": 37278, "Total num trained steps": 74008, "Timestamp in ms": 1699748611850, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.76171875}
{"Ratio train steps to played games": 1.9855328725285324, "Avg loss": 0.6797423241659999, "Avg value loss": 0.3945246423827484, "Avg policy loss": 0.28521768609061837, "Total num played games": 37326, "Total num trained steps": 74112, "Timestamp in ms": 1699748658909, "logtype": "training_step"}
{"Avg objective": 22.5, "Games time in secs": 112.50778377428651, "Avg game time in secs": 1.2219670091144508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.6}, "Total num played games": 37376, "Total num trained steps": 74146, "Timestamp in ms": 1699748673427, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859558076079395, "Avg loss": 0.5713506457395852, "Avg value loss": 0.29539444437250495, "Avg policy loss": 0.27595620218198746, "Total num played games": 37382, "Total num trained steps": 74240, "Timestamp in ms": 1699748715226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984257851063262, "Avg loss": 0.594001451972872, "Avg value loss": 0.31743830954656005, "Avg policy loss": 0.27656313811894506, "Total num played games": 37479, "Total num trained steps": 74368, "Timestamp in ms": 1699748773266, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 136.31017318367958, "Avg game time in secs": 1.1337480586807942, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.31, "played_steps": 0.38, "agent_stopped_0": 0.69}, "Total num played games": 37504, "Total num trained steps": 74449, "Timestamp in ms": 1699748809737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849720223820944, "Avg loss": 0.5635573593899608, "Avg value loss": 0.28591549629345536, "Avg policy loss": 0.27764186810236424, "Total num played games": 37530, "Total num trained steps": 74496, "Timestamp in ms": 1699748831131, "logtype": "training_step"}
{"Total num played games": 37578, "Total num trained steps": 74611, "Timestamp in ms": 1699748898198, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.734375}
{"Ratio train steps to played games": 1.9833094137032903, "Avg loss": 0.5663346466608346, "Avg value loss": 0.2954589289147407, "Avg policy loss": 0.27087571925949305, "Total num played games": 37626, "Total num trained steps": 74624, "Timestamp in ms": 1699748905047, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 149.7729717940092, "Avg game time in secs": 1.2402647955459543, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.5}, "Total num played games": 37632, "Total num trained steps": 74741, "Timestamp in ms": 1699748959510, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841008626410086, "Avg loss": 0.47626785724423826, "Avg value loss": 0.21649488946422935, "Avg policy loss": 0.25977297010831535, "Total num played games": 37675, "Total num trained steps": 74752, "Timestamp in ms": 1699748964039, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843907351460222, "Avg loss": 0.6302317522931844, "Avg value loss": 0.36783018929418176, "Avg policy loss": 0.2624015575274825, "Total num played games": 37734, "Total num trained steps": 74880, "Timestamp in ms": 1699749021632, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 97.25072286464274, "Avg game time in secs": 1.136242023902014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.43}, "Total num played games": 37760, "Total num trained steps": 74959, "Timestamp in ms": 1699749056761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851524454795682, "Avg loss": 0.5336253396235406, "Avg value loss": 0.2690255154739134, "Avg policy loss": 0.2645998306106776, "Total num played games": 37784, "Total num trained steps": 75008, "Timestamp in ms": 1699749079036, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860435610065552, "Avg loss": 0.541311907581985, "Avg value loss": 0.29092211689567193, "Avg policy loss": 0.25038979563396424, "Total num played games": 37832, "Total num trained steps": 75136, "Timestamp in ms": 1699749138638, "logtype": "training_step"}
{"Total num played games": 37881, "Total num trained steps": 75212, "Timestamp in ms": 1699749218525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7734375}
{"Avg objective": 21.640625, "Games time in secs": 163.06845048815012, "Avg game time in secs": 1.2187393243220868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 37888, "Total num trained steps": 75213, "Timestamp in ms": 1699749219830, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843127949590023, "Avg loss": 0.9530641252640635, "Avg value loss": 0.6856875118683092, "Avg policy loss": 0.26737662055529654, "Total num played games": 37929, "Total num trained steps": 75264, "Timestamp in ms": 1699749243749, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841566439455747, "Avg loss": 0.6087860623374581, "Avg value loss": 0.34817166783614084, "Avg policy loss": 0.2606143959565088, "Total num played games": 37997, "Total num trained steps": 75392, "Timestamp in ms": 1699749302185, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 125.00312846153975, "Avg game time in secs": 1.0866070373012917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.42}, "Total num played games": 38016, "Total num trained steps": 75484, "Timestamp in ms": 1699749344833, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849655679966356, "Avg loss": 0.5333162738243118, "Avg value loss": 0.28185606212355196, "Avg policy loss": 0.2514602073933929, "Total num played games": 38046, "Total num trained steps": 75520, "Timestamp in ms": 1699749360855, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858245392975271, "Avg loss": 0.5150860731955618, "Avg value loss": 0.26152377226389945, "Avg policy loss": 0.25356230011675507, "Total num played games": 38094, "Total num trained steps": 75648, "Timestamp in ms": 1699749419076, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 131.5660777427256, "Avg game time in secs": 1.1148417465446983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 38144, "Total num trained steps": 75774, "Timestamp in ms": 1699749476399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9850159794624613, "Avg loss": 0.5623563334811479, "Avg value loss": 0.31377913820324466, "Avg policy loss": 0.24857719615101814, "Total num played games": 38173, "Total num trained steps": 75776, "Timestamp in ms": 1699749477030, "logtype": "training_step"}
{"Total num played games": 38196, "Total num trained steps": 75812, "Timestamp in ms": 1699749535645, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.38671875}
{"Ratio train steps to played games": 1.9847034828992782, "Avg loss": 0.5502470801584423, "Avg value loss": 0.29271443362813443, "Avg policy loss": 0.25753264501690865, "Total num played games": 38244, "Total num trained steps": 75904, "Timestamp in ms": 1699749577949, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 136.80673323571682, "Avg game time in secs": 1.0589007628295803, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 38272, "Total num trained steps": 75979, "Timestamp in ms": 1699749613206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985558341167868, "Avg loss": 0.44265954196453094, "Avg value loss": 0.2039325031801127, "Avg policy loss": 0.23872703732922673, "Total num played games": 38292, "Total num trained steps": 76032, "Timestamp in ms": 1699749637588, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861520406832702, "Avg loss": 0.6602618752513081, "Avg value loss": 0.41038462199503556, "Avg policy loss": 0.24987725901883096, "Total num played games": 38345, "Total num trained steps": 76160, "Timestamp in ms": 1699749696154, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 135.80056564696133, "Avg game time in secs": 1.303353612369392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 38400, "Total num trained steps": 76276, "Timestamp in ms": 1699749749007, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844701108162948, "Avg loss": 0.580634844256565, "Avg value loss": 0.328422274265904, "Avg policy loss": 0.25221257156226784, "Total num played games": 38442, "Total num trained steps": 76288, "Timestamp in ms": 1699749754359, "logtype": "training_step"}
{"Total num played games": 38491, "Total num trained steps": 76413, "Timestamp in ms": 1699749843176, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.390625}
{"Ratio train steps to played games": 1.9838776675839866, "Avg loss": 0.7281990440096706, "Avg value loss": 0.47279105382040143, "Avg policy loss": 0.25540798041038215, "Total num played games": 38515, "Total num trained steps": 76416, "Timestamp in ms": 1699749845157, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 96.55803453549743, "Avg game time in secs": 1.2881012278667185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 38528, "Total num trained steps": 76417, "Timestamp in ms": 1699749845565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861179584317186, "Avg loss": 0.6980341759044677, "Avg value loss": 0.4329679599031806, "Avg policy loss": 0.2650662160012871, "Total num played games": 38539, "Total num trained steps": 76544, "Timestamp in ms": 1699749907079, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845218066519994, "Avg loss": 0.4779068829957396, "Avg value loss": 0.23260668950388208, "Avg policy loss": 0.24530019180383533, "Total num played games": 38635, "Total num trained steps": 76672, "Timestamp in ms": 1699749969093, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 163.76890192739666, "Avg game time in secs": 1.0849286549928365, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.35, "played_steps": 0.45, "agent_stopped_0": 0.65}, "Total num played games": 38656, "Total num trained steps": 76760, "Timestamp in ms": 1699750009334, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852910764140212, "Avg loss": 0.6038719235220924, "Avg value loss": 0.35954794607823715, "Avg policy loss": 0.24432398146018386, "Total num played games": 38684, "Total num trained steps": 76800, "Timestamp in ms": 1699750027964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861354951977692, "Avg loss": 0.46339683060068637, "Avg value loss": 0.22358562104636803, "Avg policy loss": 0.23981120681855828, "Total num played games": 38732, "Total num trained steps": 76928, "Timestamp in ms": 1699750087277, "logtype": "training_step"}
{"Total num played games": 38781, "Total num trained steps": 77013, "Timestamp in ms": 1699750143679, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.796875}
{"Avg objective": 21.296875, "Games time in secs": 135.3590643722564, "Avg game time in secs": 1.1948611698462628, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 38784, "Total num trained steps": 77013, "Timestamp in ms": 1699750144693, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9844703700842155, "Avg loss": 0.7081424982752651, "Avg value loss": 0.46136256196768954, "Avg policy loss": 0.24677993659861386, "Total num played games": 38829, "Total num trained steps": 77056, "Timestamp in ms": 1699750164669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9853383748746045, "Avg loss": 0.4759029874112457, "Avg value loss": 0.24168819980695844, "Avg policy loss": 0.23421478853560984, "Total num played games": 38877, "Total num trained steps": 77184, "Timestamp in ms": 1699750221348, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 103.97095952369273, "Avg game time in secs": 1.0006960607715882, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 38912, "Total num trained steps": 77246, "Timestamp in ms": 1699750248664, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858467545143972, "Avg loss": 0.5328955773729831, "Avg value loss": 0.2945434073335491, "Avg policy loss": 0.23835216846782714, "Total num played games": 38931, "Total num trained steps": 77312, "Timestamp in ms": 1699750277910, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867107929910979, "Avg loss": 0.46978723676875234, "Avg value loss": 0.2332812084350735, "Avg policy loss": 0.23650603159330785, "Total num played games": 38979, "Total num trained steps": 77440, "Timestamp in ms": 1699750335974, "logtype": "training_step"}
{"Avg objective": 21.890625, "Games time in secs": 136.86549457535148, "Avg game time in secs": 1.2089297830534633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.51}, "Total num played games": 39040, "Total num trained steps": 77552, "Timestamp in ms": 1699750385530, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846992298441777, "Avg loss": 0.5496233778540045, "Avg value loss": 0.31942996667930856, "Avg policy loss": 0.23019340238533914, "Total num played games": 39083, "Total num trained steps": 77568, "Timestamp in ms": 1699750391768, "logtype": "training_step"}
{"Total num played games": 39083, "Total num trained steps": 77616, "Timestamp in ms": 1699750431174, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6015625}
{"Ratio train steps to played games": 1.985535764483402, "Avg loss": 0.6526510268449783, "Avg value loss": 0.41166552546201274, "Avg policy loss": 0.2409855033038184, "Total num played games": 39131, "Total num trained steps": 77696, "Timestamp in ms": 1699750467772, "logtype": "training_step"}
{"Avg objective": 22.7890625, "Games time in secs": 108.04612205922604, "Avg game time in secs": 1.01036964195373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.37}, "Total num played games": 39168, "Total num trained steps": 77754, "Timestamp in ms": 1699750493576, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986370249368284, "Avg loss": 0.6938015160849318, "Avg value loss": 0.4610309343552217, "Avg policy loss": 0.23277058312669396, "Total num played games": 39179, "Total num trained steps": 77824, "Timestamp in ms": 1699750525684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869494290375205, "Avg loss": 0.5128903123550117, "Avg value loss": 0.27801547991111875, "Avg policy loss": 0.23487483081407845, "Total num played games": 39232, "Total num trained steps": 77952, "Timestamp in ms": 1699750584508, "logtype": "training_step"}
{"Avg objective": 19.7265625, "Games time in secs": 141.54247256740928, "Avg game time in secs": 1.301962429410196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 39296, "Total num trained steps": 78060, "Timestamp in ms": 1699750635118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847229283172343, "Avg loss": 0.5293724169023335, "Avg value loss": 0.29231577733298764, "Avg policy loss": 0.2370566418976523, "Total num played games": 39340, "Total num trained steps": 78080, "Timestamp in ms": 1699750644024, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855793642733828, "Avg loss": 0.6202471919823438, "Avg value loss": 0.37179419107269496, "Avg policy loss": 0.2484530033543706, "Total num played games": 39388, "Total num trained steps": 78208, "Timestamp in ms": 1699750703686, "logtype": "training_step"}
{"Total num played games": 39388, "Total num trained steps": 78217, "Timestamp in ms": 1699750728531, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.04296875}
{"Avg objective": 19.5078125, "Games time in secs": 95.81219180487096, "Avg game time in secs": 1.1134455908759264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 39424, "Total num trained steps": 78222, "Timestamp in ms": 1699750730931, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863830003042906, "Avg loss": 0.4508597522508353, "Avg value loss": 0.20960756740532815, "Avg policy loss": 0.24125218577682972, "Total num played games": 39436, "Total num trained steps": 78336, "Timestamp in ms": 1699750782280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849477598724987, "Avg loss": 0.5345295486040413, "Avg value loss": 0.28879367309855297, "Avg policy loss": 0.24573587183840573, "Total num played games": 39529, "Total num trained steps": 78464, "Timestamp in ms": 1699750840631, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 155.6105951126665, "Avg game time in secs": 1.220988013301394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 39552, "Total num trained steps": 78564, "Timestamp in ms": 1699750886541, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853985095364406, "Avg loss": 0.6587305865250528, "Avg value loss": 0.4031878688838333, "Avg policy loss": 0.2555427155457437, "Total num played games": 39585, "Total num trained steps": 78592, "Timestamp in ms": 1699750898322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861983700451644, "Avg loss": 0.6285829960834235, "Avg value loss": 0.3797424999647774, "Avg policy loss": 0.2488404930336401, "Total num played games": 39633, "Total num trained steps": 78720, "Timestamp in ms": 1699750955156, "logtype": "training_step"}
{"Avg objective": 20.9453125, "Games time in secs": 87.81856266781688, "Avg game time in secs": 1.1140502547932556, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 39680, "Total num trained steps": 78760, "Timestamp in ms": 1699750974360, "logtype": "played_game"}
{"Total num played games": 39686, "Total num trained steps": 78819, "Timestamp in ms": 1699751016735, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2109375}
{"Ratio train steps to played games": 1.9843962349625006, "Avg loss": 0.8434611726552248, "Avg value loss": 0.5914195804507472, "Avg policy loss": 0.2520415870239958, "Total num played games": 39734, "Total num trained steps": 78848, "Timestamp in ms": 1699751031513, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851444084156549, "Avg loss": 0.4752907988149673, "Avg value loss": 0.24075254565104842, "Avg policy loss": 0.23453825630713254, "Total num played games": 39783, "Total num trained steps": 78976, "Timestamp in ms": 1699751090069, "logtype": "training_step"}
{"Avg objective": 22.515625, "Games time in secs": 151.63289042375982, "Avg game time in secs": 1.2143858920317143, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 39808, "Total num trained steps": 79056, "Timestamp in ms": 1699751125993, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859657051040647, "Avg loss": 0.5105789010412991, "Avg value loss": 0.2640070107881911, "Avg policy loss": 0.2465718905441463, "Total num played games": 39831, "Total num trained steps": 79104, "Timestamp in ms": 1699751148115, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867850246997167, "Avg loss": 0.5506265098229051, "Avg value loss": 0.30980607692617923, "Avg policy loss": 0.2408204353414476, "Total num played games": 39879, "Total num trained steps": 79232, "Timestamp in ms": 1699751206462, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 130.97579666040838, "Avg game time in secs": 1.2774520760867745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.55}, "Total num played games": 39936, "Total num trained steps": 79344, "Timestamp in ms": 1699751256969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852157598499063, "Avg loss": 0.5593286941293627, "Avg value loss": 0.31739004905102775, "Avg policy loss": 0.24193863722030073, "Total num played games": 39975, "Total num trained steps": 79360, "Timestamp in ms": 1699751263625, "logtype": "training_step"}
{"Total num played games": 39975, "Total num trained steps": 79420, "Timestamp in ms": 1699751310170, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.046875}
{"Ratio train steps to played games": 1.9860330310071708, "Avg loss": 0.5363820556085557, "Avg value loss": 0.2842976783285849, "Avg policy loss": 0.2520843775710091, "Total num played games": 40023, "Total num trained steps": 79488, "Timestamp in ms": 1699751341566, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 107.05245093256235, "Avg game time in secs": 1.1190750024834415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 40064, "Total num trained steps": 79539, "Timestamp in ms": 1699751364022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986823717308844, "Avg loss": 0.4952355611603707, "Avg value loss": 0.24705697782337666, "Avg policy loss": 0.24817858485039324, "Total num played games": 40072, "Total num trained steps": 79616, "Timestamp in ms": 1699751400316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851136391924522, "Avg loss": 0.6401476617902517, "Avg value loss": 0.384452827333007, "Avg policy loss": 0.2556948373094201, "Total num played games": 40171, "Total num trained steps": 79744, "Timestamp in ms": 1699751456231, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 132.42166544683278, "Avg game time in secs": 1.301527813237044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.6, "agent_stopped_0": 0.55}, "Total num played games": 40192, "Total num trained steps": 79833, "Timestamp in ms": 1699751496443, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859021855342003, "Avg loss": 0.563572358340025, "Avg value loss": 0.3133730535628274, "Avg policy loss": 0.2501993029145524, "Total num played games": 40219, "Total num trained steps": 79872, "Timestamp in ms": 1699751513827, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864425297345616, "Avg loss": 0.5104350763140246, "Avg value loss": 0.2580143050290644, "Avg policy loss": 0.2524207681417465, "Total num played games": 40273, "Total num trained steps": 80000, "Timestamp in ms": 1699751573410, "logtype": "training_step"}
{"Total num played games": 40273, "Total num trained steps": 80020, "Timestamp in ms": 1699751595768, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.39453125}
{"Avg objective": 21.03125, "Games time in secs": 103.02783805318177, "Avg game time in secs": 1.1575713944766903, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 40320, "Total num trained steps": 80027, "Timestamp in ms": 1699751599472, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872523002901714, "Avg loss": 0.41834455565549433, "Avg value loss": 0.17368264123797417, "Avg policy loss": 0.24466191313695163, "Total num played games": 40321, "Total num trained steps": 80128, "Timestamp in ms": 1699751644949, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856252164877035, "Avg loss": 0.565497760544531, "Avg value loss": 0.31892867002170533, "Avg policy loss": 0.24656909005716443, "Total num played games": 40418, "Total num trained steps": 80256, "Timestamp in ms": 1699751702024, "logtype": "training_step"}
{"Avg objective": 22.9609375, "Games time in secs": 134.34809952042997, "Avg game time in secs": 1.1382658779621124, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.48, "agent_stopped_0": 0.58}, "Total num played games": 40448, "Total num trained steps": 80326, "Timestamp in ms": 1699751733820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986433054910295, "Avg loss": 0.5478039793670177, "Avg value loss": 0.28866544470656663, "Avg policy loss": 0.2591385378036648, "Total num played games": 40466, "Total num trained steps": 80384, "Timestamp in ms": 1699751760865, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987189929655683, "Avg loss": 0.5815930892713368, "Avg value loss": 0.316473608778324, "Avg policy loss": 0.2651194800855592, "Total num played games": 40515, "Total num trained steps": 80512, "Timestamp in ms": 1699751818349, "logtype": "training_step"}
{"Avg objective": 20.8828125, "Games time in secs": 131.719150390476, "Avg game time in secs": 1.1040054128679913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 40576, "Total num trained steps": 80617, "Timestamp in ms": 1699751865539, "logtype": "played_game"}
{"Total num played games": 40611, "Total num trained steps": 80621, "Timestamp in ms": 1699751880966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.13671875}
{"Ratio train steps to played games": 1.983348910423533, "Avg loss": 0.8088146357331425, "Avg value loss": 0.5447988954256289, "Avg policy loss": 0.26401573163457215, "Total num played games": 40658, "Total num trained steps": 80640, "Timestamp in ms": 1699751889501, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9864482648368136, "Avg loss": 0.6079997289925814, "Avg value loss": 0.32263714959844947, "Avg policy loss": 0.28536258509848267, "Total num played games": 40659, "Total num trained steps": 80768, "Timestamp in ms": 1699751948605, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 103.34681269526482, "Avg game time in secs": 1.3790424889157293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 40704, "Total num trained steps": 80812, "Timestamp in ms": 1699751968886, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872503500626428, "Avg loss": 0.45774177461862564, "Avg value loss": 0.2001250294269994, "Avg policy loss": 0.25761674577370286, "Total num played games": 40707, "Total num trained steps": 80896, "Timestamp in ms": 1699752007692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985419882868975, "Avg loss": 0.5126102422364056, "Avg value loss": 0.24575495882891119, "Avg policy loss": 0.26685528724920005, "Total num played games": 40809, "Total num trained steps": 81024, "Timestamp in ms": 1699752064150, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 132.96179844625294, "Avg game time in secs": 1.1652202930708881, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.42, "agent_stopped_0": 0.64}, "Total num played games": 40832, "Total num trained steps": 81109, "Timestamp in ms": 1699752101848, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859285906565842, "Avg loss": 0.5191985124256462, "Avg value loss": 0.25213902385439724, "Avg policy loss": 0.26705948961898685, "Total num played games": 40863, "Total num trained steps": 81152, "Timestamp in ms": 1699752121271, "logtype": "training_step"}
{"Total num played games": 40912, "Total num trained steps": 81225, "Timestamp in ms": 1699752173575, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.26171875}
{"Avg objective": 20.640625, "Games time in secs": 78.37806554697454, "Avg game time in secs": 1.1400463869067607, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 40960, "Total num trained steps": 81238, "Timestamp in ms": 1699752180226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843505859375, "Avg loss": 0.5954728040378541, "Avg value loss": 0.32473513105651364, "Avg policy loss": 0.27073767106048763, "Total num played games": 40960, "Total num trained steps": 81280, "Timestamp in ms": 1699752198929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874755859375, "Avg loss": 0.35769989085383713, "Avg value loss": 0.10417694327770732, "Avg policy loss": 0.25352294638287276, "Total num played games": 40960, "Total num trained steps": 81408, "Timestamp in ms": 1699752258270, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858976544803566, "Avg loss": 0.5667916536331177, "Avg value loss": 0.31148505449527875, "Avg policy loss": 0.2553066007094458, "Total num played games": 41057, "Total num trained steps": 81536, "Timestamp in ms": 1699752315303, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 166.5779661592096, "Avg game time in secs": 1.0398898747080239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.7, "agent_stopped_more": 0.3, "played_steps": 0.38}, "Total num played games": 41088, "Total num trained steps": 81605, "Timestamp in ms": 1699752346804, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866442855057656, "Avg loss": 0.48825949407182634, "Avg value loss": 0.2356732885236852, "Avg policy loss": 0.2525862082839012, "Total num played games": 41106, "Total num trained steps": 81664, "Timestamp in ms": 1699752373382, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987437430140448, "Avg loss": 0.4470537237357348, "Avg value loss": 0.19815420190570876, "Avg policy loss": 0.24889952363446355, "Total num played games": 41154, "Total num trained steps": 81792, "Timestamp in ms": 1699752431770, "logtype": "training_step"}
{"Total num played games": 41202, "Total num trained steps": 81828, "Timestamp in ms": 1699752463925, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1796875}
{"Avg objective": 19.828125, "Games time in secs": 118.73370549455285, "Avg game time in secs": 1.1925570261664689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 41216, "Total num trained steps": 81830, "Timestamp in ms": 1699752465538, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859151515151514, "Avg loss": 0.5847921259701252, "Avg value loss": 0.3181034725275822, "Avg policy loss": 0.2666886557126418, "Total num played games": 41250, "Total num trained steps": 81920, "Timestamp in ms": 1699752505422, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867305922804979, "Avg loss": 0.4014921745983884, "Avg value loss": 0.15776897288742475, "Avg policy loss": 0.24372320133261383, "Total num played games": 41298, "Total num trained steps": 82048, "Timestamp in ms": 1699752564178, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 117.86855289712548, "Avg game time in secs": 1.1381358180078678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.5, "agent_stopped_0": 0.57}, "Total num played games": 41344, "Total num trained steps": 82089, "Timestamp in ms": 1699752583407, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873757527388813, "Avg loss": 0.47923116968013346, "Avg value loss": 0.23152025166200474, "Avg policy loss": 0.24771092331502587, "Total num played games": 41349, "Total num trained steps": 82176, "Timestamp in ms": 1699752624001, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860524601240317, "Avg loss": 0.5549073675647378, "Avg value loss": 0.302837242546957, "Avg policy loss": 0.25207011960446835, "Total num played games": 41441, "Total num trained steps": 82304, "Timestamp in ms": 1699752680917, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 140.37754697725177, "Avg game time in secs": 1.0343087659130106, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.38, "agent_stopped_0": 0.66}, "Total num played games": 41472, "Total num trained steps": 82398, "Timestamp in ms": 1699752723785, "logtype": "played_game"}
{"Total num played games": 41502, "Total num trained steps": 82429, "Timestamp in ms": 1699752753098, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1171875}
{"Ratio train steps to played games": 1.9844242759816078, "Avg loss": 0.550141224404797, "Avg value loss": 0.30146434798371047, "Avg policy loss": 0.24867687793448567, "Total num played games": 41539, "Total num trained steps": 82432, "Timestamp in ms": 1699752755588, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869795427196149, "Avg loss": 0.48914811643771827, "Avg value loss": 0.2299919889192097, "Avg policy loss": 0.259156123152934, "Total num played games": 41550, "Total num trained steps": 82560, "Timestamp in ms": 1699752813328, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 104.64644043892622, "Avg game time in secs": 1.201292076788377, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 41600, "Total num trained steps": 82595, "Timestamp in ms": 1699752828431, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876923076923076, "Avg loss": 0.6066245194524527, "Avg value loss": 0.3532006502500735, "Avg policy loss": 0.2534238724038005, "Total num played games": 41600, "Total num trained steps": 82688, "Timestamp in ms": 1699752871619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858999568366025, "Avg loss": 0.6001238534227014, "Avg value loss": 0.34449226065771654, "Avg policy loss": 0.25563159107696265, "Total num played games": 41702, "Total num trained steps": 82816, "Timestamp in ms": 1699752930236, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 139.31286926940084, "Avg game time in secs": 1.1264075020153541, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 41728, "Total num trained steps": 82896, "Timestamp in ms": 1699752967744, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864207879295892, "Avg loss": 0.5629141228273511, "Avg value loss": 0.3086584962438792, "Avg policy loss": 0.25425562739837915, "Total num played games": 41755, "Total num trained steps": 82944, "Timestamp in ms": 1699752989542, "logtype": "training_step"}
{"Total num played games": 41806, "Total num trained steps": 83032, "Timestamp in ms": 1699753052891, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.19921875}
{"Ratio train steps to played games": 1.9848043197782768, "Avg loss": 0.6673810123465955, "Avg value loss": 0.4055786093813367, "Avg policy loss": 0.26180240395478904, "Total num played games": 41854, "Total num trained steps": 83072, "Timestamp in ms": 1699753071935, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 162.17691433429718, "Avg game time in secs": 1.403744465103955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.67, "agent_stopped_0": 0.42}, "Total num played games": 41856, "Total num trained steps": 83198, "Timestamp in ms": 1699753129921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867233392234587, "Avg loss": 0.3903235055040568, "Avg value loss": 0.1362613642704673, "Avg policy loss": 0.2540621416410431, "Total num played games": 41877, "Total num trained steps": 83200, "Timestamp in ms": 1699753130480, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98610415921821, "Avg loss": 0.5768899598624557, "Avg value loss": 0.32953220227500424, "Avg policy loss": 0.24735776032321155, "Total num played games": 41955, "Total num trained steps": 83328, "Timestamp in ms": 1699753187357, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 89.23488486930728, "Avg game time in secs": 1.1561931125615956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 41984, "Total num trained steps": 83402, "Timestamp in ms": 1699753219156, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986834587182173, "Avg loss": 0.740655061788857, "Avg value loss": 0.4789479994797148, "Avg policy loss": 0.2617070603882894, "Total num played games": 42004, "Total num trained steps": 83456, "Timestamp in ms": 1699753243445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987587092478539, "Avg loss": 0.6130203411448747, "Avg value loss": 0.35173353645950556, "Avg policy loss": 0.26128680701367557, "Total num played games": 42053, "Total num trained steps": 83584, "Timestamp in ms": 1699753302124, "logtype": "training_step"}
{"Total num played games": 42106, "Total num trained steps": 83634, "Timestamp in ms": 1699753398862, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.68359375}
{"Avg objective": 22.03125, "Games time in secs": 180.90366531349719, "Avg game time in secs": 1.3435819666628959, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.62}, "Total num played games": 42112, "Total num trained steps": 83634, "Timestamp in ms": 1699753400060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858376429283104, "Avg loss": 0.9033846249803901, "Avg value loss": 0.630000956938602, "Avg policy loss": 0.2733836737461388, "Total num played games": 42154, "Total num trained steps": 83712, "Timestamp in ms": 1699753433792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866120089095303, "Avg loss": 0.5465716496109962, "Avg value loss": 0.2809684324893169, "Avg policy loss": 0.2656032186932862, "Total num played games": 42202, "Total num trained steps": 83840, "Timestamp in ms": 1699753493513, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 118.53728598356247, "Avg game time in secs": 1.1886849924194394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 42240, "Total num trained steps": 83896, "Timestamp in ms": 1699753518598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871024233244983, "Avg loss": 0.5431660446338356, "Avg value loss": 0.2713803807273507, "Avg policy loss": 0.271785665419884, "Total num played games": 42256, "Total num trained steps": 83968, "Timestamp in ms": 1699753550719, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878264980498759, "Avg loss": 0.4790981288533658, "Avg value loss": 0.20817568356869742, "Avg policy loss": 0.27092244615778327, "Total num played games": 42305, "Total num trained steps": 84096, "Timestamp in ms": 1699753609389, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 136.88805671967566, "Avg game time in secs": 1.2489709996734746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.59, "agent_stopped_0": 0.5}, "Total num played games": 42368, "Total num trained steps": 84196, "Timestamp in ms": 1699753655486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859231313369488, "Avg loss": 0.7108499023597687, "Avg value loss": 0.4341625935048796, "Avg policy loss": 0.2766873051878065, "Total num played games": 42410, "Total num trained steps": 84224, "Timestamp in ms": 1699753667684, "logtype": "training_step"}
{"Total num played games": 42410, "Total num trained steps": 84234, "Timestamp in ms": 1699753706230, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3984375}
{"Ratio train steps to played games": 1.9866927316406802, "Avg loss": 0.6093865630682558, "Avg value loss": 0.31772695732070133, "Avg policy loss": 0.2916596014983952, "Total num played games": 42458, "Total num trained steps": 84352, "Timestamp in ms": 1699753759479, "logtype": "training_step"}
{"Avg objective": 22.4765625, "Games time in secs": 129.6557526718825, "Avg game time in secs": 1.0405969944404205, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.46}, "Total num played games": 42496, "Total num trained steps": 84408, "Timestamp in ms": 1699753785142, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874605937985226, "Avg loss": 0.5292305636685342, "Avg value loss": 0.26623621385078877, "Avg policy loss": 0.26299435168039054, "Total num played games": 42506, "Total num trained steps": 84480, "Timestamp in ms": 1699753818037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98598657340031, "Avg loss": 0.8315737112425268, "Avg value loss": 0.5647987265256234, "Avg policy loss": 0.26677498524077237, "Total num played games": 42602, "Total num trained steps": 84608, "Timestamp in ms": 1699753877971, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 131.75141808390617, "Avg game time in secs": 1.1955724609579192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 42624, "Total num trained steps": 84695, "Timestamp in ms": 1699753916893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865663243775495, "Avg loss": 0.7236516161356121, "Avg value loss": 0.4539537873934023, "Avg policy loss": 0.269697833689861, "Total num played games": 42654, "Total num trained steps": 84736, "Timestamp in ms": 1699753934952, "logtype": "training_step"}
{"Total num played games": 42705, "Total num trained steps": 84835, "Timestamp in ms": 1699754060277, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2578125}
{"Avg objective": 21.4921875, "Games time in secs": 148.60482911206782, "Avg game time in secs": 1.3144959872879554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.54}, "Total num played games": 42752, "Total num trained steps": 84846, "Timestamp in ms": 1699754065498, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849601197576778, "Avg loss": 0.6353082158602774, "Avg value loss": 0.3605050279875286, "Avg policy loss": 0.2748031945666298, "Total num played games": 42753, "Total num trained steps": 84864, "Timestamp in ms": 1699754073122, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879540617032723, "Avg loss": 0.44581615226343274, "Avg value loss": 0.17887536471243948, "Avg policy loss": 0.266940783476457, "Total num played games": 42753, "Total num trained steps": 84992, "Timestamp in ms": 1699754131020, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859312661860433, "Avg loss": 0.7238975632935762, "Avg value loss": 0.44914979208260775, "Avg policy loss": 0.2747477737721056, "Total num played games": 42861, "Total num trained steps": 85120, "Timestamp in ms": 1699754192829, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 174.48634234629571, "Avg game time in secs": 1.1678631127870176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 42880, "Total num trained steps": 85213, "Timestamp in ms": 1699754239985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866464693544628, "Avg loss": 0.5010459469631314, "Avg value loss": 0.23735789250349626, "Avg policy loss": 0.26368805882520974, "Total num played games": 42910, "Total num trained steps": 85248, "Timestamp in ms": 1699754256342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987175011056025, "Avg loss": 0.4413614720106125, "Avg value loss": 0.17537750821793452, "Avg policy loss": 0.2659839653642848, "Total num played games": 42963, "Total num trained steps": 85376, "Timestamp in ms": 1699754317804, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 99.62416054494679, "Avg game time in secs": 1.2604828129260568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 43008, "Total num trained steps": 85419, "Timestamp in ms": 1699754339609, "logtype": "played_game"}
{"Total num played games": 43017, "Total num trained steps": 85436, "Timestamp in ms": 1699754367047, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8984375}
{"Ratio train steps to played games": 1.9854406130268198, "Avg loss": 0.7103716540150344, "Avg value loss": 0.44229750300291926, "Avg policy loss": 0.2680741511285305, "Total num played games": 43065, "Total num trained steps": 85504, "Timestamp in ms": 1699754400313, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861990582886833, "Avg loss": 0.3879061653278768, "Avg value loss": 0.13892819575266913, "Avg policy loss": 0.24897796928416938, "Total num played games": 43113, "Total num trained steps": 85632, "Timestamp in ms": 1699754462459, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 164.06106673367321, "Avg game time in secs": 1.186008296586806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 43136, "Total num trained steps": 85717, "Timestamp in ms": 1699754503670, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986978985658349, "Avg loss": 0.6750690541230142, "Avg value loss": 0.42556431103730574, "Avg policy loss": 0.24950473802164197, "Total num played games": 43161, "Total num trained steps": 85760, "Timestamp in ms": 1699754525536, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876880351770423, "Avg loss": 0.5591911063529551, "Avg value loss": 0.3085656533949077, "Avg policy loss": 0.2506254566833377, "Total num played games": 43210, "Total num trained steps": 85888, "Timestamp in ms": 1699754589102, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 139.98580173775554, "Avg game time in secs": 1.2098580684832996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.64, "agent_stopped_0": 0.52}, "Total num played games": 43264, "Total num trained steps": 86006, "Timestamp in ms": 1699754643656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986237472867501, "Avg loss": 0.6797247885260731, "Avg value loss": 0.42439092829590663, "Avg policy loss": 0.2553338602883741, "Total num played games": 43306, "Total num trained steps": 86016, "Timestamp in ms": 1699754648465, "logtype": "training_step"}
{"Total num played games": 43306, "Total num trained steps": 86040, "Timestamp in ms": 1699754675783, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.65234375}
{"Ratio train steps to played games": 1.986967753840476, "Avg loss": 0.6706431554630399, "Avg value loss": 0.4121480896137655, "Avg policy loss": 0.25849506934173405, "Total num played games": 43354, "Total num trained steps": 86144, "Timestamp in ms": 1699754728232, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 110.30254657939076, "Avg game time in secs": 1.0438137043820461, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.41}, "Total num played games": 43392, "Total num trained steps": 86200, "Timestamp in ms": 1699754753959, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987719459932722, "Avg loss": 0.5552683095447719, "Avg value loss": 0.3145384975941852, "Avg policy loss": 0.24072980973869562, "Total num played games": 43402, "Total num trained steps": 86272, "Timestamp in ms": 1699754789127, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986183908045977, "Avg loss": 0.5774644734337926, "Avg value loss": 0.3315979109611362, "Avg policy loss": 0.2458665625890717, "Total num played games": 43500, "Total num trained steps": 86400, "Timestamp in ms": 1699754852688, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 144.7945214137435, "Avg game time in secs": 1.1407584667467745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 43520, "Total num trained steps": 86490, "Timestamp in ms": 1699754898754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868883326827251, "Avg loss": 0.6153633405920118, "Avg value loss": 0.35987914667930454, "Avg policy loss": 0.25548419856932014, "Total num played games": 43549, "Total num trained steps": 86528, "Timestamp in ms": 1699754917033, "logtype": "training_step"}
{"Total num played games": 43597, "Total num trained steps": 86640, "Timestamp in ms": 1699754993302, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9765625}
{"Ratio train steps to played games": 1.9854507961965862, "Avg loss": 0.6489596401806921, "Avg value loss": 0.3898106710985303, "Avg policy loss": 0.2591489664046094, "Total num played games": 43645, "Total num trained steps": 86656, "Timestamp in ms": 1699755001829, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 166.53148532100022, "Avg game time in secs": 1.1706324749829946, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 43648, "Total num trained steps": 86780, "Timestamp in ms": 1699755065285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861537053142309, "Avg loss": 0.45882350811734796, "Avg value loss": 0.20387856190791354, "Avg policy loss": 0.2549449425423518, "Total num played games": 43694, "Total num trained steps": 86784, "Timestamp in ms": 1699755067148, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9867642016230427, "Avg loss": 0.6826935266144574, "Avg value loss": 0.4296196062932722, "Avg policy loss": 0.25307391153182834, "Total num played games": 43745, "Total num trained steps": 86912, "Timestamp in ms": 1699755130587, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 99.19823125563562, "Avg game time in secs": 1.0579722081456566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.47}, "Total num played games": 43776, "Total num trained steps": 86981, "Timestamp in ms": 1699755164484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987509419313589, "Avg loss": 0.5363033364992589, "Avg value loss": 0.28058431710815057, "Avg policy loss": 0.2557190207298845, "Total num played games": 43793, "Total num trained steps": 87040, "Timestamp in ms": 1699755193049, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882530051778016, "Avg loss": 0.5116449184715748, "Avg value loss": 0.24762257328256965, "Avg policy loss": 0.26402234414126724, "Total num played games": 43841, "Total num trained steps": 87168, "Timestamp in ms": 1699755256522, "logtype": "training_step"}
{"Total num played games": 43890, "Total num trained steps": 87242, "Timestamp in ms": 1699755316618, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.859375}
{"Avg objective": 21.1171875, "Games time in secs": 153.91409543715417, "Avg game time in secs": 1.1486335944355233, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.54, "agent_stopped_0": 0.53}, "Total num played games": 43904, "Total num trained steps": 87246, "Timestamp in ms": 1699755318398, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867768218853838, "Avg loss": 0.7305620352271944, "Avg value loss": 0.46818156773224473, "Avg policy loss": 0.2623804655158892, "Total num played games": 43938, "Total num trained steps": 87296, "Timestamp in ms": 1699755340849, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987518755967808, "Avg loss": 0.47205306752584875, "Avg value loss": 0.21745215414557606, "Avg policy loss": 0.2546009124489501, "Total num played games": 43986, "Total num trained steps": 87424, "Timestamp in ms": 1699755406192, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 108.59576859138906, "Avg game time in secs": 1.17503693929757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.6}, "Total num played games": 44032, "Total num trained steps": 87465, "Timestamp in ms": 1699755426994, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880108991825614, "Avg loss": 0.4636741983704269, "Avg value loss": 0.2057542708935216, "Avg policy loss": 0.2579199339961633, "Total num played games": 44040, "Total num trained steps": 87552, "Timestamp in ms": 1699755472449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862942322504644, "Avg loss": 0.6691566333174706, "Avg value loss": 0.408226614468731, "Avg policy loss": 0.26093002408742905, "Total num played games": 44142, "Total num trained steps": 87680, "Timestamp in ms": 1699755535296, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 158.05545262806118, "Avg game time in secs": 1.124819810676854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 44160, "Total num trained steps": 87776, "Timestamp in ms": 1699755585049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869883007852278, "Avg loss": 0.735957000637427, "Avg value loss": 0.4641622793278657, "Avg policy loss": 0.2717947226483375, "Total num played games": 44191, "Total num trained steps": 87808, "Timestamp in ms": 1699755600943, "logtype": "training_step"}
{"Total num played games": 44191, "Total num trained steps": 87843, "Timestamp in ms": 1699755666809, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1328125}
{"Ratio train steps to played games": 1.9877483668256515, "Avg loss": 0.6765176102053374, "Avg value loss": 0.39420100703136995, "Avg policy loss": 0.2823166063753888, "Total num played games": 44239, "Total num trained steps": 87936, "Timestamp in ms": 1699755713936, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 197.0718099679798, "Avg game time in secs": 1.318348458094988, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.65}, "Total num played games": 44288, "Total num trained steps": 88063, "Timestamp in ms": 1699755782121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988169955298686, "Avg loss": 0.5946135642006993, "Avg value loss": 0.3170268128742464, "Avg policy loss": 0.2775867470772937, "Total num played games": 44291, "Total num trained steps": 88064, "Timestamp in ms": 1699755782223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870445891444923, "Avg loss": 0.7220126201864332, "Avg value loss": 0.44278670026687905, "Avg policy loss": 0.2792259219568223, "Total num played games": 44383, "Total num trained steps": 88192, "Timestamp in ms": 1699755845977, "logtype": "training_step"}
{"Avg objective": 22.7109375, "Games time in secs": 96.19004146382213, "Avg game time in secs": 1.0943701095384313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 44416, "Total num trained steps": 88258, "Timestamp in ms": 1699755878311, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875104079933388, "Avg loss": 0.6601038328371942, "Avg value loss": 0.37554850534070283, "Avg policy loss": 0.28455533063970506, "Total num played games": 44437, "Total num trained steps": 88320, "Timestamp in ms": 1699755908944, "logtype": "training_step"}
{"Total num played games": 44490, "Total num trained steps": 88444, "Timestamp in ms": 1699756051536, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.88671875}
{"Ratio train steps to played games": 1.9869479264950354, "Avg loss": 0.5739975264295936, "Avg value loss": 0.2893205442815088, "Avg policy loss": 0.2846769845345989, "Total num played games": 44514, "Total num trained steps": 88448, "Timestamp in ms": 1699756053706, "logtype": "training_step"}
{"Avg objective": 19.9765625, "Games time in secs": 237.15309412032366, "Avg game time in secs": 1.323442410575808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 44544, "Total num trained steps": 88566, "Timestamp in ms": 1699756115465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866101466828152, "Avg loss": 0.577474249061197, "Avg value loss": 0.30114133073948324, "Avg policy loss": 0.2763329189037904, "Total num played games": 44586, "Total num trained steps": 88576, "Timestamp in ms": 1699756120187, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873638929963704, "Avg loss": 0.5886292813811451, "Avg value loss": 0.3029088764451444, "Avg policy loss": 0.28572040027938783, "Total num played games": 44634, "Total num trained steps": 88704, "Timestamp in ms": 1699756186221, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 102.54860610887408, "Avg game time in secs": 1.0771093938092235, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 44672, "Total num trained steps": 88760, "Timestamp in ms": 1699756218014, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880712591200036, "Avg loss": 0.5675083249807358, "Avg value loss": 0.2864335826016031, "Avg policy loss": 0.2810747363837436, "Total num played games": 44682, "Total num trained steps": 88832, "Timestamp in ms": 1699756253493, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866898923578542, "Avg loss": 0.612600498367101, "Avg value loss": 0.33586529071908444, "Avg policy loss": 0.27673520741518587, "Total num played games": 44778, "Total num trained steps": 88960, "Timestamp in ms": 1699756319164, "logtype": "training_step"}
{"Total num played games": 44778, "Total num trained steps": 89044, "Timestamp in ms": 1699756399020, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8203125}
{"Avg objective": 22.1796875, "Games time in secs": 183.05840492248535, "Avg game time in secs": 1.1331937796785496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.48, "agent_stopped_0": 0.54}, "Total num played games": 44800, "Total num trained steps": 89046, "Timestamp in ms": 1699756401072, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987395707848124, "Avg loss": 0.659375349059701, "Avg value loss": 0.3765783858834766, "Avg policy loss": 0.28279696067329496, "Total num played games": 44826, "Total num trained steps": 89088, "Timestamp in ms": 1699756420911, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988100278551532, "Avg loss": 0.7586642766837031, "Avg value loss": 0.4672754282364622, "Avg policy loss": 0.291388847050257, "Total num played games": 44875, "Total num trained steps": 89216, "Timestamp in ms": 1699756486058, "logtype": "training_step"}
{"Avg objective": 22.7109375, "Games time in secs": 143.91328151896596, "Avg game time in secs": 1.2156675863807322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 44928, "Total num trained steps": 89335, "Timestamp in ms": 1699756544986, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9867025416379445, "Avg loss": 0.716732714092359, "Avg value loss": 0.4259190700831823, "Avg policy loss": 0.2908136509358883, "Total num played games": 44971, "Total num trained steps": 89344, "Timestamp in ms": 1699756549146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873392416872127, "Avg loss": 0.6776632980909199, "Avg value loss": 0.39966104965424165, "Avg policy loss": 0.27800224639941007, "Total num played games": 45021, "Total num trained steps": 89472, "Timestamp in ms": 1699756609934, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 93.38499430380762, "Avg game time in secs": 0.9963274425390409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 45056, "Total num trained steps": 89532, "Timestamp in ms": 1699756638371, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988040560030176, "Avg loss": 0.5227796449325979, "Avg value loss": 0.24819573992863297, "Avg policy loss": 0.274583907215856, "Total num played games": 45069, "Total num trained steps": 89600, "Timestamp in ms": 1699756669641, "logtype": "training_step"}
{"Total num played games": 45117, "Total num trained steps": 89644, "Timestamp in ms": 1699756746254, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.44921875}
{"Ratio train steps to played games": 1.9866710948743496, "Avg loss": 0.7543175625614822, "Avg value loss": 0.46137331990757957, "Avg policy loss": 0.2929442428285256, "Total num played games": 45165, "Total num trained steps": 89728, "Timestamp in ms": 1699756786920, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 193.40587135963142, "Avg game time in secs": 1.0430084935942432, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 45184, "Total num trained steps": 89820, "Timestamp in ms": 1699756831777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873490511788383, "Avg loss": 0.4835197012871504, "Avg value loss": 0.21072739400551654, "Avg policy loss": 0.2727923081256449, "Total num played games": 45214, "Total num trained steps": 89856, "Timestamp in ms": 1699756848869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880473686536166, "Avg loss": 0.6281876722350717, "Avg value loss": 0.35744912060908973, "Avg policy loss": 0.2707385497633368, "Total num played games": 45262, "Total num trained steps": 89984, "Timestamp in ms": 1699756908645, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 137.56963810510933, "Avg game time in secs": 1.1403007268963847, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 45312, "Total num trained steps": 90109, "Timestamp in ms": 1699756969347, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868806914647321, "Avg loss": 0.5876673886086792, "Avg value loss": 0.3148923837579787, "Avg policy loss": 0.2727750020567328, "Total num played games": 45351, "Total num trained steps": 90112, "Timestamp in ms": 1699756970775, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874025459190416, "Avg loss": 0.6782233726698905, "Avg value loss": 0.4128595120855607, "Avg policy loss": 0.2653638659976423, "Total num played games": 45406, "Total num trained steps": 90240, "Timestamp in ms": 1699757038178, "logtype": "training_step"}
{"Total num played games": 45406, "Total num trained steps": 90246, "Timestamp in ms": 1699757074205, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2109375}
{"Avg objective": 21.6796875, "Games time in secs": 107.10286243259907, "Avg game time in secs": 1.064535736979451, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 45440, "Total num trained steps": 90249, "Timestamp in ms": 1699757076450, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881198574382892, "Avg loss": 0.6042214583139867, "Avg value loss": 0.3378271605470218, "Avg policy loss": 0.2663943050429225, "Total num played games": 45454, "Total num trained steps": 90368, "Timestamp in ms": 1699757136325, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875905996046563, "Avg loss": 0.5216086495202035, "Avg value loss": 0.26238893580739386, "Avg policy loss": 0.2592197133926675, "Total num played games": 45528, "Total num trained steps": 90496, "Timestamp in ms": 1699757202192, "logtype": "training_step"}
{"Avg objective": 22.796875, "Games time in secs": 171.92726238630712, "Avg game time in secs": 1.0050384223723086, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 45568, "Total num trained steps": 90592, "Timestamp in ms": 1699757248377, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873684210526317, "Avg loss": 0.8325320901349187, "Avg value loss": 0.5754591242875904, "Avg policy loss": 0.2570729688741267, "Total num played games": 45600, "Total num trained steps": 90624, "Timestamp in ms": 1699757263285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880391684374248, "Avg loss": 0.5332085294649005, "Avg value loss": 0.28150562883820385, "Avg policy loss": 0.25170289573725313, "Total num played games": 45649, "Total num trained steps": 90752, "Timestamp in ms": 1699757327156, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 99.00755888223648, "Avg game time in secs": 1.169779619158362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 45696, "Total num trained steps": 90792, "Timestamp in ms": 1699757347385, "logtype": "played_game"}
{"Total num played games": 45697, "Total num trained steps": 90849, "Timestamp in ms": 1699757460533, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.140625}
{"Ratio train steps to played games": 1.9866433489998907, "Avg loss": 0.6778591880574822, "Avg value loss": 0.4229253985104151, "Avg policy loss": 0.25493378622923046, "Total num played games": 45745, "Total num trained steps": 90880, "Timestamp in ms": 1699757475467, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873779835346013, "Avg loss": 0.5057214458938688, "Avg value loss": 0.25656722008716315, "Avg policy loss": 0.24915422627236694, "Total num played games": 45793, "Total num trained steps": 91008, "Timestamp in ms": 1699757543166, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 227.29451021552086, "Avg game time in secs": 1.058837523116381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.48, "agent_stopped_0": 0.56}, "Total num played games": 45824, "Total num trained steps": 91076, "Timestamp in ms": 1699757574679, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880892650683886, "Avg loss": 0.5302717532031238, "Avg value loss": 0.27780112967593595, "Avg policy loss": 0.2524706207914278, "Total num played games": 45841, "Total num trained steps": 91136, "Timestamp in ms": 1699757602452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887990585979212, "Avg loss": 0.5011827782727778, "Avg value loss": 0.25981538818450645, "Avg policy loss": 0.24136738781817257, "Total num played games": 45889, "Total num trained steps": 91264, "Timestamp in ms": 1699757664654, "logtype": "training_step"}
{"Avg objective": 22.8828125, "Games time in secs": 139.85644956864417, "Avg game time in secs": 1.1367447949014604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 45952, "Total num trained steps": 91363, "Timestamp in ms": 1699757714536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873657200017396, "Avg loss": 0.5508437028620392, "Avg value loss": 0.31215758848702535, "Avg policy loss": 0.23868611361831427, "Total num played games": 45986, "Total num trained steps": 91392, "Timestamp in ms": 1699757727711, "logtype": "training_step"}
{"Total num played games": 45986, "Total num trained steps": 91451, "Timestamp in ms": 1699757776134, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.74609375}
{"Ratio train steps to played games": 1.9880957553112917, "Avg loss": 0.4939632877940312, "Avg value loss": 0.2596717384294607, "Avg policy loss": 0.23429154965560883, "Total num played games": 46034, "Total num trained steps": 91520, "Timestamp in ms": 1699757808871, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 113.26811290718615, "Avg game time in secs": 1.0827502545143943, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 46080, "Total num trained steps": 91560, "Timestamp in ms": 1699757827806, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988780868885899, "Avg loss": 0.5075067824218422, "Avg value loss": 0.26860756080714054, "Avg policy loss": 0.238899220013991, "Total num played games": 46082, "Total num trained steps": 91648, "Timestamp in ms": 1699757870117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873968687065549, "Avg loss": 0.56704157195054, "Avg value loss": 0.32168767717666924, "Avg policy loss": 0.2453538947738707, "Total num played games": 46179, "Total num trained steps": 91776, "Timestamp in ms": 1699757934787, "logtype": "training_step"}
{"Avg objective": 21.0625, "Games time in secs": 142.3342598117888, "Avg game time in secs": 1.05289501666266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 46208, "Total num trained steps": 91848, "Timestamp in ms": 1699757970141, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880805589806823, "Avg loss": 0.5363952869083732, "Avg value loss": 0.287000201002229, "Avg policy loss": 0.24939509260002524, "Total num played games": 46227, "Total num trained steps": 91904, "Timestamp in ms": 1699757998878, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888060507833603, "Avg loss": 0.49341336195357144, "Avg value loss": 0.2471111980266869, "Avg policy loss": 0.24630215915385634, "Total num played games": 46275, "Total num trained steps": 92032, "Timestamp in ms": 1699758063253, "logtype": "training_step"}
{"Total num played games": 46323, "Total num trained steps": 92052, "Timestamp in ms": 1699758085199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.25}
{"Avg objective": 20.96875, "Games time in secs": 116.42092917114496, "Avg game time in secs": 1.09743399672152, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.54, "agent_stopped_0": 0.48}, "Total num played games": 46336, "Total num trained steps": 92052, "Timestamp in ms": 1699758086562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987449052209355, "Avg loss": 0.6648508331272751, "Avg value loss": 0.40745238901581615, "Avg policy loss": 0.2573984469054267, "Total num played games": 46371, "Total num trained steps": 92160, "Timestamp in ms": 1699758137473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881298606174196, "Avg loss": 0.4456511997850612, "Avg value loss": 0.20564350130734965, "Avg policy loss": 0.24000770039856434, "Total num played games": 46419, "Total num trained steps": 92288, "Timestamp in ms": 1699758199695, "logtype": "training_step"}
{"Avg objective": 22.203125, "Games time in secs": 132.644146412611, "Avg game time in secs": 1.0758930585434427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 46464, "Total num trained steps": 92330, "Timestamp in ms": 1699758219206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888523037854822, "Avg loss": 0.4989675594260916, "Avg value loss": 0.2566739528265316, "Avg policy loss": 0.24229360895697027, "Total num played games": 46467, "Total num trained steps": 92416, "Timestamp in ms": 1699758261792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875008053604795, "Avg loss": 0.49035781575366855, "Avg value loss": 0.24636994596221484, "Avg policy loss": 0.24398786947131157, "Total num played games": 46563, "Total num trained steps": 92544, "Timestamp in ms": 1699758324828, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 140.33496857620776, "Avg game time in secs": 1.0548677561309887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 46592, "Total num trained steps": 92616, "Timestamp in ms": 1699758359541, "logtype": "played_game"}
{"Total num played games": 46611, "Total num trained steps": 92655, "Timestamp in ms": 1699758409179, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9375}
{"Ratio train steps to played games": 1.986133436207377, "Avg loss": 0.7199441387783736, "Avg value loss": 0.4701560678659007, "Avg policy loss": 0.24978807172738016, "Total num played games": 46659, "Total num trained steps": 92672, "Timestamp in ms": 1699758418091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888981761289355, "Avg loss": 0.4454155096318573, "Avg value loss": 0.197400998120429, "Avg policy loss": 0.24801451561506838, "Total num played games": 46659, "Total num trained steps": 92800, "Timestamp in ms": 1699758479814, "logtype": "training_step"}
{"Avg objective": 19.78125, "Games time in secs": 168.63984658010304, "Avg game time in secs": 1.0614537581714103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 46720, "Total num trained steps": 92903, "Timestamp in ms": 1699758528181, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987552133461662, "Avg loss": 0.5492425814736634, "Avg value loss": 0.293562670762185, "Avg policy loss": 0.25567990459967405, "Total num played games": 46755, "Total num trained steps": 92928, "Timestamp in ms": 1699758539426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881422924901186, "Avg loss": 0.7052243482321501, "Avg value loss": 0.44025509495986626, "Avg policy loss": 0.2649692540289834, "Total num played games": 46805, "Total num trained steps": 93056, "Timestamp in ms": 1699758602040, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 95.37953022681177, "Avg game time in secs": 1.0948867281840649, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 46848, "Total num trained steps": 93102, "Timestamp in ms": 1699758623563, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888587710498795, "Avg loss": 0.5186030995100737, "Avg value loss": 0.26097741164267063, "Avg policy loss": 0.25762568949721754, "Total num played games": 46853, "Total num trained steps": 93184, "Timestamp in ms": 1699758663877, "logtype": "training_step"}
{"Total num played games": 46901, "Total num trained steps": 93258, "Timestamp in ms": 1699758740501, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4921875}
{"Ratio train steps to played games": 1.9875183709983173, "Avg loss": 0.8739793801214546, "Avg value loss": 0.5972470472333953, "Avg policy loss": 0.2767323284642771, "Total num played games": 46949, "Total num trained steps": 93312, "Timestamp in ms": 1699758766299, "logtype": "training_step"}
{"Avg objective": 22.7421875, "Games time in secs": 179.4441920761019, "Avg game time in secs": 1.1370221268880414, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 46976, "Total num trained steps": 93388, "Timestamp in ms": 1699758803008, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882120135327788, "Avg loss": 0.6033497746102512, "Avg value loss": 0.3363317719195038, "Avg policy loss": 0.2670179991982877, "Total num played games": 46997, "Total num trained steps": 93440, "Timestamp in ms": 1699758827048, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889042406206823, "Avg loss": 0.6244335712399334, "Avg value loss": 0.3591820221627131, "Avg policy loss": 0.26525155326817185, "Total num played games": 47045, "Total num trained steps": 93568, "Timestamp in ms": 1699758890426, "logtype": "training_step"}
{"Avg objective": 22.5625, "Games time in secs": 139.1690806541592, "Avg game time in secs": 1.1364627875154838, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 47104, "Total num trained steps": 93675, "Timestamp in ms": 1699758942177, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875479943149275, "Avg loss": 0.6338772100862116, "Avg value loss": 0.3582349590724334, "Avg policy loss": 0.2756422469392419, "Total num played games": 47141, "Total num trained steps": 93696, "Timestamp in ms": 1699758952208, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882599758418276, "Avg loss": 0.5851246081292629, "Avg value loss": 0.3081205297494307, "Avg policy loss": 0.27700407698284835, "Total num played games": 47189, "Total num trained steps": 93824, "Timestamp in ms": 1699759014283, "logtype": "training_step"}
{"Total num played games": 47189, "Total num trained steps": 93859, "Timestamp in ms": 1699759048130, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.48046875}
{"Avg objective": 22.234375, "Games time in secs": 108.70197894796729, "Avg game time in secs": 1.0915024843561696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 47232, "Total num trained steps": 93864, "Timestamp in ms": 1699759050879, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889493405593073, "Avg loss": 0.4611851922236383, "Avg value loss": 0.19376341125462204, "Avg policy loss": 0.2674217832973227, "Total num played games": 47237, "Total num trained steps": 93952, "Timestamp in ms": 1699759094328, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875985042148183, "Avg loss": 0.6145276315510273, "Avg value loss": 0.3327718846267089, "Avg policy loss": 0.2817557433154434, "Total num played games": 47333, "Total num trained steps": 94080, "Timestamp in ms": 1699759155553, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 141.4603686928749, "Avg game time in secs": 1.1321686818118906, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 47360, "Total num trained steps": 94156, "Timestamp in ms": 1699759192340, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882864439332222, "Avg loss": 0.7553124201949686, "Avg value loss": 0.4757673369022086, "Avg policy loss": 0.279545082943514, "Total num played games": 47381, "Total num trained steps": 94208, "Timestamp in ms": 1699759218160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889940753547408, "Avg loss": 0.6229339188430458, "Avg value loss": 0.3425798256066628, "Avg policy loss": 0.28035409620497376, "Total num played games": 47429, "Total num trained steps": 94336, "Timestamp in ms": 1699759284766, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 149.87570766732097, "Avg game time in secs": 1.173781285790028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 47488, "Total num trained steps": 94443, "Timestamp in ms": 1699759342215, "logtype": "played_game"}
{"Total num played games": 47525, "Total num trained steps": 94462, "Timestamp in ms": 1699759364313, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.078125}
{"Ratio train steps to played games": 1.9874605512308017, "Avg loss": 0.7050697200465947, "Avg value loss": 0.42380567896179855, "Avg policy loss": 0.2812640388729051, "Total num played games": 47528, "Total num trained steps": 94464, "Timestamp in ms": 1699759365469, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883547390326446, "Avg loss": 0.7313679372891784, "Avg value loss": 0.4416202937136404, "Avg policy loss": 0.28974765189923346, "Total num played games": 47573, "Total num trained steps": 94592, "Timestamp in ms": 1699759425946, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 109.185521742329, "Avg game time in secs": 1.131366064044414, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 47616, "Total num trained steps": 94638, "Timestamp in ms": 1699759451401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890384494235736, "Avg loss": 0.4453012200538069, "Avg value loss": 0.17652219330193475, "Avg policy loss": 0.2687790290219709, "Total num played games": 47621, "Total num trained steps": 94720, "Timestamp in ms": 1699759490818, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9876359521364655, "Avg loss": 0.8036212222650647, "Avg value loss": 0.5252932000439614, "Avg policy loss": 0.27832802408374846, "Total num played games": 47719, "Total num trained steps": 94848, "Timestamp in ms": 1699759551653, "logtype": "training_step"}
{"Avg objective": 22.6171875, "Games time in secs": 139.66187212057412, "Avg game time in secs": 1.0646638912439812, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.47, "agent_stopped_0": 0.61}, "Total num played games": 47744, "Total num trained steps": 94928, "Timestamp in ms": 1699759591081, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988318295057257, "Avg loss": 0.5962448290083557, "Avg value loss": 0.3195228705299087, "Avg policy loss": 0.27672196098137647, "Total num played games": 47767, "Total num trained steps": 94976, "Timestamp in ms": 1699759613413, "logtype": "training_step"}
{"Total num played games": 47815, "Total num trained steps": 95063, "Timestamp in ms": 1699759674257, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8203125}
{"Ratio train steps to played games": 1.9870045755594092, "Avg loss": 0.7396919457241893, "Avg value loss": 0.4588001847732812, "Avg policy loss": 0.28089176130015403, "Total num played games": 47863, "Total num trained steps": 95104, "Timestamp in ms": 1699759694530, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 157.30420207977295, "Avg game time in secs": 1.1358413240668597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 47872, "Total num trained steps": 95216, "Timestamp in ms": 1699759748385, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876025295848725, "Avg loss": 0.5143210217356682, "Avg value loss": 0.24047493102261797, "Avg policy loss": 0.2738460899563506, "Total num played games": 47913, "Total num trained steps": 95232, "Timestamp in ms": 1699759755925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882612956360377, "Avg loss": 0.6323764901608229, "Avg value loss": 0.36338199861347675, "Avg policy loss": 0.26899448793847114, "Total num played games": 47961, "Total num trained steps": 95360, "Timestamp in ms": 1699759817042, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 94.72023702599108, "Avg game time in secs": 1.063747048174264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 48000, "Total num trained steps": 95412, "Timestamp in ms": 1699759843105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889604032577226, "Avg loss": 0.5197775745764375, "Avg value loss": 0.2591701347846538, "Avg policy loss": 0.26060743955895305, "Total num played games": 48009, "Total num trained steps": 95488, "Timestamp in ms": 1699759878407, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987528061860813, "Avg loss": 0.6780240151565522, "Avg value loss": 0.41264234425034374, "Avg policy loss": 0.2653816723031923, "Total num played games": 48108, "Total num trained steps": 95616, "Timestamp in ms": 1699759941879, "logtype": "training_step"}
{"Total num played games": 48108, "Total num trained steps": 95664, "Timestamp in ms": 1699759985484, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.55859375}
{"Avg objective": 22.9921875, "Games time in secs": 144.06363035552204, "Avg game time in secs": 1.104471792728873, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 48128, "Total num trained steps": 95666, "Timestamp in ms": 1699759987169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988205000415317, "Avg loss": 0.7398945072200149, "Avg value loss": 0.47415388422086835, "Avg policy loss": 0.26574062719009817, "Total num played games": 48156, "Total num trained steps": 95744, "Timestamp in ms": 1699760025890, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988859845655962, "Avg loss": 0.6803663605824113, "Avg value loss": 0.4201423318590969, "Avg policy loss": 0.2602240345440805, "Total num played games": 48204, "Total num trained steps": 95872, "Timestamp in ms": 1699760087458, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 165.97650529816747, "Avg game time in secs": 1.117158395354636, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.69, "agent_stopped_0": 0.39}, "Total num played games": 48256, "Total num trained steps": 95993, "Timestamp in ms": 1699760153146, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875569358178053, "Avg loss": 0.7901937188580632, "Avg value loss": 0.5316306024906226, "Avg policy loss": 0.2585631220135838, "Total num played games": 48300, "Total num trained steps": 96000, "Timestamp in ms": 1699760157145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882518408207164, "Avg loss": 0.6542334742844105, "Avg value loss": 0.40639298706082627, "Avg policy loss": 0.24784048600122333, "Total num played games": 48348, "Total num trained steps": 96128, "Timestamp in ms": 1699760226576, "logtype": "training_step"}
{"Avg objective": 22.1484375, "Games time in secs": 104.47707791626453, "Avg game time in secs": 0.9712257773790043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 48384, "Total num trained steps": 96186, "Timestamp in ms": 1699760257623, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889247045210348, "Avg loss": 0.5180252082645893, "Avg value loss": 0.25922994245775044, "Avg policy loss": 0.25879526243079454, "Total num played games": 48396, "Total num trained steps": 96256, "Timestamp in ms": 1699760292824, "logtype": "training_step"}
{"Total num played games": 48396, "Total num trained steps": 96266, "Timestamp in ms": 1699760312855, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.859375}
{"Ratio train steps to played games": 1.9875652155981276, "Avg loss": 0.649570923531428, "Avg value loss": 0.3862848848802969, "Avg policy loss": 0.2632860420271754, "Total num played games": 48493, "Total num trained steps": 96384, "Timestamp in ms": 1699760369764, "logtype": "training_step"}
{"Avg objective": 22.8671875, "Games time in secs": 158.22271456196904, "Avg game time in secs": 1.1408573070366401, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 48512, "Total num trained steps": 96476, "Timestamp in ms": 1699760415846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882367483158567, "Avg loss": 0.5793658229522407, "Avg value loss": 0.31990667089121416, "Avg policy loss": 0.25945914757903665, "Total num played games": 48541, "Total num trained steps": 96512, "Timestamp in ms": 1699760434619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889069542489042, "Avg loss": 0.422808350645937, "Avg value loss": 0.17674387810984626, "Avg policy loss": 0.24606447108089924, "Total num played games": 48589, "Total num trained steps": 96640, "Timestamp in ms": 1699760503172, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 151.44333716854453, "Avg game time in secs": 1.2071514767012559, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 48640, "Total num trained steps": 96764, "Timestamp in ms": 1699760567289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987655081751705, "Avg loss": 0.5146088786423206, "Avg value loss": 0.2703452742425725, "Avg policy loss": 0.24426360602956265, "Total num played games": 48684, "Total num trained steps": 96768, "Timestamp in ms": 1699760568997, "logtype": "training_step"}
{"Total num played games": 48735, "Total num trained steps": 96867, "Timestamp in ms": 1699760641827, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.86328125}
{"Avg objective": 21.3046875, "Games time in secs": 76.60022298060358, "Avg game time in secs": 1.0389655358303571, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 48768, "Total num trained steps": 96870, "Timestamp in ms": 1699760643890, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862657073160732, "Avg loss": 0.7625849805772305, "Avg value loss": 0.5011250404058956, "Avg policy loss": 0.26145992742385715, "Total num played games": 48783, "Total num trained steps": 96896, "Timestamp in ms": 1699760657904, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988869073242728, "Avg loss": 0.42686098371632397, "Avg value loss": 0.1822254829457961, "Avg policy loss": 0.24463550047948956, "Total num played games": 48783, "Total num trained steps": 97024, "Timestamp in ms": 1699760723912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893723763694071, "Avg loss": 0.5152022533584386, "Avg value loss": 0.2704068710154388, "Avg policy loss": 0.24479538144078106, "Total num played games": 48835, "Total num trained steps": 97152, "Timestamp in ms": 1699760790843, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 199.06225936487317, "Avg game time in secs": 1.0739757186674979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 48896, "Total num trained steps": 97249, "Timestamp in ms": 1699760842952, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9881665270085225, "Avg loss": 0.5671854516258463, "Avg value loss": 0.31202810700051486, "Avg policy loss": 0.25515734462533146, "Total num played games": 48929, "Total num trained steps": 97280, "Timestamp in ms": 1699760858034, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988730093915884, "Avg loss": 0.47956739249639213, "Avg value loss": 0.22460835258243605, "Avg policy loss": 0.2549590403214097, "Total num played games": 48980, "Total num trained steps": 97408, "Timestamp in ms": 1699760920168, "logtype": "training_step"}
{"Avg objective": 21.75, "Games time in secs": 98.79274303093553, "Avg game time in secs": 1.078222150739748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.65, "agent_stopped_0": 0.4}, "Total num played games": 49024, "Total num trained steps": 97452, "Timestamp in ms": 1699760941745, "logtype": "played_game"}
{"Total num played games": 49029, "Total num trained steps": 97467, "Timestamp in ms": 1699760972450, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.36328125}
{"Ratio train steps to played games": 1.9873871671047538, "Avg loss": 0.7422991901403293, "Avg value loss": 0.47335022065090016, "Avg policy loss": 0.2689489657059312, "Total num played games": 49077, "Total num trained steps": 97536, "Timestamp in ms": 1699761007703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880508905852416, "Avg loss": 0.44280429545324296, "Avg value loss": 0.19188239946379326, "Avg policy loss": 0.250921898172237, "Total num played games": 49125, "Total num trained steps": 97664, "Timestamp in ms": 1699761071129, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 166.49173916690052, "Avg game time in secs": 0.9828868617769331, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 49152, "Total num trained steps": 97740, "Timestamp in ms": 1699761108237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887133182844243, "Avg loss": 0.5875958544202149, "Avg value loss": 0.3294006149517372, "Avg policy loss": 0.2581952369073406, "Total num played games": 49173, "Total num trained steps": 97792, "Timestamp in ms": 1699761133628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989394770524776, "Avg loss": 0.41678588720969856, "Avg value loss": 0.16522823716513813, "Avg policy loss": 0.25155764899682254, "Total num played games": 49221, "Total num trained steps": 97920, "Timestamp in ms": 1699761198589, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 143.29236203804612, "Avg game time in secs": 1.0212088656262495, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 49280, "Total num trained steps": 98030, "Timestamp in ms": 1699761251529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880570988280142, "Avg loss": 0.5747582681942731, "Avg value loss": 0.3234606766491197, "Avg policy loss": 0.2512975864810869, "Total num played games": 49318, "Total num trained steps": 98048, "Timestamp in ms": 1699761261209, "logtype": "training_step"}
{"Total num played games": 49318, "Total num trained steps": 98069, "Timestamp in ms": 1699761329085, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.28125}
{"Ratio train steps to played games": 1.9887169306810355, "Avg loss": 0.6567702682223171, "Avg value loss": 0.39014741563005373, "Avg policy loss": 0.2666228541638702, "Total num played games": 49366, "Total num trained steps": 98176, "Timestamp in ms": 1699761381761, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 153.43605854921043, "Avg game time in secs": 1.0055878968851175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 49408, "Total num trained steps": 98224, "Timestamp in ms": 1699761404966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893554588687645, "Avg loss": 0.4625016236677766, "Avg value loss": 0.21227614951203577, "Avg policy loss": 0.25022547226399183, "Total num played games": 49415, "Total num trained steps": 98304, "Timestamp in ms": 1699761443976, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988043302633705, "Avg loss": 0.7144667468965054, "Avg value loss": 0.44839982024859637, "Avg policy loss": 0.26606692699715495, "Total num played games": 49512, "Total num trained steps": 98432, "Timestamp in ms": 1699761506480, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 144.3414311595261, "Avg game time in secs": 1.0240284880273975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 49536, "Total num trained steps": 98515, "Timestamp in ms": 1699761549309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988680387409201, "Avg loss": 0.6489315931685269, "Avg value loss": 0.37297061615390703, "Avg policy loss": 0.27596097730565816, "Total num played games": 49560, "Total num trained steps": 98560, "Timestamp in ms": 1699761572913, "logtype": "training_step"}
{"Total num played games": 49609, "Total num trained steps": 98669, "Timestamp in ms": 1699761666386, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.07421875}
{"Ratio train steps to played games": 1.9873733813963792, "Avg loss": 0.5860284559894353, "Avg value loss": 0.31771610368741676, "Avg policy loss": 0.26831234665587544, "Total num played games": 49657, "Total num trained steps": 98688, "Timestamp in ms": 1699761675677, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 185.82207784056664, "Avg game time in secs": 1.0336811617162311, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 49664, "Total num trained steps": 98804, "Timestamp in ms": 1699761735129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880494920028167, "Avg loss": 0.4696471302304417, "Avg value loss": 0.20430074134492315, "Avg policy loss": 0.2653463832102716, "Total num played games": 49705, "Total num trained steps": 98816, "Timestamp in ms": 1699761741143, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988644129115247, "Avg loss": 0.54309589904733, "Avg value loss": 0.2748000932042487, "Avg policy loss": 0.26829580566845834, "Total num played games": 49754, "Total num trained steps": 98944, "Timestamp in ms": 1699761804788, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 95.96806462854147, "Avg game time in secs": 0.9769595140533056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 49792, "Total num trained steps": 99000, "Timestamp in ms": 1699761831098, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892976185695355, "Avg loss": 0.6336549678817391, "Avg value loss": 0.3602834349148907, "Avg policy loss": 0.27337153360713273, "Total num played games": 49802, "Total num trained steps": 99072, "Timestamp in ms": 1699761866767, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9880157918996373, "Avg loss": 0.6633298587985337, "Avg value loss": 0.384711887978483, "Avg policy loss": 0.27861796785146, "Total num played games": 49899, "Total num trained steps": 99200, "Timestamp in ms": 1699761928200, "logtype": "training_step"}
{"Total num played games": 49899, "Total num trained steps": 99270, "Timestamp in ms": 1699761997799, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.09375}
{"Avg objective": 22.5390625, "Games time in secs": 168.39964452199638, "Avg game time in secs": 1.0875481841067085, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.63, "agent_stopped_0": 0.44}, "Total num played games": 49920, "Total num trained steps": 99274, "Timestamp in ms": 1699761999497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886679880673515, "Avg loss": 0.7286922328639776, "Avg value loss": 0.4493742351187393, "Avg policy loss": 0.27931800368241966, "Total num played games": 49947, "Total num trained steps": 99328, "Timestamp in ms": 1699762027212, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892791423313865, "Avg loss": 0.6795873353257775, "Avg value loss": 0.39937360025942326, "Avg policy loss": 0.28021373483352363, "Total num played games": 49996, "Total num trained steps": 99456, "Timestamp in ms": 1699762090391, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 152.62348493747413, "Avg game time in secs": 1.0916809409100097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.58}, "Total num played games": 50048, "Total num trained steps": 99577, "Timestamp in ms": 1699762152121, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880020761798292, "Avg loss": 0.7319052554666996, "Avg value loss": 0.4450994122889824, "Avg policy loss": 0.2868058324092999, "Total num played games": 50092, "Total num trained steps": 99584, "Timestamp in ms": 1699762154945, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886717191862784, "Avg loss": 0.6006046875845641, "Avg value loss": 0.31529442535247654, "Avg policy loss": 0.28531026327982545, "Total num played games": 50140, "Total num trained steps": 99712, "Timestamp in ms": 1699762217529, "logtype": "training_step"}
{"Avg objective": 22.3828125, "Games time in secs": 95.28088727593422, "Avg game time in secs": 0.9512292227445869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 50176, "Total num trained steps": 99771, "Timestamp in ms": 1699762247402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893201562126406, "Avg loss": 0.567158913007006, "Avg value loss": 0.28243777045281604, "Avg policy loss": 0.2847211442422122, "Total num played games": 50188, "Total num trained steps": 99840, "Timestamp in ms": 1699762281538, "logtype": "training_step"}
{"Total num played games": 50237, "Total num trained steps": 99870, "Timestamp in ms": 1699762308496, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.921875}
{"Ratio train steps to played games": 1.9880083523913692, "Avg loss": 0.9700303706340492, "Avg value loss": 0.6708464974653907, "Avg policy loss": 0.29918385937344283, "Total num played games": 50285, "Total num trained steps": 99968, "Timestamp in ms": 1699762358888, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 161.30680851265788, "Avg game time in secs": 1.0077085015946068, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 50304, "Total num trained steps": 100061, "Timestamp in ms": 1699762408709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885370311506676, "Avg loss": 0.5490042534656823, "Avg value loss": 0.26306913571897894, "Avg policy loss": 0.28593511565122753, "Total num played games": 50336, "Total num trained steps": 100096, "Timestamp in ms": 1699762426172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891830739917433, "Avg loss": 0.6173080082517117, "Avg value loss": 0.3346241118852049, "Avg policy loss": 0.2826838894980028, "Total num played games": 50384, "Total num trained steps": 100224, "Timestamp in ms": 1699762488192, "logtype": "training_step"}
{"Avg objective": 22.75, "Games time in secs": 96.31690409220755, "Avg game time in secs": 1.102967591054039, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.69, "agent_stopped_0": 0.39}, "Total num played games": 50432, "Total num trained steps": 100260, "Timestamp in ms": 1699762505026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898477157360406, "Avg loss": 0.5712392886634916, "Avg value loss": 0.3001086145523004, "Avg policy loss": 0.27113067416939884, "Total num played games": 50432, "Total num trained steps": 100352, "Timestamp in ms": 1699762550745, "logtype": "training_step"}
{"Total num played games": 50528, "Total num trained steps": 100471, "Timestamp in ms": 1699762636395, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.78515625}
{"Avg objective": 22.7109375, "Games time in secs": 133.68301276117563, "Avg game time in secs": 0.8781783907616045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.47}, "Total num played games": 50560, "Total num trained steps": 100473, "Timestamp in ms": 1699762638709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866932932616261, "Avg loss": 0.7063861228525639, "Avg value loss": 0.43074871704448014, "Avg policy loss": 0.27563740918412805, "Total num played games": 50576, "Total num trained steps": 100480, "Timestamp in ms": 1699762642101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892241379310345, "Avg loss": 0.47461644001305103, "Avg value loss": 0.20595758443232626, "Avg policy loss": 0.2686588551150635, "Total num played games": 50576, "Total num trained steps": 100608, "Timestamp in ms": 1699762708704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898862199747156, "Avg loss": 0.47849924210458994, "Avg value loss": 0.2139696093800012, "Avg policy loss": 0.26452962832991034, "Total num played games": 50624, "Total num trained steps": 100736, "Timestamp in ms": 1699762771374, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 182.45241118595004, "Avg game time in secs": 1.0123941670171916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.6}, "Total num played games": 50688, "Total num trained steps": 100836, "Timestamp in ms": 1699762821162, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885846099248832, "Avg loss": 0.7230394950602204, "Avg value loss": 0.44764292461331934, "Avg policy loss": 0.2753965660231188, "Total num played games": 50721, "Total num trained steps": 100864, "Timestamp in ms": 1699762834177, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892257086017058, "Avg loss": 0.5362242523115128, "Avg value loss": 0.27010410733055323, "Avg policy loss": 0.2661201417213306, "Total num played games": 50769, "Total num trained steps": 100992, "Timestamp in ms": 1699762896891, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 94.77897287160158, "Avg game time in secs": 1.1332097929989686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 50816, "Total num trained steps": 101030, "Timestamp in ms": 1699762915941, "logtype": "played_game"}
{"Total num played games": 50817, "Total num trained steps": 101074, "Timestamp in ms": 1699762987714, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.73046875}
{"Ratio train steps to played games": 1.9879878108719158, "Avg loss": 0.7357981347013265, "Avg value loss": 0.46045514987781644, "Avg policy loss": 0.27534298377577215, "Total num played games": 50865, "Total num trained steps": 101120, "Timestamp in ms": 1699763011071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886276589476166, "Avg loss": 0.4726710822433233, "Avg value loss": 0.21194028743775561, "Avg policy loss": 0.26073079474736005, "Total num played games": 50913, "Total num trained steps": 101248, "Timestamp in ms": 1699763071793, "logtype": "training_step"}
{"Avg objective": 20.7578125, "Games time in secs": 190.3997211009264, "Avg game time in secs": 1.0411863977788016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.55, "agent_stopped_0": 0.46}, "Total num played games": 50944, "Total num trained steps": 101317, "Timestamp in ms": 1699763106341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989149203359234, "Avg loss": 0.5738102928735316, "Avg value loss": 0.3074719620635733, "Avg policy loss": 0.26633833174128085, "Total num played games": 50964, "Total num trained steps": 101376, "Timestamp in ms": 1699763135074, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989786716850937, "Avg loss": 0.5112409829162061, "Avg value loss": 0.23461271618725732, "Avg policy loss": 0.2766282659722492, "Total num played games": 51012, "Total num trained steps": 101504, "Timestamp in ms": 1699763197885, "logtype": "training_step"}
{"Avg objective": 20.6875, "Games time in secs": 143.50301962159574, "Avg game time in secs": 0.9726874944171868, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 51072, "Total num trained steps": 101610, "Timestamp in ms": 1699763249844, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885147430002543, "Avg loss": 0.5547327697277069, "Avg value loss": 0.28820865001762286, "Avg policy loss": 0.26652411720715463, "Total num played games": 51109, "Total num trained steps": 101632, "Timestamp in ms": 1699763259565, "logtype": "training_step"}
{"Total num played games": 51109, "Total num trained steps": 101674, "Timestamp in ms": 1699763300511, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.87890625}
{"Ratio train steps to played games": 1.9891705924897864, "Avg loss": 0.5823949854820967, "Avg value loss": 0.3190443827188574, "Avg policy loss": 0.2633506009588018, "Total num played games": 51157, "Total num trained steps": 101760, "Timestamp in ms": 1699763343956, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 116.12445869483054, "Avg game time in secs": 0.9911882727319608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 51200, "Total num trained steps": 101806, "Timestamp in ms": 1699763365971, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898056830387658, "Avg loss": 0.7242323483806103, "Avg value loss": 0.4560627333994489, "Avg policy loss": 0.2681696128565818, "Total num played games": 51205, "Total num trained steps": 101888, "Timestamp in ms": 1699763406870, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988363934042802, "Avg loss": 0.646217516856268, "Avg value loss": 0.3734524862957187, "Avg policy loss": 0.2727650267770514, "Total num played games": 51306, "Total num trained steps": 102016, "Timestamp in ms": 1699763471357, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 149.27297996543348, "Avg game time in secs": 1.0298117016500328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 51328, "Total num trained steps": 102102, "Timestamp in ms": 1699763515244, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890174085757681, "Avg loss": 0.682965689804405, "Avg value loss": 0.4067962258704938, "Avg policy loss": 0.2761694628279656, "Total num played games": 51354, "Total num trained steps": 102144, "Timestamp in ms": 1699763537664, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896307536671725, "Avg loss": 0.6771436175331473, "Avg value loss": 0.3993804097408429, "Avg policy loss": 0.27776320942211896, "Total num played games": 51402, "Total num trained steps": 102272, "Timestamp in ms": 1699763602662, "logtype": "training_step"}
{"Total num played games": 51402, "Total num trained steps": 102276, "Timestamp in ms": 1699763618516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5703125}
{"Avg objective": 21.859375, "Games time in secs": 158.6210768967867, "Avg game time in secs": 0.9787605208402965, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.66, "agent_stopped_0": 0.37}, "Total num played games": 51456, "Total num trained steps": 102389, "Timestamp in ms": 1699763673865, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884073167890015, "Avg loss": 0.5930472454056144, "Avg value loss": 0.3177344965515658, "Avg policy loss": 0.275312741054222, "Total num played games": 51498, "Total num trained steps": 102400, "Timestamp in ms": 1699763678597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989058316843208, "Avg loss": 0.5750511360820383, "Avg value loss": 0.3103553352993913, "Avg policy loss": 0.26469579653348774, "Total num played games": 51546, "Total num trained steps": 102528, "Timestamp in ms": 1699763740084, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 93.76410618424416, "Avg game time in secs": 0.9523750735388603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 51584, "Total num trained steps": 102584, "Timestamp in ms": 1699763767629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989437984496124, "Avg loss": 0.4519303818233311, "Avg value loss": 0.19068749429425225, "Avg policy loss": 0.26124288665596396, "Total num played games": 51600, "Total num trained steps": 102656, "Timestamp in ms": 1699763803665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900673791821561, "Avg loss": 0.5651999218389392, "Avg value loss": 0.3030031152884476, "Avg policy loss": 0.26219681405927986, "Total num played games": 51648, "Total num trained steps": 102784, "Timestamp in ms": 1699763869121, "logtype": "training_step"}
{"Total num played games": 51696, "Total num trained steps": 102876, "Timestamp in ms": 1699763940251, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.19921875}
{"Avg objective": 21.109375, "Games time in secs": 174.28858694806695, "Avg game time in secs": 1.053118477924727, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 51712, "Total num trained steps": 102879, "Timestamp in ms": 1699763941918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888682745825603, "Avg loss": 0.6650009870063514, "Avg value loss": 0.4022184113273397, "Avg policy loss": 0.2627825763775036, "Total num played games": 51744, "Total num trained steps": 102912, "Timestamp in ms": 1699763957772, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894964473277725, "Avg loss": 0.5808037563692778, "Avg value loss": 0.3165913170669228, "Avg policy loss": 0.26421244349330664, "Total num played games": 51792, "Total num trained steps": 103040, "Timestamp in ms": 1699764020795, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 97.36674227006733, "Avg game time in secs": 1.0008463394187856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.65, "agent_stopped_0": 0.39}, "Total num played games": 51840, "Total num trained steps": 103077, "Timestamp in ms": 1699764039285, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901041666666666, "Avg loss": 0.5594561842735857, "Avg value loss": 0.30128855333896354, "Avg policy loss": 0.2581676305271685, "Total num played games": 51840, "Total num trained steps": 103168, "Timestamp in ms": 1699764083280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988909426987061, "Avg loss": 0.8079995941370726, "Avg value loss": 0.5358058985439129, "Avg policy loss": 0.2721936902962625, "Total num played games": 51936, "Total num trained steps": 103296, "Timestamp in ms": 1699764149584, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 142.7320279441774, "Avg game time in secs": 0.9614975302829407, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 51968, "Total num trained steps": 103363, "Timestamp in ms": 1699764182017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895160049245921, "Avg loss": 0.5138690443709493, "Avg value loss": 0.25065849674865603, "Avg policy loss": 0.26321055239532143, "Total num played games": 51984, "Total num trained steps": 103424, "Timestamp in ms": 1699764212687, "logtype": "training_step"}
{"Total num played games": 52032, "Total num trained steps": 103479, "Timestamp in ms": 1699764252393, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8828125}
{"Ratio train steps to played games": 1.9883064516129032, "Avg loss": 1.0747706016991287, "Avg value loss": 0.794719148078002, "Avg policy loss": 0.2800514579284936, "Total num played games": 52080, "Total num trained steps": 103552, "Timestamp in ms": 1699764287816, "logtype": "training_step"}
{"Avg objective": 22.7265625, "Games time in secs": 154.4215069897473, "Avg game time in secs": 0.9784998843097128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 52096, "Total num trained steps": 103650, "Timestamp in ms": 1699764336439, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889310926949049, "Avg loss": 0.46122379088774323, "Avg value loss": 0.2079966348828748, "Avg policy loss": 0.253227157285437, "Total num played games": 52128, "Total num trained steps": 103680, "Timestamp in ms": 1699764350261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989573750383318, "Avg loss": 0.511414430802688, "Avg value loss": 0.2542667269590311, "Avg policy loss": 0.25714770320337266, "Total num played games": 52176, "Total num trained steps": 103808, "Timestamp in ms": 1699764411449, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 92.66973492689431, "Avg game time in secs": 1.0106617675628513, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 52224, "Total num trained steps": 103847, "Timestamp in ms": 1699764429109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901960784313726, "Avg loss": 0.5028725238516927, "Avg value loss": 0.24008931283606216, "Avg policy loss": 0.2627832102589309, "Total num played games": 52224, "Total num trained steps": 103936, "Timestamp in ms": 1699764474225, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889336977504253, "Avg loss": 0.6887807559687644, "Avg value loss": 0.4237147030653432, "Avg policy loss": 0.26506605418398976, "Total num played games": 52321, "Total num trained steps": 104064, "Timestamp in ms": 1699764536474, "logtype": "training_step"}
{"Total num played games": 52321, "Total num trained steps": 104082, "Timestamp in ms": 1699764558658, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.33203125}
{"Avg objective": 21.4296875, "Games time in secs": 131.59962313249707, "Avg game time in secs": 0.9541882730991347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.64}, "Total num played games": 52352, "Total num trained steps": 104087, "Timestamp in ms": 1699764560709, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895548893429318, "Avg loss": 0.7413103561848402, "Avg value loss": 0.47385819302871823, "Avg policy loss": 0.26745217258576304, "Total num played games": 52369, "Total num trained steps": 104192, "Timestamp in ms": 1699764610980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900230823524923, "Avg loss": 0.5483694833237678, "Avg value loss": 0.280865965760313, "Avg policy loss": 0.2675035163993016, "Total num played games": 52421, "Total num trained steps": 104320, "Timestamp in ms": 1699764676442, "logtype": "training_step"}
{"Avg objective": 22.8671875, "Games time in secs": 171.3535381630063, "Avg game time in secs": 1.0926919711491792, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.77, "agent_stopped_0": 0.33}, "Total num played games": 52480, "Total num trained steps": 104430, "Timestamp in ms": 1699764732062, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988784797593206, "Avg loss": 0.7735617307480425, "Avg value loss": 0.502469826315064, "Avg policy loss": 0.27109190588817, "Total num played games": 52518, "Total num trained steps": 104448, "Timestamp in ms": 1699764740004, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893471313346522, "Avg loss": 0.5845269581768662, "Avg value loss": 0.3172671325155534, "Avg policy loss": 0.26725982618518174, "Total num played games": 52568, "Total num trained steps": 104576, "Timestamp in ms": 1699764801804, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 94.73042459599674, "Avg game time in secs": 1.0054295808658935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.67}, "Total num played games": 52608, "Total num trained steps": 104628, "Timestamp in ms": 1699764826793, "logtype": "played_game"}
{"Total num played games": 52616, "Total num trained steps": 104683, "Timestamp in ms": 1699764865563, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.86328125}
{"Ratio train steps to played games": 1.9881323104967341, "Avg loss": 0.6607124202419072, "Avg value loss": 0.3883583026472479, "Avg policy loss": 0.27235411875881255, "Total num played games": 52664, "Total num trained steps": 104704, "Timestamp in ms": 1699764876046, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988542812701544, "Avg loss": 0.5664463699795306, "Avg value loss": 0.29870356954052113, "Avg policy loss": 0.267742796218954, "Total num played games": 52718, "Total num trained steps": 104832, "Timestamp in ms": 1699764938815, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 158.43881878070533, "Avg game time in secs": 0.9443370628141565, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 52736, "Total num trained steps": 104926, "Timestamp in ms": 1699764985232, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891407345639238, "Avg loss": 0.6150418350007385, "Avg value loss": 0.34740447875810787, "Avg policy loss": 0.26763735665008426, "Total num played games": 52766, "Total num trained steps": 104960, "Timestamp in ms": 1699765001663, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893045091432249, "Avg loss": 0.45774146378971636, "Avg value loss": 0.20236845657927915, "Avg policy loss": 0.2553730078507215, "Total num played games": 52826, "Total num trained steps": 105088, "Timestamp in ms": 1699765068534, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 110.47356940805912, "Avg game time in secs": 0.9994069605600089, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 52864, "Total num trained steps": 105144, "Timestamp in ms": 1699765095706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898817966903073, "Avg loss": 0.47108568460680544, "Avg value loss": 0.22397229075431824, "Avg policy loss": 0.24711339478380978, "Total num played games": 52875, "Total num trained steps": 105216, "Timestamp in ms": 1699765133168, "logtype": "training_step"}
{"Total num played games": 52929, "Total num trained steps": 105286, "Timestamp in ms": 1699765189503, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.96875}
{"Ratio train steps to played games": 1.9884855692092795, "Avg loss": 0.7402212873566896, "Avg value loss": 0.47187924542231485, "Avg policy loss": 0.2683420449029654, "Total num played games": 52977, "Total num trained steps": 105344, "Timestamp in ms": 1699765220788, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 176.0118215996772, "Avg game time in secs": 1.035453393124044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 52992, "Total num trained steps": 105444, "Timestamp in ms": 1699765271718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890806223479491, "Avg loss": 0.4783966615796089, "Avg value loss": 0.21337783918716013, "Avg policy loss": 0.2650188187835738, "Total num played games": 53025, "Total num trained steps": 105472, "Timestamp in ms": 1699765285257, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989506010022985, "Avg loss": 0.5204971795901656, "Avg value loss": 0.2514061920228414, "Avg policy loss": 0.269090982968919, "Total num played games": 53078, "Total num trained steps": 105600, "Timestamp in ms": 1699765348625, "logtype": "training_step"}
{"Avg objective": 21.8359375, "Games time in secs": 100.29887237772346, "Avg game time in secs": 1.0164636574190808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.69}, "Total num played games": 53120, "Total num trained steps": 105648, "Timestamp in ms": 1699765372017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9901366562511764, "Avg loss": 0.4424715884961188, "Avg value loss": 0.17363154454506002, "Avg policy loss": 0.2688400427578017, "Total num played games": 53126, "Total num trained steps": 105728, "Timestamp in ms": 1699765412675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988933147946338, "Avg loss": 0.592403429094702, "Avg value loss": 0.328123873565346, "Avg policy loss": 0.2642795586725697, "Total num played games": 53222, "Total num trained steps": 105856, "Timestamp in ms": 1699765473945, "logtype": "training_step"}
{"Total num played games": 53222, "Total num trained steps": 105889, "Timestamp in ms": 1699765505179, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0390625}
{"Avg objective": 21.953125, "Games time in secs": 134.8919199500233, "Avg game time in secs": 0.9492706113378517, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 53248, "Total num trained steps": 105893, "Timestamp in ms": 1699765506909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989543833302046, "Avg loss": 0.5885936843696982, "Avg value loss": 0.32625625032233074, "Avg policy loss": 0.26233743922784925, "Total num played games": 53270, "Total num trained steps": 105984, "Timestamp in ms": 1699765554563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901534191079935, "Avg loss": 0.5096527483547106, "Avg value loss": 0.25500314435339533, "Avg policy loss": 0.25464960164390504, "Total num played games": 53318, "Total num trained steps": 106112, "Timestamp in ms": 1699765618800, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 165.7965557165444, "Avg game time in secs": 0.9755080627655843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 53376, "Total num trained steps": 106222, "Timestamp in ms": 1699765672705, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889729284457258, "Avg loss": 0.6193025740794837, "Avg value loss": 0.36660872341599315, "Avg policy loss": 0.25269385788124055, "Total num played games": 53414, "Total num trained steps": 106240, "Timestamp in ms": 1699765681166, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895813849089072, "Avg loss": 0.5497947551775724, "Avg value loss": 0.2854911769973114, "Avg policy loss": 0.2643035773653537, "Total num played games": 53462, "Total num trained steps": 106368, "Timestamp in ms": 1699765750343, "logtype": "training_step"}
{"Avg objective": 20.5234375, "Games time in secs": 101.56716367602348, "Avg game time in secs": 1.015643724866095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.7}, "Total num played games": 53504, "Total num trained steps": 106416, "Timestamp in ms": 1699765774273, "logtype": "played_game"}
{"Total num played games": 53510, "Total num trained steps": 106491, "Timestamp in ms": 1699765826291, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.640625}
{"Ratio train steps to played games": 1.9884608921336147, "Avg loss": 0.4749353392980993, "Avg value loss": 0.22268971422454342, "Avg policy loss": 0.2522456175647676, "Total num played games": 53557, "Total num trained steps": 106496, "Timestamp in ms": 1699765829403, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98901242398239, "Avg loss": 0.7697226263117045, "Avg value loss": 0.5065572892781347, "Avg policy loss": 0.26316532935015857, "Total num played games": 53606, "Total num trained steps": 106624, "Timestamp in ms": 1699765891543, "logtype": "training_step"}
{"Avg objective": 22.6640625, "Games time in secs": 159.39024803601205, "Avg game time in secs": 0.9723655665584374, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 53632, "Total num trained steps": 106702, "Timestamp in ms": 1699765933663, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989581586059081, "Avg loss": 0.49129846482537687, "Avg value loss": 0.2349936583195813, "Avg policy loss": 0.25630481191910803, "Total num played games": 53655, "Total num trained steps": 106752, "Timestamp in ms": 1699765958524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898532916294311, "Avg loss": 0.45016275392845273, "Avg value loss": 0.1993349297263194, "Avg policy loss": 0.2508278253953904, "Total num played games": 53712, "Total num trained steps": 106880, "Timestamp in ms": 1699766023230, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 107.35796498320997, "Avg game time in secs": 1.0365981910581468, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 53760, "Total num trained steps": 106916, "Timestamp in ms": 1699766041021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904391659381335, "Avg loss": 0.5160648481687531, "Avg value loss": 0.2688662131258752, "Avg policy loss": 0.2471986359450966, "Total num played games": 53761, "Total num trained steps": 107008, "Timestamp in ms": 1699766084639, "logtype": "training_step"}
{"Total num played games": 53810, "Total num trained steps": 107094, "Timestamp in ms": 1699766136326, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.0390625}
{"Ratio train steps to played games": 1.9892309406216346, "Avg loss": 0.6248829131945968, "Avg value loss": 0.3779642428853549, "Avg policy loss": 0.24691866675857455, "Total num played games": 53858, "Total num trained steps": 107136, "Timestamp in ms": 1699766156499, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 151.44740211218596, "Avg game time in secs": 0.916990570811322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.53, "agent_stopped_0": 0.49}, "Total num played games": 53888, "Total num trained steps": 107207, "Timestamp in ms": 1699766192469, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897786929341272, "Avg loss": 0.4807854627724737, "Avg value loss": 0.2309795388719067, "Avg policy loss": 0.2498059265781194, "Total num played games": 53907, "Total num trained steps": 107264, "Timestamp in ms": 1699766220653, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903808729496804, "Avg loss": 0.6601927563315257, "Avg value loss": 0.41100330467452295, "Avg policy loss": 0.249189464841038, "Total num played games": 53955, "Total num trained steps": 107392, "Timestamp in ms": 1699766286460, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 148.4074751008302, "Avg game time in secs": 0.9579619033902418, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 54016, "Total num trained steps": 107504, "Timestamp in ms": 1699766340876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890666913329016, "Avg loss": 0.645007808925584, "Avg value loss": 0.39355451802839525, "Avg policy loss": 0.2514532982604578, "Total num played games": 54055, "Total num trained steps": 107520, "Timestamp in ms": 1699766348805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989483994973017, "Avg loss": 0.4758914161939174, "Avg value loss": 0.2300031938648317, "Avg policy loss": 0.2458882227074355, "Total num played games": 54108, "Total num trained steps": 107648, "Timestamp in ms": 1699766413388, "logtype": "training_step"}
{"Total num played games": 54108, "Total num trained steps": 107695, "Timestamp in ms": 1699766449828, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.12109375}
{"Avg objective": 21.4375, "Games time in secs": 111.05652556195855, "Avg game time in secs": 0.8985463453718694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 54144, "Total num trained steps": 107698, "Timestamp in ms": 1699766451933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900842011965434, "Avg loss": 0.5244298782199621, "Avg value loss": 0.2818259336054325, "Avg policy loss": 0.242603940772824, "Total num played games": 54156, "Total num trained steps": 107776, "Timestamp in ms": 1699766490710, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903345999188402, "Avg loss": 0.5942035911139101, "Avg value loss": 0.3484497414319776, "Avg policy loss": 0.2457538420567289, "Total num played games": 54212, "Total num trained steps": 107904, "Timestamp in ms": 1699766551256, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 143.3608925845474, "Avg game time in secs": 0.8978569196187891, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.47, "agent_stopped_0": 0.56}, "Total num played games": 54272, "Total num trained steps": 108000, "Timestamp in ms": 1699766595294, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989411266412537, "Avg loss": 0.5562957066576928, "Avg value loss": 0.31680790515383705, "Avg policy loss": 0.23948780831415206, "Total num played games": 54303, "Total num trained steps": 108032, "Timestamp in ms": 1699766609597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898629380921717, "Avg loss": 0.5439722957089543, "Avg value loss": 0.2889046518248506, "Avg policy loss": 0.2550676439423114, "Total num played games": 54355, "Total num trained steps": 108160, "Timestamp in ms": 1699766666979, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 90.06296621076763, "Avg game time in secs": 0.9736954265681561, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.68}, "Total num played games": 54400, "Total num trained steps": 108202, "Timestamp in ms": 1699766685357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904600849217875, "Avg loss": 0.534766107914038, "Avg value loss": 0.2736105039366521, "Avg policy loss": 0.2611556004267186, "Total num played games": 54403, "Total num trained steps": 108288, "Timestamp in ms": 1699766722607, "logtype": "training_step"}
{"Total num played games": 54451, "Total num trained steps": 108298, "Timestamp in ms": 1699766737852, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83984375}
{"Ratio train steps to played games": 1.989302556010202, "Avg loss": 0.7248229421675205, "Avg value loss": 0.46033331169746816, "Avg policy loss": 0.2644896262791008, "Total num played games": 54499, "Total num trained steps": 108416, "Timestamp in ms": 1699766793852, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 142.9306312892586, "Avg game time in secs": 0.9384485960908933, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 54528, "Total num trained steps": 108489, "Timestamp in ms": 1699766828288, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898621397668108, "Avg loss": 0.6657710104482248, "Avg value loss": 0.4100658295501489, "Avg policy loss": 0.2557051843032241, "Total num played games": 54548, "Total num trained steps": 108544, "Timestamp in ms": 1699766853301, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904207190871293, "Avg loss": 0.44365438516251743, "Avg value loss": 0.19322749879211187, "Avg policy loss": 0.2504268877673894, "Total num played games": 54597, "Total num trained steps": 108672, "Timestamp in ms": 1699766911802, "logtype": "training_step"}
{"Avg objective": 20.0390625, "Games time in secs": 132.84023318439722, "Avg game time in secs": 0.930622689644224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 54656, "Total num trained steps": 108782, "Timestamp in ms": 1699766961128, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989230994258968, "Avg loss": 0.627950381487608, "Avg value loss": 0.375088527740445, "Avg policy loss": 0.252861856832169, "Total num played games": 54694, "Total num trained steps": 108800, "Timestamp in ms": 1699766968936, "logtype": "training_step"}
{"Total num played games": 54742, "Total num trained steps": 108902, "Timestamp in ms": 1699767024905, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.02734375}
{"Avg objective": 21.15625, "Games time in secs": 65.90057138353586, "Avg game time in secs": 0.9350400008261204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 54784, "Total num trained steps": 108907, "Timestamp in ms": 1699767027029, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880817667457564, "Avg loss": 0.7443257416598499, "Avg value loss": 0.47596001834608614, "Avg policy loss": 0.2683657204033807, "Total num played games": 54790, "Total num trained steps": 108928, "Timestamp in ms": 1699767036426, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904179594816573, "Avg loss": 0.37810334993992, "Avg value loss": 0.12916898221010342, "Avg policy loss": 0.24893436639104038, "Total num played games": 54790, "Total num trained steps": 109056, "Timestamp in ms": 1699767094686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989268665962176, "Avg loss": 0.590390138560906, "Avg value loss": 0.3416383490257431, "Avg policy loss": 0.2487517928238958, "Total num played games": 54886, "Total num trained steps": 109184, "Timestamp in ms": 1699767153062, "logtype": "training_step"}
{"Avg objective": 22.609375, "Games time in secs": 161.2356528826058, "Avg game time in secs": 0.9102113992557861, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 54912, "Total num trained steps": 109263, "Timestamp in ms": 1699767188265, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898605599446608, "Avg loss": 0.5466397169511765, "Avg value loss": 0.291889657266438, "Avg policy loss": 0.2547500607324764, "Total num played games": 54934, "Total num trained steps": 109312, "Timestamp in ms": 1699767209249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904696082354225, "Avg loss": 0.47106772544793785, "Avg value loss": 0.22508013324113563, "Avg policy loss": 0.24598758993670344, "Total num played games": 54982, "Total num trained steps": 109440, "Timestamp in ms": 1699767267093, "logtype": "training_step"}
{"Total num played games": 55030, "Total num trained steps": 109503, "Timestamp in ms": 1699767337936, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.1171875}
{"Avg objective": 21.453125, "Games time in secs": 151.0838096830994, "Avg game time in secs": 1.0029146761080483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.65, "agent_stopped_0": 0.41}, "Total num played games": 55040, "Total num trained steps": 109506, "Timestamp in ms": 1699767339349, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893060750208795, "Avg loss": 0.653573723975569, "Avg value loss": 0.38775908475508913, "Avg policy loss": 0.26581463403999805, "Total num played games": 55078, "Total num trained steps": 109568, "Timestamp in ms": 1699767366917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989859778330038, "Avg loss": 0.6461587024386972, "Avg value loss": 0.3757980993541423, "Avg policy loss": 0.2703606028808281, "Total num played games": 55127, "Total num trained steps": 109696, "Timestamp in ms": 1699767424221, "logtype": "training_step"}
{"Avg objective": 22.6640625, "Games time in secs": 107.69604402035475, "Avg game time in secs": 1.0374276773654856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.66}, "Total num played games": 55168, "Total num trained steps": 109746, "Timestamp in ms": 1699767447045, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990466696873584, "Avg loss": 0.5380523244384676, "Avg value loss": 0.26563811337109655, "Avg policy loss": 0.2724142128136009, "Total num played games": 55175, "Total num trained steps": 109824, "Timestamp in ms": 1699767482222, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893072316404625, "Avg loss": 0.6457996520912275, "Avg value loss": 0.3828279947920237, "Avg policy loss": 0.26297166128642857, "Total num played games": 55271, "Total num trained steps": 109952, "Timestamp in ms": 1699767540676, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 130.30555876344442, "Avg game time in secs": 0.8710506424686173, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.46, "agent_stopped_0": 0.57}, "Total num played games": 55296, "Total num trained steps": 110032, "Timestamp in ms": 1699767577351, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899130497659032, "Avg loss": 0.48977131117135286, "Avg value loss": 0.23230324883479625, "Avg policy loss": 0.25746806315146387, "Total num played games": 55319, "Total num trained steps": 110080, "Timestamp in ms": 1699767599877, "logtype": "training_step"}
{"Total num played games": 55319, "Total num trained steps": 110103, "Timestamp in ms": 1699767626649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.8125}
{"Ratio train steps to played games": 1.990481694872397, "Avg loss": 0.47233096580021083, "Avg value loss": 0.21453537879278883, "Avg policy loss": 0.2577955883461982, "Total num played games": 55367, "Total num trained steps": 110208, "Timestamp in ms": 1699767674786, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 149.20071491785347, "Avg game time in secs": 0.9795250616589328, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 55424, "Total num trained steps": 110320, "Timestamp in ms": 1699767726552, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893622775544055, "Avg loss": 0.6512527718441561, "Avg value loss": 0.39940432645380497, "Avg policy loss": 0.25184844445902854, "Total num played games": 55463, "Total num trained steps": 110336, "Timestamp in ms": 1699767733351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899299237988868, "Avg loss": 0.6105104053858668, "Avg value loss": 0.3624832970381249, "Avg policy loss": 0.24802710686344653, "Total num played games": 55511, "Total num trained steps": 110464, "Timestamp in ms": 1699767790341, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 85.65145722962916, "Avg game time in secs": 0.9281183614511974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 55552, "Total num trained steps": 110513, "Timestamp in ms": 1699767812203, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905325869796073, "Avg loss": 0.46731682936660945, "Avg value loss": 0.2160113512945827, "Avg policy loss": 0.2513054854935035, "Total num played games": 55559, "Total num trained steps": 110592, "Timestamp in ms": 1699767846904, "logtype": "training_step"}
{"Total num played games": 55615, "Total num trained steps": 110705, "Timestamp in ms": 1699767926157, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.625}
{"Ratio train steps to played games": 1.989095090095755, "Avg loss": 0.5358543319161981, "Avg value loss": 0.28320005343994126, "Avg policy loss": 0.2526542842388153, "Total num played games": 55663, "Total num trained steps": 110720, "Timestamp in ms": 1699767933765, "logtype": "training_step"}
{"Avg objective": 22.7109375, "Games time in secs": 166.72568380460143, "Avg game time in secs": 0.9674535892845597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.53, "agent_stopped_0": 0.49}, "Total num played games": 55680, "Total num trained steps": 110816, "Timestamp in ms": 1699767978929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896431648477886, "Avg loss": 0.537839534226805, "Avg value loss": 0.28128580647171475, "Avg policy loss": 0.25655372673645616, "Total num played games": 55712, "Total num trained steps": 110848, "Timestamp in ms": 1699767993397, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902439024390244, "Avg loss": 0.5593593444209546, "Avg value loss": 0.2994452466373332, "Avg policy loss": 0.25991409877315164, "Total num played games": 55760, "Total num trained steps": 110976, "Timestamp in ms": 1699768052011, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 89.97430485486984, "Avg game time in secs": 0.9823505672247848, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 55808, "Total num trained steps": 111013, "Timestamp in ms": 1699768068904, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990807769495413, "Avg loss": 0.43393752397969365, "Avg value loss": 0.17343818963854574, "Avg policy loss": 0.26049933512695134, "Total num played games": 55808, "Total num trained steps": 111104, "Timestamp in ms": 1699768110052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896787349742415, "Avg loss": 0.6516584935598075, "Avg value loss": 0.38684953417396173, "Avg policy loss": 0.2648089595604688, "Total num played games": 55904, "Total num trained steps": 111232, "Timestamp in ms": 1699768166592, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 129.28134246729314, "Avg game time in secs": 0.8909665922401473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.48}, "Total num played games": 55936, "Total num trained steps": 111299, "Timestamp in ms": 1699768198185, "logtype": "played_game"}
{"Total num played games": 55952, "Total num trained steps": 111308, "Timestamp in ms": 1699768222997, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9375}
{"Ratio train steps to played games": 1.9885535714285714, "Avg loss": 0.7972844815813005, "Avg value loss": 0.5196786483866163, "Avg policy loss": 0.2776058344170451, "Total num played games": 56000, "Total num trained steps": 111360, "Timestamp in ms": 1699768247922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908571428571429, "Avg loss": 0.36000285914633423, "Avg value loss": 0.1012581255636178, "Avg policy loss": 0.2587447324767709, "Total num played games": 56000, "Total num trained steps": 111488, "Timestamp in ms": 1699768305763, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 156.06667044200003, "Avg game time in secs": 0.9861067773745162, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 56064, "Total num trained steps": 111598, "Timestamp in ms": 1699768354252, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989483628326471, "Avg loss": 0.656443145358935, "Avg value loss": 0.3950651304621715, "Avg policy loss": 0.26137801713775843, "Total num played games": 56103, "Total num trained steps": 111616, "Timestamp in ms": 1699768362992, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898675119310492, "Avg loss": 0.45841337903402746, "Avg value loss": 0.19166545048938133, "Avg policy loss": 0.2667479267111048, "Total num played games": 56156, "Total num trained steps": 111744, "Timestamp in ms": 1699768421408, "logtype": "training_step"}
{"Avg objective": 20.9140625, "Games time in secs": 93.31904426589608, "Avg game time in secs": 0.9851833368447842, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.65}, "Total num played games": 56192, "Total num trained steps": 111804, "Timestamp in ms": 1699768447571, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904455198918227, "Avg loss": 0.4546973251271993, "Avg value loss": 0.19893876113928854, "Avg policy loss": 0.2557585636386648, "Total num played games": 56204, "Total num trained steps": 111872, "Timestamp in ms": 1699768479096, "logtype": "training_step"}
{"Total num played games": 56252, "Total num trained steps": 111910, "Timestamp in ms": 1699768553317, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3828125}
{"Ratio train steps to played games": 1.9893428063943162, "Avg loss": 0.6585911272559315, "Avg value loss": 0.38550675741862506, "Avg policy loss": 0.27308437053579837, "Total num played games": 56300, "Total num trained steps": 112000, "Timestamp in ms": 1699768596229, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 192.43573782220483, "Avg game time in secs": 0.9216052926785778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 56320, "Total num trained steps": 112090, "Timestamp in ms": 1699768640007, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896548664714755, "Avg loss": 0.40527898410800844, "Avg value loss": 0.15479886945104226, "Avg policy loss": 0.25048011587932706, "Total num played games": 56355, "Total num trained steps": 112128, "Timestamp in ms": 1699768656744, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902310160807049, "Avg loss": 0.48850566800683737, "Avg value loss": 0.22584143292624503, "Avg policy loss": 0.26266423729248345, "Total num played games": 56403, "Total num trained steps": 112256, "Timestamp in ms": 1699768713400, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 93.43936585634947, "Avg game time in secs": 1.029030199511908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 56448, "Total num trained steps": 112298, "Timestamp in ms": 1699768733447, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905240971324323, "Avg loss": 0.5481898984871805, "Avg value loss": 0.2715255521761719, "Avg policy loss": 0.27666434936691076, "Total num played games": 56459, "Total num trained steps": 112384, "Timestamp in ms": 1699768773267, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989056837266861, "Avg loss": 0.5201352620497346, "Avg value loss": 0.25741681360523216, "Avg policy loss": 0.2627184431767091, "Total num played games": 56565, "Total num trained steps": 112512, "Timestamp in ms": 1699768830982, "logtype": "training_step"}
{"Total num played games": 56565, "Total num trained steps": 112512, "Timestamp in ms": 1699768839589, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3828125}
{"Avg objective": 21.5703125, "Games time in secs": 107.56764642521739, "Avg game time in secs": 1.0040465887141181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 56576, "Total num trained steps": 112514, "Timestamp in ms": 1699768841017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896313567555155, "Avg loss": 0.6897820676676929, "Avg value loss": 0.40267181280069053, "Avg policy loss": 0.2871102591743693, "Total num played games": 56613, "Total num trained steps": 112640, "Timestamp in ms": 1699768897024, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990134655771844, "Avg loss": 0.4922319503966719, "Avg value loss": 0.23744371818611398, "Avg policy loss": 0.2547882304061204, "Total num played games": 56663, "Total num trained steps": 112768, "Timestamp in ms": 1699768954768, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 135.61981463618577, "Avg game time in secs": 1.0147519179590745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 56704, "Total num trained steps": 112818, "Timestamp in ms": 1699768976637, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990637067339058, "Avg loss": 0.5545122167095542, "Avg value loss": 0.29701839716290124, "Avg policy loss": 0.25749382260255516, "Total num played games": 56713, "Total num trained steps": 112896, "Timestamp in ms": 1699769011828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894562672721832, "Avg loss": 0.44553797401022166, "Avg value loss": 0.18483020743587986, "Avg policy loss": 0.2607077608117834, "Total num played games": 56811, "Total num trained steps": 113024, "Timestamp in ms": 1699769067388, "logtype": "training_step"}
{"Avg objective": 23.1796875, "Games time in secs": 131.40033744834363, "Avg game time in secs": 0.9966397394891828, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.57, "agent_stopped_0": 0.51}, "Total num played games": 56832, "Total num trained steps": 113112, "Timestamp in ms": 1699769108037, "logtype": "played_game"}
{"Total num played games": 56859, "Total num trained steps": 113112, "Timestamp in ms": 1699769138205, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.61328125}
{"Ratio train steps to played games": 1.9883494121988508, "Avg loss": 0.6976180052151904, "Avg value loss": 0.4259881619364023, "Avg policy loss": 0.27162984712049365, "Total num played games": 56907, "Total num trained steps": 113152, "Timestamp in ms": 1699769156449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990598696118228, "Avg loss": 0.36265709926374257, "Avg value loss": 0.09061891632154584, "Avg policy loss": 0.27203818305861205, "Total num played games": 56907, "Total num trained steps": 113280, "Timestamp in ms": 1699769215376, "logtype": "training_step"}
{"Avg objective": 20.7890625, "Games time in secs": 119.17143047228456, "Avg game time in secs": 0.9592317196511431, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.59, "agent_stopped_0": 0.42}, "Total num played games": 56960, "Total num trained steps": 113307, "Timestamp in ms": 1699769227209, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908538726213048, "Avg loss": 0.40472673275507987, "Avg value loss": 0.1496699062117841, "Avg policy loss": 0.2550568263977766, "Total num played games": 56964, "Total num trained steps": 113408, "Timestamp in ms": 1699769275622, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989398983704223, "Avg loss": 0.7742430283688009, "Avg value loss": 0.4990640056494158, "Avg policy loss": 0.2751790197798982, "Total num played games": 57070, "Total num trained steps": 113536, "Timestamp in ms": 1699769332953, "logtype": "training_step"}
{"Avg objective": 23.1640625, "Games time in secs": 149.86478752084076, "Avg game time in secs": 1.021202346732025, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.6, "agent_stopped_0": 0.47}, "Total num played games": 57088, "Total num trained steps": 113630, "Timestamp in ms": 1699769377074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899681361392205, "Avg loss": 0.6135294046252966, "Avg value loss": 0.3292939839884639, "Avg policy loss": 0.2842354215681553, "Total num played games": 57118, "Total num trained steps": 113664, "Timestamp in ms": 1699769393745, "logtype": "training_step"}
{"Total num played games": 57118, "Total num trained steps": 113715, "Timestamp in ms": 1699769432798, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.25}
{"Ratio train steps to played games": 1.9905538257005913, "Avg loss": 0.461748989415355, "Avg value loss": 0.18776628214982338, "Avg policy loss": 0.27398270240519196, "Total num played games": 57166, "Total num trained steps": 113792, "Timestamp in ms": 1699769468460, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 147.30026031658053, "Avg game time in secs": 1.0546763782040216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.66}, "Total num played games": 57216, "Total num trained steps": 113917, "Timestamp in ms": 1699769524374, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989973273708666, "Avg loss": 0.5118914495687932, "Avg value loss": 0.23599496891256422, "Avg policy loss": 0.2758964841486886, "Total num played games": 57246, "Total num trained steps": 113920, "Timestamp in ms": 1699769525175, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900017448961786, "Avg loss": 0.632103901123628, "Avg value loss": 0.3577552017522976, "Avg policy loss": 0.27434869937133044, "Total num played games": 57310, "Total num trained steps": 114048, "Timestamp in ms": 1699769582542, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 86.81062697060406, "Avg game time in secs": 0.8914787855610484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.49}, "Total num played games": 57344, "Total num trained steps": 114111, "Timestamp in ms": 1699769611185, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990394505168837, "Avg loss": 0.4930021711625159, "Avg value loss": 0.2147868295724038, "Avg policy loss": 0.27821534452959895, "Total num played games": 57363, "Total num trained steps": 114176, "Timestamp in ms": 1699769639644, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909599205727126, "Avg loss": 0.4033985808491707, "Avg value loss": 0.13674403401091695, "Avg policy loss": 0.26665454695466906, "Total num played games": 57411, "Total num trained steps": 114304, "Timestamp in ms": 1699769697501, "logtype": "training_step"}
{"Total num played games": 57464, "Total num trained steps": 114316, "Timestamp in ms": 1699769712933, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9921875}
{"Avg objective": 20.5390625, "Games time in secs": 102.91555810160935, "Avg game time in secs": 0.9415470092208125, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.56, "agent_stopped_0": 0.46}, "Total num played games": 57472, "Total num trained steps": 114317, "Timestamp in ms": 1699769714101, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98970649603561, "Avg loss": 0.8327838545665145, "Avg value loss": 0.547739629575517, "Avg policy loss": 0.2850442285416648, "Total num played games": 57512, "Total num trained steps": 114432, "Timestamp in ms": 1699769764757, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902536483669215, "Avg loss": 0.44994674157351255, "Avg value loss": 0.18048068133066408, "Avg policy loss": 0.2694660617271438, "Total num played games": 57560, "Total num trained steps": 114560, "Timestamp in ms": 1699769823575, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 132.5518179796636, "Avg game time in secs": 0.8913842746260343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 57600, "Total num trained steps": 114611, "Timestamp in ms": 1699769846653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908172476044994, "Avg loss": 0.6104431834537536, "Avg value loss": 0.3329846235283185, "Avg policy loss": 0.277458555996418, "Total num played games": 57608, "Total num trained steps": 114688, "Timestamp in ms": 1699769882817, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896717845631304, "Avg loss": 0.4954239879734814, "Avg value loss": 0.21061305826879106, "Avg policy loss": 0.2848109296755865, "Total num played games": 57706, "Total num trained steps": 114816, "Timestamp in ms": 1699769942564, "logtype": "training_step"}
{"Avg objective": 20.8671875, "Games time in secs": 135.7366805486381, "Avg game time in secs": 0.9673794366390212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.52, "agent_stopped_0": 0.49}, "Total num played games": 57728, "Total num trained steps": 114902, "Timestamp in ms": 1699769982389, "logtype": "played_game"}
{"Total num played games": 57754, "Total num trained steps": 114916, "Timestamp in ms": 1699770021765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.81640625}
{"Ratio train steps to played games": 1.9885644095360022, "Avg loss": 0.5582804419100285, "Avg value loss": 0.26945205265656114, "Avg policy loss": 0.28882839588914067, "Total num played games": 57802, "Total num trained steps": 114944, "Timestamp in ms": 1699770035461, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907788657831909, "Avg loss": 0.3617351492866874, "Avg value loss": 0.09107087019947357, "Avg policy loss": 0.27066427876707166, "Total num played games": 57802, "Total num trained steps": 115072, "Timestamp in ms": 1699770094905, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 166.26608510874212, "Avg game time in secs": 0.9595552784594474, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.61}, "Total num played games": 57856, "Total num trained steps": 115190, "Timestamp in ms": 1699770148656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896887629969948, "Avg loss": 0.5973275813739747, "Avg value loss": 0.3299114964029286, "Avg policy loss": 0.26741608092561364, "Total num played games": 57898, "Total num trained steps": 115200, "Timestamp in ms": 1699770153225, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902151966452102, "Avg loss": 0.7157285236753523, "Avg value loss": 0.43433302905759774, "Avg policy loss": 0.28139549714978784, "Total num played games": 57947, "Total num trained steps": 115328, "Timestamp in ms": 1699770210901, "logtype": "training_step"}
{"Avg objective": 22.4609375, "Games time in secs": 86.49428879842162, "Avg game time in secs": 0.8803425392543431, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.53}, "Total num played games": 57984, "Total num trained steps": 115385, "Timestamp in ms": 1699770235150, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907579833091937, "Avg loss": 0.6612266122829169, "Avg value loss": 0.38479625451145694, "Avg policy loss": 0.276430354337208, "Total num played games": 57996, "Total num trained steps": 115456, "Timestamp in ms": 1699770266072, "logtype": "training_step"}
{"Total num played games": 58052, "Total num trained steps": 115519, "Timestamp in ms": 1699770307569, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3671875}
{"Ratio train steps to played games": 1.989380378657487, "Avg loss": 0.7633046652190387, "Avg value loss": 0.4683846643893048, "Avg policy loss": 0.29492000211030245, "Total num played games": 58100, "Total num trained steps": 115584, "Timestamp in ms": 1699770337803, "logtype": "training_step"}
{"Avg objective": 23.078125, "Games time in secs": 151.09124152362347, "Avg game time in secs": 0.949152035813313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.57, "agent_stopped_0": 0.47}, "Total num played games": 58112, "Total num trained steps": 115690, "Timestamp in ms": 1699770386241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989939464813923, "Avg loss": 0.47471019194927067, "Avg value loss": 0.19768803514307365, "Avg policy loss": 0.27702215302269906, "Total num played games": 58148, "Total num trained steps": 115712, "Timestamp in ms": 1699770396265, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904976287030036, "Avg loss": 0.5486043677665293, "Avg value loss": 0.2765808586846106, "Avg policy loss": 0.2720235043670982, "Total num played games": 58196, "Total num trained steps": 115840, "Timestamp in ms": 1699770453889, "logtype": "training_step"}
{"Avg objective": 21.2578125, "Games time in secs": 88.22024201601744, "Avg game time in secs": 0.9032464597694343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.56}, "Total num played games": 58240, "Total num trained steps": 115884, "Timestamp in ms": 1699770474462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910206884711135, "Avg loss": 0.48850858793593943, "Avg value loss": 0.2259465530514717, "Avg policy loss": 0.26256203395314515, "Total num played games": 58245, "Total num trained steps": 115968, "Timestamp in ms": 1699770513307, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898191790213386, "Avg loss": 0.46831214521080256, "Avg value loss": 0.20632874601869844, "Avg policy loss": 0.26198339788243175, "Total num played games": 58345, "Total num trained steps": 116096, "Timestamp in ms": 1699770571188, "logtype": "training_step"}
{"Total num played games": 58345, "Total num trained steps": 116119, "Timestamp in ms": 1699770591501, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0546875}
{"Avg objective": 21.3984375, "Games time in secs": 118.81618120893836, "Avg game time in secs": 0.8873469242680585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.48, "agent_stopped_0": 0.55}, "Total num played games": 58368, "Total num trained steps": 116122, "Timestamp in ms": 1699770593278, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903584333738633, "Avg loss": 0.503403504495509, "Avg value loss": 0.23864707033499144, "Avg policy loss": 0.2647564358776435, "Total num played games": 58393, "Total num trained steps": 116224, "Timestamp in ms": 1699770640050, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907435923758683, "Avg loss": 0.44304690579883754, "Avg value loss": 0.18575491310912184, "Avg policy loss": 0.257291994872503, "Total num played games": 58446, "Total num trained steps": 116352, "Timestamp in ms": 1699770699973, "logtype": "training_step"}
{"Avg objective": 20.5703125, "Games time in secs": 163.35492812469602, "Avg game time in secs": 0.970465941762086, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 58496, "Total num trained steps": 116479, "Timestamp in ms": 1699770756633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912301695842451, "Avg loss": 0.4392676828429103, "Avg value loss": 0.1853545548801776, "Avg policy loss": 0.2539131280500442, "Total num played games": 58496, "Total num trained steps": 116480, "Timestamp in ms": 1699770756777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990186206072605, "Avg loss": 0.5801111307227984, "Avg value loss": 0.3235276486084331, "Avg policy loss": 0.25658347900025547, "Total num played games": 58591, "Total num trained steps": 116608, "Timestamp in ms": 1699770815841, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 88.57928371988237, "Avg game time in secs": 0.8972945814457489, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.48}, "Total num played games": 58624, "Total num trained steps": 116673, "Timestamp in ms": 1699770845213, "logtype": "played_game"}
{"Total num played games": 58640, "Total num trained steps": 116719, "Timestamp in ms": 1699770879964, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8671875}
{"Ratio train steps to played games": 1.9890778353326064, "Avg loss": 0.5186922773718834, "Avg value loss": 0.2662478319252841, "Avg policy loss": 0.2524444473674521, "Total num played games": 58688, "Total num trained steps": 116736, "Timestamp in ms": 1699770888132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912588604143948, "Avg loss": 0.35587676311843097, "Avg value loss": 0.1169945606670808, "Avg policy loss": 0.23888220230583102, "Total num played games": 58688, "Total num trained steps": 116864, "Timestamp in ms": 1699770946552, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 145.16722025163472, "Avg game time in secs": 0.9637259538576473, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.61, "agent_stopped_0": 0.43}, "Total num played games": 58752, "Total num trained steps": 116964, "Timestamp in ms": 1699770990380, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990133705303984, "Avg loss": 0.6324535245075822, "Avg value loss": 0.3940848926140461, "Avg policy loss": 0.23836862272582948, "Total num played games": 58786, "Total num trained steps": 116992, "Timestamp in ms": 1699771002396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905164941620355, "Avg loss": 0.5352502320893109, "Avg value loss": 0.2837624707899522, "Avg policy loss": 0.2514877605717629, "Total num played games": 58839, "Total num trained steps": 117120, "Timestamp in ms": 1699771059782, "logtype": "training_step"}
{"Avg objective": 21.6171875, "Games time in secs": 91.33990596607327, "Avg game time in secs": 0.9780204965354642, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 58880, "Total num trained steps": 117170, "Timestamp in ms": 1699771081720, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991067638018578, "Avg loss": 0.6017808571923524, "Avg value loss": 0.3415776731853839, "Avg policy loss": 0.260203187703155, "Total num played games": 58887, "Total num trained steps": 117248, "Timestamp in ms": 1699771117038, "logtype": "training_step"}
{"Total num played games": 58935, "Total num trained steps": 117322, "Timestamp in ms": 1699771162021, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4375}
{"Ratio train steps to played games": 1.9899801637760033, "Avg loss": 0.5824765805155039, "Avg value loss": 0.32002223533345386, "Avg policy loss": 0.26245434395968914, "Total num played games": 58983, "Total num trained steps": 117376, "Timestamp in ms": 1699771186599, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 141.11359067820013, "Avg game time in secs": 0.8996670063206693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 59008, "Total num trained steps": 117457, "Timestamp in ms": 1699771222834, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905303992817334, "Avg loss": 0.4282449559541419, "Avg value loss": 0.18785177951212972, "Avg policy loss": 0.24039317923597991, "Total num played games": 59031, "Total num trained steps": 117504, "Timestamp in ms": 1699771245238, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910629654705485, "Avg loss": 0.4748463082360104, "Avg value loss": 0.23752543603768572, "Avg policy loss": 0.23732087656389922, "Total num played games": 59080, "Total num trained steps": 117632, "Timestamp in ms": 1699771303876, "logtype": "training_step"}
{"Avg objective": 21.234375, "Games time in secs": 132.43965290114284, "Avg game time in secs": 0.9566784096532501, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 59136, "Total num trained steps": 117745, "Timestamp in ms": 1699771355274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899959443017439, "Avg loss": 0.4882690391968936, "Avg value loss": 0.24211646631010808, "Avg policy loss": 0.2461525684921071, "Total num played games": 59176, "Total num trained steps": 117760, "Timestamp in ms": 1699771362221, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903427317237887, "Avg loss": 0.5010026346426457, "Avg value loss": 0.25957474709139206, "Avg policy loss": 0.2414278860669583, "Total num played games": 59230, "Total num trained steps": 117888, "Timestamp in ms": 1699771418816, "logtype": "training_step"}
{"Total num played games": 59230, "Total num trained steps": 117923, "Timestamp in ms": 1699771453072, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.515625}
{"Avg objective": 22.5625, "Games time in secs": 101.14589285291731, "Avg game time in secs": 0.877835273873643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.48}, "Total num played games": 59264, "Total num trained steps": 117928, "Timestamp in ms": 1699771456420, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990890380917035, "Avg loss": 0.537026277044788, "Avg value loss": 0.29400267809978686, "Avg policy loss": 0.24302359810099006, "Total num played games": 59278, "Total num trained steps": 118016, "Timestamp in ms": 1699771496600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98996125989557, "Avg loss": 0.4501511853886768, "Avg value loss": 0.21272606152342632, "Avg policy loss": 0.23742512403987348, "Total num played games": 59370, "Total num trained steps": 118144, "Timestamp in ms": 1699771560464, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 150.53627393767238, "Avg game time in secs": 0.9886583694606088, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.58}, "Total num played games": 59392, "Total num trained steps": 118240, "Timestamp in ms": 1699771606956, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902901184706516, "Avg loss": 0.5644365970510989, "Avg value loss": 0.32240945028024726, "Avg policy loss": 0.24202714581042528, "Total num played games": 59424, "Total num trained steps": 118272, "Timestamp in ms": 1699771620680, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908360236750067, "Avg loss": 0.6890783911803737, "Avg value loss": 0.44575017277384177, "Avg policy loss": 0.2433282242855057, "Total num played games": 59472, "Total num trained steps": 118400, "Timestamp in ms": 1699771680475, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 90.16894892975688, "Avg game time in secs": 0.9110820070345653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 59520, "Total num trained steps": 118436, "Timestamp in ms": 1699771697125, "logtype": "played_game"}
{"Total num played games": 59520, "Total num trained steps": 118524, "Timestamp in ms": 1699771745307, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.33203125}
{"Ratio train steps to played games": 1.9902107295777012, "Avg loss": 0.49951307475566864, "Avg value loss": 0.2636536900536157, "Avg policy loss": 0.23585937917232513, "Total num played games": 59555, "Total num trained steps": 118528, "Timestamp in ms": 1699771747422, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901878564240187, "Avg loss": 0.5739686102606356, "Avg value loss": 0.33550491151981987, "Avg policy loss": 0.23846369236707687, "Total num played games": 59620, "Total num trained steps": 118656, "Timestamp in ms": 1699771805528, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 141.6272883526981, "Avg game time in secs": 0.8452434001810616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 59648, "Total num trained steps": 118731, "Timestamp in ms": 1699771838753, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907488100824562, "Avg loss": 0.5620171951595694, "Avg value loss": 0.3159309128532186, "Avg policy loss": 0.2460862701991573, "Total num played games": 59668, "Total num trained steps": 118784, "Timestamp in ms": 1699771863473, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912086807997589, "Avg loss": 0.6652602886315435, "Avg value loss": 0.41640086262486875, "Avg policy loss": 0.24885942484252155, "Total num played games": 59718, "Total num trained steps": 118912, "Timestamp in ms": 1699771922839, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 134.653503164649, "Avg game time in secs": 0.9151744506234536, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 59776, "Total num trained steps": 119028, "Timestamp in ms": 1699771973406, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900697126235016, "Avg loss": 0.5678237918764353, "Avg value loss": 0.3260583821393084, "Avg policy loss": 0.24176540900953114, "Total num played games": 59817, "Total num trained steps": 119040, "Timestamp in ms": 1699771978591, "logtype": "training_step"}
{"Total num played games": 59868, "Total num trained steps": 119125, "Timestamp in ms": 1699772026724, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9296875}
{"Avg objective": 21.7265625, "Games time in secs": 55.198187697678804, "Avg game time in secs": 0.8300754338561092, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0703125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.48}, "Total num played games": 59904, "Total num trained steps": 119129, "Timestamp in ms": 1699772028605, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889178182789238, "Avg loss": 0.6582858377369121, "Avg value loss": 0.4226535334601067, "Avg policy loss": 0.2356323068961501, "Total num played games": 59916, "Total num trained steps": 119168, "Timestamp in ms": 1699772047030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910541424661192, "Avg loss": 0.36911065480671823, "Avg value loss": 0.13658029201906174, "Avg policy loss": 0.23253036348614842, "Total num played games": 59916, "Total num trained steps": 119296, "Timestamp in ms": 1699772107260, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99000199960008, "Avg loss": 0.5166341627482325, "Avg value loss": 0.28006242783158086, "Avg policy loss": 0.23657173733226955, "Total num played games": 60012, "Total num trained steps": 119424, "Timestamp in ms": 1699772164836, "logtype": "training_step"}
{"Avg objective": 21.2421875, "Games time in secs": 178.5242183599621, "Avg game time in secs": 0.9097620846732752, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 60032, "Total num trained steps": 119516, "Timestamp in ms": 1699772207129, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904765076088042, "Avg loss": 0.7269805873511359, "Avg value loss": 0.48106140515301377, "Avg policy loss": 0.24591918929945678, "Total num played games": 60062, "Total num trained steps": 119552, "Timestamp in ms": 1699772223747, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910164698053567, "Avg loss": 0.42680037254467607, "Avg value loss": 0.1903005131171085, "Avg policy loss": 0.236499861930497, "Total num played games": 60110, "Total num trained steps": 119680, "Timestamp in ms": 1699772281060, "logtype": "training_step"}
{"Total num played games": 60158, "Total num trained steps": 119729, "Timestamp in ms": 1699772316094, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.4765625}
{"Avg objective": 21.2890625, "Games time in secs": 109.8286991585046, "Avg game time in secs": 0.9059304417169187, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.61}, "Total num played games": 60160, "Total num trained steps": 119730, "Timestamp in ms": 1699772316958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899677772979438, "Avg loss": 0.5756140649318695, "Avg value loss": 0.33286759196198545, "Avg policy loss": 0.24274647748097777, "Total num played games": 60206, "Total num trained steps": 119808, "Timestamp in ms": 1699772351364, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990506854316726, "Avg loss": 0.39803648251108825, "Avg value loss": 0.17068280093371868, "Avg policy loss": 0.22735368472058326, "Total num played games": 60254, "Total num trained steps": 119936, "Timestamp in ms": 1699772409053, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 120.56328348815441, "Avg game time in secs": 0.8559984649036778, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 60288, "Total num trained steps": 119999, "Timestamp in ms": 1699772437521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910450731319027, "Avg loss": 0.39707625028677285, "Avg value loss": 0.1635777938645333, "Avg policy loss": 0.23349845642223954, "Total num played games": 60302, "Total num trained steps": 120064, "Timestamp in ms": 1699772466384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902632886239444, "Avg loss": 0.48299800290260464, "Avg value loss": 0.2516964360838756, "Avg policy loss": 0.2313015660038218, "Total num played games": 60388, "Total num trained steps": 120192, "Timestamp in ms": 1699772522203, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 127.35049895383418, "Avg game time in secs": 0.9135093713412061, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 60416, "Total num trained steps": 120286, "Timestamp in ms": 1699772564872, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902570549508718, "Avg loss": 0.6154867587611079, "Avg value loss": 0.37497597379842773, "Avg policy loss": 0.24051078967750072, "Total num played games": 60454, "Total num trained steps": 120320, "Timestamp in ms": 1699772580144, "logtype": "training_step"}
{"Total num played games": 60454, "Total num trained steps": 120329, "Timestamp in ms": 1699772593762, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8828125}
{"Ratio train steps to played games": 1.990810221149714, "Avg loss": 0.6018253568327054, "Avg value loss": 0.348882183607202, "Avg policy loss": 0.2529431796865538, "Total num played games": 60502, "Total num trained steps": 120448, "Timestamp in ms": 1699772647680, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 104.15775758586824, "Avg game time in secs": 0.9538145135593368, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 60544, "Total num trained steps": 120496, "Timestamp in ms": 1699772669030, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911815704731235, "Avg loss": 0.44761699822265655, "Avg value loss": 0.20523232192499563, "Avg policy loss": 0.24238467344548553, "Total num played games": 60555, "Total num trained steps": 120576, "Timestamp in ms": 1699772704705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900910110136516, "Avg loss": 0.451139273471199, "Avg value loss": 0.20792821995564736, "Avg policy loss": 0.24321105214767158, "Total num played games": 60652, "Total num trained steps": 120704, "Timestamp in ms": 1699772763703, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 136.3226061873138, "Avg game time in secs": 0.959437940546195, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 60672, "Total num trained steps": 120794, "Timestamp in ms": 1699772805353, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906260296540363, "Avg loss": 0.7529547926969826, "Avg value loss": 0.49756850354606286, "Avg policy loss": 0.25538628397043794, "Total num played games": 60700, "Total num trained steps": 120832, "Timestamp in ms": 1699772821889, "logtype": "training_step"}
{"Total num played games": 60748, "Total num trained steps": 120931, "Timestamp in ms": 1699772878848, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.05859375}
{"Ratio train steps to played games": 1.9896045792486348, "Avg loss": 0.643366068135947, "Avg value loss": 0.37695649737725034, "Avg policy loss": 0.266409573960118, "Total num played games": 60796, "Total num trained steps": 120960, "Timestamp in ms": 1699772892604, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 142.2361495885998, "Avg game time in secs": 0.8675913808838231, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.61, "agent_stopped_0": 0.39}, "Total num played games": 60800, "Total num trained steps": 121082, "Timestamp in ms": 1699772947589, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900895718629303, "Avg loss": 0.39913679054006934, "Avg value loss": 0.1402291166014038, "Avg policy loss": 0.2589076717849821, "Total num played games": 60845, "Total num trained steps": 121088, "Timestamp in ms": 1699772949924, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906228958993644, "Avg loss": 0.6025633041281253, "Avg value loss": 0.3434547601500526, "Avg policy loss": 0.25910854432731867, "Total num played games": 60893, "Total num trained steps": 121216, "Timestamp in ms": 1699773008070, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 87.88370550237596, "Avg game time in secs": 0.9369044919294538, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 60928, "Total num trained steps": 121277, "Timestamp in ms": 1699773035473, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911553797935708, "Avg loss": 0.5490494257537648, "Avg value loss": 0.28789996582781896, "Avg policy loss": 0.2611494632437825, "Total num played games": 60941, "Total num trained steps": 121344, "Timestamp in ms": 1699773065161, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901207464324917, "Avg loss": 0.7812062548473477, "Avg value loss": 0.5063402311643586, "Avg policy loss": 0.274866018560715, "Total num played games": 61037, "Total num trained steps": 121472, "Timestamp in ms": 1699773123094, "logtype": "training_step"}
{"Total num played games": 61037, "Total num trained steps": 121534, "Timestamp in ms": 1699773164333, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.8984375}
{"Avg objective": 22.5859375, "Games time in secs": 130.3465770613402, "Avg game time in secs": 0.9042662717110943, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.57, "agent_stopped_0": 0.45}, "Total num played games": 61056, "Total num trained steps": 121536, "Timestamp in ms": 1699773165820, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99065236964885, "Avg loss": 0.6207520293537527, "Avg value loss": 0.3511171354330145, "Avg policy loss": 0.26963489479385316, "Total num played games": 61085, "Total num trained steps": 121600, "Timestamp in ms": 1699773195015, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911505872345994, "Avg loss": 0.5105406816583127, "Avg value loss": 0.25572303173248656, "Avg policy loss": 0.25481765100266784, "Total num played games": 61134, "Total num trained steps": 121728, "Timestamp in ms": 1699773251891, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 148.58127070777118, "Avg game time in secs": 0.906744347550557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 61184, "Total num trained steps": 121853, "Timestamp in ms": 1699773314401, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903792754238672, "Avg loss": 0.4796491442248225, "Avg value loss": 0.21386096780770458, "Avg policy loss": 0.2657881756313145, "Total num played games": 61222, "Total num trained steps": 121856, "Timestamp in ms": 1699773315266, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906491726231275, "Avg loss": 0.6360848431941122, "Avg value loss": 0.37322320096427575, "Avg policy loss": 0.2628616482252255, "Total num played games": 61278, "Total num trained steps": 121984, "Timestamp in ms": 1699773376345, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 91.60806593112648, "Avg game time in secs": 0.8834768864908256, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 61312, "Total num trained steps": 122047, "Timestamp in ms": 1699773406009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911945993542706, "Avg loss": 0.4694819685537368, "Avg value loss": 0.20486454459023662, "Avg policy loss": 0.26461742434185, "Total num played games": 61326, "Total num trained steps": 122112, "Timestamp in ms": 1699773437804, "logtype": "training_step"}
{"Total num played games": 61326, "Total num trained steps": 122136, "Timestamp in ms": 1699773459880, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.37109375}
{"Ratio train steps to played games": 1.9902473176053013, "Avg loss": 0.4372103449422866, "Avg value loss": 0.17734847695101053, "Avg policy loss": 0.25986186508089304, "Total num played games": 61419, "Total num trained steps": 122240, "Timestamp in ms": 1699773511223, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 152.476387321949, "Avg game time in secs": 0.8539624117984204, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 61440, "Total num trained steps": 122335, "Timestamp in ms": 1699773558486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906136127017178, "Avg loss": 0.7050197881180793, "Avg value loss": 0.43753650106373243, "Avg policy loss": 0.2674832819029689, "Total num played games": 61472, "Total num trained steps": 122368, "Timestamp in ms": 1699773573586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911573472041613, "Avg loss": 0.5070215698797256, "Avg value loss": 0.23564648418687284, "Avg policy loss": 0.2713750859256834, "Total num played games": 61520, "Total num trained steps": 122496, "Timestamp in ms": 1699773633159, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 91.51753467693925, "Avg game time in secs": 0.9274187337141484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.67}, "Total num played games": 61568, "Total num trained steps": 122531, "Timestamp in ms": 1699773650004, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916516428722246, "Avg loss": 0.5934818943496794, "Avg value loss": 0.33311763824895024, "Avg policy loss": 0.2603642519097775, "Total num played games": 61569, "Total num trained steps": 122624, "Timestamp in ms": 1699773694330, "logtype": "training_step"}
{"Total num played games": 61665, "Total num trained steps": 122739, "Timestamp in ms": 1699773759398, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3125}
{"Avg objective": 21.203125, "Games time in secs": 111.3457464016974, "Avg game time in secs": 0.9023901741020381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 61696, "Total num trained steps": 122741, "Timestamp in ms": 1699773761350, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890784761719573, "Avg loss": 0.6875128417741507, "Avg value loss": 0.4243317697546445, "Avg policy loss": 0.26318106066901237, "Total num played games": 61713, "Total num trained steps": 122752, "Timestamp in ms": 1699773766349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911525934568082, "Avg loss": 0.43598866323009133, "Avg value loss": 0.1793474580917973, "Avg policy loss": 0.256641207030043, "Total num played games": 61713, "Total num trained steps": 122880, "Timestamp in ms": 1699773827672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916775958938489, "Avg loss": 0.40641258656978607, "Avg value loss": 0.16367769867065363, "Avg policy loss": 0.24273488984908909, "Total num played games": 61761, "Total num trained steps": 123008, "Timestamp in ms": 1699773888034, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 175.65910798497498, "Avg game time in secs": 0.8834256924019428, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.56, "agent_stopped_0": 0.48}, "Total num played games": 61824, "Total num trained steps": 123107, "Timestamp in ms": 1699773937010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906397012464232, "Avg loss": 0.6677701908629388, "Avg value loss": 0.41585008573019877, "Avg policy loss": 0.25192011508625, "Total num played games": 61857, "Total num trained steps": 123136, "Timestamp in ms": 1699773951289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911638801389226, "Avg loss": 0.625409897766076, "Avg value loss": 0.3719004995946307, "Avg policy loss": 0.25350939913187176, "Total num played games": 61905, "Total num trained steps": 123264, "Timestamp in ms": 1699774019618, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 101.25341727025807, "Avg game time in secs": 0.9327391586120939, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 61952, "Total num trained steps": 123302, "Timestamp in ms": 1699774038263, "logtype": "played_game"}
{"Total num played games": 61953, "Total num trained steps": 123341, "Timestamp in ms": 1699774065961, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.45703125}
{"Ratio train steps to played games": 1.990161449008887, "Avg loss": 0.6159913204610348, "Avg value loss": 0.35144125495571643, "Avg policy loss": 0.26455006131436676, "Total num played games": 62001, "Total num trained steps": 123392, "Timestamp in ms": 1699774091012, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906526994359388, "Avg loss": 0.44436951354146004, "Avg value loss": 0.1957086121547036, "Avg policy loss": 0.24866089702118188, "Total num played games": 62050, "Total num trained steps": 123520, "Timestamp in ms": 1699774152578, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 147.97403595782816, "Avg game time in secs": 0.830964055887307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 62080, "Total num trained steps": 123590, "Timestamp in ms": 1699774186237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911752391381365, "Avg loss": 0.4896397911943495, "Avg value loss": 0.2365498759318143, "Avg policy loss": 0.25308991549536586, "Total num played games": 62098, "Total num trained steps": 123648, "Timestamp in ms": 1699774213169, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916969716474109, "Avg loss": 0.44928664609324187, "Avg value loss": 0.2003013547800947, "Avg policy loss": 0.24898529064375907, "Total num played games": 62146, "Total num trained steps": 123776, "Timestamp in ms": 1699774274080, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 135.5616026390344, "Avg game time in secs": 0.8776008485729108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.52, "agent_stopped_0": 0.48}, "Total num played games": 62208, "Total num trained steps": 123877, "Timestamp in ms": 1699774321799, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906815333697503, "Avg loss": 0.6086745485663414, "Avg value loss": 0.35301420793985017, "Avg policy loss": 0.2556603412376717, "Total num played games": 62242, "Total num trained steps": 123904, "Timestamp in ms": 1699774334423, "logtype": "training_step"}
{"Total num played games": 62242, "Total num trained steps": 123943, "Timestamp in ms": 1699774365917, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.296875}
{"Ratio train steps to played games": 1.991202440199069, "Avg loss": 0.7607685544062406, "Avg value loss": 0.48858982761157677, "Avg policy loss": 0.2721787279006094, "Total num played games": 62290, "Total num trained steps": 124032, "Timestamp in ms": 1699774408556, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 105.1896125022322, "Avg game time in secs": 0.8899095257074805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 62336, "Total num trained steps": 124071, "Timestamp in ms": 1699774426989, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916905949726496, "Avg loss": 0.7581018742639571, "Avg value loss": 0.49605209106812254, "Avg policy loss": 0.26204978430178016, "Total num played games": 62339, "Total num trained steps": 124160, "Timestamp in ms": 1699774473009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906464219360624, "Avg loss": 0.6497080097906291, "Avg value loss": 0.39010790979955345, "Avg policy loss": 0.2596001006895676, "Total num played games": 62436, "Total num trained steps": 124288, "Timestamp in ms": 1699774532572, "logtype": "training_step"}
{"Avg objective": 23.625, "Games time in secs": 142.80679886043072, "Avg game time in secs": 0.8853364318492822, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 62464, "Total num trained steps": 124361, "Timestamp in ms": 1699774569796, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911657384290378, "Avg loss": 0.613673965446651, "Avg value loss": 0.3515904552768916, "Avg policy loss": 0.2620835134293884, "Total num played games": 62484, "Total num trained steps": 124416, "Timestamp in ms": 1699774598359, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991668265847886, "Avg loss": 0.47012316016480327, "Avg value loss": 0.21027644336572848, "Avg policy loss": 0.2598467158386484, "Total num played games": 62532, "Total num trained steps": 124544, "Timestamp in ms": 1699774660899, "logtype": "training_step"}
{"Total num played games": 62532, "Total num trained steps": 124545, "Timestamp in ms": 1699774673944, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.359375}
{"Avg objective": 21.921875, "Games time in secs": 154.5719983652234, "Avg game time in secs": 0.9426564167515608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 62592, "Total num trained steps": 124649, "Timestamp in ms": 1699774724368, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906750974005236, "Avg loss": 0.5554984915070236, "Avg value loss": 0.2980406806454994, "Avg policy loss": 0.2574578147614375, "Total num played games": 62628, "Total num trained steps": 124672, "Timestamp in ms": 1699774734712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991097496769253, "Avg loss": 0.5193504425697029, "Avg value loss": 0.2583322216232773, "Avg policy loss": 0.2610182208009064, "Total num played games": 62679, "Total num trained steps": 124800, "Timestamp in ms": 1699774794882, "logtype": "training_step"}
{"Avg objective": 22.25, "Games time in secs": 94.31746213510633, "Avg game time in secs": 0.9202686680946499, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 62720, "Total num trained steps": 124849, "Timestamp in ms": 1699774818686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915985141964385, "Avg loss": 0.47144300676882267, "Avg value loss": 0.21513496219995432, "Avg policy loss": 0.2563080455875024, "Total num played games": 62727, "Total num trained steps": 124928, "Timestamp in ms": 1699774855553, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905768496116134, "Avg loss": 0.5328275923384354, "Avg value loss": 0.2805074026109651, "Avg policy loss": 0.25232019054237753, "Total num played games": 62824, "Total num trained steps": 125056, "Timestamp in ms": 1699774916793, "logtype": "training_step"}
{"Avg objective": 20.4453125, "Games time in secs": 137.77245146408677, "Avg game time in secs": 0.9172947346960427, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 62848, "Total num trained steps": 125138, "Timestamp in ms": 1699774956458, "logtype": "played_game"}
{"Total num played games": 62872, "Total num trained steps": 125148, "Timestamp in ms": 1699774972468, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.29296875}
{"Ratio train steps to played games": 1.989574062301335, "Avg loss": 0.6613586631137878, "Avg value loss": 0.40096350727253594, "Avg policy loss": 0.2603951519122347, "Total num played games": 62920, "Total num trained steps": 125184, "Timestamp in ms": 1699774990568, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915924984106803, "Avg loss": 0.3420871509006247, "Avg value loss": 0.09132135307299905, "Avg policy loss": 0.2507657977985218, "Total num played games": 62920, "Total num trained steps": 125312, "Timestamp in ms": 1699775055768, "logtype": "training_step"}
{"Avg objective": 20.609375, "Games time in secs": 156.64631924405694, "Avg game time in secs": 0.9262624705006601, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.64, "agent_stopped_0": 0.38}, "Total num played games": 62976, "Total num trained steps": 125425, "Timestamp in ms": 1699775113105, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906055604925734, "Avg loss": 0.4921464262297377, "Avg value loss": 0.24358845854294486, "Avg policy loss": 0.24855796829797328, "Total num played games": 63016, "Total num trained steps": 125440, "Timestamp in ms": 1699775120586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911201319294685, "Avg loss": 0.4985541350906715, "Avg value loss": 0.24255350948078558, "Avg policy loss": 0.25600063265301287, "Total num played games": 63064, "Total num trained steps": 125568, "Timestamp in ms": 1699775181949, "logtype": "training_step"}
{"Avg objective": 20.03125, "Games time in secs": 93.50848337635398, "Avg game time in secs": 0.9079444708768278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 63104, "Total num trained steps": 125618, "Timestamp in ms": 1699775206614, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915392537431673, "Avg loss": 0.3988108756020665, "Avg value loss": 0.155541465501301, "Avg policy loss": 0.24326940556056798, "Total num played games": 63115, "Total num trained steps": 125696, "Timestamp in ms": 1699775243193, "logtype": "training_step"}
{"Total num played games": 63163, "Total num trained steps": 125748, "Timestamp in ms": 1699775277353, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.203125}
{"Ratio train steps to played games": 1.9905238012371265, "Avg loss": 0.6416584341786802, "Avg value loss": 0.3794488166749943, "Avg policy loss": 0.2622096154373139, "Total num played games": 63211, "Total num trained steps": 125824, "Timestamp in ms": 1699775314655, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 151.0673902593553, "Avg game time in secs": 0.9181378856010269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 63232, "Total num trained steps": 125911, "Timestamp in ms": 1699775357681, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910368485116743, "Avg loss": 0.47251110849902034, "Avg value loss": 0.21783360542031005, "Avg policy loss": 0.25467750360257924, "Total num played games": 63259, "Total num trained steps": 125952, "Timestamp in ms": 1699775377369, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914232913711678, "Avg loss": 0.46339337807148695, "Avg value loss": 0.20981360139558092, "Avg policy loss": 0.25357978348620236, "Total num played games": 63311, "Total num trained steps": 126080, "Timestamp in ms": 1699775438757, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 140.93189461529255, "Avg game time in secs": 0.9687363000703044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.71, "agent_stopped_0": 0.33}, "Total num played games": 63360, "Total num trained steps": 126207, "Timestamp in ms": 1699775498613, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991871971717618, "Avg loss": 0.515640783472918, "Avg value loss": 0.26648174942238256, "Avg policy loss": 0.2491590379504487, "Total num played games": 63360, "Total num trained steps": 126208, "Timestamp in ms": 1699775498730, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908914698142048, "Avg loss": 0.5551504262257367, "Avg value loss": 0.3108655833057128, "Avg policy loss": 0.2442848428618163, "Total num played games": 63457, "Total num trained steps": 126336, "Timestamp in ms": 1699775559806, "logtype": "training_step"}
{"Total num played games": 63457, "Total num trained steps": 126348, "Timestamp in ms": 1699775577151, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.90234375}
{"Avg objective": 20.7578125, "Games time in secs": 80.45953714288771, "Avg game time in secs": 0.8944594310596585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.6}, "Total num played games": 63488, "Total num trained steps": 126352, "Timestamp in ms": 1699775579073, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914022517911976, "Avg loss": 0.41119235567748547, "Avg value loss": 0.1608847606985364, "Avg policy loss": 0.25030759954825044, "Total num played games": 63505, "Total num trained steps": 126464, "Timestamp in ms": 1699775629052, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918965273079163, "Avg loss": 0.46006571303587407, "Avg value loss": 0.22128959654946811, "Avg policy loss": 0.2387761129066348, "Total num played games": 63553, "Total num trained steps": 126592, "Timestamp in ms": 1699775685083, "logtype": "training_step"}
{"Avg objective": 20.5078125, "Games time in secs": 150.47581256367266, "Avg game time in secs": 0.919496848291601, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.63}, "Total num played games": 63616, "Total num trained steps": 126694, "Timestamp in ms": 1699775729549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908406780726147, "Avg loss": 0.4868867131881416, "Avg value loss": 0.23792855924693868, "Avg policy loss": 0.2489581584231928, "Total num played games": 63651, "Total num trained steps": 126720, "Timestamp in ms": 1699775740504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913186813186814, "Avg loss": 0.543196200625971, "Avg value loss": 0.2760584577044938, "Avg policy loss": 0.2671377471415326, "Total num played games": 63700, "Total num trained steps": 126848, "Timestamp in ms": 1699775799275, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 90.08741235546768, "Avg game time in secs": 0.9524812570743961, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.65}, "Total num played games": 63744, "Total num trained steps": 126892, "Timestamp in ms": 1699775819636, "logtype": "played_game"}
{"Total num played games": 63748, "Total num trained steps": 126951, "Timestamp in ms": 1699775865237, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.69921875}
{"Ratio train steps to played games": 1.9903285472443413, "Avg loss": 0.6332341064698994, "Avg value loss": 0.3678784391086083, "Avg policy loss": 0.2653556680306792, "Total num played games": 63796, "Total num trained steps": 126976, "Timestamp in ms": 1699775877360, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908527034646952, "Avg loss": 0.5190600713249296, "Avg value loss": 0.25496690458385274, "Avg policy loss": 0.2640931699424982, "Total num played games": 63844, "Total num trained steps": 127104, "Timestamp in ms": 1699775937429, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 153.63168756477535, "Avg game time in secs": 0.8533091120916652, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.61, "agent_stopped_0": 0.47}, "Total num played games": 63872, "Total num trained steps": 127179, "Timestamp in ms": 1699775973268, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913136024290612, "Avg loss": 0.5213105597067624, "Avg value loss": 0.2523027349379845, "Avg policy loss": 0.2690078222658485, "Total num played games": 63893, "Total num trained steps": 127232, "Timestamp in ms": 1699775997137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917116271796074, "Avg loss": 0.5060329346451908, "Avg value loss": 0.2380715478793718, "Avg policy loss": 0.26796138868667185, "Total num played games": 63945, "Total num trained steps": 127360, "Timestamp in ms": 1699776054428, "logtype": "training_step"}
{"Avg objective": 22.6328125, "Games time in secs": 134.52532128058374, "Avg game time in secs": 0.9546314806357259, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 64000, "Total num trained steps": 127476, "Timestamp in ms": 1699776107794, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907090769975484, "Avg loss": 0.7012078850530088, "Avg value loss": 0.4262975049787201, "Avg policy loss": 0.2749103751266375, "Total num played games": 64041, "Total num trained steps": 127488, "Timestamp in ms": 1699776112988, "logtype": "training_step"}
{"Total num played games": 64041, "Total num trained steps": 127551, "Timestamp in ms": 1699776160029, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.578125}
{"Ratio train steps to played games": 1.9912153411661908, "Avg loss": 0.6084978319704533, "Avg value loss": 0.3248883861815557, "Avg policy loss": 0.28360944846645, "Total num played games": 64089, "Total num trained steps": 127616, "Timestamp in ms": 1699776189131, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 104.97732219658792, "Avg game time in secs": 0.9133308351592859, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.69}, "Total num played games": 64128, "Total num trained steps": 127669, "Timestamp in ms": 1699776212771, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917208475606905, "Avg loss": 0.49251369608100504, "Avg value loss": 0.21804206716478802, "Avg policy loss": 0.2744716312736273, "Total num played games": 64137, "Total num trained steps": 127744, "Timestamp in ms": 1699776245110, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906748657274072, "Avg loss": 0.6080968109890819, "Avg value loss": 0.32939988537691534, "Avg policy loss": 0.27869693224783987, "Total num played games": 64235, "Total num trained steps": 127872, "Timestamp in ms": 1699776302038, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 129.49809424765408, "Avg game time in secs": 0.8883908123534638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.56, "agent_stopped_0": 0.47}, "Total num played games": 64256, "Total num trained steps": 127961, "Timestamp in ms": 1699776342269, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991148652852965, "Avg loss": 0.5117334246169776, "Avg value loss": 0.22593994642375037, "Avg policy loss": 0.28579347615595907, "Total num played games": 64284, "Total num trained steps": 128000, "Timestamp in ms": 1699776359478, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991637262369235, "Avg loss": 0.48329989751800895, "Avg value loss": 0.20901230847812258, "Avg policy loss": 0.2742875856347382, "Total num played games": 64333, "Total num trained steps": 128128, "Timestamp in ms": 1699776415895, "logtype": "training_step"}
{"Total num played games": 64333, "Total num trained steps": 128152, "Timestamp in ms": 1699776440678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6640625}
{"Avg objective": 21.5625, "Games time in secs": 143.861009567976, "Avg game time in secs": 0.9726504668942653, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.72, "played_steps": 0.77, "agent_stopped_0": 0.28}, "Total num played games": 64384, "Total num trained steps": 128252, "Timestamp in ms": 1699776486131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99067175762091, "Avg loss": 0.4998960541561246, "Avg value loss": 0.22943339514313266, "Avg policy loss": 0.2704626544145867, "Total num played games": 64428, "Total num trained steps": 128256, "Timestamp in ms": 1699776487862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911441289141865, "Avg loss": 0.5703869153512642, "Avg value loss": 0.3046460030018352, "Avg policy loss": 0.26574091904331, "Total num played games": 64477, "Total num trained steps": 128384, "Timestamp in ms": 1699776544991, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 85.78638181835413, "Avg game time in secs": 0.8640187806740869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.56}, "Total num played games": 64512, "Total num trained steps": 128445, "Timestamp in ms": 1699776571917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916466485858195, "Avg loss": 0.5566380620002747, "Avg value loss": 0.28152395598590374, "Avg policy loss": 0.2751141084590927, "Total num played games": 64525, "Total num trained steps": 128512, "Timestamp in ms": 1699776601884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906686680800358, "Avg loss": 0.5116700852522627, "Avg value loss": 0.2465914095810149, "Avg policy loss": 0.2650786725571379, "Total num played games": 64621, "Total num trained steps": 128640, "Timestamp in ms": 1699776658797, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 129.1381249241531, "Avg game time in secs": 0.9341104676859686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.69, "agent_stopped_0": 0.36}, "Total num played games": 64640, "Total num trained steps": 128733, "Timestamp in ms": 1699776701057, "logtype": "played_game"}
{"Total num played games": 64670, "Total num trained steps": 128755, "Timestamp in ms": 1699776757049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.87890625}
{"Ratio train steps to played games": 1.9896782966099076, "Avg loss": 0.7499050658661872, "Avg value loss": 0.48064813076052815, "Avg policy loss": 0.26925693778321147, "Total num played games": 64718, "Total num trained steps": 128768, "Timestamp in ms": 1699776763249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916561080379493, "Avg loss": 0.5056642084382474, "Avg value loss": 0.22854212901438586, "Avg policy loss": 0.27712208090815693, "Total num played games": 64718, "Total num trained steps": 128896, "Timestamp in ms": 1699776819581, "logtype": "training_step"}
{"Avg objective": 22.9765625, "Games time in secs": 173.96510772407055, "Avg game time in secs": 0.9158575273468159, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.76, "agent_stopped_0": 0.34}, "Total num played games": 64768, "Total num trained steps": 129022, "Timestamp in ms": 1699776875022, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908806147484068, "Avg loss": 0.5937284163665026, "Avg value loss": 0.320890883973334, "Avg policy loss": 0.27283752290531993, "Total num played games": 64807, "Total num trained steps": 129024, "Timestamp in ms": 1699776875895, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911658598254756, "Avg loss": 0.6140608107671142, "Avg value loss": 0.34773903895984404, "Avg policy loss": 0.2663217823719606, "Total num played games": 64862, "Total num trained steps": 129152, "Timestamp in ms": 1699776934138, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 88.17439881712198, "Avg game time in secs": 0.8710854583187029, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.55}, "Total num played games": 64896, "Total num trained steps": 129215, "Timestamp in ms": 1699776963197, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916653828377753, "Avg loss": 0.506798944901675, "Avg value loss": 0.24152226198930293, "Avg policy loss": 0.2652766825631261, "Total num played games": 64910, "Total num trained steps": 129280, "Timestamp in ms": 1699776994431, "logtype": "training_step"}
{"Total num played games": 64959, "Total num trained steps": 129359, "Timestamp in ms": 1699777041593, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.16796875}
{"Ratio train steps to played games": 1.9906779269924777, "Avg loss": 0.8136857906356454, "Avg value loss": 0.5386418055277318, "Avg policy loss": 0.2750439830124378, "Total num played games": 65007, "Total num trained steps": 129408, "Timestamp in ms": 1699777064947, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 145.67711535282433, "Avg game time in secs": 0.8484837446594611, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.53, "agent_stopped_0": 0.48}, "Total num played games": 65024, "Total num trained steps": 129504, "Timestamp in ms": 1699777108874, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911613250326647, "Avg loss": 0.5034606754779816, "Avg value loss": 0.24026088308892213, "Avg policy loss": 0.2631997880525887, "Total num played games": 65055, "Total num trained steps": 129536, "Timestamp in ms": 1699777123964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99165937053592, "Avg loss": 0.5648995796218514, "Avg value loss": 0.29552073689410463, "Avg policy loss": 0.2693788427859545, "Total num played games": 65103, "Total num trained steps": 129664, "Timestamp in ms": 1699777182976, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 130.79479879699647, "Avg game time in secs": 0.9966535667626886, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.73, "agent_stopped_0": 0.33}, "Total num played games": 65152, "Total num trained steps": 129791, "Timestamp in ms": 1699777239669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918968692449355, "Avg loss": 0.51133399666287, "Avg value loss": 0.2411018683342263, "Avg policy loss": 0.2702321312390268, "Total num played games": 65156, "Total num trained steps": 129792, "Timestamp in ms": 1699777239836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911568170671898, "Avg loss": 0.8379347815643996, "Avg value loss": 0.5611020470969379, "Avg policy loss": 0.2768327302765101, "Total num played games": 65248, "Total num trained steps": 129920, "Timestamp in ms": 1699777296373, "logtype": "training_step"}
{"Total num played games": 65248, "Total num trained steps": 129959, "Timestamp in ms": 1699777339812, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.90234375}
{"Avg objective": 22.859375, "Games time in secs": 101.97170876152813, "Avg game time in secs": 0.8757717218977632, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.53}, "Total num played games": 65280, "Total num trained steps": 129962, "Timestamp in ms": 1699777341641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916533937760352, "Avg loss": 0.5303316791541874, "Avg value loss": 0.24735116848023608, "Avg policy loss": 0.2829805064247921, "Total num played games": 65296, "Total num trained steps": 130048, "Timestamp in ms": 1699777380601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921187543040784, "Avg loss": 0.5059332177042961, "Avg value loss": 0.23875151641550474, "Avg policy loss": 0.26718169974628836, "Total num played games": 65345, "Total num trained steps": 130176, "Timestamp in ms": 1699777436788, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 144.95201002433896, "Avg game time in secs": 0.9076850544079207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.67}, "Total num played games": 65408, "Total num trained steps": 130286, "Timestamp in ms": 1699777486593, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909697923510628, "Avg loss": 0.7110801588278264, "Avg value loss": 0.43154594593215734, "Avg policy loss": 0.2795342127792537, "Total num played games": 65447, "Total num trained steps": 130304, "Timestamp in ms": 1699777494169, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914649973280403, "Avg loss": 0.6844901763834059, "Avg value loss": 0.3992393880907912, "Avg policy loss": 0.28525078936945647, "Total num played games": 65495, "Total num trained steps": 130432, "Timestamp in ms": 1699777552289, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 89.17736477218568, "Avg game time in secs": 0.9151068551582284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.64}, "Total num played games": 65536, "Total num trained steps": 130481, "Timestamp in ms": 1699777575770, "logtype": "played_game"}
{"Total num played games": 65543, "Total num trained steps": 130559, "Timestamp in ms": 1699777624473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.546875}
{"Ratio train steps to played games": 1.9917316288081035, "Avg loss": 0.6093377883080393, "Avg value loss": 0.32401218480663374, "Avg policy loss": 0.2853256098460406, "Total num played games": 65549, "Total num trained steps": 130560, "Timestamp in ms": 1699777625722, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909962065235607, "Avg loss": 0.6838489554356784, "Avg value loss": 0.40100188547512516, "Avg policy loss": 0.28284707374405116, "Total num played games": 65639, "Total num trained steps": 130688, "Timestamp in ms": 1699777685542, "logtype": "training_step"}
{"Avg objective": 22.4609375, "Games time in secs": 147.57082259655, "Avg game time in secs": 0.8893168972717831, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 65664, "Total num trained steps": 130769, "Timestamp in ms": 1699777723341, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914899447379237, "Avg loss": 0.6740564305800945, "Avg value loss": 0.3982669665128924, "Avg policy loss": 0.27578945306595415, "Total num played games": 65687, "Total num trained steps": 130816, "Timestamp in ms": 1699777745348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917254806522269, "Avg loss": 0.5546636949293315, "Avg value loss": 0.2783687860064674, "Avg policy loss": 0.27629491162952036, "Total num played games": 65744, "Total num trained steps": 130944, "Timestamp in ms": 1699777804188, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 97.74008792452514, "Avg game time in secs": 1.0295900289493147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.71}, "Total num played games": 65792, "Total num trained steps": 130982, "Timestamp in ms": 1699777821082, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922026994163424, "Avg loss": 0.533352859551087, "Avg value loss": 0.2607403425790835, "Avg policy loss": 0.2726125157205388, "Total num played games": 65792, "Total num trained steps": 131072, "Timestamp in ms": 1699777862063, "logtype": "training_step"}
{"Total num played games": 65840, "Total num trained steps": 131159, "Timestamp in ms": 1699777912509, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.0234375}
{"Ratio train steps to played games": 1.9912427149101506, "Avg loss": 0.5997455667238683, "Avg value loss": 0.3236224928696174, "Avg policy loss": 0.2761230783071369, "Total num played games": 65888, "Total num trained steps": 131200, "Timestamp in ms": 1699777932425, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 141.34982094727457, "Avg game time in secs": 0.8287205253291177, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 65920, "Total num trained steps": 131267, "Timestamp in ms": 1699777962432, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915381465811381, "Avg loss": 0.5110627755057067, "Avg value loss": 0.2451915119891055, "Avg policy loss": 0.2658712645061314, "Total num played games": 65943, "Total num trained steps": 131328, "Timestamp in ms": 1699777990080, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991893325251913, "Avg loss": 0.4608757789246738, "Avg value loss": 0.18665439676260576, "Avg policy loss": 0.27422138245310634, "Total num played games": 65995, "Total num trained steps": 131456, "Timestamp in ms": 1699778047057, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 138.2332797050476, "Avg game time in secs": 0.9812723668728722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 66048, "Total num trained steps": 131577, "Timestamp in ms": 1699778100665, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909066150214851, "Avg loss": 0.4949452093569562, "Avg value loss": 0.2234224411949981, "Avg policy loss": 0.271522767143324, "Total num played games": 66092, "Total num trained steps": 131584, "Timestamp in ms": 1699778103137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912917271407837, "Avg loss": 0.5735876602120697, "Avg value loss": 0.29267383326077834, "Avg policy loss": 0.2809138250304386, "Total num played games": 66144, "Total num trained steps": 131712, "Timestamp in ms": 1699778160364, "logtype": "training_step"}
{"Total num played games": 66144, "Total num trained steps": 131760, "Timestamp in ms": 1699778196177, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.23828125}
{"Avg objective": 22.6015625, "Games time in secs": 97.67868039570749, "Avg game time in secs": 0.9221606438368326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 66176, "Total num trained steps": 131764, "Timestamp in ms": 1699778198345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991766376601402, "Avg loss": 0.5256505452562124, "Avg value loss": 0.24454066291218624, "Avg policy loss": 0.2811098877573386, "Total num played games": 66192, "Total num trained steps": 131840, "Timestamp in ms": 1699778233712, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922554347826087, "Avg loss": 0.4529815760906786, "Avg value loss": 0.18070600533974357, "Avg policy loss": 0.2722755663562566, "Total num played games": 66240, "Total num trained steps": 131968, "Timestamp in ms": 1699778290973, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 135.3572346251458, "Avg game time in secs": 0.9335896163829602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 66304, "Total num trained steps": 132067, "Timestamp in ms": 1699778333719, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913018572117704, "Avg loss": 0.5875889263115823, "Avg value loss": 0.2997493792208843, "Avg policy loss": 0.28783954645041376, "Total num played games": 66336, "Total num trained steps": 132096, "Timestamp in ms": 1699778348014, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991790190407327, "Avg loss": 0.5096587548032403, "Avg value loss": 0.22416458849329501, "Avg policy loss": 0.2854941664263606, "Total num played games": 66384, "Total num trained steps": 132224, "Timestamp in ms": 1699778408509, "logtype": "training_step"}
{"Avg objective": 20.203125, "Games time in secs": 90.86909255385399, "Avg game time in secs": 0.8990693722007563, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.65}, "Total num played games": 66432, "Total num trained steps": 132260, "Timestamp in ms": 1699778424588, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921278805484894, "Avg loss": 0.4762580634560436, "Avg value loss": 0.20062638958916068, "Avg policy loss": 0.27563167607877403, "Total num played games": 66437, "Total num trained steps": 132352, "Timestamp in ms": 1699778464850, "logtype": "training_step"}
{"Total num played games": 66437, "Total num trained steps": 132360, "Timestamp in ms": 1699778479174, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.28515625}
{"Ratio train steps to played games": 1.9911773105075676, "Avg loss": 0.6348688958678395, "Avg value loss": 0.34855914398212917, "Avg policy loss": 0.2863097613444552, "Total num played games": 66533, "Total num trained steps": 132480, "Timestamp in ms": 1699778535122, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 145.301148109138, "Avg game time in secs": 0.9291856039053528, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 66560, "Total num trained steps": 132557, "Timestamp in ms": 1699778569889, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916642886108649, "Avg loss": 0.4938318538479507, "Avg value loss": 0.2012093965895474, "Avg policy loss": 0.292622456792742, "Total num played games": 66581, "Total num trained steps": 132608, "Timestamp in ms": 1699778592777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921655735490553, "Avg loss": 0.5613398482091725, "Avg value loss": 0.2738015357463155, "Avg policy loss": 0.28753831214271486, "Total num played games": 66629, "Total num trained steps": 132736, "Timestamp in ms": 1699778650667, "logtype": "training_step"}
{"Avg objective": 22.1640625, "Games time in secs": 131.93596545234323, "Avg game time in secs": 1.0031844611366978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.74}, "Total num played games": 66688, "Total num trained steps": 132850, "Timestamp in ms": 1699778701825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911281620908763, "Avg loss": 0.6169668028596789, "Avg value loss": 0.3243495903443545, "Avg policy loss": 0.29261721414513886, "Total num played games": 66728, "Total num trained steps": 132864, "Timestamp in ms": 1699778708251, "logtype": "training_step"}
{"Total num played games": 66780, "Total num trained steps": 132961, "Timestamp in ms": 1699778767729, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.3515625}
{"Avg objective": 21.1875, "Games time in secs": 67.77957185357809, "Avg game time in secs": 0.9143300691212062, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 66816, "Total num trained steps": 132964, "Timestamp in ms": 1699778769605, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900640450110731, "Avg loss": 0.6696011456660926, "Avg value loss": 0.3817955394333694, "Avg policy loss": 0.2878056042827666, "Total num played games": 66828, "Total num trained steps": 132992, "Timestamp in ms": 1699778782770, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919644460405819, "Avg loss": 0.4397714319638908, "Avg value loss": 0.1563729400804732, "Avg policy loss": 0.2833984917961061, "Total num played games": 66828, "Total num trained steps": 133120, "Timestamp in ms": 1699778839445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909453583755434, "Avg loss": 0.5213525508297607, "Avg value loss": 0.25553490049787797, "Avg policy loss": 0.265817642910406, "Total num played games": 66927, "Total num trained steps": 133248, "Timestamp in ms": 1699778896599, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 170.58748208358884, "Avg game time in secs": 0.9355474004260032, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 66944, "Total num trained steps": 133345, "Timestamp in ms": 1699778940193, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913552413515088, "Avg loss": 0.6466572678182274, "Avg value loss": 0.363356350309914, "Avg policy loss": 0.2833009229507297, "Total num played games": 66977, "Total num trained steps": 133376, "Timestamp in ms": 1699778953953, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918091486885685, "Avg loss": 0.6176504069007933, "Avg value loss": 0.3283014711923897, "Avg policy loss": 0.28934893594123423, "Total num played games": 67026, "Total num trained steps": 133504, "Timestamp in ms": 1699779010996, "logtype": "training_step"}
{"Avg objective": 22.75, "Games time in secs": 88.47296604327857, "Avg game time in secs": 1.0012463170132833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.8, "agent_stopped_0": 0.27}, "Total num played games": 67072, "Total num trained steps": 133545, "Timestamp in ms": 1699779028667, "logtype": "played_game"}
{"Total num played games": 67074, "Total num trained steps": 133564, "Timestamp in ms": 1699779048182, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0859375}
{"Ratio train steps to played games": 1.9908673758231281, "Avg loss": 0.7055609738454223, "Avg value loss": 0.41026655459427275, "Avg policy loss": 0.29529442253988236, "Total num played games": 67122, "Total num trained steps": 133632, "Timestamp in ms": 1699779078731, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991350305195772, "Avg loss": 0.5182927137939259, "Avg value loss": 0.2421625348215457, "Avg policy loss": 0.2761301778955385, "Total num played games": 67170, "Total num trained steps": 133760, "Timestamp in ms": 1699779138214, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 141.00647702626884, "Avg game time in secs": 0.8727490163582843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.58, "agent_stopped_0": 0.45}, "Total num played games": 67200, "Total num trained steps": 133831, "Timestamp in ms": 1699779169674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918177896130558, "Avg loss": 0.5298629628960043, "Avg value loss": 0.2407340008940082, "Avg policy loss": 0.2891289659310132, "Total num played games": 67219, "Total num trained steps": 133888, "Timestamp in ms": 1699779194500, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922993444036452, "Avg loss": 0.632956602727063, "Avg value loss": 0.34255379042588174, "Avg policy loss": 0.2904028178891167, "Total num played games": 67267, "Total num trained steps": 134016, "Timestamp in ms": 1699779251377, "logtype": "training_step"}
{"Avg objective": 22.609375, "Games time in secs": 131.99514564685524, "Avg game time in secs": 0.9466818641667487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.69, "agent_stopped_0": 0.35}, "Total num played games": 67328, "Total num trained steps": 134128, "Timestamp in ms": 1699779301669, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912271586978787, "Avg loss": 0.6293129532132298, "Avg value loss": 0.33424261372420006, "Avg policy loss": 0.29507033550180495, "Total num played games": 67367, "Total num trained steps": 134144, "Timestamp in ms": 1699779308033, "logtype": "training_step"}
{"Total num played games": 67367, "Total num trained steps": 134168, "Timestamp in ms": 1699779327481, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8125}
{"Ratio train steps to played games": 1.991708076837499, "Avg loss": 0.6614699987694621, "Avg value loss": 0.3577711328980513, "Avg policy loss": 0.3036988638341427, "Total num played games": 67415, "Total num trained steps": 134272, "Timestamp in ms": 1699779373763, "logtype": "training_step"}
{"Avg objective": 22.6875, "Games time in secs": 95.10733641125262, "Avg game time in secs": 0.8977475677675102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.65}, "Total num played games": 67456, "Total num trained steps": 134321, "Timestamp in ms": 1699779396777, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922031335695123, "Avg loss": 0.8107879196759313, "Avg value loss": 0.5156560620234814, "Avg policy loss": 0.295131862629205, "Total num played games": 67463, "Total num trained steps": 134400, "Timestamp in ms": 1699779434416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912226169330964, "Avg loss": 0.5756489872001112, "Avg value loss": 0.2832851801358629, "Avg policy loss": 0.29236380814109, "Total num played games": 67560, "Total num trained steps": 134528, "Timestamp in ms": 1699779490881, "logtype": "training_step"}
{"Avg objective": 21.640625, "Games time in secs": 129.3323419522494, "Avg game time in secs": 0.9265047553926706, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 67584, "Total num trained steps": 134611, "Timestamp in ms": 1699779526109, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917021654242102, "Avg loss": 0.5494457005988806, "Avg value loss": 0.260491865221411, "Avg policy loss": 0.2889538297895342, "Total num played games": 67608, "Total num trained steps": 134656, "Timestamp in ms": 1699779547086, "logtype": "training_step"}
{"Total num played games": 67660, "Total num trained steps": 134771, "Timestamp in ms": 1699779610605, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3828125}
{"Ratio train steps to played games": 1.9906658002008626, "Avg loss": 0.6074741708580405, "Avg value loss": 0.3249446206900757, "Avg policy loss": 0.28252954955678433, "Total num played games": 67708, "Total num trained steps": 134784, "Timestamp in ms": 1699779616786, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 146.53221487998962, "Avg game time in secs": 0.9240476379636675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.69}, "Total num played games": 67712, "Total num trained steps": 134906, "Timestamp in ms": 1699779672642, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991144695672708, "Avg loss": 0.5324871127959341, "Avg value loss": 0.24887788799242117, "Avg policy loss": 0.28360922855790704, "Total num played games": 67756, "Total num trained steps": 134912, "Timestamp in ms": 1699779674939, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916081647100465, "Avg loss": 0.5900576780550182, "Avg value loss": 0.3128988455864601, "Avg policy loss": 0.27715883404016495, "Total num played games": 67804, "Total num trained steps": 135040, "Timestamp in ms": 1699779732484, "logtype": "training_step"}
{"Avg objective": 19.859375, "Games time in secs": 87.63186470232904, "Avg game time in secs": 0.897561536374269, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.64}, "Total num played games": 67840, "Total num trained steps": 135099, "Timestamp in ms": 1699779760274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920857159700525, "Avg loss": 0.4469942463329062, "Avg value loss": 0.18036907046916895, "Avg policy loss": 0.2666251757182181, "Total num played games": 67852, "Total num trained steps": 135168, "Timestamp in ms": 1699779792989, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909791918062218, "Avg loss": 0.5853218872798607, "Avg value loss": 0.32163014920661226, "Avg policy loss": 0.2636917366180569, "Total num played games": 67954, "Total num trained steps": 135296, "Timestamp in ms": 1699779848800, "logtype": "training_step"}
{"Total num played games": 67954, "Total num trained steps": 135372, "Timestamp in ms": 1699779893401, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.671875}
{"Avg objective": 21.9921875, "Games time in secs": 134.47128419205546, "Avg game time in secs": 0.9013136861321982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.62, "agent_stopped_0": 0.38}, "Total num played games": 67968, "Total num trained steps": 135374, "Timestamp in ms": 1699779894745, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914708390929678, "Avg loss": 0.737195533933118, "Avg value loss": 0.45191861962666735, "Avg policy loss": 0.28527691622730345, "Total num played games": 68002, "Total num trained steps": 135424, "Timestamp in ms": 1699779917010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916104670810009, "Avg loss": 0.6673246182035655, "Avg value loss": 0.3920243870525155, "Avg policy loss": 0.27530022768769413, "Total num played games": 68061, "Total num trained steps": 135552, "Timestamp in ms": 1699779977215, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 109.95025620050728, "Avg game time in secs": 0.8730456889315974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 68096, "Total num trained steps": 135613, "Timestamp in ms": 1699780004696, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920569666715606, "Avg loss": 0.5218837035354227, "Avg value loss": 0.2455728982167784, "Avg policy loss": 0.2763108054641634, "Total num played games": 68110, "Total num trained steps": 135680, "Timestamp in ms": 1699780034478, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913488467572837, "Avg loss": 0.48546524136327207, "Avg value loss": 0.20521988152177073, "Avg policy loss": 0.2802453588228673, "Total num played games": 68198, "Total num trained steps": 135808, "Timestamp in ms": 1699780090573, "logtype": "training_step"}
{"Avg objective": 22.2734375, "Games time in secs": 131.56290002912283, "Avg game time in secs": 0.9068288021517219, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.55, "agent_stopped_0": 0.47}, "Total num played games": 68224, "Total num trained steps": 135902, "Timestamp in ms": 1699780136259, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916195387816098, "Avg loss": 0.5622785270679742, "Avg value loss": 0.2821721059153788, "Avg policy loss": 0.28010642470326275, "Total num played games": 68254, "Total num trained steps": 135936, "Timestamp in ms": 1699780151731, "logtype": "training_step"}
{"Total num played games": 68254, "Total num trained steps": 135976, "Timestamp in ms": 1699780181974, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.26953125}
{"Ratio train steps to played games": 1.9920792948961963, "Avg loss": 0.587705624755472, "Avg value loss": 0.305624570872169, "Avg policy loss": 0.28208104823715985, "Total num played games": 68302, "Total num trained steps": 136064, "Timestamp in ms": 1699780221706, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 143.29970147646964, "Avg game time in secs": 0.96168667418533, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.28, "agent_stopped_more": 0.72, "played_steps": 0.73}, "Total num played games": 68352, "Total num trained steps": 136190, "Timestamp in ms": 1699780279558, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914458676960871, "Avg loss": 0.677300610113889, "Avg value loss": 0.39107855065958574, "Avg policy loss": 0.2862220623064786, "Total num played games": 68386, "Total num trained steps": 136192, "Timestamp in ms": 1699780280169, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99130841258016, "Avg loss": 0.7302704028552398, "Avg value loss": 0.4356314454344101, "Avg policy loss": 0.2946389557328075, "Total num played games": 68457, "Total num trained steps": 136320, "Timestamp in ms": 1699780339974, "logtype": "training_step"}
{"Avg objective": 22.7734375, "Games time in secs": 99.93102355673909, "Avg game time in secs": 0.8844583979225717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 68480, "Total num trained steps": 136404, "Timestamp in ms": 1699780379490, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917816217794322, "Avg loss": 0.5600467284675688, "Avg value loss": 0.2582485214807093, "Avg policy loss": 0.30179820163175464, "Total num played games": 68505, "Total num trained steps": 136448, "Timestamp in ms": 1699780398561, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922541683077326, "Avg loss": 0.529815178597346, "Avg value loss": 0.24257035882328637, "Avg policy loss": 0.2872448245761916, "Total num played games": 68553, "Total num trained steps": 136576, "Timestamp in ms": 1699780454721, "logtype": "training_step"}
{"Total num played games": 68553, "Total num trained steps": 136580, "Timestamp in ms": 1699780474972, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.56640625}
{"Avg objective": 21.140625, "Games time in secs": 145.7155880704522, "Avg game time in secs": 0.8654496964736609, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 68608, "Total num trained steps": 136692, "Timestamp in ms": 1699780525205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991332721525441, "Avg loss": 0.5469192916061729, "Avg value loss": 0.261736506014131, "Avg policy loss": 0.28518278163392097, "Total num played games": 68649, "Total num trained steps": 136704, "Timestamp in ms": 1699780530485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917611610067105, "Avg loss": 0.6572969797998667, "Avg value loss": 0.36808300361735746, "Avg policy loss": 0.28921397775411606, "Total num played games": 68699, "Total num trained steps": 136832, "Timestamp in ms": 1699780587405, "logtype": "training_step"}
{"Avg objective": 22.578125, "Games time in secs": 87.43925886787474, "Avg game time in secs": 0.9189636068622349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 68736, "Total num trained steps": 136889, "Timestamp in ms": 1699780612645, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922323883223996, "Avg loss": 0.4802372541744262, "Avg value loss": 0.19904128179769032, "Avg policy loss": 0.28119596920441836, "Total num played games": 68747, "Total num trained steps": 136960, "Timestamp in ms": 1699780644098, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924133420536299, "Avg loss": 0.6827646030578762, "Avg value loss": 0.39465920929796994, "Avg policy loss": 0.28810540155973285, "Total num played games": 68805, "Total num trained steps": 137088, "Timestamp in ms": 1699780701369, "logtype": "training_step"}
{"Total num played games": 68858, "Total num trained steps": 137180, "Timestamp in ms": 1699780767483, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9765625}
{"Avg objective": 21.2265625, "Games time in secs": 155.8991188686341, "Avg game time in secs": 0.9425206902669743, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.66, "agent_stopped_0": 0.36}, "Total num played games": 68864, "Total num trained steps": 137181, "Timestamp in ms": 1699780768544, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991350535512147, "Avg loss": 0.6617087556514889, "Avg value loss": 0.37688144302228466, "Avg policy loss": 0.2848273153649643, "Total num played games": 68906, "Total num trained steps": 137216, "Timestamp in ms": 1699780784300, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918206340458857, "Avg loss": 0.4922108273021877, "Avg value loss": 0.2071579807670787, "Avg policy loss": 0.2850528456037864, "Total num played games": 68954, "Total num trained steps": 137344, "Timestamp in ms": 1699780847726, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 105.66653824597597, "Avg game time in secs": 0.8689926585793728, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 68992, "Total num trained steps": 137399, "Timestamp in ms": 1699780874211, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922755862148924, "Avg loss": 0.5041435731109232, "Avg value loss": 0.22517984680598602, "Avg policy loss": 0.27896372810937464, "Total num played games": 69002, "Total num trained steps": 137472, "Timestamp in ms": 1699780909101, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913600972531766, "Avg loss": 0.6043954626657069, "Avg value loss": 0.33580150053603575, "Avg policy loss": 0.26859396626241505, "Total num played games": 69098, "Total num trained steps": 137600, "Timestamp in ms": 1699780968065, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 134.92264704219997, "Avg game time in secs": 0.8364811840438051, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 69120, "Total num trained steps": 137687, "Timestamp in ms": 1699781009133, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918288838110665, "Avg loss": 0.9770738452207297, "Avg value loss": 0.6876946432166733, "Avg policy loss": 0.2893792091635987, "Total num played games": 69146, "Total num trained steps": 137728, "Timestamp in ms": 1699781028778, "logtype": "training_step"}
{"Total num played games": 69193, "Total num trained steps": 137782, "Timestamp in ms": 1699781066317, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.00390625}
{"Ratio train steps to played games": 1.9909591138198466, "Avg loss": 0.6622711068484932, "Avg value loss": 0.3661758396192454, "Avg policy loss": 0.29609526868443936, "Total num played games": 69241, "Total num trained steps": 137856, "Timestamp in ms": 1699781100267, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 145.67430904880166, "Avg game time in secs": 0.9264662921486888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 69248, "Total num trained steps": 137971, "Timestamp in ms": 1699781154808, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991412778363088, "Avg loss": 0.40024106530472636, "Avg value loss": 0.12228537918417715, "Avg policy loss": 0.2779556835303083, "Total num played games": 69289, "Total num trained steps": 137984, "Timestamp in ms": 1699781160316, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914638366593609, "Avg loss": 0.5806364824529737, "Avg value loss": 0.2945088798587676, "Avg policy loss": 0.28612761420663446, "Total num played games": 69352, "Total num trained steps": 138112, "Timestamp in ms": 1699781220019, "logtype": "training_step"}
{"Avg objective": 21.59375, "Games time in secs": 101.37580196000636, "Avg game time in secs": 0.8641148715832969, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.59}, "Total num played games": 69376, "Total num trained steps": 138194, "Timestamp in ms": 1699781256184, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918877249607354, "Avg loss": 0.6352936334442347, "Avg value loss": 0.3402606610034127, "Avg policy loss": 0.29503297072369605, "Total num played games": 69401, "Total num trained steps": 138240, "Timestamp in ms": 1699781277495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992354101570937, "Avg loss": 0.6963664658833295, "Avg value loss": 0.39733414229704067, "Avg policy loss": 0.2990323133999482, "Total num played games": 69449, "Total num trained steps": 138368, "Timestamp in ms": 1699781334305, "logtype": "training_step"}
{"Total num played games": 69449, "Total num trained steps": 138386, "Timestamp in ms": 1699781351305, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.48046875}
{"Avg objective": 22.7578125, "Games time in secs": 142.26516388729215, "Avg game time in secs": 0.898491065192502, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 69504, "Total num trained steps": 138486, "Timestamp in ms": 1699781398449, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914157536019326, "Avg loss": 0.5549380435841158, "Avg value loss": 0.2708688536658883, "Avg policy loss": 0.28406918817199767, "Total num played games": 69546, "Total num trained steps": 138496, "Timestamp in ms": 1699781402745, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918242427725732, "Avg loss": 0.708050339948386, "Avg value loss": 0.42052224921644665, "Avg policy loss": 0.28752808924764395, "Total num played games": 69596, "Total num trained steps": 138624, "Timestamp in ms": 1699781462919, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 92.59988048672676, "Avg game time in secs": 0.8905468725279206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 69632, "Total num trained steps": 138683, "Timestamp in ms": 1699781491049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923037160415829, "Avg loss": 0.5250584380701184, "Avg value loss": 0.2400113390176557, "Avg policy loss": 0.2850471049314365, "Total num played games": 69644, "Total num trained steps": 138752, "Timestamp in ms": 1699781524499, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912680660701996, "Avg loss": 0.5858679807279259, "Avg value loss": 0.3096592550573405, "Avg policy loss": 0.2762087202863768, "Total num played games": 69744, "Total num trained steps": 138880, "Timestamp in ms": 1699781581658, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 134.63186109252274, "Avg game time in secs": 0.9362920214189216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 69760, "Total num trained steps": 138978, "Timestamp in ms": 1699781625681, "logtype": "played_game"}
{"Total num played games": 69792, "Total num trained steps": 138989, "Timestamp in ms": 1699781643597, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.31640625}
{"Ratio train steps to played games": 1.9903636884306988, "Avg loss": 0.7179416373837739, "Avg value loss": 0.43673405644949526, "Avg policy loss": 0.2812075847759843, "Total num played games": 69840, "Total num trained steps": 139008, "Timestamp in ms": 1699781652093, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922107674684995, "Avg loss": 0.4139066569041461, "Avg value loss": 0.13360536348773167, "Avg policy loss": 0.28030129172839224, "Total num played games": 69840, "Total num trained steps": 139136, "Timestamp in ms": 1699781710483, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 102.80450464971364, "Avg game time in secs": 0.9155931202549255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.7}, "Total num played games": 69888, "Total num trained steps": 139176, "Timestamp in ms": 1699781728486, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992659684065934, "Avg loss": 0.6187784080393612, "Avg value loss": 0.34432534957886674, "Avg policy loss": 0.2744530657073483, "Total num played games": 69888, "Total num trained steps": 139264, "Timestamp in ms": 1699781767424, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917267985997, "Avg loss": 0.6951270399149507, "Avg value loss": 0.4127986794919707, "Avg policy loss": 0.28232835582457483, "Total num played games": 69985, "Total num trained steps": 139392, "Timestamp in ms": 1699781823349, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 126.08813880942762, "Avg game time in secs": 0.9125622143619694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 70016, "Total num trained steps": 139461, "Timestamp in ms": 1699781854574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992175229174401, "Avg loss": 0.5637187343090773, "Avg value loss": 0.2770509086258244, "Avg policy loss": 0.28666782670188695, "Total num played games": 70034, "Total num trained steps": 139520, "Timestamp in ms": 1699781881214, "logtype": "training_step"}
{"Total num played games": 70083, "Total num trained steps": 139593, "Timestamp in ms": 1699781930625, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.81640625}
{"Ratio train steps to played games": 1.9912449558683036, "Avg loss": 0.6480613823514432, "Avg value loss": 0.354899139580084, "Avg policy loss": 0.2931622435571626, "Total num played games": 70131, "Total num trained steps": 139648, "Timestamp in ms": 1699781955563, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 147.70740208029747, "Avg game time in secs": 0.9207437121367548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 70144, "Total num trained steps": 139752, "Timestamp in ms": 1699782002282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917069208737657, "Avg loss": 0.457030858960934, "Avg value loss": 0.17179537229822017, "Avg policy loss": 0.28523548413068056, "Total num played games": 70179, "Total num trained steps": 139776, "Timestamp in ms": 1699782012415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921682543750978, "Avg loss": 0.5044365448411554, "Avg value loss": 0.213914763124194, "Avg policy loss": 0.290521775954403, "Total num played games": 70227, "Total num trained steps": 139904, "Timestamp in ms": 1699782072175, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 89.64203494600952, "Avg game time in secs": 0.8588067839300493, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.58}, "Total num played games": 70272, "Total num trained steps": 139946, "Timestamp in ms": 1699782091924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926147278548558, "Avg loss": 0.5955953020602465, "Avg value loss": 0.3026944967568852, "Avg policy loss": 0.2929008106002584, "Total num played games": 70275, "Total num trained steps": 140032, "Timestamp in ms": 1699782131237, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917295476829944, "Avg loss": 0.6693099840776995, "Avg value loss": 0.3748957745847292, "Avg policy loss": 0.2944142100168392, "Total num played games": 70371, "Total num trained steps": 140160, "Timestamp in ms": 1699782187275, "logtype": "training_step"}
{"Total num played games": 70371, "Total num trained steps": 140194, "Timestamp in ms": 1699782214837, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.32421875}
{"Avg objective": 22.0078125, "Games time in secs": 124.9692078884691, "Avg game time in secs": 0.9063793001696467, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.59, "agent_stopped_0": 0.42}, "Total num played games": 70400, "Total num trained steps": 140199, "Timestamp in ms": 1699782216893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921754072054416, "Avg loss": 0.6011468730866909, "Avg value loss": 0.30636603364837356, "Avg policy loss": 0.2947808458702639, "Total num played games": 70419, "Total num trained steps": 140288, "Timestamp in ms": 1699782258498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992649041395263, "Avg loss": 0.538720769342035, "Avg value loss": 0.25452862816746347, "Avg policy loss": 0.2841921433573589, "Total num played games": 70467, "Total num trained steps": 140416, "Timestamp in ms": 1699782316794, "logtype": "training_step"}
{"Avg objective": 21.828125, "Games time in secs": 145.21638118103147, "Avg game time in secs": 0.8599262009956874, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 70528, "Total num trained steps": 140520, "Timestamp in ms": 1699782362110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917238251799785, "Avg loss": 0.5901029973756522, "Avg value loss": 0.31115049205254763, "Avg policy loss": 0.27895250730216503, "Total num played games": 70564, "Total num trained steps": 140544, "Timestamp in ms": 1699782373416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921826318472782, "Avg loss": 0.5565659229177982, "Avg value loss": 0.2720164974743966, "Avg policy loss": 0.2845494266366586, "Total num played games": 70612, "Total num trained steps": 140672, "Timestamp in ms": 1699782433583, "logtype": "training_step"}
{"Avg objective": 21.4140625, "Games time in secs": 91.49141557142138, "Avg game time in secs": 0.9285071764315944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.77}, "Total num played games": 70656, "Total num trained steps": 140716, "Timestamp in ms": 1699782453601, "logtype": "played_game"}
{"Total num played games": 70660, "Total num trained steps": 140797, "Timestamp in ms": 1699782504549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.875}
{"Ratio train steps to played games": 1.9922178988326849, "Avg loss": 0.5785626309225336, "Avg value loss": 0.28271623482578434, "Avg policy loss": 0.29584639507811517, "Total num played games": 70671, "Total num trained steps": 140800, "Timestamp in ms": 1699782506132, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917321499236813, "Avg loss": 0.8085263262037188, "Avg value loss": 0.5135053566482384, "Avg policy loss": 0.2950209671398625, "Total num played games": 70756, "Total num trained steps": 140928, "Timestamp in ms": 1699782564159, "logtype": "training_step"}
{"Avg objective": 23.0703125, "Games time in secs": 146.52286373637617, "Avg game time in secs": 0.8860651628056075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 70784, "Total num trained steps": 141003, "Timestamp in ms": 1699782600124, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992161570510557, "Avg loss": 0.686385371023789, "Avg value loss": 0.3915789570310153, "Avg policy loss": 0.29480642115231603, "Total num played games": 70805, "Total num trained steps": 141056, "Timestamp in ms": 1699782625948, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926185200344375, "Avg loss": 0.6571551621891558, "Avg value loss": 0.3631363108579535, "Avg policy loss": 0.29401885357219726, "Total num played games": 70853, "Total num trained steps": 141184, "Timestamp in ms": 1699782689481, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 145.13230535574257, "Avg game time in secs": 0.9327622342098039, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.67, "agent_stopped_0": 0.37}, "Total num played games": 70912, "Total num trained steps": 141292, "Timestamp in ms": 1699782745257, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916983791402396, "Avg loss": 0.6305036831181496, "Avg value loss": 0.34232273360248655, "Avg policy loss": 0.2881809415994212, "Total num played games": 70950, "Total num trained steps": 141312, "Timestamp in ms": 1699782755916, "logtype": "training_step"}
{"Total num played games": 70998, "Total num trained steps": 141399, "Timestamp in ms": 1699782813165, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0625}
{"Avg objective": 21.578125, "Games time in secs": 70.17990386858582, "Avg game time in secs": 0.8807133635273203, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 71040, "Total num trained steps": 141402, "Timestamp in ms": 1699782815439, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908087717816625, "Avg loss": 0.7246385378530249, "Avg value loss": 0.4373773525003344, "Avg policy loss": 0.28726118500344455, "Total num played games": 71046, "Total num trained steps": 141440, "Timestamp in ms": 1699782834762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992624496804887, "Avg loss": 0.35700828838162124, "Avg value loss": 0.08286762909847312, "Avg policy loss": 0.27414066065102816, "Total num played games": 71046, "Total num trained steps": 141568, "Timestamp in ms": 1699782897415, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917348401787973, "Avg loss": 0.6601612395606935, "Avg value loss": 0.3868675156845711, "Avg policy loss": 0.2732937269611284, "Total num played games": 71142, "Total num trained steps": 141696, "Timestamp in ms": 1699782959368, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 184.0608289744705, "Avg game time in secs": 0.8797314228286268, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.62, "agent_stopped_0": 0.4}, "Total num played games": 71168, "Total num trained steps": 141774, "Timestamp in ms": 1699782999500, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921758673971064, "Avg loss": 0.6847604187205434, "Avg value loss": 0.3979232714918908, "Avg policy loss": 0.2868371489457786, "Total num played games": 71190, "Total num trained steps": 141824, "Timestamp in ms": 1699783021733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926023666811719, "Avg loss": 0.6117428755387664, "Avg value loss": 0.3220211058796849, "Avg policy loss": 0.28972176637034863, "Total num played games": 71239, "Total num trained steps": 141952, "Timestamp in ms": 1699783078475, "logtype": "training_step"}
{"Total num played games": 71287, "Total num trained steps": 142001, "Timestamp in ms": 1699783111218, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8359375}
{"Avg objective": 21.1640625, "Games time in secs": 112.78907276503742, "Avg game time in secs": 0.9142081694881199, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.67, "agent_stopped_0": 0.4}, "Total num played games": 71296, "Total num trained steps": 142003, "Timestamp in ms": 1699783112289, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917291652064204, "Avg loss": 0.8550688503310084, "Avg value loss": 0.547982438118197, "Avg policy loss": 0.3070864115143195, "Total num played games": 71335, "Total num trained steps": 142080, "Timestamp in ms": 1699783151107, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99216900382444, "Avg loss": 0.49336799792945385, "Avg value loss": 0.20189556197146885, "Avg policy loss": 0.2914724355796352, "Total num played games": 71383, "Total num trained steps": 142208, "Timestamp in ms": 1699783212665, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 121.74888970330358, "Avg game time in secs": 0.8918888035113923, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.67, "played_steps": 0.69, "agent_stopped_0": 0.33}, "Total num played games": 71424, "Total num trained steps": 142258, "Timestamp in ms": 1699783234038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926222508434712, "Avg loss": 0.6391393383964896, "Avg value loss": 0.3434388567111455, "Avg policy loss": 0.2957004805793986, "Total num played games": 71431, "Total num trained steps": 142336, "Timestamp in ms": 1699783270917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.99157032418604, "Avg loss": 0.6247834314126521, "Avg value loss": 0.32809018398984335, "Avg policy loss": 0.29669323877897114, "Total num played games": 71533, "Total num trained steps": 142464, "Timestamp in ms": 1699783328218, "logtype": "training_step"}
{"Avg objective": 23.859375, "Games time in secs": 135.20424873940647, "Avg game time in secs": 0.9064939579111524, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 71552, "Total num trained steps": 142556, "Timestamp in ms": 1699783369243, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991995194322595, "Avg loss": 0.5130958645604551, "Avg value loss": 0.22127885854570195, "Avg policy loss": 0.29181700525805354, "Total num played games": 71582, "Total num trained steps": 142592, "Timestamp in ms": 1699783385872, "logtype": "training_step"}
{"Total num played games": 71582, "Total num trained steps": 142604, "Timestamp in ms": 1699783400678, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.37109375}
{"Ratio train steps to played games": 1.9924472986178976, "Avg loss": 0.5633547438774258, "Avg value loss": 0.27862163237296045, "Avg policy loss": 0.2847331155790016, "Total num played games": 71630, "Total num trained steps": 142720, "Timestamp in ms": 1699783458314, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 105.56483239680529, "Avg game time in secs": 0.9312424266972812, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.68}, "Total num played games": 71680, "Total num trained steps": 142753, "Timestamp in ms": 1699783474808, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927597896293403, "Avg loss": 0.5081713524414226, "Avg value loss": 0.21397652570158243, "Avg policy loss": 0.294194828835316, "Total num played games": 71683, "Total num trained steps": 142848, "Timestamp in ms": 1699783522017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916836151895914, "Avg loss": 0.6193099615629762, "Avg value loss": 0.32323013129644096, "Avg policy loss": 0.2960798336425796, "Total num played games": 71786, "Total num trained steps": 142976, "Timestamp in ms": 1699783583802, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 153.41707522794604, "Avg game time in secs": 0.9120568844809895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 71808, "Total num trained steps": 143063, "Timestamp in ms": 1699783628225, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992148564746499, "Avg loss": 0.5409094186034054, "Avg value loss": 0.2444151128293015, "Avg policy loss": 0.29649430664721876, "Total num played games": 71834, "Total num trained steps": 143104, "Timestamp in ms": 1699783650164, "logtype": "training_step"}
{"Total num played games": 71888, "Total num trained steps": 143207, "Timestamp in ms": 1699783711641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.57421875}
{"Avg objective": 20.84375, "Games time in secs": 86.01755928248167, "Avg game time in secs": 0.9784299094462767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.8, "agent_stopped_0": 0.3}, "Total num played games": 71936, "Total num trained steps": 143213, "Timestamp in ms": 1699783714243, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910893016014235, "Avg loss": 0.6351582736242563, "Avg value loss": 0.3344844375969842, "Avg policy loss": 0.3006738335825503, "Total num played games": 71936, "Total num trained steps": 143232, "Timestamp in ms": 1699783723145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928686610320285, "Avg loss": 0.52238665567711, "Avg value loss": 0.2215832906367723, "Avg policy loss": 0.30080336437094957, "Total num played games": 71936, "Total num trained steps": 143360, "Timestamp in ms": 1699783792785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918929424176801, "Avg loss": 0.623789434088394, "Avg value loss": 0.3240875457995571, "Avg policy loss": 0.299701891024597, "Total num played games": 72036, "Total num trained steps": 143488, "Timestamp in ms": 1699783859850, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 183.0002434849739, "Avg game time in secs": 0.8688313502643723, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.62}, "Total num played games": 72064, "Total num trained steps": 143562, "Timestamp in ms": 1699783897243, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923283946506853, "Avg loss": 0.6031103546265513, "Avg value loss": 0.30336895331856795, "Avg policy loss": 0.2997414041310549, "Total num played games": 72084, "Total num trained steps": 143616, "Timestamp in ms": 1699783923450, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927633676680576, "Avg loss": 0.6045302045531571, "Avg value loss": 0.30658122096792795, "Avg policy loss": 0.2979489790741354, "Total num played games": 72133, "Total num trained steps": 143744, "Timestamp in ms": 1699783989138, "logtype": "training_step"}
{"Total num played games": 72181, "Total num trained steps": 143809, "Timestamp in ms": 1699784032438, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5625}
{"Avg objective": 22.078125, "Games time in secs": 136.48333293572068, "Avg game time in secs": 0.9042115599440876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 72192, "Total num trained steps": 143809, "Timestamp in ms": 1699784033727, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918730703733958, "Avg loss": 0.8082043819595128, "Avg value loss": 0.5115910244348925, "Avg policy loss": 0.2966133572626859, "Total num played games": 72229, "Total num trained steps": 143872, "Timestamp in ms": 1699784064792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923350443432903, "Avg loss": 0.5158094873186201, "Avg value loss": 0.2313059895823244, "Avg policy loss": 0.2845034976489842, "Total num played games": 72277, "Total num trained steps": 144000, "Timestamp in ms": 1699784130737, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 118.91122245788574, "Avg game time in secs": 0.8889096139464527, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.67, "agent_stopped_0": 0.35}, "Total num played games": 72320, "Total num trained steps": 144045, "Timestamp in ms": 1699784152638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927687521603872, "Avg loss": 0.5157919290941209, "Avg value loss": 0.2279915136168711, "Avg policy loss": 0.2878004078520462, "Total num played games": 72325, "Total num trained steps": 144128, "Timestamp in ms": 1699784193563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918946162024826, "Avg loss": 0.7157851597294211, "Avg value loss": 0.421078464074526, "Avg policy loss": 0.29470668779686093, "Total num played games": 72421, "Total num trained steps": 144256, "Timestamp in ms": 1699784256372, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 142.20107814855874, "Avg game time in secs": 0.9448506321496097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.65, "agent_stopped_0": 0.42}, "Total num played games": 72448, "Total num trained steps": 144333, "Timestamp in ms": 1699784294839, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923278598040568, "Avg loss": 0.6359670818783343, "Avg value loss": 0.33162572656874545, "Avg policy loss": 0.30434135568793863, "Total num played games": 72470, "Total num trained steps": 144384, "Timestamp in ms": 1699784320614, "logtype": "training_step"}
{"Total num played games": 72470, "Total num trained steps": 144410, "Timestamp in ms": 1699784344347, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9140625}
{"Ratio train steps to played games": 1.9927604181030916, "Avg loss": 0.5435823167208582, "Avg value loss": 0.2470439942262601, "Avg policy loss": 0.29653831815812737, "Total num played games": 72518, "Total num trained steps": 144512, "Timestamp in ms": 1699784394047, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 152.29917485266924, "Avg game time in secs": 0.9653617933799978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 72576, "Total num trained steps": 144622, "Timestamp in ms": 1699784447139, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918886165202303, "Avg loss": 0.5941975128371269, "Avg value loss": 0.3016585329605732, "Avg policy loss": 0.2925389864249155, "Total num played games": 72614, "Total num trained steps": 144640, "Timestamp in ms": 1699784456061, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923343700971623, "Avg loss": 0.5979452785104513, "Avg value loss": 0.2999613989959471, "Avg policy loss": 0.2979838780593127, "Total num played games": 72662, "Total num trained steps": 144768, "Timestamp in ms": 1699784520214, "logtype": "training_step"}
{"Avg objective": 20.3203125, "Games time in secs": 97.03228415176272, "Avg game time in secs": 0.9275205683225067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.73}, "Total num played games": 72704, "Total num trained steps": 144815, "Timestamp in ms": 1699784544171, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927795351395956, "Avg loss": 0.6570151201449335, "Avg value loss": 0.35694161386345513, "Avg policy loss": 0.30007350840605795, "Total num played games": 72710, "Total num trained steps": 144896, "Timestamp in ms": 1699784583229, "logtype": "training_step"}
{"Total num played games": 72808, "Total num trained steps": 145013, "Timestamp in ms": 1699784650433, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7421875}
{"Avg objective": 20.796875, "Games time in secs": 107.96472884528339, "Avg game time in secs": 0.9651058435119921, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.66, "agent_stopped_0": 0.39}, "Total num played games": 72832, "Total num trained steps": 145015, "Timestamp in ms": 1699784652136, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905567146151313, "Avg loss": 0.6658644245471805, "Avg value loss": 0.3691396930371411, "Avg policy loss": 0.2967247288906947, "Total num played games": 72856, "Total num trained steps": 145024, "Timestamp in ms": 1699784656769, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923136049192929, "Avg loss": 0.533628951292485, "Avg value loss": 0.2333019849320408, "Avg policy loss": 0.3003269628388807, "Total num played games": 72856, "Total num trained steps": 145152, "Timestamp in ms": 1699784721457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992743882365851, "Avg loss": 0.5748317225370556, "Avg value loss": 0.2829681634029839, "Avg policy loss": 0.2918635573005304, "Total num played games": 72904, "Total num trained steps": 145280, "Timestamp in ms": 1699784784754, "logtype": "training_step"}
{"Avg objective": 22.15625, "Games time in secs": 192.51675564795732, "Avg game time in secs": 0.9182845341711072, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.64, "agent_stopped_0": 0.4}, "Total num played games": 72960, "Total num trained steps": 145396, "Timestamp in ms": 1699784844653, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991822141859127, "Avg loss": 0.604847967857495, "Avg value loss": 0.31430261535570025, "Avg policy loss": 0.29054535343311727, "Total num played games": 73002, "Total num trained steps": 145408, "Timestamp in ms": 1699784850381, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922382992703727, "Avg loss": 0.5245781494304538, "Avg value loss": 0.2228047622484155, "Avg policy loss": 0.3017733850283548, "Total num played games": 73051, "Total num trained steps": 145536, "Timestamp in ms": 1699784914578, "logtype": "training_step"}
{"Avg objective": 21.21875, "Games time in secs": 100.23004304990172, "Avg game time in secs": 0.9588421400112566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.68, "played_steps": 0.73}, "Total num played games": 73088, "Total num trained steps": 145593, "Timestamp in ms": 1699784944883, "logtype": "played_game"}
{"Total num played games": 73099, "Total num trained steps": 145612, "Timestamp in ms": 1699784979726, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.703125}
{"Ratio train steps to played games": 1.9913872065840021, "Avg loss": 0.8248502528294921, "Avg value loss": 0.5170584720617626, "Avg policy loss": 0.30779177765361965, "Total num played games": 73147, "Total num trained steps": 145664, "Timestamp in ms": 1699785006275, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918300430357265, "Avg loss": 0.4931616522371769, "Avg value loss": 0.19559404236497357, "Avg policy loss": 0.29756761400494725, "Total num played games": 73195, "Total num trained steps": 145792, "Timestamp in ms": 1699785071764, "logtype": "training_step"}
{"Avg objective": 22.765625, "Games time in secs": 169.845438092947, "Avg game time in secs": 0.9305577426275704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 73216, "Total num trained steps": 145880, "Timestamp in ms": 1699785114729, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922722990592958, "Avg loss": 0.6392971964087337, "Avg value loss": 0.3480383694404736, "Avg policy loss": 0.29125882347580045, "Total num played games": 73243, "Total num trained steps": 145920, "Timestamp in ms": 1699785134196, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992700331555034, "Avg loss": 0.6654220139607787, "Avg value loss": 0.3748854899313301, "Avg policy loss": 0.2905365340411663, "Total num played games": 73291, "Total num trained steps": 146048, "Timestamp in ms": 1699785196971, "logtype": "training_step"}
{"Avg objective": 22.359375, "Games time in secs": 141.94441001303494, "Avg game time in secs": 0.9895764257234987, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.7}, "Total num played games": 73344, "Total num trained steps": 146168, "Timestamp in ms": 1699785256674, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918377914344503, "Avg loss": 0.5562205263413489, "Avg value loss": 0.26402380884974264, "Avg policy loss": 0.29219671501778066, "Total num played games": 73387, "Total num trained steps": 146176, "Timestamp in ms": 1699785260721, "logtype": "training_step"}
{"Total num played games": 73387, "Total num trained steps": 146213, "Timestamp in ms": 1699785305710, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.84375}
{"Ratio train steps to played games": 1.9922788860897391, "Avg loss": 0.6082865162752569, "Avg value loss": 0.31309850033721887, "Avg policy loss": 0.29518801369704306, "Total num played games": 73435, "Total num trained steps": 146304, "Timestamp in ms": 1699785351275, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 123.69986741617322, "Avg game time in secs": 0.942914064755314, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.75}, "Total num played games": 73472, "Total num trained steps": 146362, "Timestamp in ms": 1699785380374, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926922867563006, "Avg loss": 0.5695603741332889, "Avg value loss": 0.27557111976784654, "Avg policy loss": 0.2939892610302195, "Total num played games": 73484, "Total num trained steps": 146432, "Timestamp in ms": 1699785415420, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918320195705355, "Avg loss": 0.4839916646014899, "Avg value loss": 0.2026812594558578, "Avg policy loss": 0.28131040709558874, "Total num played games": 73580, "Total num trained steps": 146560, "Timestamp in ms": 1699785477050, "logtype": "training_step"}
{"Avg objective": 21.7890625, "Games time in secs": 140.65876947529614, "Avg game time in secs": 0.9259755474922713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.59, "agent_stopped_0": 0.44}, "Total num played games": 73600, "Total num trained steps": 146651, "Timestamp in ms": 1699785521033, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921502587155215, "Avg loss": 0.6872590675484389, "Avg value loss": 0.39112025225767866, "Avg policy loss": 0.2961388232652098, "Total num played games": 73633, "Total num trained steps": 146688, "Timestamp in ms": 1699785539912, "logtype": "training_step"}
{"Total num played games": 73683, "Total num trained steps": 146815, "Timestamp in ms": 1699785614982, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.70703125}
{"Ratio train steps to played games": 1.992130044234579, "Avg loss": 0.4828375605866313, "Avg value loss": 0.19287539416109212, "Avg policy loss": 0.2899621659889817, "Total num played games": 73692, "Total num trained steps": 146816, "Timestamp in ms": 1699785616360, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 96.1884262766689, "Avg game time in secs": 0.937736366133322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.71, "agent_stopped_0": 0.34}, "Total num played games": 73728, "Total num trained steps": 146818, "Timestamp in ms": 1699785617221, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992960898400944, "Avg loss": 0.5423340459819883, "Avg value loss": 0.2417028087656945, "Avg policy loss": 0.3006312381476164, "Total num played games": 73731, "Total num trained steps": 146944, "Timestamp in ms": 1699785677958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921167052704296, "Avg loss": 0.6641708582174033, "Avg value loss": 0.3623505186405964, "Avg policy loss": 0.30182034347672015, "Total num played games": 73827, "Total num trained steps": 147072, "Timestamp in ms": 1699785739979, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 158.77995404787362, "Avg game time in secs": 0.8851833886292297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.62, "agent_stopped_0": 0.38}, "Total num played games": 73856, "Total num trained steps": 147145, "Timestamp in ms": 1699785776001, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925414551607445, "Avg loss": 0.5631733245681971, "Avg value loss": 0.26003895892063156, "Avg policy loss": 0.30313436838332564, "Total num played games": 73875, "Total num trained steps": 147200, "Timestamp in ms": 1699785804779, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929927086292494, "Avg loss": 0.5621370756998658, "Avg value loss": 0.2640508614422288, "Avg policy loss": 0.2980862082913518, "Total num played games": 73923, "Total num trained steps": 147328, "Timestamp in ms": 1699785872721, "logtype": "training_step"}
{"Total num played games": 73970, "Total num trained steps": 147416, "Timestamp in ms": 1699785924452, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.01953125}
{"Avg objective": 21.1171875, "Games time in secs": 149.87796941772103, "Avg game time in secs": 0.9079211039788788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 73984, "Total num trained steps": 147418, "Timestamp in ms": 1699785925879, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992164068199627, "Avg loss": 0.6309144103433937, "Avg value loss": 0.3358264699054416, "Avg policy loss": 0.29508794378489256, "Total num played games": 74018, "Total num trained steps": 147456, "Timestamp in ms": 1699785943601, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926011935300947, "Avg loss": 0.5248426136095077, "Avg value loss": 0.22758702922146767, "Avg policy loss": 0.29725558194331825, "Total num played games": 74066, "Total num trained steps": 147584, "Timestamp in ms": 1699786006602, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 100.97728303447366, "Avg game time in secs": 0.9161078511679079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.65}, "Total num played games": 74112, "Total num trained steps": 147624, "Timestamp in ms": 1699786026857, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993024259923901, "Avg loss": 0.4869588108267635, "Avg value loss": 0.1917862937261816, "Avg policy loss": 0.2951725183520466, "Total num played games": 74114, "Total num trained steps": 147712, "Timestamp in ms": 1699786071464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920501246378763, "Avg loss": 0.7558828322216868, "Avg value loss": 0.4576774876913987, "Avg policy loss": 0.29820534389000386, "Total num played games": 74215, "Total num trained steps": 147840, "Timestamp in ms": 1699786135636, "logtype": "training_step"}
{"Avg objective": 22.5, "Games time in secs": 148.26789078116417, "Avg game time in secs": 0.855522546407883, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.54, "agent_stopped_0": 0.51}, "Total num played games": 74240, "Total num trained steps": 147921, "Timestamp in ms": 1699786175125, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924861640386196, "Avg loss": 0.5667794058099389, "Avg value loss": 0.2596304464386776, "Avg policy loss": 0.3071489610010758, "Total num played games": 74263, "Total num trained steps": 147968, "Timestamp in ms": 1699786198007, "logtype": "training_step"}
{"Total num played games": 74311, "Total num trained steps": 148019, "Timestamp in ms": 1699786236070, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6953125}
{"Ratio train steps to played games": 1.9916351752982153, "Avg loss": 0.9201874327845871, "Avg value loss": 0.6132539247337263, "Avg policy loss": 0.30693349824287, "Total num played games": 74359, "Total num trained steps": 148096, "Timestamp in ms": 1699786275237, "logtype": "training_step"}
{"Avg objective": 23.921875, "Games time in secs": 160.12629590183496, "Avg game time in secs": 0.9893357729160925, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 74368, "Total num trained steps": 148208, "Timestamp in ms": 1699786335251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920571989194564, "Avg loss": 0.46543771610595286, "Avg value loss": 0.16025146911852062, "Avg policy loss": 0.3051862478023395, "Total num played games": 74407, "Total num trained steps": 148224, "Timestamp in ms": 1699786342570, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924653486622972, "Avg loss": 0.57260606973432, "Avg value loss": 0.2656182293139864, "Avg policy loss": 0.3069878432434052, "Total num played games": 74456, "Total num trained steps": 148352, "Timestamp in ms": 1699786403276, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 92.80123819597065, "Avg game time in secs": 0.9547976432950236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 74496, "Total num trained steps": 148403, "Timestamp in ms": 1699786428053, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928997100826802, "Avg loss": 0.5308514826465398, "Avg value loss": 0.2314446413947735, "Avg policy loss": 0.2994068443076685, "Total num played games": 74504, "Total num trained steps": 148480, "Timestamp in ms": 1699786465396, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920509383378016, "Avg loss": 0.5305175657849759, "Avg value loss": 0.23794416530290619, "Avg policy loss": 0.29257339728064835, "Total num played games": 74600, "Total num trained steps": 148608, "Timestamp in ms": 1699786526829, "logtype": "training_step"}
{"Total num played games": 74600, "Total num trained steps": 148622, "Timestamp in ms": 1699786547816, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.83203125}
{"Avg objective": 20.3203125, "Games time in secs": 121.58014926873147, "Avg game time in secs": 0.9553437638969626, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.75, "agent_stopped_0": 0.31}, "Total num played games": 74624, "Total num trained steps": 148626, "Timestamp in ms": 1699786549633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924981245311328, "Avg loss": 0.5937494162935764, "Avg value loss": 0.29381587338866666, "Avg policy loss": 0.299933550064452, "Total num played games": 74648, "Total num trained steps": 148736, "Timestamp in ms": 1699786605609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929179608011138, "Avg loss": 0.7756487338338047, "Avg value loss": 0.48037739857682027, "Avg policy loss": 0.295271321432665, "Total num played games": 74696, "Total num trained steps": 148864, "Timestamp in ms": 1699786672000, "logtype": "training_step"}
{"Avg objective": 21.5859375, "Games time in secs": 179.24284702166915, "Avg game time in secs": 0.9282265140791424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.67}, "Total num played games": 74752, "Total num trained steps": 148978, "Timestamp in ms": 1699786728876, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919515488589115, "Avg loss": 0.6843341835774481, "Avg value loss": 0.39056263052043505, "Avg policy loss": 0.2937715611187741, "Total num played games": 74797, "Total num trained steps": 148992, "Timestamp in ms": 1699786735346, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923442802554578, "Avg loss": 0.5739787113852799, "Avg value loss": 0.2797928397776559, "Avg policy loss": 0.29418587556574494, "Total num played games": 74846, "Total num trained steps": 149120, "Timestamp in ms": 1699786799166, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 101.3607680760324, "Avg game time in secs": 0.954066743288422, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.73}, "Total num played games": 74880, "Total num trained steps": 149183, "Timestamp in ms": 1699786830237, "logtype": "played_game"}
{"Total num played games": 74894, "Total num trained steps": 149224, "Timestamp in ms": 1699786862058, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.56640625}
{"Ratio train steps to played games": 1.9915000934055669, "Avg loss": 0.7107603719923645, "Avg value loss": 0.4175132554664742, "Avg policy loss": 0.29324711998924613, "Total num played games": 74942, "Total num trained steps": 149248, "Timestamp in ms": 1699786873810, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920119487377812, "Avg loss": 0.4361973878694698, "Avg value loss": 0.13622338123968802, "Avg policy loss": 0.2999740071827546, "Total num played games": 74984, "Total num trained steps": 149376, "Timestamp in ms": 1699786935499, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 152.58413045108318, "Avg game time in secs": 0.930657684628386, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.62, "agent_stopped_0": 0.4}, "Total num played games": 75008, "Total num trained steps": 149476, "Timestamp in ms": 1699786982821, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992284217960848, "Avg loss": 0.56715471833013, "Avg value loss": 0.27931515185628086, "Avg policy loss": 0.2878395653096959, "Total num played games": 75041, "Total num trained steps": 149504, "Timestamp in ms": 1699786995210, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926887734718337, "Avg loss": 0.5025298189138994, "Avg value loss": 0.2121342686295975, "Avg policy loss": 0.2903955529909581, "Total num played games": 75090, "Total num trained steps": 149632, "Timestamp in ms": 1699787051925, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 87.72745324671268, "Avg game time in secs": 0.897922910444322, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.69}, "Total num played games": 75136, "Total num trained steps": 149672, "Timestamp in ms": 1699787070549, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931193271047938, "Avg loss": 0.4748108747880906, "Avg value loss": 0.19571428676135838, "Avg policy loss": 0.2790965902386233, "Total num played games": 75138, "Total num trained steps": 149760, "Timestamp in ms": 1699787114173, "logtype": "training_step"}
{"Total num played games": 75190, "Total num trained steps": 149826, "Timestamp in ms": 1699787154406, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.28515625}
{"Ratio train steps to played games": 1.9921715090778596, "Avg loss": 0.8002284204121679, "Avg value loss": 0.5102134417102206, "Avg policy loss": 0.2900149872293696, "Total num played games": 75238, "Total num trained steps": 149888, "Timestamp in ms": 1699787187013, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 153.3923672325909, "Avg game time in secs": 0.868668745708419, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 75264, "Total num trained steps": 149967, "Timestamp in ms": 1699787223941, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9926015461041893, "Avg loss": 0.45769802131690085, "Avg value loss": 0.17825899313902482, "Avg policy loss": 0.27943903079722077, "Total num played games": 75286, "Total num trained steps": 150016, "Timestamp in ms": 1699787247056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993031035123583, "Avg loss": 0.5272352299652994, "Avg value loss": 0.24541820166632533, "Avg policy loss": 0.2818170302780345, "Total num played games": 75334, "Total num trained steps": 150144, "Timestamp in ms": 1699787309769, "logtype": "training_step"}
{"Avg objective": 22.25, "Games time in secs": 142.49199453927577, "Avg game time in secs": 0.9052632069942774, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 75392, "Total num trained steps": 150253, "Timestamp in ms": 1699787366433, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992191435768262, "Avg loss": 0.7246651493478566, "Avg value loss": 0.43255269184010103, "Avg policy loss": 0.2921124591957778, "Total num played games": 75430, "Total num trained steps": 150272, "Timestamp in ms": 1699787375718, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925939665337378, "Avg loss": 0.6673259020317346, "Avg value loss": 0.35201458289520815, "Avg policy loss": 0.3153113172156736, "Total num played games": 75479, "Total num trained steps": 150400, "Timestamp in ms": 1699787437427, "logtype": "training_step"}
{"Total num played games": 75479, "Total num trained steps": 150427, "Timestamp in ms": 1699787464991, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.06640625}
{"Avg objective": 22.140625, "Games time in secs": 100.97945404238999, "Avg game time in secs": 0.975150098951417, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.23, "agent_stopped_more": 0.77, "played_steps": 0.85}, "Total num played games": 75520, "Total num trained steps": 150431, "Timestamp in ms": 1699787467413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9930356031617833, "Avg loss": 0.5443623163737357, "Avg value loss": 0.22550588625017554, "Avg policy loss": 0.31885642965789884, "Total num played games": 75527, "Total num trained steps": 150528, "Timestamp in ms": 1699787516679, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992105889508899, "Avg loss": 0.6123401813674718, "Avg value loss": 0.29887588825658895, "Avg policy loss": 0.3134642990771681, "Total num played games": 75626, "Total num trained steps": 150656, "Timestamp in ms": 1699787580584, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 154.22819757275283, "Avg game time in secs": 0.9111153036938049, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 75648, "Total num trained steps": 150742, "Timestamp in ms": 1699787621641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925074331020813, "Avg loss": 0.7801833332050592, "Avg value loss": 0.4659651023685001, "Avg policy loss": 0.31421823939308524, "Total num played games": 75675, "Total num trained steps": 150784, "Timestamp in ms": 1699787641562, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992934775431507, "Avg loss": 0.5904705168213695, "Avg value loss": 0.28318888635840267, "Avg policy loss": 0.307281632325612, "Total num played games": 75723, "Total num trained steps": 150912, "Timestamp in ms": 1699787700799, "logtype": "training_step"}
{"Total num played games": 75772, "Total num trained steps": 151028, "Timestamp in ms": 1699787769685, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.25}
{"Avg objective": 21.84375, "Games time in secs": 149.0536539349705, "Avg game time in secs": 0.9140550103911664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 75776, "Total num trained steps": 151029, "Timestamp in ms": 1699787770695, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920733315747823, "Avg loss": 0.7184501572046429, "Avg value loss": 0.4151864160376135, "Avg policy loss": 0.3032637375872582, "Total num played games": 75820, "Total num trained steps": 151040, "Timestamp in ms": 1699787775384, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925133125955607, "Avg loss": 0.6476182790938765, "Avg value loss": 0.3484159626532346, "Avg policy loss": 0.2992023139959201, "Total num played games": 75868, "Total num trained steps": 151168, "Timestamp in ms": 1699787839419, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 97.88542191684246, "Avg game time in secs": 0.9537388585013105, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.31, "agent_stopped_more": 0.69, "played_steps": 0.73}, "Total num played games": 75904, "Total num trained steps": 151227, "Timestamp in ms": 1699787868581, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929001409433986, "Avg loss": 0.5524921473115683, "Avg value loss": 0.258469612483168, "Avg policy loss": 0.294022539164871, "Total num played games": 75917, "Total num trained steps": 151296, "Timestamp in ms": 1699787901244, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920540952982346, "Avg loss": 0.5454900136683136, "Avg value loss": 0.25309546713833697, "Avg policy loss": 0.2923945467919111, "Total num played games": 76014, "Total num trained steps": 151424, "Timestamp in ms": 1699787961473, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 140.3199131861329, "Avg game time in secs": 0.8648326619004365, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.61, "agent_stopped_0": 0.43}, "Total num played games": 76032, "Total num trained steps": 151519, "Timestamp in ms": 1699788008901, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924666719255344, "Avg loss": 0.6549665746279061, "Avg value loss": 0.351749807363376, "Avg policy loss": 0.3032167737837881, "Total num played games": 76062, "Total num trained steps": 151552, "Timestamp in ms": 1699788025705, "logtype": "training_step"}
{"Total num played games": 76110, "Total num trained steps": 151632, "Timestamp in ms": 1699788081196, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.63671875}
{"Ratio train steps to played games": 1.991635809763912, "Avg loss": 0.6228172453120351, "Avg value loss": 0.31175720164901577, "Avg policy loss": 0.31106004083994776, "Total num played games": 76158, "Total num trained steps": 151680, "Timestamp in ms": 1699788103754, "logtype": "training_step"}
{"Avg objective": 20.96875, "Games time in secs": 157.37210133485496, "Avg game time in secs": 0.9516086142975837, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.73, "played_steps": 0.76, "agent_stopped_0": 0.27}, "Total num played games": 76160, "Total num trained steps": 151805, "Timestamp in ms": 1699788166273, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920741148990893, "Avg loss": 0.3753365573938936, "Avg value loss": 0.07732125217444263, "Avg policy loss": 0.2980153082171455, "Total num played games": 76204, "Total num trained steps": 151808, "Timestamp in ms": 1699788167232, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924856400975686, "Avg loss": 0.7232041913084686, "Avg value loss": 0.4260709019144997, "Avg policy loss": 0.297133288346231, "Total num played games": 76254, "Total num trained steps": 151936, "Timestamp in ms": 1699788233181, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 98.248071487993, "Avg game time in secs": 0.8974655003257794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.66}, "Total num played games": 76288, "Total num trained steps": 151999, "Timestamp in ms": 1699788264521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992909753348536, "Avg loss": 0.5166188613511622, "Avg value loss": 0.21785047254525125, "Avg policy loss": 0.2987683928804472, "Total num played games": 76302, "Total num trained steps": 152064, "Timestamp in ms": 1699788294909, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932811190276614, "Avg loss": 0.4789582130033523, "Avg value loss": 0.1870837154565379, "Avg policy loss": 0.2918744975468144, "Total num played games": 76352, "Total num trained steps": 152192, "Timestamp in ms": 1699788356023, "logtype": "training_step"}
{"Total num played games": 76400, "Total num trained steps": 152234, "Timestamp in ms": 1699788387113, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.421875}
{"Avg objective": 21.046875, "Games time in secs": 124.06389363668859, "Avg game time in secs": 0.9489155109913554, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.74, "agent_stopped_0": 0.29}, "Total num played games": 76416, "Total num trained steps": 152236, "Timestamp in ms": 1699788388585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992465466722478, "Avg loss": 0.7001919220201671, "Avg value loss": 0.4169846072618384, "Avg policy loss": 0.283207310247235, "Total num played games": 76448, "Total num trained steps": 152320, "Timestamp in ms": 1699788429674, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928624651947136, "Avg loss": 0.48182252305559814, "Avg value loss": 0.1978675170103088, "Avg policy loss": 0.28395500546321273, "Total num played games": 76497, "Total num trained steps": 152448, "Timestamp in ms": 1699788492187, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 122.33135108090937, "Avg game time in secs": 0.9612083136598812, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.71, "played_steps": 0.75, "agent_stopped_0": 0.29}, "Total num played games": 76544, "Total num trained steps": 152486, "Timestamp in ms": 1699788510917, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932849957541316, "Avg loss": 0.47328896215185523, "Avg value loss": 0.1934795611887239, "Avg policy loss": 0.27980940346606076, "Total num played games": 76545, "Total num trained steps": 152576, "Timestamp in ms": 1699788555628, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923153197818542, "Avg loss": 0.6307778712362051, "Avg value loss": 0.3534269445517566, "Avg policy loss": 0.27735093352384865, "Total num played games": 76646, "Total num trained steps": 152704, "Timestamp in ms": 1699788614767, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 141.3880381770432, "Avg game time in secs": 0.8586937000945909, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.61, "agent_stopped_0": 0.42}, "Total num played games": 76672, "Total num trained steps": 152783, "Timestamp in ms": 1699788652305, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927373718934989, "Avg loss": 0.5679330327548087, "Avg value loss": 0.2825168854324147, "Avg policy loss": 0.2854161465074867, "Total num played games": 76694, "Total num trained steps": 152832, "Timestamp in ms": 1699788677457, "logtype": "training_step"}
{"Total num played games": 76694, "Total num trained steps": 152836, "Timestamp in ms": 1699788688038, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.75390625}
{"Ratio train steps to played games": 1.9931588960412812, "Avg loss": 0.48147094529122114, "Avg value loss": 0.20726565533550456, "Avg policy loss": 0.27420529001392424, "Total num played games": 76742, "Total num trained steps": 152960, "Timestamp in ms": 1699788751529, "logtype": "training_step"}
{"Avg objective": 20.8515625, "Games time in secs": 152.64083379134536, "Avg game time in secs": 0.9287423364585266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.68, "agent_stopped_0": 0.36}, "Total num played games": 76800, "Total num trained steps": 153070, "Timestamp in ms": 1699788804946, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922826652785008, "Avg loss": 0.5770479587372392, "Avg value loss": 0.30220089279464446, "Avg policy loss": 0.2748470649821684, "Total num played games": 76840, "Total num trained steps": 153088, "Timestamp in ms": 1699788813141, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927036728748309, "Avg loss": 0.65881989733316, "Avg value loss": 0.3793171533034183, "Avg policy loss": 0.27950274269096553, "Total num played games": 76888, "Total num trained steps": 153216, "Timestamp in ms": 1699788876008, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 96.54163345694542, "Avg game time in secs": 0.8775067899259739, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1015625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.64}, "Total num played games": 76928, "Total num trained steps": 153267, "Timestamp in ms": 1699788901488, "logtype": "played_game"}
{"Ratio train steps to played games": 1.993124155141936, "Avg loss": 0.4171220224816352, "Avg value loss": 0.1499446365633048, "Avg policy loss": 0.26717738376464695, "Total num played games": 76936, "Total num trained steps": 153344, "Timestamp in ms": 1699788938276, "logtype": "training_step"}
{"Total num played games": 76984, "Total num trained steps": 153438, "Timestamp in ms": 1699788993427, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.19140625}
{"Ratio train steps to played games": 1.9923148821269083, "Avg loss": 0.6183249964378774, "Avg value loss": 0.3575085478951223, "Avg policy loss": 0.26081645116209984, "Total num played games": 77032, "Total num trained steps": 153472, "Timestamp in ms": 1699789010707, "logtype": "training_step"}
{"Avg objective": 22.5859375, "Games time in secs": 149.83232341520488, "Avg game time in secs": 0.8398588499694597, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.52, "agent_stopped_0": 0.53}, "Total num played games": 77056, "Total num trained steps": 153554, "Timestamp in ms": 1699789051320, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99246335452069, "Avg loss": 0.48428286286070943, "Avg value loss": 0.23060595785500482, "Avg policy loss": 0.25367690820712596, "Total num played games": 77090, "Total num trained steps": 153600, "Timestamp in ms": 1699789072131, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992882885218699, "Avg loss": 0.4683330395491794, "Avg value loss": 0.21881681165541522, "Avg policy loss": 0.2495162304257974, "Total num played games": 77138, "Total num trained steps": 153728, "Timestamp in ms": 1699789135522, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 103.65348435565829, "Avg game time in secs": 0.924051254420192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.71, "agent_stopped_0": 0.3}, "Total num played games": 77184, "Total num trained steps": 153769, "Timestamp in ms": 1699789154974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932502461522517, "Avg loss": 0.54955895524472, "Avg value loss": 0.29110822931397706, "Avg policy loss": 0.25845073035452515, "Total num played games": 77188, "Total num trained steps": 153856, "Timestamp in ms": 1699789196365, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924305160188396, "Avg loss": 0.5957030293066055, "Avg value loss": 0.3301491761521902, "Avg policy loss": 0.2655538485851139, "Total num played games": 77284, "Total num trained steps": 153984, "Timestamp in ms": 1699789259753, "logtype": "training_step"}
{"Total num played games": 77284, "Total num trained steps": 154040, "Timestamp in ms": 1699789301545, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.19140625}
{"Avg objective": 21.09375, "Games time in secs": 148.34670788049698, "Avg game time in secs": 0.9441800375207094, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.68, "agent_stopped_0": 0.4}, "Total num played games": 77312, "Total num trained steps": 154043, "Timestamp in ms": 1699789303321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928490146381834, "Avg loss": 0.5324600390158594, "Avg value loss": 0.25372421569772996, "Avg policy loss": 0.27873581869062036, "Total num played games": 77332, "Total num trained steps": 154112, "Timestamp in ms": 1699789337692, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932669940553114, "Avg loss": 0.4805664801970124, "Avg value loss": 0.2055876326339785, "Avg policy loss": 0.2749788461951539, "Total num played games": 77380, "Total num trained steps": 154240, "Timestamp in ms": 1699789400591, "logtype": "training_step"}
{"Avg objective": 23.515625, "Games time in secs": 149.00891453959048, "Avg game time in secs": 0.9096512847027043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 77440, "Total num trained steps": 154346, "Timestamp in ms": 1699789452330, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9923206979775687, "Avg loss": 0.6025706513319165, "Avg value loss": 0.33437723547103815, "Avg policy loss": 0.2681934150168672, "Total num played games": 77481, "Total num trained steps": 154368, "Timestamp in ms": 1699789462765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927382011892325, "Avg loss": 0.5184749244945124, "Avg value loss": 0.2572630582144484, "Avg policy loss": 0.26121186441741884, "Total num played games": 77529, "Total num trained steps": 154496, "Timestamp in ms": 1699789521264, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 94.25363562069833, "Avg game time in secs": 0.9108462183212396, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 77568, "Total num trained steps": 154548, "Timestamp in ms": 1699789546584, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9931551877489462, "Avg loss": 0.4757632570108399, "Avg value loss": 0.22134827519766986, "Avg policy loss": 0.2544149778550491, "Total num played games": 77577, "Total num trained steps": 154624, "Timestamp in ms": 1699789584979, "logtype": "training_step"}
{"Total num played games": 77577, "Total num trained steps": 154640, "Timestamp in ms": 1699789601241, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.95703125}
{"Ratio train steps to played games": 1.9923396804552418, "Avg loss": 0.4790425952523947, "Avg value loss": 0.22836150688817725, "Avg policy loss": 0.2506810901686549, "Total num played games": 77673, "Total num trained steps": 154752, "Timestamp in ms": 1699789655645, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 150.1346714682877, "Avg game time in secs": 0.9150347265094751, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.69, "agent_stopped_0": 0.37}, "Total num played games": 77696, "Total num trained steps": 154837, "Timestamp in ms": 1699789696718, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925766776451215, "Avg loss": 0.5458479395601898, "Avg value loss": 0.2891341765935067, "Avg policy loss": 0.25671376334503293, "Total num played games": 77728, "Total num trained steps": 154880, "Timestamp in ms": 1699789717929, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992967072527868, "Avg loss": 0.437934284331277, "Avg value loss": 0.18526984917116351, "Avg policy loss": 0.2526644377503544, "Total num played games": 77777, "Total num trained steps": 155008, "Timestamp in ms": 1699789780632, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 101.72340602427721, "Avg game time in secs": 0.9358155991940293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.72, "agent_stopped_0": 0.31}, "Total num played games": 77824, "Total num trained steps": 155047, "Timestamp in ms": 1699789798442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99335697581785, "Avg loss": 0.47292921761982143, "Avg value loss": 0.2282761449168902, "Avg policy loss": 0.24465307081118226, "Total num played games": 77826, "Total num trained steps": 155136, "Timestamp in ms": 1699789838292, "logtype": "training_step"}
{"Total num played games": 77923, "Total num trained steps": 155241, "Timestamp in ms": 1699789898545, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.29296875}
{"Avg objective": 21.5625, "Games time in secs": 101.86733475327492, "Avg game time in secs": 0.9112878726737108, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 77952, "Total num trained steps": 155244, "Timestamp in ms": 1699789900309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991291634069077, "Avg loss": 0.6543457335792482, "Avg value loss": 0.40362765541067347, "Avg policy loss": 0.25071807811036706, "Total num played games": 77971, "Total num trained steps": 155264, "Timestamp in ms": 1699789910042, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929332700619462, "Avg loss": 0.4439943057950586, "Avg value loss": 0.1838766201690305, "Avg policy loss": 0.26011768518947065, "Total num played games": 77971, "Total num trained steps": 155392, "Timestamp in ms": 1699789971454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933477742601162, "Avg loss": 0.5367675051093102, "Avg value loss": 0.29131678788689896, "Avg policy loss": 0.24545071658212692, "Total num played games": 78019, "Total num trained steps": 155520, "Timestamp in ms": 1699790032442, "logtype": "training_step"}
{"Avg objective": 21.3671875, "Games time in secs": 182.18618662841618, "Avg game time in secs": 0.8721030218875967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1171875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 78080, "Total num trained steps": 155624, "Timestamp in ms": 1699790082496, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9925366446905204, "Avg loss": 0.5663729392690584, "Avg value loss": 0.31211051222635433, "Avg policy loss": 0.2542624258203432, "Total num played games": 78115, "Total num trained steps": 155648, "Timestamp in ms": 1699790093838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929251317742183, "Avg loss": 0.451936739962548, "Avg value loss": 0.1894135386974085, "Avg policy loss": 0.2625232025748119, "Total num played games": 78164, "Total num trained steps": 155776, "Timestamp in ms": 1699790158965, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 98.32545028626919, "Avg game time in secs": 0.9629688962741056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.29, "agent_stopped_more": 0.71, "played_steps": 0.74}, "Total num played games": 78208, "Total num trained steps": 155819, "Timestamp in ms": 1699790180821, "logtype": "played_game"}
{"Total num played games": 78212, "Total num trained steps": 155842, "Timestamp in ms": 1699790205525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.9375}
{"Ratio train steps to played games": 1.9921160235113724, "Avg loss": 0.6239754031412303, "Avg value loss": 0.3534622750012204, "Avg policy loss": 0.2705131337279454, "Total num played games": 78260, "Total num trained steps": 155904, "Timestamp in ms": 1699790241002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925040544509571, "Avg loss": 0.41382893780246377, "Avg value loss": 0.14924107407568954, "Avg policy loss": 0.2645878641633317, "Total num played games": 78309, "Total num trained steps": 156032, "Timestamp in ms": 1699790307952, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 163.9874730296433, "Avg game time in secs": 0.8983701262768591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.68, "agent_stopped_0": 0.35}, "Total num played games": 78336, "Total num trained steps": 156109, "Timestamp in ms": 1699790344809, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9929170335770894, "Avg loss": 0.4953983447048813, "Avg value loss": 0.23456130691920407, "Avg policy loss": 0.26083704142365605, "Total num played games": 78357, "Total num trained steps": 156160, "Timestamp in ms": 1699790370433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9933295070467445, "Avg loss": 0.44023542560171336, "Avg value loss": 0.17063694386160932, "Avg policy loss": 0.2695984812453389, "Total num played games": 78405, "Total num trained steps": 156288, "Timestamp in ms": 1699790432772, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 141.7655850686133, "Avg game time in secs": 0.9463831527682487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 78464, "Total num trained steps": 156396, "Timestamp in ms": 1699790486575, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924970064456957, "Avg loss": 0.735003718174994, "Avg value loss": 0.4529503559751902, "Avg policy loss": 0.28205337014514953, "Total num played games": 78502, "Total num trained steps": 156416, "Timestamp in ms": 1699790496248, "logtype": "training_step"}
{"Total num played games": 78502, "Total num trained steps": 156442, "Timestamp in ms": 1699790520547, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.43359375}
{"Ratio train steps to played games": 1.9929089751750477, "Avg loss": 0.5711514849681407, "Avg value loss": 0.2861808197631035, "Avg policy loss": 0.28497067012358457, "Total num played games": 78550, "Total num trained steps": 156544, "Timestamp in ms": 1699790569497, "logtype": "training_step"}
{"Avg objective": 20.3046875, "Games time in secs": 106.73444030247629, "Avg game time in secs": 0.8702591309265699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 78592, "Total num trained steps": 156591, "Timestamp in ms": 1699790593309, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9933204407236826, "Avg loss": 0.4658161500701681, "Avg value loss": 0.18837336503202096, "Avg policy loss": 0.27744278812315315, "Total num played games": 78598, "Total num trained steps": 156672, "Timestamp in ms": 1699790632638, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924899930109918, "Avg loss": 0.4856804598821327, "Avg value loss": 0.21549404732650146, "Avg policy loss": 0.27018641377799213, "Total num played games": 78695, "Total num trained steps": 156800, "Timestamp in ms": 1699790695512, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 140.53137407265604, "Avg game time in secs": 0.9243443854211364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.64, "agent_stopped_0": 0.42}, "Total num played games": 78720, "Total num trained steps": 156881, "Timestamp in ms": 1699790733841, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992913655817025, "Avg loss": 0.4628089894540608, "Avg value loss": 0.18869191355770454, "Avg policy loss": 0.27411707339342684, "Total num played games": 78743, "Total num trained steps": 156928, "Timestamp in ms": 1699790755673, "logtype": "training_step"}
{"Total num played games": 78792, "Total num trained steps": 157044, "Timestamp in ms": 1699790826651, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.54296875}
{"Ratio train steps to played games": 1.9920725520040587, "Avg loss": 0.5937033970840275, "Avg value loss": 0.3205950567498803, "Avg policy loss": 0.2731083470862359, "Total num played games": 78840, "Total num trained steps": 157056, "Timestamp in ms": 1699790833438, "logtype": "training_step"}
{"Avg objective": 22.859375, "Games time in secs": 156.97190031223, "Avg game time in secs": 0.89440508215921, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.64, "agent_stopped_0": 0.38}, "Total num played games": 78848, "Total num trained steps": 157170, "Timestamp in ms": 1699790890813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992470433140235, "Avg loss": 0.6072532278485596, "Avg value loss": 0.34269944491097704, "Avg policy loss": 0.26455377880483866, "Total num played games": 78889, "Total num trained steps": 157184, "Timestamp in ms": 1699790898404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928677299618682, "Avg loss": 0.8203616691753268, "Avg value loss": 0.5407645769591909, "Avg policy loss": 0.2795970857841894, "Total num played games": 78937, "Total num trained steps": 157312, "Timestamp in ms": 1699790968174, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 105.67932325974107, "Avg game time in secs": 0.9325397627981147, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "agent_stopped_more": 0.7, "played_steps": 0.76}, "Total num played games": 78976, "Total num trained steps": 157365, "Timestamp in ms": 1699790996492, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932772045325062, "Avg loss": 0.5369184729643166, "Avg value loss": 0.2605893414875027, "Avg policy loss": 0.2763291298178956, "Total num played games": 78985, "Total num trained steps": 157440, "Timestamp in ms": 1699791034138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924760688408087, "Avg loss": 0.5057360010687262, "Avg value loss": 0.23471067060017958, "Avg policy loss": 0.27102532947901636, "Total num played games": 79081, "Total num trained steps": 157568, "Timestamp in ms": 1699791095524, "logtype": "training_step"}
{"Total num played games": 79081, "Total num trained steps": 157646, "Timestamp in ms": 1699791146513, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.81640625}
{"Avg objective": 21.109375, "Games time in secs": 151.76073116064072, "Avg game time in secs": 0.917657889687689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.7, "agent_stopped_0": 0.34}, "Total num played games": 79104, "Total num trained steps": 157649, "Timestamp in ms": 1699791148253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928850358275727, "Avg loss": 0.6701817065477371, "Avg value loss": 0.3928080871410202, "Avg policy loss": 0.2773736154194921, "Total num played games": 79129, "Total num trained steps": 157696, "Timestamp in ms": 1699791172705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932935069527766, "Avg loss": 0.4694290178595111, "Avg value loss": 0.18810048417071812, "Avg policy loss": 0.2813285293523222, "Total num played games": 79177, "Total num trained steps": 157824, "Timestamp in ms": 1699791237280, "logtype": "training_step"}
{"Avg objective": 22.546875, "Games time in secs": 149.99516548216343, "Avg game time in secs": 0.9534095822746167, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.67}, "Total num played games": 79232, "Total num trained steps": 157946, "Timestamp in ms": 1699791298249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992418890963217, "Avg loss": 0.5042577858548611, "Avg value loss": 0.22450370856677182, "Avg policy loss": 0.27975407626945525, "Total num played games": 79276, "Total num trained steps": 157952, "Timestamp in ms": 1699791300886, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928268871968131, "Avg loss": 0.529200597666204, "Avg value loss": 0.24478771034046076, "Avg policy loss": 0.2844128884607926, "Total num played games": 79324, "Total num trained steps": 158080, "Timestamp in ms": 1699791362283, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 92.28734580986202, "Avg game time in secs": 0.8843298963474808, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.6}, "Total num played games": 79360, "Total num trained steps": 158139, "Timestamp in ms": 1699791390536, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932092777140842, "Avg loss": 0.5180858573876321, "Avg value loss": 0.2362313177145552, "Avg policy loss": 0.28185453941114247, "Total num played games": 79373, "Total num trained steps": 158208, "Timestamp in ms": 1699791423022, "logtype": "training_step"}
{"Total num played games": 79421, "Total num trained steps": 158247, "Timestamp in ms": 1699791456059, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.5703125}
{"Ratio train steps to played games": 1.9924121355497113, "Avg loss": 0.8643181922379881, "Avg value loss": 0.5730637547385413, "Avg policy loss": 0.2912544432329014, "Total num played games": 79469, "Total num trained steps": 158336, "Timestamp in ms": 1699791502209, "logtype": "training_step"}
{"Avg objective": 23.9453125, "Games time in secs": 158.58635256625712, "Avg game time in secs": 0.894046431989409, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 79488, "Total num trained steps": 158428, "Timestamp in ms": 1699791549123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992831721518669, "Avg loss": 0.7225729065248743, "Avg value loss": 0.4491934410179965, "Avg policy loss": 0.2733794666128233, "Total num played games": 79517, "Total num trained steps": 158464, "Timestamp in ms": 1699791566044, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993225664550996, "Avg loss": 0.5001495943870395, "Avg value loss": 0.2143786187225487, "Avg policy loss": 0.28577097319066525, "Total num played games": 79565, "Total num trained steps": 158592, "Timestamp in ms": 1699791629484, "logtype": "training_step"}
{"Avg objective": 20.6640625, "Games time in secs": 142.03041616268456, "Avg game time in secs": 0.9446177215577336, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.27, "agent_stopped_more": 0.73, "played_steps": 0.77}, "Total num played games": 79616, "Total num trained steps": 158716, "Timestamp in ms": 1699791691153, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924554356013056, "Avg loss": 0.4774980291258544, "Avg value loss": 0.2001082786882762, "Avg policy loss": 0.27738975128158927, "Total num played games": 79660, "Total num trained steps": 158720, "Timestamp in ms": 1699791692877, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928364425598113, "Avg loss": 0.6625206841854379, "Avg value loss": 0.3944656187959481, "Avg policy loss": 0.2680550654185936, "Total num played games": 79709, "Total num trained steps": 158848, "Timestamp in ms": 1699791755737, "logtype": "training_step"}
{"Total num played games": 79709, "Total num trained steps": 158848, "Timestamp in ms": 1699791767747, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.28515625}
{"Avg objective": 21.421875, "Games time in secs": 78.50286193192005, "Avg game time in secs": 0.8513781252113404, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.57}, "Total num played games": 79744, "Total num trained steps": 158851, "Timestamp in ms": 1699791769656, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9932419724914427, "Avg loss": 0.48070993390865624, "Avg value loss": 0.2113223896594718, "Avg policy loss": 0.2693875435506925, "Total num played games": 79757, "Total num trained steps": 158976, "Timestamp in ms": 1699791829355, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923238748779082, "Avg loss": 0.45051699108444154, "Avg value loss": 0.1860599069914315, "Avg policy loss": 0.2644570751581341, "Total num played games": 79858, "Total num trained steps": 159104, "Timestamp in ms": 1699791891925, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 172.31266992166638, "Avg game time in secs": 0.9090804685256444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 79872, "Total num trained steps": 159208, "Timestamp in ms": 1699791941969, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9927040184214149, "Avg loss": 0.6229072539135814, "Avg value loss": 0.35760889112134464, "Avg policy loss": 0.2652983656153083, "Total num played games": 79907, "Total num trained steps": 159232, "Timestamp in ms": 1699791953811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931086236007753, "Avg loss": 0.5557194012217224, "Avg value loss": 0.29208587497123517, "Avg policy loss": 0.26363352790940553, "Total num played games": 79955, "Total num trained steps": 159360, "Timestamp in ms": 1699792017927, "logtype": "training_step"}
{"Avg objective": 22.625, "Games time in secs": 98.41564051620662, "Avg game time in secs": 0.8774257409095298, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.67}, "Total num played games": 80000, "Total num trained steps": 159402, "Timestamp in ms": 1699792040385, "logtype": "played_game"}
{"Total num played games": 80003, "Total num trained steps": 159405, "Timestamp in ms": 1699792051881, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3125}
{"Total num played games": 80014, "Total num trained steps": 159405, "Timestamp in ms": 1699792062808, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.34375}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1699868416839, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4921875}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1699868544987, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 0.17578125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702307661081, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.03125}
{"Total num played games": 0, "Total num trained steps": 0, "Timestamp in ms": 1702308576112, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.03125}
