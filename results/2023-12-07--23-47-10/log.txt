{"Avg objective": 16.390625, "Games time in secs": 290.186730902642, "Avg game time in secs": 122.21541480181622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.09, "agent_stopped_more": 0.63, "played_steps": 11.59, "reached_maximum_moves": 0.28}, "Total num played games": 128, "Total num trained steps": 0, "Timestamp in ms": 1701993127239, "logtype": "played_game"}
{"Avg objective": 15.9453125, "Games time in secs": 252.7473110407591, "Avg game time in secs": 135.9492707659956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.1015625, "Avg reasons for ending game": {"reached_maximum_moves": 0.4, "played_steps": 13.02, "agent_stopped_more": 0.46, "agent_stopped_0": 0.14}, "Total num played games": 256, "Total num trained steps": 0, "Timestamp in ms": 1701993379986, "logtype": "played_game"}
{"Ratio train steps to played games": 0.4413793103448276, "Avg loss": 58.04263036698103, "Avg value loss": 57.49857544898987, "Avg policy loss": 0.5440556996036321, "Total num played games": 290, "Total num trained steps": 128, "Timestamp in ms": 1701993461937, "logtype": "training_step"}
{"Ratio train steps to played games": 0.7710843373493976, "Avg loss": 10.859809521585703, "Avg value loss": 10.341571275144815, "Avg policy loss": 0.518238308141008, "Total num played games": 332, "Total num trained steps": 256, "Timestamp in ms": 1701993540100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.0666666666666667, "Avg loss": 6.328359456732869, "Avg value loss": 5.832888757809997, "Avg policy loss": 0.4954706630669534, "Total num played games": 360, "Total num trained steps": 384, "Timestamp in ms": 1701993612163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.3544973544973544, "Avg loss": 4.556742778047919, "Avg value loss": 4.074480624869466, "Avg policy loss": 0.4822621806524694, "Total num played games": 378, "Total num trained steps": 512, "Timestamp in ms": 1701993670693, "logtype": "training_step"}
{"Avg objective": 15.15625, "Games time in secs": 310.60773815587163, "Avg game time in secs": 161.55986802701955, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 4.03125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 14.59, "reached_maximum_moves": 0.55, "agent_stopped_0": 0.12}, "Total num played games": 384, "Total num trained steps": 552, "Timestamp in ms": 1701993690594, "logtype": "played_game"}
{"Total num played games": 490, "Total num trained steps": 602, "Timestamp in ms": 1701994075581, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.43359375}
{"Ratio train steps to played games": 1.3061224489795917, "Avg loss": 3.985103975981474, "Avg value loss": 3.5262985806912184, "Avg policy loss": 0.45880540274083614, "Total num played games": 490, "Total num trained steps": 640, "Timestamp in ms": 1701994093274, "logtype": "training_step"}
{"Ratio train steps to played games": 1.5298804780876494, "Avg loss": 4.160625567659736, "Avg value loss": 3.723747296258807, "Avg policy loss": 0.43687825347296894, "Total num played games": 502, "Total num trained steps": 768, "Timestamp in ms": 1701994152896, "logtype": "training_step"}
{"Avg objective": 15.734375, "Games time in secs": 505.16862192749977, "Avg game time in secs": 199.3382288418361, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"reached_maximum_moves": 0.6, "played_steps": 15.62, "agent_stopped_more": 0.37, "agent_stopped_0": 0.03}, "Total num played games": 512, "Total num trained steps": 859, "Timestamp in ms": 1701994195763, "logtype": "played_game"}
{"Ratio train steps to played games": 1.7364341085271318, "Avg loss": 2.9608519207686186, "Avg value loss": 2.530610633082688, "Avg policy loss": 0.43024128628894687, "Total num played games": 516, "Total num trained steps": 896, "Timestamp in ms": 1701994213041, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9176029962546817, "Avg loss": 2.912701031193137, "Avg value loss": 2.46303416416049, "Avg policy loss": 0.44966687844134867, "Total num played games": 534, "Total num trained steps": 1024, "Timestamp in ms": 1701994273119, "logtype": "training_step"}
{"Ratio train steps to played games": 2.07942238267148, "Avg loss": 3.123469954356551, "Avg value loss": 2.683119914494455, "Avg policy loss": 0.4403500377666205, "Total num played games": 554, "Total num trained steps": 1152, "Timestamp in ms": 1701994333389, "logtype": "training_step"}
{"Avg objective": 13.6796875, "Games time in secs": 361.6436144262552, "Avg game time in secs": 193.2615760236804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"reached_maximum_moves": 0.7, "played_steps": 16.23, "agent_stopped_0": 0.09, "agent_stopped_more": 0.21}, "Total num played games": 640, "Total num trained steps": 1204, "Timestamp in ms": 1701994557407, "logtype": "played_game"}
{"Total num played games": 644, "Total num trained steps": 1204, "Timestamp in ms": 1701994573559, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.59375}
{"Ratio train steps to played games": 1.9571865443425076, "Avg loss": 3.5411465084180236, "Avg value loss": 3.1223000762984157, "Avg policy loss": 0.4188464479520917, "Total num played games": 654, "Total num trained steps": 1280, "Timestamp in ms": 1701994609649, "logtype": "training_step"}
{"Ratio train steps to played games": 2.1, "Avg loss": 2.3649169970303774, "Avg value loss": 1.9385499032214284, "Avg policy loss": 0.42636708775535226, "Total num played games": 670, "Total num trained steps": 1408, "Timestamp in ms": 1701994668334, "logtype": "training_step"}
{"Ratio train steps to played games": 2.213256484149856, "Avg loss": 1.9140535686165094, "Avg value loss": 1.4972866224125028, "Avg policy loss": 0.416766966227442, "Total num played games": 694, "Total num trained steps": 1536, "Timestamp in ms": 1701994727072, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3047091412742384, "Avg loss": 1.837709292769432, "Avg value loss": 1.4238457647152245, "Avg policy loss": 0.41386354295536876, "Total num played games": 722, "Total num trained steps": 1664, "Timestamp in ms": 1701994786650, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4281842818428183, "Avg loss": 1.5055396119132638, "Avg value loss": 1.0814766376279294, "Avg policy loss": 0.4240629756823182, "Total num played games": 738, "Total num trained steps": 1792, "Timestamp in ms": 1701994847656, "logtype": "training_step"}
{"Avg objective": 15.015625, "Games time in secs": 337.71181973814964, "Avg game time in secs": 138.28657343430677, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"reached_maximum_moves": 0.47, "played_steps": 12.39, "agent_stopped_more": 0.34, "agent_stopped_0": 0.19}, "Total num played games": 768, "Total num trained steps": 1806, "Timestamp in ms": 1701994895119, "logtype": "played_game"}
{"Total num played games": 836, "Total num trained steps": 1806, "Timestamp in ms": 1701995261548, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.76171875}
{"Ratio train steps to played games": 2.2857142857142856, "Avg loss": 1.9336444502696395, "Avg value loss": 1.5350824808701873, "Avg policy loss": 0.3985619710292667, "Total num played games": 840, "Total num trained steps": 1920, "Timestamp in ms": 1701995316370, "logtype": "training_step"}
{"Ratio train steps to played games": 2.42080378250591, "Avg loss": 1.5361016392707825, "Avg value loss": 1.1367132500745356, "Avg policy loss": 0.39938839292153716, "Total num played games": 846, "Total num trained steps": 2048, "Timestamp in ms": 1701995376339, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5185185185185186, "Avg loss": 1.4429306536912918, "Avg value loss": 1.0425055106170475, "Avg policy loss": 0.4004251533187926, "Total num played games": 864, "Total num trained steps": 2176, "Timestamp in ms": 1701995435655, "logtype": "training_step"}
{"Ratio train steps to played games": 2.618181818181818, "Avg loss": 1.4472006587311625, "Avg value loss": 1.0483705694787204, "Avg policy loss": 0.398830093909055, "Total num played games": 880, "Total num trained steps": 2304, "Timestamp in ms": 1701995496805, "logtype": "training_step"}
{"Avg objective": 15.140625, "Games time in secs": 633.8608189560473, "Avg game time in secs": 176.9949410884292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 15.34, "reached_maximum_moves": 0.61, "agent_stopped_0": 0.1}, "Total num played games": 896, "Total num trained steps": 2372, "Timestamp in ms": 1701995528980, "logtype": "played_game"}
{"Total num played games": 996, "Total num trained steps": 2409, "Timestamp in ms": 1701995858459, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0625}
{"Ratio train steps to played games": 2.4417670682730925, "Avg loss": 1.6720045870169997, "Avg value loss": 1.271053722128272, "Avg policy loss": 0.40095088235102594, "Total num played games": 996, "Total num trained steps": 2432, "Timestamp in ms": 1701995870060, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5548902195608783, "Avg loss": 1.6986412536352873, "Avg value loss": 1.3078784551471472, "Avg policy loss": 0.39076279709115624, "Total num played games": 1002, "Total num trained steps": 2560, "Timestamp in ms": 1701995929600, "logtype": "training_step"}
{"Ratio train steps to played games": 2.656126482213439, "Avg loss": 1.1919976808130741, "Avg value loss": 0.8019149373285472, "Avg policy loss": 0.3900827565230429, "Total num played games": 1012, "Total num trained steps": 2688, "Timestamp in ms": 1701995987678, "logtype": "training_step"}
{"Avg objective": 14.6015625, "Games time in secs": 472.11426469683647, "Avg game time in secs": 199.25311418567435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9765625, "Avg reasons for ending game": {"reached_maximum_moves": 0.6, "played_steps": 15.86, "agent_stopped_more": 0.33, "agent_stopped_0": 0.07}, "Total num played games": 1024, "Total num trained steps": 2717, "Timestamp in ms": 1701996001095, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7024952015355086, "Avg loss": 1.5896893059834838, "Avg value loss": 1.1958978958427906, "Avg policy loss": 0.39379140944220126, "Total num played games": 1042, "Total num trained steps": 2816, "Timestamp in ms": 1701996047193, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7773584905660376, "Avg loss": 1.3329404704272747, "Avg value loss": 0.9444963689893484, "Avg policy loss": 0.3884441021364182, "Total num played games": 1060, "Total num trained steps": 2944, "Timestamp in ms": 1701996106893, "logtype": "training_step"}
{"Avg objective": 15.078125, "Games time in secs": 323.6879681907594, "Avg game time in secs": 190.79304155314458, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 15.5, "reached_maximum_moves": 0.59, "agent_stopped_0": 0.04}, "Total num played games": 1152, "Total num trained steps": 3009, "Timestamp in ms": 1701996324783, "logtype": "played_game"}
{"Total num played games": 1168, "Total num trained steps": 3009, "Timestamp in ms": 1701996487553, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.6171875}
{"Ratio train steps to played games": 2.607809847198642, "Avg loss": 1.9896648488938808, "Avg value loss": 1.602778120432049, "Avg policy loss": 0.3868867235723883, "Total num played games": 1178, "Total num trained steps": 3072, "Timestamp in ms": 1701996517893, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6936026936026938, "Avg loss": 1.4724309872835875, "Avg value loss": 1.0870810891501606, "Avg policy loss": 0.3853499067481607, "Total num played games": 1188, "Total num trained steps": 3200, "Timestamp in ms": 1701996578785, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7872696817420435, "Avg loss": 1.2195354951545596, "Avg value loss": 0.8323100074194372, "Avg policy loss": 0.3872254884336144, "Total num played games": 1194, "Total num trained steps": 3328, "Timestamp in ms": 1701996639748, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8327868852459015, "Avg loss": 1.1452455027028918, "Avg value loss": 0.7604734916239977, "Avg policy loss": 0.38477200525812805, "Total num played games": 1220, "Total num trained steps": 3456, "Timestamp in ms": 1701996700645, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8535031847133756, "Avg loss": 1.2317179781384766, "Avg value loss": 0.8500689978245646, "Avg policy loss": 0.3816489824093878, "Total num played games": 1256, "Total num trained steps": 3584, "Timestamp in ms": 1701996760144, "logtype": "training_step"}
{"Avg objective": 15.3203125, "Games time in secs": 484.4462419115007, "Avg game time in secs": 151.47072764096083, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.29, "played_steps": 13.14, "reached_maximum_moves": 0.5, "agent_stopped_0": 0.21}, "Total num played games": 1280, "Total num trained steps": 3609, "Timestamp in ms": 1701996809229, "logtype": "played_game"}
{"Total num played games": 1346, "Total num trained steps": 3609, "Timestamp in ms": 1701997065221, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.796875}
{"Ratio train steps to played games": 2.717423133235725, "Avg loss": 1.7958578667603433, "Avg value loss": 1.419570378959179, "Avg policy loss": 0.3762874808162451, "Total num played games": 1366, "Total num trained steps": 3712, "Timestamp in ms": 1701997114267, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7947598253275108, "Avg loss": 1.6634368761442602, "Avg value loss": 1.2833172897808254, "Avg policy loss": 0.3801195719279349, "Total num played games": 1374, "Total num trained steps": 3840, "Timestamp in ms": 1701997173721, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8254985754985755, "Avg loss": 1.2861066511832178, "Avg value loss": 0.9050651686266065, "Avg policy loss": 0.38104147417470813, "Total num played games": 1404, "Total num trained steps": 3968, "Timestamp in ms": 1701997231294, "logtype": "training_step"}
{"Avg objective": 16.2578125, "Games time in secs": 427.1921002715826, "Avg game time in secs": 157.4909975005139, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_more": 0.24, "played_steps": 13.23, "reached_maximum_moves": 0.54, "agent_stopped_0": 0.22}, "Total num played games": 1408, "Total num trained steps": 3979, "Timestamp in ms": 1701997236422, "logtype": "played_game"}
{"Ratio train steps to played games": 2.852367688022284, "Avg loss": 1.4316194294951856, "Avg value loss": 1.0516809616237879, "Avg policy loss": 0.3799384750891477, "Total num played games": 1436, "Total num trained steps": 4096, "Timestamp in ms": 1701997291554, "logtype": "training_step"}
{"Avg objective": 16.328125, "Games time in secs": 236.62734619528055, "Avg game time in secs": 152.84355850249995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 13.38, "agent_stopped_0": 0.17, "reached_maximum_moves": 0.45}, "Total num played games": 1536, "Total num trained steps": 4210, "Timestamp in ms": 1701997473049, "logtype": "played_game"}
{"Total num played games": 1550, "Total num trained steps": 4210, "Timestamp in ms": 1701997565322, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.546875}
{"Ratio train steps to played games": 2.718146718146718, "Avg loss": 1.599059577099979, "Avg value loss": 1.2134643974713981, "Avg policy loss": 0.3855951887089759, "Total num played games": 1554, "Total num trained steps": 4224, "Timestamp in ms": 1701997572736, "logtype": "training_step"}
{"Ratio train steps to played games": 2.764930114358323, "Avg loss": 2.1048720963299274, "Avg value loss": 1.727769353426993, "Avg policy loss": 0.37710275035351515, "Total num played games": 1574, "Total num trained steps": 4352, "Timestamp in ms": 1701997632321, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8247162673392183, "Avg loss": 1.237442194018513, "Avg value loss": 0.863817339297384, "Avg policy loss": 0.3736248512286693, "Total num played games": 1586, "Total num trained steps": 4480, "Timestamp in ms": 1701997692631, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8550185873605947, "Avg loss": 1.3766378476284444, "Avg value loss": 1.0072829057462513, "Avg policy loss": 0.3693549414165318, "Total num played games": 1614, "Total num trained steps": 4608, "Timestamp in ms": 1701997752780, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8737864077669903, "Avg loss": 1.2961413864977658, "Avg value loss": 0.9288427303545177, "Avg policy loss": 0.3672986493911594, "Total num played games": 1648, "Total num trained steps": 4736, "Timestamp in ms": 1701997813953, "logtype": "training_step"}
{"Avg objective": 17.09375, "Games time in secs": 390.4852069541812, "Avg game time in secs": 118.85509490795084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"reached_maximum_moves": 0.39, "played_steps": 11.58, "agent_stopped_more": 0.41, "agent_stopped_0": 0.2}, "Total num played games": 1664, "Total num trained steps": 4815, "Timestamp in ms": 1701997863534, "logtype": "played_game"}
{"Total num played games": 1744, "Total num trained steps": 4815, "Timestamp in ms": 1701998113528, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.28125}
{"Ratio train steps to played games": 2.782608695652174, "Avg loss": 1.5976910390891135, "Avg value loss": 1.2404067451134324, "Avg policy loss": 0.357284297933802, "Total num played games": 1748, "Total num trained steps": 4864, "Timestamp in ms": 1701998136565, "logtype": "training_step"}
{"Ratio train steps to played games": 2.833144154370034, "Avg loss": 1.387280528433621, "Avg value loss": 1.0341217792592943, "Avg policy loss": 0.35315873217768967, "Total num played games": 1762, "Total num trained steps": 4992, "Timestamp in ms": 1701998198841, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8635346756152127, "Avg loss": 1.2264329995959997, "Avg value loss": 0.8737494857050478, "Avg policy loss": 0.3526835087686777, "Total num played games": 1788, "Total num trained steps": 5120, "Timestamp in ms": 1701998259813, "logtype": "training_step"}
{"Avg objective": 15.4453125, "Games time in secs": 399.4764910675585, "Avg game time in secs": 175.35523391418974, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 14.18, "reached_maximum_moves": 0.58, "agent_stopped_0": 0.14}, "Total num played games": 1792, "Total num trained steps": 5126, "Timestamp in ms": 1701998263011, "logtype": "played_game"}
{"Ratio train steps to played games": 2.909090909090909, "Avg loss": 1.147516479715705, "Avg value loss": 0.789179652929306, "Avg policy loss": 0.3583368237596005, "Total num played games": 1804, "Total num trained steps": 5248, "Timestamp in ms": 1701998319339, "logtype": "training_step"}
{"Ratio train steps to played games": 2.931297709923664, "Avg loss": 1.0477469717152417, "Avg value loss": 0.6942910053767264, "Avg policy loss": 0.35345596075057983, "Total num played games": 1834, "Total num trained steps": 5376, "Timestamp in ms": 1701998379785, "logtype": "training_step"}
{"Avg objective": 16.0390625, "Games time in secs": 245.99772930890322, "Avg game time in secs": 168.92510496321484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.27, "played_steps": 14.7, "reached_maximum_moves": 0.6, "agent_stopped_0": 0.12}, "Total num played games": 1920, "Total num trained steps": 5418, "Timestamp in ms": 1701998509009, "logtype": "played_game"}
{"Total num played games": 1938, "Total num trained steps": 5418, "Timestamp in ms": 1701998650778, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.03125}
{"Ratio train steps to played games": 2.8053007135575942, "Avg loss": 1.8339947424829006, "Avg value loss": 1.4726963355205953, "Avg policy loss": 0.361298416974023, "Total num played games": 1962, "Total num trained steps": 5504, "Timestamp in ms": 1701998692605, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8468149646107177, "Avg loss": 1.279819046612829, "Avg value loss": 0.9114188370294869, "Avg policy loss": 0.36840021796524525, "Total num played games": 1978, "Total num trained steps": 5632, "Timestamp in ms": 1701998751497, "logtype": "training_step"}
{"Ratio train steps to played games": 2.877122877122877, "Avg loss": 1.037265752442181, "Avg value loss": 0.6691771023906767, "Avg policy loss": 0.36808865307830274, "Total num played games": 2002, "Total num trained steps": 5760, "Timestamp in ms": 1701998812229, "logtype": "training_step"}
{"Ratio train steps to played games": 2.88578431372549, "Avg loss": 1.0647794413380325, "Avg value loss": 0.703087295871228, "Avg policy loss": 0.36169214616529644, "Total num played games": 2040, "Total num trained steps": 5888, "Timestamp in ms": 1701998872972, "logtype": "training_step"}
{"Avg objective": 16.546875, "Games time in secs": 370.46349116414785, "Avg game time in secs": 87.35413979398436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "reached_maximum_moves": 0.35, "played_steps": 9.3, "agent_stopped_more": 0.33}, "Total num played games": 2048, "Total num trained steps": 5901, "Timestamp in ms": 1701998879473, "logtype": "played_game"}
{"Ratio train steps to played games": 2.9006750241080037, "Avg loss": 1.2268998781219125, "Avg value loss": 0.864446910796687, "Avg policy loss": 0.36245296709239483, "Total num played games": 2074, "Total num trained steps": 6016, "Timestamp in ms": 1701998933917, "logtype": "training_step"}
{"Total num played games": 2160, "Total num trained steps": 6019, "Timestamp in ms": 1701999154946, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.76171875}
{"Avg objective": 16.015625, "Games time in secs": 293.24193105474114, "Avg game time in secs": 170.03661757646478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"reached_maximum_moves": 0.53, "played_steps": 13.62, "agent_stopped_0": 0.21, "agent_stopped_more": 0.26}, "Total num played games": 2176, "Total num trained steps": 6055, "Timestamp in ms": 1701999172715, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8106129917657823, "Avg loss": 1.5290958872064948, "Avg value loss": 1.1612764839082956, "Avg policy loss": 0.36781941214576364, "Total num played games": 2186, "Total num trained steps": 6144, "Timestamp in ms": 1701999214357, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8354430379746836, "Avg loss": 1.1449612234719098, "Avg value loss": 0.7784510040655732, "Avg policy loss": 0.3665102187078446, "Total num played games": 2212, "Total num trained steps": 6272, "Timestamp in ms": 1701999274690, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8596961572832886, "Avg loss": 1.1291556237265468, "Avg value loss": 0.764719127677381, "Avg policy loss": 0.36443649837747216, "Total num played games": 2238, "Total num trained steps": 6400, "Timestamp in ms": 1701999333605, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8481675392670156, "Avg loss": 1.3264621305279434, "Avg value loss": 0.9558567036874592, "Avg policy loss": 0.37060541613027453, "Total num played games": 2292, "Total num trained steps": 6528, "Timestamp in ms": 1701999393784, "logtype": "training_step"}
{"Avg objective": 17.2578125, "Games time in secs": 256.6075806133449, "Avg game time in secs": 92.72126353086787, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 9.82, "agent_stopped_0": 0.21, "reached_maximum_moves": 0.35}, "Total num played games": 2304, "Total num trained steps": 6602, "Timestamp in ms": 1701999429323, "logtype": "played_game"}
{"Total num played games": 2380, "Total num trained steps": 6619, "Timestamp in ms": 1701999649865, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.12109375}
{"Ratio train steps to played games": 2.7872696817420435, "Avg loss": 1.292919839732349, "Avg value loss": 0.9186780420131981, "Avg policy loss": 0.3742418026085943, "Total num played games": 2388, "Total num trained steps": 6656, "Timestamp in ms": 1701999667674, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8149377593361, "Avg loss": 1.2112433528527617, "Avg value loss": 0.8368654581718147, "Avg policy loss": 0.3743778867647052, "Total num played games": 2410, "Total num trained steps": 6784, "Timestamp in ms": 1701999727775, "logtype": "training_step"}
{"Avg objective": 15.90625, "Games time in secs": 338.5088919438422, "Avg game time in secs": 151.65697731272667, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 13.13, "agent_stopped_0": 0.16, "reached_maximum_moves": 0.48}, "Total num played games": 2432, "Total num trained steps": 6870, "Timestamp in ms": 1701999767832, "logtype": "played_game"}
{"Ratio train steps to played games": 2.832377049180328, "Avg loss": 1.0954852579161525, "Avg value loss": 0.7262203400023282, "Avg policy loss": 0.36926492280326784, "Total num played games": 2440, "Total num trained steps": 6912, "Timestamp in ms": 1701999787342, "logtype": "training_step"}
{"Ratio train steps to played games": 2.836422240128928, "Avg loss": 1.0580100300721824, "Avg value loss": 0.677703466732055, "Avg policy loss": 0.38030656706541777, "Total num played games": 2482, "Total num trained steps": 7040, "Timestamp in ms": 1701999847687, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8535031847133756, "Avg loss": 0.9644062197767198, "Avg value loss": 0.5848887409083545, "Avg policy loss": 0.379517478402704, "Total num played games": 2512, "Total num trained steps": 7168, "Timestamp in ms": 1701999909029, "logtype": "training_step"}
{"Avg objective": 16.640625, "Games time in secs": 234.6263053305447, "Avg game time in secs": 99.97946924250573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "reached_maximum_moves": 0.39, "played_steps": 10.62, "agent_stopped_more": 0.37}, "Total num played games": 2560, "Total num trained steps": 7223, "Timestamp in ms": 1702000002458, "logtype": "played_game"}
{"Total num played games": 2606, "Total num trained steps": 7223, "Timestamp in ms": 1702000127109, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.0859375}
{"Ratio train steps to played games": 2.7868601986249044, "Avg loss": 1.5505191003903747, "Avg value loss": 1.1687834486365318, "Avg policy loss": 0.3817356612998992, "Total num played games": 2618, "Total num trained steps": 7296, "Timestamp in ms": 1702000163951, "logtype": "training_step"}
{"Ratio train steps to played games": 2.812121212121212, "Avg loss": 1.1361465696245432, "Avg value loss": 0.7482805303297937, "Avg policy loss": 0.38786602951586246, "Total num played games": 2640, "Total num trained steps": 7424, "Timestamp in ms": 1702000224663, "logtype": "training_step"}
{"Ratio train steps to played games": 2.841234010534236, "Avg loss": 1.0413504801690578, "Avg value loss": 0.6567592492792755, "Avg policy loss": 0.38459123438224196, "Total num played games": 2658, "Total num trained steps": 7552, "Timestamp in ms": 1702000286237, "logtype": "training_step"}
{"Avg objective": 17.8046875, "Games time in secs": 321.042449682951, "Avg game time in secs": 128.64547200725065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"reached_maximum_moves": 0.43, "played_steps": 11.57, "agent_stopped_0": 0.23, "agent_stopped_more": 0.34}, "Total num played games": 2688, "Total num trained steps": 7630, "Timestamp in ms": 1702000323501, "logtype": "played_game"}
{"Ratio train steps to played games": 2.8360413589364843, "Avg loss": 1.1554744206368923, "Avg value loss": 0.7759685162454844, "Avg policy loss": 0.37950589531101286, "Total num played games": 2708, "Total num trained steps": 7680, "Timestamp in ms": 1702000346773, "logtype": "training_step"}
{"Ratio train steps to played games": 2.8454810495626823, "Avg loss": 1.1704400540329516, "Avg value loss": 0.7835438034962863, "Avg policy loss": 0.38689625286497176, "Total num played games": 2744, "Total num trained steps": 7808, "Timestamp in ms": 1702000406873, "logtype": "training_step"}
{"Avg objective": 15.8984375, "Games time in secs": 218.73699577897787, "Avg game time in secs": 123.8381401768711, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.2, "agent_stopped_more": 0.41, "played_steps": 11.45, "reached_maximum_moves": 0.39}, "Total num played games": 2816, "Total num trained steps": 7823, "Timestamp in ms": 1702000542238, "logtype": "played_game"}
{"Total num played games": 2820, "Total num trained steps": 7823, "Timestamp in ms": 1702000557199, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.328125}
{"Ratio train steps to played games": 2.7690160502442427, "Avg loss": 1.5041183708235621, "Avg value loss": 1.1033900089096278, "Avg policy loss": 0.4007283579558134, "Total num played games": 2866, "Total num trained steps": 7936, "Timestamp in ms": 1702000610418, "logtype": "training_step"}
{"Ratio train steps to played games": 2.780689655172414, "Avg loss": 1.2046317090280354, "Avg value loss": 0.8058137707412243, "Avg policy loss": 0.39881794387474656, "Total num played games": 2900, "Total num trained steps": 8064, "Timestamp in ms": 1702000669884, "logtype": "training_step"}
{"Ratio train steps to played games": 2.790190735694823, "Avg loss": 1.0271894009783864, "Avg value loss": 0.6335276160389185, "Avg policy loss": 0.3936617812141776, "Total num played games": 2936, "Total num trained steps": 8192, "Timestamp in ms": 1702000729427, "logtype": "training_step"}
{"Avg objective": 18.0703125, "Games time in secs": 195.9991169348359, "Avg game time in secs": 75.42062145494856, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "reached_maximum_moves": 0.24, "played_steps": 7.19, "agent_stopped_more": 0.35}, "Total num played games": 2944, "Total num trained steps": 8211, "Timestamp in ms": 1702000738237, "logtype": "played_game"}
{"Ratio train steps to played games": 2.786336235766912, "Avg loss": 1.131243600975722, "Avg value loss": 0.7312083609867841, "Avg policy loss": 0.40003523067571223, "Total num played games": 2986, "Total num trained steps": 8320, "Timestamp in ms": 1702000788292, "logtype": "training_step"}
{"Avg objective": 15.9296875, "Games time in secs": 238.58356566354632, "Avg game time in secs": 120.3264710008225, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"reached_maximum_moves": 0.45, "played_steps": 11.58, "agent_stopped_more": 0.3, "agent_stopped_0": 0.24}, "Total num played games": 3072, "Total num trained steps": 8424, "Timestamp in ms": 1702000976822, "logtype": "played_game"}
{"Total num played games": 3086, "Total num trained steps": 8424, "Timestamp in ms": 1702001013585, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.6640625}
{"Ratio train steps to played games": 2.7251612903225806, "Avg loss": 1.1173576032742858, "Avg value loss": 0.7203617319464684, "Avg policy loss": 0.39699586923234165, "Total num played games": 3100, "Total num trained steps": 8448, "Timestamp in ms": 1702001026214, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7312101910828024, "Avg loss": 1.279298735782504, "Avg value loss": 0.8761103299912065, "Avg policy loss": 0.403188408119604, "Total num played games": 3140, "Total num trained steps": 8576, "Timestamp in ms": 1702001086823, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7422810333963454, "Avg loss": 1.0601245677098632, "Avg value loss": 0.6544689161237329, "Avg policy loss": 0.4056556527502835, "Total num played games": 3174, "Total num trained steps": 8704, "Timestamp in ms": 1702001145528, "logtype": "training_step"}
{"Avg objective": 18.0390625, "Games time in secs": 219.3207039348781, "Avg game time in secs": 80.7198710499215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 7.77, "reached_maximum_moves": 0.27, "agent_stopped_0": 0.4}, "Total num played games": 3200, "Total num trained steps": 8810, "Timestamp in ms": 1702001196143, "logtype": "played_game"}
{"Ratio train steps to played games": 2.7548346849656893, "Avg loss": 0.9351545399986207, "Avg value loss": 0.5407124329358339, "Avg policy loss": 0.394442104967311, "Total num played games": 3206, "Total num trained steps": 8832, "Timestamp in ms": 1702001206229, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7467811158798283, "Avg loss": 0.9547675824724138, "Avg value loss": 0.557079165475443, "Avg policy loss": 0.3976884081494063, "Total num played games": 3262, "Total num trained steps": 8960, "Timestamp in ms": 1702001267451, "logtype": "training_step"}
{"Avg objective": 16.7421875, "Games time in secs": 187.7477757371962, "Avg game time in secs": 97.96568426612066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 9.88, "reached_maximum_moves": 0.36, "agent_stopped_0": 0.25}, "Total num played games": 3328, "Total num trained steps": 9025, "Timestamp in ms": 1702001383890, "logtype": "played_game"}
{"Total num played games": 3340, "Total num trained steps": 9025, "Timestamp in ms": 1702001404268, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.625}
{"Ratio train steps to played games": 2.711217183770883, "Avg loss": 1.3647667071782053, "Avg value loss": 0.970509696751833, "Avg policy loss": 0.39425699901767075, "Total num played games": 3352, "Total num trained steps": 9088, "Timestamp in ms": 1702001434237, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7074030552291424, "Avg loss": 1.1207652701996267, "Avg value loss": 0.7221013591624796, "Avg policy loss": 0.3986639124341309, "Total num played games": 3404, "Total num trained steps": 9216, "Timestamp in ms": 1702001495489, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7068366164542295, "Avg loss": 1.0259131956845522, "Avg value loss": 0.6300490770954639, "Avg policy loss": 0.3958641260396689, "Total num played games": 3452, "Total num trained steps": 9344, "Timestamp in ms": 1702001556729, "logtype": "training_step"}
{"Avg objective": 18.71875, "Games time in secs": 180.0708672516048, "Avg game time in secs": 77.66851506641251, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 7.25, "reached_maximum_moves": 0.25, "agent_stopped_0": 0.38}, "Total num played games": 3456, "Total num trained steps": 9359, "Timestamp in ms": 1702001563962, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6924388857305286, "Avg loss": 1.1143520320765674, "Avg value loss": 0.7120193485170603, "Avg policy loss": 0.4023326898459345, "Total num played games": 3518, "Total num trained steps": 9472, "Timestamp in ms": 1702001617236, "logtype": "training_step"}
{"Ratio train steps to played games": 2.7133973996608254, "Avg loss": 1.0357799748890102, "Avg value loss": 0.636087978258729, "Avg policy loss": 0.3996919842902571, "Total num played games": 3538, "Total num trained steps": 9600, "Timestamp in ms": 1702001675660, "logtype": "training_step"}
{"Avg objective": 18.0703125, "Games time in secs": 196.35099417716265, "Avg game time in secs": 98.45453450936475, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.3, "reached_maximum_moves": 0.38, "played_steps": 10.05, "agent_stopped_more": 0.31}, "Total num played games": 3584, "Total num trained steps": 9628, "Timestamp in ms": 1702001760313, "logtype": "played_game"}
{"Total num played games": 3628, "Total num trained steps": 9628, "Timestamp in ms": 1702001859483, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.5546875}
{"Ratio train steps to played games": 2.64204236827811, "Avg loss": 1.5527801825664937, "Avg value loss": 1.154812777414918, "Avg policy loss": 0.3979674116708338, "Total num played games": 3682, "Total num trained steps": 9728, "Timestamp in ms": 1702001906424, "logtype": "training_step"}
{"Ratio train steps to played games": 2.6580366774541533, "Avg loss": 0.9933409630320966, "Avg value loss": 0.5966389284003526, "Avg policy loss": 0.39670201879926026, "Total num played games": 3708, "Total num trained steps": 9856, "Timestamp in ms": 1702001965780, "logtype": "training_step"}
{"Avg objective": 18.015625, "Games time in secs": 209.25668040663004, "Avg game time in secs": 70.59001075895503, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 6.9, "reached_maximum_moves": 0.2, "agent_stopped_0": 0.37}, "Total num played games": 3712, "Total num trained steps": 9863, "Timestamp in ms": 1702001969570, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6510886882634095, "Avg loss": 1.3375501413829625, "Avg value loss": 0.9379429393447936, "Avg policy loss": 0.39960721344687045, "Total num played games": 3766, "Total num trained steps": 9984, "Timestamp in ms": 1702002026393, "logtype": "training_step"}
{"Avg objective": 18.8671875, "Games time in secs": 108.80955338850617, "Avg game time in secs": 63.06871561636217, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 6.66, "agent_stopped_0": 0.38, "reached_maximum_moves": 0.23}, "Total num played games": 3840, "Total num trained steps": 10095, "Timestamp in ms": 1702002078380, "logtype": "played_game"}
{"Ratio train steps to played games": 2.6264935064935067, "Avg loss": 1.2459748880937696, "Avg value loss": 0.8409871570765972, "Avg policy loss": 0.40498774079605937, "Total num played games": 3850, "Total num trained steps": 10112, "Timestamp in ms": 1702002086453, "logtype": "training_step"}
{"Avg objective": 16.9609375, "Games time in secs": 231.16452461481094, "Avg game time in secs": 96.05238421750255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.24, "agent_stopped_more": 0.39, "played_steps": 10.25, "reached_maximum_moves": 0.37}, "Total num played games": 3968, "Total num trained steps": 10230, "Timestamp in ms": 1702002309544, "logtype": "played_game"}
{"Total num played games": 3972, "Total num trained steps": 10230, "Timestamp in ms": 1702002339209, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.05078125}
{"Ratio train steps to played games": 2.5780463242698892, "Avg loss": 1.212823438923806, "Avg value loss": 0.8068380334880203, "Avg policy loss": 0.4059854003135115, "Total num played games": 3972, "Total num trained steps": 10240, "Timestamp in ms": 1702002344896, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5727047146401985, "Avg loss": 1.4427134478464723, "Avg value loss": 1.038776934146881, "Avg policy loss": 0.40393652371130884, "Total num played games": 4030, "Total num trained steps": 10368, "Timestamp in ms": 1702002404159, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5814067879980325, "Avg loss": 0.9716768465004861, "Avg value loss": 0.5653566892724484, "Avg policy loss": 0.40632015164010227, "Total num played games": 4066, "Total num trained steps": 10496, "Timestamp in ms": 1702002464334, "logtype": "training_step"}
{"Avg objective": 18.375, "Games time in secs": 208.95389825478196, "Avg game time in secs": 51.34231345090666, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"reached_maximum_moves": 0.18, "played_steps": 5.32, "agent_stopped_0": 0.47, "agent_stopped_more": 0.35}, "Total num played games": 4096, "Total num trained steps": 10611, "Timestamp in ms": 1702002518498, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5886939571150096, "Avg loss": 0.9548021876253188, "Avg value loss": 0.5537066590040922, "Avg policy loss": 0.40109552373178303, "Total num played games": 4104, "Total num trained steps": 10624, "Timestamp in ms": 1702002524270, "logtype": "training_step"}
{"Ratio train steps to played games": 2.57841726618705, "Avg loss": 1.1289284327067435, "Avg value loss": 0.7353189673740417, "Avg policy loss": 0.39360946347005665, "Total num played games": 4170, "Total num trained steps": 10752, "Timestamp in ms": 1702002582650, "logtype": "training_step"}
{"Avg objective": 18.40625, "Games time in secs": 147.50207640603185, "Avg game time in secs": 72.87603346351534, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "reached_maximum_moves": 0.28, "played_steps": 7.8, "agent_stopped_more": 0.4}, "Total num played games": 4224, "Total num trained steps": 10829, "Timestamp in ms": 1702002666001, "logtype": "played_game"}
{"Total num played games": 4276, "Total num trained steps": 10829, "Timestamp in ms": 1702002813458, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.87109375}
{"Ratio train steps to played games": 2.5173530772790373, "Avg loss": 1.4011459331959486, "Avg value loss": 0.9992423688527197, "Avg policy loss": 0.40190355596132576, "Total num played games": 4322, "Total num trained steps": 10880, "Timestamp in ms": 1702002837711, "logtype": "training_step"}
{"Ratio train steps to played games": 2.5387453874538743, "Avg loss": 1.0383721198886633, "Avg value loss": 0.6360430105123669, "Avg policy loss": 0.4023291114717722, "Total num played games": 4336, "Total num trained steps": 11008, "Timestamp in ms": 1702002896553, "logtype": "training_step"}
{"Avg objective": 18.28125, "Games time in secs": 264.0333275794983, "Avg game time in secs": 83.23822598851984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "reached_maximum_moves": 0.3, "played_steps": 7.94, "agent_stopped_more": 0.3}, "Total num played games": 4352, "Total num trained steps": 11079, "Timestamp in ms": 1702002930034, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5447897623400366, "Avg loss": 0.8570436802692711, "Avg value loss": 0.45981272449716926, "Avg policy loss": 0.39723094808869064, "Total num played games": 4376, "Total num trained steps": 11136, "Timestamp in ms": 1702002956373, "logtype": "training_step"}
{"Ratio train steps to played games": 2.539224526600541, "Avg loss": 0.9040912119671702, "Avg value loss": 0.5160190113820136, "Avg policy loss": 0.3880722038447857, "Total num played games": 4436, "Total num trained steps": 11264, "Timestamp in ms": 1702003015202, "logtype": "training_step"}
{"Avg objective": 17.3359375, "Games time in secs": 135.71584358811378, "Avg game time in secs": 66.2227862245054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"reached_maximum_moves": 0.25, "played_steps": 7.43, "agent_stopped_more": 0.43, "agent_stopped_0": 0.32}, "Total num played games": 4480, "Total num trained steps": 11372, "Timestamp in ms": 1702003065750, "logtype": "played_game"}
{"Ratio train steps to played games": 2.5383244206773616, "Avg loss": 0.9358488190919161, "Avg value loss": 0.5479483869858086, "Avg policy loss": 0.38790043303743005, "Total num played games": 4488, "Total num trained steps": 11392, "Timestamp in ms": 1702003074779, "logtype": "training_step"}
{"Total num played games": 4588, "Total num trained steps": 11433, "Timestamp in ms": 1702003332351, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.27734375}
{"Avg objective": 18.0, "Games time in secs": 279.4156673103571, "Avg game time in secs": 99.12201990562608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 9.8, "reached_maximum_moves": 0.34, "agent_stopped_0": 0.27}, "Total num played games": 4608, "Total num trained steps": 11459, "Timestamp in ms": 1702003345166, "logtype": "played_game"}
{"Ratio train steps to played games": 2.467866323907455, "Avg loss": 1.5920897019095719, "Avg value loss": 1.1986428392119706, "Avg policy loss": 0.39344686758704484, "Total num played games": 4666, "Total num trained steps": 11520, "Timestamp in ms": 1702003374312, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4780851063829785, "Avg loss": 1.185806138906628, "Avg value loss": 0.7839165015611798, "Avg policy loss": 0.40188962826505303, "Total num played games": 4700, "Total num trained steps": 11648, "Timestamp in ms": 1702003434546, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4917477782479898, "Avg loss": 0.9799787336960435, "Avg value loss": 0.5888005171436816, "Avg policy loss": 0.39117822237312794, "Total num played games": 4726, "Total num trained steps": 11776, "Timestamp in ms": 1702003493384, "logtype": "training_step"}
{"Avg objective": 19.71875, "Games time in secs": 164.9392874762416, "Avg game time in secs": 39.652373820281355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 4.2, "agent_stopped_0": 0.43, "reached_maximum_moves": 0.11}, "Total num played games": 4736, "Total num trained steps": 11812, "Timestamp in ms": 1702003510105, "logtype": "played_game"}
{"Ratio train steps to played games": 2.488294314381271, "Avg loss": 1.014042609371245, "Avg value loss": 0.6213143628556281, "Avg policy loss": 0.39272824488580227, "Total num played games": 4784, "Total num trained steps": 11904, "Timestamp in ms": 1702003555694, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4847170590665013, "Avg loss": 0.9592041987925768, "Avg value loss": 0.5707775235641748, "Avg policy loss": 0.38842667709104717, "Total num played games": 4842, "Total num trained steps": 12032, "Timestamp in ms": 1702003617675, "logtype": "training_step"}
{"Avg objective": 18.46875, "Games time in secs": 136.14639318734407, "Avg game time in secs": 66.49386532077915, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 7.14, "agent_stopped_0": 0.33, "reached_maximum_moves": 0.24}, "Total num played games": 4864, "Total num trained steps": 12036, "Timestamp in ms": 1702003646252, "logtype": "played_game"}
{"Total num played games": 4930, "Total num trained steps": 12036, "Timestamp in ms": 1702003787079, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.3359375}
{"Avg objective": 19.40625, "Games time in secs": 160.36778449639678, "Avg game time in secs": 84.30044335444109, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.28, "played_steps": 7.8, "reached_maximum_moves": 0.28, "agent_stopped_0": 0.44}, "Total num played games": 4992, "Total num trained steps": 12075, "Timestamp in ms": 1702003806620, "logtype": "played_game"}
{"Ratio train steps to played games": 2.415574096146206, "Avg loss": 1.7716586645692587, "Avg value loss": 1.3726883120834827, "Avg policy loss": 0.3989703613333404, "Total num played games": 5034, "Total num trained steps": 12160, "Timestamp in ms": 1702003844895, "logtype": "training_step"}
{"Ratio train steps to played games": 2.4198503347774714, "Avg loss": 1.0139154670760036, "Avg value loss": 0.6130289677530527, "Avg policy loss": 0.40088650141842663, "Total num played games": 5078, "Total num trained steps": 12288, "Timestamp in ms": 1702003903081, "logtype": "training_step"}
{"Avg objective": 19.265625, "Games time in secs": 133.04962787032127, "Avg game time in secs": 32.9076228623162, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.43, "played_steps": 3.6, "reached_maximum_moves": 0.09}, "Total num played games": 5120, "Total num trained steps": 12367, "Timestamp in ms": 1702003939670, "logtype": "played_game"}
{"Ratio train steps to played games": 2.4165044764499806, "Avg loss": 1.0088412761688232, "Avg value loss": 0.6164535349234939, "Avg policy loss": 0.3923877456691116, "Total num played games": 5138, "Total num trained steps": 12416, "Timestamp in ms": 1702003961903, "logtype": "training_step"}
{"Ratio train steps to played games": 2.405638665132336, "Avg loss": 1.218224622309208, "Avg value loss": 0.8233954380266368, "Avg policy loss": 0.3948291796259582, "Total num played games": 5214, "Total num trained steps": 12544, "Timestamp in ms": 1702004020375, "logtype": "training_step"}
{"Avg objective": 19.71875, "Games time in secs": 112.38812781497836, "Avg game time in secs": 51.50677352360799, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "reached_maximum_moves": 0.2, "played_steps": 5.79, "agent_stopped_more": 0.39}, "Total num played games": 5248, "Total num trained steps": 12614, "Timestamp in ms": 1702004052058, "logtype": "played_game"}
{"Total num played games": 5304, "Total num trained steps": 12636, "Timestamp in ms": 1702004143525, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.49609375}
{"Ratio train steps to played games": 2.3748125937031483, "Avg loss": 1.2723597805015743, "Avg value loss": 0.8756920765154064, "Avg policy loss": 0.39666769723407924, "Total num played games": 5336, "Total num trained steps": 12672, "Timestamp in ms": 1702004160889, "logtype": "training_step"}
{"Avg objective": 18.0625, "Games time in secs": 126.7515536211431, "Avg game time in secs": 78.87897963885916, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "reached_maximum_moves": 0.24, "played_steps": 7.38, "agent_stopped_more": 0.39}, "Total num played games": 5376, "Total num trained steps": 12712, "Timestamp in ms": 1702004178810, "logtype": "played_game"}
{"Ratio train steps to played games": 2.3624953857512, "Avg loss": 1.305368906352669, "Avg value loss": 0.9123783623799682, "Avg policy loss": 0.39299055142328143, "Total num played games": 5418, "Total num trained steps": 12800, "Timestamp in ms": 1702004218415, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3712399119589143, "Avg loss": 0.9379417430609465, "Avg value loss": 0.5511076678521931, "Avg policy loss": 0.38683408102951944, "Total num played games": 5452, "Total num trained steps": 12928, "Timestamp in ms": 1702004275490, "logtype": "training_step"}
{"Avg objective": 19.375, "Games time in secs": 154.1155062355101, "Avg game time in secs": 50.79969552118564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.41, "played_steps": 5.74, "reached_maximum_moves": 0.2}, "Total num played games": 5504, "Total num trained steps": 13053, "Timestamp in ms": 1702004332926, "logtype": "played_game"}
{"Ratio train steps to played games": 2.371049763893934, "Avg loss": 0.969176980201155, "Avg value loss": 0.5832381139043719, "Avg policy loss": 0.3859388646669686, "Total num played games": 5506, "Total num trained steps": 13056, "Timestamp in ms": 1702004334225, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3509272467902997, "Avg loss": 1.1779119321145117, "Avg value loss": 0.7945786770433187, "Avg policy loss": 0.3833332599606365, "Total num played games": 5608, "Total num trained steps": 13184, "Timestamp in ms": 1702004392341, "logtype": "training_step"}
{"Avg objective": 19.3671875, "Games time in secs": 89.02020404487848, "Avg game time in secs": 57.41921688927687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "reached_maximum_moves": 0.17, "played_steps": 5.12, "agent_stopped_more": 0.37}, "Total num played games": 5632, "Total num trained steps": 13237, "Timestamp in ms": 1702004421946, "logtype": "played_game"}
{"Total num played games": 5708, "Total num trained steps": 13237, "Timestamp in ms": 1702004551250, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.69140625}
{"Avg objective": 18.8046875, "Games time in secs": 154.25212079286575, "Avg game time in secs": 77.00516186794266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"reached_maximum_moves": 0.27, "played_steps": 7.88, "agent_stopped_0": 0.31, "agent_stopped_more": 0.41}, "Total num played games": 5760, "Total num trained steps": 13291, "Timestamp in ms": 1702004576198, "logtype": "played_game"}
{"Ratio train steps to played games": 2.303738317757009, "Avg loss": 1.5564437415450811, "Avg value loss": 1.1713943660724908, "Avg policy loss": 0.3850493864156306, "Total num played games": 5778, "Total num trained steps": 13312, "Timestamp in ms": 1702004585387, "logtype": "training_step"}
{"Ratio train steps to played games": 2.3013698630136985, "Avg loss": 1.1102357036434114, "Avg value loss": 0.7104401430115104, "Avg policy loss": 0.3997955631930381, "Total num played games": 5840, "Total num trained steps": 13440, "Timestamp in ms": 1702004642617, "logtype": "training_step"}
{"Avg objective": 18.6875, "Games time in secs": 108.36624313145876, "Avg game time in secs": 31.50246431247797, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 3.41, "agent_stopped_0": 0.46, "reached_maximum_moves": 0.09}, "Total num played games": 5888, "Total num trained steps": 13536, "Timestamp in ms": 1702004684565, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2942171119377748, "Avg loss": 1.0275288093835115, "Avg value loss": 0.6299602277576923, "Avg policy loss": 0.3975685762707144, "Total num played games": 5914, "Total num trained steps": 13568, "Timestamp in ms": 1702004698143, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 67.23298369720578, "Avg game time in secs": 33.216268020449206, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 3.8, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.11}, "Total num played games": 6016, "Total num trained steps": 13690, "Timestamp in ms": 1702004751798, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2735723771580347, "Avg loss": 1.2659493261016905, "Avg value loss": 0.8557695499621332, "Avg policy loss": 0.41017977916635573, "Total num played games": 6024, "Total num trained steps": 13696, "Timestamp in ms": 1702004754335, "logtype": "training_step"}
{"Ratio train steps to played games": 2.2692055154300723, "Avg loss": 1.1961710136383772, "Avg value loss": 0.7758186731953174, "Avg policy loss": 0.4203523376490921, "Total num played games": 6092, "Total num trained steps": 13824, "Timestamp in ms": 1702004812580, "logtype": "training_step"}
{"Avg objective": 19.0, "Games time in secs": 145.68789046257734, "Avg game time in secs": 52.57964517863002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 5.84, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.18}, "Total num played games": 6144, "Total num trained steps": 13840, "Timestamp in ms": 1702004897486, "logtype": "played_game"}
{"Total num played games": 6178, "Total num trained steps": 13840, "Timestamp in ms": 1702004947202, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.84375}
{"Ratio train steps to played games": 2.22661985317587, "Avg loss": 1.6695049991831183, "Avg value loss": 1.2550990541931242, "Avg policy loss": 0.41440596291795373, "Total num played games": 6266, "Total num trained steps": 13952, "Timestamp in ms": 1702004998142, "logtype": "training_step"}
{"Avg objective": 19.78125, "Games time in secs": 103.97512139379978, "Avg game time in secs": 52.7693462515017, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "reached_maximum_moves": 0.17, "played_steps": 5.14, "agent_stopped_more": 0.41}, "Total num played games": 6272, "Total num trained steps": 13959, "Timestamp in ms": 1702005001461, "logtype": "played_game"}
{"Ratio train steps to played games": 2.225031605562579, "Avg loss": 1.1173879988491535, "Avg value loss": 0.7044178545475006, "Avg policy loss": 0.41297014337033033, "Total num played games": 6328, "Total num trained steps": 14080, "Timestamp in ms": 1702005055614, "logtype": "training_step"}
{"Ratio train steps to played games": 2.2269592476489026, "Avg loss": 1.209676945116371, "Avg value loss": 0.8100895571988076, "Avg policy loss": 0.3995873932726681, "Total num played games": 6380, "Total num trained steps": 14208, "Timestamp in ms": 1702005112594, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 119.62863990291953, "Avg game time in secs": 37.055543528229464, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.39, "played_steps": 4.22, "reached_maximum_moves": 0.12}, "Total num played games": 6400, "Total num trained steps": 14227, "Timestamp in ms": 1702005121112, "logtype": "played_game"}
{"Ratio train steps to played games": 2.2014742014742015, "Avg loss": 1.346955997403711, "Avg value loss": 0.9447107987944037, "Avg policy loss": 0.4022451937198639, "Total num played games": 6512, "Total num trained steps": 14336, "Timestamp in ms": 1702005169142, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 56.9216243699193, "Avg game time in secs": 36.33341922055115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.35, "played_steps": 4.17, "reached_maximum_moves": 0.15}, "Total num played games": 6528, "Total num trained steps": 14356, "Timestamp in ms": 1702005178034, "logtype": "played_game"}
{"Total num played games": 6646, "Total num trained steps": 14441, "Timestamp in ms": 1702005349508, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.640625}
{"Avg objective": 19.71875, "Games time in secs": 180.49379064142704, "Avg game time in secs": 74.70559870539, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.31, "played_steps": 8.27, "reached_maximum_moves": 0.3}, "Total num played games": 6656, "Total num trained steps": 14460, "Timestamp in ms": 1702005358528, "logtype": "played_game"}
{"Ratio train steps to played games": 2.16981698169817, "Avg loss": 1.6621657451614738, "Avg value loss": 1.248414051020518, "Avg policy loss": 0.4137516904156655, "Total num played games": 6666, "Total num trained steps": 14464, "Timestamp in ms": 1702005360304, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 49.41966859996319, "Avg game time in secs": 15.837834246282, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "reached_maximum_moves": 0.02, "played_steps": 1.24, "agent_stopped_more": 0.41}, "Total num played games": 6784, "Total num trained steps": 14570, "Timestamp in ms": 1702005407948, "logtype": "played_game"}
{"Ratio train steps to played games": 2.144620811287478, "Avg loss": 1.4765054141171277, "Avg value loss": 1.0695805167779326, "Avg policy loss": 0.4069248952437192, "Total num played games": 6804, "Total num trained steps": 14592, "Timestamp in ms": 1702005417425, "logtype": "training_step"}
{"Ratio train steps to played games": 2.137670636073192, "Avg loss": 1.3093745009973645, "Avg value loss": 0.8991830381564796, "Avg policy loss": 0.4101914663333446, "Total num played games": 6886, "Total num trained steps": 14720, "Timestamp in ms": 1702005473776, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 77.0846688747406, "Avg game time in secs": 28.882686451164773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "reached_maximum_moves": 0.06, "played_steps": 2.69, "agent_stopped_more": 0.41}, "Total num played games": 6912, "Total num trained steps": 14745, "Timestamp in ms": 1702005485033, "logtype": "played_game"}
{"Ratio train steps to played games": 2.123569794050343, "Avg loss": 1.333377372007817, "Avg value loss": 0.931759444065392, "Avg policy loss": 0.40161792491562665, "Total num played games": 6992, "Total num trained steps": 14848, "Timestamp in ms": 1702005530094, "logtype": "training_step"}
{"Avg objective": 20.0625, "Games time in secs": 77.18529906868935, "Avg game time in secs": 34.99460214219289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.36, "played_steps": 3.9, "reached_maximum_moves": 0.1}, "Total num played games": 7040, "Total num trained steps": 14922, "Timestamp in ms": 1702005562233, "logtype": "played_game"}
{"Ratio train steps to played games": 2.112270803949224, "Avg loss": 1.2920209127478302, "Avg value loss": 0.8934740598779172, "Avg policy loss": 0.39854686008766294, "Total num played games": 7090, "Total num trained steps": 14976, "Timestamp in ms": 1702005585908, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 56.372776091098785, "Avg game time in secs": 29.802023470489075, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.39, "played_steps": 3.36, "reached_maximum_moves": 0.08}, "Total num played games": 7168, "Total num trained steps": 15044, "Timestamp in ms": 1702005618605, "logtype": "played_game"}
{"Total num played games": 7222, "Total num trained steps": 15044, "Timestamp in ms": 1702005682220, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.03515625}
{"Ratio train steps to played games": 2.0718792866941014, "Avg loss": 1.6846446567215025, "Avg value loss": 1.2911658165976405, "Avg policy loss": 0.3934788419865072, "Total num played games": 7290, "Total num trained steps": 15104, "Timestamp in ms": 1702005710788, "logtype": "training_step"}
{"Avg objective": 19.4296875, "Games time in secs": 94.33989455550909, "Avg game time in secs": 42.579225163848605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 4.42, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.13}, "Total num played games": 7296, "Total num trained steps": 15108, "Timestamp in ms": 1702005712946, "logtype": "played_game"}
{"Ratio train steps to played games": 2.055600539811066, "Avg loss": 1.3897753120400012, "Avg value loss": 1.003256693482399, "Avg policy loss": 0.3865186225157231, "Total num played games": 7410, "Total num trained steps": 15232, "Timestamp in ms": 1702005767939, "logtype": "training_step"}
{"Avg objective": 19.671875, "Games time in secs": 62.278258100152016, "Avg game time in secs": 22.8405587222951, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.41, "played_steps": 2.23, "reached_maximum_moves": 0.05}, "Total num played games": 7424, "Total num trained steps": 15248, "Timestamp in ms": 1702005775224, "logtype": "played_game"}
{"Ratio train steps to played games": 2.046908315565032, "Avg loss": 1.3105032620951533, "Avg value loss": 0.9254255841951817, "Avg policy loss": 0.3850776734761894, "Total num played games": 7504, "Total num trained steps": 15360, "Timestamp in ms": 1702005824682, "logtype": "training_step"}
{"Avg objective": 20.7734375, "Games time in secs": 76.78967883065343, "Avg game time in secs": 31.517991615401115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "reached_maximum_moves": 0.11, "played_steps": 3.83, "agent_stopped_more": 0.4}, "Total num played games": 7552, "Total num trained steps": 15423, "Timestamp in ms": 1702005852014, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0346820809248554, "Avg loss": 1.1823037168942392, "Avg value loss": 0.8080303859896958, "Avg policy loss": 0.37427332275547087, "Total num played games": 7612, "Total num trained steps": 15488, "Timestamp in ms": 1702005880517, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 61.50618962943554, "Avg game time in secs": 34.183995768631576, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"reached_maximum_moves": 0.08, "played_steps": 3.73, "agent_stopped_0": 0.43, "agent_stopped_more": 0.49}, "Total num played games": 7680, "Total num trained steps": 15561, "Timestamp in ms": 1702005913520, "logtype": "played_game"}
{"Ratio train steps to played games": 2.0179632980098217, "Avg loss": 1.343633346259594, "Avg value loss": 0.9728405938949436, "Avg policy loss": 0.3707927498035133, "Total num played games": 7738, "Total num trained steps": 15616, "Timestamp in ms": 1702005938141, "logtype": "training_step"}
{"Avg objective": 18.921875, "Games time in secs": 60.20743399113417, "Avg game time in secs": 33.823200315004215, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.39, "played_steps": 3.71, "reached_maximum_moves": 0.07}, "Total num played games": 7808, "Total num trained steps": 15648, "Timestamp in ms": 1702005973728, "logtype": "played_game"}
{"Total num played games": 7836, "Total num trained steps": 15648, "Timestamp in ms": 1702006032680, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.44140625}
{"Avg objective": 19.7421875, "Games time in secs": 101.05396514758468, "Avg game time in secs": 32.362314443220384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"reached_maximum_moves": 0.08, "played_steps": 3.49, "agent_stopped_0": 0.48, "agent_stopped_more": 0.44}, "Total num played games": 7936, "Total num trained steps": 15738, "Timestamp in ms": 1702006074782, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823721984386804, "Avg loss": 1.60838527046144, "Avg value loss": 1.238671988947317, "Avg policy loss": 0.3697132801171392, "Total num played games": 7942, "Total num trained steps": 15744, "Timestamp in ms": 1702006077190, "logtype": "training_step"}
{"Avg objective": 19.9765625, "Games time in secs": 61.03189981356263, "Avg game time in secs": 27.08969741378678, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.42, "played_steps": 2.75, "reached_maximum_moves": 0.04}, "Total num played games": 8064, "Total num trained steps": 15869, "Timestamp in ms": 1702006135814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9682539682539681, "Avg loss": 1.4177135154604912, "Avg value loss": 1.0409215395338833, "Avg policy loss": 0.37679198710247874, "Total num played games": 8064, "Total num trained steps": 15872, "Timestamp in ms": 1702006137008, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9627085377821394, "Avg loss": 1.467887924052775, "Avg value loss": 1.0791309427004308, "Avg policy loss": 0.38875698391348124, "Total num played games": 8152, "Total num trained steps": 16000, "Timestamp in ms": 1702006200303, "logtype": "training_step"}
{"Avg objective": 20.3203125, "Games time in secs": 83.63187355920672, "Avg game time in secs": 32.78086458751932, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 3.71, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.09}, "Total num played games": 8192, "Total num trained steps": 16042, "Timestamp in ms": 1702006219446, "logtype": "played_game"}
{"Ratio train steps to played games": 1.945945945945946, "Avg loss": 1.3998347856104374, "Avg value loss": 1.0057371640577912, "Avg policy loss": 0.39409763598814607, "Total num played games": 8288, "Total num trained steps": 16128, "Timestamp in ms": 1702006259890, "logtype": "training_step"}
{"Avg objective": 19.9921875, "Games time in secs": 51.63278317078948, "Avg game time in secs": 33.181773471529596, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.4, "played_steps": 3.66, "reached_maximum_moves": 0.11}, "Total num played games": 8320, "Total num trained steps": 16151, "Timestamp in ms": 1702006271079, "logtype": "played_game"}
{"Avg objective": 18.40625, "Games time in secs": 125.67336071282625, "Avg game time in secs": 54.069677422143286, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 6.09, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.12}, "Total num played games": 8448, "Total num trained steps": 16252, "Timestamp in ms": 1702006396752, "logtype": "played_game"}
{"Total num played games": 8468, "Total num trained steps": 16252, "Timestamp in ms": 1702006485206, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.1015625}
{"Ratio train steps to played games": 1.9196976854038734, "Avg loss": 1.225227433256805, "Avg value loss": 0.8257373173255473, "Avg policy loss": 0.39949011499993503, "Total num played games": 8468, "Total num trained steps": 16256, "Timestamp in ms": 1702006487311, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9167056621431915, "Avg loss": 1.4525577067397535, "Avg value loss": 1.0676222948823124, "Avg policy loss": 0.3849354216363281, "Total num played games": 8548, "Total num trained steps": 16384, "Timestamp in ms": 1702006550498, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9298737727910238, "Avg loss": 0.8350409572012722, "Avg value loss": 0.46249296120367944, "Avg policy loss": 0.37254799297079444, "Total num played games": 8556, "Total num trained steps": 16512, "Timestamp in ms": 1702006617764, "logtype": "training_step"}
{"Avg objective": 18.921875, "Games time in secs": 281.0492079332471, "Avg game time in secs": 40.197871663374826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.33, "played_steps": 4.08, "reached_maximum_moves": 0.15, "agent_stopped_0": 0.52}, "Total num played games": 8576, "Total num trained steps": 16629, "Timestamp in ms": 1702006677802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9371362048894063, "Avg loss": 0.7847924940288067, "Avg value loss": 0.4225862512830645, "Avg policy loss": 0.36220625089481473, "Total num played games": 8590, "Total num trained steps": 16640, "Timestamp in ms": 1702006682673, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9420894139448692, "Avg loss": 1.0978926662355661, "Avg value loss": 0.7213049150304869, "Avg policy loss": 0.3765877529513091, "Total num played games": 8634, "Total num trained steps": 16768, "Timestamp in ms": 1702006749168, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 136.16623647511005, "Avg game time in secs": 21.990154365252238, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.48, "played_steps": 2.49, "reached_maximum_moves": 0.04}, "Total num played games": 8704, "Total num trained steps": 16855, "Timestamp in ms": 1702006813968, "logtype": "played_game"}
{"Total num played games": 8734, "Total num trained steps": 16855, "Timestamp in ms": 1702006912649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.02734375}
{"Ratio train steps to played games": 1.9221843003412968, "Avg loss": 1.5537743628956378, "Avg value loss": 1.1771681015379727, "Avg policy loss": 0.3766062657814473, "Total num played games": 8790, "Total num trained steps": 16896, "Timestamp in ms": 1702006933112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9305965071444773, "Avg loss": 1.0086681181564927, "Avg value loss": 0.632455982035026, "Avg policy loss": 0.3762121305335313, "Total num played games": 8818, "Total num trained steps": 17024, "Timestamp in ms": 1702007000887, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 249.79435470700264, "Avg game time in secs": 37.06867993451306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "reached_maximum_moves": 0.12, "played_steps": 4.23, "agent_stopped_more": 0.41}, "Total num played games": 8832, "Total num trained steps": 17145, "Timestamp in ms": 1702007063763, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9358916478555306, "Avg loss": 0.7697990541346371, "Avg value loss": 0.4001132142730057, "Avg policy loss": 0.3696858377661556, "Total num played games": 8860, "Total num trained steps": 17152, "Timestamp in ms": 1702007066713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9389587073608618, "Avg loss": 1.3278056825511158, "Avg value loss": 0.9552167193032801, "Avg policy loss": 0.3725889439228922, "Total num played games": 8912, "Total num trained steps": 17280, "Timestamp in ms": 1702007134228, "logtype": "training_step"}
{"Avg objective": 21.4296875, "Games time in secs": 105.3112435489893, "Avg game time in secs": 15.505253375333268, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"reached_maximum_moves": 0.02, "played_steps": 1.55, "agent_stopped_0": 0.59, "agent_stopped_more": 0.38}, "Total num played games": 8960, "Total num trained steps": 17346, "Timestamp in ms": 1702007169075, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9355125639315098, "Avg loss": 0.9852991714142263, "Avg value loss": 0.6111777316546068, "Avg policy loss": 0.37412144523113966, "Total num played games": 8994, "Total num trained steps": 17408, "Timestamp in ms": 1702007200088, "logtype": "training_step"}
{"Total num played games": 9008, "Total num trained steps": 17457, "Timestamp in ms": 1702007281674, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.015625}
{"Ratio train steps to played games": 1.933406835722161, "Avg loss": 0.9673334937542677, "Avg value loss": 0.5933361891657114, "Avg policy loss": 0.37399730551987886, "Total num played games": 9070, "Total num trained steps": 17536, "Timestamp in ms": 1702007319243, "logtype": "training_step"}
{"Avg objective": 19.5234375, "Games time in secs": 211.11153584346175, "Avg game time in secs": 28.010718931240262, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.32, "agent_stopped_more": 0.63, "played_steps": 3.02, "reached_maximum_moves": 0.05}, "Total num played games": 9088, "Total num trained steps": 17661, "Timestamp in ms": 1702007380186, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9423795909390806, "Avg loss": 0.7674700105562806, "Avg value loss": 0.3961239845957607, "Avg policy loss": 0.371346035040915, "Total num played games": 9094, "Total num trained steps": 17664, "Timestamp in ms": 1702007381445, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9410866244817806, "Avg loss": 1.0153343682177365, "Avg value loss": 0.6412416535895318, "Avg policy loss": 0.37409271532669663, "Total num played games": 9166, "Total num trained steps": 17792, "Timestamp in ms": 1702007447639, "logtype": "training_step"}
{"Avg objective": 20.1328125, "Games time in secs": 100.13572507351637, "Avg game time in secs": 22.299823309207568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.44, "played_steps": 2.31, "reached_maximum_moves": 0.03}, "Total num played games": 9216, "Total num trained steps": 17853, "Timestamp in ms": 1702007480322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9398138125135311, "Avg loss": 1.017966321669519, "Avg value loss": 0.6444001168711111, "Avg policy loss": 0.3735661976970732, "Total num played games": 9238, "Total num trained steps": 17920, "Timestamp in ms": 1702007514560, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9352348273643578, "Avg loss": 0.8987877382896841, "Avg value loss": 0.5186806021956727, "Avg policy loss": 0.38010714389383793, "Total num played games": 9326, "Total num trained steps": 18048, "Timestamp in ms": 1702007581888, "logtype": "training_step"}
{"Avg objective": 20.4140625, "Games time in secs": 148.24732863157988, "Avg game time in secs": 29.738574006129056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 3.27, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.08}, "Total num played games": 9344, "Total num trained steps": 18060, "Timestamp in ms": 1702007628570, "logtype": "played_game"}
{"Total num played games": 9344, "Total num trained steps": 18060, "Timestamp in ms": 1702007640024, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.99609375}
{"Ratio train steps to played games": 1.929511677282378, "Avg loss": 1.2598827686160803, "Avg value loss": 0.8610554272308946, "Avg policy loss": 0.3988273444119841, "Total num played games": 9420, "Total num trained steps": 18176, "Timestamp in ms": 1702007699291, "logtype": "training_step"}
{"Ratio train steps to played games": 1.939805002119542, "Avg loss": 0.7661060397513211, "Avg value loss": 0.3790046434151009, "Avg policy loss": 0.38710140041075647, "Total num played games": 9436, "Total num trained steps": 18304, "Timestamp in ms": 1702007765556, "logtype": "training_step"}
{"Avg objective": 20.0234375, "Games time in secs": 179.95335118472576, "Avg game time in secs": 25.734457832295448, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 2.77, "agent_stopped_0": 0.46, "reached_maximum_moves": 0.03}, "Total num played games": 9472, "Total num trained steps": 18387, "Timestamp in ms": 1702007808523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9385780395456458, "Avg loss": 0.9067488461732864, "Avg value loss": 0.521885480848141, "Avg policy loss": 0.3848633710294962, "Total num played games": 9508, "Total num trained steps": 18432, "Timestamp in ms": 1702007831820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.938988717091517, "Avg loss": 0.8727642721496522, "Avg value loss": 0.4875683968421072, "Avg policy loss": 0.3851958755403757, "Total num played games": 9572, "Total num trained steps": 18560, "Timestamp in ms": 1702007895651, "logtype": "training_step"}
{"Avg objective": 19.15625, "Games time in secs": 124.41501589864492, "Avg game time in secs": 19.765708202379756, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 2.23, "agent_stopped_0": 0.46, "reached_maximum_moves": 0.02}, "Total num played games": 9600, "Total num trained steps": 18631, "Timestamp in ms": 1702007932938, "logtype": "played_game"}
{"Total num played games": 9614, "Total num trained steps": 18660, "Timestamp in ms": 1702007994549, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.875}
{"Ratio train steps to played games": 1.9373833713456354, "Avg loss": 1.0089748175814748, "Avg value loss": 0.6238179462961853, "Avg policy loss": 0.3851568731479347, "Total num played games": 9646, "Total num trained steps": 18688, "Timestamp in ms": 1702008009156, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9417956656346749, "Avg loss": 0.9915916137397289, "Avg value loss": 0.6029433396179229, "Avg policy loss": 0.38864826667122543, "Total num played games": 9690, "Total num trained steps": 18816, "Timestamp in ms": 1702008074113, "logtype": "training_step"}
{"Avg objective": 21.0234375, "Games time in secs": 188.0350068435073, "Avg game time in secs": 26.625635159260128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"reached_maximum_moves": 0.09, "played_steps": 3.13, "agent_stopped_more": 0.41, "agent_stopped_0": 0.51}, "Total num played games": 9728, "Total num trained steps": 18905, "Timestamp in ms": 1702008120973, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9388945752302968, "Avg loss": 1.242411816958338, "Avg value loss": 0.8655511501710862, "Avg policy loss": 0.376860668649897, "Total num played games": 9770, "Total num trained steps": 18944, "Timestamp in ms": 1702008140337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9477124183006536, "Avg loss": 1.0150882303714752, "Avg value loss": 0.6239764696219936, "Avg policy loss": 0.3911117548123002, "Total num played games": 9792, "Total num trained steps": 19072, "Timestamp in ms": 1702008206857, "logtype": "training_step"}
{"Avg objective": 21.078125, "Games time in secs": 117.7621851824224, "Avg game time in secs": 22.111761647392996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.58, "played_steps": 2.37, "reached_maximum_moves": 0.04}, "Total num played games": 9856, "Total num trained steps": 19135, "Timestamp in ms": 1702008238736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9452887537993921, "Avg loss": 0.9394652107730508, "Avg value loss": 0.5575212092371657, "Avg policy loss": 0.3819439981598407, "Total num played games": 9870, "Total num trained steps": 19200, "Timestamp in ms": 1702008271397, "logtype": "training_step"}
{"Total num played games": 9972, "Total num trained steps": 19261, "Timestamp in ms": 1702008420092, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.9765625}
{"Avg objective": 20.390625, "Games time in secs": 189.91389600932598, "Avg game time in secs": 28.73040088659036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 3.48, "agent_stopped_0": 0.42, "reached_maximum_moves": 0.06}, "Total num played games": 9984, "Total num trained steps": 19278, "Timestamp in ms": 1702008428650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9258668792347549, "Avg loss": 1.33169128280133, "Avg value loss": 0.9335742476396263, "Avg policy loss": 0.3981170349288732, "Total num played games": 10036, "Total num trained steps": 19328, "Timestamp in ms": 1702008453927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9347653142402546, "Avg loss": 0.8402642090804875, "Avg value loss": 0.44368267711251974, "Avg policy loss": 0.39658152987249196, "Total num played games": 10056, "Total num trained steps": 19456, "Timestamp in ms": 1702008520332, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9463327370304115, "Avg loss": 0.6534173781983554, "Avg value loss": 0.26597570651210845, "Avg policy loss": 0.3874416649341583, "Total num played games": 10062, "Total num trained steps": 19584, "Timestamp in ms": 1702008587774, "logtype": "training_step"}
{"Avg objective": 21.3359375, "Games time in secs": 194.5575896576047, "Avg game time in secs": 24.38560648067505, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 2.71, "agent_stopped_0": 0.46, "reached_maximum_moves": 0.06}, "Total num played games": 10112, "Total num trained steps": 19651, "Timestamp in ms": 1702008623207, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9420689655172414, "Avg loss": 1.0663186642341316, "Avg value loss": 0.6907668946078047, "Avg policy loss": 0.3755517837125808, "Total num played games": 10150, "Total num trained steps": 19712, "Timestamp in ms": 1702008655195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.942051683633516, "Avg loss": 0.8313620057888329, "Avg value loss": 0.4600750911049545, "Avg policy loss": 0.3712869184091687, "Total num played games": 10216, "Total num trained steps": 19840, "Timestamp in ms": 1702008720052, "logtype": "training_step"}
{"Avg objective": 20.03125, "Games time in secs": 137.15180799737573, "Avg game time in secs": 20.171161308302544, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 2.27, "agent_stopped_0": 0.37, "reached_maximum_moves": 0.02}, "Total num played games": 10240, "Total num trained steps": 19862, "Timestamp in ms": 1702008760360, "logtype": "played_game"}
{"Total num played games": 10246, "Total num trained steps": 19862, "Timestamp in ms": 1702008786636, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.73046875}
{"Ratio train steps to played games": 1.9359123521427186, "Avg loss": 1.1982448673807085, "Avg value loss": 0.8105863044038415, "Avg policy loss": 0.38765855855308473, "Total num played games": 10314, "Total num trained steps": 19968, "Timestamp in ms": 1702008838760, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9457784663051898, "Avg loss": 0.7063321084715426, "Avg value loss": 0.3356490551959723, "Avg policy loss": 0.37068304955028, "Total num played games": 10328, "Total num trained steps": 20096, "Timestamp in ms": 1702008903050, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 179.76377947628498, "Avg game time in secs": 23.163525410782313, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 2.48, "agent_stopped_0": 0.59, "reached_maximum_moves": 0.03}, "Total num played games": 10368, "Total num trained steps": 20169, "Timestamp in ms": 1702008940123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.942374183634268, "Avg loss": 0.8150435164570808, "Avg value loss": 0.4428601259132847, "Avg policy loss": 0.3721833894960582, "Total num played games": 10412, "Total num trained steps": 20224, "Timestamp in ms": 1702008966794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9490519057651792, "Avg loss": 0.7145457826554775, "Avg value loss": 0.3399554493371397, "Avg policy loss": 0.37459033518098295, "Total num played games": 10442, "Total num trained steps": 20352, "Timestamp in ms": 1702009030372, "logtype": "training_step"}
{"Avg objective": 20.3828125, "Games time in secs": 109.63754365965724, "Avg game time in secs": 20.775991826463724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.55, "played_steps": 2.08, "reached_maximum_moves": 0.04}, "Total num played games": 10496, "Total num trained steps": 20392, "Timestamp in ms": 1702009049761, "logtype": "played_game"}
{"Total num played games": 10520, "Total num trained steps": 20465, "Timestamp in ms": 1702009128913, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.3984375}
{"Ratio train steps to played games": 1.9419685188697136, "Avg loss": 0.8724062368273735, "Avg value loss": 0.50769198150374, "Avg policy loss": 0.36471425415948033, "Total num played games": 10548, "Total num trained steps": 20480, "Timestamp in ms": 1702009137251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.942684766214178, "Avg loss": 0.9683580910786986, "Avg value loss": 0.5883013446582481, "Avg policy loss": 0.38005674513988197, "Total num played games": 10608, "Total num trained steps": 20608, "Timestamp in ms": 1702009203025, "logtype": "training_step"}
{"Avg objective": 20.265625, "Games time in secs": 209.64087995141745, "Avg game time in secs": 18.935300233453745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 2.17, "agent_stopped_0": 0.52, "reached_maximum_moves": 0.03}, "Total num played games": 10624, "Total num trained steps": 20721, "Timestamp in ms": 1702009259402, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9455807843873147, "Avg loss": 0.6366836510132998, "Avg value loss": 0.2751908361678943, "Avg policy loss": 0.36149281705729663, "Total num played games": 10658, "Total num trained steps": 20736, "Timestamp in ms": 1702009266552, "logtype": "training_step"}
{"Ratio train steps to played games": 1.94944870117735, "Avg loss": 0.8866228880360723, "Avg value loss": 0.521177063928917, "Avg policy loss": 0.3654458378441632, "Total num played games": 10702, "Total num trained steps": 20864, "Timestamp in ms": 1702009333803, "logtype": "training_step"}
{"Avg objective": 20.2734375, "Games time in secs": 107.32929043844342, "Avg game time in secs": 17.200695398671087, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 1.78, "agent_stopped_0": 0.5, "reached_maximum_moves": 0.03}, "Total num played games": 10752, "Total num trained steps": 20929, "Timestamp in ms": 1702009366732, "logtype": "played_game"}
{"Ratio train steps to played games": 1.946948618067149, "Avg loss": 0.7940571019425988, "Avg value loss": 0.44251843669917434, "Avg policy loss": 0.3515386690851301, "Total num played games": 10782, "Total num trained steps": 20992, "Timestamp in ms": 1702009400590, "logtype": "training_step"}
{"Total num played games": 10802, "Total num trained steps": 21065, "Timestamp in ms": 1702009551894, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.15625}
{"Ratio train steps to played games": 1.9414414414414414, "Avg loss": 0.818362578516826, "Avg value loss": 0.4649398851906881, "Avg policy loss": 0.35342269320972264, "Total num played games": 10878, "Total num trained steps": 21120, "Timestamp in ms": 1702009580229, "logtype": "training_step"}
{"Avg objective": 19.5546875, "Games time in secs": 217.4710300937295, "Avg game time in secs": 21.55547263781773, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 2.5, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.02}, "Total num played games": 10880, "Total num trained steps": 21128, "Timestamp in ms": 1702009584203, "logtype": "played_game"}
{"Ratio train steps to played games": 1.950431430145034, "Avg loss": 0.6417987612076104, "Avg value loss": 0.29395422036759555, "Avg policy loss": 0.3478445385117084, "Total num played games": 10894, "Total num trained steps": 21248, "Timestamp in ms": 1702009646027, "logtype": "training_step"}
{"Ratio train steps to played games": 1.945749135263062, "Avg loss": 0.9086055844090879, "Avg value loss": 0.5608124728314579, "Avg policy loss": 0.3477931166999042, "Total num played games": 10986, "Total num trained steps": 21376, "Timestamp in ms": 1702009709016, "logtype": "training_step"}
{"Avg objective": 20.859375, "Games time in secs": 177.88334852457047, "Avg game time in secs": 17.392141268850537, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 1.79, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.01}, "Total num played games": 11008, "Total num trained steps": 21483, "Timestamp in ms": 1702009762088, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9478260869565218, "Avg loss": 0.7260471649933606, "Avg value loss": 0.3871242393506691, "Avg policy loss": 0.33892292622476816, "Total num played games": 11040, "Total num trained steps": 21504, "Timestamp in ms": 1702009771958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.95164200649585, "Avg loss": 0.7718627504073083, "Avg value loss": 0.4287849075626582, "Avg policy loss": 0.3430778500624001, "Total num played games": 11084, "Total num trained steps": 21632, "Timestamp in ms": 1702009835404, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 106.09521131590009, "Avg game time in secs": 17.03748107375577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.59, "played_steps": 1.8, "reached_maximum_moves": 0.02}, "Total num played games": 11136, "Total num trained steps": 21668, "Timestamp in ms": 1702009868183, "logtype": "played_game"}
{"Total num played games": 11174, "Total num trained steps": 21668, "Timestamp in ms": 1702009939078, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.1328125}
{"Ratio train steps to played games": 1.935254357879758, "Avg loss": 1.1094783714506775, "Avg value loss": 0.757939578150399, "Avg policy loss": 0.35153878945857286, "Total num played games": 11244, "Total num trained steps": 21760, "Timestamp in ms": 1702009983031, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9442174453721799, "Avg loss": 0.635692048817873, "Avg value loss": 0.28725235536694527, "Avg policy loss": 0.34843969671055675, "Total num played games": 11258, "Total num trained steps": 21888, "Timestamp in ms": 1702010047017, "logtype": "training_step"}
{"Avg objective": 19.0703125, "Games time in secs": 214.47826570644975, "Avg game time in secs": 29.358694930677302, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 3.25, "agent_stopped_0": 0.34, "reached_maximum_moves": 0.03}, "Total num played games": 11264, "Total num trained steps": 21958, "Timestamp in ms": 1702010082662, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9541984732824427, "Avg loss": 0.5634512051474303, "Avg value loss": 0.22101280436618254, "Avg policy loss": 0.34243839886039495, "Total num played games": 11266, "Total num trained steps": 22016, "Timestamp in ms": 1702010111472, "logtype": "training_step"}
{"Ratio train steps to played games": 1.950325876343139, "Avg loss": 0.8283359222114086, "Avg value loss": 0.489036115584895, "Avg policy loss": 0.3392998103518039, "Total num played games": 11354, "Total num trained steps": 22144, "Timestamp in ms": 1702010174287, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 134.35572104528546, "Avg game time in secs": 16.703204458404798, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "reached_maximum_moves": 0.02, "played_steps": 1.44, "agent_stopped_more": 0.41}, "Total num played games": 11392, "Total num trained steps": 22227, "Timestamp in ms": 1702010217018, "logtype": "played_game"}
{"Total num played games": 11448, "Total num trained steps": 22271, "Timestamp in ms": 1702010278028, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.98828125}
{"Ratio train steps to played games": 1.9454926624737945, "Avg loss": 0.8166814490687102, "Avg value loss": 0.4796325876377523, "Avg policy loss": 0.3370488688815385, "Total num played games": 11448, "Total num trained steps": 22272, "Timestamp in ms": 1702010279002, "logtype": "training_step"}
{"Avg objective": 21.1171875, "Games time in secs": 81.76072409749031, "Avg game time in secs": 20.073384294781135, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 2.05, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.01}, "Total num played games": 11520, "Total num trained steps": 22312, "Timestamp in ms": 1702010298778, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9424210891432536, "Avg loss": 1.0107874255627394, "Avg value loss": 0.6591079707723111, "Avg policy loss": 0.3516794580500573, "Total num played games": 11532, "Total num trained steps": 22400, "Timestamp in ms": 1702010343446, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9518281060474787, "Avg loss": 0.5673547405749559, "Avg value loss": 0.22488356963731349, "Avg policy loss": 0.3424711679108441, "Total num played games": 11542, "Total num trained steps": 22528, "Timestamp in ms": 1702010410336, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9480653482373174, "Avg loss": 0.7425419024657458, "Avg value loss": 0.4103167806752026, "Avg policy loss": 0.3322251283098012, "Total num played games": 11630, "Total num trained steps": 22656, "Timestamp in ms": 1702010474580, "logtype": "training_step"}
{"Avg objective": 20.6328125, "Games time in secs": 238.86969853937626, "Avg game time in secs": 17.637677842692938, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 2.0, "agent_stopped_0": 0.52, "reached_maximum_moves": 0.02}, "Total num played games": 11648, "Total num trained steps": 22779, "Timestamp in ms": 1702010537648, "logtype": "played_game"}
{"Ratio train steps to played games": 1.953025887193554, "Avg loss": 0.6311216736212373, "Avg value loss": 0.2973877696786076, "Avg policy loss": 0.3337338997516781, "Total num played games": 11666, "Total num trained steps": 22784, "Timestamp in ms": 1702010540001, "logtype": "training_step"}
{"Total num played games": 11734, "Total num trained steps": 22872, "Timestamp in ms": 1702010622668, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.37890625}
{"Avg objective": 22.1953125, "Games time in secs": 96.13657175377011, "Avg game time in secs": 11.631660314451437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.96, "agent_stopped_0": 0.55, "reached_maximum_moves": 0.01}, "Total num played games": 11776, "Total num trained steps": 22894, "Timestamp in ms": 1702010633785, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9430122116689281, "Avg loss": 0.9565172889269888, "Avg value loss": 0.6182992330286652, "Avg policy loss": 0.3382180549670011, "Total num played games": 11792, "Total num trained steps": 22912, "Timestamp in ms": 1702010642010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9492385786802031, "Avg loss": 0.642306175082922, "Avg value loss": 0.3048109185183421, "Avg policy loss": 0.33749525318853557, "Total num played games": 11820, "Total num trained steps": 23040, "Timestamp in ms": 1702010706454, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9504967166189595, "Avg loss": 0.5946834387723356, "Avg value loss": 0.2699071696260944, "Avg policy loss": 0.32477627031039447, "Total num played games": 11878, "Total num trained steps": 23168, "Timestamp in ms": 1702010771592, "logtype": "training_step"}
{"Avg objective": 20.1015625, "Games time in secs": 173.61264841258526, "Avg game time in secs": 21.606168901460478, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 2.48, "agent_stopped_0": 0.36, "reached_maximum_moves": 0.02}, "Total num played games": 11904, "Total num trained steps": 23239, "Timestamp in ms": 1702010807398, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9560033585222503, "Avg loss": 0.8026566721964628, "Avg value loss": 0.47292976547032595, "Avg policy loss": 0.3297269099857658, "Total num played games": 11910, "Total num trained steps": 23296, "Timestamp in ms": 1702010836386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.952650883627876, "Avg loss": 0.7901119235903025, "Avg value loss": 0.45803989353589714, "Avg policy loss": 0.3320720272604376, "Total num played games": 11996, "Total num trained steps": 23424, "Timestamp in ms": 1702010900998, "logtype": "training_step"}
{"Total num played games": 12012, "Total num trained steps": 23472, "Timestamp in ms": 1702011047516, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.265625}
{"Avg objective": 20.0625, "Games time in secs": 247.46083062142134, "Avg game time in secs": 23.40602016041521, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 2.7, "agent_stopped_0": 0.47, "reached_maximum_moves": 0.02}, "Total num played games": 12032, "Total num trained steps": 23485, "Timestamp in ms": 1702011054859, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9490235021516054, "Avg loss": 1.039403630886227, "Avg value loss": 0.7019187352852896, "Avg policy loss": 0.33748489432036877, "Total num played games": 12084, "Total num trained steps": 23552, "Timestamp in ms": 1702011088875, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9567013716741035, "Avg loss": 0.6175245740450919, "Avg value loss": 0.2745784295257181, "Avg policy loss": 0.3429461426567286, "Total num played games": 12102, "Total num trained steps": 23680, "Timestamp in ms": 1702011155568, "logtype": "training_step"}
{"Avg objective": 21.4921875, "Games time in secs": 125.45064683631063, "Avg game time in secs": 17.863246804481605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.58, "played_steps": 1.85, "reached_maximum_moves": 0.02}, "Total num played games": 12160, "Total num trained steps": 23727, "Timestamp in ms": 1702011180310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.952755905511811, "Avg loss": 0.9624599216040224, "Avg value loss": 0.6138137880479917, "Avg policy loss": 0.34864614019170403, "Total num played games": 12192, "Total num trained steps": 23808, "Timestamp in ms": 1702011221848, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9510922725790676, "Avg loss": 0.8055116336327046, "Avg value loss": 0.45655317255295813, "Avg policy loss": 0.3489584680646658, "Total num played games": 12268, "Total num trained steps": 23936, "Timestamp in ms": 1702011283507, "logtype": "training_step"}
{"Avg objective": 19.1953125, "Games time in secs": 133.67528676241636, "Avg game time in secs": 20.373209595039953, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 2.48, "agent_stopped_0": 0.44, "reached_maximum_moves": 0.02}, "Total num played games": 12288, "Total num trained steps": 23992, "Timestamp in ms": 1702011313985, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9573775825605986, "Avg loss": 0.7167738766875118, "Avg value loss": 0.36934992647729814, "Avg policy loss": 0.3474239525385201, "Total num played games": 12294, "Total num trained steps": 24064, "Timestamp in ms": 1702011353570, "logtype": "training_step"}
{"Total num played games": 12294, "Total num trained steps": 24074, "Timestamp in ms": 1702011442641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.08203125}
{"Ratio train steps to played games": 1.9547511312217194, "Avg loss": 0.878630802500993, "Avg value loss": 0.5277977680088952, "Avg policy loss": 0.35083304019644856, "Total num played games": 12376, "Total num trained steps": 24192, "Timestamp in ms": 1702011498584, "logtype": "training_step"}
{"Avg objective": 20.625, "Games time in secs": 222.98090828210115, "Avg game time in secs": 13.824200025759637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 1.41, "agent_stopped_0": 0.59}, "Total num played games": 12416, "Total num trained steps": 24269, "Timestamp in ms": 1702011536966, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9527862534125582, "Avg loss": 0.7683673915453255, "Avg value loss": 0.4219077354064211, "Avg policy loss": 0.346459653461352, "Total num played games": 12454, "Total num trained steps": 24320, "Timestamp in ms": 1702011560830, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9586604710783528, "Avg loss": 0.6148332366719842, "Avg value loss": 0.2707537008682266, "Avg policy loss": 0.34407953848131, "Total num played games": 12482, "Total num trained steps": 24448, "Timestamp in ms": 1702011623111, "logtype": "training_step"}
{"Avg objective": 20.1484375, "Games time in secs": 99.92970945686102, "Avg game time in secs": 17.29707843082724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.48, "played_steps": 1.79, "reached_maximum_moves": 0.02}, "Total num played games": 12544, "Total num trained steps": 24476, "Timestamp in ms": 1702011636896, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9554423933800127, "Avg loss": 0.9173313740175217, "Avg value loss": 0.5658696435857564, "Avg policy loss": 0.35146172204986215, "Total num played games": 12568, "Total num trained steps": 24576, "Timestamp in ms": 1702011687368, "logtype": "training_step"}
{"Avg objective": 20.078125, "Games time in secs": 178.2194168418646, "Avg game time in secs": 22.98014816941577, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.890625, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 2.79, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.34}, "Total num played games": 12672, "Total num trained steps": 24676, "Timestamp in ms": 1702011815116, "logtype": "played_game"}
{"Total num played games": 12674, "Total num trained steps": 24676, "Timestamp in ms": 1702011832057, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.28515625}
{"Ratio train steps to played games": 1.940534171249018, "Avg loss": 1.0052338077221066, "Avg value loss": 0.6497961177956313, "Avg policy loss": 0.3554376799147576, "Total num played games": 12730, "Total num trained steps": 24704, "Timestamp in ms": 1702011846805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.944862155388471, "Avg loss": 1.0222590351477265, "Avg value loss": 0.6491205646889284, "Avg policy loss": 0.3731384740676731, "Total num played games": 12768, "Total num trained steps": 24832, "Timestamp in ms": 1702011910160, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9548872180451127, "Avg loss": 0.5811953232623637, "Avg value loss": 0.22432005836162716, "Avg policy loss": 0.35687526129186153, "Total num played games": 12768, "Total num trained steps": 24960, "Timestamp in ms": 1702011975725, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 204.17138523235917, "Avg game time in secs": 12.26018731467775, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"reached_maximum_moves": 0.01, "played_steps": 1.21, "agent_stopped_0": 0.52, "agent_stopped_more": 0.47}, "Total num played games": 12800, "Total num trained steps": 25048, "Timestamp in ms": 1702012019288, "logtype": "played_game"}
{"Ratio train steps to played games": 1.954502960423808, "Avg loss": 0.8270722094457597, "Avg value loss": 0.48508577834581956, "Avg policy loss": 0.3419864308089018, "Total num played games": 12836, "Total num trained steps": 25088, "Timestamp in ms": 1702012038252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9608087091757387, "Avg loss": 0.6213356095831841, "Avg value loss": 0.2766738230129704, "Avg policy loss": 0.3446617852896452, "Total num played games": 12860, "Total num trained steps": 25216, "Timestamp in ms": 1702012100829, "logtype": "training_step"}
{"Avg objective": 20.59375, "Games time in secs": 96.12320946902037, "Avg game time in secs": 17.577351724583423, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.56, "played_steps": 1.94, "reached_maximum_moves": 0.02}, "Total num played games": 12928, "Total num trained steps": 25247, "Timestamp in ms": 1702012115411, "logtype": "played_game"}
{"Total num played games": 12964, "Total num trained steps": 25278, "Timestamp in ms": 1702012222661, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.546875}
{"Ratio train steps to played games": 1.943779720816076, "Avg loss": 1.0370398117229342, "Avg value loss": 0.683808728819713, "Avg policy loss": 0.3532310831360519, "Total num played games": 13038, "Total num trained steps": 25344, "Timestamp in ms": 1702012256192, "logtype": "training_step"}
{"Avg objective": 20.3359375, "Games time in secs": 192.756271276623, "Avg game time in secs": 19.746639895514818, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 2.14, "agent_stopped_0": 0.44, "reached_maximum_moves": 0.02}, "Total num played games": 13056, "Total num trained steps": 25448, "Timestamp in ms": 1702012308167, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9509803921568627, "Avg loss": 0.6566145175602287, "Avg value loss": 0.31601543037686497, "Avg policy loss": 0.3405990907922387, "Total num played games": 13056, "Total num trained steps": 25472, "Timestamp in ms": 1702012319447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9604839944861387, "Avg loss": 0.5087546391878277, "Avg value loss": 0.17953136493451893, "Avg policy loss": 0.3292232744861394, "Total num played games": 13058, "Total num trained steps": 25600, "Timestamp in ms": 1702012381618, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9561283454987834, "Avg loss": 0.8309181204531342, "Avg value loss": 0.4983832933357917, "Avg policy loss": 0.3325348263606429, "Total num played games": 13152, "Total num trained steps": 25728, "Timestamp in ms": 1702012441785, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 175.33089857921004, "Avg game time in secs": 10.828614692087285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"reached_maximum_moves": 0.01, "played_steps": 0.95, "agent_stopped_0": 0.64, "agent_stopped_more": 0.35}, "Total num played games": 13184, "Total num trained steps": 25809, "Timestamp in ms": 1702012483499, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9528700906344412, "Avg loss": 1.0574464311357588, "Avg value loss": 0.7292356299003586, "Avg policy loss": 0.32821079553104937, "Total num played games": 13240, "Total num trained steps": 25856, "Timestamp in ms": 1702012506978, "logtype": "training_step"}
{"Total num played games": 13252, "Total num trained steps": 25880, "Timestamp in ms": 1702012632007, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.0390625}
{"Avg objective": 21.078125, "Games time in secs": 164.4153798520565, "Avg game time in secs": 15.736854411981767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 1.67, "agent_stopped_0": 0.44, "reached_maximum_moves": 0.02}, "Total num played games": 13312, "Total num trained steps": 25911, "Timestamp in ms": 1702012647914, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9481181586444745, "Avg loss": 1.0357657792046666, "Avg value loss": 0.6780728010926396, "Avg policy loss": 0.3576929762493819, "Total num played games": 13338, "Total num trained steps": 25984, "Timestamp in ms": 1702012682891, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9568345323741008, "Avg loss": 0.5666149670723826, "Avg value loss": 0.22517034248448908, "Avg policy loss": 0.3414446266833693, "Total num played games": 13344, "Total num trained steps": 26112, "Timestamp in ms": 1702012748556, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9552160953800297, "Avg loss": 0.7431965637952089, "Avg value loss": 0.4131956985220313, "Avg policy loss": 0.33000085898675025, "Total num played games": 13420, "Total num trained steps": 26240, "Timestamp in ms": 1702012809301, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 214.0958813689649, "Avg game time in secs": 19.87198645895114, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 2.13, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.01}, "Total num played games": 13440, "Total num trained steps": 26345, "Timestamp in ms": 1702012862010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9616128552298766, "Avg loss": 0.663141731871292, "Avg value loss": 0.32230444077868015, "Avg policy loss": 0.34083729633130133, "Total num played games": 13442, "Total num trained steps": 26368, "Timestamp in ms": 1702012873063, "logtype": "training_step"}
{"Total num played games": 13544, "Total num trained steps": 26482, "Timestamp in ms": 1702013039941, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.83203125}
{"Ratio train steps to played games": 1.9531180893409996, "Avg loss": 1.08910599257797, "Avg value loss": 0.7458553836913779, "Avg policy loss": 0.3432506069075316, "Total num played games": 13566, "Total num trained steps": 26496, "Timestamp in ms": 1702013047039, "logtype": "training_step"}
{"Avg objective": 22.546875, "Games time in secs": 185.5748872719705, "Avg game time in secs": 16.478344964474672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 1.73, "agent_stopped_0": 0.52, "reached_maximum_moves": 0.02}, "Total num played games": 13568, "Total num trained steps": 26497, "Timestamp in ms": 1702013047585, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9524787327662072, "Avg loss": 1.1299209976568818, "Avg value loss": 0.7738284132210538, "Avg policy loss": 0.35609257919713855, "Total num played games": 13636, "Total num trained steps": 26624, "Timestamp in ms": 1702013110302, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9615779439800558, "Avg loss": 0.5450228133704513, "Avg value loss": 0.20374408608768135, "Avg policy loss": 0.3412787322886288, "Total num played games": 13638, "Total num trained steps": 26752, "Timestamp in ms": 1702013172245, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 146.04853893071413, "Avg game time in secs": 12.975127764249919, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 1.17}, "Total num played games": 13696, "Total num trained steps": 26797, "Timestamp in ms": 1702013193634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9583272621302636, "Avg loss": 0.8629002317320555, "Avg value loss": 0.5292079633218236, "Avg policy loss": 0.3336922636954114, "Total num played games": 13726, "Total num trained steps": 26880, "Timestamp in ms": 1702013233366, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9551179962357028, "Avg loss": 0.8226155543234199, "Avg value loss": 0.4919052114710212, "Avg policy loss": 0.3307103463448584, "Total num played games": 13814, "Total num trained steps": 27008, "Timestamp in ms": 1702013294620, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 133.8636306449771, "Avg game time in secs": 18.59017843991751, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.921875, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 1.96, "agent_stopped_0": 0.36}, "Total num played games": 13824, "Total num trained steps": 27072, "Timestamp in ms": 1702013327498, "logtype": "played_game"}
{"Total num played games": 13830, "Total num trained steps": 27082, "Timestamp in ms": 1702013454003, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.3671875}
{"Ratio train steps to played games": 1.9530732690369943, "Avg loss": 1.095068502239883, "Avg value loss": 0.739847230957821, "Avg policy loss": 0.35522126965224743, "Total num played games": 13894, "Total num trained steps": 27136, "Timestamp in ms": 1702013479542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9586206896551723, "Avg loss": 0.7331236368045211, "Avg value loss": 0.3775725362356752, "Avg policy loss": 0.3555510984733701, "Total num played games": 13920, "Total num trained steps": 27264, "Timestamp in ms": 1702013539295, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 250.71479622647166, "Avg game time in secs": 19.100488941709045, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 1.98, "reached_maximum_moves": 0.02, "agent_stopped_0": 0.48}, "Total num played games": 13952, "Total num trained steps": 27348, "Timestamp in ms": 1702013578212, "logtype": "played_game"}
{"Ratio train steps to played games": 1.955174875089222, "Avg loss": 1.302358993794769, "Avg value loss": 0.9470143787912093, "Avg policy loss": 0.35534461634233594, "Total num played games": 14010, "Total num trained steps": 27392, "Timestamp in ms": 1702013599264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9634703196347032, "Avg loss": 0.7845862188842148, "Avg value loss": 0.42042057414073497, "Avg policy loss": 0.3641656453255564, "Total num played games": 14016, "Total num trained steps": 27520, "Timestamp in ms": 1702013664180, "logtype": "training_step"}
{"Avg objective": 22.7734375, "Games time in secs": 103.81328328698874, "Avg game time in secs": 13.027812204643851, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 1.46, "agent_stopped_0": 0.43, "reached_maximum_moves": 0.02}, "Total num played games": 14080, "Total num trained steps": 27558, "Timestamp in ms": 1702013682026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9594613749114103, "Avg loss": 0.7783942341338843, "Avg value loss": 0.41789668053388596, "Avg policy loss": 0.36049755779094994, "Total num played games": 14110, "Total num trained steps": 27648, "Timestamp in ms": 1702013725536, "logtype": "training_step"}
{"Total num played games": 14116, "Total num trained steps": 27683, "Timestamp in ms": 1702013853190, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.10546875}
{"Ratio train steps to played games": 1.9557808759329671, "Avg loss": 0.8328260260168463, "Avg value loss": 0.46470902813598514, "Avg policy loss": 0.3681170006748289, "Total num played games": 14202, "Total num trained steps": 27776, "Timestamp in ms": 1702013898068, "logtype": "training_step"}
{"Avg objective": 19.578125, "Games time in secs": 240.46811283752322, "Avg game time in secs": 16.25403080828255, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.96875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 1.86, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.01}, "Total num played games": 14208, "Total num trained steps": 27825, "Timestamp in ms": 1702013922494, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9639639639639639, "Avg loss": 0.5875808123964816, "Avg value loss": 0.22261181398062035, "Avg policy loss": 0.36496899416670203, "Total num played games": 14208, "Total num trained steps": 27904, "Timestamp in ms": 1702013962880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960553923625682, "Avg loss": 0.9798281250987202, "Avg value loss": 0.6198519491008483, "Avg policy loss": 0.35997617547400296, "Total num played games": 14298, "Total num trained steps": 28032, "Timestamp in ms": 1702014025203, "logtype": "training_step"}
{"Avg objective": 22.1015625, "Games time in secs": 138.74647176265717, "Avg game time in secs": 9.65194098628126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.93}, "Total num played games": 14336, "Total num trained steps": 28108, "Timestamp in ms": 1702014061241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9588202559821926, "Avg loss": 0.71695751324296, "Avg value loss": 0.3692935900762677, "Avg policy loss": 0.34766392270103097, "Total num played games": 14376, "Total num trained steps": 28160, "Timestamp in ms": 1702014085588, "logtype": "training_step"}
{"Avg objective": 20.296875, "Games time in secs": 99.30117719620466, "Avg game time in secs": 16.651093213265995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7890625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.51, "played_steps": 1.84, "reached_maximum_moves": 0.02}, "Total num played games": 14464, "Total num trained steps": 28287, "Timestamp in ms": 1702014160542, "logtype": "played_game"}
{"Total num played games": 14490, "Total num trained steps": 28287, "Timestamp in ms": 1702014264942, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 31.2109375}
{"Ratio train steps to played games": 1.9522429261559697, "Avg loss": 0.6483125374652445, "Avg value loss": 0.3018879306036979, "Avg policy loss": 0.3464246039511636, "Total num played games": 14490, "Total num trained steps": 28288, "Timestamp in ms": 1702014265942, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9497735693701113, "Avg loss": 1.385267250239849, "Avg value loss": 1.0089477121364325, "Avg policy loss": 0.3763195453211665, "Total num played games": 14574, "Total num trained steps": 28416, "Timestamp in ms": 1702014326484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9574132492113565, "Avg loss": 0.7145083218347281, "Avg value loss": 0.3471604568185285, "Avg policy loss": 0.36734786396846175, "Total num played games": 14582, "Total num trained steps": 28544, "Timestamp in ms": 1702014390891, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 291.26868733018637, "Avg game time in secs": 19.172247966576833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.859375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 2.23, "agent_stopped_0": 0.35, "reached_maximum_moves": 0.01}, "Total num played games": 14592, "Total num trained steps": 28668, "Timestamp in ms": 1702014451811, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9635666347075742, "Avg loss": 0.5229088268242776, "Avg value loss": 0.17481927812332287, "Avg policy loss": 0.34808954945765436, "Total num played games": 14602, "Total num trained steps": 28672, "Timestamp in ms": 1702014453597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9615856150388231, "Avg loss": 0.8954919311217964, "Avg value loss": 0.5363448827993125, "Avg policy loss": 0.3591470381943509, "Total num played games": 14682, "Total num trained steps": 28800, "Timestamp in ms": 1702014515875, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 96.6141437664628, "Avg game time in secs": 11.531934970087605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 1.01}, "Total num played games": 14720, "Total num trained steps": 28867, "Timestamp in ms": 1702014548425, "logtype": "played_game"}
{"Total num played games": 14782, "Total num trained steps": 28888, "Timestamp in ms": 1702014715377, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.15234375}
{"Avg objective": 21.546875, "Games time in secs": 184.05895898863673, "Avg game time in secs": 11.85393411613768, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 1.23}, "Total num played games": 14848, "Total num trained steps": 28921, "Timestamp in ms": 1702014732484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9479461279461279, "Avg loss": 1.330556563101709, "Avg value loss": 0.9605867045465857, "Avg policy loss": 0.3699698329437524, "Total num played games": 14850, "Total num trained steps": 28928, "Timestamp in ms": 1702014735654, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9537385691231846, "Avg loss": 0.8018302859272808, "Avg value loss": 0.43337477825116366, "Avg policy loss": 0.3684555063955486, "Total num played games": 14872, "Total num trained steps": 29056, "Timestamp in ms": 1702014796371, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9617504705566013, "Avg loss": 0.5322169517166913, "Avg value loss": 0.1878762884880416, "Avg policy loss": 0.34434066293761134, "Total num played games": 14876, "Total num trained steps": 29184, "Timestamp in ms": 1702014859834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9590963774896404, "Avg loss": 0.7090524907689542, "Avg value loss": 0.378684846451506, "Avg policy loss": 0.33036765223369, "Total num played games": 14962, "Total num trained steps": 29312, "Timestamp in ms": 1702014921677, "logtype": "training_step"}
{"Avg objective": 20.21875, "Games time in secs": 246.49150947481394, "Avg game time in secs": 14.058966341923224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 1.57, "agent_stopped_0": 0.52}, "Total num played games": 14976, "Total num trained steps": 29431, "Timestamp in ms": 1702014978976, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9629283904520602, "Avg loss": 0.5793886566534638, "Avg value loss": 0.24599447514628991, "Avg policy loss": 0.3333941828459501, "Total num played games": 14998, "Total num trained steps": 29440, "Timestamp in ms": 1702014982721, "logtype": "training_step"}
{"Total num played games": 15064, "Total num trained steps": 29488, "Timestamp in ms": 1702015125322, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.01171875}
{"Avg objective": 21.734375, "Games time in secs": 157.89633502066135, "Avg game time in secs": 16.940907833602978, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.51, "played_steps": 1.98, "reached_maximum_moves": 0.01}, "Total num played games": 15104, "Total num trained steps": 29508, "Timestamp in ms": 1702015136873, "logtype": "played_game"}
{"Ratio train steps to played games": 1.952132576257758, "Avg loss": 1.3525146637111902, "Avg value loss": 0.9979748108889908, "Avg policy loss": 0.3545398546848446, "Total num played games": 15146, "Total num trained steps": 29568, "Timestamp in ms": 1702015166525, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9596146232017948, "Avg loss": 0.5876713083125651, "Avg value loss": 0.24283084098715335, "Avg policy loss": 0.34484047000296414, "Total num played games": 15154, "Total num trained steps": 29696, "Timestamp in ms": 1702015231703, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9621052631578948, "Avg loss": 0.6153188159223646, "Avg value loss": 0.2952184088062495, "Avg policy loss": 0.320100407814607, "Total num played games": 15200, "Total num trained steps": 29824, "Timestamp in ms": 1702015293083, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 170.7396230623126, "Avg game time in secs": 16.26106150439591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.953125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 1.81, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.02}, "Total num played games": 15232, "Total num trained steps": 29854, "Timestamp in ms": 1702015307612, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9640655737704917, "Avg loss": 0.7615197817794979, "Avg value loss": 0.42412130086449906, "Avg policy loss": 0.33739848039112985, "Total num played games": 15250, "Total num trained steps": 29952, "Timestamp in ms": 1702015356879, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960565767175075, "Avg loss": 1.180640768026933, "Avg value loss": 0.8435387633508071, "Avg policy loss": 0.33710199361667037, "Total num played games": 15342, "Total num trained steps": 30080, "Timestamp in ms": 1702015420753, "logtype": "training_step"}
{"Total num played games": 15352, "Total num trained steps": 30090, "Timestamp in ms": 1702015537135, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 30.390625}
{"Avg objective": 20.9921875, "Games time in secs": 234.58710313215852, "Avg game time in secs": 17.779757527721813, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.765625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 2.09, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.01}, "Total num played games": 15360, "Total num trained steps": 30100, "Timestamp in ms": 1702015542199, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9574909279419388, "Avg loss": 0.8508229511789978, "Avg value loss": 0.515286163194105, "Avg policy loss": 0.33553679729811847, "Total num played games": 15432, "Total num trained steps": 30208, "Timestamp in ms": 1702015596272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964003625534119, "Avg loss": 0.5829864139668643, "Avg value loss": 0.2584753562696278, "Avg policy loss": 0.32451105874497443, "Total num played games": 15446, "Total num trained steps": 30336, "Timestamp in ms": 1702015662789, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 154.8708236142993, "Avg game time in secs": 15.733210292557487, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.45, "played_steps": 1.67, "reached_maximum_moves": 0.02}, "Total num played games": 15488, "Total num trained steps": 30406, "Timestamp in ms": 1702015697070, "logtype": "played_game"}
{"Ratio train steps to played games": 1.959855892949048, "Avg loss": 0.7427772271912545, "Avg value loss": 0.42288757249480113, "Avg policy loss": 0.3198896513786167, "Total num played games": 15544, "Total num trained steps": 30464, "Timestamp in ms": 1702015725230, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9675842552096732, "Avg loss": 0.5123527108225971, "Avg value loss": 0.1853316083434038, "Avg policy loss": 0.3270211035851389, "Total num played games": 15548, "Total num trained steps": 30592, "Timestamp in ms": 1702015789141, "logtype": "training_step"}
{"Avg objective": 20.4609375, "Games time in secs": 107.4027288928628, "Avg game time in secs": 12.495052557816962, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 1.17, "agent_stopped_0": 0.43}, "Total num played games": 15616, "Total num trained steps": 30624, "Timestamp in ms": 1702015804473, "logtype": "played_game"}
{"Total num played games": 15648, "Total num trained steps": 30691, "Timestamp in ms": 1702015955573, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.38671875}
{"Ratio train steps to played games": 1.956687898089172, "Avg loss": 1.1558195364195853, "Avg value loss": 0.8327964668860659, "Avg policy loss": 0.32302307488862425, "Total num played games": 15700, "Total num trained steps": 30720, "Timestamp in ms": 1702015970355, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960033041047147, "Avg loss": 0.7164290321525186, "Avg value loss": 0.3885367986513302, "Avg policy loss": 0.327892231522128, "Total num played games": 15738, "Total num trained steps": 30848, "Timestamp in ms": 1702016035460, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9677296404522933, "Avg loss": 0.47199942311272025, "Avg value loss": 0.1626889498438686, "Avg policy loss": 0.30931047385092825, "Total num played games": 15742, "Total num trained steps": 30976, "Timestamp in ms": 1702016100733, "logtype": "training_step"}
{"Avg objective": 19.8515625, "Games time in secs": 296.91570231318474, "Avg game time in secs": 19.073377660126425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6953125, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 2.26, "agent_stopped_0": 0.38, "reached_maximum_moves": 0.02}, "Total num played games": 15744, "Total num trained steps": 30977, "Timestamp in ms": 1702016101389, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9643172919034988, "Avg loss": 0.7828540145419538, "Avg value loss": 0.47015611233655363, "Avg policy loss": 0.3126978985965252, "Total num played games": 15834, "Total num trained steps": 31104, "Timestamp in ms": 1702016164010, "logtype": "training_step"}
{"Avg objective": 21.40625, "Games time in secs": 101.98871620371938, "Avg game time in secs": 11.956172687932849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 1.26}, "Total num played games": 15872, "Total num trained steps": 31185, "Timestamp in ms": 1702016203378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9637826961770624, "Avg loss": 0.7535357426386327, "Avg value loss": 0.443635432748124, "Avg policy loss": 0.30990031245164573, "Total num played games": 15904, "Total num trained steps": 31232, "Timestamp in ms": 1702016226176, "logtype": "training_step"}
{"Total num played games": 15936, "Total num trained steps": 31291, "Timestamp in ms": 1702016356483, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.27734375}
{"Avg objective": 20.6796875, "Games time in secs": 172.05188109725714, "Avg game time in secs": 18.19898754681344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 1.88}, "Total num played games": 16000, "Total num trained steps": 31331, "Timestamp in ms": 1702016375430, "logtype": "played_game"}
{"Ratio train steps to played games": 1.957797477837433, "Avg loss": 0.9306391733698547, "Avg value loss": 0.604393778485246, "Avg policy loss": 0.32624539895914495, "Total num played games": 16018, "Total num trained steps": 31360, "Timestamp in ms": 1702016389033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9645620164711755, "Avg loss": 0.5991322742775083, "Avg value loss": 0.2784590353840031, "Avg policy loss": 0.3206732355756685, "Total num played games": 16028, "Total num trained steps": 31488, "Timestamp in ms": 1702016452834, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9622641509433962, "Avg loss": 0.8097699955105782, "Avg value loss": 0.4970180322416127, "Avg policy loss": 0.31275196641217917, "Total num played games": 16112, "Total num trained steps": 31616, "Timestamp in ms": 1702016512605, "logtype": "training_step"}
{"Avg objective": 20.390625, "Games time in secs": 177.3947978578508, "Avg game time in secs": 16.85255075650639, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 2.05, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.02}, "Total num played games": 16128, "Total num trained steps": 31700, "Timestamp in ms": 1702016552825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9682539682539681, "Avg loss": 0.5506327070761472, "Avg value loss": 0.2347817209083587, "Avg policy loss": 0.3158509833738208, "Total num played games": 16128, "Total num trained steps": 31744, "Timestamp in ms": 1702016574686, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9652238253792083, "Avg loss": 0.7000939161516726, "Avg value loss": 0.3907122070668265, "Avg policy loss": 0.30938171420712024, "Total num played games": 16218, "Total num trained steps": 31872, "Timestamp in ms": 1702016634252, "logtype": "training_step"}
{"Total num played games": 16226, "Total num trained steps": 31891, "Timestamp in ms": 1702016736065, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.50390625}
{"Avg objective": 21.5546875, "Games time in secs": 190.80087449774146, "Avg game time in secs": 12.825448452174896, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 1.4, "reached_maximum_moves": 0.01}, "Total num played games": 16256, "Total num trained steps": 31907, "Timestamp in ms": 1702016743626, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9607843137254901, "Avg loss": 0.8645496016833931, "Avg value loss": 0.5478720646351576, "Avg policy loss": 0.3166775320423767, "Total num played games": 16320, "Total num trained steps": 32000, "Timestamp in ms": 1702016788551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.968627450980392, "Avg loss": 0.4838575846515596, "Avg value loss": 0.17606201535090804, "Avg policy loss": 0.3077955699991435, "Total num played games": 16320, "Total num trained steps": 32128, "Timestamp in ms": 1702016853609, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 127.18867183104157, "Avg game time in secs": 10.910197449091356, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.98}, "Total num played games": 16384, "Total num trained steps": 32164, "Timestamp in ms": 1702016870815, "logtype": "played_game"}
{"Ratio train steps to played games": 1.964672919965891, "Avg loss": 0.7366722696460783, "Avg value loss": 0.4319389830925502, "Avg policy loss": 0.30473328894004226, "Total num played games": 16418, "Total num trained steps": 32256, "Timestamp in ms": 1702016917794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9621909840038778, "Avg loss": 0.8391337424982339, "Avg value loss": 0.5372420526691712, "Avg policy loss": 0.3018916988512501, "Total num played games": 16504, "Total num trained steps": 32384, "Timestamp in ms": 1702016979271, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 116.47227774560452, "Avg game time in secs": 13.528254245204153, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 1.47, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.02}, "Total num played games": 16512, "Total num trained steps": 32398, "Timestamp in ms": 1702016987287, "logtype": "played_game"}
{"Total num played games": 16516, "Total num trained steps": 32492, "Timestamp in ms": 1702017140421, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.71484375}
{"Ratio train steps to played games": 1.9637593621647742, "Avg loss": 0.6162602198310196, "Avg value loss": 0.31106423056917265, "Avg policy loss": 0.3051959907170385, "Total num played games": 16556, "Total num trained steps": 32512, "Timestamp in ms": 1702017150138, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9660281893747742, "Avg loss": 0.7398487539030612, "Avg value loss": 0.4380876695504412, "Avg policy loss": 0.3017610792303458, "Total num played games": 16602, "Total num trained steps": 32640, "Timestamp in ms": 1702017210687, "logtype": "training_step"}
{"Avg objective": 22.453125, "Games time in secs": 259.25507920980453, "Avg game time in secs": 11.67491133508156, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 1.22, "agent_stopped_0": 0.61, "reached_maximum_moves": 0.02}, "Total num played games": 16640, "Total num trained steps": 32715, "Timestamp in ms": 1702017246542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9635666347075742, "Avg loss": 0.7650917193386704, "Avg value loss": 0.4667453427100554, "Avg policy loss": 0.29834637558087707, "Total num played games": 16688, "Total num trained steps": 32768, "Timestamp in ms": 1702017269828, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9693486590038314, "Avg loss": 0.5724558532238007, "Avg value loss": 0.2745565570658073, "Avg policy loss": 0.29789929499384016, "Total num played games": 16704, "Total num trained steps": 32896, "Timestamp in ms": 1702017331566, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 103.36840649694204, "Avg game time in secs": 15.679794217576273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 1.83, "agent_stopped_0": 0.39, "reached_maximum_moves": 0.02}, "Total num played games": 16768, "Total num trained steps": 32932, "Timestamp in ms": 1702017349911, "logtype": "played_game"}
{"Ratio train steps to played games": 1.967353747170261, "Avg loss": 0.9487480404786766, "Avg value loss": 0.6417398931225762, "Avg policy loss": 0.30700813606381416, "Total num played games": 16786, "Total num trained steps": 33024, "Timestamp in ms": 1702017394432, "logtype": "training_step"}
{"Total num played games": 16884, "Total num trained steps": 33093, "Timestamp in ms": 1702017517687, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.4765625}
{"Avg objective": 21.5546875, "Games time in secs": 173.1234388947487, "Avg game time in secs": 17.977927187865134, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.84375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.48, "played_steps": 2.17, "reached_maximum_moves": 0.02}, "Total num played games": 16896, "Total num trained steps": 33104, "Timestamp in ms": 1702017523034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9558702064896756, "Avg loss": 1.2020261730067432, "Avg value loss": 0.8777717439224944, "Avg policy loss": 0.324254427687265, "Total num played games": 16948, "Total num trained steps": 33152, "Timestamp in ms": 1702017545254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.960645693413456, "Avg loss": 0.7366529768332839, "Avg value loss": 0.4013104219920933, "Avg policy loss": 0.335342553909868, "Total num played games": 16974, "Total num trained steps": 33280, "Timestamp in ms": 1702017606356, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9677229355636707, "Avg loss": 0.5318917720578611, "Avg value loss": 0.21671613480430096, "Avg policy loss": 0.3151756356237456, "Total num played games": 16978, "Total num trained steps": 33408, "Timestamp in ms": 1702017668876, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 170.27201152220368, "Avg game time in secs": 15.848586389969569, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "reached_maximum_moves": 0.02, "played_steps": 1.8, "agent_stopped_more": 0.48}, "Total num played games": 17024, "Total num trained steps": 33461, "Timestamp in ms": 1702017693307, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9655374516469346, "Avg loss": 0.6810182617045939, "Avg value loss": 0.37807764613535255, "Avg policy loss": 0.3029406218556687, "Total num played games": 17062, "Total num trained steps": 33536, "Timestamp in ms": 1702017729713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9647484533675732, "Avg loss": 0.5620999997481704, "Avg value loss": 0.25951544556301087, "Avg policy loss": 0.30258455174043775, "Total num played games": 17134, "Total num trained steps": 33664, "Timestamp in ms": 1702017789483, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 106.49447122588754, "Avg game time in secs": 12.328639774437761, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 1.27, "reached_maximum_moves": 0.01}, "Total num played games": 17152, "Total num trained steps": 33686, "Timestamp in ms": 1702017799801, "logtype": "played_game"}
{"Total num played games": 17172, "Total num trained steps": 33696, "Timestamp in ms": 1702017895330, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.390625}
{"Ratio train steps to played games": 1.9582753824756607, "Avg loss": 0.8497060483787209, "Avg value loss": 0.5359825482591987, "Avg policy loss": 0.3137234941823408, "Total num played games": 17256, "Total num trained steps": 33792, "Timestamp in ms": 1702017939420, "logtype": "training_step"}
{"Ratio train steps to played games": 1.964724281742354, "Avg loss": 0.5088691909331828, "Avg value loss": 0.19935548421926796, "Avg policy loss": 0.30951370554976165, "Total num played games": 17264, "Total num trained steps": 33920, "Timestamp in ms": 1702018001016, "logtype": "training_step"}
{"Avg objective": 20.0078125, "Games time in secs": 254.00440600141883, "Avg game time in secs": 18.440190936991712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.78125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.48, "played_steps": 2.21, "reached_maximum_moves": 0.02}, "Total num played games": 17280, "Total num trained steps": 34032, "Timestamp in ms": 1702018053806, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9644588045234248, "Avg loss": 0.5076273658778518, "Avg value loss": 0.20497907738899812, "Avg policy loss": 0.30264828773215413, "Total num played games": 17332, "Total num trained steps": 34048, "Timestamp in ms": 1702018060727, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9682100898410504, "Avg loss": 0.7634891357738525, "Avg value loss": 0.4565509164240211, "Avg policy loss": 0.3069382121320814, "Total num played games": 17364, "Total num trained steps": 34176, "Timestamp in ms": 1702018122101, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 100.84047946333885, "Avg game time in secs": 9.524336793081602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.92}, "Total num played games": 17408, "Total num trained steps": 34244, "Timestamp in ms": 1702018154646, "logtype": "played_game"}
{"Total num played games": 17464, "Total num trained steps": 34299, "Timestamp in ms": 1702018271204, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.91796875}
{"Ratio train steps to played games": 1.964044429176686, "Avg loss": 0.7218334225472063, "Avg value loss": 0.4251190418144688, "Avg policy loss": 0.2967143871355802, "Total num played games": 17466, "Total num trained steps": 34304, "Timestamp in ms": 1702018274964, "logtype": "training_step"}
{"Avg objective": 20.7265625, "Games time in secs": 135.6751052327454, "Avg game time in secs": 13.176610134280054, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 1.48, "agent_stopped_0": 0.43}, "Total num played games": 17536, "Total num trained steps": 34335, "Timestamp in ms": 1702018290322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9614902586305116, "Avg loss": 0.8396084164269269, "Avg value loss": 0.5243919185595587, "Avg policy loss": 0.31521649670321494, "Total num played games": 17554, "Total num trained steps": 34432, "Timestamp in ms": 1702018337088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9685577580314422, "Avg loss": 0.44498132914304733, "Avg value loss": 0.15275851945625618, "Avg policy loss": 0.292222807998769, "Total num played games": 17556, "Total num trained steps": 34560, "Timestamp in ms": 1702018398908, "logtype": "training_step"}
{"Ratio train steps to played games": 1.96577127961011, "Avg loss": 0.6688664723187685, "Avg value loss": 0.3735755071975291, "Avg policy loss": 0.29529095569159836, "Total num played games": 17646, "Total num trained steps": 34688, "Timestamp in ms": 1702018462726, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 233.2946637906134, "Avg game time in secs": 13.81652121519437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 1.62, "agent_stopped_0": 0.51, "reached_maximum_moves": 0.01}, "Total num played games": 17664, "Total num trained steps": 34806, "Timestamp in ms": 1702018523616, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9678950938277187, "Avg loss": 0.5490411238279194, "Avg value loss": 0.2612850645673461, "Avg policy loss": 0.28775605757255107, "Total num played games": 17692, "Total num trained steps": 34816, "Timestamp in ms": 1702018527991, "logtype": "training_step"}
{"Total num played games": 17752, "Total num trained steps": 34901, "Timestamp in ms": 1702018695348, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.81640625}
{"Avg objective": 21.609375, "Games time in secs": 180.95937935635448, "Avg game time in secs": 13.281012809078675, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 1.51, "reached_maximum_moves": 0.01}, "Total num played games": 17792, "Total num trained steps": 34921, "Timestamp in ms": 1702018704576, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9607227022780833, "Avg loss": 0.9956411486491561, "Avg value loss": 0.6932623567990959, "Avg policy loss": 0.30237879033666104, "Total num played games": 17822, "Total num trained steps": 34944, "Timestamp in ms": 1702018714931, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9654225509975343, "Avg loss": 0.6309723551385105, "Avg value loss": 0.3171270259190351, "Avg policy loss": 0.3138453308492899, "Total num played games": 17844, "Total num trained steps": 35072, "Timestamp in ms": 1702018775137, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9686241610738255, "Avg loss": 0.46120041445828974, "Avg value loss": 0.16805567761184648, "Avg policy loss": 0.2931447360897437, "Total num played games": 17880, "Total num trained steps": 35200, "Timestamp in ms": 1702018834754, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 140.12749887257814, "Avg game time in secs": 13.002700758894207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 1.41}, "Total num played games": 17920, "Total num trained steps": 35221, "Timestamp in ms": 1702018844704, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9687360677663843, "Avg loss": 0.6645744009874761, "Avg value loss": 0.37207468959968537, "Avg policy loss": 0.2924997181398794, "Total num played games": 17944, "Total num trained steps": 35328, "Timestamp in ms": 1702018895886, "logtype": "training_step"}
{"Ratio train steps to played games": 1.96693664706535, "Avg loss": 0.6214024068322033, "Avg value loss": 0.33624207373941317, "Avg policy loss": 0.28516032733023167, "Total num played games": 18026, "Total num trained steps": 35456, "Timestamp in ms": 1702018955106, "logtype": "training_step"}
{"Total num played games": 18046, "Total num trained steps": 35501, "Timestamp in ms": 1702019085129, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.19140625}
{"Avg objective": 20.4375, "Games time in secs": 242.71842209249735, "Avg game time in secs": 17.097777673130622, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.59, "played_steps": 2.16, "reached_maximum_moves": 0.02}, "Total num played games": 18048, "Total num trained steps": 35505, "Timestamp in ms": 1702019087422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9624972424442975, "Avg loss": 0.9081814717501402, "Avg value loss": 0.6085432027466595, "Avg policy loss": 0.29963826562743634, "Total num played games": 18132, "Total num trained steps": 35584, "Timestamp in ms": 1702019126461, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9686879823594268, "Avg loss": 0.4574587701354176, "Avg value loss": 0.1678680155891925, "Avg policy loss": 0.28959075501188636, "Total num played games": 18140, "Total num trained steps": 35712, "Timestamp in ms": 1702019193320, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 143.66679714247584, "Avg game time in secs": 10.843216275243321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 1.02}, "Total num played games": 18176, "Total num trained steps": 35790, "Timestamp in ms": 1702019231089, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9675010979358805, "Avg loss": 0.6534377110656351, "Avg value loss": 0.36564699397422373, "Avg policy loss": 0.28779071394819766, "Total num played games": 18216, "Total num trained steps": 35840, "Timestamp in ms": 1702019253633, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9717136278916785, "Avg loss": 0.49358392553403974, "Avg value loss": 0.21746466192416847, "Avg policy loss": 0.2761192674515769, "Total num played games": 18242, "Total num trained steps": 35968, "Timestamp in ms": 1702019317127, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 101.71295951679349, "Avg game time in secs": 13.885715540935053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 1.56, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.01}, "Total num played games": 18304, "Total num trained steps": 36002, "Timestamp in ms": 1702019332802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.7628867039456964, "Avg value loss": 0.4748852080665529, "Avg policy loss": 0.28800149145536125, "Total num played games": 18330, "Total num trained steps": 36096, "Timestamp in ms": 1702019378951, "logtype": "training_step"}
{"Total num played games": 18332, "Total num trained steps": 36105, "Timestamp in ms": 1702019511062, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.39453125}
{"Ratio train steps to played games": 1.9667173417309154, "Avg loss": 0.881084865424782, "Avg value loss": 0.5861530352849513, "Avg policy loss": 0.29493183246813715, "Total num played games": 18418, "Total num trained steps": 36224, "Timestamp in ms": 1702019566516, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 290.7676013596356, "Avg game time in secs": 16.235888390860055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 1.98, "agent_stopped_0": 0.4, "reached_maximum_moves": 0.01}, "Total num played games": 18432, "Total num trained steps": 36340, "Timestamp in ms": 1702019623570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9685909238600672, "Avg loss": 0.496545986039564, "Avg value loss": 0.22011588391615078, "Avg policy loss": 0.2764301054412499, "Total num played games": 18466, "Total num trained steps": 36352, "Timestamp in ms": 1702019628587, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9706136560069145, "Avg loss": 0.6733208852820098, "Avg value loss": 0.39415115577867255, "Avg policy loss": 0.2791697308421135, "Total num played games": 18512, "Total num trained steps": 36480, "Timestamp in ms": 1702019689606, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 95.05771239846945, "Avg game time in secs": 11.911882298561977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.37, "played_steps": 1.3, "reached_maximum_moves": 0.02}, "Total num played games": 18560, "Total num trained steps": 36537, "Timestamp in ms": 1702019718628, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9677488712104925, "Avg loss": 0.7327379966154695, "Avg value loss": 0.4463291566935368, "Avg policy loss": 0.2864088361384347, "Total num played games": 18604, "Total num trained steps": 36608, "Timestamp in ms": 1702019751232, "logtype": "training_step"}
{"Total num played games": 18614, "Total num trained steps": 36707, "Timestamp in ms": 1702019896667, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.78125}
{"Ratio train steps to played games": 1.9684921230307577, "Avg loss": 0.5322600090876222, "Avg value loss": 0.254340234445408, "Avg policy loss": 0.2779197774361819, "Total num played games": 18662, "Total num trained steps": 36736, "Timestamp in ms": 1702019910924, "logtype": "training_step"}
{"Avg objective": 21.875, "Games time in secs": 198.11800281703472, "Avg game time in secs": 15.958939421310788, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 1.88, "agent_stopped_0": 0.36, "reached_maximum_moves": 0.02}, "Total num played games": 18688, "Total num trained steps": 36747, "Timestamp in ms": 1702019916746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9711260827718962, "Avg loss": 0.6658397892024368, "Avg value loss": 0.38374056440079585, "Avg policy loss": 0.28209922811947763, "Total num played games": 18702, "Total num trained steps": 36864, "Timestamp in ms": 1702019973017, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9680783145350074, "Avg loss": 0.8969109999015927, "Avg value loss": 0.6216804711730219, "Avg policy loss": 0.27523052552714944, "Total num played games": 18796, "Total num trained steps": 36992, "Timestamp in ms": 1702020034126, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 171.03774455562234, "Avg game time in secs": 15.320138147828402, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 1.99, "agent_stopped_0": 0.49, "reached_maximum_moves": 0.02}, "Total num played games": 18816, "Total num trained steps": 37099, "Timestamp in ms": 1702020087784, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9671436142024377, "Avg loss": 0.5575430747121572, "Avg value loss": 0.2866721728350967, "Avg policy loss": 0.2708709016442299, "Total num played games": 18868, "Total num trained steps": 37120, "Timestamp in ms": 1702020096876, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9714194982534137, "Avg loss": 0.6572818092536181, "Avg value loss": 0.37621058139484376, "Avg policy loss": 0.28107122937217355, "Total num played games": 18894, "Total num trained steps": 37248, "Timestamp in ms": 1702020159936, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 99.7994109801948, "Avg game time in secs": 9.968679354409687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.796875, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.97, "agent_stopped_0": 0.51}, "Total num played games": 18944, "Total num trained steps": 37307, "Timestamp in ms": 1702020187584, "logtype": "played_game"}
{"Total num played games": 18992, "Total num trained steps": 37311, "Timestamp in ms": 1702020343203, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.3046875}
{"Avg objective": 19.8203125, "Games time in secs": 175.781325571239, "Avg game time in secs": 14.512652475794312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 1.73, "agent_stopped_0": 0.44, "reached_maximum_moves": 0.02}, "Total num played games": 19072, "Total num trained steps": 37353, "Timestamp in ms": 1702020363365, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9590627948422266, "Avg loss": 1.0631534142885357, "Avg value loss": 0.7734888843842782, "Avg policy loss": 0.28966452926397324, "Total num played games": 19078, "Total num trained steps": 37376, "Timestamp in ms": 1702020374199, "logtype": "training_step"}
{"Ratio train steps to played games": 1.965360025154596, "Avg loss": 0.5228409343399107, "Avg value loss": 0.22890274721430615, "Avg policy loss": 0.293938186718151, "Total num played games": 19082, "Total num trained steps": 37504, "Timestamp in ms": 1702020435105, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971654615948863, "Avg loss": 0.4112672184128314, "Avg value loss": 0.13348669605329633, "Avg policy loss": 0.27778052049688995, "Total num played games": 19086, "Total num trained steps": 37632, "Timestamp in ms": 1702020497372, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9689227239545313, "Avg loss": 0.749861546093598, "Avg value loss": 0.4681428667390719, "Avg policy loss": 0.28171867749188095, "Total num played games": 19178, "Total num trained steps": 37760, "Timestamp in ms": 1702020557199, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 242.91607388854027, "Avg game time in secs": 12.045076493755914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.49, "played_steps": 1.21, "reached_maximum_moves": 0.01}, "Total num played games": 19200, "Total num trained steps": 37862, "Timestamp in ms": 1702020606282, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9684123025768911, "Avg loss": 0.6118676837068051, "Avg value loss": 0.3328944410313852, "Avg policy loss": 0.2789732440141961, "Total num played games": 19248, "Total num trained steps": 37888, "Timestamp in ms": 1702020618812, "logtype": "training_step"}
{"Total num played games": 19278, "Total num trained steps": 37914, "Timestamp in ms": 1702020746845, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.78125}
{"Avg objective": 21.109375, "Games time in secs": 151.228036981076, "Avg game time in secs": 14.137079815787729, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.41, "played_steps": 1.55, "reached_maximum_moves": 0.02}, "Total num played games": 19328, "Total num trained steps": 37935, "Timestamp in ms": 1702020757510, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9634335295940502, "Avg loss": 0.9161157100461423, "Avg value loss": 0.6096252901479602, "Avg policy loss": 0.306490424554795, "Total num played games": 19362, "Total num trained steps": 38016, "Timestamp in ms": 1702020795028, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9690274623167459, "Avg loss": 0.5099040435161442, "Avg value loss": 0.2232483433908783, "Avg policy loss": 0.2866557058878243, "Total num played games": 19372, "Total num trained steps": 38144, "Timestamp in ms": 1702020857387, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9678630193336075, "Avg loss": 0.6355098988860846, "Avg value loss": 0.3518977129715495, "Avg policy loss": 0.28361219190992415, "Total num played games": 19448, "Total num trained steps": 38272, "Timestamp in ms": 1702020916956, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 168.95221786201, "Avg game time in secs": 14.242189259646693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 1.74, "agent_stopped_0": 0.45, "reached_maximum_moves": 0.01}, "Total num played games": 19456, "Total num trained steps": 38294, "Timestamp in ms": 1702020926462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972670296927977, "Avg loss": 0.6021909886039793, "Avg value loss": 0.30037555447779596, "Avg policy loss": 0.30181543435901403, "Total num played games": 19466, "Total num trained steps": 38400, "Timestamp in ms": 1702020974397, "logtype": "training_step"}
{"Total num played games": 19564, "Total num trained steps": 38515, "Timestamp in ms": 1702021160385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3984375}
{"Avg objective": 20.3515625, "Games time in secs": 240.4054900407791, "Avg game time in secs": 13.585593735188013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.42, "played_steps": 1.69, "reached_maximum_moves": 0.02}, "Total num played games": 19584, "Total num trained steps": 38527, "Timestamp in ms": 1702021166868, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9673202614379084, "Avg loss": 0.6802024408243597, "Avg value loss": 0.3955648430273868, "Avg policy loss": 0.2846375950612128, "Total num played games": 19584, "Total num trained steps": 38528, "Timestamp in ms": 1702021167002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.966775211152946, "Avg loss": 0.747842337237671, "Avg value loss": 0.44568701297976077, "Avg policy loss": 0.30215532786678523, "Total num played games": 19654, "Total num trained steps": 38656, "Timestamp in ms": 1702021226559, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9728863566995625, "Avg loss": 0.45097644603811204, "Avg value loss": 0.1584873940446414, "Avg policy loss": 0.2924890541471541, "Total num played games": 19658, "Total num trained steps": 38784, "Timestamp in ms": 1702021288845, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 143.5856149494648, "Avg game time in secs": 11.28221016729367, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 1.14}, "Total num played games": 19712, "Total num trained steps": 38832, "Timestamp in ms": 1702021310453, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9700283515593358, "Avg loss": 0.7865435408893973, "Avg value loss": 0.4917984180501662, "Avg policy loss": 0.2947451170766726, "Total num played games": 19752, "Total num trained steps": 38912, "Timestamp in ms": 1702021345782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.969528806376753, "Avg loss": 0.5926172113977373, "Avg value loss": 0.29768725362373516, "Avg policy loss": 0.2949299565516412, "Total num played games": 19822, "Total num trained steps": 39040, "Timestamp in ms": 1702021406855, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 103.9452398121357, "Avg game time in secs": 10.764834024215816, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 1.21}, "Total num played games": 19840, "Total num trained steps": 39054, "Timestamp in ms": 1702021414399, "logtype": "played_game"}
{"Total num played games": 19852, "Total num trained steps": 39115, "Timestamp in ms": 1702021548877, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.00390625}
{"Ratio train steps to played games": 1.9652784746613146, "Avg loss": 0.8177903592586517, "Avg value loss": 0.5205207660328597, "Avg policy loss": 0.29726958833634853, "Total num played games": 19930, "Total num trained steps": 39168, "Timestamp in ms": 1702021573404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9700691868043718, "Avg loss": 0.523917862214148, "Avg value loss": 0.22831934579880908, "Avg policy loss": 0.2955985154258087, "Total num played games": 19946, "Total num trained steps": 39296, "Timestamp in ms": 1702021635300, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 267.97627272456884, "Avg game time in secs": 11.521227659162832, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 1.38, "agent_stopped_0": 0.54, "reached_maximum_moves": 0.01}, "Total num played games": 19968, "Total num trained steps": 39392, "Timestamp in ms": 1702021682375, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9692307692307693, "Avg loss": 0.5852006520144641, "Avg value loss": 0.3002704866230488, "Avg policy loss": 0.2849301639944315, "Total num played games": 20018, "Total num trained steps": 39424, "Timestamp in ms": 1702021696915, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9732588305727399, "Avg loss": 0.6353191884700209, "Avg value loss": 0.34267844911664724, "Avg policy loss": 0.29264073888771236, "Total num played games": 20044, "Total num trained steps": 39552, "Timestamp in ms": 1702021760075, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 100.55724328383803, "Avg game time in secs": 9.749724367429735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.94}, "Total num played games": 20096, "Total num trained steps": 39600, "Timestamp in ms": 1702021782933, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9705999205403257, "Avg loss": 0.8883211167994887, "Avg value loss": 0.5914408606477082, "Avg policy loss": 0.2968802524264902, "Total num played games": 20136, "Total num trained steps": 39680, "Timestamp in ms": 1702021820801, "logtype": "training_step"}
{"Total num played games": 20142, "Total num trained steps": 39718, "Timestamp in ms": 1702021942228, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.29296875}
{"Avg objective": 20.890625, "Games time in secs": 182.1932755485177, "Avg game time in secs": 11.342264775565127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 1.23}, "Total num played games": 20224, "Total num trained steps": 39768, "Timestamp in ms": 1702021965126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9675761170423092, "Avg loss": 0.7560673914849758, "Avg value loss": 0.45522961480310187, "Avg policy loss": 0.3008377776714042, "Total num played games": 20232, "Total num trained steps": 39808, "Timestamp in ms": 1702021983833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737076208362163, "Avg loss": 0.4380834980402142, "Avg value loss": 0.15077386348275468, "Avg policy loss": 0.28730963554698974, "Total num played games": 20234, "Total num trained steps": 39936, "Timestamp in ms": 1702022043600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9704898681880778, "Avg loss": 0.8012944059446454, "Avg value loss": 0.5036022737622261, "Avg policy loss": 0.29769213672261685, "Total num played games": 20332, "Total num trained steps": 40064, "Timestamp in ms": 1702022102201, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 182.64689425751567, "Avg game time in secs": 11.14917406492168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 1.1, "agent_stopped_0": 0.56}, "Total num played games": 20352, "Total num trained steps": 40164, "Timestamp in ms": 1702022147773, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968652037617555, "Avg loss": 0.6027488349936903, "Avg value loss": 0.3099912512116134, "Avg policy loss": 0.292757582385093, "Total num played games": 20416, "Total num trained steps": 40192, "Timestamp in ms": 1702022160386, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9737615038182885, "Avg loss": 0.47660802002064884, "Avg value loss": 0.19544866040814668, "Avg policy loss": 0.2811593583319336, "Total num played games": 20428, "Total num trained steps": 40320, "Timestamp in ms": 1702022222238, "logtype": "training_step"}
{"Total num played games": 20430, "Total num trained steps": 40321, "Timestamp in ms": 1702022328112, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.96484375}
{"Avg objective": 20.0546875, "Games time in secs": 188.79600108414888, "Avg game time in secs": 8.364934368350077, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.67}, "Total num played games": 20480, "Total num trained steps": 40338, "Timestamp in ms": 1702022336569, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9709579962966572, "Avg loss": 0.7874786874745041, "Avg value loss": 0.4942184282117523, "Avg policy loss": 0.2932602552464232, "Total num played games": 20522, "Total num trained steps": 40448, "Timestamp in ms": 1702022387537, "logtype": "training_step"}
{"Ratio train steps to played games": 1.970091279860167, "Avg loss": 0.5935174068436027, "Avg value loss": 0.31457992794457823, "Avg policy loss": 0.2789374850690365, "Total num played games": 20596, "Total num trained steps": 40576, "Timestamp in ms": 1702022446282, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 116.19214529916644, "Avg game time in secs": 9.9909668553737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 1.16}, "Total num played games": 20608, "Total num trained steps": 40589, "Timestamp in ms": 1702022452762, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9741973033271898, "Avg loss": 0.579976693727076, "Avg value loss": 0.2770915830042213, "Avg policy loss": 0.3028851120034233, "Total num played games": 20618, "Total num trained steps": 40704, "Timestamp in ms": 1702022506644, "logtype": "training_step"}
{"Ratio train steps to played games": 1.971036879706507, "Avg loss": 0.7508924824651331, "Avg value loss": 0.45525789714884013, "Avg policy loss": 0.2956345925340429, "Total num played games": 20716, "Total num trained steps": 40832, "Timestamp in ms": 1702022564469, "logtype": "training_step"}
{"Total num played games": 20720, "Total num trained steps": 40923, "Timestamp in ms": 1702022689741, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.15625}
{"Avg objective": 20.7265625, "Games time in secs": 243.31442325934768, "Avg game time in secs": 11.58403024438303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.23, "agent_stopped_0": 0.54}, "Total num played games": 20736, "Total num trained steps": 40937, "Timestamp in ms": 1702022696076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9694201365515915, "Avg loss": 0.620649436255917, "Avg value loss": 0.3261321127647534, "Avg policy loss": 0.2945173302432522, "Total num played games": 20798, "Total num trained steps": 40960, "Timestamp in ms": 1702022707203, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9740559238973767, "Avg loss": 0.5703344300854951, "Avg value loss": 0.270693477417808, "Avg policy loss": 0.29964095016475767, "Total num played games": 20814, "Total num trained steps": 41088, "Timestamp in ms": 1702022765249, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 93.81202740967274, "Avg game time in secs": 8.592430544900708, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.87}, "Total num played games": 20864, "Total num trained steps": 41144, "Timestamp in ms": 1702022789888, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9724349157733538, "Avg loss": 0.6631511186715215, "Avg value loss": 0.36407718766713515, "Avg policy loss": 0.29907393106259406, "Total num played games": 20896, "Total num trained steps": 41216, "Timestamp in ms": 1702022819893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9712024411175741, "Avg loss": 0.5331545935478061, "Avg value loss": 0.2430556077742949, "Avg policy loss": 0.29009898856747895, "Total num played games": 20974, "Total num trained steps": 41344, "Timestamp in ms": 1702022877420, "logtype": "training_step"}
{"Avg objective": 20.6484375, "Games time in secs": 98.96668884530663, "Avg game time in secs": 14.207242449105252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.828125, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 1.85, "agent_stopped_0": 0.41, "reached_maximum_moves": 0.02}, "Total num played games": 20992, "Total num trained steps": 41369, "Timestamp in ms": 1702022888855, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9744810512283375, "Avg loss": 0.5612715729512274, "Avg value loss": 0.2533388709416613, "Avg policy loss": 0.3079327023588121, "Total num played games": 21004, "Total num trained steps": 41472, "Timestamp in ms": 1702022938316, "logtype": "training_step"}
{"Total num played games": 21102, "Total num trained steps": 41523, "Timestamp in ms": 1702023060049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.93359375}
{"Avg objective": 20.8828125, "Games time in secs": 175.78249271214008, "Avg game time in secs": 11.72592206511763, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 1.48, "agent_stopped_0": 0.52}, "Total num played games": 21120, "Total num trained steps": 41531, "Timestamp in ms": 1702023064638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9628196659431916, "Avg loss": 1.2695649249944836, "Avg value loss": 0.9444709707167931, "Avg policy loss": 0.3250939422287047, "Total num played games": 21194, "Total num trained steps": 41600, "Timestamp in ms": 1702023098102, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9686733345914325, "Avg loss": 0.49985116347670555, "Avg value loss": 0.18046397989382967, "Avg policy loss": 0.3193871862022206, "Total num played games": 21196, "Total num trained steps": 41728, "Timestamp in ms": 1702023156662, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9747122098509153, "Avg loss": 0.39456003881059587, "Avg value loss": 0.1022111363708973, "Avg policy loss": 0.29234890441875905, "Total num played games": 21196, "Total num trained steps": 41856, "Timestamp in ms": 1702023217018, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 173.34374176338315, "Avg game time in secs": 7.110222856135806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.68}, "Total num played games": 21248, "Total num trained steps": 41900, "Timestamp in ms": 1702023237982, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972005636449037, "Avg loss": 0.6821066038683057, "Avg value loss": 0.38477874582167715, "Avg policy loss": 0.2973278568824753, "Total num played games": 21288, "Total num trained steps": 41984, "Timestamp in ms": 1702023275451, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 94.599439419806, "Avg game time in secs": 9.492012866860023, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7265625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 1.09}, "Total num played games": 21376, "Total num trained steps": 42108, "Timestamp in ms": 1702023332582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970059880239521, "Avg loss": 0.6651358418166637, "Avg value loss": 0.3702645287849009, "Avg policy loss": 0.2948713059304282, "Total num played games": 21376, "Total num trained steps": 42112, "Timestamp in ms": 1702023334331, "logtype": "training_step"}
{"Total num played games": 21392, "Total num trained steps": 42123, "Timestamp in ms": 1702023455765, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.0078125}
{"Ratio train steps to played games": 1.9659313041049986, "Avg loss": 1.0155620924197137, "Avg value loss": 0.6849670854862779, "Avg policy loss": 0.3305950004141778, "Total num played games": 21486, "Total num trained steps": 42240, "Timestamp in ms": 1702023509697, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9718886716931956, "Avg loss": 0.4430643068626523, "Avg value loss": 0.14441521291155368, "Avg policy loss": 0.2986490953480825, "Total num played games": 21486, "Total num trained steps": 42368, "Timestamp in ms": 1702023572041, "logtype": "training_step"}
{"Avg objective": 22.03125, "Games time in secs": 288.26455840468407, "Avg game time in secs": 11.056858085968997, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.23, "agent_stopped_0": 0.53, "reached_maximum_moves": 0.01}, "Total num played games": 21504, "Total num trained steps": 42471, "Timestamp in ms": 1702023620846, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9710575139146567, "Avg loss": 0.6518502659164369, "Avg value loss": 0.37174718565074727, "Avg policy loss": 0.28010307368822396, "Total num played games": 21560, "Total num trained steps": 42496, "Timestamp in ms": 1702023632392, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974979149291076, "Avg loss": 0.6423505202401429, "Avg value loss": 0.3403326047118753, "Avg policy loss": 0.30201791087165475, "Total num played games": 21582, "Total num trained steps": 42624, "Timestamp in ms": 1702023691883, "logtype": "training_step"}
{"Avg objective": 21.5546875, "Games time in secs": 91.36731669679284, "Avg game time in secs": 7.506422101461794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.83, "agent_stopped_0": 0.53}, "Total num played games": 21632, "Total num trained steps": 42670, "Timestamp in ms": 1702023712214, "logtype": "played_game"}
{"Total num played games": 21684, "Total num trained steps": 42727, "Timestamp in ms": 1702023834473, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.171875}
{"Avg objective": 21.3359375, "Games time in secs": 131.9636618643999, "Avg game time in secs": 7.148950274509843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.77}, "Total num played games": 21760, "Total num trained steps": 42745, "Timestamp in ms": 1702023844178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9636230020209444, "Avg loss": 0.8624985490459949, "Avg value loss": 0.5617718840949237, "Avg policy loss": 0.3007266635540873, "Total num played games": 21772, "Total num trained steps": 42752, "Timestamp in ms": 1702023847416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9689595004132612, "Avg loss": 0.6855422572698444, "Avg value loss": 0.3774270438007079, "Avg policy loss": 0.3081152167869732, "Total num played games": 21778, "Total num trained steps": 42880, "Timestamp in ms": 1702023912608, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974791073560474, "Avg loss": 0.39421632583253086, "Avg value loss": 0.1156055690953508, "Avg policy loss": 0.27861075766850263, "Total num played games": 21778, "Total num trained steps": 43008, "Timestamp in ms": 1702023972790, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9728777899743872, "Avg loss": 0.8561955811455846, "Avg value loss": 0.5704337626812048, "Avg policy loss": 0.2857618135167286, "Total num played games": 21864, "Total num trained steps": 43136, "Timestamp in ms": 1702024032719, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 241.27896193042397, "Avg game time in secs": 9.627210657345131, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 1.1, "agent_stopped_0": 0.55, "reached_maximum_moves": 0.01}, "Total num played games": 21888, "Total num trained steps": 43245, "Timestamp in ms": 1702024085457, "logtype": "played_game"}
{"Ratio train steps to played games": 1.970665937870092, "Avg loss": 0.5453405606094748, "Avg value loss": 0.264582627103664, "Avg policy loss": 0.28075793012976646, "Total num played games": 21954, "Total num trained steps": 43264, "Timestamp in ms": 1702024094216, "logtype": "training_step"}
{"Total num played games": 21970, "Total num trained steps": 43329, "Timestamp in ms": 1702024239574, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.41015625}
{"Avg objective": 21.25, "Games time in secs": 162.40630795806646, "Avg game time in secs": 8.23348688808619, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.45, "played_steps": 0.95, "reached_maximum_moves": 0.02}, "Total num played games": 22016, "Total num trained steps": 43344, "Timestamp in ms": 1702024247863, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9666424945612764, "Avg loss": 1.3538087867200375, "Avg value loss": 1.0461650653742254, "Avg policy loss": 0.3076437284471467, "Total num played games": 22064, "Total num trained steps": 43392, "Timestamp in ms": 1702024271586, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9723984771573604, "Avg loss": 0.5857239675242454, "Avg value loss": 0.2722396895987913, "Avg policy loss": 0.3134842823492363, "Total num played games": 22064, "Total num trained steps": 43520, "Timestamp in ms": 1702024333330, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 142.89603201299906, "Avg game time in secs": 7.252160410396755, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.77, "agent_stopped_0": 0.45}, "Total num played games": 22144, "Total num trained steps": 43643, "Timestamp in ms": 1702024390759, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9709202564797255, "Avg loss": 0.5731522210408002, "Avg value loss": 0.2880156476749107, "Avg policy loss": 0.2851365738315508, "Total num played games": 22146, "Total num trained steps": 43648, "Timestamp in ms": 1702024393240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9752278675209818, "Avg loss": 0.5188202364370227, "Avg value loss": 0.2166161480708979, "Avg policy loss": 0.30220408854074776, "Total num played games": 22162, "Total num trained steps": 43776, "Timestamp in ms": 1702024453606, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9726815240833933, "Avg loss": 0.6592712076380849, "Avg value loss": 0.3548259605304338, "Avg policy loss": 0.30444524774793535, "Total num played games": 22256, "Total num trained steps": 43904, "Timestamp in ms": 1702024512712, "logtype": "training_step"}
{"Total num played games": 22260, "Total num trained steps": 43932, "Timestamp in ms": 1702024591224, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.578125}
{"Avg objective": 19.484375, "Games time in secs": 204.35572999343276, "Avg game time in secs": 9.436751885019476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 1.09, "agent_stopped_0": 0.54}, "Total num played games": 22272, "Total num trained steps": 43940, "Timestamp in ms": 1702024595115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9698908375089477, "Avg loss": 0.825280760647729, "Avg value loss": 0.5160489547997713, "Avg policy loss": 0.3092318079434335, "Total num played games": 22352, "Total num trained steps": 44032, "Timestamp in ms": 1702024636609, "logtype": "training_step"}
{"Ratio train steps to played games": 1.975485371745549, "Avg loss": 0.44391126092523336, "Avg value loss": 0.15418669680366293, "Avg policy loss": 0.28972456336487085, "Total num played games": 22354, "Total num trained steps": 44160, "Timestamp in ms": 1702024698277, "logtype": "training_step"}
{"Avg objective": 21.7421875, "Games time in secs": 127.46162636205554, "Avg game time in secs": 7.230694875412155, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.36, "played_steps": 0.74, "reached_maximum_moves": 0.01}, "Total num played games": 22400, "Total num trained steps": 44211, "Timestamp in ms": 1702024722577, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9728706343549536, "Avg loss": 0.8493718570098281, "Avg value loss": 0.5486478767707013, "Avg policy loss": 0.3007239841390401, "Total num played games": 22448, "Total num trained steps": 44288, "Timestamp in ms": 1702024757511, "logtype": "training_step"}
{"Avg objective": 22.1953125, "Games time in secs": 91.11015243828297, "Avg game time in secs": 6.666647216829006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.77, "agent_stopped_0": 0.55, "reached_maximum_moves": 0.01}, "Total num played games": 22528, "Total num trained steps": 44409, "Timestamp in ms": 1702024813687, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9708910188143416, "Avg loss": 0.6050344177056104, "Avg value loss": 0.31846479792147875, "Avg policy loss": 0.2865696110529825, "Total num played games": 22536, "Total num trained steps": 44416, "Timestamp in ms": 1702024817068, "logtype": "training_step"}
{"Total num played games": 22546, "Total num trained steps": 44533, "Timestamp in ms": 1702024915061, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.796875}
{"Ratio train steps to played games": 1.9719762705861519, "Avg loss": 0.6715321778319776, "Avg value loss": 0.3795623586047441, "Avg policy loss": 0.2919698202749714, "Total num played games": 22586, "Total num trained steps": 44544, "Timestamp in ms": 1702024920705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9731448763250883, "Avg loss": 0.7723997044377029, "Avg value loss": 0.4758887318894267, "Avg policy loss": 0.29651097336318344, "Total num played games": 22640, "Total num trained steps": 44672, "Timestamp in ms": 1702024980639, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 216.4229079671204, "Avg game time in secs": 7.17701851594029, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.8}, "Total num played games": 22656, "Total num trained steps": 44777, "Timestamp in ms": 1702025030110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.97148389368069, "Avg loss": 0.5821217962075025, "Avg value loss": 0.29851814749417827, "Avg policy loss": 0.28360363910906017, "Total num played games": 22724, "Total num trained steps": 44800, "Timestamp in ms": 1702025039862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.976203043899006, "Avg loss": 0.514198723481968, "Avg value loss": 0.23433589813066646, "Avg policy loss": 0.2798628231976181, "Total num played games": 22734, "Total num trained steps": 44928, "Timestamp in ms": 1702025096672, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 85.45441714301705, "Avg game time in secs": 5.365353444853099, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.42}, "Total num played games": 22784, "Total num trained steps": 44969, "Timestamp in ms": 1702025115565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9738894243406642, "Avg loss": 0.7125882664695382, "Avg value loss": 0.43269024521578103, "Avg policy loss": 0.27989802381489426, "Total num played games": 22826, "Total num trained steps": 45056, "Timestamp in ms": 1702025155909, "logtype": "training_step"}
{"Total num played games": 22830, "Total num trained steps": 45134, "Timestamp in ms": 1702025299638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.33203125}
{"Avg objective": 20.25, "Games time in secs": 199.0889887996018, "Avg game time in secs": 8.440959837083938, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 1.03, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.01}, "Total num played games": 22912, "Total num trained steps": 45168, "Timestamp in ms": 1702025314654, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9715507461384065, "Avg loss": 0.588196249678731, "Avg value loss": 0.3063596582505852, "Avg policy loss": 0.2818365882849321, "Total num played games": 22918, "Total num trained steps": 45184, "Timestamp in ms": 1702025322223, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9766183912057234, "Avg loss": 0.4341927070636302, "Avg value loss": 0.16117890906753018, "Avg policy loss": 0.2730137964244932, "Total num played games": 22924, "Total num trained steps": 45312, "Timestamp in ms": 1702025382999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9740637761751672, "Avg loss": 0.7674258353654295, "Avg value loss": 0.48144851584220305, "Avg policy loss": 0.285977314109914, "Total num played games": 23018, "Total num trained steps": 45440, "Timestamp in ms": 1702025442039, "logtype": "training_step"}
{"Avg objective": 21.5625, "Games time in secs": 174.03194297105074, "Avg game time in secs": 8.230949613149278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 1.16}, "Total num played games": 23040, "Total num trained steps": 45542, "Timestamp in ms": 1702025488686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9719577635450927, "Avg loss": 0.5279546387027949, "Avg value loss": 0.26059448660817, "Avg policy loss": 0.26736014685593545, "Total num played games": 23108, "Total num trained steps": 45568, "Timestamp in ms": 1702025499597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9766415779911757, "Avg loss": 0.458065050188452, "Avg value loss": 0.17768046783749014, "Avg policy loss": 0.2803845814196393, "Total num played games": 23118, "Total num trained steps": 45696, "Timestamp in ms": 1702025558516, "logtype": "training_step"}
{"Avg objective": 21.328125, "Games time in secs": 88.70739189907908, "Avg game time in secs": 6.3057190304098185, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.67, "agent_stopped_0": 0.56}, "Total num played games": 23168, "Total num trained steps": 45735, "Timestamp in ms": 1702025577393, "logtype": "played_game"}
{"Total num played games": 23214, "Total num trained steps": 45735, "Timestamp in ms": 1702025663898, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.578125}
{"Avg objective": 21.546875, "Games time in secs": 106.85574913024902, "Avg game time in secs": 8.095153434027452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 1.04, "agent_stopped_0": 0.48, "reached_maximum_moves": 0.01}, "Total num played games": 23296, "Total num trained steps": 45776, "Timestamp in ms": 1702025684249, "logtype": "played_game"}
{"Ratio train steps to played games": 1.96652647841387, "Avg loss": 1.0633677712175995, "Avg value loss": 0.7624513365735766, "Avg policy loss": 0.30091642355546355, "Total num played games": 23302, "Total num trained steps": 45824, "Timestamp in ms": 1702025706252, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9715119272352841, "Avg loss": 0.44694220018573105, "Avg value loss": 0.16123533801874146, "Avg policy loss": 0.2857068593148142, "Total num played games": 23308, "Total num trained steps": 45952, "Timestamp in ms": 1702025766170, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9770036039128196, "Avg loss": 0.36684102402068675, "Avg value loss": 0.0968549829267431, "Avg policy loss": 0.2699860428692773, "Total num played games": 23308, "Total num trained steps": 46080, "Timestamp in ms": 1702025827263, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9745320912742501, "Avg loss": 0.8365995645290241, "Avg value loss": 0.561653077689698, "Avg policy loss": 0.2749464891385287, "Total num played games": 23402, "Total num trained steps": 46208, "Timestamp in ms": 1702025885023, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 245.37700740247965, "Avg game time in secs": 8.227695923647843, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 1.02, "agent_stopped_0": 0.55}, "Total num played games": 23424, "Total num trained steps": 46306, "Timestamp in ms": 1702025929626, "logtype": "played_game"}
{"Total num played games": 23500, "Total num trained steps": 46335, "Timestamp in ms": 1702026057737, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.33984375}
{"Ratio train steps to played games": 1.971744680851064, "Avg loss": 0.6890449821949005, "Avg value loss": 0.41470503009622917, "Avg policy loss": 0.27433995075989515, "Total num played games": 23500, "Total num trained steps": 46336, "Timestamp in ms": 1702026058585, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 134.90751153230667, "Avg game time in secs": 6.619232423079666, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.578125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.75}, "Total num played games": 23552, "Total num trained steps": 46350, "Timestamp in ms": 1702026064534, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9693142324319741, "Avg loss": 1.1575158382765949, "Avg value loss": 0.847751206078101, "Avg policy loss": 0.30976462515536696, "Total num played games": 23594, "Total num trained steps": 46464, "Timestamp in ms": 1702026116146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9746969568534374, "Avg loss": 0.40894460887648165, "Avg value loss": 0.1303093223250471, "Avg policy loss": 0.2786352870753035, "Total num played games": 23594, "Total num trained steps": 46592, "Timestamp in ms": 1702026177357, "logtype": "training_step"}
{"Avg objective": 20.984375, "Games time in secs": 164.22607527673244, "Avg game time in secs": 5.935102179530077, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.68}, "Total num played games": 23680, "Total num trained steps": 46707, "Timestamp in ms": 1702026228761, "logtype": "played_game"}
{"Ratio train steps to played games": 1.972306653157717, "Avg loss": 0.5926862938795239, "Avg value loss": 0.3235797913512215, "Avg policy loss": 0.26910649763885885, "Total num played games": 23686, "Total num trained steps": 46720, "Timestamp in ms": 1702026235092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777102330293819, "Avg loss": 0.5840448895469308, "Avg value loss": 0.3090230781817809, "Avg policy loss": 0.27502181485760957, "Total num played games": 23688, "Total num trained steps": 46848, "Timestamp in ms": 1702026294335, "logtype": "training_step"}
{"Total num played games": 23786, "Total num trained steps": 46938, "Timestamp in ms": 1702026442017, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1484375}
{"Avg objective": 21.765625, "Games time in secs": 217.81498186290264, "Avg game time in secs": 7.12739717704244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.88, "agent_stopped_0": 0.63, "reached_maximum_moves": 0.01}, "Total num played games": 23808, "Total num trained steps": 46948, "Timestamp in ms": 1702026446576, "logtype": "played_game"}
{"Ratio train steps to played games": 1.968158203452321, "Avg loss": 0.8883632700890303, "Avg value loss": 0.6100466449861415, "Avg policy loss": 0.2783166306326166, "Total num played games": 23868, "Total num trained steps": 46976, "Timestamp in ms": 1702026459373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.972694530530195, "Avg loss": 0.5303397031966597, "Avg value loss": 0.24889163934858516, "Avg policy loss": 0.2814480672823265, "Total num played games": 23878, "Total num trained steps": 47104, "Timestamp in ms": 1702026517960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.977889447236181, "Avg loss": 0.36341459094546735, "Avg value loss": 0.10631695343181491, "Avg policy loss": 0.25709763437043875, "Total num played games": 23880, "Total num trained steps": 47232, "Timestamp in ms": 1702026575939, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 143.595125105232, "Avg game time in secs": 7.32304815351381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.89, "reached_maximum_moves": 0.01}, "Total num played games": 23936, "Total num trained steps": 47263, "Timestamp in ms": 1702026590171, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9753086419753085, "Avg loss": 0.8660968167241663, "Avg value loss": 0.5925483086029999, "Avg policy loss": 0.2735485159792006, "Total num played games": 23976, "Total num trained steps": 47360, "Timestamp in ms": 1702026634200, "logtype": "training_step"}
{"Avg objective": 23.421875, "Games time in secs": 92.41249674931169, "Avg game time in secs": 5.769364076317288, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.64, "agent_stopped_0": 0.54}, "Total num played games": 24064, "Total num trained steps": 47465, "Timestamp in ms": 1702026682583, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730762838623899, "Avg loss": 1.1699132032226771, "Avg value loss": 0.9019598223385401, "Avg policy loss": 0.26795338129159063, "Total num played games": 24068, "Total num trained steps": 47488, "Timestamp in ms": 1702026693173, "logtype": "training_step"}
{"Total num played games": 24074, "Total num trained steps": 47540, "Timestamp in ms": 1702026845891, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.2578125}
{"Ratio train steps to played games": 1.9702085402184708, "Avg loss": 0.7437425102107227, "Avg value loss": 0.44833442382514477, "Avg policy loss": 0.2954080862691626, "Total num played games": 24168, "Total num trained steps": 47616, "Timestamp in ms": 1702026881075, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9755047997351871, "Avg loss": 0.39414141210727394, "Avg value loss": 0.1232240159297362, "Avg policy loss": 0.2709173981565982, "Total num played games": 24168, "Total num trained steps": 47744, "Timestamp in ms": 1702026940568, "logtype": "training_step"}
{"Avg objective": 21.7109375, "Games time in secs": 299.2382316440344, "Avg game time in secs": 5.565537219838006, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.66, "agent_stopped_0": 0.58}, "Total num played games": 24192, "Total num trained steps": 47835, "Timestamp in ms": 1702026981822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9732893652102226, "Avg loss": 0.6482226450461894, "Avg value loss": 0.3857538829324767, "Avg policy loss": 0.26246876921504736, "Total num played games": 24260, "Total num trained steps": 47872, "Timestamp in ms": 1702026998281, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978402440029676, "Avg loss": 0.4671878458466381, "Avg value loss": 0.18305163306649774, "Avg policy loss": 0.28413621592335403, "Total num played games": 24262, "Total num trained steps": 48000, "Timestamp in ms": 1702027059601, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 91.26272445172071, "Avg game time in secs": 6.493581952439854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.79}, "Total num played games": 24320, "Total num trained steps": 48029, "Timestamp in ms": 1702027073085, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9758600870350604, "Avg loss": 0.725160414353013, "Avg value loss": 0.44933701684931293, "Avg policy loss": 0.2758234031498432, "Total num played games": 24358, "Total num trained steps": 48128, "Timestamp in ms": 1702027118856, "logtype": "training_step"}
{"Total num played games": 24360, "Total num trained steps": 48144, "Timestamp in ms": 1702027278287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.01953125}
{"Avg objective": 20.4765625, "Games time in secs": 235.16484130173922, "Avg game time in secs": 7.503749808005523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.95, "agent_stopped_0": 0.5}, "Total num played games": 24448, "Total num trained steps": 48211, "Timestamp in ms": 1702027308250, "logtype": "played_game"}
{"Ratio train steps to played games": 1.973499100278096, "Avg loss": 0.8747254249174148, "Avg value loss": 0.5899231802322902, "Avg policy loss": 0.2848022482357919, "Total num played games": 24452, "Total num trained steps": 48256, "Timestamp in ms": 1702027329025, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9785311196532265, "Avg loss": 0.3958450108766556, "Avg value loss": 0.1285011368454434, "Avg policy loss": 0.2673438744386658, "Total num played games": 24454, "Total num trained steps": 48384, "Timestamp in ms": 1702027389926, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9758879113717824, "Avg loss": 0.80897475220263, "Avg value loss": 0.5360045714187436, "Avg policy loss": 0.2729701859643683, "Total num played games": 24552, "Total num trained steps": 48512, "Timestamp in ms": 1702027449965, "logtype": "training_step"}
{"Avg objective": 21.0390625, "Games time in secs": 183.31625158712268, "Avg game time in secs": 7.2126773122290615, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.96}, "Total num played games": 24576, "Total num trained steps": 48603, "Timestamp in ms": 1702027491566, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974025974025974, "Avg loss": 0.6488041805569082, "Avg value loss": 0.3810992423677817, "Avg policy loss": 0.267704933648929, "Total num played games": 24640, "Total num trained steps": 48640, "Timestamp in ms": 1702027507000, "logtype": "training_step"}
{"Total num played games": 24648, "Total num trained steps": 48745, "Timestamp in ms": 1702027676598, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.375}
{"Avg objective": 21.578125, "Games time in secs": 190.9232407025993, "Avg game time in secs": 7.021452196757309, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.703125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.86, "agent_stopped_0": 0.56, "reached_maximum_moves": 0.01}, "Total num played games": 24704, "Total num trained steps": 48755, "Timestamp in ms": 1702027682489, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9721772889032676, "Avg loss": 0.7228451073169708, "Avg value loss": 0.45239080558530986, "Avg policy loss": 0.2704543158179149, "Total num played games": 24728, "Total num trained steps": 48768, "Timestamp in ms": 1702027688801, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9762347425430442, "Avg loss": 0.5711348988115788, "Avg value loss": 0.30727347848005593, "Avg policy loss": 0.2638614175375551, "Total num played games": 24742, "Total num trained steps": 48896, "Timestamp in ms": 1702027749081, "logtype": "training_step"}
{"Avg objective": 20.2578125, "Games time in secs": 113.47655934840441, "Avg game time in secs": 6.233988279651385, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.71, "agent_stopped_0": 0.57}, "Total num played games": 24832, "Total num trained steps": 49001, "Timestamp in ms": 1702027795967, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9737498993477736, "Avg loss": 0.6975541245192289, "Avg value loss": 0.4415718953241594, "Avg policy loss": 0.2559822351904586, "Total num played games": 24838, "Total num trained steps": 49024, "Timestamp in ms": 1702027805714, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789032933408488, "Avg loss": 0.4037688560783863, "Avg value loss": 0.1517778969136998, "Avg policy loss": 0.25199095613788813, "Total num played games": 24838, "Total num trained steps": 49152, "Timestamp in ms": 1702027863861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9764177428411005, "Avg loss": 0.8217695022467524, "Avg value loss": 0.5596149451448582, "Avg policy loss": 0.2621545592555776, "Total num played games": 24934, "Total num trained steps": 49280, "Timestamp in ms": 1702027921986, "logtype": "training_step"}
{"Total num played games": 24936, "Total num trained steps": 49346, "Timestamp in ms": 1702028094561, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.53515625}
{"Avg objective": 21.4453125, "Games time in secs": 303.03016662597656, "Avg game time in secs": 6.545677006710321, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.84, "agent_stopped_0": 0.63, "reached_maximum_moves": 0.01}, "Total num played games": 24960, "Total num trained steps": 49355, "Timestamp in ms": 1702028098997, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9739512584898122, "Avg loss": 0.8243500639218837, "Avg value loss": 0.5592756545520388, "Avg policy loss": 0.2650743981357664, "Total num played games": 25030, "Total num trained steps": 49408, "Timestamp in ms": 1702028123402, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9790651218537754, "Avg loss": 0.4102775522042066, "Avg value loss": 0.14728592039318755, "Avg policy loss": 0.2629916324513033, "Total num played games": 25030, "Total num trained steps": 49536, "Timestamp in ms": 1702028184333, "logtype": "training_step"}
{"Avg objective": 22.6484375, "Games time in secs": 97.61491372808814, "Avg game time in secs": 4.991997768491274, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.66}, "Total num played games": 25088, "Total num trained steps": 49564, "Timestamp in ms": 1702028196612, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976597946350394, "Avg loss": 0.662070588208735, "Avg value loss": 0.40043705294374377, "Avg policy loss": 0.2616335372440517, "Total num played games": 25126, "Total num trained steps": 49664, "Timestamp in ms": 1702028240930, "logtype": "training_step"}
{"Avg objective": 20.6171875, "Games time in secs": 95.51076892390847, "Avg game time in secs": 6.795426618045894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.92}, "Total num played games": 25216, "Total num trained steps": 49779, "Timestamp in ms": 1702028292123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9743061062648692, "Avg loss": 0.6097575984895229, "Avg value loss": 0.3407648677821271, "Avg policy loss": 0.2689927357714623, "Total num played games": 25220, "Total num trained steps": 49792, "Timestamp in ms": 1702028298182, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979224486559353, "Avg loss": 0.42225590720772743, "Avg value loss": 0.1569853974506259, "Avg policy loss": 0.26527051033917814, "Total num played games": 25222, "Total num trained steps": 49920, "Timestamp in ms": 1702028358802, "logtype": "training_step"}
{"Total num played games": 25320, "Total num trained steps": 49948, "Timestamp in ms": 1702028580019, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.56640625}
{"Avg objective": 21.53125, "Games time in secs": 292.6659995839, "Avg game time in secs": 5.277824055432575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.69, "agent_stopped_0": 0.64}, "Total num played games": 25344, "Total num trained steps": 49957, "Timestamp in ms": 1702028584789, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9693082552923586, "Avg loss": 1.1264726070221514, "Avg value loss": 0.8272663276875392, "Avg policy loss": 0.29920627758838236, "Total num played games": 25414, "Total num trained steps": 50048, "Timestamp in ms": 1702028627582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.974344849295664, "Avg loss": 0.40361118607688695, "Avg value loss": 0.12873387057334185, "Avg policy loss": 0.2748773144558072, "Total num played games": 25414, "Total num trained steps": 50176, "Timestamp in ms": 1702028687533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9793814432989691, "Avg loss": 0.33837251050863415, "Avg value loss": 0.08385556103894487, "Avg policy loss": 0.2545169483637437, "Total num played games": 25414, "Total num trained steps": 50304, "Timestamp in ms": 1702028747347, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 173.52445494383574, "Avg game time in secs": 5.455309463781305, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.66, "agent_stopped_0": 0.57}, "Total num played games": 25472, "Total num trained steps": 50330, "Timestamp in ms": 1702028758314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.976950215601725, "Avg loss": 0.6459862948395312, "Avg value loss": 0.3705044971720781, "Avg policy loss": 0.2754817989189178, "Total num played games": 25510, "Total num trained steps": 50432, "Timestamp in ms": 1702028805805, "logtype": "training_step"}
{"Avg objective": 21.2109375, "Games time in secs": 101.18110591173172, "Avg game time in secs": 5.482359091605758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.74, "agent_stopped_0": 0.46}, "Total num played games": 25600, "Total num trained steps": 50548, "Timestamp in ms": 1702028859495, "logtype": "played_game"}
{"Total num played games": 25606, "Total num trained steps": 50549, "Timestamp in ms": 1702028955322, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.74609375}
{"Ratio train steps to played games": 1.9717260744091725, "Avg loss": 0.746374296490103, "Avg value loss": 0.48543035055627115, "Avg policy loss": 0.26094394747633487, "Total num played games": 25642, "Total num trained steps": 50560, "Timestamp in ms": 1702028960243, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9722568093385213, "Avg loss": 0.8704943384509534, "Avg value loss": 0.5547998062102124, "Avg policy loss": 0.31569453328847885, "Total num played games": 25700, "Total num trained steps": 50688, "Timestamp in ms": 1702029017580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9772373540856032, "Avg loss": 0.37611703271977603, "Avg value loss": 0.10314448206918314, "Avg policy loss": 0.2729725531535223, "Total num played games": 25700, "Total num trained steps": 50816, "Timestamp in ms": 1702029077172, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 255.13225389644504, "Avg game time in secs": 5.4951036350103095, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.65625, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.77, "agent_stopped_0": 0.56}, "Total num played games": 25728, "Total num trained steps": 50898, "Timestamp in ms": 1702029114627, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9750329534000155, "Avg loss": 0.6189831285737455, "Avg value loss": 0.33924295552424155, "Avg policy loss": 0.27974018186796457, "Total num played games": 25794, "Total num trained steps": 50944, "Timestamp in ms": 1702029135172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9796883479339484, "Avg loss": 0.41098801139742136, "Avg value loss": 0.14190529321786016, "Avg policy loss": 0.26908271736465394, "Total num played games": 25798, "Total num trained steps": 51072, "Timestamp in ms": 1702029193238, "logtype": "training_step"}
{"Avg objective": 22.25, "Games time in secs": 90.29904301092029, "Avg game time in secs": 5.398101897299057, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.75}, "Total num played games": 25856, "Total num trained steps": 51099, "Timestamp in ms": 1702029204927, "logtype": "played_game"}
{"Total num played games": 25894, "Total num trained steps": 51151, "Timestamp in ms": 1702029390752, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.359375}
{"Avg objective": 21.515625, "Games time in secs": 206.51539573818445, "Avg game time in secs": 5.756147995474748, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.77, "agent_stopped_0": 0.5}, "Total num played games": 25984, "Total num trained steps": 51196, "Timestamp in ms": 1702029411442, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9704048645320198, "Avg loss": 1.0224784382153302, "Avg value loss": 0.7236782861873507, "Avg policy loss": 0.29880014655645937, "Total num played games": 25984, "Total num trained steps": 51200, "Timestamp in ms": 1702029412990, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9750654148068338, "Avg loss": 0.47311688284389675, "Avg value loss": 0.18326644430635497, "Avg policy loss": 0.289850439527072, "Total num played games": 25988, "Total num trained steps": 51328, "Timestamp in ms": 1702029472487, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9799522856703093, "Avg loss": 0.3483835174702108, "Avg value loss": 0.08794752351241186, "Avg policy loss": 0.26043599483091384, "Total num played games": 25988, "Total num trained steps": 51456, "Timestamp in ms": 1702029529285, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9777624415305575, "Avg loss": 1.0336167188361287, "Avg value loss": 0.754756792623084, "Avg policy loss": 0.27885991951916367, "Total num played games": 26082, "Total num trained steps": 51584, "Timestamp in ms": 1702029585711, "logtype": "training_step"}
{"Avg objective": 23.25, "Games time in secs": 210.83785511553288, "Avg game time in secs": 5.396394946670625, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.68, "agent_stopped_more": 0.32, "played_steps": 0.72}, "Total num played games": 26112, "Total num trained steps": 51664, "Timestamp in ms": 1702029622280, "logtype": "played_game"}
{"Ratio train steps to played games": 1.975360990144396, "Avg loss": 0.7467768779024482, "Avg value loss": 0.4729468170553446, "Avg policy loss": 0.27383005688898265, "Total num played games": 26178, "Total num trained steps": 51712, "Timestamp in ms": 1702029642466, "logtype": "training_step"}
{"Total num played games": 26180, "Total num trained steps": 51754, "Timestamp in ms": 1702029831259, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.1953125}
{"Avg objective": 22.34375, "Games time in secs": 214.50061947107315, "Avg game time in secs": 4.490161639347207, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.59}, "Total num played games": 26240, "Total num trained steps": 51764, "Timestamp in ms": 1702029836781, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9730532084950902, "Avg loss": 0.8150153977330774, "Avg value loss": 0.516488362220116, "Avg policy loss": 0.2985270305071026, "Total num played games": 26274, "Total num trained steps": 51840, "Timestamp in ms": 1702029871851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 0.3932209655176848, "Avg value loss": 0.12165113748051226, "Avg policy loss": 0.2715698272222653, "Total num played games": 26274, "Total num trained steps": 51968, "Timestamp in ms": 1702029931842, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 149.26469212397933, "Avg game time in secs": 5.123764401942026, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.9296875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.8, "agent_stopped_0": 0.48}, "Total num played games": 26368, "Total num trained steps": 52087, "Timestamp in ms": 1702029986047, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9755783086841108, "Avg loss": 0.6480872510001063, "Avg value loss": 0.3788905383553356, "Avg policy loss": 0.26919671264477074, "Total num played games": 26370, "Total num trained steps": 52096, "Timestamp in ms": 1702029990280, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802821173972396, "Avg loss": 0.41859035193920135, "Avg value loss": 0.13905828958377242, "Avg policy loss": 0.27953206095844507, "Total num played games": 26372, "Total num trained steps": 52224, "Timestamp in ms": 1702030049272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779356203717697, "Avg loss": 0.7735001991968602, "Avg value loss": 0.49097211501793936, "Avg policy loss": 0.2825280833058059, "Total num played games": 26468, "Total num trained steps": 52352, "Timestamp in ms": 1702030107498, "logtype": "training_step"}
{"Total num played games": 26468, "Total num trained steps": 52357, "Timestamp in ms": 1702030287987, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 29.1484375}
{"Avg objective": 22.5078125, "Games time in secs": 306.6364781446755, "Avg game time in secs": 4.027336583298165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.57, "agent_stopped_0": 0.6}, "Total num played games": 26496, "Total num trained steps": 52366, "Timestamp in ms": 1702030292683, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9757548377381222, "Avg loss": 0.7596957464702427, "Avg value loss": 0.4659276915481314, "Avg policy loss": 0.29376804979983717, "Total num played games": 26562, "Total num trained steps": 52480, "Timestamp in ms": 1702030342904, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9805737519765079, "Avg loss": 0.3627277435734868, "Avg value loss": 0.09550616843625903, "Avg policy loss": 0.2672215737402439, "Total num played games": 26562, "Total num trained steps": 52608, "Timestamp in ms": 1702030400817, "logtype": "training_step"}
{"Avg objective": 20.75, "Games time in secs": 114.89664460346103, "Avg game time in secs": 4.718899551924551, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.68}, "Total num played games": 26624, "Total num trained steps": 52622, "Timestamp in ms": 1702030407580, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978391356542617, "Avg loss": 0.6299823776353151, "Avg value loss": 0.3483475227258168, "Avg policy loss": 0.2816348501946777, "Total num played games": 26656, "Total num trained steps": 52736, "Timestamp in ms": 1702030461825, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9762242990654206, "Avg loss": 0.7062634723260999, "Avg value loss": 0.4327492102747783, "Avg policy loss": 0.2735142601886764, "Total num played games": 26750, "Total num trained steps": 52864, "Timestamp in ms": 1702030522154, "logtype": "training_step"}
{"Avg objective": 20.9296875, "Games time in secs": 171.94947358593345, "Avg game time in secs": 6.6332157897995785, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 1.16, "agent_stopped_0": 0.44, "reached_maximum_moves": 0.01}, "Total num played games": 26752, "Total num trained steps": 52959, "Timestamp in ms": 1702030579530, "logtype": "played_game"}
{"Total num played games": 26752, "Total num trained steps": 52959, "Timestamp in ms": 1702030757940, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.37890625}
{"Ratio train steps to played games": 1.9742195067431636, "Avg loss": 0.612936899298802, "Avg value loss": 0.33735997742041945, "Avg policy loss": 0.27557692292612046, "Total num played games": 26842, "Total num trained steps": 52992, "Timestamp in ms": 1702030773734, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978693287640617, "Avg loss": 0.4761075130663812, "Avg value loss": 0.1857722676359117, "Avg policy loss": 0.2903352458961308, "Total num played games": 26846, "Total num trained steps": 53120, "Timestamp in ms": 1702030832652, "logtype": "training_step"}
{"Avg objective": 22.875, "Games time in secs": 284.34860571473837, "Avg game time in secs": 4.098438082495704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.6}, "Total num played games": 26880, "Total num trained steps": 53190, "Timestamp in ms": 1702030863879, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765404602821084, "Avg loss": 0.8304059472866356, "Avg value loss": 0.5467674437386449, "Avg policy loss": 0.28363848896697164, "Total num played games": 26940, "Total num trained steps": 53248, "Timestamp in ms": 1702030890261, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9786476868327403, "Avg loss": 0.43741389480419457, "Avg value loss": 0.15402197308139876, "Avg policy loss": 0.28339192317798734, "Total num played games": 26976, "Total num trained steps": 53376, "Timestamp in ms": 1702030947491, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 85.41289803013206, "Avg game time in secs": 4.938471666275291, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.671875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.41, "played_steps": 0.73, "reached_maximum_moves": 0.01}, "Total num played games": 27008, "Total num trained steps": 53380, "Timestamp in ms": 1702030949292, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788445890968267, "Avg loss": 0.8064460251480341, "Avg value loss": 0.5141895212582313, "Avg policy loss": 0.29225650371517986, "Total num played games": 27038, "Total num trained steps": 53504, "Timestamp in ms": 1702031003442, "logtype": "training_step"}
{"Total num played games": 27038, "Total num trained steps": 53561, "Timestamp in ms": 1702031188715, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.9453125}
{"Ratio train steps to played games": 1.9767064720625092, "Avg loss": 0.6982393912039697, "Avg value loss": 0.41623197635635734, "Avg policy loss": 0.28200740623287857, "Total num played games": 27132, "Total num trained steps": 53632, "Timestamp in ms": 1702031222743, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 330.286241106689, "Avg game time in secs": 4.759275700926082, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.75}, "Total num played games": 27136, "Total num trained steps": 53756, "Timestamp in ms": 1702031279578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978944268571008, "Avg loss": 0.40953261288814247, "Avg value loss": 0.1393293253495358, "Avg policy loss": 0.2702032857341692, "Total num played games": 27164, "Total num trained steps": 53760, "Timestamp in ms": 1702031280957, "logtype": "training_step"}
{"Ratio train steps to played games": 1.979139121492581, "Avg loss": 0.8711859018076211, "Avg value loss": 0.5837010443792678, "Avg policy loss": 0.2874848654028028, "Total num played games": 27228, "Total num trained steps": 53888, "Timestamp in ms": 1702031340428, "logtype": "training_step"}
{"Avg objective": 23.15625, "Games time in secs": 90.20102596655488, "Avg game time in secs": 3.4841414357651956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 27264, "Total num trained steps": 53954, "Timestamp in ms": 1702031369779, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9765442037470726, "Avg loss": 0.7885544039309025, "Avg value loss": 0.5003954822896048, "Avg policy loss": 0.28815892338752747, "Total num played games": 27328, "Total num trained steps": 54016, "Timestamp in ms": 1702031398600, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981264637002342, "Avg loss": 0.39506970695219934, "Avg value loss": 0.11553515656851232, "Avg policy loss": 0.27953455224633217, "Total num played games": 27328, "Total num trained steps": 54144, "Timestamp in ms": 1702031457595, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 92.19864359125495, "Avg game time in secs": 3.895048230071552, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8203125, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.51, "agent_stopped_0": 0.61}, "Total num played games": 27392, "Total num trained steps": 54154, "Timestamp in ms": 1702031461978, "logtype": "played_game"}
{"Total num played games": 27424, "Total num trained steps": 54164, "Timestamp in ms": 1702031556330, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.66015625}
{"Ratio train steps to played games": 1.9723433638610264, "Avg loss": 1.5649179597385228, "Avg value loss": 1.2428379369084723, "Avg policy loss": 0.3220800240524113, "Total num played games": 27516, "Total num trained steps": 54272, "Timestamp in ms": 1702031606318, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9768515153717567, "Avg loss": 0.42415758478455245, "Avg value loss": 0.12783240026328713, "Avg policy loss": 0.2963251832406968, "Total num played games": 27518, "Total num trained steps": 54400, "Timestamp in ms": 1702031663233, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 260.73908963799477, "Avg game time in secs": 4.428526246570982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.69, "agent_stopped_0": 0.48}, "Total num played games": 27520, "Total num trained steps": 54527, "Timestamp in ms": 1702031722717, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9813953488372094, "Avg loss": 0.3519699100870639, "Avg value loss": 0.082031892525265, "Avg policy loss": 0.26993801700882614, "Total num played games": 27520, "Total num trained steps": 54528, "Timestamp in ms": 1702031722893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9794292336665218, "Avg loss": 0.8845552275888622, "Avg value loss": 0.5858478131121956, "Avg policy loss": 0.29870740592014045, "Total num played games": 27612, "Total num trained steps": 54656, "Timestamp in ms": 1702031780849, "logtype": "training_step"}
{"Avg objective": 22.9375, "Games time in secs": 87.9570737183094, "Avg game time in secs": 4.140048070607008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.68}, "Total num played games": 27648, "Total num trained steps": 54725, "Timestamp in ms": 1702031810674, "logtype": "played_game"}
{"Total num played games": 27710, "Total num trained steps": 54765, "Timestamp in ms": 1702031926558, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.18359375}
{"Avg objective": 21.9609375, "Games time in secs": 121.25520979613066, "Avg game time in secs": 3.452556988573633, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.51}, "Total num played games": 27776, "Total num trained steps": 54776, "Timestamp in ms": 1702031931930, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9709310692185926, "Avg loss": 1.1172083262354136, "Avg value loss": 0.8191499839886092, "Avg policy loss": 0.29805834614671767, "Total num played games": 27796, "Total num trained steps": 54784, "Timestamp in ms": 1702031935476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9749676305567545, "Avg loss": 0.9617644497193396, "Avg value loss": 0.6392926744301803, "Avg policy loss": 0.3224717758130282, "Total num played games": 27804, "Total num trained steps": 54912, "Timestamp in ms": 1702031989832, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795712847072364, "Avg loss": 0.38475461094640195, "Avg value loss": 0.10362730096676387, "Avg policy loss": 0.2811273082625121, "Total num played games": 27804, "Total num trained steps": 55040, "Timestamp in ms": 1702032048491, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9772059350584188, "Avg loss": 0.7847943601664156, "Avg value loss": 0.4981935786199756, "Avg policy loss": 0.28660078276880085, "Total num played games": 27902, "Total num trained steps": 55168, "Timestamp in ms": 1702032105851, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9816155389908257, "Avg loss": 0.41399579239077866, "Avg value loss": 0.1275290916673839, "Avg policy loss": 0.2864667003741488, "Total num played games": 27902, "Total num trained steps": 55296, "Timestamp in ms": 1702032160709, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 228.78052028641105, "Avg game time in secs": 4.681595187925268, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.90625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.84, "agent_stopped_0": 0.42}, "Total num played games": 27904, "Total num trained steps": 55296, "Timestamp in ms": 1702032160710, "logtype": "played_game"}
{"Total num played games": 28002, "Total num trained steps": 55369, "Timestamp in ms": 1702032284270, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.296875}
{"Avg objective": 21.3359375, "Games time in secs": 126.79762653261423, "Avg game time in secs": 3.5699638585792854, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.44}, "Total num played games": 28032, "Total num trained steps": 55376, "Timestamp in ms": 1702032287508, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9726651480637813, "Avg loss": 1.0858908283989877, "Avg value loss": 0.7750719519099221, "Avg policy loss": 0.31081888754852116, "Total num played games": 28096, "Total num trained steps": 55424, "Timestamp in ms": 1702032306411, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9772209567198178, "Avg loss": 0.4409467678051442, "Avg value loss": 0.14580595766892657, "Avg policy loss": 0.29514081100933254, "Total num played games": 28096, "Total num trained steps": 55552, "Timestamp in ms": 1702032360424, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9817767653758542, "Avg loss": 0.38059821887873113, "Avg value loss": 0.10732448773342185, "Avg policy loss": 0.27327373379375786, "Total num played games": 28096, "Total num trained steps": 55680, "Timestamp in ms": 1702032412278, "logtype": "training_step"}
{"Avg objective": 21.671875, "Games time in secs": 129.16371028870344, "Avg game time in secs": 3.2259857736353297, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.44}, "Total num played games": 28160, "Total num trained steps": 55692, "Timestamp in ms": 1702032416672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795686719636776, "Avg loss": 0.7331971004605293, "Avg value loss": 0.44720512331696227, "Avg policy loss": 0.2859919749898836, "Total num played games": 28192, "Total num trained steps": 55808, "Timestamp in ms": 1702032465711, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 100.0280373133719, "Avg game time in secs": 4.315664366702549, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.73, "agent_stopped_0": 0.52}, "Total num played games": 28288, "Total num trained steps": 55933, "Timestamp in ms": 1702032516700, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773755656108598, "Avg loss": 0.7287730118259788, "Avg value loss": 0.4485450288048014, "Avg policy loss": 0.28022798616439104, "Total num played games": 28288, "Total num trained steps": 55936, "Timestamp in ms": 1702032517837, "logtype": "training_step"}
{"Total num played games": 28288, "Total num trained steps": 55969, "Timestamp in ms": 1702032632825, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.328125}
{"Ratio train steps to played games": 1.975336480868156, "Avg loss": 0.8591202483512461, "Avg value loss": 0.5562816800666042, "Avg policy loss": 0.3028385688085109, "Total num played games": 28382, "Total num trained steps": 56064, "Timestamp in ms": 1702032671958, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9798463815094074, "Avg loss": 0.38459990033879876, "Avg value loss": 0.10886628535808995, "Avg policy loss": 0.2757336157374084, "Total num played games": 28382, "Total num trained steps": 56192, "Timestamp in ms": 1702032724025, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 235.77763824909925, "Avg game time in secs": 2.7523132515489124, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.41}, "Total num played games": 28416, "Total num trained steps": 56261, "Timestamp in ms": 1702032752478, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9776669709951542, "Avg loss": 0.7520582191646099, "Avg value loss": 0.4686639870633371, "Avg policy loss": 0.28339422831777483, "Total num played games": 28478, "Total num trained steps": 56320, "Timestamp in ms": 1702032776897, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820224719101123, "Avg loss": 0.38173828762955964, "Avg value loss": 0.10690716560930014, "Avg policy loss": 0.2748311231844127, "Total num played games": 28480, "Total num trained steps": 56448, "Timestamp in ms": 1702032828846, "logtype": "training_step"}
{"Avg objective": 20.9609375, "Games time in secs": 79.76698011532426, "Avg game time in secs": 3.288988184853224, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 28544, "Total num trained steps": 56456, "Timestamp in ms": 1702032832245, "logtype": "played_game"}
{"Total num played games": 28574, "Total num trained steps": 56571, "Timestamp in ms": 1702033010648, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.85546875}
{"Ratio train steps to played games": 1.9784585256679257, "Avg loss": 0.8077979260124266, "Avg value loss": 0.5043680016533472, "Avg policy loss": 0.3034299194114283, "Total num played games": 28590, "Total num trained steps": 56576, "Timestamp in ms": 1702033013088, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779545137435468, "Avg loss": 0.7753118064720184, "Avg value loss": 0.46747490076813847, "Avg policy loss": 0.30783691781107336, "Total num played games": 28668, "Total num trained steps": 56704, "Timestamp in ms": 1702033067427, "logtype": "training_step"}
{"Avg objective": 22.4765625, "Games time in secs": 288.09271916374564, "Avg game time in secs": 4.134389686631039, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.73, "agent_stopped_0": 0.48}, "Total num played games": 28672, "Total num trained steps": 56829, "Timestamp in ms": 1702033120338, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9807611877875366, "Avg loss": 0.37516587041318417, "Avg value loss": 0.0931733779143542, "Avg policy loss": 0.2819924942450598, "Total num played games": 28690, "Total num trained steps": 56832, "Timestamp in ms": 1702033121329, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802530941454597, "Avg loss": 0.7088775362353772, "Avg value loss": 0.40875602210871875, "Avg policy loss": 0.30012151622213423, "Total num played games": 28764, "Total num trained steps": 56960, "Timestamp in ms": 1702033174758, "logtype": "training_step"}
{"Avg objective": 19.8046875, "Games time in secs": 80.57200502976775, "Avg game time in secs": 3.2400130693567917, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.47}, "Total num played games": 28800, "Total num trained steps": 57023, "Timestamp in ms": 1702033200910, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781011781011781, "Avg loss": 0.8874425676185638, "Avg value loss": 0.5949825388379395, "Avg policy loss": 0.292460028314963, "Total num played games": 28860, "Total num trained steps": 57088, "Timestamp in ms": 1702033227308, "logtype": "training_step"}
{"Total num played games": 28860, "Total num trained steps": 57173, "Timestamp in ms": 1702033369768, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.62109375}
{"Avg objective": 22.109375, "Games time in secs": 173.93239653855562, "Avg game time in secs": 2.742125921708066, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.42}, "Total num played games": 28928, "Total num trained steps": 57184, "Timestamp in ms": 1702033374842, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9761000207225254, "Avg loss": 0.8623118828982115, "Avg value loss": 0.5683578118332662, "Avg policy loss": 0.29395407729316503, "Total num played games": 28954, "Total num trained steps": 57216, "Timestamp in ms": 1702033387410, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9804862885957035, "Avg loss": 0.45242573670111597, "Avg value loss": 0.17062523105414584, "Avg policy loss": 0.28180050710216165, "Total num played games": 28954, "Total num trained steps": 57344, "Timestamp in ms": 1702033440269, "logtype": "training_step"}
{"Ratio train steps to played games": 1.978382099827883, "Avg loss": 0.7556165701244026, "Avg value loss": 0.47655501373810694, "Avg policy loss": 0.27906155004166067, "Total num played games": 29050, "Total num trained steps": 57472, "Timestamp in ms": 1702033492175, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 169.3263801932335, "Avg game time in secs": 3.9947618065634742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8984375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.73, "agent_stopped_0": 0.54}, "Total num played games": 29056, "Total num trained steps": 57593, "Timestamp in ms": 1702033544169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.978429621487944, "Avg loss": 0.4132473957724869, "Avg value loss": 0.1406331627513282, "Avg policy loss": 0.272614230401814, "Total num played games": 29114, "Total num trained steps": 57600, "Timestamp in ms": 1702033546821, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9806491456803679, "Avg loss": 0.6111176987178624, "Avg value loss": 0.3277498160605319, "Avg policy loss": 0.2833678809693083, "Total num played games": 29146, "Total num trained steps": 57728, "Timestamp in ms": 1702033599203, "logtype": "training_step"}
{"Total num played games": 29146, "Total num trained steps": 57773, "Timestamp in ms": 1702033710274, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.734375}
{"Avg objective": 21.75, "Games time in secs": 168.8925792351365, "Avg game time in secs": 2.8607081524678506, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.47}, "Total num played games": 29184, "Total num trained steps": 57779, "Timestamp in ms": 1702033713062, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786593707250342, "Avg loss": 0.7771643402520567, "Avg value loss": 0.49565958965104073, "Avg policy loss": 0.2815047486219555, "Total num played games": 29240, "Total num trained steps": 57856, "Timestamp in ms": 1702033743905, "logtype": "training_step"}
{"Avg objective": 23.1328125, "Games time in secs": 79.7602237612009, "Avg game time in secs": 2.7106629869085737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.41}, "Total num played games": 29312, "Total num trained steps": 57978, "Timestamp in ms": 1702033792822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9774913034581543, "Avg loss": 0.6521659998688847, "Avg value loss": 0.38556408463045955, "Avg policy loss": 0.2666019321186468, "Total num played games": 29322, "Total num trained steps": 57984, "Timestamp in ms": 1702033794966, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9809108262885193, "Avg loss": 0.8246605535969138, "Avg value loss": 0.5349322685506195, "Avg policy loss": 0.2897282767808065, "Total num played games": 29336, "Total num trained steps": 58112, "Timestamp in ms": 1702033847059, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9787985865724382, "Avg loss": 0.8378640515729785, "Avg value loss": 0.5597602214547805, "Avg policy loss": 0.2781038237735629, "Total num played games": 29432, "Total num trained steps": 58240, "Timestamp in ms": 1702033898704, "logtype": "training_step"}
{"Avg objective": 22.0546875, "Games time in secs": 154.38823987171054, "Avg game time in secs": 3.3758693702111486, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7734375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.61, "agent_stopped_0": 0.59}, "Total num played games": 29440, "Total num trained steps": 58356, "Timestamp in ms": 1702033947210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977101822369758, "Avg loss": 0.6194477577228099, "Avg value loss": 0.34109236020594835, "Avg policy loss": 0.27835539798252285, "Total num played games": 29522, "Total num trained steps": 58368, "Timestamp in ms": 1702033951625, "logtype": "training_step"}
{"Total num played games": 29526, "Total num trained steps": 58377, "Timestamp in ms": 1702034072705, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.36328125}
{"Avg objective": 21.953125, "Games time in secs": 128.0290308482945, "Avg game time in secs": 2.3155008362664375, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.73, "agent_stopped_more": 0.27, "played_steps": 0.31}, "Total num played games": 29568, "Total num trained steps": 58380, "Timestamp in ms": 1702034075239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.974881836596894, "Avg loss": 1.1377996464725584, "Avg value loss": 0.8280739799374714, "Avg policy loss": 0.3097256646724418, "Total num played games": 29620, "Total num trained steps": 58496, "Timestamp in ms": 1702034123405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9791694800810264, "Avg loss": 0.3832943239249289, "Avg value loss": 0.10964317954494618, "Avg policy loss": 0.2736511431867257, "Total num played games": 29620, "Total num trained steps": 58624, "Timestamp in ms": 1702034176020, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 147.5579473040998, "Avg game time in secs": 2.4969056356640067, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 29696, "Total num trained steps": 58741, "Timestamp in ms": 1702034222797, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9773828756058158, "Avg loss": 0.4678983010817319, "Avg value loss": 0.21048812905792147, "Avg policy loss": 0.25741017842665315, "Total num played games": 29712, "Total num trained steps": 58752, "Timestamp in ms": 1702034227652, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814241486068112, "Avg loss": 0.5199144270736724, "Avg value loss": 0.24968019250081852, "Avg policy loss": 0.27023423567879945, "Total num played games": 29716, "Total num trained steps": 58880, "Timestamp in ms": 1702034281457, "logtype": "training_step"}
{"Total num played games": 29814, "Total num trained steps": 58977, "Timestamp in ms": 1702034429397, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.546875}
{"Avg objective": 21.75, "Games time in secs": 208.59847970679402, "Avg game time in secs": 3.1304123860027175, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8828125, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.59, "agent_stopped_0": 0.55}, "Total num played games": 29824, "Total num trained steps": 58978, "Timestamp in ms": 1702034431396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9731157627231994, "Avg loss": 0.9965636804699898, "Avg value loss": 0.7175650323624723, "Avg policy loss": 0.2789986546849832, "Total num played games": 29906, "Total num trained steps": 59008, "Timestamp in ms": 1702034443841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9772636083990907, "Avg loss": 0.5053109396249056, "Avg value loss": 0.22274404793279245, "Avg policy loss": 0.2825668902369216, "Total num played games": 29908, "Total num trained steps": 59136, "Timestamp in ms": 1702034495153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9815433997592617, "Avg loss": 0.343019244261086, "Avg value loss": 0.09100980494986288, "Avg policy loss": 0.25200944137759507, "Total num played games": 29908, "Total num trained steps": 59264, "Timestamp in ms": 1702034547964, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 136.4056323952973, "Avg game time in secs": 2.5531957770581357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.49}, "Total num played games": 29952, "Total num trained steps": 59312, "Timestamp in ms": 1702034567802, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9794360751899747, "Avg loss": 0.8548721785191447, "Avg value loss": 0.5808138567372225, "Avg policy loss": 0.27405833010561764, "Total num played games": 30004, "Total num trained steps": 59392, "Timestamp in ms": 1702034600091, "logtype": "training_step"}
{"Avg objective": 22.59375, "Games time in secs": 79.16021728143096, "Avg game time in secs": 2.904875636624638, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.55, "agent_stopped_0": 0.54}, "Total num played games": 30080, "Total num trained steps": 59507, "Timestamp in ms": 1702034646962, "logtype": "played_game"}
{"Ratio train steps to played games": 1.977408637873754, "Avg loss": 0.695308604510501, "Avg value loss": 0.43011488777119666, "Avg policy loss": 0.2651937111513689, "Total num played games": 30100, "Total num trained steps": 59520, "Timestamp in ms": 1702034652320, "logtype": "training_step"}
{"Total num played games": 30100, "Total num trained steps": 59581, "Timestamp in ms": 1702034805313, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.578125}
{"Ratio train steps to played games": 1.9754918195668014, "Avg loss": 1.0268049710430205, "Avg value loss": 0.7329757578554563, "Avg policy loss": 0.2938292067265138, "Total num played games": 30194, "Total num trained steps": 59648, "Timestamp in ms": 1702034832818, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797310723984898, "Avg loss": 0.41516381152905524, "Avg value loss": 0.14041798358084634, "Avg policy loss": 0.27474582684226334, "Total num played games": 30194, "Total num trained steps": 59776, "Timestamp in ms": 1702034884944, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 280.2714446783066, "Avg game time in secs": 3.0409001759253442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8046875, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.51, "agent_stopped_0": 0.61}, "Total num played games": 30208, "Total num trained steps": 59880, "Timestamp in ms": 1702034927234, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778129952456418, "Avg loss": 0.5659613206516951, "Avg value loss": 0.31057964137289673, "Avg policy loss": 0.2553816855652258, "Total num played games": 30288, "Total num trained steps": 59904, "Timestamp in ms": 1702034937611, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9820060750132065, "Avg loss": 0.47614869521930814, "Avg value loss": 0.20886051695561036, "Avg policy loss": 0.2672881743637845, "Total num played games": 30288, "Total num trained steps": 60032, "Timestamp in ms": 1702035000719, "logtype": "training_step"}
{"Avg objective": 22.7109375, "Games time in secs": 92.67139359936118, "Avg game time in secs": 2.4409673824266065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.67, "agent_stopped_more": 0.33, "played_steps": 0.41}, "Total num played games": 30336, "Total num trained steps": 60068, "Timestamp in ms": 1702035019906, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980119807780923, "Avg loss": 0.764879792695865, "Avg value loss": 0.49471815695869736, "Avg policy loss": 0.2701616423437372, "Total num played games": 30382, "Total num trained steps": 60160, "Timestamp in ms": 1702035066483, "logtype": "training_step"}
{"Total num played games": 30382, "Total num trained steps": 60181, "Timestamp in ms": 1702035161444, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.53125}
{"Avg objective": 21.1171875, "Games time in secs": 147.02354869619012, "Avg game time in secs": 2.587535384867806, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 30464, "Total num trained steps": 60190, "Timestamp in ms": 1702035166929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9781795511221945, "Avg loss": 0.8318365949671715, "Avg value loss": 0.5452745956135914, "Avg policy loss": 0.286561997840181, "Total num played games": 30476, "Total num trained steps": 60288, "Timestamp in ms": 1702035218737, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823795773723585, "Avg loss": 0.3518205073196441, "Avg value loss": 0.09341104625491425, "Avg policy loss": 0.25840945972595364, "Total num played games": 30476, "Total num trained steps": 60416, "Timestamp in ms": 1702035285610, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98037419861311, "Avg loss": 0.8157164859585464, "Avg value loss": 0.5355702448287047, "Avg policy loss": 0.2801462454954162, "Total num played games": 30572, "Total num trained steps": 60544, "Timestamp in ms": 1702035342520, "logtype": "training_step"}
{"Avg objective": 21.546875, "Games time in secs": 214.12069022282958, "Avg game time in secs": 2.976233734196285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.64, "agent_stopped_0": 0.52}, "Total num played games": 30592, "Total num trained steps": 60636, "Timestamp in ms": 1702035381050, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9784777929955, "Avg loss": 0.6737520099850371, "Avg value loss": 0.40576785037410446, "Avg policy loss": 0.2679841573117301, "Total num played games": 30666, "Total num trained steps": 60672, "Timestamp in ms": 1702035396807, "logtype": "training_step"}
{"Total num played games": 30666, "Total num trained steps": 60782, "Timestamp in ms": 1702035547283, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8046875}
{"Avg objective": 22.421875, "Games time in secs": 169.86340253427625, "Avg game time in secs": 2.4626621364150196, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.39, "played_steps": 0.44, "agent_stopped_0": 0.61}, "Total num played games": 30720, "Total num trained steps": 60790, "Timestamp in ms": 1702035550914, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9767215033487222, "Avg loss": 0.54374696360901, "Avg value loss": 0.27091702207690105, "Avg policy loss": 0.27282993972767144, "Total num played games": 30758, "Total num trained steps": 60800, "Timestamp in ms": 1702035555124, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9807542262678803, "Avg loss": 0.5914587005972862, "Avg value loss": 0.30684173238114454, "Avg policy loss": 0.2846169676631689, "Total num played games": 30760, "Total num trained steps": 60928, "Timestamp in ms": 1702035608487, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 96.20840601250529, "Avg game time in secs": 2.797062916419236, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.57, "agent_stopped_0": 0.55}, "Total num played games": 30848, "Total num trained steps": 61022, "Timestamp in ms": 1702035647122, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788682180592467, "Avg loss": 0.7752734082750976, "Avg value loss": 0.49881660810206085, "Avg policy loss": 0.2764567913254723, "Total num played games": 30854, "Total num trained steps": 61056, "Timestamp in ms": 1702035662047, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982984378038504, "Avg loss": 0.3981732912361622, "Avg value loss": 0.12510450038826093, "Avg policy loss": 0.2730687928851694, "Total num played games": 30854, "Total num trained steps": 61184, "Timestamp in ms": 1702035714874, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9810016155088852, "Avg loss": 0.8371440158225596, "Avg value loss": 0.5494919778138865, "Avg policy loss": 0.2876520485151559, "Total num played games": 30950, "Total num trained steps": 61312, "Timestamp in ms": 1702035768360, "logtype": "training_step"}
{"Total num played games": 30950, "Total num trained steps": 61386, "Timestamp in ms": 1702035912397, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.75}
{"Avg objective": 22.1953125, "Games time in secs": 267.4107769988477, "Avg game time in secs": 2.4674619563738815, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.46, "agent_stopped_0": 0.63}, "Total num played games": 30976, "Total num trained steps": 61388, "Timestamp in ms": 1702035914533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979126401236954, "Avg loss": 0.6542843051720411, "Avg value loss": 0.3810061528638471, "Avg policy loss": 0.2732781578088179, "Total num played games": 31044, "Total num trained steps": 61440, "Timestamp in ms": 1702035935045, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983249581239531, "Avg loss": 0.37915749743115157, "Avg value loss": 0.11180168180726469, "Avg policy loss": 0.267355814576149, "Total num played games": 31044, "Total num trained steps": 61568, "Timestamp in ms": 1702035989416, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 81.06887212768197, "Avg game time in secs": 2.1247138762264512, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.41, "agent_stopped_0": 0.64}, "Total num played games": 31104, "Total num trained steps": 61583, "Timestamp in ms": 1702035995602, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9811187463875153, "Avg loss": 0.8351298368070275, "Avg value loss": 0.560852630296722, "Avg policy loss": 0.2742771994089708, "Total num played games": 31142, "Total num trained steps": 61696, "Timestamp in ms": 1702036042184, "logtype": "training_step"}
{"Avg objective": 20.828125, "Games time in secs": 84.80290117487311, "Avg game time in secs": 2.547962967888452, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.63}, "Total num played games": 31232, "Total num trained steps": 61788, "Timestamp in ms": 1702036080405, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979222691765911, "Avg loss": 0.7191840745508671, "Avg value loss": 0.4477369421219919, "Avg policy loss": 0.2714471312938258, "Total num played games": 31236, "Total num trained steps": 61824, "Timestamp in ms": 1702036095100, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833525419387885, "Avg loss": 0.4077687857206911, "Avg value loss": 0.12634693627478555, "Avg policy loss": 0.2814218511339277, "Total num played games": 31236, "Total num trained steps": 61952, "Timestamp in ms": 1702036147987, "logtype": "training_step"}
{"Total num played games": 31332, "Total num trained steps": 61990, "Timestamp in ms": 1702036242841, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.046875}
{"Avg objective": 20.984375, "Games time in secs": 164.71250307932496, "Avg game time in secs": 2.2819042515475303, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.45, "agent_stopped_0": 0.66}, "Total num played games": 31360, "Total num trained steps": 61995, "Timestamp in ms": 1702036245118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9754343537198498, "Avg loss": 1.3524057776667178, "Avg value loss": 1.0410429655457847, "Avg policy loss": 0.31136279564816505, "Total num played games": 31426, "Total num trained steps": 62080, "Timestamp in ms": 1702036279960, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795074142429836, "Avg loss": 0.4066265569999814, "Avg value loss": 0.12468039285158738, "Avg policy loss": 0.2819461637409404, "Total num played games": 31426, "Total num trained steps": 62208, "Timestamp in ms": 1702036332081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9835804747661172, "Avg loss": 0.3558796711731702, "Avg value loss": 0.08428314299089834, "Avg policy loss": 0.27159652626141906, "Total num played games": 31426, "Total num trained steps": 62336, "Timestamp in ms": 1702036384976, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 144.59209701791406, "Avg game time in secs": 2.3113208032154944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.51}, "Total num played games": 31488, "Total num trained steps": 62348, "Timestamp in ms": 1702036389710, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9816001522746018, "Avg loss": 0.6377209676429629, "Avg value loss": 0.348682597046718, "Avg policy loss": 0.2890383736230433, "Total num played games": 31522, "Total num trained steps": 62464, "Timestamp in ms": 1702036436906, "logtype": "training_step"}
{"Avg objective": 22.8671875, "Games time in secs": 81.36528005823493, "Avg game time in secs": 2.74317951744888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6484375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.71, "agent_stopped_0": 0.45}, "Total num played games": 31616, "Total num trained steps": 62547, "Timestamp in ms": 1702036471075, "logtype": "played_game"}
{"Total num played games": 31616, "Total num trained steps": 62591, "Timestamp in ms": 1702036612231, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.171875}
{"Ratio train steps to played games": 1.9797570850202428, "Avg loss": 0.904502117075026, "Avg value loss": 0.6151964374003001, "Avg policy loss": 0.2893056769389659, "Total num played games": 31616, "Total num trained steps": 62592, "Timestamp in ms": 1702036612892, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9779249448123621, "Avg loss": 0.8500834791921079, "Avg value loss": 0.5210275205899961, "Avg policy loss": 0.32905596354976296, "Total num played games": 31710, "Total num trained steps": 62720, "Timestamp in ms": 1702036666672, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9819615263323873, "Avg loss": 0.37476428924128413, "Avg value loss": 0.09192544955294579, "Avg policy loss": 0.2828388406196609, "Total num played games": 31710, "Total num trained steps": 62848, "Timestamp in ms": 1702036718718, "logtype": "training_step"}
{"Avg objective": 21.8203125, "Games time in secs": 274.2692534998059, "Avg game time in secs": 2.153787487128284, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.69, "agent_stopped_more": 0.31, "played_steps": 0.39}, "Total num played games": 31744, "Total num trained steps": 62913, "Timestamp in ms": 1702036745345, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800037728730429, "Avg loss": 1.0255103844683617, "Avg value loss": 0.7384877299773507, "Avg policy loss": 0.2870226587401703, "Total num played games": 31806, "Total num trained steps": 62976, "Timestamp in ms": 1702036771543, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836539670564566, "Avg loss": 0.40937583334743977, "Avg value loss": 0.13097616977756843, "Avg policy loss": 0.27839966176543385, "Total num played games": 31812, "Total num trained steps": 63104, "Timestamp in ms": 1702036824423, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 80.50010399892926, "Avg game time in secs": 2.200313334411476, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 31872, "Total num trained steps": 63107, "Timestamp in ms": 1702036825845, "logtype": "played_game"}
{"Total num played games": 31902, "Total num trained steps": 63193, "Timestamp in ms": 1702036996661, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2265625}
{"Ratio train steps to played games": 1.9762470308788598, "Avg loss": 1.0826512051280588, "Avg value loss": 0.7782212106976658, "Avg policy loss": 0.30442998791113496, "Total num played games": 31996, "Total num trained steps": 63232, "Timestamp in ms": 1702037014010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9802475309413676, "Avg loss": 0.5124667403288186, "Avg value loss": 0.21686458319891244, "Avg policy loss": 0.2956021568970755, "Total num played games": 31996, "Total num trained steps": 63360, "Timestamp in ms": 1702037067829, "logtype": "training_step"}
{"Avg objective": 21.0546875, "Games time in secs": 292.28155175596476, "Avg game time in secs": 3.0098696405184455, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.67, "agent_stopped_0": 0.46}, "Total num played games": 32000, "Total num trained steps": 63484, "Timestamp in ms": 1702037118127, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9806576402321083, "Avg loss": 0.3802937427535653, "Avg value loss": 0.10567773951333947, "Avg policy loss": 0.2746160024544224, "Total num played games": 32050, "Total num trained steps": 63488, "Timestamp in ms": 1702037119705, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9823008849557522, "Avg loss": 0.7863804590888321, "Avg value loss": 0.5005354791064747, "Avg policy loss": 0.28584498388227075, "Total num played games": 32092, "Total num trained steps": 63616, "Timestamp in ms": 1702037175302, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 81.70322477817535, "Avg game time in secs": 2.1165922454965767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.66, "agent_stopped_more": 0.34, "played_steps": 0.38}, "Total num played games": 32128, "Total num trained steps": 63678, "Timestamp in ms": 1702037199830, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9804884111104206, "Avg loss": 0.6863428993383422, "Avg value loss": 0.41723336704308167, "Avg policy loss": 0.2691095322370529, "Total num played games": 32186, "Total num trained steps": 63744, "Timestamp in ms": 1702037227312, "logtype": "training_step"}
{"Total num played games": 32186, "Total num trained steps": 63795, "Timestamp in ms": 1702037371119, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.28515625}
{"Avg objective": 21.0703125, "Games time in secs": 174.79532411694527, "Avg game time in secs": 2.2330581900605466, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 32256, "Total num trained steps": 63803, "Timestamp in ms": 1702037374625, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9786864931846344, "Avg loss": 0.8246053599286824, "Avg value loss": 0.5529464857536368, "Avg policy loss": 0.2716588715557009, "Total num played games": 32280, "Total num trained steps": 63872, "Timestamp in ms": 1702037404733, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982651796778191, "Avg loss": 0.3556902086129412, "Avg value loss": 0.09878220135578886, "Avg policy loss": 0.2569080088287592, "Total num played games": 32280, "Total num trained steps": 64000, "Timestamp in ms": 1702037457471, "logtype": "training_step"}
{"Ratio train steps to played games": 1.980604113904503, "Avg loss": 0.6615930536063388, "Avg value loss": 0.40438278566580266, "Avg policy loss": 0.25721026910468936, "Total num played games": 32378, "Total num trained steps": 64128, "Timestamp in ms": 1702037510698, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 185.8875010125339, "Avg game time in secs": 2.418714779196307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7421875, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.52, "agent_stopped_0": 0.58}, "Total num played games": 32384, "Total num trained steps": 64248, "Timestamp in ms": 1702037560513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9788125153978813, "Avg loss": 0.3751648045144975, "Avg value loss": 0.12923817356931977, "Avg policy loss": 0.24592663045041263, "Total num played games": 32472, "Total num trained steps": 64256, "Timestamp in ms": 1702037563546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982632259653877, "Avg loss": 0.528233609511517, "Avg value loss": 0.27205580289592035, "Avg policy loss": 0.25617780431639403, "Total num played games": 32474, "Total num trained steps": 64384, "Timestamp in ms": 1702037615932, "logtype": "training_step"}
{"Total num played games": 32474, "Total num trained steps": 64398, "Timestamp in ms": 1702037684874, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.6953125}
{"Avg objective": 21.53125, "Games time in secs": 126.96204084530473, "Avg game time in secs": 2.202037976210704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.46}, "Total num played games": 32512, "Total num trained steps": 64404, "Timestamp in ms": 1702037687475, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808400884303612, "Avg loss": 0.7638564186636358, "Avg value loss": 0.49089440423995256, "Avg policy loss": 0.2729620160534978, "Total num played games": 32568, "Total num trained steps": 64512, "Timestamp in ms": 1702037733982, "logtype": "training_step"}
{"Avg objective": 22.6796875, "Games time in secs": 96.65080963820219, "Avg game time in secs": 2.3445895523764193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.65, "agent_stopped_0": 0.46}, "Total num played games": 32640, "Total num trained steps": 64633, "Timestamp in ms": 1702037784126, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9791794243723209, "Avg loss": 0.45591378305107355, "Avg value loss": 0.19792961087659933, "Avg policy loss": 0.2579841698752716, "Total num played games": 32660, "Total num trained steps": 64640, "Timestamp in ms": 1702037786907, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827343415171739, "Avg loss": 0.5386370299383998, "Avg value loss": 0.28037741751177236, "Avg policy loss": 0.25825961760710925, "Total num played games": 32666, "Total num trained steps": 64768, "Timestamp in ms": 1702037840158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9808314510713632, "Avg loss": 0.6522592892870307, "Avg value loss": 0.3986119259498082, "Avg policy loss": 0.2536473624641076, "Total num played games": 32762, "Total num trained steps": 64896, "Timestamp in ms": 1702037893515, "logtype": "training_step"}
{"Total num played games": 32762, "Total num trained steps": 65000, "Timestamp in ms": 1702038023287, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.5625}
{"Avg objective": 21.6875, "Games time in secs": 240.87923307344317, "Avg game time in secs": 2.6243703857180662, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.68, "agent_stopped_0": 0.45}, "Total num played games": 32768, "Total num trained steps": 65003, "Timestamp in ms": 1702038025005, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9790601412223034, "Avg loss": 0.6076356971170753, "Avg value loss": 0.3575801105471328, "Avg policy loss": 0.25005558656994253, "Total num played games": 32856, "Total num trained steps": 65024, "Timestamp in ms": 1702038032943, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9829559289018748, "Avg loss": 0.4724896533880383, "Avg value loss": 0.21237142707104795, "Avg policy loss": 0.26011822815053165, "Total num played games": 32856, "Total num trained steps": 65152, "Timestamp in ms": 1702038088613, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 85.47802395001054, "Avg game time in secs": 2.1632186297210865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 32896, "Total num trained steps": 65207, "Timestamp in ms": 1702038110484, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980943132851854, "Avg loss": 0.8587896167300642, "Avg value loss": 0.599869603960542, "Avg policy loss": 0.2589200130896643, "Total num played games": 32954, "Total num trained steps": 65280, "Timestamp in ms": 1702038140242, "logtype": "training_step"}
{"Avg objective": 21.15625, "Games time in secs": 79.49642433226109, "Avg game time in secs": 2.314993710606359, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.56, "agent_stopped_0": 0.51}, "Total num played games": 33024, "Total num trained steps": 65404, "Timestamp in ms": 1702038189980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9789422727822825, "Avg loss": 0.4278504451503977, "Avg value loss": 0.17090242487029172, "Avg policy loss": 0.2569480175152421, "Total num played games": 33052, "Total num trained steps": 65408, "Timestamp in ms": 1702038191543, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982694983965632, "Avg loss": 0.6985709194559604, "Avg value loss": 0.4393637791508809, "Avg policy loss": 0.2592071444960311, "Total num played games": 33054, "Total num trained steps": 65536, "Timestamp in ms": 1702038244385, "logtype": "training_step"}
{"Avg objective": 20.953125, "Games time in secs": 87.05371808633208, "Avg game time in secs": 2.4328055552614387, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 33152, "Total num trained steps": 65603, "Timestamp in ms": 1702038277034, "logtype": "played_game"}
{"Total num played games": 33152, "Total num trained steps": 65603, "Timestamp in ms": 1702038296374, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.484375}
{"Ratio train steps to played games": 1.975064669433917, "Avg loss": 1.0989547605859116, "Avg value loss": 0.8310121764370706, "Avg policy loss": 0.2679425817914307, "Total num played games": 33246, "Total num trained steps": 65664, "Timestamp in ms": 1702038322304, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9789448354689285, "Avg loss": 0.42888109269551933, "Avg value loss": 0.16149066982325166, "Avg policy loss": 0.26739042438566685, "Total num played games": 33246, "Total num trained steps": 65792, "Timestamp in ms": 1702038375271, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9827949226974673, "Avg loss": 0.33120255707763135, "Avg value loss": 0.08591622021049261, "Avg policy loss": 0.24528633733280003, "Total num played games": 33246, "Total num trained steps": 65920, "Timestamp in ms": 1702038426144, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 175.87913878634572, "Avg game time in secs": 2.3018542308127508, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 33280, "Total num trained steps": 65986, "Timestamp in ms": 1702038452913, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9808949673085, "Avg loss": 0.7494834553217515, "Avg value loss": 0.4897246577311307, "Avg policy loss": 0.25975880480837077, "Total num played games": 33342, "Total num trained steps": 66048, "Timestamp in ms": 1702038477644, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844068609811683, "Avg loss": 0.378502833773382, "Avg value loss": 0.11717085837153718, "Avg policy loss": 0.26133197522722185, "Total num played games": 33344, "Total num trained steps": 66176, "Timestamp in ms": 1702038531129, "logtype": "training_step"}
{"Avg objective": 20.9375, "Games time in secs": 79.6694703809917, "Avg game time in secs": 2.325541676109424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 33408, "Total num trained steps": 66179, "Timestamp in ms": 1702038532583, "logtype": "played_game"}
{"Total num played games": 33436, "Total num trained steps": 66203, "Timestamp in ms": 1702038664868, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.39453125}
{"Ratio train steps to played games": 1.9774530271398747, "Avg loss": 1.1046789260581136, "Avg value loss": 0.815055265033152, "Avg policy loss": 0.2896236600354314, "Total num played games": 33530, "Total num trained steps": 66304, "Timestamp in ms": 1702038706782, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981270504026245, "Avg loss": 0.3634009868837893, "Avg value loss": 0.10085200591129251, "Avg policy loss": 0.26254898123443127, "Total num played games": 33530, "Total num trained steps": 66432, "Timestamp in ms": 1702038760496, "logtype": "training_step"}
{"Avg objective": 22.7578125, "Games time in secs": 276.6818821877241, "Avg game time in secs": 2.458889645524323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.63, "agent_stopped_0": 0.5}, "Total num played games": 33536, "Total num trained steps": 66552, "Timestamp in ms": 1702038809267, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9795384249345704, "Avg loss": 0.3950834817951545, "Avg value loss": 0.1445562725130003, "Avg policy loss": 0.25052720308303833, "Total num played games": 33624, "Total num trained steps": 66560, "Timestamp in ms": 1702038812299, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9833452295979062, "Avg loss": 0.636115649715066, "Avg value loss": 0.3668523397645913, "Avg policy loss": 0.2692633109400049, "Total num played games": 33624, "Total num trained steps": 66688, "Timestamp in ms": 1702038865920, "logtype": "training_step"}
{"Avg objective": 22.484375, "Games time in secs": 79.21505337953568, "Avg game time in secs": 1.8980267217266373, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.64, "agent_stopped_more": 0.36, "played_steps": 0.38}, "Total num played games": 33664, "Total num trained steps": 66742, "Timestamp in ms": 1702038888482, "logtype": "played_game"}
{"Total num played games": 33720, "Total num trained steps": 66806, "Timestamp in ms": 1702039072917, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8828125}
{"Avg objective": 21.4609375, "Games time in secs": 188.58606127277017, "Avg game time in secs": 2.371426588855684, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.6}, "Total num played games": 33792, "Total num trained steps": 66815, "Timestamp in ms": 1702039077068, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9769217113438664, "Avg loss": 0.7572310470277444, "Avg value loss": 0.48087901654071175, "Avg policy loss": 0.27635203511454165, "Total num played games": 33798, "Total num trained steps": 66816, "Timestamp in ms": 1702039077254, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9797716921984976, "Avg loss": 0.7469060395378619, "Avg value loss": 0.4336543712997809, "Avg policy loss": 0.31325166556052864, "Total num played games": 33814, "Total num trained steps": 66944, "Timestamp in ms": 1702039129204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983557106523925, "Avg loss": 0.3571046700235456, "Avg value loss": 0.07984288682928309, "Avg policy loss": 0.2772617826703936, "Total num played games": 33814, "Total num trained steps": 67072, "Timestamp in ms": 1702039180987, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981833195706028, "Avg loss": 0.7446650695055723, "Avg value loss": 0.46054030605591834, "Avg policy loss": 0.2841247656615451, "Total num played games": 33908, "Total num trained steps": 67200, "Timestamp in ms": 1702039234010, "logtype": "training_step"}
{"Avg objective": 21.703125, "Games time in secs": 201.9012986496091, "Avg game time in secs": 2.7507330348016694, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.8359375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.78, "agent_stopped_0": 0.44}, "Total num played games": 33920, "Total num trained steps": 67309, "Timestamp in ms": 1702039278970, "logtype": "played_game"}
{"Ratio train steps to played games": 1.979769466007998, "Avg loss": 0.7564836865058169, "Avg value loss": 0.47606472359620966, "Avg policy loss": 0.28041896782815456, "Total num played games": 34008, "Total num trained steps": 67328, "Timestamp in ms": 1702039286891, "logtype": "training_step"}
{"Total num played games": 34008, "Total num trained steps": 67407, "Timestamp in ms": 1702039470839, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.29296875}
{"Avg objective": 22.625, "Games time in secs": 194.28277375921607, "Avg game time in secs": 2.2104375504131895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.46, "agent_stopped_0": 0.62}, "Total num played games": 34048, "Total num trained steps": 67412, "Timestamp in ms": 1702039473253, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9780658025922233, "Avg loss": 0.8090404397808015, "Avg value loss": 0.5078168611507863, "Avg policy loss": 0.3012235815403983, "Total num played games": 34102, "Total num trained steps": 67456, "Timestamp in ms": 1702039490762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981819248137939, "Avg loss": 0.3977482817135751, "Avg value loss": 0.12077119151945226, "Avg policy loss": 0.2769770900486037, "Total num played games": 34102, "Total num trained steps": 67584, "Timestamp in ms": 1702039544941, "logtype": "training_step"}
{"Avg objective": 20.65625, "Games time in secs": 121.04618948325515, "Avg game time in secs": 2.208705555909546, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 34176, "Total num trained steps": 67701, "Timestamp in ms": 1702039594299, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9801146332904433, "Avg loss": 0.4428338115103543, "Avg value loss": 0.17595622924272902, "Avg policy loss": 0.26687758264597505, "Total num played games": 34196, "Total num trained steps": 67712, "Timestamp in ms": 1702039598555, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838285179553163, "Avg loss": 0.4694051309488714, "Avg value loss": 0.19658168376190588, "Avg policy loss": 0.2728234500391409, "Total num played games": 34196, "Total num trained steps": 67840, "Timestamp in ms": 1702039650043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9821522309711286, "Avg loss": 0.7218573205173016, "Avg value loss": 0.4459728754591197, "Avg policy loss": 0.27588444482535124, "Total num played games": 34290, "Total num trained steps": 67968, "Timestamp in ms": 1702039702231, "logtype": "training_step"}
{"Total num played games": 34290, "Total num trained steps": 68010, "Timestamp in ms": 1702039798596, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.63671875}
{"Avg objective": 21.109375, "Games time in secs": 206.417116753757, "Avg game time in secs": 2.2500027783680707, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.55}, "Total num played games": 34304, "Total num trained steps": 68013, "Timestamp in ms": 1702039800716, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980456026058632, "Avg loss": 0.6144127823645249, "Avg value loss": 0.3356572667544242, "Avg policy loss": 0.27875551860779524, "Total num played games": 34384, "Total num trained steps": 68096, "Timestamp in ms": 1702039836004, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841786877617495, "Avg loss": 0.3552525141276419, "Avg value loss": 0.09210484175127931, "Avg policy loss": 0.2631476717069745, "Total num played games": 34384, "Total num trained steps": 68224, "Timestamp in ms": 1702039890216, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 105.53430514037609, "Avg game time in secs": 2.0639860093651805, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.42}, "Total num played games": 34432, "Total num trained steps": 68261, "Timestamp in ms": 1702039906251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824815824583792, "Avg loss": 0.8272228393470868, "Avg value loss": 0.5511093872773927, "Avg policy loss": 0.27611344517208636, "Total num played games": 34478, "Total num trained steps": 68352, "Timestamp in ms": 1702039943541, "logtype": "training_step"}
{"Avg objective": 21.1875, "Games time in secs": 80.4099847972393, "Avg game time in secs": 2.3699017485196237, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.64}, "Total num played games": 34560, "Total num trained steps": 68453, "Timestamp in ms": 1702039986661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980793705889159, "Avg loss": 0.8576568854041398, "Avg value loss": 0.5883665115106851, "Avg policy loss": 0.26929038076195866, "Total num played games": 34572, "Total num trained steps": 68480, "Timestamp in ms": 1702039997483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.4975789033342153, "Avg value loss": 0.2087298209371511, "Avg policy loss": 0.28884908196050674, "Total num played games": 34572, "Total num trained steps": 68608, "Timestamp in ms": 1702040051291, "logtype": "training_step"}
{"Total num played games": 34572, "Total num trained steps": 68613, "Timestamp in ms": 1702040102005, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.953125}
{"Ratio train steps to played games": 1.9828073616800324, "Avg loss": 0.7598746332805604, "Avg value loss": 0.46979965770151466, "Avg policy loss": 0.29007498058490455, "Total num played games": 34666, "Total num trained steps": 68736, "Timestamp in ms": 1702040153315, "logtype": "training_step"}
{"Avg objective": 21.359375, "Games time in secs": 202.4964247830212, "Avg game time in secs": 2.1220884059439413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 34688, "Total num trained steps": 68825, "Timestamp in ms": 1702040189157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9810137506472585, "Avg loss": 0.5564326180610806, "Avg value loss": 0.2864436438539997, "Avg policy loss": 0.2699889715295285, "Total num played games": 34762, "Total num trained steps": 68864, "Timestamp in ms": 1702040205286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846959323399114, "Avg loss": 0.38960744510404766, "Avg value loss": 0.12040803776471876, "Avg policy loss": 0.26919940835796297, "Total num played games": 34762, "Total num trained steps": 68992, "Timestamp in ms": 1702040257803, "logtype": "training_step"}
{"Avg objective": 20.84375, "Games time in secs": 79.75173127651215, "Avg game time in secs": 2.324342495179735, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.55}, "Total num played games": 34816, "Total num trained steps": 69019, "Timestamp in ms": 1702040268909, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982902059785415, "Avg loss": 0.6262162497732788, "Avg value loss": 0.34312366403173655, "Avg policy loss": 0.28309258876834065, "Total num played games": 34858, "Total num trained steps": 69120, "Timestamp in ms": 1702040309953, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 80.34351122379303, "Avg game time in secs": 2.3217373475490604, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 34944, "Total num trained steps": 69214, "Timestamp in ms": 1702040349253, "logtype": "played_game"}
{"Total num played games": 34952, "Total num trained steps": 69214, "Timestamp in ms": 1702040458698, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2734375}
{"Ratio train steps to played games": 1.9759173657478741, "Avg loss": 0.9724119373131543, "Avg value loss": 0.6960891507042106, "Avg policy loss": 0.276322795660235, "Total num played games": 35046, "Total num trained steps": 69248, "Timestamp in ms": 1702040473704, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9795697083832677, "Avg loss": 0.5161480505485088, "Avg value loss": 0.22815627692034468, "Avg policy loss": 0.2879917767131701, "Total num played games": 35046, "Total num trained steps": 69376, "Timestamp in ms": 1702040526481, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832220510186611, "Avg loss": 0.33802248700521886, "Avg value loss": 0.07008844963274896, "Avg policy loss": 0.26793403609190136, "Total num played games": 35046, "Total num trained steps": 69504, "Timestamp in ms": 1702040581337, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 266.3000671043992, "Avg game time in secs": 2.086164684180403, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6328125, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.48, "agent_stopped_0": 0.62}, "Total num played games": 35072, "Total num trained steps": 69585, "Timestamp in ms": 1702040615553, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812211916007512, "Avg loss": 0.7610164443030953, "Avg value loss": 0.4800557701091748, "Avg policy loss": 0.2809606724185869, "Total num played games": 35146, "Total num trained steps": 69632, "Timestamp in ms": 1702040634405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848631423206056, "Avg loss": 0.407215901883319, "Avg value loss": 0.12064030751935206, "Avg policy loss": 0.2865755968960002, "Total num played games": 35146, "Total num trained steps": 69760, "Timestamp in ms": 1702040687100, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 82.42821943387389, "Avg game time in secs": 2.0961570805229712, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 35200, "Total num trained steps": 69786, "Timestamp in ms": 1702040697981, "logtype": "played_game"}
{"Total num played games": 35242, "Total num trained steps": 69818, "Timestamp in ms": 1702040781046, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3828125}
{"Avg objective": 22.859375, "Games time in secs": 89.14912733063102, "Avg game time in secs": 2.4355807012470905, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.734375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 35328, "Total num trained steps": 69832, "Timestamp in ms": 1702040787131, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9778129952456418, "Avg loss": 1.2011638196418062, "Avg value loss": 0.8885250177409034, "Avg policy loss": 0.3126387861557305, "Total num played games": 35336, "Total num trained steps": 69888, "Timestamp in ms": 1702040809713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9814353633688024, "Avg loss": 0.4044926001224667, "Avg value loss": 0.12143594346707687, "Avg policy loss": 0.28305665880907327, "Total num played games": 35336, "Total num trained steps": 70016, "Timestamp in ms": 1702040863038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850577314919629, "Avg loss": 0.3445387042593211, "Avg value loss": 0.07796693436102942, "Avg policy loss": 0.2665717744966969, "Total num played games": 35336, "Total num trained steps": 70144, "Timestamp in ms": 1702040915182, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832637164145406, "Avg loss": 0.7253659509588033, "Avg value loss": 0.4327533718023915, "Avg policy loss": 0.29261257720645517, "Total num played games": 35432, "Total num trained steps": 70272, "Timestamp in ms": 1702040967128, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 214.52610911801457, "Avg game time in secs": 2.3742358275630977, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.63, "agent_stopped_0": 0.52}, "Total num played games": 35456, "Total num trained steps": 70357, "Timestamp in ms": 1702041001657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981647244271801, "Avg loss": 0.6336027679499239, "Avg value loss": 0.3437076357076876, "Avg policy loss": 0.2898951268289238, "Total num played games": 35526, "Total num trained steps": 70400, "Timestamp in ms": 1702041020118, "logtype": "training_step"}
{"Total num played games": 35526, "Total num trained steps": 70422, "Timestamp in ms": 1702041101033, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.8046875}
{"Avg objective": 22.609375, "Games time in secs": 102.49123137816787, "Avg game time in secs": 2.106425361154834, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 35584, "Total num trained steps": 70429, "Timestamp in ms": 1702041104150, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9800112296462662, "Avg loss": 0.9058258596342057, "Avg value loss": 0.5933349395054393, "Avg policy loss": 0.3124909341568127, "Total num played games": 35620, "Total num trained steps": 70528, "Timestamp in ms": 1702041145361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9836047164514319, "Avg loss": 0.3791167023591697, "Avg value loss": 0.08930820517707616, "Avg policy loss": 0.28980849497020245, "Total num played games": 35620, "Total num trained steps": 70656, "Timestamp in ms": 1702041199997, "logtype": "training_step"}
{"Avg objective": 22.203125, "Games time in secs": 132.70735987648368, "Avg game time in secs": 2.654536884481786, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7109375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.77}, "Total num played games": 35712, "Total num trained steps": 70743, "Timestamp in ms": 1702041236857, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981967855742846, "Avg loss": 0.7652329832781106, "Avg value loss": 0.46839850992546417, "Avg policy loss": 0.29683446569833905, "Total num played games": 35714, "Total num trained steps": 70784, "Timestamp in ms": 1702041254056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855518844150752, "Avg loss": 0.4262136381585151, "Avg value loss": 0.1305775053333491, "Avg policy loss": 0.2956361338729039, "Total num played games": 35714, "Total num trained steps": 70912, "Timestamp in ms": 1702041307259, "logtype": "training_step"}
{"Total num played games": 35814, "Total num trained steps": 71022, "Timestamp in ms": 1702041414315, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66796875}
{"Avg objective": 21.71875, "Games time in secs": 179.8686405941844, "Avg game time in secs": 2.1514051397971343, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 35840, "Total num trained steps": 71027, "Timestamp in ms": 1702041416726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9783892168876016, "Avg loss": 1.0185887580737472, "Avg value loss": 0.7106279224099126, "Avg policy loss": 0.3079608285333961, "Total num played games": 35908, "Total num trained steps": 71040, "Timestamp in ms": 1702041422334, "logtype": "training_step"}
{"Ratio train steps to played games": 1.981953882143255, "Avg loss": 0.572334117256105, "Avg value loss": 0.2549332355847582, "Avg policy loss": 0.3174008772475645, "Total num played games": 35908, "Total num trained steps": 71168, "Timestamp in ms": 1702041475755, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855185473989083, "Avg loss": 0.3620771556161344, "Avg value loss": 0.07198530522873625, "Avg policy loss": 0.29009185009635985, "Total num played games": 35908, "Total num trained steps": 71296, "Timestamp in ms": 1702041527796, "logtype": "training_step"}
{"Avg objective": 22.40625, "Games time in secs": 117.08723453432322, "Avg game time in secs": 2.2398765315883793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.6}, "Total num played games": 35968, "Total num trained steps": 71311, "Timestamp in ms": 1702041533813, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9838897839008944, "Avg loss": 0.6869081521872431, "Avg value loss": 0.37752945022657514, "Avg policy loss": 0.3093787053367123, "Total num played games": 36002, "Total num trained steps": 71424, "Timestamp in ms": 1702041578131, "logtype": "training_step"}
{"Avg objective": 22.5859375, "Games time in secs": 76.38498761504889, "Avg game time in secs": 2.300787308224244, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.61}, "Total num played games": 36096, "Total num trained steps": 71504, "Timestamp in ms": 1702041610198, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821596764363676, "Avg loss": 0.9908579343464226, "Avg value loss": 0.6936359041428659, "Avg policy loss": 0.29722202965058386, "Total num played games": 36098, "Total num trained steps": 71552, "Timestamp in ms": 1702041629023, "logtype": "training_step"}
{"Total num played games": 36098, "Total num trained steps": 71626, "Timestamp in ms": 1702041733572, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.4453125}
{"Ratio train steps to played games": 1.9805481874447393, "Avg loss": 0.8312832389492542, "Avg value loss": 0.5154125563567504, "Avg policy loss": 0.3158706951653585, "Total num played games": 36192, "Total num trained steps": 71680, "Timestamp in ms": 1702041758484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840848806366047, "Avg loss": 0.43566933390684426, "Avg value loss": 0.12744738603942096, "Avg policy loss": 0.30822195135988295, "Total num played games": 36192, "Total num trained steps": 71808, "Timestamp in ms": 1702041810936, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 229.271382920444, "Avg game time in secs": 2.0244571848015767, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.51, "agent_stopped_0": 0.6}, "Total num played games": 36224, "Total num trained steps": 71878, "Timestamp in ms": 1702041839470, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9824725789560713, "Avg loss": 0.844559507095255, "Avg value loss": 0.5411435256537516, "Avg policy loss": 0.30341597902588546, "Total num played games": 36286, "Total num trained steps": 71936, "Timestamp in ms": 1702041863144, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856717733935854, "Avg loss": 0.40432229777798057, "Avg value loss": 0.10222570665064268, "Avg policy loss": 0.3020965924952179, "Total num played games": 36292, "Total num trained steps": 72064, "Timestamp in ms": 1702041914274, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 76.64034497737885, "Avg game time in secs": 2.2688592953199986, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.63, "agent_stopped_0": 0.45}, "Total num played games": 36352, "Total num trained steps": 72068, "Timestamp in ms": 1702041916110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843870258383727, "Avg loss": 0.7325493672396988, "Avg value loss": 0.41692152997711673, "Avg policy loss": 0.31562783697154373, "Total num played games": 36380, "Total num trained steps": 72192, "Timestamp in ms": 1702041968292, "logtype": "training_step"}
{"Total num played games": 36380, "Total num trained steps": 72226, "Timestamp in ms": 1702042071826, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.640625}
{"Ratio train steps to played games": 1.9827548390634424, "Avg loss": 0.896299485117197, "Avg value loss": 0.5821468342619482, "Avg policy loss": 0.31415265577379614, "Total num played games": 36474, "Total num trained steps": 72320, "Timestamp in ms": 1702042111127, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 242.1153636984527, "Avg game time in secs": 2.1055194152868353, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.38, "played_steps": 0.48, "agent_stopped_0": 0.62}, "Total num played games": 36480, "Total num trained steps": 72440, "Timestamp in ms": 1702042158226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9815108582681473, "Avg loss": 0.44936549104750156, "Avg value loss": 0.15867131610866636, "Avg policy loss": 0.2906941707478836, "Total num played games": 36562, "Total num trained steps": 72448, "Timestamp in ms": 1702042161193, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9846860643185298, "Avg loss": 0.8724022808019072, "Avg value loss": 0.5517724053934216, "Avg policy loss": 0.32062986760865897, "Total num played games": 36568, "Total num trained steps": 72576, "Timestamp in ms": 1702042214408, "logtype": "training_step"}
{"Avg objective": 21.09375, "Games time in secs": 78.15805221349001, "Avg game time in secs": 2.086209650209639, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.7578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 36608, "Total num trained steps": 72630, "Timestamp in ms": 1702042236384, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830887567508593, "Avg loss": 0.7364747291430831, "Avg value loss": 0.42680858430685475, "Avg policy loss": 0.30966614023782313, "Total num played games": 36662, "Total num trained steps": 72704, "Timestamp in ms": 1702042267082, "logtype": "training_step"}
{"Avg objective": 20.8046875, "Games time in secs": 78.67916861176491, "Avg game time in secs": 2.278854232543381, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.55, "agent_stopped_0": 0.53}, "Total num played games": 36736, "Total num trained steps": 72821, "Timestamp in ms": 1702042315063, "logtype": "played_game"}
{"Total num played games": 36756, "Total num trained steps": 72831, "Timestamp in ms": 1702042381180, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1796875}
{"Ratio train steps to played games": 1.981499619109805, "Avg loss": 0.5169800480362028, "Avg value loss": 0.22085846331901848, "Avg policy loss": 0.2961215851828456, "Total num played games": 36756, "Total num trained steps": 72832, "Timestamp in ms": 1702042381925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9799185888738127, "Avg loss": 0.837316203629598, "Avg value loss": 0.5087419147021137, "Avg policy loss": 0.3285742901498452, "Total num played games": 36850, "Total num trained steps": 72960, "Timestamp in ms": 1702042434279, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983392130257802, "Avg loss": 0.3687191444914788, "Avg value loss": 0.07809863198781386, "Avg policy loss": 0.29062051128130406, "Total num played games": 36850, "Total num trained steps": 73088, "Timestamp in ms": 1702042485979, "logtype": "training_step"}
{"Avg objective": 20.1796875, "Games time in secs": 214.01468493044376, "Avg game time in secs": 2.1500815811159555, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.48, "agent_stopped_0": 0.59}, "Total num played games": 36864, "Total num trained steps": 73192, "Timestamp in ms": 1702042529078, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981810307492421, "Avg loss": 0.6329917768016458, "Avg value loss": 0.3468669772555586, "Avg policy loss": 0.2861247946275398, "Total num played games": 36944, "Total num trained steps": 73216, "Timestamp in ms": 1702042538287, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985275010827198, "Avg loss": 0.5229869906324893, "Avg value loss": 0.22125870271702297, "Avg policy loss": 0.30172828829381615, "Total num played games": 36944, "Total num trained steps": 73344, "Timestamp in ms": 1702042591187, "logtype": "training_step"}
{"Avg objective": 22.046875, "Games time in secs": 77.37168036401272, "Avg game time in secs": 1.9356278538762126, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 36992, "Total num trained steps": 73383, "Timestamp in ms": 1702042606450, "logtype": "played_game"}
{"Total num played games": 37040, "Total num trained steps": 73431, "Timestamp in ms": 1702042659501, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66015625}
{"Avg objective": 21.59375, "Games time in secs": 57.29568900913, "Avg game time in secs": 2.272260044963332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 37120, "Total num trained steps": 73439, "Timestamp in ms": 1702042663746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785641191361016, "Avg loss": 1.099341818364337, "Avg value loss": 0.8031504519458394, "Avg policy loss": 0.296191367902793, "Total num played games": 37134, "Total num trained steps": 73472, "Timestamp in ms": 1702042676842, "logtype": "training_step"}
{"Ratio train steps to played games": 1.982011094953412, "Avg loss": 0.43633434595540166, "Avg value loss": 0.15234888234408572, "Avg policy loss": 0.28398546820972115, "Total num played games": 37134, "Total num trained steps": 73600, "Timestamp in ms": 1702042730651, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854580707707223, "Avg loss": 0.34583615546580404, "Avg value loss": 0.07582701477804221, "Avg policy loss": 0.2700091419974342, "Total num played games": 37134, "Total num trained steps": 73728, "Timestamp in ms": 1702042782549, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9838830987428817, "Avg loss": 0.7087715241359547, "Avg value loss": 0.42283330115606077, "Avg policy loss": 0.2859382285969332, "Total num played games": 37228, "Total num trained steps": 73856, "Timestamp in ms": 1702042835618, "logtype": "training_step"}
{"Avg objective": 22.328125, "Games time in secs": 209.97593519836664, "Avg game time in secs": 2.2169469441869296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.6, "agent_stopped_0": 0.55}, "Total num played games": 37248, "Total num trained steps": 73948, "Timestamp in ms": 1702042873722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822098381738291, "Avg loss": 0.7895336115034297, "Avg value loss": 0.515760711627081, "Avg policy loss": 0.27377290092408657, "Total num played games": 37324, "Total num trained steps": 73984, "Timestamp in ms": 1702042888520, "logtype": "training_step"}
{"Total num played games": 37324, "Total num trained steps": 74033, "Timestamp in ms": 1702042977068, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4765625}
{"Avg objective": 20.84375, "Games time in secs": 105.93542160466313, "Avg game time in secs": 1.9148467083869036, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 37376, "Total num trained steps": 74037, "Timestamp in ms": 1702042979657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.980651023571543, "Avg loss": 0.932506444863975, "Avg value loss": 0.6326115392730571, "Avg policy loss": 0.29989490285515785, "Total num played games": 37418, "Total num trained steps": 74112, "Timestamp in ms": 1702043009914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9840718370837565, "Avg loss": 0.37975213839672506, "Avg value loss": 0.10283664616872557, "Avg policy loss": 0.27691548748407513, "Total num played games": 37418, "Total num trained steps": 74240, "Timestamp in ms": 1702043063800, "logtype": "training_step"}
{"Avg objective": 21.390625, "Games time in secs": 122.94386795535684, "Avg game time in secs": 2.208160666952608, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 37504, "Total num trained steps": 74333, "Timestamp in ms": 1702043102601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982512262742589, "Avg loss": 0.6331044494872913, "Avg value loss": 0.3616876534651965, "Avg policy loss": 0.2714167988160625, "Total num played games": 37512, "Total num trained steps": 74368, "Timestamp in ms": 1702043116778, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859245041586693, "Avg loss": 0.38893141923472285, "Avg value loss": 0.10927570358035155, "Avg policy loss": 0.2796557151013985, "Total num played games": 37512, "Total num trained steps": 74496, "Timestamp in ms": 1702043168267, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984364197202574, "Avg loss": 0.725527044152841, "Avg value loss": 0.42847722047008574, "Avg policy loss": 0.2970498186768964, "Total num played games": 37606, "Total num trained steps": 74624, "Timestamp in ms": 1702043218908, "logtype": "training_step"}
{"Total num played games": 37606, "Total num trained steps": 74636, "Timestamp in ms": 1702043313502, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.70703125}
{"Avg objective": 20.875, "Games time in secs": 212.97224113717675, "Avg game time in secs": 2.090754760109121, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.51}, "Total num played games": 37632, "Total num trained steps": 74640, "Timestamp in ms": 1702043315574, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828116710875332, "Avg loss": 0.6984456744976342, "Avg value loss": 0.40447845606831834, "Avg policy loss": 0.29396722302772105, "Total num played games": 37700, "Total num trained steps": 74752, "Timestamp in ms": 1702043361440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986206896551724, "Avg loss": 0.34280091791879386, "Avg value loss": 0.07378870766842738, "Avg policy loss": 0.269012211705558, "Total num played games": 37700, "Total num trained steps": 74880, "Timestamp in ms": 1702043412127, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 102.4000724516809, "Avg game time in secs": 1.9785222757491283, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.54}, "Total num played games": 37760, "Total num trained steps": 74895, "Timestamp in ms": 1702043417974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9845486294846015, "Avg loss": 0.8271814731415361, "Avg value loss": 0.5321889268234372, "Avg policy loss": 0.29499254713300616, "Total num played games": 37796, "Total num trained steps": 75008, "Timestamp in ms": 1702043464191, "logtype": "training_step"}
{"Avg objective": 23.40625, "Games time in secs": 80.2356876693666, "Avg game time in secs": 2.299311255424982, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5546875, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.77, "agent_stopped_0": 0.4}, "Total num played games": 37888, "Total num trained steps": 75093, "Timestamp in ms": 1702043498210, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830034309844287, "Avg loss": 0.8533956001047045, "Avg value loss": 0.5556198456324637, "Avg policy loss": 0.2977757495827973, "Total num played games": 37890, "Total num trained steps": 75136, "Timestamp in ms": 1702043516326, "logtype": "training_step"}
{"Total num played games": 37890, "Total num trained steps": 75239, "Timestamp in ms": 1702043643677, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4375}
{"Ratio train steps to played games": 1.9814658803706824, "Avg loss": 0.700556798139587, "Avg value loss": 0.4105631008860655, "Avg policy loss": 0.28999369277153164, "Total num played games": 37984, "Total num trained steps": 75264, "Timestamp in ms": 1702043655148, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9848357203032856, "Avg loss": 0.5615331851877272, "Avg value loss": 0.2615901198296342, "Avg policy loss": 0.29994306713342667, "Total num played games": 37984, "Total num trained steps": 75392, "Timestamp in ms": 1702043708131, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 237.78746089711785, "Avg game time in secs": 1.8893608784710523, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 38016, "Total num trained steps": 75461, "Timestamp in ms": 1702043735997, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9832974420925469, "Avg loss": 0.7719730460084975, "Avg value loss": 0.47844192924094386, "Avg policy loss": 0.29353111633099616, "Total num played games": 38078, "Total num trained steps": 75520, "Timestamp in ms": 1702043759899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986241663603424, "Avg loss": 0.37209901167079806, "Avg value loss": 0.08931431392556988, "Avg policy loss": 0.2827846964355558, "Total num played games": 38086, "Total num trained steps": 75648, "Timestamp in ms": 1702043812100, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 77.17150108143687, "Avg game time in secs": 2.006664881686447, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 38144, "Total num trained steps": 75650, "Timestamp in ms": 1702043813169, "logtype": "played_game"}
{"Ratio train steps to played games": 1.985119983233784, "Avg loss": 0.6422691408079118, "Avg value loss": 0.34829346157494, "Avg policy loss": 0.29397567792329937, "Total num played games": 38172, "Total num trained steps": 75776, "Timestamp in ms": 1702043865515, "logtype": "training_step"}
{"Total num played games": 38270, "Total num trained steps": 75843, "Timestamp in ms": 1702043999649, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.21484375}
{"Avg objective": 21.5078125, "Games time in secs": 187.7486596032977, "Avg game time in secs": 2.1284179664216936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 38272, "Total num trained steps": 75843, "Timestamp in ms": 1702044000918, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9785215306016057, "Avg loss": 1.4878095230087638, "Avg value loss": 1.179793511313619, "Avg policy loss": 0.308016020571813, "Total num played games": 38364, "Total num trained steps": 75904, "Timestamp in ms": 1702044025665, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9818579918673758, "Avg loss": 0.45794247509911656, "Avg value loss": 0.16214051039423794, "Avg policy loss": 0.2958019678480923, "Total num played games": 38364, "Total num trained steps": 76032, "Timestamp in ms": 1702044077584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851944531331456, "Avg loss": 0.35601787525229156, "Avg value loss": 0.07325506609049626, "Avg policy loss": 0.2827628086088225, "Total num played games": 38364, "Total num trained steps": 76160, "Timestamp in ms": 1702044130359, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 153.8800927400589, "Avg game time in secs": 1.7804396405990701, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.4}, "Total num played games": 38400, "Total num trained steps": 76221, "Timestamp in ms": 1702044154798, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835673426937077, "Avg loss": 0.6936203418299556, "Avg value loss": 0.40515108354156837, "Avg policy loss": 0.2884692548541352, "Total num played games": 38460, "Total num trained steps": 76288, "Timestamp in ms": 1702044181301, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 79.52468810603023, "Avg game time in secs": 1.93286680750316, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 38528, "Total num trained steps": 76414, "Timestamp in ms": 1702044234323, "logtype": "played_game"}
{"Ratio train steps to played games": 1.982462512322939, "Avg loss": 0.3904868592508137, "Avg value loss": 0.11543450120370835, "Avg policy loss": 0.2750523587455973, "Total num played games": 38542, "Total num trained steps": 76416, "Timestamp in ms": 1702044234993, "logtype": "training_step"}
{"Total num played games": 38554, "Total num trained steps": 76444, "Timestamp in ms": 1702044336716, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.3671875}
{"Ratio train steps to played games": 1.9805423307803767, "Avg loss": 1.1573766614310443, "Avg value loss": 0.8469006833038293, "Avg policy loss": 0.3104759850539267, "Total num played games": 38648, "Total num trained steps": 76544, "Timestamp in ms": 1702044377756, "logtype": "training_step"}
{"Ratio train steps to played games": 1.983854274477334, "Avg loss": 0.38210719102062285, "Avg value loss": 0.1016157308476977, "Avg policy loss": 0.2804914611624554, "Total num played games": 38648, "Total num trained steps": 76672, "Timestamp in ms": 1702044430630, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 243.2047348357737, "Avg game time in secs": 2.0057129492633976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 38656, "Total num trained steps": 76787, "Timestamp in ms": 1702044477528, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9823447421403129, "Avg loss": 0.4967694381484762, "Avg value loss": 0.22088961122790352, "Avg policy loss": 0.2758798253489658, "Total num played games": 38742, "Total num trained steps": 76800, "Timestamp in ms": 1702044482476, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856486500438801, "Avg loss": 0.5588846763130277, "Avg value loss": 0.26632684862124734, "Avg policy loss": 0.2925578268477693, "Total num played games": 38742, "Total num trained steps": 76928, "Timestamp in ms": 1702044534440, "logtype": "training_step"}
{"Avg objective": 22.125, "Games time in secs": 76.65608924254775, "Avg game time in secs": 1.8144316613615956, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.42}, "Total num played games": 38784, "Total num trained steps": 76978, "Timestamp in ms": 1702044554184, "logtype": "played_game"}
{"Total num played games": 38838, "Total num trained steps": 77048, "Timestamp in ms": 1702044672147, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.30859375}
{"Avg objective": 20.90625, "Games time in secs": 121.01385957747698, "Avg game time in secs": 1.9421523576893378, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 38912, "Total num trained steps": 77054, "Timestamp in ms": 1702044675198, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9798561151079137, "Avg loss": 0.8400748441927135, "Avg value loss": 0.5381028867559507, "Avg policy loss": 0.3019719519652426, "Total num played games": 38920, "Total num trained steps": 77056, "Timestamp in ms": 1702044676030, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9825336484126168, "Avg loss": 0.6783862509764731, "Avg value loss": 0.36925557150971144, "Avg policy loss": 0.3091306739952415, "Total num played games": 38932, "Total num trained steps": 77184, "Timestamp in ms": 1702044727573, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98582143224083, "Avg loss": 0.3463240957353264, "Avg value loss": 0.0708070567343384, "Avg policy loss": 0.27551703818608075, "Total num played games": 38932, "Total num trained steps": 77312, "Timestamp in ms": 1702044779496, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984216459977452, "Avg loss": 0.7705950590316206, "Avg value loss": 0.4782308462599758, "Avg policy loss": 0.292364216176793, "Total num played games": 39028, "Total num trained steps": 77440, "Timestamp in ms": 1702044830333, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 197.83279962465167, "Avg game time in secs": 2.1472943916451186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.67, "agent_stopped_0": 0.47}, "Total num played games": 39040, "Total num trained steps": 77548, "Timestamp in ms": 1702044873031, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9827207197996013, "Avg loss": 0.5723630078136921, "Avg value loss": 0.2901396909437608, "Avg policy loss": 0.28222332487348467, "Total num played games": 39122, "Total num trained steps": 77568, "Timestamp in ms": 1702044880736, "logtype": "training_step"}
{"Total num played games": 39122, "Total num trained steps": 77650, "Timestamp in ms": 1702044995413, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.59765625}
{"Avg objective": 21.3828125, "Games time in secs": 124.70615310966969, "Avg game time in secs": 1.9519743765413295, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.49}, "Total num played games": 39168, "Total num trained steps": 77654, "Timestamp in ms": 1702044997737, "logtype": "played_game"}
{"Ratio train steps to played games": 1.981232150142799, "Avg loss": 1.0045684720389545, "Avg value loss": 0.6801335324998945, "Avg policy loss": 0.3244349507149309, "Total num played games": 39216, "Total num trained steps": 77696, "Timestamp in ms": 1702045014742, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9844961240310077, "Avg loss": 0.41196135617792606, "Avg value loss": 0.10375711560482159, "Avg policy loss": 0.30820423969998956, "Total num played games": 39216, "Total num trained steps": 77824, "Timestamp in ms": 1702045068134, "logtype": "training_step"}
{"Avg objective": 20.03125, "Games time in secs": 112.78438940644264, "Avg game time in secs": 1.9748939029523171, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 39296, "Total num trained steps": 77928, "Timestamp in ms": 1702045110522, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9828051075952586, "Avg loss": 0.6228008400648832, "Avg value loss": 0.33127042031264864, "Avg policy loss": 0.29153042135294527, "Total num played games": 39314, "Total num trained steps": 77952, "Timestamp in ms": 1702045120272, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9860609452103577, "Avg loss": 0.4432897127699107, "Avg value loss": 0.14626092565595172, "Avg policy loss": 0.29702879034448415, "Total num played games": 39314, "Total num trained steps": 78080, "Timestamp in ms": 1702045171582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9845716605765327, "Avg loss": 0.7138857466634363, "Avg value loss": 0.42027903551934287, "Avg policy loss": 0.29360671364702284, "Total num played games": 39408, "Total num trained steps": 78208, "Timestamp in ms": 1702045221840, "logtype": "training_step"}
{"Total num played games": 39408, "Total num trained steps": 78253, "Timestamp in ms": 1702045284589, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.99609375}
{"Avg objective": 21.8515625, "Games time in secs": 175.7245534658432, "Avg game time in secs": 1.9805852944846265, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.59, "agent_stopped_0": 0.49}, "Total num played games": 39424, "Total num trained steps": 78256, "Timestamp in ms": 1702045286246, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830894638246164, "Avg loss": 0.87370978994295, "Avg value loss": 0.5764541643729899, "Avg policy loss": 0.2972556222230196, "Total num played games": 39502, "Total num trained steps": 78336, "Timestamp in ms": 1702045317959, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863298060857677, "Avg loss": 0.36314566258806735, "Avg value loss": 0.09010053990641609, "Avg policy loss": 0.27304512332193553, "Total num played games": 39502, "Total num trained steps": 78464, "Timestamp in ms": 1702045369385, "logtype": "training_step"}
{"Avg objective": 22.96875, "Games time in secs": 96.99118559062481, "Avg game time in secs": 1.855791270674672, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.44}, "Total num played games": 39552, "Total num trained steps": 78498, "Timestamp in ms": 1702045383241, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848469542378018, "Avg loss": 0.825339277042076, "Avg value loss": 0.5365021658944897, "Avg policy loss": 0.28883711888920516, "Total num played games": 39596, "Total num trained steps": 78592, "Timestamp in ms": 1702045422728, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 79.00971621274948, "Avg game time in secs": 1.9937101126706693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 39680, "Total num trained steps": 78688, "Timestamp in ms": 1702045462251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833459309649786, "Avg loss": 0.67376344720833, "Avg value loss": 0.40318841752014123, "Avg policy loss": 0.2705750314053148, "Total num played games": 39690, "Total num trained steps": 78720, "Timestamp in ms": 1702045475342, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9865961199294533, "Avg loss": 0.40590223018079996, "Avg value loss": 0.13480534058180638, "Avg policy loss": 0.271096887299791, "Total num played games": 39690, "Total num trained steps": 78848, "Timestamp in ms": 1702045527486, "logtype": "training_step"}
{"Total num played games": 39690, "Total num trained steps": 78856, "Timestamp in ms": 1702045594108, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.09375}
{"Ratio train steps to played games": 1.98511964608888, "Avg loss": 0.6686614754144102, "Avg value loss": 0.3913347669877112, "Avg policy loss": 0.2773267099400982, "Total num played games": 39784, "Total num trained steps": 78976, "Timestamp in ms": 1702045645131, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 217.0119286440313, "Avg game time in secs": 1.8129776470013894, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.51, "agent_stopped_0": 0.55}, "Total num played games": 39808, "Total num trained steps": 79060, "Timestamp in ms": 1702045679263, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9836501329053613, "Avg loss": 0.6204890293302014, "Avg value loss": 0.3548264615528751, "Avg policy loss": 0.26566256885416806, "Total num played games": 39878, "Total num trained steps": 79104, "Timestamp in ms": 1702045697485, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868599227644315, "Avg loss": 0.36511920928023756, "Avg value loss": 0.10611709469230846, "Avg policy loss": 0.25900211394764483, "Total num played games": 39878, "Total num trained steps": 79232, "Timestamp in ms": 1702045751697, "logtype": "training_step"}
{"Avg objective": 20.375, "Games time in secs": 79.8716091401875, "Avg game time in secs": 1.8207818535156548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 39936, "Total num trained steps": 79250, "Timestamp in ms": 1702045759134, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9853897728409886, "Avg loss": 0.5351710601244122, "Avg value loss": 0.2506675721378997, "Avg policy loss": 0.2845034922938794, "Total num played games": 39972, "Total num trained steps": 79360, "Timestamp in ms": 1702045804407, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 79.66931577026844, "Avg game time in secs": 2.0436128052242566, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.66}, "Total num played games": 40064, "Total num trained steps": 79444, "Timestamp in ms": 1702045838804, "logtype": "played_game"}
{"Total num played games": 40066, "Total num trained steps": 79459, "Timestamp in ms": 1702045922226, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.453125}
{"Ratio train steps to played games": 1.9792828685258965, "Avg loss": 1.301726337405853, "Avg value loss": 1.019251410238212, "Avg policy loss": 0.2824749128194526, "Total num played games": 40160, "Total num trained steps": 79488, "Timestamp in ms": 1702045934542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9824701195219123, "Avg loss": 0.7001230493187904, "Avg value loss": 0.3797667371109128, "Avg policy loss": 0.3203563205897808, "Total num played games": 40160, "Total num trained steps": 79616, "Timestamp in ms": 1702045988524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9856573705179283, "Avg loss": 0.3581806740257889, "Avg value loss": 0.07476938134641387, "Avg policy loss": 0.2834112923592329, "Total num played games": 40160, "Total num trained steps": 79744, "Timestamp in ms": 1702046042058, "logtype": "training_step"}
{"Avg objective": 22.71875, "Games time in secs": 231.85581880062819, "Avg game time in secs": 1.8052948843105696, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.45, "agent_stopped_0": 0.59}, "Total num played games": 40192, "Total num trained steps": 79813, "Timestamp in ms": 1702046070660, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842003279177225, "Avg loss": 0.7934239255264401, "Avg value loss": 0.5103931816993281, "Avg policy loss": 0.28303075348958373, "Total num played games": 40254, "Total num trained steps": 79872, "Timestamp in ms": 1702046094999, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869852466345437, "Avg loss": 0.3622186775319278, "Avg value loss": 0.08489695232128724, "Avg policy loss": 0.2773217250360176, "Total num played games": 40258, "Total num trained steps": 80000, "Timestamp in ms": 1702046148319, "logtype": "training_step"}
{"Avg objective": 20.578125, "Games time in secs": 78.77491211146116, "Avg game time in secs": 1.7928863801935222, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 40320, "Total num trained steps": 80003, "Timestamp in ms": 1702046149435, "logtype": "played_game"}
{"Total num played games": 40348, "Total num trained steps": 80061, "Timestamp in ms": 1702046246715, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.05859375}
{"Ratio train steps to played games": 1.9813065624845458, "Avg loss": 1.0444084303453565, "Avg value loss": 0.7405920077580959, "Avg policy loss": 0.3038164322497323, "Total num played games": 40442, "Total num trained steps": 80128, "Timestamp in ms": 1702046276542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.984471588942189, "Avg loss": 0.37904591928236187, "Avg value loss": 0.09296683224965818, "Avg policy loss": 0.2860790860140696, "Total num played games": 40442, "Total num trained steps": 80256, "Timestamp in ms": 1702046328177, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 228.30122589319944, "Avg game time in secs": 1.969757886196021, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.57}, "Total num played games": 40448, "Total num trained steps": 80375, "Timestamp in ms": 1702046377736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9831252775447772, "Avg loss": 0.43603231362067163, "Avg value loss": 0.16535486467182636, "Avg policy loss": 0.2706774518592283, "Total num played games": 40534, "Total num trained steps": 80384, "Timestamp in ms": 1702046381314, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861851194000395, "Avg loss": 0.7289775414392352, "Avg value loss": 0.4413398674223572, "Avg policy loss": 0.28763767902273685, "Total num played games": 40536, "Total num trained steps": 80512, "Timestamp in ms": 1702046435296, "logtype": "training_step"}
{"Avg objective": 23.0625, "Games time in secs": 79.45303863286972, "Avg game time in secs": 1.8195603255589958, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.49}, "Total num played games": 40576, "Total num trained steps": 80564, "Timestamp in ms": 1702046457189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847403396505046, "Avg loss": 0.8555809534154832, "Avg value loss": 0.5696937317261472, "Avg policy loss": 0.2858872094657272, "Total num played games": 40630, "Total num trained steps": 80640, "Timestamp in ms": 1702046488925, "logtype": "training_step"}
{"Total num played games": 40630, "Total num trained steps": 80661, "Timestamp in ms": 1702046567437, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.87890625}
{"Avg objective": 22.3046875, "Games time in secs": 113.51606936752796, "Avg game time in secs": 1.9223647106846329, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 40704, "Total num trained steps": 80668, "Timestamp in ms": 1702046570707, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833022296434535, "Avg loss": 0.7113574417307973, "Avg value loss": 0.4263595470110886, "Avg policy loss": 0.28499788837507367, "Total num played games": 40724, "Total num trained steps": 80768, "Timestamp in ms": 1702046612214, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986420783812985, "Avg loss": 0.33681474428158253, "Avg value loss": 0.07591607558424585, "Avg policy loss": 0.26089866820257157, "Total num played games": 40724, "Total num trained steps": 80896, "Timestamp in ms": 1702046663440, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9850066147287961, "Avg loss": 0.8149624461075291, "Avg value loss": 0.5419697729230393, "Avg policy loss": 0.2729926845058799, "Total num played games": 40818, "Total num trained steps": 81024, "Timestamp in ms": 1702046714905, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 187.40232472494245, "Avg game time in secs": 1.9753232463554014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.41, "played_steps": 0.47, "agent_stopped_0": 0.59}, "Total num played games": 40832, "Total num trained steps": 81128, "Timestamp in ms": 1702046758110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9835745013687915, "Avg loss": 0.5717390640638769, "Avg value loss": 0.30581048381282017, "Avg policy loss": 0.2659285820554942, "Total num played games": 40912, "Total num trained steps": 81152, "Timestamp in ms": 1702046767898, "logtype": "training_step"}
{"Total num played games": 40912, "Total num trained steps": 81264, "Timestamp in ms": 1702046889258, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5}
{"Avg objective": 21.75, "Games time in secs": 133.5898080393672, "Avg game time in secs": 1.743029586650664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.4}, "Total num played games": 40960, "Total num trained steps": 81267, "Timestamp in ms": 1702046891700, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9821489538116372, "Avg loss": 0.5721920123323798, "Avg value loss": 0.30416233619325794, "Avg policy loss": 0.26802967756520957, "Total num played games": 41006, "Total num trained steps": 81280, "Timestamp in ms": 1702046896483, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9852704482270886, "Avg loss": 0.5526816351339221, "Avg value loss": 0.2799703544587828, "Avg policy loss": 0.27271127875428647, "Total num played games": 41006, "Total num trained steps": 81408, "Timestamp in ms": 1702046950328, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 101.30178891867399, "Avg game time in secs": 1.8864951790310442, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.5}, "Total num played games": 41088, "Total num trained steps": 81509, "Timestamp in ms": 1702046993002, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9837477495012408, "Avg loss": 0.7023947878042236, "Avg value loss": 0.44014872252591886, "Avg policy loss": 0.2622460644925013, "Total num played games": 41102, "Total num trained steps": 81536, "Timestamp in ms": 1702047003809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868619531896259, "Avg loss": 0.4139632931910455, "Avg value loss": 0.1448313917790074, "Avg policy loss": 0.2691318995784968, "Total num played games": 41102, "Total num trained steps": 81664, "Timestamp in ms": 1702047056652, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9854112049713564, "Avg loss": 0.6510151494294405, "Avg value loss": 0.3708576329227071, "Avg policy loss": 0.28015751973725855, "Total num played games": 41196, "Total num trained steps": 81792, "Timestamp in ms": 1702047108857, "logtype": "training_step"}
{"Total num played games": 41196, "Total num trained steps": 81865, "Timestamp in ms": 1702047202434, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.57421875}
{"Avg objective": 20.9375, "Games time in secs": 211.23612516745925, "Avg game time in secs": 1.926476237771567, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.42, "played_steps": 0.51, "agent_stopped_0": 0.58}, "Total num played games": 41216, "Total num trained steps": 81868, "Timestamp in ms": 1702047204238, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840155001210946, "Avg loss": 0.7662261086516082, "Avg value loss": 0.48818953803856857, "Avg policy loss": 0.2780365669168532, "Total num played games": 41290, "Total num trained steps": 81920, "Timestamp in ms": 1702047225489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9871155243400338, "Avg loss": 0.38227078947238624, "Avg value loss": 0.11191143241012469, "Avg policy loss": 0.27035936154425144, "Total num played games": 41290, "Total num trained steps": 82048, "Timestamp in ms": 1702047277207, "logtype": "training_step"}
{"Avg objective": 21.3046875, "Games time in secs": 82.99208310618997, "Avg game time in secs": 1.8556765567045659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.63, "agent_stopped_more": 0.37, "played_steps": 0.42}, "Total num played games": 41344, "Total num trained steps": 82073, "Timestamp in ms": 1702047287230, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856949545718152, "Avg loss": 0.8665667996974662, "Avg value loss": 0.5733091971487738, "Avg policy loss": 0.293257586308755, "Total num played games": 41384, "Total num trained steps": 82176, "Timestamp in ms": 1702047329197, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 77.61261424794793, "Avg game time in secs": 1.9414549291250296, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.59}, "Total num played games": 41472, "Total num trained steps": 82264, "Timestamp in ms": 1702047364843, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984280823569121, "Avg loss": 0.7066623938735574, "Avg value loss": 0.4283725126006175, "Avg policy loss": 0.27828988002147526, "Total num played games": 41478, "Total num trained steps": 82304, "Timestamp in ms": 1702047381584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873667968561648, "Avg loss": 0.38160536368377507, "Avg value loss": 0.11283580560120754, "Avg policy loss": 0.26876955630723387, "Total num played games": 41478, "Total num trained steps": 82432, "Timestamp in ms": 1702047434561, "logtype": "training_step"}
{"Total num played games": 41576, "Total num trained steps": 82467, "Timestamp in ms": 1702047549958, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.74609375}
{"Avg objective": 20.53125, "Games time in secs": 186.89112405851483, "Avg game time in secs": 1.8740123002498876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.51, "agent_stopped_0": 0.52}, "Total num played games": 41600, "Total num trained steps": 82470, "Timestamp in ms": 1702047551734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9812814974802015, "Avg loss": 1.1138764973729849, "Avg value loss": 0.8250017435639165, "Avg policy loss": 0.28887473966460675, "Total num played games": 41670, "Total num trained steps": 82560, "Timestamp in ms": 1702047588486, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9843532517398608, "Avg loss": 0.37127944512758404, "Avg value loss": 0.1118249888822902, "Avg policy loss": 0.25945445359684527, "Total num played games": 41670, "Total num trained steps": 82688, "Timestamp in ms": 1702047640558, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98742500599952, "Avg loss": 0.3230974123580381, "Avg value loss": 0.0738977676955983, "Avg policy loss": 0.24919964373111725, "Total num played games": 41670, "Total num trained steps": 82816, "Timestamp in ms": 1702047693456, "logtype": "training_step"}
{"Avg objective": 22.0234375, "Games time in secs": 148.6717364154756, "Avg game time in secs": 1.731585516827181, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 41728, "Total num trained steps": 82834, "Timestamp in ms": 1702047700407, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860166650703956, "Avg loss": 0.6565477806143463, "Avg value loss": 0.39468850841512904, "Avg policy loss": 0.26185926946345717, "Total num played games": 41764, "Total num trained steps": 82944, "Timestamp in ms": 1702047744159, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 77.40234883502126, "Avg game time in secs": 2.021219259419013, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.54}, "Total num played games": 41856, "Total num trained steps": 83027, "Timestamp in ms": 1702047777810, "logtype": "played_game"}
{"Total num played games": 41858, "Total num trained steps": 83067, "Timestamp in ms": 1702047895388, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.53125}
{"Ratio train steps to played games": 1.9810177898602566, "Avg loss": 0.6961054659914225, "Avg value loss": 0.44886867099558003, "Avg policy loss": 0.24723679071757942, "Total num played games": 41934, "Total num trained steps": 83072, "Timestamp in ms": 1702047898284, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832189168573608, "Avg loss": 0.6907578743994236, "Avg value loss": 0.41863415780244395, "Avg policy loss": 0.27212372177746147, "Total num played games": 41952, "Total num trained steps": 83200, "Timestamp in ms": 1702047951823, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862700228832952, "Avg loss": 0.3190822754986584, "Avg value loss": 0.07705350767355412, "Avg policy loss": 0.2420287661952898, "Total num played games": 41952, "Total num trained steps": 83328, "Timestamp in ms": 1702048003035, "logtype": "training_step"}
{"Avg objective": 22.8125, "Games time in secs": 253.36752519756556, "Avg game time in secs": 1.6973686871642713, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.72, "agent_stopped_more": 0.28, "played_steps": 0.34}, "Total num played games": 41984, "Total num trained steps": 83396, "Timestamp in ms": 1702048031178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847792998477929, "Avg loss": 0.9783562764059752, "Avg value loss": 0.7304525441722944, "Avg policy loss": 0.2479037211742252, "Total num played games": 42048, "Total num trained steps": 83456, "Timestamp in ms": 1702048054741, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878234398782344, "Avg loss": 0.3785868607228622, "Avg value loss": 0.12861315280315466, "Avg policy loss": 0.24997370911296457, "Total num played games": 42048, "Total num trained steps": 83584, "Timestamp in ms": 1702048105761, "logtype": "training_step"}
{"Avg objective": 20.546875, "Games time in secs": 76.9479055032134, "Avg game time in secs": 1.8573387013166212, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 42112, "Total num trained steps": 83590, "Timestamp in ms": 1702048108126, "logtype": "played_game"}
{"Total num played games": 42142, "Total num trained steps": 83668, "Timestamp in ms": 1702048236194, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.01171875}
{"Ratio train steps to played games": 1.98200587176816, "Avg loss": 1.159217617707327, "Avg value loss": 0.8923326096846722, "Avg policy loss": 0.2668850035406649, "Total num played games": 42236, "Total num trained steps": 83712, "Timestamp in ms": 1702048255524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985036461786154, "Avg loss": 0.44925757055170834, "Avg value loss": 0.19144172227242962, "Avg policy loss": 0.25781584926880896, "Total num played games": 42236, "Total num trained steps": 83840, "Timestamp in ms": 1702048309061, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 250.9889646321535, "Avg game time in secs": 1.8595901223015971, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 42240, "Total num trained steps": 83963, "Timestamp in ms": 1702048359115, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9841209829867674, "Avg loss": 0.3009894232964143, "Avg value loss": 0.07253085833508521, "Avg policy loss": 0.2284585654269904, "Total num played games": 42320, "Total num trained steps": 83968, "Timestamp in ms": 1702048360766, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866761162296245, "Avg loss": 0.5262413717573509, "Avg value loss": 0.2930369723471813, "Avg policy loss": 0.23320439271628857, "Total num played games": 42330, "Total num trained steps": 84096, "Timestamp in ms": 1702048414133, "logtype": "training_step"}
{"Avg objective": 20.484375, "Games time in secs": 78.72322076186538, "Avg game time in secs": 1.7697912263683975, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.41}, "Total num played games": 42368, "Total num trained steps": 84154, "Timestamp in ms": 1702048437838, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852913445219686, "Avg loss": 0.5729477135464549, "Avg value loss": 0.3368863031791989, "Avg policy loss": 0.236061408999376, "Total num played games": 42424, "Total num trained steps": 84224, "Timestamp in ms": 1702048467217, "logtype": "training_step"}
{"Total num played games": 42424, "Total num trained steps": 84268, "Timestamp in ms": 1702048572977, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.2890625}
{"Avg objective": 22.09375, "Games time in secs": 137.68336116150022, "Avg game time in secs": 1.8485563363938127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 42496, "Total num trained steps": 84273, "Timestamp in ms": 1702048575521, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9839126957994262, "Avg loss": 0.6894149617291987, "Avg value loss": 0.43562593270326033, "Avg policy loss": 0.2537890215171501, "Total num played games": 42518, "Total num trained steps": 84352, "Timestamp in ms": 1702048608091, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869231854743874, "Avg loss": 0.3212845386005938, "Avg value loss": 0.08147995648323558, "Avg policy loss": 0.23980458336882293, "Total num played games": 42518, "Total num trained steps": 84480, "Timestamp in ms": 1702048660955, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9855439782220972, "Avg loss": 0.7396227834979072, "Avg value loss": 0.5025943272339646, "Avg policy loss": 0.23702845035586506, "Total num played games": 42612, "Total num trained steps": 84608, "Timestamp in ms": 1702048713269, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 181.83836324512959, "Avg game time in secs": 1.9530197181738913, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.59}, "Total num played games": 42624, "Total num trained steps": 84716, "Timestamp in ms": 1702048757360, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840779245106304, "Avg loss": 0.6811954145086929, "Avg value loss": 0.4479673444875516, "Avg policy loss": 0.23322805436328053, "Total num played games": 42708, "Total num trained steps": 84736, "Timestamp in ms": 1702048765657, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9870750210733352, "Avg loss": 0.4701050150906667, "Avg value loss": 0.2144932848168537, "Avg policy loss": 0.2556117291096598, "Total num played games": 42708, "Total num trained steps": 84864, "Timestamp in ms": 1702048818895, "logtype": "training_step"}
{"Total num played games": 42708, "Total num trained steps": 84870, "Timestamp in ms": 1702048841790, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.00390625}
{"Avg objective": 22.2578125, "Games time in secs": 86.64941408857703, "Avg game time in secs": 1.7398824218835216, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 42752, "Total num trained steps": 84873, "Timestamp in ms": 1702048844009, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9857016027288446, "Avg loss": 0.9076848265249282, "Avg value loss": 0.6493851432169322, "Avg policy loss": 0.2582996805431321, "Total num played games": 42802, "Total num trained steps": 84992, "Timestamp in ms": 1702048894483, "logtype": "training_step"}
{"Avg objective": 23.15625, "Games time in secs": 94.87119990214705, "Avg game time in secs": 2.005282734084176, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 42880, "Total num trained steps": 85100, "Timestamp in ms": 1702048938881, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9843342036553524, "Avg loss": 0.8231408924330026, "Avg value loss": 0.5812189804564696, "Avg policy loss": 0.2419219184666872, "Total num played games": 42896, "Total num trained steps": 85120, "Timestamp in ms": 1702048946416, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873181648638567, "Avg loss": 0.5567664396949112, "Avg value loss": 0.29855740020866506, "Avg policy loss": 0.2582090438809246, "Total num played games": 42896, "Total num trained steps": 85248, "Timestamp in ms": 1702049000249, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859502209816235, "Avg loss": 0.7694171832408756, "Avg value loss": 0.510034811886726, "Avg policy loss": 0.2593823604984209, "Total num played games": 42990, "Total num trained steps": 85376, "Timestamp in ms": 1702049051220, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 151.64834674820304, "Avg game time in secs": 1.9061009383003693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.546875, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.46, "agent_stopped_0": 0.63}, "Total num played games": 43008, "Total num trained steps": 85472, "Timestamp in ms": 1702049090530, "logtype": "played_game"}
{"Total num played games": 43084, "Total num trained steps": 85472, "Timestamp in ms": 1702049186589, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.3359375}
{"Avg objective": 23.234375, "Games time in secs": 98.54143786430359, "Avg game time in secs": 1.902187046391191, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.47}, "Total num played games": 43136, "Total num trained steps": 85476, "Timestamp in ms": 1702049189071, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9802677289360322, "Avg loss": 0.9239614403340966, "Avg value loss": 0.6686034738377202, "Avg policy loss": 0.2553579550003633, "Total num played games": 43178, "Total num trained steps": 85504, "Timestamp in ms": 1702049200428, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9832322015841402, "Avg loss": 0.5862585264258087, "Avg value loss": 0.2817842020886019, "Avg policy loss": 0.3044743228238076, "Total num played games": 43178, "Total num trained steps": 85632, "Timestamp in ms": 1702049252596, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9861966742322479, "Avg loss": 0.34711840748786926, "Avg value loss": 0.07517020925297402, "Avg policy loss": 0.2719481961103156, "Total num played games": 43178, "Total num trained steps": 85760, "Timestamp in ms": 1702049304481, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 153.55822031199932, "Avg game time in secs": 1.9429231345711742, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.52}, "Total num played games": 43264, "Total num trained steps": 85851, "Timestamp in ms": 1702049342629, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847483477376715, "Avg loss": 0.7125833440804854, "Avg value loss": 0.43718969394103624, "Avg policy loss": 0.2753936508670449, "Total num played games": 43274, "Total num trained steps": 85888, "Timestamp in ms": 1702049357580, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877062439340019, "Avg loss": 0.39917125878855586, "Avg value loss": 0.11785341848735698, "Avg policy loss": 0.28131784324068576, "Total num played games": 43274, "Total num trained steps": 86016, "Timestamp in ms": 1702049411544, "logtype": "training_step"}
{"Total num played games": 43368, "Total num trained steps": 86074, "Timestamp in ms": 1702049486033, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.875}
{"Avg objective": 21.015625, "Games time in secs": 145.29193921387196, "Avg game time in secs": 1.7952905153506435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.36, "played_steps": 0.39, "agent_stopped_0": 0.64}, "Total num played games": 43392, "Total num trained steps": 86078, "Timestamp in ms": 1702049487921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9820532879296857, "Avg loss": 0.8301024585962296, "Avg value loss": 0.5342475398501847, "Avg policy loss": 0.2958549138857052, "Total num played games": 43462, "Total num trained steps": 86144, "Timestamp in ms": 1702049515451, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9849983893976346, "Avg loss": 0.3559992825612426, "Avg value loss": 0.09265516509185545, "Avg policy loss": 0.26334411709103733, "Total num played games": 43462, "Total num trained steps": 86272, "Timestamp in ms": 1702049567240, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879434908655838, "Avg loss": 0.31138994987122715, "Avg value loss": 0.061199629766633734, "Avg policy loss": 0.25019031926058233, "Total num played games": 43462, "Total num trained steps": 86400, "Timestamp in ms": 1702049618949, "logtype": "training_step"}
{"Avg objective": 21.765625, "Games time in secs": 138.32897805422544, "Avg game time in secs": 1.9009577913675457, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 43520, "Total num trained steps": 86418, "Timestamp in ms": 1702049626251, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865919735512902, "Avg loss": 0.6523468203376979, "Avg value loss": 0.3867460485198535, "Avg policy loss": 0.2656007700134069, "Total num played games": 43556, "Total num trained steps": 86528, "Timestamp in ms": 1702049672291, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 79.37043632939458, "Avg game time in secs": 1.8342106766067445, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.43}, "Total num played games": 43648, "Total num trained steps": 86610, "Timestamp in ms": 1702049705621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98524627720504, "Avg loss": 0.669135760399513, "Avg value loss": 0.3979783525574021, "Avg policy loss": 0.27115740696899593, "Total num played games": 43650, "Total num trained steps": 86656, "Timestamp in ms": 1702049724125, "logtype": "training_step"}
{"Total num played games": 43650, "Total num trained steps": 86678, "Timestamp in ms": 1702049839016, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.58203125}
{"Ratio train steps to played games": 1.98390636430139, "Avg loss": 0.8018242279067636, "Avg value loss": 0.5016586112906225, "Avg policy loss": 0.3001656226115301, "Total num played games": 43744, "Total num trained steps": 86784, "Timestamp in ms": 1702049883098, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9868324798829553, "Avg loss": 0.3501234403811395, "Avg value loss": 0.07492489920696244, "Avg policy loss": 0.27519854344427586, "Total num played games": 43744, "Total num trained steps": 86912, "Timestamp in ms": 1702049934873, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 257.8793843537569, "Avg game time in secs": 1.758917580213165, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.34, "played_steps": 0.41, "agent_stopped_0": 0.66}, "Total num played games": 43776, "Total num trained steps": 86981, "Timestamp in ms": 1702049963501, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854920388703865, "Avg loss": 0.717997302301228, "Avg value loss": 0.4446953216684051, "Avg policy loss": 0.2733019778970629, "Total num played games": 43838, "Total num trained steps": 87040, "Timestamp in ms": 1702049987116, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875957679678948, "Avg loss": 0.36012895044405013, "Avg value loss": 0.08763087951228954, "Avg policy loss": 0.2724980666534975, "Total num played games": 43852, "Total num trained steps": 87168, "Timestamp in ms": 1702050039243, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 76.80294915661216, "Avg game time in secs": 1.883849513338646, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.52, "agent_stopped_0": 0.55}, "Total num played games": 43904, "Total num trained steps": 87170, "Timestamp in ms": 1702050040304, "logtype": "played_game"}
{"Total num played games": 43932, "Total num trained steps": 87280, "Timestamp in ms": 1702050184812, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.640625}
{"Ratio train steps to played games": 1.9828283287148503, "Avg loss": 0.8786325838882476, "Avg value loss": 0.585189504257869, "Avg policy loss": 0.2934430862078443, "Total num played games": 44026, "Total num trained steps": 87296, "Timestamp in ms": 1702050192051, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857357016308546, "Avg loss": 0.4471644589211792, "Avg value loss": 0.16643697337713093, "Avg policy loss": 0.280727484729141, "Total num played games": 44026, "Total num trained steps": 87424, "Timestamp in ms": 1702050245302, "logtype": "training_step"}
{"Avg objective": 21.171875, "Games time in secs": 253.7720835916698, "Avg game time in secs": 1.824013073113747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 44032, "Total num trained steps": 87544, "Timestamp in ms": 1702050294076, "logtype": "played_game"}
{"Ratio train steps to played games": 1.984586091214072, "Avg loss": 0.3944413379067555, "Avg value loss": 0.1326328004943207, "Avg policy loss": 0.26180853857658803, "Total num played games": 44116, "Total num trained steps": 87552, "Timestamp in ms": 1702050297073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873073436083408, "Avg loss": 0.6541200417559594, "Avg value loss": 0.37640401924727485, "Avg policy loss": 0.27771602058783174, "Total num played games": 44120, "Total num trained steps": 87680, "Timestamp in ms": 1702050350814, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 78.1421909071505, "Avg game time in secs": 1.7942737055418547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_0": 0.65, "agent_stopped_more": 0.35, "played_steps": 0.41}, "Total num played games": 44160, "Total num trained steps": 87733, "Timestamp in ms": 1702050372218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98597729226037, "Avg loss": 0.7544861348578706, "Avg value loss": 0.4806974811654072, "Avg policy loss": 0.2737886548275128, "Total num played games": 44214, "Total num trained steps": 87808, "Timestamp in ms": 1702050404181, "logtype": "training_step"}
{"Total num played games": 44214, "Total num trained steps": 87881, "Timestamp in ms": 1702050534169, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.9296875}
{"Avg objective": 22.4453125, "Games time in secs": 165.4790076725185, "Avg game time in secs": 1.9325154767138883, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 44288, "Total num trained steps": 87888, "Timestamp in ms": 1702050537698, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9846528843549698, "Avg loss": 0.6183232376351953, "Avg value loss": 0.33864175277994946, "Avg policy loss": 0.27968148281797767, "Total num played games": 44308, "Total num trained steps": 87936, "Timestamp in ms": 1702050557807, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875417531822697, "Avg loss": 0.37945392564870417, "Avg value loss": 0.11065811465959996, "Avg policy loss": 0.2687958087772131, "Total num played games": 44308, "Total num trained steps": 88064, "Timestamp in ms": 1702050612338, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9862168370794109, "Avg loss": 0.5905239481944591, "Avg value loss": 0.3237740356998984, "Avg policy loss": 0.2667499053059146, "Total num played games": 44402, "Total num trained steps": 88192, "Timestamp in ms": 1702050665561, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 171.16430321335793, "Avg game time in secs": 1.9981553846155293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.61, "agent_stopped_0": 0.53}, "Total num played games": 44416, "Total num trained steps": 88296, "Timestamp in ms": 1702050708862, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848975188781015, "Avg loss": 0.5840366173069924, "Avg value loss": 0.32911386754130945, "Avg policy loss": 0.25492274411953986, "Total num played games": 44496, "Total num trained steps": 88320, "Timestamp in ms": 1702050718583, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877741819489392, "Avg loss": 0.43282826198264956, "Avg value loss": 0.16745803179219365, "Avg policy loss": 0.2653702284442261, "Total num played games": 44496, "Total num trained steps": 88448, "Timestamp in ms": 1702050769329, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 76.30348839983344, "Avg game time in secs": 1.7648039784107823, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.45}, "Total num played games": 44544, "Total num trained steps": 88485, "Timestamp in ms": 1702050785166, "logtype": "played_game"}
{"Total num played games": 44590, "Total num trained steps": 88485, "Timestamp in ms": 1702050878433, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.953125}
{"Avg objective": 22.0703125, "Games time in secs": 96.54981284216046, "Avg game time in secs": 1.9056139573513065, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.44, "played_steps": 0.52, "agent_stopped_0": 0.56}, "Total num played games": 44672, "Total num trained steps": 88492, "Timestamp in ms": 1702050881715, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9822755348670664, "Avg loss": 1.0491455447627231, "Avg value loss": 0.7769098460557871, "Avg policy loss": 0.27223570365458727, "Total num played games": 44684, "Total num trained steps": 88576, "Timestamp in ms": 1702050916927, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9851177155133828, "Avg loss": 0.3292869810247794, "Avg value loss": 0.08183464349713176, "Avg policy loss": 0.24745233519934118, "Total num played games": 44684, "Total num trained steps": 88704, "Timestamp in ms": 1702050969541, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988004654910035, "Avg loss": 0.2962328363209963, "Avg value loss": 0.059794756147312, "Avg policy loss": 0.23643808288034052, "Total num played games": 44684, "Total num trained steps": 88832, "Timestamp in ms": 1702051021073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9866898923578542, "Avg loss": 0.827205323963426, "Avg value loss": 0.5765229508979246, "Avg policy loss": 0.2506823744624853, "Total num played games": 44778, "Total num trained steps": 88960, "Timestamp in ms": 1702051073648, "logtype": "training_step"}
{"Avg objective": 22.9765625, "Games time in secs": 228.17163705080748, "Avg game time in secs": 1.932833824539557, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.59, "agent_stopped_0": 0.53}, "Total num played games": 44800, "Total num trained steps": 89049, "Timestamp in ms": 1702051109887, "logtype": "played_game"}
{"Total num played games": 44872, "Total num trained steps": 89085, "Timestamp in ms": 1702051218992, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.9765625}
{"Ratio train steps to played games": 1.9852036723415634, "Avg loss": 0.9083306917455047, "Avg value loss": 0.6634723240276799, "Avg policy loss": 0.24485836131498218, "Total num played games": 44876, "Total num trained steps": 89088, "Timestamp in ms": 1702051220478, "logtype": "training_step"}
{"Avg objective": 22.3125, "Games time in secs": 111.81647567823529, "Avg game time in secs": 1.8465669553552289, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 44928, "Total num trained steps": 89091, "Timestamp in ms": 1702051221704, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9840768580705421, "Avg loss": 0.7895897466223687, "Avg value loss": 0.49848099797964096, "Avg policy loss": 0.29110875295009464, "Total num played games": 44966, "Total num trained steps": 89216, "Timestamp in ms": 1702051274404, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869234532758084, "Avg loss": 0.3328434319701046, "Avg value loss": 0.07890749641228467, "Avg policy loss": 0.25393593462649733, "Total num played games": 44966, "Total num trained steps": 89344, "Timestamp in ms": 1702051324272, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 138.94590256735682, "Avg game time in secs": 2.1900497733731754, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 45056, "Total num trained steps": 89432, "Timestamp in ms": 1702051360650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855969818020418, "Avg loss": 0.7070566231850535, "Avg value loss": 0.45428168948274106, "Avg policy loss": 0.25277493614703417, "Total num played games": 45060, "Total num trained steps": 89472, "Timestamp in ms": 1702051377833, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884598313359965, "Avg loss": 0.378507646615617, "Avg value loss": 0.12812481904984452, "Avg policy loss": 0.2503828277112916, "Total num played games": 45060, "Total num trained steps": 89600, "Timestamp in ms": 1702051428302, "logtype": "training_step"}
{"Total num played games": 45154, "Total num trained steps": 89689, "Timestamp in ms": 1702051531486, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5}
{"Avg objective": 21.890625, "Games time in secs": 172.93212355673313, "Avg game time in secs": 1.8356780877511483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.37, "played_steps": 0.42, "agent_stopped_0": 0.63}, "Total num played games": 45184, "Total num trained steps": 89693, "Timestamp in ms": 1702051533582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983026874115983, "Avg loss": 1.26055249851197, "Avg value loss": 0.9938654877187219, "Avg policy loss": 0.26668700808659196, "Total num played games": 45248, "Total num trained steps": 89728, "Timestamp in ms": 1702051548158, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9858557284299858, "Avg loss": 0.43800449930131435, "Avg value loss": 0.1792940718587488, "Avg policy loss": 0.2587104272097349, "Total num played games": 45248, "Total num trained steps": 89856, "Timestamp in ms": 1702051599308, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886845827439887, "Avg loss": 0.305822950322181, "Avg value loss": 0.06473010050831363, "Avg policy loss": 0.24109285010490566, "Total num played games": 45248, "Total num trained steps": 89984, "Timestamp in ms": 1702051651561, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 120.50998405367136, "Avg game time in secs": 1.871674225636525, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 45312, "Total num trained steps": 89991, "Timestamp in ms": 1702051654092, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987384764677341, "Avg loss": 0.6857790125068277, "Avg value loss": 0.4201041977794375, "Avg policy loss": 0.26567482168320566, "Total num played games": 45342, "Total num trained steps": 90112, "Timestamp in ms": 1702051702698, "logtype": "training_step"}
{"Ratio train steps to played games": 1.98609032485254, "Avg loss": 0.5923868390964344, "Avg value loss": 0.32977970127831213, "Avg policy loss": 0.26260713778901845, "Total num played games": 45436, "Total num trained steps": 90240, "Timestamp in ms": 1702051754008, "logtype": "training_step"}
{"Total num played games": 45436, "Total num trained steps": 90293, "Timestamp in ms": 1702051838738, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.66015625}
{"Avg objective": 20.453125, "Games time in secs": 185.92898131161928, "Avg game time in secs": 2.1542413385468535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.69, "agent_stopped_0": 0.43}, "Total num played games": 45440, "Total num trained steps": 90294, "Timestamp in ms": 1702051840021, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9848012299582694, "Avg loss": 0.6899145359639078, "Avg value loss": 0.41429864257224835, "Avg policy loss": 0.2756158874835819, "Total num played games": 45530, "Total num trained steps": 90368, "Timestamp in ms": 1702051870421, "logtype": "training_step"}
{"Ratio train steps to played games": 1.987612563145179, "Avg loss": 0.3538077078992501, "Avg value loss": 0.08994789567077532, "Avg policy loss": 0.26385981123894453, "Total num played games": 45530, "Total num trained steps": 90496, "Timestamp in ms": 1702051922842, "logtype": "training_step"}
{"Avg objective": 21.3984375, "Games time in secs": 105.66037066280842, "Avg game time in secs": 1.936669678951148, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.49}, "Total num played games": 45568, "Total num trained steps": 90553, "Timestamp in ms": 1702051945682, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863010696124848, "Avg loss": 0.5473084510304034, "Avg value loss": 0.27325574011774734, "Avg policy loss": 0.27405271539464593, "Total num played games": 45624, "Total num trained steps": 90624, "Timestamp in ms": 1702051975380, "logtype": "training_step"}
{"Avg objective": 21.625, "Games time in secs": 77.83105590566993, "Avg game time in secs": 1.9222908637893852, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.55, "agent_stopped_0": 0.52}, "Total num played games": 45696, "Total num trained steps": 90743, "Timestamp in ms": 1702052023513, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849518810148732, "Avg loss": 0.5191578548401594, "Avg value loss": 0.2564443971205037, "Avg policy loss": 0.26271345978602767, "Total num played games": 45720, "Total num trained steps": 90752, "Timestamp in ms": 1702052026993, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877515310586176, "Avg loss": 0.5592666890006512, "Avg value loss": 0.2837854001845699, "Avg policy loss": 0.27548128948546946, "Total num played games": 45720, "Total num trained steps": 90880, "Timestamp in ms": 1702052079203, "logtype": "training_step"}
{"Total num played games": 45720, "Total num trained steps": 90896, "Timestamp in ms": 1702052141707, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.93359375}
{"Ratio train steps to played games": 1.9864670188152094, "Avg loss": 0.7611195218050852, "Avg value loss": 0.4694145568064414, "Avg policy loss": 0.29170496307779104, "Total num played games": 45814, "Total num trained steps": 91008, "Timestamp in ms": 1702052188303, "logtype": "training_step"}
{"Avg objective": 21.84375, "Games time in secs": 211.10489800944924, "Avg game time in secs": 2.03636087992345, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 45824, "Total num trained steps": 91120, "Timestamp in ms": 1702052234618, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9851877668380238, "Avg loss": 0.5143607407808304, "Avg value loss": 0.2419501819240395, "Avg policy loss": 0.272410556091927, "Total num played games": 45908, "Total num trained steps": 91136, "Timestamp in ms": 1702052241248, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9879759519038076, "Avg loss": 0.5741775797214359, "Avg value loss": 0.287445209803991, "Avg policy loss": 0.2867323727114126, "Total num played games": 45908, "Total num trained steps": 91264, "Timestamp in ms": 1702052294096, "logtype": "training_step"}
{"Avg objective": 21.5390625, "Games time in secs": 77.02608734741807, "Avg game time in secs": 1.8725654734880663, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.5}, "Total num played games": 45952, "Total num trained steps": 91310, "Timestamp in ms": 1702052311644, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866962305986697, "Avg loss": 0.6382273850031197, "Avg value loss": 0.3468857920379378, "Avg policy loss": 0.2913415968650952, "Total num played games": 46002, "Total num trained steps": 91392, "Timestamp in ms": 1702052344936, "logtype": "training_step"}
{"Avg objective": 22.296875, "Games time in secs": 77.46117995679379, "Avg game time in secs": 2.211846487974981, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.74, "agent_stopped_0": 0.34}, "Total num played games": 46080, "Total num trained steps": 91499, "Timestamp in ms": 1702052389106, "logtype": "played_game"}
{"Total num played games": 46096, "Total num trained steps": 91499, "Timestamp in ms": 1702052457535, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.69140625}
{"Ratio train steps to played games": 1.9813812513531068, "Avg loss": 0.9048858734313399, "Avg value loss": 0.6160625976335723, "Avg policy loss": 0.2888232828117907, "Total num played games": 46190, "Total num trained steps": 91520, "Timestamp in ms": 1702052467474, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9841524139424118, "Avg loss": 0.7093525673262775, "Avg value loss": 0.37502836826024577, "Avg policy loss": 0.33432418992742896, "Total num played games": 46190, "Total num trained steps": 91648, "Timestamp in ms": 1702052517784, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9869235765317168, "Avg loss": 0.3597581796348095, "Avg value loss": 0.0668898667790927, "Avg policy loss": 0.2928683131467551, "Total num played games": 46190, "Total num trained steps": 91776, "Timestamp in ms": 1702052569845, "logtype": "training_step"}
{"Avg objective": 21.015625, "Games time in secs": 219.21530389413238, "Avg game time in secs": 2.0816409269464202, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 46208, "Total num trained steps": 91872, "Timestamp in ms": 1702052608321, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855679903210475, "Avg loss": 0.6759844196494669, "Avg value loss": 0.3801466519362293, "Avg policy loss": 0.2958377655595541, "Total num played games": 46286, "Total num trained steps": 91904, "Timestamp in ms": 1702052620868, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883334053493498, "Avg loss": 0.45546315563842654, "Avg value loss": 0.1560339726274833, "Avg policy loss": 0.2994291812647134, "Total num played games": 46286, "Total num trained steps": 92032, "Timestamp in ms": 1702052672095, "logtype": "training_step"}
{"Avg objective": 21.9921875, "Games time in secs": 77.30782441049814, "Avg game time in secs": 1.7719503795378841, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.62, "agent_stopped_more": 0.38, "played_steps": 0.42}, "Total num played games": 46336, "Total num trained steps": 92066, "Timestamp in ms": 1702052685629, "logtype": "played_game"}
{"Total num played games": 46380, "Total num trained steps": 92099, "Timestamp in ms": 1702052768168, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.36328125}
{"Avg objective": 22.0859375, "Games time in secs": 86.27624034136534, "Avg game time in secs": 2.1341981293226127, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.61, "agent_stopped_0": 0.41}, "Total num played games": 46464, "Total num trained steps": 92106, "Timestamp in ms": 1702052771905, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9830442828248052, "Avg loss": 1.1180143328383565, "Avg value loss": 0.7962946308834944, "Avg policy loss": 0.3217197002377361, "Total num played games": 46474, "Total num trained steps": 92160, "Timestamp in ms": 1702052794823, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9857769935878125, "Avg loss": 0.42063903133384883, "Avg value loss": 0.11043982591945678, "Avg policy loss": 0.31019920588005334, "Total num played games": 46474, "Total num trained steps": 92288, "Timestamp in ms": 1702052848406, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885527391659852, "Avg loss": 0.3537845117971301, "Avg value loss": 0.05869760119821876, "Avg policy loss": 0.2950869086198509, "Total num played games": 46474, "Total num trained steps": 92416, "Timestamp in ms": 1702052900591, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9872874076619138, "Avg loss": 0.7735805222764611, "Avg value loss": 0.4622234273410868, "Avg policy loss": 0.31135709793306887, "Total num played games": 46568, "Total num trained steps": 92544, "Timestamp in ms": 1702052950741, "logtype": "training_step"}
{"Avg objective": 21.96875, "Games time in secs": 212.49075576290488, "Avg game time in secs": 1.9171744165651035, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.54, "agent_stopped_0": 0.55}, "Total num played games": 46592, "Total num trained steps": 92629, "Timestamp in ms": 1702052984396, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986027174145986, "Avg loss": 0.7120611622231081, "Avg value loss": 0.40751184584223665, "Avg policy loss": 0.30454931675922126, "Total num played games": 46662, "Total num trained steps": 92672, "Timestamp in ms": 1702053001832, "logtype": "training_step"}
{"Total num played games": 46662, "Total num trained steps": 92700, "Timestamp in ms": 1702053060843, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.37109375}
{"Avg objective": 20.9140625, "Games time in secs": 79.14845009148121, "Avg game time in secs": 1.985017794475425, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.6}, "Total num played games": 46720, "Total num trained steps": 92705, "Timestamp in ms": 1702053063545, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9847720078706477, "Avg loss": 0.7806812606286258, "Avg value loss": 0.44880238216137514, "Avg policy loss": 0.33187888818793, "Total num played games": 46756, "Total num trained steps": 92800, "Timestamp in ms": 1702053101330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875096244332278, "Avg loss": 0.3836215592455119, "Avg value loss": 0.07350612722802907, "Avg policy loss": 0.3101154296891764, "Total num played games": 46756, "Total num trained steps": 92928, "Timestamp in ms": 1702053152893, "logtype": "training_step"}
{"Avg objective": 22.4453125, "Games time in secs": 121.81683035194874, "Avg game time in secs": 2.197186020464869, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.59375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 46848, "Total num trained steps": 93011, "Timestamp in ms": 1702053185362, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862326574172893, "Avg loss": 0.7197070464026183, "Avg value loss": 0.40866845165146515, "Avg policy loss": 0.31103860202711076, "Total num played games": 46850, "Total num trained steps": 93056, "Timestamp in ms": 1702053202893, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889861259338313, "Avg loss": 0.4154358468949795, "Avg value loss": 0.10256021254463121, "Avg policy loss": 0.31287563464138657, "Total num played games": 46850, "Total num trained steps": 93184, "Timestamp in ms": 1702053256451, "logtype": "training_step"}
{"Total num played games": 46944, "Total num trained steps": 93305, "Timestamp in ms": 1702053317700, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6875}
{"Avg objective": 21.1796875, "Games time in secs": 134.38443552702665, "Avg game time in secs": 1.8402801810880192, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 46976, "Total num trained steps": 93307, "Timestamp in ms": 1702053319746, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9842640241568494, "Avg loss": 0.8183380758855492, "Avg value loss": 0.48404770268825814, "Avg policy loss": 0.33429038373287767, "Total num played games": 47026, "Total num trained steps": 93312, "Timestamp in ms": 1702053321528, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986479016965007, "Avg loss": 0.7487437599338591, "Avg value loss": 0.39819697543862276, "Avg policy loss": 0.35054678621236235, "Total num played games": 47038, "Total num trained steps": 93440, "Timestamp in ms": 1702053375827, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888619648854313, "Avg loss": 0.38935633818618953, "Avg value loss": 0.06115562966442667, "Avg policy loss": 0.32820070546586066, "Total num played games": 47046, "Total num trained steps": 93568, "Timestamp in ms": 1702053428306, "logtype": "training_step"}
{"Avg objective": 20.6796875, "Games time in secs": 110.0674097277224, "Avg game time in secs": 2.003593245492084, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 47104, "Total num trained steps": 93572, "Timestamp in ms": 1702053429814, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879275227021982, "Avg loss": 0.6301731641869992, "Avg value loss": 0.29241247358731925, "Avg policy loss": 0.3377606834983453, "Total num played games": 47132, "Total num trained steps": 93696, "Timestamp in ms": 1702053480363, "logtype": "training_step"}
{"Ratio train steps to played games": 1.986702240291365, "Avg loss": 0.8913558386266232, "Avg value loss": 0.5599323913629632, "Avg policy loss": 0.33142344071529806, "Total num played games": 47226, "Total num trained steps": 93824, "Timestamp in ms": 1702053532619, "logtype": "training_step"}
{"Total num played games": 47226, "Total num trained steps": 93906, "Timestamp in ms": 1702053582861, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.24609375}
{"Avg objective": 21.3203125, "Games time in secs": 154.60786828771234, "Avg game time in secs": 2.0323865663376637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 47232, "Total num trained steps": 93909, "Timestamp in ms": 1702053584422, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9854606931530008, "Avg loss": 0.6864688268397003, "Avg value loss": 0.3512142085819505, "Avg policy loss": 0.33525461703538895, "Total num played games": 47320, "Total num trained steps": 93952, "Timestamp in ms": 1702053601461, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881445477599324, "Avg loss": 0.4227942491415888, "Avg value loss": 0.09272887880797498, "Avg policy loss": 0.3300653671612963, "Total num played games": 47320, "Total num trained steps": 94080, "Timestamp in ms": 1702053653226, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 90.10741372033954, "Avg game time in secs": 1.6616812810243573, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.45}, "Total num played games": 47360, "Total num trained steps": 94133, "Timestamp in ms": 1702053674529, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868398852707947, "Avg loss": 0.7205080413259566, "Avg value loss": 0.4001838715048507, "Avg policy loss": 0.32032417110167444, "Total num played games": 47416, "Total num trained steps": 94208, "Timestamp in ms": 1702053704583, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 76.99406251683831, "Avg game time in secs": 1.8953238448011689, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 47488, "Total num trained steps": 94327, "Timestamp in ms": 1702053751523, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856030309408546, "Avg loss": 0.6576169808395207, "Avg value loss": 0.3430228300858289, "Avg policy loss": 0.31459414842538536, "Total num played games": 47510, "Total num trained steps": 94336, "Timestamp in ms": 1702053754860, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882972005893496, "Avg loss": 0.7731174340005964, "Avg value loss": 0.43988113504019566, "Avg policy loss": 0.3332362943328917, "Total num played games": 47510, "Total num trained steps": 94464, "Timestamp in ms": 1702053806936, "logtype": "training_step"}
{"Total num played games": 47510, "Total num trained steps": 94507, "Timestamp in ms": 1702053893548, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.7109375}
{"Ratio train steps to played games": 1.9870599109318545, "Avg loss": 1.1701957155019045, "Avg value loss": 0.8427405168768018, "Avg policy loss": 0.3274552006041631, "Total num played games": 47604, "Total num trained steps": 94592, "Timestamp in ms": 1702053929888, "logtype": "training_step"}
{"Avg objective": 22.234375, "Games time in secs": 222.23381352424622, "Avg game time in secs": 2.0181138589105103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.6, "agent_stopped_0": 0.49}, "Total num played games": 47616, "Total num trained steps": 94700, "Timestamp in ms": 1702053973757, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9856609785753219, "Avg loss": 0.6502108054701239, "Avg value loss": 0.3315117693855427, "Avg policy loss": 0.3186990334652364, "Total num played games": 47702, "Total num trained steps": 94720, "Timestamp in ms": 1702053981794, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883443042220452, "Avg loss": 0.5836981292814016, "Avg value loss": 0.2675113695440814, "Avg policy loss": 0.31618676299694926, "Total num played games": 47702, "Total num trained steps": 94848, "Timestamp in ms": 1702054035099, "logtype": "training_step"}
{"Avg objective": 21.03125, "Games time in secs": 80.7186695560813, "Avg game time in secs": 1.8446455633966252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.53, "agent_stopped_0": 0.57}, "Total num played games": 47744, "Total num trained steps": 94898, "Timestamp in ms": 1702054054476, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987111892208553, "Avg loss": 0.7988118047360331, "Avg value loss": 0.485103014158085, "Avg policy loss": 0.3137087879003957, "Total num played games": 47796, "Total num trained steps": 94976, "Timestamp in ms": 1702054085669, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 76.53425379097462, "Avg game time in secs": 1.9294327348761726, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.62}, "Total num played games": 47872, "Total num trained steps": 95088, "Timestamp in ms": 1702054131010, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9858843182292754, "Avg loss": 0.704418141162023, "Avg value loss": 0.38791161330300383, "Avg policy loss": 0.3165065262001008, "Total num played games": 47890, "Total num trained steps": 95104, "Timestamp in ms": 1702054137676, "logtype": "training_step"}
{"Total num played games": 47890, "Total num trained steps": 95111, "Timestamp in ms": 1702054223217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.69921875}
{"Ratio train steps to played games": 1.9846615538512837, "Avg loss": 1.1716343932785094, "Avg value loss": 0.8123562512919307, "Avg policy loss": 0.35927813430316746, "Total num played games": 47984, "Total num trained steps": 95232, "Timestamp in ms": 1702054272150, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873291097032344, "Avg loss": 0.39522302197292447, "Avg value loss": 0.07768012300948612, "Avg policy loss": 0.31754289974924177, "Total num played games": 47984, "Total num trained steps": 95360, "Timestamp in ms": 1702054325262, "logtype": "training_step"}
{"Avg objective": 21.9765625, "Games time in secs": 234.7230024896562, "Avg game time in secs": 2.1009677019610535, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.609375, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.64, "agent_stopped_0": 0.44}, "Total num played games": 48000, "Total num trained steps": 95460, "Timestamp in ms": 1702054365734, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859406846636996, "Avg loss": 0.632131660124287, "Avg value loss": 0.3311362736276351, "Avg policy loss": 0.3009953883010894, "Total num played games": 48082, "Total num trained steps": 95488, "Timestamp in ms": 1702054377071, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885820057401937, "Avg loss": 0.49062172416597605, "Avg value loss": 0.18417172617046162, "Avg policy loss": 0.3064499996835366, "Total num played games": 48082, "Total num trained steps": 95616, "Timestamp in ms": 1702054427608, "logtype": "training_step"}
{"Avg objective": 21.6953125, "Games time in secs": 77.57489112764597, "Avg game time in secs": 1.8457993323972914, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 48128, "Total num trained steps": 95657, "Timestamp in ms": 1702054443309, "logtype": "played_game"}
{"Total num played games": 48180, "Total num trained steps": 95715, "Timestamp in ms": 1702054519456, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.62890625}
{"Avg objective": 23.2109375, "Games time in secs": 79.11436900123954, "Avg game time in secs": 1.8785342460032552, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.59}, "Total num played games": 48256, "Total num trained steps": 95719, "Timestamp in ms": 1702054522423, "logtype": "played_game"}
{"Ratio train steps to played games": 1.983345071881344, "Avg loss": 1.2395152114331722, "Avg value loss": 0.9192607158329338, "Avg policy loss": 0.3202544985106215, "Total num played games": 48274, "Total num trained steps": 95744, "Timestamp in ms": 1702054532501, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9859966027261051, "Avg loss": 0.5814964845776558, "Avg value loss": 0.25335500441724434, "Avg policy loss": 0.3281414861558005, "Total num played games": 48274, "Total num trained steps": 95872, "Timestamp in ms": 1702054585251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886481335708663, "Avg loss": 0.37693087151274085, "Avg value loss": 0.07860218509449624, "Avg policy loss": 0.29832868406083435, "Total num played games": 48274, "Total num trained steps": 96000, "Timestamp in ms": 1702054636862, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9873475294604093, "Avg loss": 0.6950963593553752, "Avg value loss": 0.3841608642542269, "Avg policy loss": 0.31093548773787916, "Total num played games": 48370, "Total num trained steps": 96128, "Timestamp in ms": 1702054688836, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 208.28250938281417, "Avg game time in secs": 2.076204701210372, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 48384, "Total num trained steps": 96232, "Timestamp in ms": 1702054730706, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861340376361836, "Avg loss": 0.6053353550378233, "Avg value loss": 0.31212834949838, "Avg policy loss": 0.29320700897369534, "Total num played games": 48464, "Total num trained steps": 96256, "Timestamp in ms": 1702054741129, "logtype": "training_step"}
{"Total num played games": 48464, "Total num trained steps": 96318, "Timestamp in ms": 1702054784641, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.671875}
{"Avg objective": 22.25, "Games time in secs": 56.22292622178793, "Avg game time in secs": 1.902730195201002, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.56}, "Total num played games": 48512, "Total num trained steps": 96322, "Timestamp in ms": 1702054786929, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9849252440380576, "Avg loss": 0.9515678957104683, "Avg value loss": 0.6294310817611404, "Avg policy loss": 0.3221368087688461, "Total num played games": 48558, "Total num trained steps": 96384, "Timestamp in ms": 1702054813206, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9875612669385065, "Avg loss": 0.41260558157227933, "Avg value loss": 0.11097158852498978, "Avg policy loss": 0.30163399351295084, "Total num played games": 48558, "Total num trained steps": 96512, "Timestamp in ms": 1702054865677, "logtype": "training_step"}
{"Avg objective": 22.765625, "Games time in secs": 118.29140598326921, "Avg game time in secs": 1.9422630892076995, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 48640, "Total num trained steps": 96612, "Timestamp in ms": 1702054905220, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9863520513031325, "Avg loss": 0.6013512013014406, "Avg value loss": 0.3065406131790951, "Avg policy loss": 0.29481059592217207, "Total num played games": 48652, "Total num trained steps": 96640, "Timestamp in ms": 1702054917057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988982981172408, "Avg loss": 0.4425495765171945, "Avg value loss": 0.14483831933466718, "Avg policy loss": 0.2977112577063963, "Total num played games": 48652, "Total num trained steps": 96768, "Timestamp in ms": 1702054969731, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877733557625241, "Avg loss": 0.872864092933014, "Avg value loss": 0.5633977802062873, "Avg policy loss": 0.3094663047231734, "Total num played games": 48746, "Total num trained steps": 96896, "Timestamp in ms": 1702055022134, "logtype": "training_step"}
{"Total num played games": 48746, "Total num trained steps": 96920, "Timestamp in ms": 1702055107661, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.94921875}
{"Avg objective": 21.9609375, "Games time in secs": 204.37747456505895, "Avg game time in secs": 1.904435112257488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.56, "agent_stopped_0": 0.52}, "Total num played games": 48768, "Total num trained steps": 96923, "Timestamp in ms": 1702055109598, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9865683865683865, "Avg loss": 0.7990332492627203, "Avg value loss": 0.4755813581869006, "Avg policy loss": 0.3234518988756463, "Total num played games": 48840, "Total num trained steps": 97024, "Timestamp in ms": 1702055151479, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891891891891893, "Avg loss": 0.3865155456587672, "Avg value loss": 0.07907100781449117, "Avg policy loss": 0.30744453810621053, "Total num played games": 48840, "Total num trained steps": 97152, "Timestamp in ms": 1702055205134, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 103.8985553830862, "Avg game time in secs": 1.8524624439596664, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 48896, "Total num trained steps": 97174, "Timestamp in ms": 1702055213497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879838149344013, "Avg loss": 0.6243270493578166, "Avg value loss": 0.3035421001841314, "Avg policy loss": 0.32078494667075574, "Total num played games": 48934, "Total num trained steps": 97280, "Timestamp in ms": 1702055257197, "logtype": "training_step"}
{"Avg objective": 21.2734375, "Games time in secs": 77.98778214678168, "Avg game time in secs": 2.01516731508309, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 49024, "Total num trained steps": 97365, "Timestamp in ms": 1702055291485, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986783062739659, "Avg loss": 0.8666799417696893, "Avg value loss": 0.5443941025005188, "Avg policy loss": 0.3222858377266675, "Total num played games": 49028, "Total num trained steps": 97408, "Timestamp in ms": 1702055308977, "logtype": "training_step"}
{"Total num played games": 49028, "Total num trained steps": 97524, "Timestamp in ms": 1702055455880, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.1015625}
{"Ratio train steps to played games": 1.9855869060705997, "Avg loss": 0.6406047956552356, "Avg value loss": 0.3134519361483399, "Avg policy loss": 0.327152855345048, "Total num played games": 49122, "Total num trained steps": 97536, "Timestamp in ms": 1702055461546, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881926631651805, "Avg loss": 0.8475548832211643, "Avg value loss": 0.5143181271268986, "Avg policy loss": 0.33323675324209034, "Total num played games": 49122, "Total num trained steps": 97664, "Timestamp in ms": 1702055513721, "logtype": "training_step"}
{"Avg objective": 20.390625, "Games time in secs": 250.28294142335653, "Avg game time in secs": 1.701852427358972, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.5, "agent_stopped_0": 0.54}, "Total num played games": 49152, "Total num trained steps": 97737, "Timestamp in ms": 1702055541769, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986996098829649, "Avg loss": 0.710331583628431, "Avg value loss": 0.3997882977128029, "Avg policy loss": 0.3105432882439345, "Total num played games": 49216, "Total num trained steps": 97792, "Timestamp in ms": 1702055563925, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989596879063719, "Avg loss": 0.41331033129245043, "Avg value loss": 0.10647611459717155, "Avg policy loss": 0.30683421716094017, "Total num played games": 49216, "Total num trained steps": 97920, "Timestamp in ms": 1702055616126, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 77.04092270508409, "Avg game time in secs": 2.0026074076013174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.63, "agent_stopped_0": 0.43}, "Total num played games": 49280, "Total num trained steps": 97927, "Timestamp in ms": 1702055618810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9883999188805517, "Avg loss": 0.829113308340311, "Avg value loss": 0.5058107698569074, "Avg policy loss": 0.32330254081171006, "Total num played games": 49310, "Total num trained steps": 98048, "Timestamp in ms": 1702055668569, "logtype": "training_step"}
{"Total num played games": 49406, "Total num trained steps": 98124, "Timestamp in ms": 1702055764281, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.00390625}
{"Avg objective": 21.0390625, "Games time in secs": 146.7161435931921, "Avg game time in secs": 2.1824989521701355, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5234375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.75, "agent_stopped_0": 0.39}, "Total num played games": 49408, "Total num trained steps": 98126, "Timestamp in ms": 1702055765526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9833535353535354, "Avg loss": 1.2768007018603384, "Avg value loss": 0.9550176308548544, "Avg policy loss": 0.32178307289723307, "Total num played games": 49500, "Total num trained steps": 98176, "Timestamp in ms": 1702055785525, "logtype": "training_step"}
{"Ratio train steps to played games": 1.985939393939394, "Avg loss": 0.48225982394069433, "Avg value loss": 0.17233597341692075, "Avg policy loss": 0.3099238515133038, "Total num played games": 49500, "Total num trained steps": 98304, "Timestamp in ms": 1702055838037, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885252525252526, "Avg loss": 0.3715483658015728, "Avg value loss": 0.08409850092721172, "Avg policy loss": 0.28744986513629556, "Total num played games": 49500, "Total num trained steps": 98432, "Timestamp in ms": 1702055890946, "logtype": "training_step"}
{"Avg objective": 22.0859375, "Games time in secs": 149.74774551391602, "Avg game time in secs": 1.683953661879059, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 49536, "Total num trained steps": 98492, "Timestamp in ms": 1702055915274, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873371778844215, "Avg loss": 0.6490849184338003, "Avg value loss": 0.35633227066136897, "Avg policy loss": 0.29275263904128224, "Total num played games": 49594, "Total num trained steps": 98560, "Timestamp in ms": 1702055942572, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 77.62602448835969, "Avg game time in secs": 1.8850112404325046, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 49664, "Total num trained steps": 98683, "Timestamp in ms": 1702055992900, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9860535318977661, "Avg loss": 0.5379550573416054, "Avg value loss": 0.24000545431044884, "Avg policy loss": 0.29794959793798625, "Total num played games": 49690, "Total num trained steps": 98688, "Timestamp in ms": 1702055994794, "logtype": "training_step"}
{"Total num played games": 49690, "Total num trained steps": 98724, "Timestamp in ms": 1702056082385, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.78515625}
{"Ratio train steps to played games": 1.9848947452996948, "Avg loss": 1.2943658195436, "Avg value loss": 0.9673540694639087, "Avg policy loss": 0.32701176567934453, "Total num played games": 49784, "Total num trained steps": 98816, "Timestamp in ms": 1702056120597, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9874658524827253, "Avg loss": 0.3820909250061959, "Avg value loss": 0.09397743988665752, "Avg policy loss": 0.2881134859053418, "Total num played games": 49784, "Total num trained steps": 98944, "Timestamp in ms": 1702056173032, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 225.78622119873762, "Avg game time in secs": 2.2261636194307357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.59}, "Total num played games": 49792, "Total num trained steps": 99060, "Timestamp in ms": 1702056218686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9862865391555395, "Avg loss": 0.4703958116006106, "Avg value loss": 0.20020278127049096, "Avg policy loss": 0.2701930272160098, "Total num played games": 49878, "Total num trained steps": 99072, "Timestamp in ms": 1702056223441, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888528008340352, "Avg loss": 0.6161734685301781, "Avg value loss": 0.3158429652103223, "Avg policy loss": 0.3003305037273094, "Total num played games": 49878, "Total num trained steps": 99200, "Timestamp in ms": 1702056274071, "logtype": "training_step"}
{"Avg objective": 22.671875, "Games time in secs": 75.11919487640262, "Avg game time in secs": 1.8325028927938547, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 49920, "Total num trained steps": 99249, "Timestamp in ms": 1702056293805, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876530857280077, "Avg loss": 0.7862293366342783, "Avg value loss": 0.49438783634104766, "Avg policy loss": 0.29184150032233447, "Total num played games": 49972, "Total num trained steps": 99328, "Timestamp in ms": 1702056326930, "logtype": "training_step"}
{"Total num played games": 49972, "Total num trained steps": 99328, "Timestamp in ms": 1702056390986, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.9140625}
{"Avg objective": 21.8984375, "Games time in secs": 100.17399003356695, "Avg game time in secs": 2.0724907323601656, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 50048, "Total num trained steps": 99332, "Timestamp in ms": 1702056393980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9864978228738066, "Avg loss": 0.869324927451089, "Avg value loss": 0.5655448081670329, "Avg policy loss": 0.30378012091387063, "Total num played games": 50066, "Total num trained steps": 99456, "Timestamp in ms": 1702056444381, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890544481284704, "Avg loss": 0.35690584825351834, "Avg value loss": 0.08613938439521007, "Avg policy loss": 0.2707664677873254, "Total num played games": 50066, "Total num trained steps": 99584, "Timestamp in ms": 1702056497574, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878787878787878, "Avg loss": 0.7825285869184881, "Avg value loss": 0.4936949898547027, "Avg policy loss": 0.288833609665744, "Total num played games": 50160, "Total num trained steps": 99712, "Timestamp in ms": 1702056548594, "logtype": "training_step"}
{"Avg objective": 21.3828125, "Games time in secs": 195.5535594150424, "Avg game time in secs": 2.1020937351568136, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.65, "agent_stopped_0": 0.45}, "Total num played games": 50176, "Total num trained steps": 99812, "Timestamp in ms": 1702056589533, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866876268555738, "Avg loss": 0.7226310514379293, "Avg value loss": 0.4402212507557124, "Avg policy loss": 0.28240979951806366, "Total num played games": 50254, "Total num trained steps": 99840, "Timestamp in ms": 1702056600621, "logtype": "training_step"}
{"Total num played games": 50254, "Total num trained steps": 99930, "Timestamp in ms": 1702056701049, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.546875}
{"Avg objective": 21.9375, "Games time in secs": 114.03863485902548, "Avg game time in secs": 1.8860882891749498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 50304, "Total num trained steps": 99935, "Timestamp in ms": 1702056703572, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855406371653292, "Avg loss": 0.8670308685395867, "Avg value loss": 0.5585094868438318, "Avg policy loss": 0.30852138507179916, "Total num played games": 50348, "Total num trained steps": 99968, "Timestamp in ms": 1702056716914, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988082942718678, "Avg loss": 0.4374966840259731, "Avg value loss": 0.14925172869698144, "Avg policy loss": 0.2882449545431882, "Total num played games": 50348, "Total num trained steps": 100096, "Timestamp in ms": 1702056768425, "logtype": "training_step"}
{"Avg objective": 21.1953125, "Games time in secs": 102.50159001350403, "Avg game time in secs": 1.9089494015497621, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.53}, "Total num played games": 50432, "Total num trained steps": 100192, "Timestamp in ms": 1702056806074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869156655168312, "Avg loss": 0.613863866776228, "Avg value loss": 0.3408304303884506, "Avg policy loss": 0.2730334351072088, "Total num played games": 50442, "Total num trained steps": 100224, "Timestamp in ms": 1702056819508, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894532334165973, "Avg loss": 0.4120652441633865, "Avg value loss": 0.13488570996560156, "Avg policy loss": 0.2771795322187245, "Total num played games": 50442, "Total num trained steps": 100352, "Timestamp in ms": 1702056872820, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882855785974356, "Avg loss": 0.9033218075055629, "Avg value loss": 0.6256882674060762, "Avg policy loss": 0.27763353753834963, "Total num played games": 50536, "Total num trained steps": 100480, "Timestamp in ms": 1702056925069, "logtype": "training_step"}
{"Total num played games": 50536, "Total num trained steps": 100531, "Timestamp in ms": 1702057027106, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.96875}
{"Avg objective": 22.40625, "Games time in secs": 223.03586281836033, "Avg game time in secs": 1.8385971940297168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.46, "agent_stopped_0": 0.55}, "Total num played games": 50560, "Total num trained steps": 100534, "Timestamp in ms": 1702057029110, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987122259529923, "Avg loss": 0.7320861930493265, "Avg value loss": 0.45548019115813076, "Avg policy loss": 0.2766060046851635, "Total num played games": 50630, "Total num trained steps": 100608, "Timestamp in ms": 1702057058986, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896504048982817, "Avg loss": 0.35917692561633885, "Avg value loss": 0.08906683509121649, "Avg policy loss": 0.2701100903796032, "Total num played games": 50630, "Total num trained steps": 100736, "Timestamp in ms": 1702057110811, "logtype": "training_step"}
{"Avg objective": 21.796875, "Games time in secs": 89.10351002961397, "Avg game time in secs": 1.8534615036915056, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 50688, "Total num trained steps": 100755, "Timestamp in ms": 1702057118213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988408311319639, "Avg loss": 0.8448432099539787, "Avg value loss": 0.5575488653848879, "Avg policy loss": 0.2872943412512541, "Total num played games": 50726, "Total num trained steps": 100864, "Timestamp in ms": 1702057163058, "logtype": "training_step"}
{"Avg objective": 22.6328125, "Games time in secs": 79.39672949910164, "Avg game time in secs": 1.9473131682898384, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.65, "agent_stopped_0": 0.44}, "Total num played games": 50816, "Total num trained steps": 100949, "Timestamp in ms": 1702057197610, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871709102357247, "Avg loss": 0.7670195321552455, "Avg value loss": 0.4892873043427244, "Avg policy loss": 0.27773222944233567, "Total num played games": 50822, "Total num trained steps": 100992, "Timestamp in ms": 1702057214666, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896895045452756, "Avg loss": 0.3979129584040493, "Avg value loss": 0.125655932322843, "Avg policy loss": 0.2722570258192718, "Total num played games": 50822, "Total num trained steps": 101120, "Timestamp in ms": 1702057266998, "logtype": "training_step"}
{"Total num played games": 50822, "Total num trained steps": 101132, "Timestamp in ms": 1702057337632, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.7265625}
{"Ratio train steps to played games": 1.9885301280540497, "Avg loss": 0.5892362091690302, "Avg value loss": 0.3120328612567391, "Avg policy loss": 0.2772033461369574, "Total num played games": 50916, "Total num trained steps": 101248, "Timestamp in ms": 1702057385673, "logtype": "training_step"}
{"Avg objective": 20.9453125, "Games time in secs": 219.1834646947682, "Avg game time in secs": 1.8891666345589329, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.54, "agent_stopped_0": 0.53}, "Total num played games": 50944, "Total num trained steps": 101324, "Timestamp in ms": 1702057416795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872971065631617, "Avg loss": 0.7135264261160046, "Avg value loss": 0.43608284916263074, "Avg policy loss": 0.27744357963092625, "Total num played games": 51012, "Total num trained steps": 101376, "Timestamp in ms": 1702057437484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898063200815495, "Avg loss": 0.36518355063162744, "Avg value loss": 0.09247342229355127, "Avg policy loss": 0.2727101290365681, "Total num played games": 51012, "Total num trained steps": 101504, "Timestamp in ms": 1702057489681, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 78.79172753542662, "Avg game time in secs": 1.8874098350352142, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 51072, "Total num trained steps": 101519, "Timestamp in ms": 1702057495586, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886510390169452, "Avg loss": 0.6686913638841361, "Avg value loss": 0.37030742096249014, "Avg policy loss": 0.2983839400112629, "Total num played games": 51106, "Total num trained steps": 101632, "Timestamp in ms": 1702057542189, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 80.13029873743653, "Avg game time in secs": 2.076756610913435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.640625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 51200, "Total num trained steps": 101714, "Timestamp in ms": 1702057575717, "logtype": "played_game"}
{"Total num played games": 51200, "Total num trained steps": 101732, "Timestamp in ms": 1702057652441, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.93359375}
{"Ratio train steps to played games": 1.983857761141654, "Avg loss": 1.0497664327267557, "Avg value loss": 0.7527978326543234, "Avg policy loss": 0.29696859512478113, "Total num played games": 51294, "Total num trained steps": 101760, "Timestamp in ms": 1702057665298, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9863531797091278, "Avg loss": 0.5691941834520549, "Avg value loss": 0.26122797722928226, "Avg policy loss": 0.30796620657201856, "Total num played games": 51294, "Total num trained steps": 101888, "Timestamp in ms": 1702057717033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9888291028190432, "Avg loss": 0.3682864510919899, "Avg value loss": 0.08811055077239871, "Avg policy loss": 0.280175901716575, "Total num played games": 51294, "Total num trained steps": 102016, "Timestamp in ms": 1702057770897, "logtype": "training_step"}
{"Avg objective": 20.8359375, "Games time in secs": 220.31726654618979, "Avg game time in secs": 1.7507440739427693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 51328, "Total num trained steps": 102081, "Timestamp in ms": 1702057796034, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876240513718622, "Avg loss": 0.7374420965788886, "Avg value loss": 0.45533361384877935, "Avg policy loss": 0.2821084839524701, "Total num played games": 51390, "Total num trained steps": 102144, "Timestamp in ms": 1702057821201, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899599175000973, "Avg loss": 0.3698244949337095, "Avg value loss": 0.09193018963560462, "Avg policy loss": 0.2778943054145202, "Total num played games": 51394, "Total num trained steps": 102272, "Timestamp in ms": 1702057873210, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 78.31117952242494, "Avg game time in secs": 1.8896744490775745, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.62, "agent_stopped_0": 0.41}, "Total num played games": 51456, "Total num trained steps": 102275, "Timestamp in ms": 1702057874345, "logtype": "played_game"}
{"Total num played games": 51484, "Total num trained steps": 102333, "Timestamp in ms": 1702057964956, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.6953125}
{"Ratio train steps to played games": 1.985323199813874, "Avg loss": 1.159814148209989, "Avg value loss": 0.8509007045067847, "Avg policy loss": 0.3089134379988536, "Total num played games": 51578, "Total num trained steps": 102400, "Timestamp in ms": 1702057992516, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878242661599907, "Avg loss": 0.37664994318038225, "Avg value loss": 0.09840661360067315, "Avg policy loss": 0.2782433272805065, "Total num played games": 51578, "Total num trained steps": 102528, "Timestamp in ms": 1702058043156, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 217.3136434815824, "Avg game time in secs": 2.0758875613391865, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6171875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 51584, "Total num trained steps": 102647, "Timestamp in ms": 1702058091659, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9866852453940238, "Avg loss": 0.35850806173402816, "Avg value loss": 0.09958085452672094, "Avg policy loss": 0.2589272080222145, "Total num played games": 51672, "Total num trained steps": 102656, "Timestamp in ms": 1702058094847, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891624090416473, "Avg loss": 0.4907092822249979, "Avg value loss": 0.22032852945267223, "Avg policy loss": 0.2703807526268065, "Total num played games": 51672, "Total num trained steps": 102784, "Timestamp in ms": 1702058147046, "logtype": "training_step"}
{"Avg objective": 21.2265625, "Games time in secs": 76.5351069830358, "Avg game time in secs": 1.7303842974069994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 51712, "Total num trained steps": 102837, "Timestamp in ms": 1702058168194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880230266970598, "Avg loss": 0.8006034069694579, "Avg value loss": 0.522262576763751, "Avg policy loss": 0.2783408398972824, "Total num played games": 51766, "Total num trained steps": 102912, "Timestamp in ms": 1702058201052, "logtype": "training_step"}
{"Total num played games": 51766, "Total num trained steps": 102933, "Timestamp in ms": 1702058268319, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.859375}
{"Avg objective": 21.40625, "Games time in secs": 103.38322296738625, "Avg game time in secs": 1.8686397555866279, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 51840, "Total num trained steps": 102940, "Timestamp in ms": 1702058271578, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868877747782492, "Avg loss": 0.6790606519207358, "Avg value loss": 0.3929237835109234, "Avg policy loss": 0.2861368741141632, "Total num played games": 51860, "Total num trained steps": 103040, "Timestamp in ms": 1702058313262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893559583494023, "Avg loss": 0.33762976550497115, "Avg value loss": 0.07399762209388427, "Avg policy loss": 0.2636321426834911, "Total num played games": 51860, "Total num trained steps": 103168, "Timestamp in ms": 1702058364994, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882203487700658, "Avg loss": 1.0319194465409964, "Avg value loss": 0.7512264201068319, "Avg policy loss": 0.2806930284714326, "Total num played games": 51954, "Total num trained steps": 103296, "Timestamp in ms": 1702058416070, "logtype": "training_step"}
{"Avg objective": 22.390625, "Games time in secs": 186.65883349627256, "Avg game time in secs": 1.9905914958799258, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.67, "agent_stopped_0": 0.45}, "Total num played games": 51968, "Total num trained steps": 103400, "Timestamp in ms": 1702058458237, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9870888410697818, "Avg loss": 0.6179236250463873, "Avg value loss": 0.34053943047183566, "Avg policy loss": 0.2773841917514801, "Total num played games": 52048, "Total num trained steps": 103424, "Timestamp in ms": 1702058467790, "logtype": "training_step"}
{"Total num played games": 52048, "Total num trained steps": 103535, "Timestamp in ms": 1702058594286, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.453125}
{"Avg objective": 21.828125, "Games time in secs": 138.53697833046317, "Avg game time in secs": 1.8210467336175498, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.55}, "Total num played games": 52096, "Total num trained steps": 103540, "Timestamp in ms": 1702058596774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859614130643244, "Avg loss": 0.6464998971205205, "Avg value loss": 0.3584551786771044, "Avg policy loss": 0.2880447180941701, "Total num played games": 52142, "Total num trained steps": 103552, "Timestamp in ms": 1702058601286, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884162479383223, "Avg loss": 0.5606547694187611, "Avg value loss": 0.26848908865940757, "Avg policy loss": 0.2921656862599775, "Total num played games": 52142, "Total num trained steps": 103680, "Timestamp in ms": 1702058653988, "logtype": "training_step"}
{"Avg objective": 21.1015625, "Games time in secs": 97.6879245787859, "Avg game time in secs": 2.0321034711087123, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.65, "agent_stopped_0": 0.42}, "Total num played games": 52224, "Total num trained steps": 103781, "Timestamp in ms": 1702058694462, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872123741337724, "Avg loss": 0.5989176402799785, "Avg value loss": 0.32303113635862246, "Avg policy loss": 0.275886507704854, "Total num played games": 52238, "Total num trained steps": 103808, "Timestamp in ms": 1702058705457, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989643554500555, "Avg loss": 0.43371903500519693, "Avg value loss": 0.15558936877641827, "Avg policy loss": 0.27812966564670205, "Total num played games": 52238, "Total num trained steps": 103936, "Timestamp in ms": 1702058756204, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988534739738592, "Avg loss": 0.6201023199828342, "Avg value loss": 0.33537826949032024, "Avg policy loss": 0.28472405194770545, "Total num played games": 52332, "Total num trained steps": 104064, "Timestamp in ms": 1702058808215, "logtype": "training_step"}
{"Total num played games": 52332, "Total num trained steps": 104140, "Timestamp in ms": 1702058923465, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0234375}
{"Avg objective": 21.0859375, "Games time in secs": 231.03974740207195, "Avg game time in secs": 1.8729990404099226, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.45, "agent_stopped_0": 0.6}, "Total num played games": 52352, "Total num trained steps": 104142, "Timestamp in ms": 1702058925502, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874108266890473, "Avg loss": 0.6559622371569276, "Avg value loss": 0.3775670409668237, "Avg policy loss": 0.27839519327972084, "Total num played games": 52426, "Total num trained steps": 104192, "Timestamp in ms": 1702058945340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989833288826155, "Avg loss": 0.3649707701988518, "Avg value loss": 0.0930699220043607, "Avg policy loss": 0.27190084813628346, "Total num played games": 52426, "Total num trained steps": 104320, "Timestamp in ms": 1702058996307, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 81.44294788315892, "Avg game time in secs": 1.87046470635687, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 52480, "Total num trained steps": 104345, "Timestamp in ms": 1702059006945, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887281035795887, "Avg loss": 0.6503495243377984, "Avg value loss": 0.36707061281776987, "Avg policy loss": 0.28327890776563436, "Total num played games": 52520, "Total num trained steps": 104448, "Timestamp in ms": 1702059050307, "logtype": "training_step"}
{"Avg objective": 22.3046875, "Games time in secs": 80.09324819222093, "Avg game time in secs": 1.92364117296529, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 52608, "Total num trained steps": 104536, "Timestamp in ms": 1702059087038, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875323095636308, "Avg loss": 0.6667853081598878, "Avg value loss": 0.3878319938085042, "Avg policy loss": 0.27895330754108727, "Total num played games": 52616, "Total num trained steps": 104576, "Timestamp in ms": 1702059103691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989965029648776, "Avg loss": 0.37688231840729713, "Avg value loss": 0.0949433935165871, "Avg policy loss": 0.2819389228243381, "Total num played games": 52616, "Total num trained steps": 104704, "Timestamp in ms": 1702059156569, "logtype": "training_step"}
{"Total num played games": 52710, "Total num trained steps": 104742, "Timestamp in ms": 1702059237664, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.9921875}
{"Avg objective": 22.1015625, "Games time in secs": 152.7111942730844, "Avg game time in secs": 1.8490674754430074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.52}, "Total num played games": 52736, "Total num trained steps": 104746, "Timestamp in ms": 1702059239749, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9852852056662373, "Avg loss": 1.4304611880797893, "Avg value loss": 1.110667917819228, "Avg policy loss": 0.31979328230954707, "Total num played games": 52804, "Total num trained steps": 104832, "Timestamp in ms": 1702059274629, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9877282024089085, "Avg loss": 0.41182364779524505, "Avg value loss": 0.11031748206005432, "Avg policy loss": 0.3015061652986333, "Total num played games": 52804, "Total num trained steps": 104960, "Timestamp in ms": 1702059327669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990152261192334, "Avg loss": 0.34054468967951834, "Avg value loss": 0.07227171072736382, "Avg policy loss": 0.26827297639101744, "Total num played games": 52804, "Total num trained steps": 105088, "Timestamp in ms": 1702059378824, "logtype": "training_step"}
{"Avg objective": 24.109375, "Games time in secs": 144.64083540812135, "Avg game time in secs": 1.8240561322600115, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.54, "agent_stopped_0": 0.52}, "Total num played games": 52864, "Total num trained steps": 105102, "Timestamp in ms": 1702059384390, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989035502287421, "Avg loss": 1.1172246737405658, "Avg value loss": 0.8154469832370523, "Avg policy loss": 0.3017776916967705, "Total num played games": 52898, "Total num trained steps": 105216, "Timestamp in ms": 1702059429386, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 76.24254060909152, "Avg game time in secs": 2.122609562036814, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.77}, "Total num played games": 52992, "Total num trained steps": 105294, "Timestamp in ms": 1702059460633, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878288108087707, "Avg loss": 0.6409591508563608, "Avg value loss": 0.35524072404950857, "Avg policy loss": 0.2857184293679893, "Total num played games": 52994, "Total num trained steps": 105344, "Timestamp in ms": 1702059481999, "logtype": "training_step"}
{"Total num played games": 52994, "Total num trained steps": 105344, "Timestamp in ms": 1702059562004, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.30078125}
{"Ratio train steps to played games": 1.9867389993972273, "Avg loss": 0.8371062441729009, "Avg value loss": 0.531528920691926, "Avg policy loss": 0.3055773312225938, "Total num played games": 53088, "Total num trained steps": 105472, "Timestamp in ms": 1702059616103, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891500904159132, "Avg loss": 0.3536855545826256, "Avg value loss": 0.07694888691185042, "Avg policy loss": 0.2767366658663377, "Total num played games": 53088, "Total num trained steps": 105600, "Timestamp in ms": 1702059670153, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 238.49020118266344, "Avg game time in secs": 1.9990187570801936, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.55, "agent_stopped_0": 0.5}, "Total num played games": 53120, "Total num trained steps": 105670, "Timestamp in ms": 1702059699123, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879663056558363, "Avg loss": 0.7378491327399388, "Avg value loss": 0.4527648735092953, "Avg policy loss": 0.28508424549363554, "Total num played games": 53184, "Total num trained steps": 105728, "Timestamp in ms": 1702059724213, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903542418772564, "Avg loss": 0.3797867288812995, "Avg value loss": 0.09305884034256451, "Avg policy loss": 0.28672789002303034, "Total num played games": 53184, "Total num trained steps": 105856, "Timestamp in ms": 1702059777374, "logtype": "training_step"}
{"Avg objective": 22.453125, "Games time in secs": 80.59219325706363, "Avg game time in secs": 1.9717249942477793, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5859375, "Avg reasons for ending game": {"agent_stopped_0": 0.46, "agent_stopped_more": 0.54, "played_steps": 0.62}, "Total num played games": 53248, "Total num trained steps": 105862, "Timestamp in ms": 1702059779716, "logtype": "played_game"}
{"Total num played games": 53278, "Total num trained steps": 105945, "Timestamp in ms": 1702059872075, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.11328125}
{"Ratio train steps to played games": 1.9857603237652701, "Avg loss": 1.085865706205368, "Avg value loss": 0.770958025532309, "Avg policy loss": 0.31490768084768206, "Total num played games": 53372, "Total num trained steps": 105984, "Timestamp in ms": 1702059888295, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881585850258563, "Avg loss": 0.4472198758739978, "Avg value loss": 0.1460907338769175, "Avg policy loss": 0.3011291422881186, "Total num played games": 53372, "Total num trained steps": 106112, "Timestamp in ms": 1702059940825, "logtype": "training_step"}
{"Avg objective": 22.0703125, "Games time in secs": 210.63813884928823, "Avg game time in secs": 1.9665949540794827, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.55, "agent_stopped_0": 0.47}, "Total num played games": 53376, "Total num trained steps": 106236, "Timestamp in ms": 1702059990354, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877263882652298, "Avg loss": 0.38072763313539326, "Avg value loss": 0.09989095557830296, "Avg policy loss": 0.2808366783428937, "Total num played games": 53448, "Total num trained steps": 106240, "Timestamp in ms": 1702059992010, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893768235206104, "Avg loss": 0.7939122854731977, "Avg value loss": 0.49610806969576515, "Avg policy loss": 0.29780420986935496, "Total num played games": 53468, "Total num trained steps": 106368, "Timestamp in ms": 1702060046259, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 80.94728942960501, "Avg game time in secs": 1.7990219410567079, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_0": 0.56, "agent_stopped_more": 0.44, "played_steps": 0.47}, "Total num played games": 53504, "Total num trained steps": 106429, "Timestamp in ms": 1702060071301, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882752697808148, "Avg loss": 0.7148490368854254, "Avg value loss": 0.43193765098112635, "Avg policy loss": 0.2829113834304735, "Total num played games": 53562, "Total num trained steps": 106496, "Timestamp in ms": 1702060098778, "logtype": "training_step"}
{"Total num played games": 53562, "Total num trained steps": 106545, "Timestamp in ms": 1702060189720, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.0234375}
{"Avg objective": 21.71875, "Games time in secs": 121.30007690563798, "Avg game time in secs": 1.8301412369764876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 53632, "Total num trained steps": 106550, "Timestamp in ms": 1702060192601, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9871775756672134, "Avg loss": 0.7852119202725589, "Avg value loss": 0.4885869238351006, "Avg policy loss": 0.29662499157711864, "Total num played games": 53656, "Total num trained steps": 106624, "Timestamp in ms": 1702060223420, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895631429849412, "Avg loss": 0.3570103698875755, "Avg value loss": 0.08129828108940274, "Avg policy loss": 0.2757120890310034, "Total num played games": 53656, "Total num trained steps": 106752, "Timestamp in ms": 1702060278332, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9884651162790699, "Avg loss": 0.6755212310235947, "Avg value loss": 0.399379838781897, "Avg policy loss": 0.27614139288198203, "Total num played games": 53750, "Total num trained steps": 106880, "Timestamp in ms": 1702060329100, "logtype": "training_step"}
{"Avg objective": 21.53125, "Games time in secs": 181.7086209617555, "Avg game time in secs": 1.9439705454569776, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 53760, "Total num trained steps": 106992, "Timestamp in ms": 1702060374310, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872971065631617, "Avg loss": 0.6706138029694557, "Avg value loss": 0.40132561553036794, "Avg policy loss": 0.26928818970918655, "Total num played games": 53846, "Total num trained steps": 107008, "Timestamp in ms": 1702060380961, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896742562121605, "Avg loss": 0.5514704675879329, "Avg value loss": 0.26847471750807017, "Avg policy loss": 0.28299575531855226, "Total num played games": 53846, "Total num trained steps": 107136, "Timestamp in ms": 1702060433238, "logtype": "training_step"}
{"Total num played games": 53846, "Total num trained steps": 107149, "Timestamp in ms": 1702060509366, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.125}
{"Avg objective": 21.859375, "Games time in secs": 137.1668155491352, "Avg game time in secs": 1.8139846429985482, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.51, "agent_stopped_0": 0.54}, "Total num played games": 53888, "Total num trained steps": 107152, "Timestamp in ms": 1702060511477, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885799035965888, "Avg loss": 1.203260063426569, "Avg value loss": 0.8918801933468785, "Avg policy loss": 0.3113798728445545, "Total num played games": 53940, "Total num trained steps": 107264, "Timestamp in ms": 1702060560955, "logtype": "training_step"}
{"Avg objective": 23.5, "Games time in secs": 94.98923747614026, "Avg game time in secs": 1.7751918367866892, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 54016, "Total num trained steps": 107375, "Timestamp in ms": 1702060606467, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9874157968761565, "Avg loss": 0.8394845731090754, "Avg value loss": 0.5478615026804619, "Avg policy loss": 0.2916230777045712, "Total num played games": 54036, "Total num trained steps": 107392, "Timestamp in ms": 1702060614118, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897845880524094, "Avg loss": 0.5593830146826804, "Avg value loss": 0.25180168717633933, "Avg policy loss": 0.3075813381001353, "Total num played games": 54036, "Total num trained steps": 107520, "Timestamp in ms": 1702060667918, "logtype": "training_step"}
{"Ratio train steps to played games": 1.988601936008276, "Avg loss": 0.6901608989574015, "Avg value loss": 0.3994198323052842, "Avg policy loss": 0.2907410728512332, "Total num played games": 54132, "Total num trained steps": 107648, "Timestamp in ms": 1702060720196, "logtype": "training_step"}
{"Total num played games": 54132, "Total num trained steps": 107749, "Timestamp in ms": 1702060838217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.625}
{"Avg objective": 21.046875, "Games time in secs": 233.50707651674747, "Avg game time in secs": 1.8936420694517437, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.58}, "Total num played games": 54144, "Total num trained steps": 107751, "Timestamp in ms": 1702060839974, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875336554420389, "Avg loss": 0.4987347424030304, "Avg value loss": 0.21943401955650188, "Avg policy loss": 0.27930072124581784, "Total num played games": 54226, "Total num trained steps": 107776, "Timestamp in ms": 1702060849567, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898941467192859, "Avg loss": 0.41668447433039546, "Avg value loss": 0.12300422039697878, "Avg policy loss": 0.2936802541371435, "Total num played games": 54226, "Total num trained steps": 107904, "Timestamp in ms": 1702060902410, "logtype": "training_step"}
{"Avg objective": 19.7421875, "Games time in secs": 78.1630416624248, "Avg game time in secs": 1.764362318586791, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.6, "agent_stopped_more": 0.4, "played_steps": 0.44}, "Total num played games": 54272, "Total num trained steps": 107945, "Timestamp in ms": 1702060918137, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888070692194404, "Avg loss": 0.7566688877996057, "Avg value loss": 0.4597963010019157, "Avg policy loss": 0.29687258088961244, "Total num played games": 54320, "Total num trained steps": 108032, "Timestamp in ms": 1702060952382, "logtype": "training_step"}
{"Avg objective": 21.984375, "Games time in secs": 76.15859846770763, "Avg game time in secs": 1.9223369844839908, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 54400, "Total num trained steps": 108136, "Timestamp in ms": 1702060994296, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987723747564965, "Avg loss": 0.7137765435036272, "Avg value loss": 0.4266951001191046, "Avg policy loss": 0.2870814494090155, "Total num played games": 54414, "Total num trained steps": 108160, "Timestamp in ms": 1702061004337, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900760833608997, "Avg loss": 0.46376530756242573, "Avg value loss": 0.16327460709726438, "Avg policy loss": 0.3004907036665827, "Total num played games": 54414, "Total num trained steps": 108288, "Timestamp in ms": 1702061057686, "logtype": "training_step"}
{"Total num played games": 54508, "Total num trained steps": 108349, "Timestamp in ms": 1702061140877, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.08203125}
{"Avg objective": 21.9375, "Games time in secs": 148.4300387017429, "Avg game time in secs": 2.0848258923215326, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.53, "agent_stopped_0": 0.55}, "Total num played games": 54528, "Total num trained steps": 108352, "Timestamp in ms": 1702061142726, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9855682942016777, "Avg loss": 0.9312816370511428, "Avg value loss": 0.6289315208850894, "Avg policy loss": 0.3023501131683588, "Total num played games": 54602, "Total num trained steps": 108416, "Timestamp in ms": 1702061169233, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9878942163290723, "Avg loss": 0.38348104315809906, "Avg value loss": 0.09861712701967917, "Avg policy loss": 0.28486391401384026, "Total num played games": 54602, "Total num trained steps": 108544, "Timestamp in ms": 1702061221590, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902567671513864, "Avg loss": 0.3508145425003022, "Avg value loss": 0.07104735510074534, "Avg policy loss": 0.27976718766149133, "Total num played games": 54602, "Total num trained steps": 108672, "Timestamp in ms": 1702061274649, "logtype": "training_step"}
{"Avg objective": 21.9140625, "Games time in secs": 142.6675556972623, "Avg game time in secs": 1.796340295491973, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.45}, "Total num played games": 54656, "Total num trained steps": 108698, "Timestamp in ms": 1702061285393, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889583561844173, "Avg loss": 0.7142104108352214, "Avg value loss": 0.4177188106114045, "Avg policy loss": 0.29649160662665963, "Total num played games": 54702, "Total num trained steps": 108800, "Timestamp in ms": 1702061327838, "logtype": "training_step"}
{"Avg objective": 23.4921875, "Games time in secs": 82.34272883459926, "Avg game time in secs": 1.9081626658444293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 54784, "Total num trained steps": 108900, "Timestamp in ms": 1702061367736, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878823271771662, "Avg loss": 0.7170482932124287, "Avg value loss": 0.43029494656366296, "Avg policy loss": 0.28675333748105913, "Total num played games": 54796, "Total num trained steps": 108928, "Timestamp in ms": 1702061378544, "logtype": "training_step"}
{"Total num played games": 54796, "Total num trained steps": 108951, "Timestamp in ms": 1702061456826, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.11328125}
{"Ratio train steps to played games": 1.9868099836035709, "Avg loss": 0.8801356751937419, "Avg value loss": 0.5741322170943022, "Avg policy loss": 0.30600345239508897, "Total num played games": 54890, "Total num trained steps": 109056, "Timestamp in ms": 1702061500786, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891237019493533, "Avg loss": 0.360306907678023, "Avg value loss": 0.0862576165527571, "Avg policy loss": 0.274049291620031, "Total num played games": 54890, "Total num trained steps": 109184, "Timestamp in ms": 1702061551569, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 218.99303320795298, "Avg game time in secs": 1.8428469257196411, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.53, "agent_stopped_0": 0.54}, "Total num played games": 54912, "Total num trained steps": 109272, "Timestamp in ms": 1702061586730, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988069256510985, "Avg loss": 0.520590134896338, "Avg value loss": 0.25100955087691545, "Avg policy loss": 0.26958058471791446, "Total num played games": 54984, "Total num trained steps": 109312, "Timestamp in ms": 1702061602113, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990397206460061, "Avg loss": 0.371444090269506, "Avg value loss": 0.08995396483805962, "Avg policy loss": 0.28149012417998165, "Total num played games": 54984, "Total num trained steps": 109440, "Timestamp in ms": 1702061654043, "logtype": "training_step"}
{"Avg objective": 21.375, "Games time in secs": 75.96409142017365, "Avg game time in secs": 1.7413002581160981, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.61, "agent_stopped_more": 0.39, "played_steps": 0.45}, "Total num played games": 55040, "Total num trained steps": 109461, "Timestamp in ms": 1702061662694, "logtype": "played_game"}
{"Total num played games": 55078, "Total num trained steps": 109552, "Timestamp in ms": 1702061757145, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.2890625}
{"Avg objective": 21.4296875, "Games time in secs": 98.37104282155633, "Avg game time in secs": 2.0053501597139984, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.62, "agent_stopped_0": 0.47}, "Total num played games": 55168, "Total num trained steps": 109560, "Timestamp in ms": 1702061761065, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859348945117088, "Avg loss": 0.9123780226800591, "Avg value loss": 0.6273504601267632, "Avg policy loss": 0.2850275655509904, "Total num played games": 55172, "Total num trained steps": 109568, "Timestamp in ms": 1702061764382, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882549119118393, "Avg loss": 0.6629585027694702, "Avg value loss": 0.3578697696211748, "Avg policy loss": 0.3050887376302853, "Total num played games": 55172, "Total num trained steps": 109696, "Timestamp in ms": 1702061816060, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905749293119699, "Avg loss": 0.3423554633045569, "Avg value loss": 0.06922856118762866, "Avg policy loss": 0.27312690124381334, "Total num played games": 55172, "Total num trained steps": 109824, "Timestamp in ms": 1702061867309, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895053016321065, "Avg loss": 0.7445279746316373, "Avg value loss": 0.4386123523581773, "Avg policy loss": 0.30591562716290355, "Total num played games": 55266, "Total num trained steps": 109952, "Timestamp in ms": 1702061918038, "logtype": "training_step"}
{"Avg objective": 21.34375, "Games time in secs": 187.240696888417, "Avg game time in secs": 1.8589417191105895, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.484375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.49, "agent_stopped_0": 0.52}, "Total num played games": 55296, "Total num trained steps": 110025, "Timestamp in ms": 1702061948306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884393063583814, "Avg loss": 0.5874115293845534, "Avg value loss": 0.29780077529721893, "Avg policy loss": 0.28961075108963996, "Total num played games": 55360, "Total num trained steps": 110080, "Timestamp in ms": 1702061969851, "logtype": "training_step"}
{"Total num played games": 55360, "Total num trained steps": 110156, "Timestamp in ms": 1702062056676, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.234375}
{"Avg objective": 20.1484375, "Games time in secs": 110.94900267198682, "Avg game time in secs": 1.8923811623535585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.55}, "Total num played games": 55424, "Total num trained steps": 110161, "Timestamp in ms": 1702062059255, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9873769250189346, "Avg loss": 0.6139680173946545, "Avg value loss": 0.32748560805339366, "Avg policy loss": 0.2864824093412608, "Total num played games": 55454, "Total num trained steps": 110208, "Timestamp in ms": 1702062079542, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896851444440438, "Avg loss": 0.37880182825028896, "Avg value loss": 0.09575937717454508, "Avg policy loss": 0.2830424470594153, "Total num played games": 55454, "Total num trained steps": 110336, "Timestamp in ms": 1702062130964, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886044502052278, "Avg loss": 0.8085659217322245, "Avg value loss": 0.5200747919734567, "Avg policy loss": 0.2884911310393363, "Total num played games": 55548, "Total num trained steps": 110464, "Timestamp in ms": 1702062182073, "logtype": "training_step"}
{"Avg objective": 23.3828125, "Games time in secs": 171.51472716405988, "Avg game time in secs": 2.0286809538665693, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.55, "agent_stopped_0": 0.55}, "Total num played games": 55552, "Total num trained steps": 110587, "Timestamp in ms": 1702062230770, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879741146863203, "Avg loss": 0.3818411813117564, "Avg value loss": 0.10081234498647973, "Avg policy loss": 0.28102883719839156, "Total num played games": 55626, "Total num trained steps": 110592, "Timestamp in ms": 1702062232585, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897922507368269, "Avg loss": 0.6613279692828655, "Avg value loss": 0.37054745911154896, "Avg policy loss": 0.2907805099384859, "Total num played games": 55644, "Total num trained steps": 110720, "Timestamp in ms": 1702062282838, "logtype": "training_step"}
{"Total num played games": 55644, "Total num trained steps": 110756, "Timestamp in ms": 1702062339138, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.59375}
{"Avg objective": 23.03125, "Games time in secs": 110.41971947997808, "Avg game time in secs": 1.7117073413683102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.47}, "Total num played games": 55680, "Total num trained steps": 110758, "Timestamp in ms": 1702062341189, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887330008252897, "Avg loss": 0.6770920678973198, "Avg value loss": 0.3793311792833265, "Avg policy loss": 0.2977608913788572, "Total num played games": 55738, "Total num trained steps": 110848, "Timestamp in ms": 1702062378551, "logtype": "training_step"}
{"Avg objective": 22.2734375, "Games time in secs": 87.15235451981425, "Avg game time in secs": 1.8447273187630344, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 55808, "Total num trained steps": 110970, "Timestamp in ms": 1702062428342, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9876773176672875, "Avg loss": 0.48682383028790355, "Avg value loss": 0.1997931487567257, "Avg policy loss": 0.28703068231698126, "Total num played games": 55832, "Total num trained steps": 110976, "Timestamp in ms": 1702062430448, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899699097291876, "Avg loss": 0.5850978102535009, "Avg value loss": 0.304763555934187, "Avg policy loss": 0.28033424739260226, "Total num played games": 55832, "Total num trained steps": 111104, "Timestamp in ms": 1702062484207, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9889139219683152, "Avg loss": 0.7483170558698475, "Avg value loss": 0.47136232515913434, "Avg policy loss": 0.2769547385396436, "Total num played games": 55926, "Total num trained steps": 111232, "Timestamp in ms": 1702062535773, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 152.04322632402182, "Avg game time in secs": 1.9029282635601703, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.59}, "Total num played games": 55936, "Total num trained steps": 111343, "Timestamp in ms": 1702062580385, "logtype": "played_game"}
{"Total num played games": 56020, "Total num trained steps": 111358, "Timestamp in ms": 1702062638638, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.02734375}
{"Ratio train steps to played games": 1.9876485917252704, "Avg loss": 0.7283307544421405, "Avg value loss": 0.46865371699095704, "Avg policy loss": 0.25967701815534383, "Total num played games": 56024, "Total num trained steps": 111360, "Timestamp in ms": 1702062640124, "logtype": "training_step"}
{"Avg objective": 21.421875, "Games time in secs": 60.89759884774685, "Avg game time in secs": 1.7303835370694287, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.52}, "Total num played games": 56064, "Total num trained steps": 111363, "Timestamp in ms": 1702062641283, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9868125601454183, "Avg loss": 1.3706581061705947, "Avg value loss": 1.0472391757648438, "Avg policy loss": 0.32341892342083156, "Total num played games": 56114, "Total num trained steps": 111488, "Timestamp in ms": 1702062690922, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9890936308229676, "Avg loss": 0.3662224162835628, "Avg value loss": 0.08299093446112238, "Avg policy loss": 0.28323148423805833, "Total num played games": 56114, "Total num trained steps": 111616, "Timestamp in ms": 1702062743326, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 145.91844460368156, "Avg game time in secs": 2.0644731373758987, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.6, "agent_stopped_0": 0.48}, "Total num played games": 56192, "Total num trained steps": 111724, "Timestamp in ms": 1702062787202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880444064901794, "Avg loss": 0.5316097342874855, "Avg value loss": 0.26174839938175865, "Avg policy loss": 0.26986133493483067, "Total num played games": 56208, "Total num trained steps": 111744, "Timestamp in ms": 1702062795449, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903216623968119, "Avg loss": 0.4184140875004232, "Avg value loss": 0.14301163630443625, "Avg policy loss": 0.27540245035197586, "Total num played games": 56208, "Total num trained steps": 111872, "Timestamp in ms": 1702062847180, "logtype": "training_step"}
{"Total num played games": 56302, "Total num trained steps": 111961, "Timestamp in ms": 1702062956861, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.64453125}
{"Avg objective": 22.7421875, "Games time in secs": 171.6015249043703, "Avg game time in secs": 1.9711334049643483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.40625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 56320, "Total num trained steps": 111964, "Timestamp in ms": 1702062958803, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859564508121144, "Avg loss": 1.2064490062184632, "Avg value loss": 0.910210174828535, "Avg policy loss": 0.29623881937004626, "Total num played games": 56396, "Total num trained steps": 112000, "Timestamp in ms": 1702062973235, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9882261153273282, "Avg loss": 0.4873669857624918, "Avg value loss": 0.17261576547753066, "Avg policy loss": 0.31475122063420713, "Total num played games": 56396, "Total num trained steps": 112128, "Timestamp in ms": 1702063025043, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990495779842542, "Avg loss": 0.3470858702203259, "Avg value loss": 0.06461668104748242, "Avg policy loss": 0.28246918926015496, "Total num played games": 56396, "Total num trained steps": 112256, "Timestamp in ms": 1702063077114, "logtype": "training_step"}
{"Avg objective": 21.9375, "Games time in secs": 129.77833307906985, "Avg game time in secs": 1.9449799684807658, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.54}, "Total num played games": 56448, "Total num trained steps": 112286, "Timestamp in ms": 1702063088582, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894494600814303, "Avg loss": 0.7136870613321662, "Avg value loss": 0.42188020612229593, "Avg policy loss": 0.2918068493017927, "Total num played games": 56490, "Total num trained steps": 112384, "Timestamp in ms": 1702063128500, "logtype": "training_step"}
{"Avg objective": 20.3671875, "Games time in secs": 75.62029672786593, "Avg game time in secs": 1.947970552573679, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.57}, "Total num played games": 56576, "Total num trained steps": 112476, "Timestamp in ms": 1702063164202, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9884066167114378, "Avg loss": 0.638764608418569, "Avg value loss": 0.35146604035981, "Avg policy loss": 0.2872985639842227, "Total num played games": 56584, "Total num trained steps": 112512, "Timestamp in ms": 1702063179039, "logtype": "training_step"}
{"Total num played games": 56584, "Total num trained steps": 112563, "Timestamp in ms": 1702063239657, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.671875}
{"Ratio train steps to played games": 1.9873672324358658, "Avg loss": 0.8938971431925893, "Avg value loss": 0.5885085185291246, "Avg policy loss": 0.3053886281559244, "Total num played games": 56678, "Total num trained steps": 112640, "Timestamp in ms": 1702063271593, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9896256042909066, "Avg loss": 0.40131173306144774, "Avg value loss": 0.10296573201776482, "Avg policy loss": 0.2983459997922182, "Total num played games": 56678, "Total num trained steps": 112768, "Timestamp in ms": 1702063323730, "logtype": "training_step"}
{"Avg objective": 22.46875, "Games time in secs": 192.84685151278973, "Avg game time in secs": 1.8862858316570055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.53125, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.54, "agent_stopped_0": 0.54}, "Total num played games": 56704, "Total num trained steps": 112848, "Timestamp in ms": 1702063357049, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885859226379201, "Avg loss": 0.6580572279635817, "Avg value loss": 0.3683496084122453, "Avg policy loss": 0.289707611547783, "Total num played games": 56772, "Total num trained steps": 112896, "Timestamp in ms": 1702063376873, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908405552032693, "Avg loss": 0.382795900804922, "Avg value loss": 0.08724931665346958, "Avg policy loss": 0.2955465834820643, "Total num played games": 56772, "Total num trained steps": 113024, "Timestamp in ms": 1702063429778, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 78.60820113122463, "Avg game time in secs": 1.822687858628342, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.54}, "Total num played games": 56832, "Total num trained steps": 113038, "Timestamp in ms": 1702063435657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898005838286499, "Avg loss": 0.7137475039344281, "Avg value loss": 0.41366809234023094, "Avg policy loss": 0.3000794182298705, "Total num played games": 56866, "Total num trained steps": 113152, "Timestamp in ms": 1702063482129, "logtype": "training_step"}
{"Total num played games": 56866, "Total num trained steps": 113163, "Timestamp in ms": 1702063552550, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.11328125}
{"Avg objective": 22.9765625, "Games time in secs": 124.32018180936575, "Avg game time in secs": 2.1720553694758564, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.7}, "Total num played games": 56960, "Total num trained steps": 113179, "Timestamp in ms": 1702063559978, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887640449438202, "Avg loss": 0.9343908634036779, "Avg value loss": 0.6164625684905332, "Avg policy loss": 0.3179282824276015, "Total num played games": 56960, "Total num trained steps": 113280, "Timestamp in ms": 1702063602713, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910112359550562, "Avg loss": 0.35530292778275907, "Avg value loss": 0.07134505230351351, "Avg policy loss": 0.2839578768471256, "Total num played games": 56960, "Total num trained steps": 113408, "Timestamp in ms": 1702063655836, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899744102078731, "Avg loss": 0.764077931875363, "Avg value loss": 0.46787466152454726, "Avg policy loss": 0.29620327381417155, "Total num played games": 57054, "Total num trained steps": 113536, "Timestamp in ms": 1702063707989, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 174.91496851295233, "Avg game time in secs": 1.7314199587272014, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.45}, "Total num played games": 57088, "Total num trained steps": 113601, "Timestamp in ms": 1702063734893, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988940995310422, "Avg loss": 0.8765203976072371, "Avg value loss": 0.572284206020413, "Avg policy loss": 0.30423619179055095, "Total num played games": 57148, "Total num trained steps": 113664, "Timestamp in ms": 1702063761795, "logtype": "training_step"}
{"Total num played games": 57148, "Total num trained steps": 113763, "Timestamp in ms": 1702063871165, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 28.11328125}
{"Avg objective": 21.890625, "Games time in secs": 139.22480827197433, "Avg game time in secs": 1.817772517708363, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 57216, "Total num trained steps": 113768, "Timestamp in ms": 1702063874118, "logtype": "played_game"}
{"Ratio train steps to played games": 1.987910974459313, "Avg loss": 0.6475615862291306, "Avg value loss": 0.3541159923770465, "Avg policy loss": 0.29344559006858617, "Total num played games": 57242, "Total num trained steps": 113792, "Timestamp in ms": 1702063884153, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901470947905384, "Avg loss": 0.44168241904117167, "Avg value loss": 0.136511529533891, "Avg policy loss": 0.3051708878483623, "Total num played games": 57242, "Total num trained steps": 113920, "Timestamp in ms": 1702063934531, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9891167852658016, "Avg loss": 0.5621661141049117, "Avg value loss": 0.2585371564491652, "Avg policy loss": 0.3036289574811235, "Total num played games": 57336, "Total num trained steps": 114048, "Timestamp in ms": 1702063986864, "logtype": "training_step"}
{"Avg objective": 21.484375, "Games time in secs": 160.779386267066, "Avg game time in secs": 2.089205048396252, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 57344, "Total num trained steps": 114164, "Timestamp in ms": 1702064034898, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879513876797716, "Avg loss": 0.5198109319899231, "Avg value loss": 0.2241851240687538, "Avg policy loss": 0.29562580853234977, "Total num played games": 57434, "Total num trained steps": 114176, "Timestamp in ms": 1702064039916, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901800327332242, "Avg loss": 0.6111574086826295, "Avg value loss": 0.2980171655945014, "Avg policy loss": 0.313140241894871, "Total num played games": 57434, "Total num trained steps": 114304, "Timestamp in ms": 1702064092323, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 80.43810331821442, "Avg game time in secs": 1.77178102475591, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.45}, "Total num played games": 57472, "Total num trained steps": 114361, "Timestamp in ms": 1702064115337, "logtype": "played_game"}
{"Total num played games": 57528, "Total num trained steps": 114366, "Timestamp in ms": 1702064188642, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.125}
{"Avg objective": 21.4453125, "Games time in secs": 76.27095091342926, "Avg game time in secs": 1.9956057399394922, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.66, "agent_stopped_0": 0.43}, "Total num played games": 57600, "Total num trained steps": 114371, "Timestamp in ms": 1702064191608, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9859081600777482, "Avg loss": 1.1470541888847947, "Avg value loss": 0.831549352791626, "Avg policy loss": 0.3155048458138481, "Total num played games": 57622, "Total num trained steps": 114432, "Timestamp in ms": 1702064217435, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9881121793759329, "Avg loss": 0.4304565128404647, "Avg value loss": 0.12686561467126012, "Avg policy loss": 0.30359089910052717, "Total num played games": 57622, "Total num trained steps": 114560, "Timestamp in ms": 1702064272669, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903509076394432, "Avg loss": 0.3593549248762429, "Avg value loss": 0.06090110310469754, "Avg policy loss": 0.2984538215678185, "Total num played games": 57622, "Total num trained steps": 114688, "Timestamp in ms": 1702064326330, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893270496915934, "Avg loss": 0.7469227204564959, "Avg value loss": 0.44306078797671944, "Avg policy loss": 0.30386193620506674, "Total num played games": 57716, "Total num trained steps": 114816, "Timestamp in ms": 1702064379567, "logtype": "training_step"}
{"Avg objective": 21.859375, "Games time in secs": 232.1292720772326, "Avg game time in secs": 2.0162307019054424, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 57728, "Total num trained steps": 114924, "Timestamp in ms": 1702064423738, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988306521363086, "Avg loss": 0.5648994368966669, "Avg value loss": 0.2732289177365601, "Avg policy loss": 0.2916705139214173, "Total num played games": 57810, "Total num trained steps": 114944, "Timestamp in ms": 1702064431936, "logtype": "training_step"}
{"Total num played games": 57810, "Total num trained steps": 114968, "Timestamp in ms": 1702064502361, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.515625}
{"Avg objective": 22.5, "Games time in secs": 80.93393894284964, "Avg game time in secs": 1.8003722917928826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.55}, "Total num played games": 57856, "Total num trained steps": 114971, "Timestamp in ms": 1702064504672, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9872893064382426, "Avg loss": 1.0068070564884692, "Avg value loss": 0.6800963088753633, "Avg policy loss": 0.3267107567517087, "Total num played games": 57904, "Total num trained steps": 115072, "Timestamp in ms": 1702064546340, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9894998618402873, "Avg loss": 0.3686372513184324, "Avg value loss": 0.07746218767715618, "Avg policy loss": 0.2911750653292984, "Total num played games": 57904, "Total num trained steps": 115200, "Timestamp in ms": 1702064600264, "logtype": "training_step"}
{"Avg objective": 23.2265625, "Games time in secs": 137.76614328101277, "Avg game time in secs": 1.917922152322717, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 57984, "Total num trained steps": 115302, "Timestamp in ms": 1702064642438, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98848236146074, "Avg loss": 0.710841340944171, "Avg value loss": 0.41906634261249565, "Avg policy loss": 0.29177500086370856, "Total num played games": 57998, "Total num trained steps": 115328, "Timestamp in ms": 1702064652251, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906893341149694, "Avg loss": 0.49419507943093777, "Avg value loss": 0.19511621724814177, "Avg policy loss": 0.29907886148430407, "Total num played games": 57998, "Total num trained steps": 115456, "Timestamp in ms": 1702064703236, "logtype": "training_step"}
{"Total num played games": 58092, "Total num trained steps": 115570, "Timestamp in ms": 1702064813394, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.98046875}
{"Avg objective": 20.8046875, "Games time in secs": 172.89250026270747, "Avg game time in secs": 1.9394721603312064, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4921875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 58112, "Total num trained steps": 115573, "Timestamp in ms": 1702064815331, "logtype": "played_game"}
{"Ratio train steps to played games": 1.986457223387069, "Avg loss": 0.9390745197888464, "Avg value loss": 0.6402592387457844, "Avg policy loss": 0.29881528683472425, "Total num played games": 58186, "Total num trained steps": 115584, "Timestamp in ms": 1702064819557, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9886570652734334, "Avg loss": 0.6483147798571736, "Avg value loss": 0.350536213896703, "Avg policy loss": 0.29777856182772666, "Total num played games": 58186, "Total num trained steps": 115712, "Timestamp in ms": 1702064872320, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908397208950606, "Avg loss": 0.352045294130221, "Avg value loss": 0.06838769867317751, "Avg policy loss": 0.2836575942346826, "Total num played games": 58186, "Total num trained steps": 115840, "Timestamp in ms": 1702064925475, "logtype": "training_step"}
{"Avg objective": 23.53125, "Games time in secs": 120.75915315374732, "Avg game time in secs": 1.8372931178892031, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.53}, "Total num played games": 58240, "Total num trained steps": 115866, "Timestamp in ms": 1702064936090, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897567001818743, "Avg loss": 0.7487339582294226, "Avg value loss": 0.44393495633266866, "Avg policy loss": 0.30479899782221764, "Total num played games": 58282, "Total num trained steps": 115968, "Timestamp in ms": 1702064980929, "logtype": "training_step"}
{"Avg objective": 22.84375, "Games time in secs": 82.4752515219152, "Avg game time in secs": 2.078315605293028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.64, "agent_stopped_0": 0.43}, "Total num played games": 58368, "Total num trained steps": 116061, "Timestamp in ms": 1702065018565, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887625051390982, "Avg loss": 0.8942428710870445, "Avg value loss": 0.5965005767648108, "Avg policy loss": 0.29774227691814303, "Total num played games": 58376, "Total num trained steps": 116096, "Timestamp in ms": 1702065032754, "logtype": "training_step"}
{"Total num played games": 58376, "Total num trained steps": 116174, "Timestamp in ms": 1702065156484, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.765625}
{"Ratio train steps to played games": 1.9877373011800923, "Avg loss": 0.8651363682001829, "Avg value loss": 0.5433153129415587, "Avg policy loss": 0.3218210486229509, "Total num played games": 58470, "Total num trained steps": 116224, "Timestamp in ms": 1702065178347, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899435608004106, "Avg loss": 0.4344499632716179, "Avg value loss": 0.12172249116702005, "Avg policy loss": 0.31272747076582164, "Total num played games": 58470, "Total num trained steps": 116352, "Timestamp in ms": 1702065231293, "logtype": "training_step"}
{"Avg objective": 22.4609375, "Games time in secs": 245.15456676110625, "Avg game time in secs": 1.9563621174020227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.56, "agent_stopped_0": 0.55}, "Total num played games": 58496, "Total num trained steps": 116433, "Timestamp in ms": 1702065263720, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9888672608680804, "Avg loss": 0.8631663501728326, "Avg value loss": 0.5599941327527631, "Avg policy loss": 0.30317221058066934, "Total num played games": 58566, "Total num trained steps": 116480, "Timestamp in ms": 1702065283561, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9910528292866168, "Avg loss": 0.427918087458238, "Avg value loss": 0.11768425031914376, "Avg policy loss": 0.3102338358294219, "Total num played games": 58566, "Total num trained steps": 116608, "Timestamp in ms": 1702065336244, "logtype": "training_step"}
{"Avg objective": 21.1796875, "Games time in secs": 79.87677690014243, "Avg game time in secs": 1.9309711893438362, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 58624, "Total num trained steps": 116625, "Timestamp in ms": 1702065343597, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900443232185476, "Avg loss": 0.8483345895074308, "Avg value loss": 0.5429641678929329, "Avg policy loss": 0.30537041439674795, "Total num played games": 58660, "Total num trained steps": 116736, "Timestamp in ms": 1702065389727, "logtype": "training_step"}
{"Total num played games": 58660, "Total num trained steps": 116775, "Timestamp in ms": 1702065501453, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.19921875}
{"Avg objective": 23.140625, "Games time in secs": 161.50200809165835, "Avg game time in secs": 1.9436878502601758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 58752, "Total num trained steps": 116781, "Timestamp in ms": 1702065505099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890390441501855, "Avg loss": 0.9903384826611727, "Avg value loss": 0.6731158703914843, "Avg policy loss": 0.31722262140829116, "Total num played games": 58754, "Total num trained steps": 116864, "Timestamp in ms": 1702065538433, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991217619225925, "Avg loss": 0.391270593740046, "Avg value loss": 0.09432769054546952, "Avg policy loss": 0.29694290552288294, "Total num played games": 58754, "Total num trained steps": 116992, "Timestamp in ms": 1702065590728, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9902120717781402, "Avg loss": 0.6660148072987795, "Avg value loss": 0.3601613446662668, "Avg policy loss": 0.3058534573065117, "Total num played games": 58848, "Total num trained steps": 117120, "Timestamp in ms": 1702065641801, "logtype": "training_step"}
{"Avg objective": 21.0078125, "Games time in secs": 164.94261441007257, "Avg game time in secs": 1.8439862265076954, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.48, "agent_stopped_0": 0.57}, "Total num played games": 58880, "Total num trained steps": 117189, "Timestamp in ms": 1702065670042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.98914223669924, "Avg loss": 0.6747415959835052, "Avg value loss": 0.36772334002307616, "Avg policy loss": 0.30701825313735753, "Total num played games": 58944, "Total num trained steps": 117248, "Timestamp in ms": 1702065694912, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912968241042346, "Avg loss": 0.379473146982491, "Avg value loss": 0.08145577210234478, "Avg policy loss": 0.2980173761025071, "Total num played games": 58944, "Total num trained steps": 117376, "Timestamp in ms": 1702065748248, "logtype": "training_step"}
{"Total num played games": 58944, "Total num trained steps": 117376, "Timestamp in ms": 1702065801207, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.87109375}
{"Avg objective": 22.2578125, "Games time in secs": 133.7442525215447, "Avg game time in secs": 1.8246253976540174, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 59008, "Total num trained steps": 117380, "Timestamp in ms": 1702065803786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902439024390244, "Avg loss": 0.7914121630601585, "Avg value loss": 0.48585602987441234, "Avg policy loss": 0.30555613117758185, "Total num played games": 59040, "Total num trained steps": 117504, "Timestamp in ms": 1702065853092, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9892447661243955, "Avg loss": 0.6961316165979952, "Avg value loss": 0.385816321184393, "Avg policy loss": 0.31031530094332993, "Total num played games": 59134, "Total num trained steps": 117632, "Timestamp in ms": 1702065905466, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 153.80977088212967, "Avg game time in secs": 2.108190159779042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.59}, "Total num played games": 59136, "Total num trained steps": 117758, "Timestamp in ms": 1702065957596, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912746457438533, "Avg loss": 0.3741440768353641, "Avg value loss": 0.07986107436590828, "Avg policy loss": 0.2942830048268661, "Total num played games": 59138, "Total num trained steps": 117760, "Timestamp in ms": 1702065958277, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903427317237887, "Avg loss": 0.8923782557249069, "Avg value loss": 0.5615698562469333, "Avg policy loss": 0.3308083941228688, "Total num played games": 59230, "Total num trained steps": 117888, "Timestamp in ms": 1702066010451, "logtype": "training_step"}
{"Avg objective": 22.28125, "Games time in secs": 81.27335271984339, "Avg game time in secs": 1.8142924185376614, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.48}, "Total num played games": 59264, "Total num trained steps": 117953, "Timestamp in ms": 1702066038869, "logtype": "played_game"}
{"Total num played games": 59324, "Total num trained steps": 117980, "Timestamp in ms": 1702066141692, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.171875}
{"Avg objective": 22.4296875, "Games time in secs": 105.49992626532912, "Avg game time in secs": 1.8771885144815315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.56}, "Total num played games": 59392, "Total num trained steps": 117985, "Timestamp in ms": 1702066144369, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9861994681746271, "Avg loss": 1.3866662092041224, "Avg value loss": 1.0579426289186813, "Avg policy loss": 0.32872357254382223, "Total num played games": 59418, "Total num trained steps": 118016, "Timestamp in ms": 1702066157195, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9883536975327343, "Avg loss": 0.5339932318311185, "Avg value loss": 0.20142562611727044, "Avg policy loss": 0.33256760775111616, "Total num played games": 59418, "Total num trained steps": 118144, "Timestamp in ms": 1702066209884, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9905079268908412, "Avg loss": 0.37129428517073393, "Avg value loss": 0.07218047862988897, "Avg policy loss": 0.29911380889825523, "Total num played games": 59418, "Total num trained steps": 118272, "Timestamp in ms": 1702066261181, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895147197203926, "Avg loss": 0.762054476654157, "Avg value loss": 0.4524521746498067, "Avg policy loss": 0.30960230284836143, "Total num played games": 59512, "Total num trained steps": 118400, "Timestamp in ms": 1702066311576, "logtype": "training_step"}
{"Avg objective": 22.5078125, "Games time in secs": 213.48445691913366, "Avg game time in secs": 2.040375899669016, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.64, "agent_stopped_0": 0.42}, "Total num played games": 59520, "Total num trained steps": 118515, "Timestamp in ms": 1702066357854, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885246451699494, "Avg loss": 0.46101331198588014, "Avg value loss": 0.16364040222833864, "Avg policy loss": 0.2973729158984497, "Total num played games": 59606, "Total num trained steps": 118528, "Timestamp in ms": 1702066362861, "logtype": "training_step"}
{"Total num played games": 59606, "Total num trained steps": 118580, "Timestamp in ms": 1702066462755, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.03125}
{"Avg objective": 21.5859375, "Games time in secs": 107.08949162065983, "Avg game time in secs": 1.765489566983888, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.59, "agent_stopped_more": 0.41, "played_steps": 0.46}, "Total num played games": 59648, "Total num trained steps": 118585, "Timestamp in ms": 1702066464944, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9875376884422111, "Avg loss": 1.0516617544926703, "Avg value loss": 0.7249562378856353, "Avg policy loss": 0.32670551957562566, "Total num played games": 59700, "Total num trained steps": 118656, "Timestamp in ms": 1702066493551, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989681742043551, "Avg loss": 0.40170163731090724, "Avg value loss": 0.09629654805758037, "Avg policy loss": 0.3054050891660154, "Total num played games": 59700, "Total num trained steps": 118784, "Timestamp in ms": 1702066546095, "logtype": "training_step"}
{"Avg objective": 22.265625, "Games time in secs": 126.2513884305954, "Avg game time in secs": 1.892871435644338, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.55, "agent_stopped_0": 0.49}, "Total num played games": 59776, "Total num trained steps": 118895, "Timestamp in ms": 1702066591195, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886945178445998, "Avg loss": 0.5521783535368741, "Avg value loss": 0.2553859318722971, "Avg policy loss": 0.2967924189288169, "Total num played games": 59794, "Total num trained steps": 118912, "Timestamp in ms": 1702066597904, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908352008562733, "Avg loss": 0.45129582891240716, "Avg value loss": 0.13435291309724562, "Avg policy loss": 0.31694291590247303, "Total num played games": 59794, "Total num trained steps": 119040, "Timestamp in ms": 1702066651226, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9897812656536984, "Avg loss": 0.6640733837848529, "Avg value loss": 0.35825061512878165, "Avg policy loss": 0.305822771275416, "Total num played games": 59890, "Total num trained steps": 119168, "Timestamp in ms": 1702066702436, "logtype": "training_step"}
{"Total num played games": 59890, "Total num trained steps": 119181, "Timestamp in ms": 1702066781192, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.4140625}
{"Avg objective": 22.078125, "Games time in secs": 191.81048065051436, "Avg game time in secs": 1.936963088111952, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 59904, "Total num trained steps": 119183, "Timestamp in ms": 1702066783006, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887970125366765, "Avg loss": 0.9494965025223792, "Avg value loss": 0.6369196880550589, "Avg policy loss": 0.31257681210990995, "Total num played games": 59984, "Total num trained steps": 119296, "Timestamp in ms": 1702066828539, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990930914910643, "Avg loss": 0.36191430455073714, "Avg value loss": 0.06958830001531169, "Avg policy loss": 0.29232600471004844, "Total num played games": 59984, "Total num trained steps": 119424, "Timestamp in ms": 1702066881310, "logtype": "training_step"}
{"Avg objective": 22.1171875, "Games time in secs": 113.50474555790424, "Avg game time in secs": 1.8497471059381496, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.6}, "Total num played games": 60032, "Total num trained steps": 119461, "Timestamp in ms": 1702066896511, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899464030094212, "Avg loss": 0.6673044860363007, "Avg value loss": 0.3554630813305266, "Avg policy loss": 0.31184140068944544, "Total num played games": 60078, "Total num trained steps": 119552, "Timestamp in ms": 1702066933664, "logtype": "training_step"}
{"Avg objective": 22.4140625, "Games time in secs": 78.64600436761975, "Avg game time in secs": 2.0893221722217277, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.7, "agent_stopped_0": 0.38}, "Total num played games": 60160, "Total num trained steps": 119652, "Timestamp in ms": 1702066975157, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889483480688692, "Avg loss": 0.7094285900238901, "Avg value loss": 0.3953183570120018, "Avg policy loss": 0.31411022460088134, "Total num played games": 60172, "Total num trained steps": 119680, "Timestamp in ms": 1702066986207, "logtype": "training_step"}
{"Total num played games": 60172, "Total num trained steps": 119782, "Timestamp in ms": 1702067104296, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 27.29296875}
{"Ratio train steps to played games": 1.987986592772044, "Avg loss": 0.6982987432274967, "Avg value loss": 0.367592192516895, "Avg policy loss": 0.330706556327641, "Total num played games": 60266, "Total num trained steps": 119808, "Timestamp in ms": 1702067115509, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990110510072014, "Avg loss": 0.5021296374034137, "Avg value loss": 0.17661928886082023, "Avg policy loss": 0.32551034714560956, "Total num played games": 60266, "Total num trained steps": 119936, "Timestamp in ms": 1702067168881, "logtype": "training_step"}
{"Avg objective": 20.9765625, "Games time in secs": 230.71065690740943, "Avg game time in secs": 1.9422241301799659, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.46, "played_steps": 0.55, "agent_stopped_0": 0.54}, "Total num played games": 60288, "Total num trained steps": 120024, "Timestamp in ms": 1702067205868, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891318754141816, "Avg loss": 0.6459993096068501, "Avg value loss": 0.3275556588778272, "Avg policy loss": 0.3184436537558213, "Total num played games": 60360, "Total num trained steps": 120064, "Timestamp in ms": 1702067221495, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912524850894633, "Avg loss": 0.41895606950856745, "Avg value loss": 0.10192955646198243, "Avg policy loss": 0.31702651269733906, "Total num played games": 60360, "Total num trained steps": 120192, "Timestamp in ms": 1702067274318, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 77.65176337957382, "Avg game time in secs": 1.874230758898193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 60416, "Total num trained steps": 120214, "Timestamp in ms": 1702067283519, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902735964535019, "Avg loss": 0.7767540421336889, "Avg value loss": 0.4711285226221662, "Avg policy loss": 0.30562552344053984, "Total num played games": 60454, "Total num trained steps": 120320, "Timestamp in ms": 1702067327519, "logtype": "training_step"}
{"Total num played games": 60454, "Total num trained steps": 120386, "Timestamp in ms": 1702067415610, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.890625}
{"Avg objective": 21.3828125, "Games time in secs": 136.2360563725233, "Avg game time in secs": 2.15067438071128, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5703125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 60544, "Total num trained steps": 120395, "Timestamp in ms": 1702067419756, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892977472418576, "Avg loss": 0.5679069333709776, "Avg value loss": 0.26824124398990534, "Avg policy loss": 0.29966568970121443, "Total num played games": 60548, "Total num trained steps": 120448, "Timestamp in ms": 1702067441899, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991411772478034, "Avg loss": 0.36966891027987003, "Avg value loss": 0.06987977755488828, "Avg policy loss": 0.2997891326667741, "Total num played games": 60548, "Total num trained steps": 120576, "Timestamp in ms": 1702067493400, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904356716467135, "Avg loss": 0.9420384895056486, "Avg value loss": 0.6190346722432878, "Avg policy loss": 0.323003820842132, "Total num played games": 60642, "Total num trained steps": 120704, "Timestamp in ms": 1702067546036, "logtype": "training_step"}
{"Avg objective": 22.2109375, "Games time in secs": 155.7867530658841, "Avg game time in secs": 1.9575918117479887, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4296875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.59}, "Total num played games": 60672, "Total num trained steps": 120777, "Timestamp in ms": 1702067575542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989397082551286, "Avg loss": 0.8781845853663981, "Avg value loss": 0.572941291204188, "Avg policy loss": 0.3052432880504057, "Total num played games": 60738, "Total num trained steps": 120832, "Timestamp in ms": 1702067597785, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914880305574765, "Avg loss": 0.4130542909260839, "Avg value loss": 0.10643561350298114, "Avg policy loss": 0.3066186780342832, "Total num played games": 60738, "Total num trained steps": 120960, "Timestamp in ms": 1702067651676, "logtype": "training_step"}
{"Avg objective": 22.96875, "Games time in secs": 80.83136020228267, "Avg game time in secs": 1.9311125534877647, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 60800, "Total num trained steps": 120969, "Timestamp in ms": 1702067656374, "logtype": "played_game"}
{"Total num played games": 60832, "Total num trained steps": 120988, "Timestamp in ms": 1702067737609, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 26.51953125}
{"Ratio train steps to played games": 1.987460197616781, "Avg loss": 1.3353871372528374, "Avg value loss": 1.010511981730815, "Avg policy loss": 0.32487516291439533, "Total num played games": 60926, "Total num trained steps": 121088, "Timestamp in ms": 1702067778073, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9895611069165873, "Avg loss": 0.37085658707655966, "Avg value loss": 0.07930962339742109, "Avg policy loss": 0.2915469667641446, "Total num played games": 60926, "Total num trained steps": 121216, "Timestamp in ms": 1702067830564, "logtype": "training_step"}
{"Avg objective": 20.0703125, "Games time in secs": 226.4252739176154, "Avg game time in secs": 2.048351966543123, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.7, "agent_stopped_0": 0.42}, "Total num played games": 60928, "Total num trained steps": 121341, "Timestamp in ms": 1702067882799, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913351713272942, "Avg loss": 0.33994854940101504, "Avg value loss": 0.05568971790489741, "Avg policy loss": 0.28425882977899164, "Total num played games": 60934, "Total num trained steps": 121344, "Timestamp in ms": 1702067883805, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906915765322846, "Avg loss": 0.8076611936558038, "Avg value loss": 0.5034348693443462, "Avg policy loss": 0.30422632046975195, "Total num played games": 61020, "Total num trained steps": 121472, "Timestamp in ms": 1702067935275, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 77.33971348777413, "Avg game time in secs": 1.7067121059517376, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.57, "agent_stopped_more": 0.43, "played_steps": 0.47}, "Total num played games": 61056, "Total num trained steps": 121532, "Timestamp in ms": 1702067960139, "logtype": "played_game"}
{"Total num played games": 61114, "Total num trained steps": 121592, "Timestamp in ms": 1702068045621, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.19921875}
{"Avg objective": 22.234375, "Games time in secs": 88.41195026040077, "Avg game time in secs": 1.8816586467437446, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.53, "played_steps": 0.59, "agent_stopped_0": 0.47}, "Total num played games": 61184, "Total num trained steps": 121598, "Timestamp in ms": 1702068048551, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9869930389882022, "Avg loss": 0.6763578888494521, "Avg value loss": 0.37282226444222033, "Avg policy loss": 0.3035356248728931, "Total num played games": 61194, "Total num trained steps": 121600, "Timestamp in ms": 1702068049038, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887596392628415, "Avg loss": 0.7100501777604222, "Avg value loss": 0.3762682764499914, "Avg policy loss": 0.33378190256189555, "Total num played games": 61208, "Total num trained steps": 121728, "Timestamp in ms": 1702068100635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908508691674291, "Avg loss": 0.36453418782912195, "Avg value loss": 0.06542947757407092, "Avg policy loss": 0.2991047118557617, "Total num played games": 61208, "Total num trained steps": 121856, "Timestamp in ms": 1702068151841, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9898861374832795, "Avg loss": 0.7167939550708979, "Avg value loss": 0.40513795110746287, "Avg policy loss": 0.31165599927771837, "Total num played games": 61302, "Total num trained steps": 121984, "Timestamp in ms": 1702068203302, "logtype": "training_step"}
{"Avg objective": 22.84375, "Games time in secs": 200.80332469195127, "Avg game time in secs": 1.9584819457377307, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.61, "agent_stopped_0": 0.48}, "Total num played games": 61312, "Total num trained steps": 122096, "Timestamp in ms": 1702068249355, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889243598931527, "Avg loss": 0.5699235789943486, "Avg value loss": 0.27539873248315416, "Avg policy loss": 0.29452484485227615, "Total num played games": 61396, "Total num trained steps": 122112, "Timestamp in ms": 1702068255980, "logtype": "training_step"}
{"Total num played games": 61396, "Total num trained steps": 122193, "Timestamp in ms": 1702068361090, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.8984375}
{"Avg objective": 22.015625, "Games time in secs": 113.92628901079297, "Avg game time in secs": 1.7931325669342186, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.55}, "Total num played games": 61440, "Total num trained steps": 122196, "Timestamp in ms": 1702068363281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879655228492439, "Avg loss": 1.1290145725943148, "Avg value loss": 0.8053628543857485, "Avg policy loss": 0.32365171459969133, "Total num played games": 61490, "Total num trained steps": 122240, "Timestamp in ms": 1702068382295, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9900471621401854, "Avg loss": 0.4276911010965705, "Avg value loss": 0.11394165133242495, "Avg policy loss": 0.31374944909475744, "Total num played games": 61490, "Total num trained steps": 122368, "Timestamp in ms": 1702068435220, "logtype": "training_step"}
{"Avg objective": 22.3984375, "Games time in secs": 114.30669867247343, "Avg game time in secs": 1.882968978228746, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 61568, "Total num trained steps": 122475, "Timestamp in ms": 1702068477588, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9890234793621928, "Avg loss": 0.6953773428685963, "Avg value loss": 0.398366001812974, "Avg policy loss": 0.2970113339833915, "Total num played games": 61586, "Total num trained steps": 122496, "Timestamp in ms": 1702068485711, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911018738024875, "Avg loss": 0.5752017879858613, "Avg value loss": 0.26801427896134555, "Avg policy loss": 0.30718750215601176, "Total num played games": 61586, "Total num trained steps": 122624, "Timestamp in ms": 1702068538405, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901426718547341, "Avg loss": 0.722035561222583, "Avg value loss": 0.42913850644254126, "Avg policy loss": 0.29289704840630293, "Total num played games": 61680, "Total num trained steps": 122752, "Timestamp in ms": 1702068590892, "logtype": "training_step"}
{"Total num played games": 61680, "Total num trained steps": 122793, "Timestamp in ms": 1702068666500, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.42578125}
{"Avg objective": 22.4296875, "Games time in secs": 190.62942207232118, "Avg game time in secs": 1.8288695384107996, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 61696, "Total num trained steps": 122796, "Timestamp in ms": 1702068668218, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989186389095736, "Avg loss": 0.6502638701349497, "Avg value loss": 0.3598526930436492, "Avg policy loss": 0.2904111772077158, "Total num played games": 61774, "Total num trained steps": 122880, "Timestamp in ms": 1702068702933, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912422702107684, "Avg loss": 0.34294215962290764, "Avg value loss": 0.07035317717236467, "Avg policy loss": 0.27258898480795324, "Total num played games": 61774, "Total num trained steps": 123008, "Timestamp in ms": 1702068755839, "logtype": "training_step"}
{"Avg objective": 21.4609375, "Games time in secs": 101.70610013231635, "Avg game time in secs": 1.8527842921903357, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.47, "agent_stopped_more": 0.53, "played_steps": 0.59}, "Total num played games": 61824, "Total num trained steps": 123042, "Timestamp in ms": 1702068769924, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903019331479925, "Avg loss": 0.6320579400053248, "Avg value loss": 0.35164055149652995, "Avg policy loss": 0.28041739179752767, "Total num played games": 61868, "Total num trained steps": 123136, "Timestamp in ms": 1702068808231, "logtype": "training_step"}
{"Avg objective": 22.0625, "Games time in secs": 78.70960780978203, "Avg game time in secs": 2.0830845877353568, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.66}, "Total num played games": 61952, "Total num trained steps": 123232, "Timestamp in ms": 1702068848634, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893483102546723, "Avg loss": 0.7076593588571995, "Avg value loss": 0.41990908395382576, "Avg policy loss": 0.2877502782503143, "Total num played games": 61962, "Total num trained steps": 123264, "Timestamp in ms": 1702068861775, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914140925083115, "Avg loss": 0.4102644941303879, "Avg value loss": 0.1222357923979871, "Avg policy loss": 0.28802870120853186, "Total num played games": 61962, "Total num trained steps": 123392, "Timestamp in ms": 1702068916211, "logtype": "training_step"}
{"Total num played games": 61962, "Total num trained steps": 123395, "Timestamp in ms": 1702068976305, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.203125}
{"Ratio train steps to played games": 1.9904602294701559, "Avg loss": 0.8368169248569757, "Avg value loss": 0.5235894339566585, "Avg policy loss": 0.3132274945965037, "Total num played games": 62056, "Total num trained steps": 123520, "Timestamp in ms": 1702069028409, "logtype": "training_step"}
{"Avg objective": 21.4375, "Games time in secs": 213.8483990803361, "Avg game time in secs": 1.8715177265694365, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.64, "agent_stopped_0": 0.48}, "Total num played games": 62080, "Total num trained steps": 123605, "Timestamp in ms": 1702069062482, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894452310464668, "Avg loss": 0.8227715566754341, "Avg value loss": 0.524087691999739, "Avg policy loss": 0.298683870350942, "Total num played games": 62152, "Total num trained steps": 123648, "Timestamp in ms": 1702069079555, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915046981593512, "Avg loss": 0.41860803961753845, "Avg value loss": 0.11857788349152543, "Avg policy loss": 0.30003016139380634, "Total num played games": 62152, "Total num trained steps": 123776, "Timestamp in ms": 1702069132964, "logtype": "training_step"}
{"Avg objective": 23.0, "Games time in secs": 79.7632484138012, "Avg game time in secs": 1.8209868731210008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.62, "agent_stopped_0": 0.45}, "Total num played games": 62208, "Total num trained steps": 123799, "Timestamp in ms": 1702069142246, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904896542860815, "Avg loss": 0.6174232535995543, "Avg value loss": 0.32501388347009197, "Avg policy loss": 0.2924093643669039, "Total num played games": 62248, "Total num trained steps": 123904, "Timestamp in ms": 1702069186276, "logtype": "training_step"}
{"Avg objective": 20.890625, "Games time in secs": 80.55420829728246, "Avg game time in secs": 2.2011382824275643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6796875, "Avg reasons for ending game": {"agent_stopped_more": 0.68, "played_steps": 0.73, "agent_stopped_0": 0.32}, "Total num played games": 62336, "Total num trained steps": 123993, "Timestamp in ms": 1702069222801, "logtype": "played_game"}
{"Total num played games": 62342, "Total num trained steps": 123995, "Timestamp in ms": 1702069247978, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.0546875}
{"Ratio train steps to played games": 1.9865462233326927, "Avg loss": 1.0668403131421655, "Avg value loss": 0.7591030759504065, "Avg policy loss": 0.30773724312894046, "Total num played games": 62436, "Total num trained steps": 124032, "Timestamp in ms": 1702069263507, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9885963226343777, "Avg loss": 0.4944644868373871, "Avg value loss": 0.16534676821902394, "Avg policy loss": 0.3291177162900567, "Total num played games": 62436, "Total num trained steps": 124160, "Timestamp in ms": 1702069316900, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906464219360624, "Avg loss": 0.36072499211877584, "Avg value loss": 0.0650068343966268, "Avg policy loss": 0.29571816278621554, "Total num played games": 62436, "Total num trained steps": 124288, "Timestamp in ms": 1702069370470, "logtype": "training_step"}
{"Avg objective": 21.0703125, "Games time in secs": 179.40468025580049, "Avg game time in secs": 1.9200698236236349, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 62464, "Total num trained steps": 124365, "Timestamp in ms": 1702069402206, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896373056994818, "Avg loss": 0.7409284624736756, "Avg value loss": 0.4370867515099235, "Avg policy loss": 0.30384171358309686, "Total num played games": 62532, "Total num trained steps": 124416, "Timestamp in ms": 1702069423172, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991684257660078, "Avg loss": 0.3919788852799684, "Avg value loss": 0.09130216995254159, "Avg policy loss": 0.30067671299912035, "Total num played games": 62532, "Total num trained steps": 124544, "Timestamp in ms": 1702069475306, "logtype": "training_step"}
{"Avg objective": 21.7265625, "Games time in secs": 78.8498889580369, "Avg game time in secs": 1.9695785054645967, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.63}, "Total num played games": 62592, "Total num trained steps": 124558, "Timestamp in ms": 1702069481056, "logtype": "played_game"}
{"Total num played games": 62626, "Total num trained steps": 124596, "Timestamp in ms": 1702069535781, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.98046875}
{"Avg objective": 22.5390625, "Games time in secs": 63.85198741778731, "Avg game time in secs": 2.1250445581390522, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5625, "Avg reasons for ending game": {"agent_stopped_0": 0.37, "agent_stopped_more": 0.63, "played_steps": 0.71}, "Total num played games": 62720, "Total num trained steps": 124616, "Timestamp in ms": 1702069544908, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9877551020408164, "Avg loss": 1.251845846651122, "Avg value loss": 0.9205924035049975, "Avg policy loss": 0.33125345048028976, "Total num played games": 62720, "Total num trained steps": 124672, "Timestamp in ms": 1702069567814, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989795918367347, "Avg loss": 0.4002229026518762, "Avg value loss": 0.09000086109153926, "Avg policy loss": 0.3102220429573208, "Total num played games": 62720, "Total num trained steps": 124800, "Timestamp in ms": 1702069620520, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918367346938775, "Avg loss": 0.3548558030743152, "Avg value loss": 0.0553388679982163, "Avg policy loss": 0.29951693559996784, "Total num played games": 62720, "Total num trained steps": 124928, "Timestamp in ms": 1702069674323, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908303616912888, "Avg loss": 0.7803705653641373, "Avg value loss": 0.4654538661998231, "Avg policy loss": 0.3149166889488697, "Total num played games": 62816, "Total num trained steps": 125056, "Timestamp in ms": 1702069727809, "logtype": "training_step"}
{"Avg objective": 20.8984375, "Games time in secs": 210.5976270325482, "Avg game time in secs": 1.696414788835682, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 62848, "Total num trained steps": 125125, "Timestamp in ms": 1702069755506, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898903195040534, "Avg loss": 0.82032016874291, "Avg value loss": 0.5060314397269394, "Avg policy loss": 0.31428872200194746, "Total num played games": 62910, "Total num trained steps": 125184, "Timestamp in ms": 1702069778683, "logtype": "training_step"}
{"Total num played games": 62910, "Total num trained steps": 125199, "Timestamp in ms": 1702069822596, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8671875}
{"Avg objective": 21.5859375, "Games time in secs": 69.7603397667408, "Avg game time in secs": 1.8845800654380582, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 62976, "Total num trained steps": 125204, "Timestamp in ms": 1702069825266, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9889372103358518, "Avg loss": 0.8100466572213918, "Avg value loss": 0.485428141662851, "Avg policy loss": 0.3246185185853392, "Total num played games": 63004, "Total num trained steps": 125312, "Timestamp in ms": 1702069869492, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909688273760395, "Avg loss": 0.37226146669127047, "Avg value loss": 0.06862436191295274, "Avg policy loss": 0.3036371023626998, "Total num played games": 63004, "Total num trained steps": 125440, "Timestamp in ms": 1702069921980, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9899841521394612, "Avg loss": 0.8241162712220103, "Avg value loss": 0.5121704586490523, "Avg policy loss": 0.3119458123110235, "Total num played games": 63100, "Total num trained steps": 125568, "Timestamp in ms": 1702069973130, "logtype": "training_step"}
{"Avg objective": 22.5546875, "Games time in secs": 198.3128962442279, "Avg game time in secs": 1.9784759867179673, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6015625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.73, "agent_stopped_0": 0.38}, "Total num played games": 63104, "Total num trained steps": 125691, "Timestamp in ms": 1702070023579, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892384629993036, "Avg loss": 0.4383137854747474, "Avg value loss": 0.11744782741880044, "Avg policy loss": 0.32086595764849335, "Total num played games": 63188, "Total num trained steps": 125696, "Timestamp in ms": 1702070025539, "logtype": "training_step"}
{"Total num played games": 63196, "Total num trained steps": 125799, "Timestamp in ms": 1702070123032, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.15234375}
{"Avg objective": 21.09375, "Games time in secs": 101.59599032253027, "Avg game time in secs": 1.6589333114097826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 63232, "Total num trained steps": 125802, "Timestamp in ms": 1702070125176, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9880549849897298, "Avg loss": 1.283395677804947, "Avg value loss": 0.9373674648231827, "Avg policy loss": 0.3460282201413065, "Total num played games": 63290, "Total num trained steps": 125824, "Timestamp in ms": 1702070135021, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990077421393585, "Avg loss": 0.5314019285142422, "Avg value loss": 0.1924065567436628, "Avg policy loss": 0.33899537404067814, "Total num played games": 63290, "Total num trained steps": 125952, "Timestamp in ms": 1702070186657, "logtype": "training_step"}
{"Avg objective": 22.859375, "Games time in secs": 112.1303312368691, "Avg game time in secs": 1.8518013772263657, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 63360, "Total num trained steps": 126075, "Timestamp in ms": 1702070237306, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9891455256847155, "Avg loss": 0.5077347094193101, "Avg value loss": 0.18213366536656395, "Avg policy loss": 0.32560104003641754, "Total num played games": 63384, "Total num trained steps": 126080, "Timestamp in ms": 1702070238985, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9911649627666288, "Avg loss": 0.7374350852333009, "Avg value loss": 0.4003284923383035, "Avg policy loss": 0.3371065923711285, "Total num played games": 63384, "Total num trained steps": 126208, "Timestamp in ms": 1702070293512, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901701323251417, "Avg loss": 0.8963901291135699, "Avg value loss": 0.5582844622258563, "Avg policy loss": 0.33810565806925297, "Total num played games": 63480, "Total num trained steps": 126336, "Timestamp in ms": 1702070344753, "logtype": "training_step"}
{"Total num played games": 63480, "Total num trained steps": 126400, "Timestamp in ms": 1702070428827, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.13671875}
{"Avg objective": 23.0, "Games time in secs": 192.9395464323461, "Avg game time in secs": 1.884401847346453, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.62, "agent_stopped_0": 0.46}, "Total num played games": 63488, "Total num trained steps": 126402, "Timestamp in ms": 1702070430246, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9892408846383742, "Avg loss": 0.8773235706612468, "Avg value loss": 0.5341360773891211, "Avg policy loss": 0.3431874930392951, "Total num played games": 63574, "Total num trained steps": 126464, "Timestamp in ms": 1702070456468, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912542863434737, "Avg loss": 0.40502021205611527, "Avg value loss": 0.08075787522830069, "Avg policy loss": 0.32426233612932265, "Total num played games": 63574, "Total num trained steps": 126592, "Timestamp in ms": 1702070507937, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 98.52156988531351, "Avg game time in secs": 1.7308250598725863, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.55}, "Total num played games": 63616, "Total num trained steps": 126641, "Timestamp in ms": 1702070528768, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990324809951624, "Avg loss": 0.8222909324103966, "Avg value loss": 0.4959874439809937, "Avg policy loss": 0.3263034967239946, "Total num played games": 63668, "Total num trained steps": 126720, "Timestamp in ms": 1702070560677, "logtype": "training_step"}
{"Avg objective": 21.0859375, "Games time in secs": 76.89314614981413, "Avg game time in secs": 1.9270566008344758, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.58}, "Total num played games": 63744, "Total num trained steps": 126830, "Timestamp in ms": 1702070605662, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893980740880148, "Avg loss": 0.645361349452287, "Avg value loss": 0.3234288730309345, "Avg policy loss": 0.3219324751989916, "Total num played games": 63762, "Total num trained steps": 126848, "Timestamp in ms": 1702070612817, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914055393494559, "Avg loss": 0.5186358743812889, "Avg value loss": 0.18805017264094204, "Avg policy loss": 0.330585700343363, "Total num played games": 63762, "Total num trained steps": 126976, "Timestamp in ms": 1702070665840, "logtype": "training_step"}
{"Total num played games": 63762, "Total num trained steps": 127000, "Timestamp in ms": 1702070719768, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.234375}
{"Ratio train steps to played games": 1.990478576797795, "Avg loss": 0.6788792470470071, "Avg value loss": 0.3599165792693384, "Avg policy loss": 0.31896265724208206, "Total num played games": 63856, "Total num trained steps": 127104, "Timestamp in ms": 1702070762379, "logtype": "training_step"}
{"Avg objective": 20.1796875, "Games time in secs": 196.05742464587092, "Avg game time in secs": 1.7297757421038114, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3359375, "Avg reasons for ending game": {"agent_stopped_more": 0.47, "played_steps": 0.51, "agent_stopped_0": 0.53}, "Total num played games": 63872, "Total num trained steps": 127204, "Timestamp in ms": 1702070801719, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895543393275996, "Avg loss": 0.7387739755213261, "Avg value loss": 0.4330409973335918, "Avg policy loss": 0.30573298200033605, "Total num played games": 63950, "Total num trained steps": 127232, "Timestamp in ms": 1702070812452, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915559030492573, "Avg loss": 0.5196381080895662, "Avg value loss": 0.19955001430935226, "Avg policy loss": 0.32008809712715447, "Total num played games": 63950, "Total num trained steps": 127360, "Timestamp in ms": 1702070864163, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 75.9284050501883, "Avg game time in secs": 1.874428463721415, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.62}, "Total num played games": 64000, "Total num trained steps": 127394, "Timestamp in ms": 1702070877648, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990631440884392, "Avg loss": 0.7385536106303334, "Avg value loss": 0.41989777894923463, "Avg policy loss": 0.3186558325542137, "Total num played games": 64044, "Total num trained steps": 127488, "Timestamp in ms": 1702070917129, "logtype": "training_step"}
{"Avg objective": 21.8125, "Games time in secs": 77.92105813324451, "Avg game time in secs": 1.8724647841008846, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.66}, "Total num played games": 64128, "Total num trained steps": 127583, "Timestamp in ms": 1702070955569, "logtype": "played_game"}
{"Total num played games": 64138, "Total num trained steps": 127600, "Timestamp in ms": 1702071002470, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.73046875}
{"Ratio train steps to played games": 1.9867978577655998, "Avg loss": 0.9361210793722421, "Avg value loss": 0.6230976292281412, "Avg policy loss": 0.3130234517157078, "Total num played games": 64232, "Total num trained steps": 127616, "Timestamp in ms": 1702071008930, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9887906339519243, "Avg loss": 0.9744443788658828, "Avg value loss": 0.614637580991257, "Avg policy loss": 0.3598067872226238, "Total num played games": 64232, "Total num trained steps": 127744, "Timestamp in ms": 1702071060321, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9907834101382489, "Avg loss": 0.3965040813200176, "Avg value loss": 0.07475921625155024, "Avg policy loss": 0.3217448622453958, "Total num played games": 64232, "Total num trained steps": 127872, "Timestamp in ms": 1702071111152, "logtype": "training_step"}
{"Avg objective": 22.5234375, "Games time in secs": 188.74293787032366, "Avg game time in secs": 1.9542137574462686, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4609375, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 64256, "Total num trained steps": 127957, "Timestamp in ms": 1702071144312, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897404010570496, "Avg loss": 0.7196055925451219, "Avg value loss": 0.40347850279067643, "Avg policy loss": 0.31612707884050906, "Total num played games": 64330, "Total num trained steps": 128000, "Timestamp in ms": 1702071161765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917301414581066, "Avg loss": 0.4528114425484091, "Avg value loss": 0.13187652730266564, "Avg policy loss": 0.3209349194075912, "Total num played games": 64330, "Total num trained steps": 128128, "Timestamp in ms": 1702071213342, "logtype": "training_step"}
{"Avg objective": 22.5390625, "Games time in secs": 79.50999973714352, "Avg game time in secs": 1.8989004968607333, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 64384, "Total num trained steps": 128154, "Timestamp in ms": 1702071223822, "logtype": "played_game"}
{"Total num played games": 64424, "Total num trained steps": 128203, "Timestamp in ms": 1702071318622, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.203125}
{"Avg objective": 20.3359375, "Games time in secs": 97.97278794273734, "Avg game time in secs": 1.8416185803362168, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.67, "agent_stopped_0": 0.43}, "Total num played games": 64512, "Total num trained steps": 128210, "Timestamp in ms": 1702071321795, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9879103505998326, "Avg loss": 1.2070059177931398, "Avg value loss": 0.8618345696013421, "Avg policy loss": 0.3451713433023542, "Total num played games": 64518, "Total num trained steps": 128256, "Timestamp in ms": 1702071341109, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989894293065501, "Avg loss": 0.4546167296357453, "Avg value loss": 0.12243560151546262, "Avg policy loss": 0.3321811273926869, "Total num played games": 64518, "Total num trained steps": 128384, "Timestamp in ms": 1702071392462, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918782355311695, "Avg loss": 0.36632117233239114, "Avg value loss": 0.05781718439538963, "Avg policy loss": 0.3085039868019521, "Total num played games": 64518, "Total num trained steps": 128512, "Timestamp in ms": 1702071444765, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909614313130688, "Avg loss": 0.8347275617998093, "Avg value loss": 0.5019272009376436, "Avg policy loss": 0.33280036109499633, "Total num played games": 64612, "Total num trained steps": 128640, "Timestamp in ms": 1702071495621, "logtype": "training_step"}
{"Avg objective": 23.0078125, "Games time in secs": 204.39881247282028, "Avg game time in secs": 1.7024012849433348, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.52, "agent_stopped_0": 0.52}, "Total num played games": 64640, "Total num trained steps": 128716, "Timestamp in ms": 1702071526194, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900472908231075, "Avg loss": 0.8101940609049052, "Avg value loss": 0.4924182100512553, "Avg policy loss": 0.31777586159296334, "Total num played games": 64706, "Total num trained steps": 128768, "Timestamp in ms": 1702071546568, "logtype": "training_step"}
{"Total num played games": 64706, "Total num trained steps": 128806, "Timestamp in ms": 1702071630341, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.66015625}
{"Avg objective": 21.9453125, "Games time in secs": 106.44761931151152, "Avg game time in secs": 1.7120255538902711, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.5}, "Total num played games": 64768, "Total num trained steps": 128809, "Timestamp in ms": 1702071632641, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989135802469136, "Avg loss": 0.7404370291624218, "Avg value loss": 0.40307196212233976, "Avg policy loss": 0.3373650750145316, "Total num played games": 64800, "Total num trained steps": 128896, "Timestamp in ms": 1702071667588, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991111111111111, "Avg loss": 0.3931033757980913, "Avg value loss": 0.07553551928140223, "Avg policy loss": 0.3175678557017818, "Total num played games": 64800, "Total num trained steps": 129024, "Timestamp in ms": 1702071718774, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901994021018892, "Avg loss": 0.738046049606055, "Avg value loss": 0.4174251322983764, "Avg policy loss": 0.32062091666739434, "Total num played games": 64894, "Total num trained steps": 129152, "Timestamp in ms": 1702071770142, "logtype": "training_step"}
{"Avg objective": 22.4609375, "Games time in secs": 188.91228072717786, "Avg game time in secs": 1.8932647491747048, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.61, "agent_stopped_0": 0.45}, "Total num played games": 64896, "Total num trained steps": 129277, "Timestamp in ms": 1702071821554, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920490616043638, "Avg loss": 0.40353981172665954, "Avg value loss": 0.09112738387193531, "Avg policy loss": 0.3124124262249097, "Total num played games": 64896, "Total num trained steps": 129280, "Timestamp in ms": 1702071822241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991259924909214, "Avg loss": 0.8488200719002634, "Avg value loss": 0.512373913807096, "Avg policy loss": 0.3364461555611342, "Total num played games": 64988, "Total num trained steps": 129408, "Timestamp in ms": 1702071872560, "logtype": "training_step"}
{"Total num played games": 64988, "Total num trained steps": 129410, "Timestamp in ms": 1702071958618, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.6796875}
{"Avg objective": 21.296875, "Games time in secs": 139.08356228098273, "Avg game time in secs": 1.7858946130145341, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.66}, "Total num played games": 65024, "Total num trained steps": 129413, "Timestamp in ms": 1702071960638, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903506345840631, "Avg loss": 0.7979885537642986, "Avg value loss": 0.46116083953529596, "Avg policy loss": 0.3368277276167646, "Total num played games": 65082, "Total num trained steps": 129536, "Timestamp in ms": 1702072012085, "logtype": "training_step"}
{"Avg objective": 21.6875, "Games time in secs": 100.58411465957761, "Avg game time in secs": 1.7900210320658516, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 65152, "Total num trained steps": 129658, "Timestamp in ms": 1702072061222, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894439671044557, "Avg loss": 0.4972587259253487, "Avg value loss": 0.18479473615298048, "Avg policy loss": 0.312463988782838, "Total num played games": 65176, "Total num trained steps": 129664, "Timestamp in ms": 1702072063533, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991392537130232, "Avg loss": 0.8655721275135875, "Avg value loss": 0.5416642734489869, "Avg policy loss": 0.32390785904135555, "Total num played games": 65176, "Total num trained steps": 129792, "Timestamp in ms": 1702072116524, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904400049025617, "Avg loss": 0.7515699295327067, "Avg value loss": 0.4273506286263, "Avg policy loss": 0.3242193035548553, "Total num played games": 65272, "Total num trained steps": 129920, "Timestamp in ms": 1702072169564, "logtype": "training_step"}
{"Total num played games": 65272, "Total num trained steps": 130011, "Timestamp in ms": 1702072268952, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.06640625}
{"Avg objective": 22.53125, "Games time in secs": 209.28888342902064, "Avg game time in secs": 2.0391965839953627, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.7, "agent_stopped_0": 0.4}, "Total num played games": 65280, "Total num trained steps": 130014, "Timestamp in ms": 1702072270511, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9895358443227367, "Avg loss": 0.8436254151165485, "Avg value loss": 0.5148389541136567, "Avg policy loss": 0.3287864498561248, "Total num played games": 65366, "Total num trained steps": 130048, "Timestamp in ms": 1702072283838, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914940488939203, "Avg loss": 0.4749156082980335, "Avg value loss": 0.13451576215447858, "Avg policy loss": 0.3403998446883634, "Total num played games": 65366, "Total num trained steps": 130176, "Timestamp in ms": 1702072333935, "logtype": "training_step"}
{"Avg objective": 21.65625, "Games time in secs": 83.24262729659677, "Avg game time in secs": 1.7452298190328293, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.53, "agent_stopped_more": 0.47, "played_steps": 0.51}, "Total num played games": 65408, "Total num trained steps": 130225, "Timestamp in ms": 1702072353754, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990574396578063, "Avg loss": 0.7094762986525893, "Avg value loss": 0.3737904778972734, "Avg policy loss": 0.33568582660518587, "Total num played games": 65460, "Total num trained steps": 130304, "Timestamp in ms": 1702072386705, "logtype": "training_step"}
{"Avg objective": 21.5703125, "Games time in secs": 78.35372381657362, "Avg game time in secs": 1.9188507396320347, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4765625, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.66}, "Total num played games": 65536, "Total num trained steps": 130415, "Timestamp in ms": 1702072432107, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896271889682104, "Avg loss": 0.6551473264116794, "Avg value loss": 0.32644328588503413, "Avg policy loss": 0.32870403316337615, "Total num played games": 65556, "Total num trained steps": 130432, "Timestamp in ms": 1702072439333, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915797181036061, "Avg loss": 0.5484255226328969, "Avg value loss": 0.21208943534293212, "Avg policy loss": 0.3363360887160525, "Total num played games": 65556, "Total num trained steps": 130560, "Timestamp in ms": 1702072491557, "logtype": "training_step"}
{"Total num played games": 65650, "Total num trained steps": 130615, "Timestamp in ms": 1702072591684, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.86328125}
{"Avg objective": 21.296875, "Games time in secs": 161.2508166693151, "Avg game time in secs": 1.9984880014671944, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.71875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 65664, "Total num trained steps": 130617, "Timestamp in ms": 1702072593358, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9878315891944511, "Avg loss": 1.2866929441224784, "Avg value loss": 0.9343492759508081, "Avg policy loss": 0.3523436627583578, "Total num played games": 65744, "Total num trained steps": 130688, "Timestamp in ms": 1702072622885, "logtype": "training_step"}
{"Ratio train steps to played games": 1.989778534923339, "Avg loss": 0.4485563621856272, "Avg value loss": 0.11571911157807335, "Avg policy loss": 0.3328372498508543, "Total num played games": 65744, "Total num trained steps": 130816, "Timestamp in ms": 1702072674018, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917254806522269, "Avg loss": 0.3726439403835684, "Avg value loss": 0.0579799230908975, "Avg policy loss": 0.31466401764191687, "Total num played games": 65744, "Total num trained steps": 130944, "Timestamp in ms": 1702072724672, "logtype": "training_step"}
{"Avg objective": 21.296875, "Games time in secs": 145.70224944502115, "Avg game time in secs": 1.7894224259653129, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 65792, "Total num trained steps": 130982, "Timestamp in ms": 1702072739061, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908107779701691, "Avg loss": 0.693810461089015, "Avg value loss": 0.36922777132713236, "Avg policy loss": 0.32458268746268004, "Total num played games": 65838, "Total num trained steps": 131072, "Timestamp in ms": 1702072775609, "logtype": "training_step"}
{"Avg objective": 21.28125, "Games time in secs": 75.68118616938591, "Avg game time in secs": 1.9327701098809484, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.61}, "Total num played games": 65920, "Total num trained steps": 131170, "Timestamp in ms": 1702072814742, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898686565353232, "Avg loss": 0.6751246065832675, "Avg value loss": 0.3567504310340155, "Avg policy loss": 0.31837418011855334, "Total num played games": 65934, "Total num trained steps": 131200, "Timestamp in ms": 1702072826442, "logtype": "training_step"}
{"Total num played games": 65934, "Total num trained steps": 131219, "Timestamp in ms": 1702072909349, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.484375}
{"Ratio train steps to played games": 1.9889592294178227, "Avg loss": 0.8905629406217486, "Avg value loss": 0.5502032107906416, "Avg policy loss": 0.3403597373981029, "Total num played games": 66028, "Total num trained steps": 131328, "Timestamp in ms": 1702072954464, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9909129460228994, "Avg loss": 0.37817260646261275, "Avg value loss": 0.07049555634148419, "Avg policy loss": 0.3076770472107455, "Total num played games": 66028, "Total num trained steps": 131456, "Timestamp in ms": 1702073005142, "logtype": "training_step"}
{"Avg objective": 21.1640625, "Games time in secs": 227.71091241389513, "Avg game time in secs": 1.816916242154548, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.66, "agent_stopped_0": 0.38}, "Total num played games": 66048, "Total num trained steps": 131549, "Timestamp in ms": 1702073042453, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900184507425667, "Avg loss": 0.8200320661999285, "Avg value loss": 0.5064941898745019, "Avg policy loss": 0.31353788590058684, "Total num played games": 66122, "Total num trained steps": 131584, "Timestamp in ms": 1702073057264, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919542663561296, "Avg loss": 0.45341673982329667, "Avg value loss": 0.14227134859538637, "Avg policy loss": 0.3111453887540847, "Total num played games": 66122, "Total num trained steps": 131712, "Timestamp in ms": 1702073110001, "logtype": "training_step"}
{"Avg objective": 21.125, "Games time in secs": 78.69938234239817, "Avg game time in secs": 1.8091204444353934, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.54, "agent_stopped_0": 0.49}, "Total num played games": 66176, "Total num trained steps": 131737, "Timestamp in ms": 1702073121153, "logtype": "played_game"}
{"Total num played games": 66216, "Total num trained steps": 131823, "Timestamp in ms": 1702073251414, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.90625}
{"Avg objective": 22.0234375, "Games time in secs": 135.12878315523267, "Avg game time in secs": 1.9930554224993102, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.34375, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 66304, "Total num trained steps": 131834, "Timestamp in ms": 1702073256281, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988237068315488, "Avg loss": 1.1263912443537265, "Avg value loss": 0.7984531916154083, "Avg policy loss": 0.327938067028299, "Total num played games": 66310, "Total num trained steps": 131840, "Timestamp in ms": 1702073258843, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901673955662795, "Avg loss": 0.6235878090374172, "Avg value loss": 0.2977077544783242, "Avg policy loss": 0.32588005042634904, "Total num played games": 66310, "Total num trained steps": 131968, "Timestamp in ms": 1702073310509, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920977228170713, "Avg loss": 0.36034031002782285, "Avg value loss": 0.05628514973795973, "Avg policy loss": 0.30405516154132783, "Total num played games": 66310, "Total num trained steps": 132096, "Timestamp in ms": 1702073363975, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991205349075357, "Avg loss": 0.9456772396806628, "Avg value loss": 0.6208113933971617, "Avg policy loss": 0.3248658492229879, "Total num played games": 66404, "Total num trained steps": 132224, "Timestamp in ms": 1702073416679, "logtype": "training_step"}
{"Avg objective": 22.2890625, "Games time in secs": 193.62136693298817, "Avg game time in secs": 1.6871037454984616, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.4, "played_steps": 0.48, "agent_stopped_0": 0.6}, "Total num played games": 66432, "Total num trained steps": 132301, "Timestamp in ms": 1702073449903, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903154982104725, "Avg loss": 0.6555613509844989, "Avg value loss": 0.34476856017136015, "Avg policy loss": 0.3107927879318595, "Total num played games": 66498, "Total num trained steps": 132352, "Timestamp in ms": 1702073471637, "logtype": "training_step"}
{"Total num played games": 66498, "Total num trained steps": 132423, "Timestamp in ms": 1702073573992, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.08203125}
{"Avg objective": 22.1640625, "Games time in secs": 126.6426794603467, "Avg game time in secs": 1.899850922753103, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.63}, "Total num played games": 66560, "Total num trained steps": 132427, "Timestamp in ms": 1702073576546, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894281595386833, "Avg loss": 0.714914410142228, "Avg value loss": 0.3979154588887468, "Avg policy loss": 0.3169989576563239, "Total num played games": 66592, "Total num trained steps": 132480, "Timestamp in ms": 1702073598004, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913503123498317, "Avg loss": 0.36874528927728534, "Avg value loss": 0.07217735872836784, "Avg policy loss": 0.29656792944297194, "Total num played games": 66592, "Total num trained steps": 132608, "Timestamp in ms": 1702073650715, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904627657979186, "Avg loss": 0.7479803676251322, "Avg value loss": 0.4482364993018564, "Avg policy loss": 0.29974387225229293, "Total num played games": 66686, "Total num trained steps": 132736, "Timestamp in ms": 1702073703097, "logtype": "training_step"}
{"Avg objective": 22.0078125, "Games time in secs": 178.2641353160143, "Avg game time in secs": 2.0294276954082306, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3984375, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.71, "agent_stopped_0": 0.38}, "Total num played games": 66688, "Total num trained steps": 132862, "Timestamp in ms": 1702073754810, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920834832673624, "Avg loss": 0.3844692336861044, "Avg value loss": 0.08266146678943187, "Avg policy loss": 0.30180776573251933, "Total num played games": 66696, "Total num trained steps": 132864, "Timestamp in ms": 1702073755504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914198436704502, "Avg loss": 1.1231835596263409, "Avg value loss": 0.8101526912359986, "Avg policy loss": 0.3130308525869623, "Total num played games": 66782, "Total num trained steps": 132992, "Timestamp in ms": 1702073806680, "logtype": "training_step"}
{"Total num played games": 66782, "Total num trained steps": 133025, "Timestamp in ms": 1702073894454, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.625}
{"Avg objective": 22.625, "Games time in secs": 141.66385700553656, "Avg game time in secs": 1.62349949075724, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.55, "agent_stopped_more": 0.45, "played_steps": 0.48}, "Total num played games": 66816, "Total num trained steps": 133029, "Timestamp in ms": 1702073896474, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990549674023566, "Avg loss": 1.00244321487844, "Avg value loss": 0.6917280211928301, "Avg policy loss": 0.310715188505128, "Total num played games": 66876, "Total num trained steps": 133120, "Timestamp in ms": 1702073934422, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 89.29139268770814, "Avg game time in secs": 1.8596676485030912, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.62}, "Total num played games": 66944, "Total num trained steps": 133246, "Timestamp in ms": 1702073985766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899047220811803, "Avg loss": 0.3770738863386214, "Avg value loss": 0.09873754566069692, "Avg policy loss": 0.27833634393755347, "Total num played games": 66960, "Total num trained steps": 133248, "Timestamp in ms": 1702073986373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991578318650142, "Avg loss": 0.7023178809322417, "Avg value loss": 0.40932912248536013, "Avg policy loss": 0.2929887573700398, "Total num played games": 66970, "Total num trained steps": 133376, "Timestamp in ms": 1702074038953, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906954550876774, "Avg loss": 0.6557512296130881, "Avg value loss": 0.37041810585651547, "Avg policy loss": 0.2853331182850525, "Total num played games": 67064, "Total num trained steps": 133504, "Timestamp in ms": 1702074092851, "logtype": "training_step"}
{"Avg objective": 21.0, "Games time in secs": 154.60374685004354, "Avg game time in secs": 1.9164023221237585, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.515625, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.62, "agent_stopped_0": 0.44}, "Total num played games": 67072, "Total num trained steps": 133620, "Timestamp in ms": 1702074140369, "logtype": "played_game"}
{"Total num played games": 67158, "Total num trained steps": 133627, "Timestamp in ms": 1702074279440, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.41796875}
{"Ratio train steps to played games": 1.9888081914513633, "Avg loss": 0.549766841577366, "Avg value loss": 0.2742625081446022, "Avg policy loss": 0.27550433948636055, "Total num played games": 67188, "Total num trained steps": 133632, "Timestamp in ms": 1702074281551, "logtype": "training_step"}
{"Avg objective": 22.7890625, "Games time in secs": 141.26197568327188, "Avg game time in secs": 1.793227847025264, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.53, "agent_stopped_0": 0.52}, "Total num played games": 67200, "Total num trained steps": 133632, "Timestamp in ms": 1702074281631, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988937131981205, "Avg loss": 1.1022586347535253, "Avg value loss": 0.7895194902666844, "Avg policy loss": 0.31273914652410895, "Total num played games": 67252, "Total num trained steps": 133760, "Timestamp in ms": 1702074334708, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9908404211027182, "Avg loss": 0.3507135647814721, "Avg value loss": 0.06517705164151266, "Avg policy loss": 0.28553651343099773, "Total num played games": 67252, "Total num trained steps": 133888, "Timestamp in ms": 1702074387298, "logtype": "training_step"}
{"Avg objective": 21.9296875, "Games time in secs": 151.0638042986393, "Avg game time in secs": 1.8257594372553285, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.59, "agent_stopped_0": 0.45}, "Total num played games": 67328, "Total num trained steps": 133998, "Timestamp in ms": 1702074432695, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899622843227511, "Avg loss": 0.6478807586245239, "Avg value loss": 0.37563679480808787, "Avg policy loss": 0.2722439677454531, "Total num played games": 67346, "Total num trained steps": 134016, "Timestamp in ms": 1702074439331, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918629168770232, "Avg loss": 0.5492711910046637, "Avg value loss": 0.2700609690800775, "Avg policy loss": 0.27921021939255297, "Total num played games": 67346, "Total num trained steps": 134144, "Timestamp in ms": 1702074490554, "logtype": "training_step"}
{"Total num played games": 67440, "Total num trained steps": 134227, "Timestamp in ms": 1702074593217, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.4453125}
{"Avg objective": 22.28125, "Games time in secs": 162.2878192514181, "Avg game time in secs": 1.71938490823959, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.43, "played_steps": 0.47, "agent_stopped_0": 0.57}, "Total num played games": 67456, "Total num trained steps": 134230, "Timestamp in ms": 1702074594983, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882133443894927, "Avg loss": 1.1923222545301542, "Avg value loss": 0.90766838597483, "Avg policy loss": 0.28465388785116374, "Total num played games": 67534, "Total num trained steps": 134272, "Timestamp in ms": 1702074612510, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901086859952024, "Avg loss": 0.44524947134777904, "Avg value loss": 0.16347170009976253, "Avg policy loss": 0.28177777014207095, "Total num played games": 67534, "Total num trained steps": 134400, "Timestamp in ms": 1702074664147, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992004027600912, "Avg loss": 0.33691173139959574, "Avg value loss": 0.07093389364308678, "Avg policy loss": 0.2659778370289132, "Total num played games": 67534, "Total num trained steps": 134528, "Timestamp in ms": 1702074717215, "logtype": "training_step"}
{"Avg objective": 21.6640625, "Games time in secs": 135.31615899130702, "Avg game time in secs": 1.751997964514885, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.55, "agent_stopped_0": 0.51}, "Total num played games": 67584, "Total num trained steps": 134561, "Timestamp in ms": 1702074730300, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911279351747797, "Avg loss": 0.6429842330981046, "Avg value loss": 0.3622250883054221, "Avg policy loss": 0.2807591495802626, "Total num played games": 67628, "Total num trained steps": 134656, "Timestamp in ms": 1702074770869, "logtype": "training_step"}
{"Avg objective": 20.875, "Games time in secs": 79.9561717286706, "Avg game time in secs": 1.8493605557305273, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.66, "agent_stopped_0": 0.45}, "Total num played games": 67712, "Total num trained steps": 134752, "Timestamp in ms": 1702074810256, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9902542748294498, "Avg loss": 0.5801234432728961, "Avg value loss": 0.3062637672992423, "Avg policy loss": 0.2738596700364724, "Total num played games": 67722, "Total num trained steps": 134784, "Timestamp in ms": 1702074822842, "logtype": "training_step"}
{"Total num played games": 67722, "Total num trained steps": 134831, "Timestamp in ms": 1702074910562, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.00390625}
{"Ratio train steps to played games": 1.9893830364515748, "Avg loss": 0.7921689900103956, "Avg value loss": 0.4899466580245644, "Avg policy loss": 0.30222233396489173, "Total num played games": 67816, "Total num trained steps": 134912, "Timestamp in ms": 1702074944802, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912704966379615, "Avg loss": 0.3550310640130192, "Avg value loss": 0.06690119023551233, "Avg policy loss": 0.2881298733409494, "Total num played games": 67816, "Total num trained steps": 135040, "Timestamp in ms": 1702074998168, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 223.36514849588275, "Avg game time in secs": 1.6631054539175238, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.45, "played_steps": 0.5, "agent_stopped_0": 0.55}, "Total num played games": 67840, "Total num trained steps": 135124, "Timestamp in ms": 1702075033621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903843322043882, "Avg loss": 0.6533827785169706, "Avg value loss": 0.3707084466586821, "Avg policy loss": 0.2826743341283873, "Total num played games": 67910, "Total num trained steps": 135168, "Timestamp in ms": 1702075051349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922839051686054, "Avg loss": 0.41089011216536164, "Avg value loss": 0.12155005705426447, "Avg policy loss": 0.2893400521716103, "Total num played games": 67910, "Total num trained steps": 135296, "Timestamp in ms": 1702075104576, "logtype": "training_step"}
{"Avg objective": 20.796875, "Games time in secs": 77.99947734549642, "Avg game time in secs": 1.7073373682214878, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.49, "agent_stopped_0": 0.52}, "Total num played games": 67968, "Total num trained steps": 135313, "Timestamp in ms": 1702075111621, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914122698664785, "Avg loss": 0.7225599985104054, "Avg value loss": 0.4288370438735001, "Avg policy loss": 0.29372295388020575, "Total num played games": 68004, "Total num trained steps": 135424, "Timestamp in ms": 1702075156412, "logtype": "training_step"}
{"Total num played games": 68004, "Total num trained steps": 135432, "Timestamp in ms": 1702075219966, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 25.5625}
{"Avg objective": 22.84375, "Games time in secs": 112.04549737647176, "Avg game time in secs": 1.869671133783413, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.64, "agent_stopped_0": 0.41}, "Total num played games": 68096, "Total num trained steps": 135440, "Timestamp in ms": 1702075223666, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905430409116274, "Avg loss": 0.8865448920987546, "Avg value loss": 0.5943386346916668, "Avg policy loss": 0.2922062606085092, "Total num played games": 68098, "Total num trained steps": 135552, "Timestamp in ms": 1702075268550, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924226849540367, "Avg loss": 0.33287599741015583, "Avg value loss": 0.06168075880850665, "Avg policy loss": 0.27119523799046874, "Total num played games": 68098, "Total num trained steps": 135680, "Timestamp in ms": 1702075319684, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991553261379634, "Avg loss": 0.6716483496129513, "Avg value loss": 0.3859834054892417, "Avg policy loss": 0.2856649538734928, "Total num played games": 68192, "Total num trained steps": 135808, "Timestamp in ms": 1702075372818, "logtype": "training_step"}
{"Avg objective": 21.265625, "Games time in secs": 176.57222340628505, "Avg game time in secs": 1.734437031293055, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.421875, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.59, "agent_stopped_0": 0.46}, "Total num played games": 68224, "Total num trained steps": 135876, "Timestamp in ms": 1702075400239, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906862314383622, "Avg loss": 0.7035432250704616, "Avg value loss": 0.41851897405285854, "Avg policy loss": 0.28502424200996757, "Total num played games": 68286, "Total num trained steps": 135936, "Timestamp in ms": 1702075424920, "logtype": "training_step"}
{"Total num played games": 68286, "Total num trained steps": 136034, "Timestamp in ms": 1702075500541, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.3046875}
{"Avg objective": 22.453125, "Games time in secs": 102.87486658245325, "Avg game time in secs": 1.7563304914510809, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 68352, "Total num trained steps": 136039, "Timestamp in ms": 1702075503114, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9898069610997369, "Avg loss": 0.7470416447613388, "Avg value loss": 0.4661550114687998, "Avg policy loss": 0.28088662796653807, "Total num played games": 68380, "Total num trained steps": 136064, "Timestamp in ms": 1702075513553, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916934776250366, "Avg loss": 0.45012326864525676, "Avg value loss": 0.15137522638542578, "Avg policy loss": 0.298748038476333, "Total num played games": 68380, "Total num trained steps": 136192, "Timestamp in ms": 1702075567117, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990828635686538, "Avg loss": 0.72813127678819, "Avg value loss": 0.41981433487671893, "Avg policy loss": 0.30831694474909455, "Total num played games": 68474, "Total num trained steps": 136320, "Timestamp in ms": 1702075617296, "logtype": "training_step"}
{"Avg objective": 22.5234375, "Games time in secs": 162.6935869678855, "Avg game time in secs": 1.9355153801152483, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3671875, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.7, "agent_stopped_0": 0.41}, "Total num played games": 68480, "Total num trained steps": 136439, "Timestamp in ms": 1702075665807, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989951580912379, "Avg loss": 0.5785185965942219, "Avg value loss": 0.28418283100472763, "Avg policy loss": 0.2943357598269358, "Total num played games": 68568, "Total num trained steps": 136448, "Timestamp in ms": 1702075669430, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918329249795823, "Avg loss": 1.0061849115882069, "Avg value loss": 0.6924092113331426, "Avg policy loss": 0.3137757075019181, "Total num played games": 68568, "Total num trained steps": 136576, "Timestamp in ms": 1702075720268, "logtype": "training_step"}
{"Avg objective": 23.3125, "Games time in secs": 75.80975037068129, "Avg game time in secs": 1.6470697435433976, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.49}, "Total num played games": 68608, "Total num trained steps": 136629, "Timestamp in ms": 1702075741617, "logtype": "played_game"}
{"Total num played games": 68662, "Total num trained steps": 136638, "Timestamp in ms": 1702075822090, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.63671875}
{"Avg objective": 21.2578125, "Games time in secs": 83.30312808603048, "Avg game time in secs": 1.7995828626735602, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 68736, "Total num trained steps": 136643, "Timestamp in ms": 1702075824921, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9882482983303276, "Avg loss": 1.4131980640813708, "Avg value loss": 1.0894859993713908, "Avg policy loss": 0.32371206826064736, "Total num played games": 68756, "Total num trained steps": 136704, "Timestamp in ms": 1702075850362, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9901099540403746, "Avg loss": 0.444198529003188, "Avg value loss": 0.1259465838666074, "Avg policy loss": 0.318251941469498, "Total num played games": 68756, "Total num trained steps": 136832, "Timestamp in ms": 1702075902940, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919716097504219, "Avg loss": 0.3568003298714757, "Avg value loss": 0.06033179417136125, "Avg policy loss": 0.2964685370679945, "Total num played games": 68756, "Total num trained steps": 136960, "Timestamp in ms": 1702075955952, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991111111111111, "Avg loss": 0.6265724992845207, "Avg value loss": 0.31490177000523545, "Avg policy loss": 0.3116707281442359, "Total num played games": 68850, "Total num trained steps": 137088, "Timestamp in ms": 1702076010228, "logtype": "training_step"}
{"Avg objective": 21.953125, "Games time in secs": 228.62103575095534, "Avg game time in secs": 1.8682950531074312, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.57, "agent_stopped_0": 0.5}, "Total num played games": 68864, "Total num trained steps": 137191, "Timestamp in ms": 1702076053542, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990252958923184, "Avg loss": 0.6970204981043935, "Avg value loss": 0.38643240893725306, "Avg policy loss": 0.3105880847433582, "Total num played games": 68944, "Total num trained steps": 137216, "Timestamp in ms": 1702076063819, "logtype": "training_step"}
{"Total num played games": 68944, "Total num trained steps": 137239, "Timestamp in ms": 1702076134426, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.92578125}
{"Avg objective": 21.9765625, "Games time in secs": 83.1036982499063, "Avg game time in secs": 1.7335629079607315, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.56}, "Total num played games": 68992, "Total num trained steps": 137243, "Timestamp in ms": 1702076136646, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9893971436020743, "Avg loss": 0.8374076317995787, "Avg value loss": 0.4979595039621927, "Avg policy loss": 0.3394481323193759, "Total num played games": 69038, "Total num trained steps": 137344, "Timestamp in ms": 1702076180146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912511949940612, "Avg loss": 0.3780695123132318, "Avg value loss": 0.07323831360554323, "Avg policy loss": 0.3048312009777874, "Total num played games": 69038, "Total num trained steps": 137472, "Timestamp in ms": 1702076232477, "logtype": "training_step"}
{"Avg objective": 21.6484375, "Games time in secs": 136.53263501822948, "Avg game time in secs": 1.8471446852490772, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.62}, "Total num played games": 69120, "Total num trained steps": 137571, "Timestamp in ms": 1702076273178, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9903951860209455, "Avg loss": 0.611926339333877, "Avg value loss": 0.31989976397017017, "Avg policy loss": 0.2920265740249306, "Total num played games": 69132, "Total num trained steps": 137600, "Timestamp in ms": 1702076284863, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922467164265463, "Avg loss": 0.422769048018381, "Avg value loss": 0.11566413586842827, "Avg policy loss": 0.3071049068821594, "Total num played games": 69132, "Total num trained steps": 137728, "Timestamp in ms": 1702076337852, "logtype": "training_step"}
{"Total num played games": 69226, "Total num trained steps": 137843, "Timestamp in ms": 1702076438734, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.27734375}
{"Avg objective": 21.6640625, "Games time in secs": 167.4713186249137, "Avg game time in secs": 1.667856305546593, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_0": 0.52, "agent_stopped_more": 0.48, "played_steps": 0.53}, "Total num played games": 69248, "Total num trained steps": 137847, "Timestamp in ms": 1702076440650, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9887475114688826, "Avg loss": 0.8977800835855305, "Avg value loss": 0.5952968297642656, "Avg policy loss": 0.3024832517839968, "Total num played games": 69318, "Total num trained steps": 137856, "Timestamp in ms": 1702076444484, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990536641661858, "Avg loss": 0.5819509646389633, "Avg value loss": 0.28884366949205287, "Avg policy loss": 0.2931072920328006, "Total num played games": 69320, "Total num trained steps": 137984, "Timestamp in ms": 1702076498175, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923831506058858, "Avg loss": 0.33461785316467285, "Avg value loss": 0.053858256796956994, "Avg policy loss": 0.28075959510169923, "Total num played games": 69320, "Total num trained steps": 138112, "Timestamp in ms": 1702076548810, "logtype": "training_step"}
{"Avg objective": 22.0, "Games time in secs": 116.53245255723596, "Avg game time in secs": 1.7493864883726928, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 69376, "Total num trained steps": 138134, "Timestamp in ms": 1702076557182, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9914717068111099, "Avg loss": 0.732755282195285, "Avg value loss": 0.42298561820643954, "Avg policy loss": 0.3097696608165279, "Total num played games": 69416, "Total num trained steps": 138240, "Timestamp in ms": 1702076599121, "logtype": "training_step"}
{"Avg objective": 22.0234375, "Games time in secs": 78.28223515674472, "Avg game time in secs": 1.8711362250032835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.68, "agent_stopped_0": 0.41}, "Total num played games": 69504, "Total num trained steps": 138328, "Timestamp in ms": 1702076635465, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990620054668393, "Avg loss": 0.8651802903041244, "Avg value loss": 0.556301943201106, "Avg policy loss": 0.3088783441344276, "Total num played games": 69510, "Total num trained steps": 138368, "Timestamp in ms": 1702076651274, "logtype": "training_step"}
{"Total num played games": 69510, "Total num trained steps": 138443, "Timestamp in ms": 1702076745905, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.40625}
{"Ratio train steps to played games": 1.9897707028331706, "Avg loss": 0.8943247327115387, "Avg value loss": 0.5781805838923901, "Avg policy loss": 0.31614414730574936, "Total num played games": 69604, "Total num trained steps": 138496, "Timestamp in ms": 1702076769146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915953106143325, "Avg loss": 0.42556679202243686, "Avg value loss": 0.1094651761231944, "Avg policy loss": 0.31610161380376667, "Total num played games": 69604, "Total num trained steps": 138624, "Timestamp in ms": 1702076822783, "logtype": "training_step"}
{"Avg objective": 21.2890625, "Games time in secs": 218.46654849126935, "Avg game time in secs": 1.7138494935643394, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.25, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.57, "agent_stopped_0": 0.48}, "Total num played games": 69632, "Total num trained steps": 138700, "Timestamp in ms": 1702076853931, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907601365892853, "Avg loss": 0.6913349401438609, "Avg value loss": 0.3788907766866032, "Avg policy loss": 0.31244417023845017, "Total num played games": 69698, "Total num trained steps": 138752, "Timestamp in ms": 1702076875275, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925966311802348, "Avg loss": 0.3829981128219515, "Avg value loss": 0.07748962604091503, "Avg policy loss": 0.3055084836669266, "Total num played games": 69698, "Total num trained steps": 138880, "Timestamp in ms": 1702076928056, "logtype": "training_step"}
{"Avg objective": 21.4453125, "Games time in secs": 78.09459649026394, "Avg game time in secs": 1.745698895159876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.56}, "Total num played games": 69760, "Total num trained steps": 138890, "Timestamp in ms": 1702076932026, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917469050894085, "Avg loss": 0.6382297289092094, "Avg value loss": 0.3235458623676095, "Avg policy loss": 0.31468387227505445, "Total num played games": 69792, "Total num trained steps": 139008, "Timestamp in ms": 1702076979791, "logtype": "training_step"}
{"Total num played games": 69792, "Total num trained steps": 139046, "Timestamp in ms": 1702077065039, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.4921875}
{"Ratio train steps to played games": 1.9908994648427438, "Avg loss": 0.8012319405097514, "Avg value loss": 0.48257416050182655, "Avg policy loss": 0.31865779170766473, "Total num played games": 69886, "Total num trained steps": 139136, "Timestamp in ms": 1702077101290, "logtype": "training_step"}
{"Avg objective": 20.515625, "Games time in secs": 221.49947848170996, "Avg game time in secs": 1.8610379270103294, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 69888, "Total num trained steps": 139261, "Timestamp in ms": 1702077153526, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924459196520545, "Avg loss": 0.3698635441251099, "Avg value loss": 0.06957966930349357, "Avg policy loss": 0.30028387845959514, "Total num played games": 69896, "Total num trained steps": 139264, "Timestamp in ms": 1702077154361, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918833952557873, "Avg loss": 0.7019915403798223, "Avg value loss": 0.38991248479578644, "Avg policy loss": 0.3120790548855439, "Total num played games": 69980, "Total num trained steps": 139392, "Timestamp in ms": 1702077207871, "logtype": "training_step"}
{"Avg objective": 21.78125, "Games time in secs": 79.87727753445506, "Avg game time in secs": 1.6529329125769436, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0625, "Avg reasons for ending game": {"agent_stopped_0": 0.54, "agent_stopped_more": 0.46, "played_steps": 0.52}, "Total num played games": 70016, "Total num trained steps": 139453, "Timestamp in ms": 1702077233403, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910380454947627, "Avg loss": 0.7857595074456185, "Avg value loss": 0.47738085928722285, "Avg policy loss": 0.3083786544157192, "Total num played games": 70074, "Total num trained steps": 139520, "Timestamp in ms": 1702077261564, "logtype": "training_step"}
{"Avg objective": 22.4921875, "Games time in secs": 78.93633253127337, "Avg game time in secs": 1.820762273069704, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.39, "agent_stopped_more": 0.61, "played_steps": 0.65}, "Total num played games": 70144, "Total num trained steps": 139642, "Timestamp in ms": 1702077312340, "logtype": "played_game"}
{"Total num played games": 70168, "Total num trained steps": 139646, "Timestamp in ms": 1702077372184, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.15234375}
{"Ratio train steps to played games": 1.9901382357132678, "Avg loss": 0.4585336912423372, "Avg value loss": 0.15024033898953348, "Avg policy loss": 0.30829335877206177, "Total num played games": 70170, "Total num trained steps": 139648, "Timestamp in ms": 1702077373333, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9893541316785746, "Avg loss": 1.0309180615004152, "Avg value loss": 0.7111519434838556, "Avg policy loss": 0.31976610817946494, "Total num played games": 70262, "Total num trained steps": 139776, "Timestamp in ms": 1702077425289, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991175884546412, "Avg loss": 0.3558174262288958, "Avg value loss": 0.05897225903754588, "Avg policy loss": 0.2968451677588746, "Total num played games": 70262, "Total num trained steps": 139904, "Timestamp in ms": 1702077477199, "logtype": "training_step"}
{"Avg objective": 21.3515625, "Games time in secs": 209.4341612868011, "Avg game time in secs": 1.7472787535807583, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 70272, "Total num trained steps": 140016, "Timestamp in ms": 1702077521774, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990278291025896, "Avg loss": 0.5606481289723888, "Avg value loss": 0.27369884942891076, "Avg policy loss": 0.2869492679601535, "Total num played games": 70358, "Total num trained steps": 140032, "Timestamp in ms": 1702077527951, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920975582023366, "Avg loss": 0.5406988456379622, "Avg value loss": 0.22834546442027204, "Avg policy loss": 0.3123533824691549, "Total num played games": 70358, "Total num trained steps": 140160, "Timestamp in ms": 1702077578758, "logtype": "training_step"}
{"Avg objective": 22.015625, "Games time in secs": 77.47141164913774, "Avg game time in secs": 1.6300722369924188, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.49, "agent_stopped_more": 0.51, "played_steps": 0.57}, "Total num played games": 70400, "Total num trained steps": 140209, "Timestamp in ms": 1702077599245, "logtype": "played_game"}
{"Total num played games": 70452, "Total num trained steps": 140248, "Timestamp in ms": 1702077678037, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.60546875}
{"Avg objective": 21.2109375, "Games time in secs": 81.82016730681062, "Avg game time in secs": 1.8300945686351042, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.67}, "Total num played games": 70528, "Total num trained steps": 140253, "Timestamp in ms": 1702077681066, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9886031809032405, "Avg loss": 1.1346202280838042, "Avg value loss": 0.8123277931590565, "Avg policy loss": 0.3222924422007054, "Total num played games": 70546, "Total num trained steps": 140288, "Timestamp in ms": 1702077695589, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904175998639186, "Avg loss": 0.48691542190499604, "Avg value loss": 0.16897802567109466, "Avg policy loss": 0.31793739774730057, "Total num played games": 70546, "Total num trained steps": 140416, "Timestamp in ms": 1702077748635, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922178436764664, "Avg loss": 0.3585919155739248, "Avg value loss": 0.06203469060710631, "Avg policy loss": 0.29655722610186785, "Total num played games": 70546, "Total num trained steps": 140544, "Timestamp in ms": 1702077800868, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913929784824462, "Avg loss": 0.6725593833252788, "Avg value loss": 0.35654176204116084, "Avg policy loss": 0.3160176173551008, "Total num played games": 70640, "Total num trained steps": 140672, "Timestamp in ms": 1702077853372, "logtype": "training_step"}
{"Avg objective": 21.3125, "Games time in secs": 212.43112399801612, "Avg game time in secs": 1.8683295650989749, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.51, "played_steps": 0.56, "agent_stopped_0": 0.49}, "Total num played games": 70656, "Total num trained steps": 140772, "Timestamp in ms": 1702077893497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905561681793762, "Avg loss": 0.6815901543013752, "Avg value loss": 0.3622867303492967, "Avg policy loss": 0.3193034138530493, "Total num played games": 70734, "Total num trained steps": 140800, "Timestamp in ms": 1702077904429, "logtype": "training_step"}
{"Total num played games": 70734, "Total num trained steps": 140850, "Timestamp in ms": 1702077992739, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.01171875}
{"Avg objective": 22.0390625, "Games time in secs": 101.59989022836089, "Avg game time in secs": 1.743529795698123, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.21875, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.55, "agent_stopped_0": 0.48}, "Total num played games": 70784, "Total num trained steps": 140854, "Timestamp in ms": 1702077995097, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897215790365392, "Avg loss": 0.9795501041226089, "Avg value loss": 0.632867464562878, "Avg policy loss": 0.34668264572974294, "Total num played games": 70828, "Total num trained steps": 140928, "Timestamp in ms": 1702078024869, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991514655221099, "Avg loss": 0.4034189030062407, "Avg value loss": 0.08084095051162876, "Avg policy loss": 0.3225779513595626, "Total num played games": 70828, "Total num trained steps": 141056, "Timestamp in ms": 1702078076114, "logtype": "training_step"}
{"Avg objective": 23.6953125, "Games time in secs": 119.66872434318066, "Avg game time in secs": 1.8018226362764835, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 70912, "Total num trained steps": 141152, "Timestamp in ms": 1702078114766, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906940018611996, "Avg loss": 0.8129850856494159, "Avg value loss": 0.50038357367157, "Avg policy loss": 0.3126015072921291, "Total num played games": 70922, "Total num trained steps": 141184, "Timestamp in ms": 1702078127691, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924988015002396, "Avg loss": 0.437465327559039, "Avg value loss": 0.11092642034054734, "Avg policy loss": 0.32653890806250274, "Total num played games": 70922, "Total num trained steps": 141312, "Timestamp in ms": 1702078178812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916638503999098, "Avg loss": 0.8425900025758892, "Avg value loss": 0.5194995001947973, "Avg policy loss": 0.3230904957745224, "Total num played games": 71016, "Total num trained steps": 141440, "Timestamp in ms": 1702078232855, "logtype": "training_step"}
{"Total num played games": 71016, "Total num trained steps": 141451, "Timestamp in ms": 1702078309957, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.19921875}
{"Avg objective": 22.515625, "Games time in secs": 197.1970975138247, "Avg game time in secs": 1.870825706719188, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.69, "agent_stopped_0": 0.41}, "Total num played games": 71040, "Total num trained steps": 141455, "Timestamp in ms": 1702078311963, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908311067360427, "Avg loss": 0.7995565631426871, "Avg value loss": 0.4786106418177951, "Avg policy loss": 0.32094592100474983, "Total num played games": 71110, "Total num trained steps": 141568, "Timestamp in ms": 1702078357349, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926311348614822, "Avg loss": 0.3550594181288034, "Avg value loss": 0.05652096378616989, "Avg policy loss": 0.2985384532948956, "Total num played games": 71110, "Total num trained steps": 141696, "Timestamp in ms": 1702078410009, "logtype": "training_step"}
{"Avg objective": 22.3671875, "Games time in secs": 105.05399387329817, "Avg game time in secs": 1.82407056845841, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_more": 0.54, "played_steps": 0.58, "agent_stopped_0": 0.46}, "Total num played games": 71168, "Total num trained steps": 141713, "Timestamp in ms": 1702078417017, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917982135835066, "Avg loss": 0.8792120073921978, "Avg value loss": 0.5610057496814989, "Avg policy loss": 0.31820625730324537, "Total num played games": 71204, "Total num trained steps": 141824, "Timestamp in ms": 1702078465285, "logtype": "training_step"}
{"Avg objective": 21.8515625, "Games time in secs": 81.21083212643862, "Avg game time in secs": 1.8893697432940826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.66, "agent_stopped_0": 0.4}, "Total num played games": 71296, "Total num trained steps": 141905, "Timestamp in ms": 1702078498228, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909674885691042, "Avg loss": 0.7250868750270456, "Avg value loss": 0.41151914463262074, "Avg policy loss": 0.3135677333921194, "Total num played games": 71298, "Total num trained steps": 141952, "Timestamp in ms": 1702078517252, "logtype": "training_step"}
{"Total num played games": 71298, "Total num trained steps": 142054, "Timestamp in ms": 1702078632558, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.9296875}
{"Ratio train steps to played games": 1.9901389511429852, "Avg loss": 0.7331333747133613, "Avg value loss": 0.423275422595907, "Avg policy loss": 0.3098579494981095, "Total num played games": 71392, "Total num trained steps": 142080, "Timestamp in ms": 1702078644146, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9919318691169878, "Avg loss": 0.5428790031000972, "Avg value loss": 0.2241873854654841, "Avg policy loss": 0.31869161676149815, "Total num played games": 71392, "Total num trained steps": 142208, "Timestamp in ms": 1702078695768, "logtype": "training_step"}
{"Avg objective": 21.46875, "Games time in secs": 225.17053043469787, "Avg game time in secs": 1.623829882562859, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 71424, "Total num trained steps": 142276, "Timestamp in ms": 1702078723399, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991047448522829, "Avg loss": 0.6830469791311771, "Avg value loss": 0.36716213254840113, "Avg policy loss": 0.31588484661187977, "Total num played games": 71488, "Total num trained steps": 142336, "Timestamp in ms": 1702078748245, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928379588182632, "Avg loss": 0.40145034343004227, "Avg value loss": 0.08482316375011578, "Avg policy loss": 0.31662717752624303, "Total num played games": 71488, "Total num trained steps": 142464, "Timestamp in ms": 1702078799877, "logtype": "training_step"}
{"Avg objective": 21.203125, "Games time in secs": 78.77225708216429, "Avg game time in secs": 1.6317453274095897, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.140625, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.57}, "Total num played games": 71552, "Total num trained steps": 142470, "Timestamp in ms": 1702078802171, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920091643150513, "Avg loss": 0.8867096805479378, "Avg value loss": 0.5647082658833824, "Avg policy loss": 0.32200142147485167, "Total num played games": 71582, "Total num trained steps": 142592, "Timestamp in ms": 1702078850229, "logtype": "training_step"}
{"Total num played games": 71678, "Total num trained steps": 142654, "Timestamp in ms": 1702078943983, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8828125}
{"Avg objective": 23.0078125, "Games time in secs": 142.84219381213188, "Avg game time in secs": 1.8703736263269093, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.67}, "Total num played games": 71680, "Total num trained steps": 142654, "Timestamp in ms": 1702078945013, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9885052666778131, "Avg loss": 1.336850591469556, "Avg value loss": 1.0094562055310234, "Avg policy loss": 0.32739438267890364, "Total num played games": 71772, "Total num trained steps": 142720, "Timestamp in ms": 1702078972033, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9903026249791005, "Avg loss": 0.4729179774876684, "Avg value loss": 0.14454746094997972, "Avg policy loss": 0.328370513394475, "Total num played games": 71772, "Total num trained steps": 142848, "Timestamp in ms": 1702079021861, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920860502703004, "Avg loss": 0.3640305306762457, "Avg value loss": 0.05824617072357796, "Avg policy loss": 0.3057843566639349, "Total num played games": 71772, "Total num trained steps": 142976, "Timestamp in ms": 1702079074064, "logtype": "training_step"}
{"Avg objective": 22.34375, "Games time in secs": 154.18765088915825, "Avg game time in secs": 1.5845269485434983, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1328125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 71808, "Total num trained steps": 143037, "Timestamp in ms": 1702079099201, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991261514485292, "Avg loss": 0.7016456597484648, "Avg value loss": 0.38350156290107407, "Avg policy loss": 0.3181440974585712, "Total num played games": 71866, "Total num trained steps": 143104, "Timestamp in ms": 1702079125912, "logtype": "training_step"}
{"Avg objective": 20.6953125, "Games time in secs": 77.19255872443318, "Avg game time in secs": 1.8130206313508097, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3828125, "Avg reasons for ending game": {"agent_stopped_0": 0.4, "agent_stopped_more": 0.6, "played_steps": 0.64}, "Total num played games": 71936, "Total num trained steps": 143226, "Timestamp in ms": 1702079176394, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9904391328515842, "Avg loss": 0.46846249024383724, "Avg value loss": 0.15558355781831779, "Avg policy loss": 0.31287893396802247, "Total num played games": 71960, "Total num trained steps": 143232, "Timestamp in ms": 1702079178554, "logtype": "training_step"}
{"Total num played games": 71960, "Total num trained steps": 143256, "Timestamp in ms": 1702079210796, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.16796875}
{"Ratio train steps to played games": 1.9896188969384072, "Avg loss": 0.9598443852737546, "Avg value loss": 0.6309737845440395, "Avg policy loss": 0.3288705968298018, "Total num played games": 72054, "Total num trained steps": 143360, "Timestamp in ms": 1702079254996, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913953423821023, "Avg loss": 0.3600842470768839, "Avg value loss": 0.05905532409087755, "Avg policy loss": 0.3010289187077433, "Total num played games": 72054, "Total num trained steps": 143488, "Timestamp in ms": 1702079306874, "logtype": "training_step"}
{"Avg objective": 21.9609375, "Games time in secs": 176.8727862611413, "Avg game time in secs": 1.872321751608979, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.67, "agent_stopped_0": 0.38}, "Total num played games": 72064, "Total num trained steps": 143600, "Timestamp in ms": 1702079353267, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9905197505197505, "Avg loss": 0.5052952519617975, "Avg value loss": 0.20180677380994894, "Avg policy loss": 0.3034884803928435, "Total num played games": 72150, "Total num trained steps": 143616, "Timestamp in ms": 1702079359675, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922938322938324, "Avg loss": 0.532436665147543, "Avg value loss": 0.20704724310780875, "Avg policy loss": 0.3253894215449691, "Total num played games": 72150, "Total num trained steps": 143744, "Timestamp in ms": 1702079412116, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 79.26598960906267, "Avg game time in secs": 1.8152853935898747, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 72192, "Total num trained steps": 143793, "Timestamp in ms": 1702079432533, "logtype": "played_game"}
{"Total num played games": 72244, "Total num trained steps": 143858, "Timestamp in ms": 1702079528276, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5390625}
{"Avg objective": 22.4453125, "Games time in secs": 98.66300528496504, "Avg game time in secs": 1.8940790889027994, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2734375, "Avg reasons for ending game": {"agent_stopped_more": 0.64, "played_steps": 0.7, "agent_stopped_0": 0.36}, "Total num played games": 72320, "Total num trained steps": 143863, "Timestamp in ms": 1702079531196, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988940499889405, "Avg loss": 0.9362997014541179, "Avg value loss": 0.6222702312661568, "Avg policy loss": 0.3140294711338356, "Total num played games": 72336, "Total num trained steps": 143872, "Timestamp in ms": 1702079534391, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9906411567917277, "Avg loss": 0.8242503951769322, "Avg value loss": 0.48985959083074704, "Avg policy loss": 0.3343908058013767, "Total num played games": 72338, "Total num trained steps": 144000, "Timestamp in ms": 1702079587056, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924244518786807, "Avg loss": 0.3854989118408412, "Avg value loss": 0.07624174348893575, "Avg policy loss": 0.3092571663437411, "Total num played games": 72338, "Total num trained steps": 144128, "Timestamp in ms": 1702079639518, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916059200353435, "Avg loss": 0.844489436596632, "Avg value loss": 0.5313731255882885, "Avg policy loss": 0.3131163106299937, "Total num played games": 72432, "Total num trained steps": 144256, "Timestamp in ms": 1702079690887, "logtype": "training_step"}
{"Avg objective": 22.6015625, "Games time in secs": 201.12614227831364, "Avg game time in secs": 1.7732911735074595, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4140625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.59, "agent_stopped_0": 0.48}, "Total num played games": 72448, "Total num trained steps": 144356, "Timestamp in ms": 1702079732322, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9907346128391794, "Avg loss": 0.754017801489681, "Avg value loss": 0.4474560274393298, "Avg policy loss": 0.3065617809770629, "Total num played games": 72528, "Total num trained steps": 144384, "Timestamp in ms": 1702079743977, "logtype": "training_step"}
{"Total num played games": 72528, "Total num trained steps": 144459, "Timestamp in ms": 1702079849197, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.96875}
{"Avg objective": 22.25, "Games time in secs": 119.05529714748263, "Avg game time in secs": 1.7726308542478364, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_0": 0.43, "agent_stopped_more": 0.57, "played_steps": 0.6}, "Total num played games": 72576, "Total num trained steps": 144463, "Timestamp in ms": 1702079851378, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899204097931755, "Avg loss": 1.0840242519043386, "Avg value loss": 0.7518010667408817, "Avg policy loss": 0.3322231685742736, "Total num played games": 72622, "Total num trained steps": 144512, "Timestamp in ms": 1702079871607, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916829610861722, "Avg loss": 0.4274510268587619, "Avg value loss": 0.10362317963154055, "Avg policy loss": 0.3238278483040631, "Total num played games": 72622, "Total num trained steps": 144640, "Timestamp in ms": 1702079923065, "logtype": "training_step"}
{"Avg objective": 22.4296875, "Games time in secs": 110.08053141832352, "Avg game time in secs": 1.8083043324295431, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.67, "agent_stopped_0": 0.35}, "Total num played games": 72704, "Total num trained steps": 144740, "Timestamp in ms": 1702079961458, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908138287631674, "Avg loss": 0.7781816313508898, "Avg value loss": 0.4727842345018871, "Avg policy loss": 0.3053973950445652, "Total num played games": 72718, "Total num trained steps": 144768, "Timestamp in ms": 1702079972111, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992574053191782, "Avg loss": 0.50909089948982, "Avg value loss": 0.18544972655945458, "Avg policy loss": 0.32364116911776364, "Total num played games": 72718, "Total num trained steps": 144896, "Timestamp in ms": 1702080023351, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917596000659232, "Avg loss": 0.6920354377944022, "Avg value loss": 0.3767525100556668, "Avg policy loss": 0.31528292316943407, "Total num played games": 72812, "Total num trained steps": 145024, "Timestamp in ms": 1702080076557, "logtype": "training_step"}
{"Total num played games": 72812, "Total num trained steps": 145063, "Timestamp in ms": 1702080120255, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.921875}
{"Avg objective": 21.5390625, "Games time in secs": 160.67152711749077, "Avg game time in secs": 1.774829736619722, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.58, "agent_stopped_0": 0.52}, "Total num played games": 72832, "Total num trained steps": 145066, "Timestamp in ms": 1702080122130, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990947247140153, "Avg loss": 0.7242371866013855, "Avg value loss": 0.4138553781667724, "Avg policy loss": 0.31038180424366146, "Total num played games": 72906, "Total num trained steps": 145152, "Timestamp in ms": 1702080157163, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992689216251063, "Avg loss": 0.3692470150999725, "Avg value loss": 0.07072788116056472, "Avg policy loss": 0.29851913324091583, "Total num played games": 72906, "Total num trained steps": 145280, "Timestamp in ms": 1702080210067, "logtype": "training_step"}
{"Avg objective": 20.921875, "Games time in secs": 98.9113792590797, "Avg game time in secs": 1.6936562666669488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.0859375, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 72960, "Total num trained steps": 145305, "Timestamp in ms": 1702080221042, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918904109589042, "Avg loss": 0.9970771621447057, "Avg value loss": 0.6769960350356996, "Avg policy loss": 0.3200811316492036, "Total num played games": 73000, "Total num trained steps": 145408, "Timestamp in ms": 1702080263846, "logtype": "training_step"}
{"Avg objective": 22.3203125, "Games time in secs": 78.90754923969507, "Avg game time in secs": 1.821936541935429, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.73, "agent_stopped_0": 0.34}, "Total num played games": 73088, "Total num trained steps": 145496, "Timestamp in ms": 1702080299949, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910255007113933, "Avg loss": 0.8560707357246429, "Avg value loss": 0.5406066988944076, "Avg policy loss": 0.3154640308348462, "Total num played games": 73096, "Total num trained steps": 145536, "Timestamp in ms": 1702080316373, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927629418846449, "Avg loss": 0.4387877625413239, "Avg value loss": 0.12839422092656605, "Avg policy loss": 0.31039354111999273, "Total num played games": 73096, "Total num trained steps": 145664, "Timestamp in ms": 1702080369004, "logtype": "training_step"}
{"Total num played games": 73096, "Total num trained steps": 145664, "Timestamp in ms": 1702080436633, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8671875}
{"Ratio train steps to played games": 1.9919661155895614, "Avg loss": 0.8395076408050954, "Avg value loss": 0.5336549373168964, "Avg policy loss": 0.30585269862785935, "Total num played games": 73190, "Total num trained steps": 145792, "Timestamp in ms": 1702080490114, "logtype": "training_step"}
{"Avg objective": 21.734375, "Games time in secs": 223.6003321968019, "Avg game time in secs": 1.722969389084028, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 73216, "Total num trained steps": 145872, "Timestamp in ms": 1702080523550, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991103348524957, "Avg loss": 0.8352404781617224, "Avg value loss": 0.5418963359843474, "Avg policy loss": 0.29334413702599704, "Total num played games": 73286, "Total num trained steps": 145920, "Timestamp in ms": 1702080542463, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992849930409628, "Avg loss": 0.4172002850100398, "Avg value loss": 0.11575085355434567, "Avg policy loss": 0.3014494312228635, "Total num played games": 73286, "Total num trained steps": 146048, "Timestamp in ms": 1702080594185, "logtype": "training_step"}
{"Avg objective": 21.515625, "Games time in secs": 77.6289096698165, "Avg game time in secs": 1.7007585673127323, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.15625, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 73344, "Total num trained steps": 146065, "Timestamp in ms": 1702080601179, "logtype": "played_game"}
{"Ratio train steps to played games": 1.992041428182066, "Avg loss": 0.6735843506176025, "Avg value loss": 0.37355295015731826, "Avg policy loss": 0.30003139981999993, "Total num played games": 73380, "Total num trained steps": 146176, "Timestamp in ms": 1702080647164, "logtype": "training_step"}
{"Avg objective": 21.71875, "Games time in secs": 78.40164491534233, "Avg game time in secs": 1.886732151178876, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2265625, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.75}, "Total num played games": 73472, "Total num trained steps": 146256, "Timestamp in ms": 1702080679581, "logtype": "played_game"}
{"Total num played games": 73474, "Total num trained steps": 146264, "Timestamp in ms": 1702080757994, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.88671875}
{"Ratio train steps to played games": 1.9886907351022183, "Avg loss": 0.9222351729404181, "Avg value loss": 0.6285464472894091, "Avg policy loss": 0.29368872102349997, "Total num played games": 73568, "Total num trained steps": 146304, "Timestamp in ms": 1702080776262, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9904306220095693, "Avg loss": 0.47291710088029504, "Avg value loss": 0.17663544754032046, "Avg policy loss": 0.2962816535728052, "Total num played games": 73568, "Total num trained steps": 146432, "Timestamp in ms": 1702080828418, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921705089169204, "Avg loss": 0.35583340958692133, "Avg value loss": 0.07372198620578274, "Avg policy loss": 0.28211142565123737, "Total num played games": 73568, "Total num trained steps": 146560, "Timestamp in ms": 1702080883223, "logtype": "training_step"}
{"Avg objective": 20.453125, "Games time in secs": 231.61260243877769, "Avg game time in secs": 1.639755017706193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.48, "played_steps": 0.49, "agent_stopped_0": 0.52}, "Total num played games": 73600, "Total num trained steps": 146629, "Timestamp in ms": 1702080911193, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913119026933102, "Avg loss": 0.7190365960123017, "Avg value loss": 0.439012004295364, "Avg policy loss": 0.28002459625713527, "Total num played games": 73664, "Total num trained steps": 146688, "Timestamp in ms": 1702080935002, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993049522154648, "Avg loss": 0.35905923694372177, "Avg value loss": 0.08470524509903044, "Avg policy loss": 0.274353988468647, "Total num played games": 73664, "Total num trained steps": 146816, "Timestamp in ms": 1702080987653, "logtype": "training_step"}
{"Avg objective": 21.7734375, "Games time in secs": 78.98230050504208, "Avg game time in secs": 1.9090405336755794, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.23, "agent_stopped_more": 0.77, "played_steps": 0.78}, "Total num played games": 73728, "Total num trained steps": 146822, "Timestamp in ms": 1702080990176, "logtype": "played_game"}
{"Total num played games": 73760, "Total num trained steps": 146868, "Timestamp in ms": 1702081078117, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.0234375}
{"Ratio train steps to played games": 1.989655265794676, "Avg loss": 1.2709515672177076, "Avg value loss": 0.9699990308727138, "Avg policy loss": 0.3009525308152661, "Total num played games": 73854, "Total num trained steps": 146944, "Timestamp in ms": 1702081108584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913884149809082, "Avg loss": 0.38072016544174403, "Avg value loss": 0.0955957034311723, "Avg policy loss": 0.2851244572084397, "Total num played games": 73854, "Total num trained steps": 147072, "Timestamp in ms": 1702081160743, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 222.6100121550262, "Avg game time in secs": 2.0342357762274332, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.359375, "Avg reasons for ending game": {"agent_stopped_more": 0.63, "played_steps": 0.71, "agent_stopped_0": 0.37}, "Total num played games": 73856, "Total num trained steps": 147198, "Timestamp in ms": 1702081212786, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928921502260972, "Avg loss": 0.3262160314479843, "Avg value loss": 0.05724402115447447, "Avg policy loss": 0.2689720084890723, "Total num played games": 73862, "Total num trained steps": 147200, "Timestamp in ms": 1702081213447, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923189268134365, "Avg loss": 0.6904462778475136, "Avg value loss": 0.4108979798911605, "Avg policy loss": 0.2795482937945053, "Total num played games": 73948, "Total num trained steps": 147328, "Timestamp in ms": 1702081265960, "logtype": "training_step"}
{"Avg objective": 21.90625, "Games time in secs": 77.44008202850819, "Avg game time in secs": 1.6845862201298587, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.54}, "Total num played games": 73984, "Total num trained steps": 147389, "Timestamp in ms": 1702081290226, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991464534601048, "Avg loss": 0.7732423006091267, "Avg value loss": 0.49041924669290893, "Avg policy loss": 0.2828230579616502, "Total num played games": 74044, "Total num trained steps": 147456, "Timestamp in ms": 1702081317073, "logtype": "training_step"}
{"Total num played games": 74044, "Total num trained steps": 147471, "Timestamp in ms": 1702081333993, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.66015625}
{"Avg objective": 21.2265625, "Games time in secs": 46.278524462133646, "Avg game time in secs": 1.7918146750889719, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.64}, "Total num played games": 74112, "Total num trained steps": 147477, "Timestamp in ms": 1702081336505, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9906660551943673, "Avg loss": 0.642118162009865, "Avg value loss": 0.34212947072228417, "Avg policy loss": 0.29998868831899017, "Total num played games": 74138, "Total num trained steps": 147584, "Timestamp in ms": 1702081381353, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923925652162184, "Avg loss": 0.33632731961552054, "Avg value loss": 0.05842021820717491, "Avg policy loss": 0.2779070978285745, "Total num played games": 74138, "Total num trained steps": 147712, "Timestamp in ms": 1702081434410, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9915939217588101, "Avg loss": 0.7774418510962278, "Avg value loss": 0.5079519856953993, "Avg policy loss": 0.2694898667978123, "Total num played games": 74232, "Total num trained steps": 147840, "Timestamp in ms": 1702081485879, "logtype": "training_step"}
{"Avg objective": 21.6015625, "Games time in secs": 197.3927746526897, "Avg game time in secs": 1.716920837527141, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.46875, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.59, "agent_stopped_0": 0.43}, "Total num played games": 74240, "Total num trained steps": 147956, "Timestamp in ms": 1702081533897, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9908508691674291, "Avg loss": 0.4499445613473654, "Avg value loss": 0.1839318965212442, "Avg policy loss": 0.2660126619739458, "Total num played games": 74324, "Total num trained steps": 147968, "Timestamp in ms": 1702081538581, "logtype": "training_step"}
{"Total num played games": 74326, "Total num trained steps": 148072, "Timestamp in ms": 1702081599113, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.8671875}
{"Avg objective": 21.9921875, "Games time in secs": 67.25532280281186, "Avg game time in secs": 1.7498211252095643, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.296875, "Avg reasons for ending game": {"agent_stopped_0": 0.51, "agent_stopped_more": 0.49, "played_steps": 0.52}, "Total num played games": 74368, "Total num trained steps": 148075, "Timestamp in ms": 1702081601153, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9900026874496104, "Avg loss": 0.9114676802419126, "Avg value loss": 0.6234344643889926, "Avg policy loss": 0.2880332210334018, "Total num played games": 74420, "Total num trained steps": 148096, "Timestamp in ms": 1702081609582, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9917092179521634, "Avg loss": 0.5382718939799815, "Avg value loss": 0.24788293780875392, "Avg policy loss": 0.29038895783014596, "Total num played games": 74420, "Total num trained steps": 148224, "Timestamp in ms": 1702081662779, "logtype": "training_step"}
{"Avg objective": 20.71875, "Games time in secs": 105.160998377949, "Avg game time in secs": 1.7517975692171603, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 74496, "Total num trained steps": 148334, "Timestamp in ms": 1702081706314, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909144590278336, "Avg loss": 0.4626833936199546, "Avg value loss": 0.18635458986682352, "Avg policy loss": 0.2763288072310388, "Total num played games": 74514, "Total num trained steps": 148352, "Timestamp in ms": 1702081713005, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926322570255255, "Avg loss": 0.42214356851764023, "Avg value loss": 0.14310493963421322, "Avg policy loss": 0.2790386282140389, "Total num played games": 74514, "Total num trained steps": 148480, "Timestamp in ms": 1702081763952, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918507398670384, "Avg loss": 0.8486023830482736, "Avg value loss": 0.5551974260888528, "Avg policy loss": 0.2934049579780549, "Total num played games": 74608, "Total num trained steps": 148608, "Timestamp in ms": 1702081817238, "logtype": "training_step"}
{"Total num played games": 74608, "Total num trained steps": 148676, "Timestamp in ms": 1702081904978, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.765625}
{"Avg objective": 21.78125, "Games time in secs": 200.346620477736, "Avg game time in secs": 1.8279994338809047, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 74624, "Total num trained steps": 148679, "Timestamp in ms": 1702081906661, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910578030039356, "Avg loss": 0.7260713146533817, "Avg value loss": 0.4259859503363259, "Avg policy loss": 0.3000853641424328, "Total num played games": 74702, "Total num trained steps": 148736, "Timestamp in ms": 1702081930435, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992771277877433, "Avg loss": 0.4079610260669142, "Avg value loss": 0.10823549365159124, "Avg policy loss": 0.29972553125116974, "Total num played games": 74702, "Total num trained steps": 148864, "Timestamp in ms": 1702081983228, "logtype": "training_step"}
{"Avg objective": 21.3203125, "Games time in secs": 89.75207729265094, "Avg game time in secs": 1.6881154070433695, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.61}, "Total num played games": 74752, "Total num trained steps": 148898, "Timestamp in ms": 1702081996413, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919249177785503, "Avg loss": 0.757591063156724, "Avg value loss": 0.44969075213884935, "Avg policy loss": 0.3079003095626831, "Total num played games": 74798, "Total num trained steps": 148992, "Timestamp in ms": 1702082035196, "logtype": "training_step"}
{"Avg objective": 21.8828125, "Games time in secs": 79.56743569672108, "Avg game time in secs": 1.7919022236892488, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.64, "agent_stopped_0": 0.39}, "Total num played games": 74880, "Total num trained steps": 149091, "Timestamp in ms": 1702082075980, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910807274280984, "Avg loss": 0.6044544505421072, "Avg value loss": 0.3043328234634828, "Avg policy loss": 0.3001216273987666, "Total num played games": 74894, "Total num trained steps": 149120, "Timestamp in ms": 1702082088112, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927898095975645, "Avg loss": 0.40933128516189754, "Avg value loss": 0.10136852640425786, "Avg policy loss": 0.307962759048678, "Total num played games": 74894, "Total num trained steps": 149248, "Timestamp in ms": 1702082140959, "logtype": "training_step"}
{"Total num played games": 74988, "Total num trained steps": 149281, "Timestamp in ms": 1702082227043, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.046875}
{"Avg objective": 21.8984375, "Games time in secs": 152.80918568372726, "Avg game time in secs": 1.7134694217238575, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.56, "agent_stopped_0": 0.5}, "Total num played games": 75008, "Total num trained steps": 149284, "Timestamp in ms": 1702082228790, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9894914893050264, "Avg loss": 1.2078317271079868, "Avg value loss": 0.87422782368958, "Avg policy loss": 0.3336039010901004, "Total num played games": 75082, "Total num trained steps": 149376, "Timestamp in ms": 1702082267811, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9912096108254975, "Avg loss": 0.3981921134982258, "Avg value loss": 0.08549157410743646, "Avg policy loss": 0.3127005362184718, "Total num played games": 75082, "Total num trained steps": 149504, "Timestamp in ms": 1702082320809, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929144135744918, "Avg loss": 0.35588133824057877, "Avg value loss": 0.05319692206103355, "Avg policy loss": 0.30268441687803715, "Total num played games": 75082, "Total num trained steps": 149632, "Timestamp in ms": 1702082373917, "logtype": "training_step"}
{"Avg objective": 21.140625, "Games time in secs": 155.2679903022945, "Avg game time in secs": 1.5863847422006074, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.58, "agent_stopped_more": 0.42, "played_steps": 0.46}, "Total num played games": 75136, "Total num trained steps": 149657, "Timestamp in ms": 1702082384058, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920721487669264, "Avg loss": 0.650830952450633, "Avg value loss": 0.3372112890065182, "Avg policy loss": 0.31361966498661786, "Total num played games": 75178, "Total num trained steps": 149760, "Timestamp in ms": 1702082426928, "logtype": "training_step"}
{"Avg objective": 21.6328125, "Games time in secs": 81.00741868466139, "Avg game time in secs": 1.8363092755898833, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.6, "played_steps": 0.64, "agent_stopped_0": 0.4}, "Total num played games": 75264, "Total num trained steps": 149850, "Timestamp in ms": 1702082465065, "logtype": "played_game"}
{"Total num played games": 75272, "Total num trained steps": 149881, "Timestamp in ms": 1702082548014, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.19140625}
{"Ratio train steps to played games": 1.9891708249283364, "Avg loss": 0.7248897245153785, "Avg value loss": 0.4172629681706894, "Avg policy loss": 0.3076267623109743, "Total num played games": 75350, "Total num trained steps": 149888, "Timestamp in ms": 1702082550839, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990486426239949, "Avg loss": 0.9101211545057595, "Avg value loss": 0.5727831652620807, "Avg policy loss": 0.33733798167668283, "Total num played games": 75366, "Total num trained steps": 150016, "Timestamp in ms": 1702082601501, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9921980734017992, "Avg loss": 0.36826902034226805, "Avg value loss": 0.06064503954257816, "Avg policy loss": 0.3076239798683673, "Total num played games": 75366, "Total num trained steps": 150144, "Timestamp in ms": 1702082653537, "logtype": "training_step"}
{"Avg objective": 22.171875, "Games time in secs": 221.1469564884901, "Avg game time in secs": 1.6385617653722875, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.53, "agent_stopped_0": 0.5}, "Total num played games": 75392, "Total num trained steps": 150225, "Timestamp in ms": 1702082686213, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913598897458324, "Avg loss": 0.8168506610672921, "Avg value loss": 0.5105600525421323, "Avg policy loss": 0.30629061546642333, "Total num played games": 75462, "Total num trained steps": 150272, "Timestamp in ms": 1702082704812, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930561077098408, "Avg loss": 0.47335870820097625, "Avg value loss": 0.16660888853948563, "Avg policy loss": 0.30674982082564384, "Total num played games": 75462, "Total num trained steps": 150400, "Timestamp in ms": 1702082758522, "logtype": "training_step"}
{"Avg objective": 22.7421875, "Games time in secs": 79.59481766074896, "Avg game time in secs": 1.8009068552346434, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.35, "agent_stopped_more": 0.65, "played_steps": 0.66}, "Total num played games": 75520, "Total num trained steps": 150418, "Timestamp in ms": 1702082765808, "logtype": "played_game"}
{"Total num played games": 75558, "Total num trained steps": 150482, "Timestamp in ms": 1702082853186, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.14453125}
{"Avg objective": 21.984375, "Games time in secs": 90.54961594939232, "Avg game time in secs": 1.7674105469777714, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.67, "agent_stopped_0": 0.39}, "Total num played games": 75648, "Total num trained steps": 150489, "Timestamp in ms": 1702082856357, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9897292867339924, "Avg loss": 1.10939213167876, "Avg value loss": 0.7854041417886037, "Avg policy loss": 0.3239879871252924, "Total num played games": 75652, "Total num trained steps": 150528, "Timestamp in ms": 1702082872322, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914344630677312, "Avg loss": 0.4265473282430321, "Avg value loss": 0.10437317722244188, "Avg policy loss": 0.3221741490997374, "Total num played games": 75652, "Total num trained steps": 150656, "Timestamp in ms": 1702082927148, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931264209802781, "Avg loss": 0.3523074451368302, "Avg value loss": 0.051953319445601664, "Avg policy loss": 0.30035412369761616, "Total num played games": 75652, "Total num trained steps": 150784, "Timestamp in ms": 1702082979726, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9923428299844217, "Avg loss": 0.7263027904555202, "Avg value loss": 0.39655157303786837, "Avg policy loss": 0.329751226818189, "Total num played games": 75746, "Total num trained steps": 150912, "Timestamp in ms": 1702083032806, "logtype": "training_step"}
{"Avg objective": 21.109375, "Games time in secs": 206.51424742862582, "Avg game time in secs": 1.7398257679014932, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.58, "agent_stopped_0": 0.48}, "Total num played games": 75776, "Total num trained steps": 150984, "Timestamp in ms": 1702083062872, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915611814345993, "Avg loss": 0.9932088514324278, "Avg value loss": 0.6597068625560496, "Avg policy loss": 0.33350198809057474, "Total num played games": 75840, "Total num trained steps": 151040, "Timestamp in ms": 1702083085937, "logtype": "training_step"}
{"Total num played games": 75840, "Total num trained steps": 151085, "Timestamp in ms": 1702083162314, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7890625}
{"Avg objective": 23.1484375, "Games time in secs": 101.98788096383214, "Avg game time in secs": 1.7365897089766804, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.56, "played_steps": 0.61, "agent_stopped_0": 0.44}, "Total num played games": 75904, "Total num trained steps": 151088, "Timestamp in ms": 1702083164860, "logtype": "played_game"}
{"Ratio train steps to played games": 1.990781468117049, "Avg loss": 0.9075416342820972, "Avg value loss": 0.5509269252070226, "Avg policy loss": 0.3566147100646049, "Total num played games": 75934, "Total num trained steps": 151168, "Timestamp in ms": 1702083198584, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992467142518503, "Avg loss": 0.42602196359075606, "Avg value loss": 0.08407154606538825, "Avg policy loss": 0.3419504186604172, "Total num played games": 75934, "Total num trained steps": 151296, "Timestamp in ms": 1702083252009, "logtype": "training_step"}
{"Ratio train steps to played games": 1.991687273109907, "Avg loss": 0.8278952424880117, "Avg value loss": 0.4910738744074479, "Avg policy loss": 0.3368213626090437, "Total num played games": 76028, "Total num trained steps": 151424, "Timestamp in ms": 1702083306685, "logtype": "training_step"}
{"Avg objective": 21.6796875, "Games time in secs": 194.29393136128783, "Avg game time in secs": 1.970045524474699, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.66, "played_steps": 0.77, "agent_stopped_0": 0.34}, "Total num played games": 76032, "Total num trained steps": 151547, "Timestamp in ms": 1702083359154, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9912624165659327, "Avg loss": 0.43293233192525804, "Avg value loss": 0.09859009241336025, "Avg policy loss": 0.334342238958925, "Total num played games": 76108, "Total num trained steps": 151552, "Timestamp in ms": 1702083360880, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925908410183653, "Avg loss": 0.7161448791157454, "Avg value loss": 0.3659956777410116, "Avg policy loss": 0.35014919948298484, "Total num played games": 76122, "Total num trained steps": 151680, "Timestamp in ms": 1702083413552, "logtype": "training_step"}
{"Total num played games": 76122, "Total num trained steps": 151685, "Timestamp in ms": 1702083446614, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.125}
{"Avg objective": 21.1640625, "Games time in secs": 89.41549926623702, "Avg game time in secs": 1.815508272673469, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.265625, "Avg reasons for ending game": {"agent_stopped_more": 0.52, "played_steps": 0.62, "agent_stopped_0": 0.48}, "Total num played games": 76160, "Total num trained steps": 151689, "Timestamp in ms": 1702083448570, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918127427311851, "Avg loss": 0.8431931443046778, "Avg value loss": 0.5018080309964716, "Avg policy loss": 0.3413851148216054, "Total num played games": 76216, "Total num trained steps": 151808, "Timestamp in ms": 1702083498199, "logtype": "training_step"}
{"Avg objective": 21.4765625, "Games time in secs": 100.71035422384739, "Avg game time in secs": 1.701379866892239, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.203125, "Avg reasons for ending game": {"agent_stopped_more": 0.49, "played_steps": 0.53, "agent_stopped_0": 0.51}, "Total num played games": 76288, "Total num trained steps": 151925, "Timestamp in ms": 1702083549280, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9910365613943126, "Avg loss": 0.5109358145855367, "Avg value loss": 0.19806828681612387, "Avg policy loss": 0.3128675244515762, "Total num played games": 76310, "Total num trained steps": 151936, "Timestamp in ms": 1702083553777, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927139300222776, "Avg loss": 0.5564952578861266, "Avg value loss": 0.22631967294728383, "Avg policy loss": 0.3301755841821432, "Total num played games": 76310, "Total num trained steps": 152064, "Timestamp in ms": 1702083608215, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918854540219355, "Avg loss": 0.6508259319234639, "Avg value loss": 0.3226640371431131, "Avg policy loss": 0.3281618948094547, "Total num played games": 76406, "Total num trained steps": 152192, "Timestamp in ms": 1702083662296, "logtype": "training_step"}
{"Total num played games": 76406, "Total num trained steps": 152288, "Timestamp in ms": 1702083715055, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.7734375}
{"Avg objective": 21.6328125, "Games time in secs": 167.28215816244483, "Avg game time in secs": 1.8254496715671849, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.453125, "Avg reasons for ending game": {"agent_stopped_more": 0.61, "played_steps": 0.68, "agent_stopped_0": 0.39}, "Total num played games": 76416, "Total num trained steps": 152289, "Timestamp in ms": 1702083716562, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991111111111111, "Avg loss": 0.7643955177627504, "Avg value loss": 0.4435836911725346, "Avg policy loss": 0.32081184117123485, "Total num played games": 76500, "Total num trained steps": 152320, "Timestamp in ms": 1702083729348, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927843137254901, "Avg loss": 0.48432309622876346, "Avg value loss": 0.15621576967532746, "Avg policy loss": 0.32810732268262655, "Total num played games": 76500, "Total num trained steps": 152448, "Timestamp in ms": 1702083784852, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 87.36563690006733, "Avg game time in secs": 1.6412075220432598, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 76544, "Total num trained steps": 152493, "Timestamp in ms": 1702083803928, "logtype": "played_game"}
{"Ratio train steps to played games": 1.99200981800141, "Avg loss": 0.7273833844810724, "Avg value loss": 0.3979277691396419, "Avg policy loss": 0.3294556103646755, "Total num played games": 76594, "Total num trained steps": 152576, "Timestamp in ms": 1702083842093, "logtype": "training_step"}
{"Avg objective": 22.109375, "Games time in secs": 85.09725047647953, "Avg game time in secs": 1.86186673634802, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3125, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.7, "agent_stopped_0": 0.35}, "Total num played games": 76672, "Total num trained steps": 152683, "Timestamp in ms": 1702083889025, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911852914330421, "Avg loss": 0.7581210350617766, "Avg value loss": 0.4351725176675245, "Avg policy loss": 0.32294851168990135, "Total num played games": 76690, "Total num trained steps": 152704, "Timestamp in ms": 1702083897917, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928543486764898, "Avg loss": 0.5316106472164392, "Avg value loss": 0.20414209764567204, "Avg policy loss": 0.3274685498327017, "Total num played games": 76690, "Total num trained steps": 152832, "Timestamp in ms": 1702083953983, "logtype": "training_step"}
{"Total num played games": 76784, "Total num trained steps": 152888, "Timestamp in ms": 1702084065955, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.73046875}
{"Avg objective": 21.6953125, "Games time in secs": 178.70609597489238, "Avg game time in secs": 1.7154328706674278, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.54, "agent_stopped_0": 0.5}, "Total num played games": 76800, "Total num trained steps": 152891, "Timestamp in ms": 1702084067732, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9896459325164546, "Avg loss": 1.3374790892703459, "Avg value loss": 1.001452975498978, "Avg policy loss": 0.336026115110144, "Total num played games": 76878, "Total num trained steps": 152960, "Timestamp in ms": 1702084098489, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9913109081922007, "Avg loss": 0.4609365190844983, "Avg value loss": 0.13253772677853703, "Avg policy loss": 0.32839879184029996, "Total num played games": 76878, "Total num trained steps": 153088, "Timestamp in ms": 1702084156935, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9929758838679466, "Avg loss": 0.37279655900783837, "Avg value loss": 0.06410554121248424, "Avg policy loss": 0.3086910202400759, "Total num played games": 76878, "Total num trained steps": 153216, "Timestamp in ms": 1702084215703, "logtype": "training_step"}
{"Avg objective": 21.1484375, "Games time in secs": 161.98992309719324, "Avg game time in secs": 1.7139150030270685, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.109375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.65}, "Total num played games": 76928, "Total num trained steps": 153249, "Timestamp in ms": 1702084229722, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9921402031854911, "Avg loss": 0.9283974992576987, "Avg value loss": 0.5977708643185906, "Avg policy loss": 0.3306266471045092, "Total num played games": 76974, "Total num trained steps": 153344, "Timestamp in ms": 1702084271516, "logtype": "training_step"}
{"Avg objective": 21.7578125, "Games time in secs": 86.33809182420373, "Avg game time in secs": 1.8504439073731191, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.28125, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.68, "agent_stopped_0": 0.38}, "Total num played games": 77056, "Total num trained steps": 153443, "Timestamp in ms": 1702084316060, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991384232106711, "Avg loss": 0.8425014752428979, "Avg value loss": 0.5223307060368825, "Avg policy loss": 0.3201707572443411, "Total num played games": 77068, "Total num trained steps": 153472, "Timestamp in ms": 1702084329138, "logtype": "training_step"}
{"Total num played games": 77068, "Total num trained steps": 153492, "Timestamp in ms": 1702084347965, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.375}
{"Ratio train steps to played games": 1.9906171431533657, "Avg loss": 1.0817143598105758, "Avg value loss": 0.7363222972489893, "Avg policy loss": 0.34539207024499774, "Total num played games": 77162, "Total num trained steps": 153600, "Timestamp in ms": 1702084394789, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9922630310256344, "Avg loss": 0.39701057341881096, "Avg value loss": 0.08783864948782139, "Avg policy loss": 0.3091719241347164, "Total num played games": 77162, "Total num trained steps": 153728, "Timestamp in ms": 1702084453198, "logtype": "training_step"}
{"Avg objective": 23.640625, "Games time in secs": 177.3439534343779, "Avg game time in secs": 1.822727806022158, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.6640625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.6, "agent_stopped_0": 0.45}, "Total num played games": 77184, "Total num trained steps": 153815, "Timestamp in ms": 1702084493404, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915087501294397, "Avg loss": 1.0065445064101368, "Avg value loss": 0.6926422549004201, "Avg policy loss": 0.3139022513059899, "Total num played games": 77256, "Total num trained steps": 153856, "Timestamp in ms": 1702084511345, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9931655793724758, "Avg loss": 0.4404719923622906, "Avg value loss": 0.12708416106761433, "Avg policy loss": 0.31338783248793334, "Total num played games": 77256, "Total num trained steps": 153984, "Timestamp in ms": 1702084568866, "logtype": "training_step"}
{"Avg objective": 21.8671875, "Games time in secs": 85.81935569643974, "Avg game time in secs": 1.7861147031362634, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1875, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.62}, "Total num played games": 77312, "Total num trained steps": 154005, "Timestamp in ms": 1702084579224, "logtype": "played_game"}
{"Total num played games": 77350, "Total num trained steps": 154093, "Timestamp in ms": 1702084677337, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.5625}
{"Avg objective": 21.890625, "Games time in secs": 101.69540183618665, "Avg game time in secs": 1.9168329589592759, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.4453125, "Avg reasons for ending game": {"agent_stopped_more": 0.59, "played_steps": 0.66, "agent_stopped_0": 0.41}, "Total num played games": 77440, "Total num trained steps": 154099, "Timestamp in ms": 1702084680919, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9899798564123754, "Avg loss": 0.9919608340132982, "Avg value loss": 0.6766690430813469, "Avg policy loss": 0.3152917883126065, "Total num played games": 77444, "Total num trained steps": 154112, "Timestamp in ms": 1702084686180, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9916326636020867, "Avg loss": 0.5695358684752136, "Avg value loss": 0.26333198725478724, "Avg policy loss": 0.3062038797652349, "Total num played games": 77444, "Total num trained steps": 154240, "Timestamp in ms": 1702084741896, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993285470791798, "Avg loss": 0.3530511911958456, "Avg value loss": 0.06275897068553604, "Avg policy loss": 0.290292217861861, "Total num played games": 77444, "Total num trained steps": 154368, "Timestamp in ms": 1702084798792, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925197967448218, "Avg loss": 0.7156482415739447, "Avg value loss": 0.42084953613812104, "Avg policy loss": 0.294798711896874, "Total num played games": 77538, "Total num trained steps": 154496, "Timestamp in ms": 1702084857501, "logtype": "training_step"}
{"Avg objective": 22.140625, "Games time in secs": 209.24584531784058, "Avg game time in secs": 1.6601363588124514, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3046875, "Avg reasons for ending game": {"agent_stopped_0": 0.5, "agent_stopped_more": 0.5, "played_steps": 0.55}, "Total num played games": 77568, "Total num trained steps": 154569, "Timestamp in ms": 1702084890165, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9917559769167354, "Avg loss": 0.5846556010656059, "Avg value loss": 0.29348445279174484, "Avg policy loss": 0.29117114993277937, "Total num played games": 77632, "Total num trained steps": 154624, "Timestamp in ms": 1702084916189, "logtype": "training_step"}
{"Total num played games": 77632, "Total num trained steps": 154695, "Timestamp in ms": 1702084959926, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.2109375}
{"Avg objective": 20.5234375, "Games time in secs": 72.22046622633934, "Avg game time in secs": 1.763690160762053, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.62, "agent_stopped_0": 0.43}, "Total num played games": 77696, "Total num trained steps": 154699, "Timestamp in ms": 1702084962386, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9909811388724494, "Avg loss": 0.6525195937138051, "Avg value loss": 0.360825881420169, "Avg policy loss": 0.29169371421448886, "Total num played games": 77726, "Total num trained steps": 154752, "Timestamp in ms": 1702084987215, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9926408151712425, "Avg loss": 0.37714107520878315, "Avg value loss": 0.08341541400295682, "Avg policy loss": 0.2937256619334221, "Total num played games": 77726, "Total num trained steps": 154880, "Timestamp in ms": 1702085044145, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9918786944230276, "Avg loss": 0.8120378612075001, "Avg value loss": 0.5066355621966068, "Avg policy loss": 0.305402297526598, "Total num played games": 77820, "Total num trained steps": 155008, "Timestamp in ms": 1702085100209, "logtype": "training_step"}
{"Avg objective": 22.9140625, "Games time in secs": 193.68814897537231, "Avg game time in secs": 1.8363319413911086, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.36, "agent_stopped_more": 0.64, "played_steps": 0.69}, "Total num played games": 77824, "Total num trained steps": 155131, "Timestamp in ms": 1702085156074, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913739987677141, "Avg loss": 0.4077262030914426, "Avg value loss": 0.10546536184847355, "Avg policy loss": 0.3022608398459852, "Total num played games": 77902, "Total num trained steps": 155136, "Timestamp in ms": 1702085157883, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927612495828735, "Avg loss": 0.725055880844593, "Avg value loss": 0.4257729048258625, "Avg policy loss": 0.2992829759605229, "Total num played games": 77914, "Total num trained steps": 155264, "Timestamp in ms": 1702085219786, "logtype": "training_step"}
{"Total num played games": 77914, "Total num trained steps": 155295, "Timestamp in ms": 1702085248623, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.8828125}
{"Avg objective": 20.2890625, "Games time in secs": 94.74752033874393, "Avg game time in secs": 1.7789161061518826, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1484375, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.62}, "Total num played games": 77952, "Total num trained steps": 155299, "Timestamp in ms": 1702085250822, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9920008204286739, "Avg loss": 0.849587697070092, "Avg value loss": 0.5521472088003065, "Avg policy loss": 0.2974404849810526, "Total num played games": 78008, "Total num trained steps": 155392, "Timestamp in ms": 1702085294373, "logtype": "training_step"}
{"Avg objective": 21.609375, "Games time in secs": 95.13599505648017, "Avg game time in secs": 1.819180546415737, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1953125, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 78080, "Total num trained steps": 155510, "Timestamp in ms": 1702085345958, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9911912322032161, "Avg loss": 0.5105636911466718, "Avg value loss": 0.22207526749116369, "Avg policy loss": 0.288488412508741, "Total num played games": 78104, "Total num trained steps": 155520, "Timestamp in ms": 1702085350057, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9928300727235482, "Avg loss": 0.6401008216198534, "Avg value loss": 0.3480956211569719, "Avg policy loss": 0.29200519795995206, "Total num played games": 78104, "Total num trained steps": 155648, "Timestamp in ms": 1702085406241, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9920586204250748, "Avg loss": 0.7713399355998263, "Avg value loss": 0.46803077749791555, "Avg policy loss": 0.3033091608667746, "Total num played games": 78198, "Total num trained steps": 155776, "Timestamp in ms": 1702085463421, "logtype": "training_step"}
{"Avg objective": 21.453125, "Games time in secs": 169.50991952046752, "Avg game time in secs": 1.8343092315481044, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5078125, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.68}, "Total num played games": 78208, "Total num trained steps": 155887, "Timestamp in ms": 1702085515468, "logtype": "played_game"}
{"Total num played games": 78292, "Total num trained steps": 155895, "Timestamp in ms": 1702085556305, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.80859375}
{"Avg objective": 21.265625, "Games time in secs": 43.02950570359826, "Avg game time in secs": 1.6344041127013043, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2578125, "Avg reasons for ending game": {"agent_stopped_0": 0.48, "agent_stopped_more": 0.52, "played_steps": 0.53}, "Total num played games": 78336, "Total num trained steps": 155899, "Timestamp in ms": 1702085558497, "logtype": "played_game"}
{"Ratio train steps to played games": 1.988926594034649, "Avg loss": 0.722019150853157, "Avg value loss": 0.42017802636837587, "Avg policy loss": 0.3018411287339404, "Total num played games": 78386, "Total num trained steps": 155904, "Timestamp in ms": 1702085561162, "logtype": "training_step"}
{"Ratio train steps to played games": 1.990559538693134, "Avg loss": 1.0818862500600517, "Avg value loss": 0.7439557524048723, "Avg policy loss": 0.33793050749227405, "Total num played games": 78386, "Total num trained steps": 156032, "Timestamp in ms": 1702085620504, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992192483351619, "Avg loss": 0.37725223414599895, "Avg value loss": 0.06725403454038315, "Avg policy loss": 0.3099981968989596, "Total num played games": 78386, "Total num trained steps": 156160, "Timestamp in ms": 1702085680654, "logtype": "training_step"}
{"Avg objective": 21.5078125, "Games time in secs": 172.9704293422401, "Avg game time in secs": 1.8688195002032444, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2890625, "Avg reasons for ending game": {"agent_stopped_more": 0.65, "played_steps": 0.71, "agent_stopped_0": 0.35}, "Total num played games": 78464, "Total num trained steps": 156266, "Timestamp in ms": 1702085731468, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913738182003518, "Avg loss": 0.7192090433090925, "Avg value loss": 0.40781807695748284, "Avg policy loss": 0.31139097071718425, "Total num played games": 78482, "Total num trained steps": 156288, "Timestamp in ms": 1702085741466, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993017507199103, "Avg loss": 0.5808419596869498, "Avg value loss": 0.2526675517729018, "Avg policy loss": 0.328174403286539, "Total num played games": 78482, "Total num trained steps": 156416, "Timestamp in ms": 1702085799821, "logtype": "training_step"}
{"Total num played games": 78580, "Total num trained steps": 156498, "Timestamp in ms": 1702085854742, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.59765625}
{"Avg objective": 22.6015625, "Games time in secs": 125.03897214308381, "Avg game time in secs": 1.8088441281579435, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.328125, "Avg reasons for ending game": {"agent_stopped_more": 0.57, "played_steps": 0.68, "agent_stopped_0": 0.43}, "Total num played games": 78592, "Total num trained steps": 156500, "Timestamp in ms": 1702085856507, "logtype": "played_game"}
{"Ratio train steps to played games": 1.989780613671607, "Avg loss": 1.3188886819407344, "Avg value loss": 0.9718847463082056, "Avg policy loss": 0.3470039148814976, "Total num played games": 78674, "Total num trained steps": 156544, "Timestamp in ms": 1702085875619, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9914075806492615, "Avg loss": 0.4772822947707027, "Avg value loss": 0.13691697287140414, "Avg policy loss": 0.340365321142599, "Total num played games": 78674, "Total num trained steps": 156672, "Timestamp in ms": 1702085934587, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9930345476269162, "Avg loss": 0.37202426919247955, "Avg value loss": 0.05706645510508679, "Avg policy loss": 0.3149578112643212, "Total num played games": 78674, "Total num trained steps": 156800, "Timestamp in ms": 1702085991702, "logtype": "training_step"}
{"Avg objective": 22.53125, "Games time in secs": 152.64268066734076, "Avg game time in secs": 1.7335033632116392, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1640625, "Avg reasons for ending game": {"agent_stopped_0": 0.41, "agent_stopped_more": 0.59, "played_steps": 0.61}, "Total num played games": 78720, "Total num trained steps": 156841, "Timestamp in ms": 1702086009150, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9922811293926468, "Avg loss": 0.6984317754395306, "Avg value loss": 0.3627442106953822, "Avg policy loss": 0.3356875568861142, "Total num played games": 78768, "Total num trained steps": 156928, "Timestamp in ms": 1702086047891, "logtype": "training_step"}
{"Avg objective": 21.8984375, "Games time in secs": 86.53583970293403, "Avg game time in secs": 1.8876220363017637, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2421875, "Avg reasons for ending game": {"agent_stopped_0": 0.34, "agent_stopped_more": 0.66, "played_steps": 0.68}, "Total num played games": 78848, "Total num trained steps": 157030, "Timestamp in ms": 1702086095686, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9915168268621135, "Avg loss": 0.5610477062873542, "Avg value loss": 0.23789520096033812, "Avg policy loss": 0.3231525089358911, "Total num played games": 78862, "Total num trained steps": 157056, "Timestamp in ms": 1702086108091, "logtype": "training_step"}
{"Total num played games": 78862, "Total num trained steps": 157098, "Timestamp in ms": 1702086151313, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.359375}
{"Ratio train steps to played games": 1.990767009473631, "Avg loss": 0.8055018442682922, "Avg value loss": 0.47488321049604565, "Avg policy loss": 0.3306186293484643, "Total num played games": 78956, "Total num trained steps": 157184, "Timestamp in ms": 1702086192119, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9924008308424945, "Avg loss": 0.38509800960309803, "Avg value loss": 0.0733028476824984, "Avg policy loss": 0.3117951628519222, "Total num played games": 78956, "Total num trained steps": 157312, "Timestamp in ms": 1702086251993, "logtype": "training_step"}
{"Avg objective": 22.3359375, "Games time in secs": 200.0040734820068, "Avg game time in secs": 1.9011183808906935, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.390625, "Avg reasons for ending game": {"agent_stopped_more": 0.55, "played_steps": 0.64, "agent_stopped_0": 0.45}, "Total num played games": 78976, "Total num trained steps": 157404, "Timestamp in ms": 1702086295690, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9916508538899431, "Avg loss": 0.6962169844191521, "Avg value loss": 0.37992138108529616, "Avg policy loss": 0.31629560759756714, "Total num played games": 79050, "Total num trained steps": 157440, "Timestamp in ms": 1702086312959, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9932700822264389, "Avg loss": 0.44038984063081443, "Avg value loss": 0.12071239019860514, "Avg policy loss": 0.3196774498792365, "Total num played games": 79050, "Total num trained steps": 157568, "Timestamp in ms": 1702086369967, "logtype": "training_step"}
{"Avg objective": 21.9453125, "Games time in secs": 85.55796425044537, "Avg game time in secs": 1.7549277264042757, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.38, "agent_stopped_more": 0.62, "played_steps": 0.66}, "Total num played games": 79104, "Total num trained steps": 157592, "Timestamp in ms": 1702086381248, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9924696131200565, "Avg loss": 0.7349344505928457, "Avg value loss": 0.4093183330260217, "Avg policy loss": 0.32561611849814653, "Total num played games": 79146, "Total num trained steps": 157696, "Timestamp in ms": 1702086430216, "logtype": "training_step"}
{"Total num played games": 79146, "Total num trained steps": 157700, "Timestamp in ms": 1702086486688, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.12109375}
{"Avg objective": 22.2734375, "Games time in secs": 108.55309680849314, "Avg game time in secs": 1.9272525408596266, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3203125, "Avg reasons for ending game": {"agent_stopped_more": 0.7, "played_steps": 0.73, "agent_stopped_0": 0.3}, "Total num played games": 79232, "Total num trained steps": 157705, "Timestamp in ms": 1702086489801, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991721352852095, "Avg loss": 0.7446105421986431, "Avg value loss": 0.409124152851291, "Avg policy loss": 0.33548638643696904, "Total num played games": 79240, "Total num trained steps": 157824, "Timestamp in ms": 1702086545762, "logtype": "training_step"}
{"Ratio train steps to played games": 1.993324078748107, "Avg loss": 0.37396826362237334, "Avg value loss": 0.06191938742995262, "Avg policy loss": 0.31204887735657394, "Total num played games": 79240, "Total num trained steps": 157952, "Timestamp in ms": 1702086604813, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9925756926412383, "Avg loss": 0.7236621219199151, "Avg value loss": 0.3975644650054164, "Avg policy loss": 0.3260976583696902, "Total num played games": 79334, "Total num trained steps": 158080, "Timestamp in ms": 1702086665978, "logtype": "training_step"}
{"Avg objective": 20.78125, "Games time in secs": 212.89735621213913, "Avg game time in secs": 1.8180349079775624, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.3515625, "Avg reasons for ending game": {"agent_stopped_more": 0.58, "played_steps": 0.62, "agent_stopped_0": 0.42}, "Total num played games": 79360, "Total num trained steps": 158160, "Timestamp in ms": 1702086702699, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9918416679256685, "Avg loss": 0.8392716548405588, "Avg value loss": 0.523659548809519, "Avg policy loss": 0.3156121108913794, "Total num played games": 79428, "Total num trained steps": 158208, "Timestamp in ms": 1702086723426, "logtype": "training_step"}
{"Total num played games": 79428, "Total num trained steps": 158301, "Timestamp in ms": 1702086837351, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.953125}
{"Avg objective": 21.1015625, "Games time in secs": 137.1259323321283, "Avg game time in secs": 1.8079224586545024, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.1796875, "Avg reasons for ending game": {"agent_stopped_0": 0.44, "agent_stopped_more": 0.56, "played_steps": 0.61}, "Total num played games": 79488, "Total num trained steps": 158306, "Timestamp in ms": 1702086839825, "logtype": "played_game"}
{"Ratio train steps to played games": 1.991096803400317, "Avg loss": 0.7025546357035637, "Avg value loss": 0.3729245436261408, "Avg policy loss": 0.32963008841034025, "Total num played games": 79522, "Total num trained steps": 158336, "Timestamp in ms": 1702086854081, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927064208646663, "Avg loss": 0.4696773726027459, "Avg value loss": 0.13982985593611374, "Avg policy loss": 0.32984751684125513, "Total num played games": 79522, "Total num trained steps": 158464, "Timestamp in ms": 1702086915059, "logtype": "training_step"}
{"Avg objective": 22.375, "Games time in secs": 109.83226434141397, "Avg game time in secs": 1.9248073044000193, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5390625, "Avg reasons for ending game": {"agent_stopped_more": 0.69, "played_steps": 0.77, "agent_stopped_0": 0.31}, "Total num played games": 79616, "Total num trained steps": 158540, "Timestamp in ms": 1702086949657, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919113768243362, "Avg loss": 0.9231092052068561, "Avg value loss": 0.5971204230736475, "Avg policy loss": 0.3259887807071209, "Total num played games": 79618, "Total num trained steps": 158592, "Timestamp in ms": 1702086971563, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935190534803688, "Avg loss": 0.40931207267567515, "Avg value loss": 0.08573228633031249, "Avg policy loss": 0.32357978529762477, "Total num played games": 79618, "Total num trained steps": 158720, "Timestamp in ms": 1702087029205, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9927114434101914, "Avg loss": 0.7573659284971654, "Avg value loss": 0.4339274936937727, "Avg policy loss": 0.32343843614216894, "Total num played games": 79714, "Total num trained steps": 158848, "Timestamp in ms": 1702087084962, "logtype": "training_step"}
{"Total num played games": 79714, "Total num trained steps": 158901, "Timestamp in ms": 1702087187289, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 24.09375}
{"Avg objective": 21.40625, "Games time in secs": 239.5480740442872, "Avg game time in secs": 1.6767011802294292, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.171875, "Avg reasons for ending game": {"agent_stopped_more": 0.5, "played_steps": 0.58, "agent_stopped_0": 0.5}, "Total num played games": 79744, "Total num trained steps": 158903, "Timestamp in ms": 1702087189205, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9919807538091419, "Avg loss": 0.751859997631982, "Avg value loss": 0.4303346951783169, "Avg policy loss": 0.32152530702296644, "Total num played games": 79808, "Total num trained steps": 158976, "Timestamp in ms": 1702087223954, "logtype": "training_step"}
{"Ratio train steps to played games": 1.9935720729751403, "Avg loss": 0.38830847945064306, "Avg value loss": 0.07199091149959713, "Avg policy loss": 0.31631756806746125, "Total num played games": 79808, "Total num trained steps": 159104, "Timestamp in ms": 1702087283467, "logtype": "training_step"}
{"Avg objective": 20.671875, "Games time in secs": 96.540961638093, "Avg game time in secs": 1.7399643575481605, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.234375, "Avg reasons for ending game": {"agent_stopped_0": 0.42, "agent_stopped_more": 0.58, "played_steps": 0.62}, "Total num played games": 79872, "Total num trained steps": 159109, "Timestamp in ms": 1702087285747, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9928412305073715, "Avg loss": 0.6444802877958864, "Avg value loss": 0.3371652004425414, "Avg policy loss": 0.3073150828713551, "Total num played games": 79902, "Total num trained steps": 159232, "Timestamp in ms": 1702087342193, "logtype": "training_step"}
{"Ratio train steps to played games": 1.992099604980249, "Avg loss": 0.7337188797537237, "Avg value loss": 0.43009862178587355, "Avg policy loss": 0.3036202534567565, "Total num played games": 79996, "Total num trained steps": 159360, "Timestamp in ms": 1702087402382, "logtype": "training_step"}
{"Avg objective": 22.21875, "Games time in secs": 170.3522583656013, "Avg game time in secs": 1.8524595799390227, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.5, "Avg reasons for ending game": {"agent_stopped_more": 0.62, "played_steps": 0.69, "agent_stopped_0": 0.38}, "Total num played games": 80000, "Total num trained steps": 159483, "Timestamp in ms": 1702087456099, "logtype": "played_game"}
{"Ratio train steps to played games": 1.9913969633403257, "Avg loss": 0.4088548836298287, "Avg value loss": 0.10216835921164602, "Avg policy loss": 0.306686521274969, "Total num played games": 80082, "Total num trained steps": 159488, "Timestamp in ms": 1702087459645, "logtype": "training_step"}
{"Total num played games": 80090, "Total num trained steps": 159488, "Timestamp in ms": 1702087478187, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 23.25390625}
{"Avg objective": 20.640625, "Games time in secs": 24.29899714514613, "Avg game time in secs": 1.7013977013994008, "Avg Inferencer Time in secs": 0, "Avg max search depth per move": 3.2109375, "Avg reasons for ending game": {"agent_stopped_0": 0.45, "agent_stopped_more": 0.55, "played_steps": 0.59}, "Total num played games": 80128, "Total num trained steps": 159488, "Timestamp in ms": 1702087480398, "logtype": "played_game"}
{"Total num played games": 80184, "Total num trained steps": 159488, "Timestamp in ms": 1702087527481, "logtype": "evaluation", "Evaluation Type": "Validation", "Evaluation MCTS": 22.96875}
